2022-11-16 16:15:01.838544 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 1 finished
---------------------------------------  -------------
epoch                                       1
total_step                               6000
replay_pool/size                         6000
trainer/alpha                               0.9997
trainer/alpha_loss                          0
trainer/entropy                             3.9709
trainer/qf_loss                            14.1851
trainer/policy_loss                        -4.00939
trainer/adversary_policy_loss             nan
trainer/policy_loss_without_entropy         0.0396791
trainer/entropy_penalty                     3.96971
trainer/entropy_percentage                100.045
trainer/Q1Pred Mean                        -0.0415065
trainer/Q1Pred Std                          0.064431
trainer/Q1Pred Max                          0.0974977
trainer/Q1Pred Min                         -0.233531
trainer/Q2Pred Mean                         0.135885
trainer/Q2Pred Std                          0.065056
trainer/Q2Pred Max                          0.341186
trainer/Q2Pred Min                         -0.00456847
trainer/QTargetWithReg Mean                 3.62479
trainer/QTargetWithReg Std                  1.17193
trainer/QTargetWithReg Max                  5.59111
trainer/QTargetWithReg Min                 -0.124064
trainer/PolicyLossWithoutReg Mean           0.0396791
trainer/PolicyLossWithoutReg Std            0.0571801
trainer/PolicyLossWithoutReg Max            0.164106
trainer/PolicyLossWithoutReg Min           -0.132295
exploration/num steps total              6000
exploration/num paths total               287
exploration/path length this epoch Mean    30.5667
exploration/path length this epoch Std     18.8338
exploration/path length this epoch Max     91
exploration/path length this epoch Min     10
exploration/Rewards Mean                    0.152989
exploration/Rewards Std                     0.603072
exploration/Rewards Max                     1.90435
exploration/Rewards Min                    -2.12008
exploration/Returns Mean                    4.67637
exploration/Returns Std                     7.14476
exploration/Returns Max                    30.7654
exploration/Returns Min                    -4.06664
exploration/Num Paths                      30
exploration/Average Returns                 4.67637
evaluation_0/num steps total             7870
evaluation_0/num paths total               48
evaluation_0/path length Mean             163.958
evaluation_0/path length Std                4.04639
evaluation_0/path length Max              173
evaluation_0/path length Min              155
evaluation_0/Rewards Mean                   0.248714
evaluation_0/Rewards Std                    0.712692
evaluation_0/Rewards Max                    1.13793
evaluation_0/Rewards Min                   -1.41953
evaluation_0/Returns Mean                  40.7788
evaluation_0/Returns Std                    3.74363
evaluation_0/Returns Max                   48.7955
evaluation_0/Returns Min                   32.2633
evaluation_0/Num Paths                     48
evaluation_0/Average Returns               40.7788
time/epoch (s)                              0
time/total (s)                             19.0335
Epoch                                       1
---------------------------------------  -------------
2022-11-16 16:15:15.029303 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 2 finished
---------------------------------------  ------------
epoch                                        2
total_step                                7000
replay_pool/size                          7000
trainer/alpha                                0.74379
trainer/alpha_loss                          -2.78226
trainer/entropy                              3.40873
trainer/qf_loss                              0.79334
trainer/policy_loss                        -16.5644
trainer/adversary_policy_loss                0.51597
trainer/policy_loss_without_entropy         14.029
trainer/entropy_penalty                      2.53538
trainer/entropy_percentage                   0.180725
trainer/Q1Pred Mean                         12.9696
trainer/Q1Pred Std                           4.79721
trainer/Q1Pred Max                          21.2643
trainer/Q1Pred Min                          -0.29264
trainer/Q2Pred Mean                         13.0322
trainer/Q2Pred Std                           4.80666
trainer/Q2Pred Max                          21.6181
trainer/Q2Pred Min                          -0.389478
trainer/QTargetWithReg Mean                 13.1657
trainer/QTargetWithReg Std                   4.84789
trainer/QTargetWithReg Max                  22.1354
trainer/QTargetWithReg Min                  -0.97699
trainer/PolicyLossWithoutReg Mean           14.029
trainer/PolicyLossWithoutReg Std             4.19778
trainer/PolicyLossWithoutReg Max            20.6571
trainer/PolicyLossWithoutReg Min             0.408141
exploration/num steps total               7000
exploration/num paths total                294
exploration/path length this epoch Mean    135.857
exploration/path length this epoch Std      82.7309
exploration/path length this epoch Max     319
exploration/path length this epoch Min      39
exploration/Rewards Mean                     0.399598
exploration/Rewards Std                      1.10244
exploration/Rewards Max                      3.99203
exploration/Rewards Min                     -2.08747
exploration/Returns Mean                    54.2882
exploration/Returns Std                    100.358
exploration/Returns Max                    229.907
exploration/Returns Min                    -35.2309
exploration/Num Paths                        7
exploration/Average Returns                 54.2882
evaluation_0/num steps total             15818
evaluation_0/num paths total                91
evaluation_0/path length Mean              184.837
evaluation_0/path length Std                13.9233
evaluation_0/path length Max               223
evaluation_0/path length Min               166
evaluation_0/Rewards Mean                    1.68031
evaluation_0/Rewards Std                     0.693012
evaluation_0/Rewards Max                     3.28209
evaluation_0/Rewards Min                     0.896515
evaluation_0/Returns Mean                  310.584
evaluation_0/Returns Std                    15.064
evaluation_0/Returns Max                   351.599
evaluation_0/Returns Min                   289.344
evaluation_0/Num Paths                      43
evaluation_0/Average Returns               310.584
time/epoch (s)                               0
time/total (s)                              32.2213
Epoch                                        2
---------------------------------------  ------------
2022-11-16 16:15:28.974664 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 3 finished
---------------------------------------  -------------
epoch                                        3
total_step                                8000
replay_pool/size                          8000
trainer/alpha                                0.563676
trainer/alpha_loss                          -4.78038
trainer/entropy                              2.34269
trainer/qf_loss                              2.67515
trainer/policy_loss                        -26.9228
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         25.6022
trainer/entropy_penalty                      1.32052
trainer/entropy_percentage                   0.0515782
trainer/Q1Pred Mean                         23.3316
trainer/Q1Pred Std                           7.299
trainer/Q1Pred Max                          38.0987
trainer/Q1Pred Min                          -2.44059
trainer/Q2Pred Mean                         23.1833
trainer/Q2Pred Std                           7.35176
trainer/Q2Pred Max                          37.6371
trainer/Q2Pred Min                          -1.65323
trainer/QTargetWithReg Mean                 23.2946
trainer/QTargetWithReg Std                   7.70624
trainer/QTargetWithReg Max                  39.5371
trainer/QTargetWithReg Min                  -1.64502
trainer/PolicyLossWithoutReg Mean           25.6022
trainer/PolicyLossWithoutReg Std             6.2668
trainer/PolicyLossWithoutReg Max            37.3656
trainer/PolicyLossWithoutReg Min            -1.41759
exploration/num steps total               8000
exploration/num paths total                299
exploration/path length this epoch Mean    189.4
exploration/path length this epoch Std      41.0297
exploration/path length this epoch Max     225
exploration/path length this epoch Min     111
exploration/Rewards Mean                     0.535272
exploration/Rewards Std                      0.997687
exploration/Rewards Max                      3.97344
exploration/Rewards Min                     -1.89806
exploration/Returns Mean                   101.381
exploration/Returns Std                    104.782
exploration/Returns Max                    304.06
exploration/Returns Min                     10.8092
exploration/Num Paths                        5
exploration/Average Returns                101.381
evaluation_0/num steps total             22907
evaluation_0/num paths total               104
evaluation_0/path length Mean              545.308
evaluation_0/path length Std               367.05
evaluation_0/path length Max              1000
evaluation_0/path length Min               198
evaluation_0/Rewards Mean                    1.18669
evaluation_0/Rewards Std                     0.475532
evaluation_0/Rewards Max                     3.7755
evaluation_0/Rewards Min                     0.0294294
evaluation_0/Returns Mean                  647.112
evaluation_0/Returns Std                   315.428
evaluation_0/Returns Max                  1043.27
evaluation_0/Returns Min                   332.589
evaluation_0/Num Paths                      13
evaluation_0/Average Returns               647.112
time/epoch (s)                               0
time/total (s)                              46.1652
Epoch                                        3
---------------------------------------  -------------
2022-11-16 16:15:42.469047 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 4 finished
---------------------------------------  -------------
epoch                                        4
total_step                                9000
replay_pool/size                          9000
trainer/alpha                                0.431239
trainer/alpha_loss                          -5.95465
trainer/entropy                              1.0819
trainer/qf_loss                              3.64657
trainer/policy_loss                        -36.2363
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         35.7697
trainer/entropy_penalty                      0.466558
trainer/entropy_percentage                   0.0130434
trainer/Q1Pred Mean                         32.4218
trainer/Q1Pred Std                          11.5378
trainer/Q1Pred Max                          63.253
trainer/Q1Pred Min                          -2.36628
trainer/Q2Pred Mean                         32.3228
trainer/Q2Pred Std                          11.5838
trainer/Q2Pred Max                          59.627
trainer/Q2Pred Min                          -3.69537
trainer/QTargetWithReg Mean                 31.9358
trainer/QTargetWithReg Std                  11.7573
trainer/QTargetWithReg Max                  59.6468
trainer/QTargetWithReg Min                  -4.15555
trainer/PolicyLossWithoutReg Mean           35.7697
trainer/PolicyLossWithoutReg Std             9.20806
trainer/PolicyLossWithoutReg Max            67.4892
trainer/PolicyLossWithoutReg Min            -4.0419
exploration/num steps total               9000
exploration/num paths total                302
exploration/path length this epoch Mean    293.667
exploration/path length this epoch Std      65.8297
exploration/path length this epoch Max     384
exploration/path length this epoch Min     229
exploration/Rewards Mean                     0.549489
exploration/Rewards Std                      0.848457
exploration/Rewards Max                      3.31345
exploration/Rewards Min                     -2.24732
exploration/Returns Mean                   161.367
exploration/Returns Std                     48.2131
exploration/Returns Max                    228.999
exploration/Returns Min                    120.06
exploration/Num Paths                        3
exploration/Average Returns                161.367
evaluation_0/num steps total             30825
evaluation_0/num paths total               155
evaluation_0/path length Mean              155.255
evaluation_0/path length Std                11.0398
evaluation_0/path length Max               180
evaluation_0/path length Min               141
evaluation_0/Rewards Mean                    1.96422
evaluation_0/Rewards Std                     0.883046
evaluation_0/Rewards Max                     4.18516
evaluation_0/Rewards Min                     0.844011
evaluation_0/Returns Mean                  304.955
evaluation_0/Returns Std                    14.923
evaluation_0/Returns Max                   338.129
evaluation_0/Returns Min                   283.248
evaluation_0/Num Paths                      51
evaluation_0/Average Returns               304.955
time/epoch (s)                               0
time/total (s)                              59.6599
Epoch                                        4
---------------------------------------  -------------
2022-11-16 16:15:55.265905 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 5 finished
---------------------------------------  -------------
epoch                                        5
total_step                               10000
replay_pool/size                         10000
trainer/alpha                                0.32712
trainer/alpha_loss                          -7.92904
trainer/entropy                              1.09761
trainer/qf_loss                              3.47235
trainer/policy_loss                        -45.0589
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         44.6998
trainer/entropy_penalty                      0.359051
trainer/entropy_percentage                   0.0080325
trainer/Q1Pred Mean                         41.02
trainer/Q1Pred Std                          11.8787
trainer/Q1Pred Max                          75.2347
trainer/Q1Pred Min                          -2.7613
trainer/Q2Pred Mean                         40.996
trainer/Q2Pred Std                          11.7878
trainer/Q2Pred Max                          74.3033
trainer/Q2Pred Min                          -2.82021
trainer/QTargetWithReg Mean                 41.3991
trainer/QTargetWithReg Std                  12.4844
trainer/QTargetWithReg Max                  79.5346
trainer/QTargetWithReg Min                  -0.848517
trainer/PolicyLossWithoutReg Mean           44.6998
trainer/PolicyLossWithoutReg Std             9.31445
trainer/PolicyLossWithoutReg Max            78.5259
trainer/PolicyLossWithoutReg Min             1.95418
exploration/num steps total              10000
exploration/num paths total                306
exploration/path length this epoch Mean    193.25
exploration/path length this epoch Std      59.9223
exploration/path length this epoch Max     264
exploration/path length this epoch Min     117
exploration/Rewards Mean                     0.996537
exploration/Rewards Std                      1.04165
exploration/Rewards Max                      3.99628
exploration/Rewards Min                     -1.84303
exploration/Returns Mean                   192.581
exploration/Returns Std                    134.759
exploration/Returns Max                    412.542
exploration/Returns Min                     71.7085
exploration/Num Paths                        4
exploration/Average Returns                192.581
evaluation_0/num steps total             38789
evaluation_0/num paths total               197
evaluation_0/path length Mean              189.619
evaluation_0/path length Std                16.6031
evaluation_0/path length Max               239
evaluation_0/path length Min               171
evaluation_0/Rewards Mean                    1.92981
evaluation_0/Rewards Std                     0.94565
evaluation_0/Rewards Max                     4.24905
evaluation_0/Rewards Min                     0.675529
evaluation_0/Returns Mean                  365.93
evaluation_0/Returns Std                    16.4119
evaluation_0/Returns Max                   414.81
evaluation_0/Returns Min                   345.935
evaluation_0/Num Paths                      42
evaluation_0/Average Returns               365.93
time/epoch (s)                               0
time/total (s)                              72.4565
Epoch                                        5
---------------------------------------  -------------
2022-11-16 16:16:08.324328 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 6 finished
---------------------------------------  --------------
epoch                                        6
total_step                               11000
replay_pool/size                         11000
trainer/alpha                                0.244597
trainer/alpha_loss                         -10.102
trainer/entropy                              1.17546
trainer/qf_loss                              4.45373
trainer/policy_loss                        -50.795
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         50.5075
trainer/entropy_penalty                      0.287513
trainer/entropy_percentage                   0.00569248
trainer/Q1Pred Mean                         47.6784
trainer/Q1Pred Std                          13.761
trainer/Q1Pred Max                          96.459
trainer/Q1Pred Min                         -12.4492
trainer/Q2Pred Mean                         47.8392
trainer/Q2Pred Std                          13.7437
trainer/Q2Pred Max                          97.8339
trainer/Q2Pred Min                         -13.924
trainer/QTargetWithReg Mean                 47.6537
trainer/QTargetWithReg Std                  14.0904
trainer/QTargetWithReg Max                  97.4977
trainer/QTargetWithReg Min                 -10.8987
trainer/PolicyLossWithoutReg Mean           50.5075
trainer/PolicyLossWithoutReg Std            12.0788
trainer/PolicyLossWithoutReg Max           102.479
trainer/PolicyLossWithoutReg Min           -13.2823
exploration/num steps total              11000
exploration/num paths total                312
exploration/path length this epoch Mean    161.667
exploration/path length this epoch Std      22.4252
exploration/path length this epoch Max     189
exploration/path length this epoch Min     125
exploration/Rewards Mean                     0.946131
exploration/Rewards Std                      1.20322
exploration/Rewards Max                      4.18186
exploration/Rewards Min                     -1.6696
exploration/Returns Mean                   152.958
exploration/Returns Std                    139.85
exploration/Returns Max                    332.827
exploration/Returns Min                      2.64687
exploration/Num Paths                        6
exploration/Average Returns                152.958
evaluation_0/num steps total             46765
evaluation_0/num paths total               236
evaluation_0/path length Mean              204.513
evaluation_0/path length Std                61.1995
evaluation_0/path length Max               408
evaluation_0/path length Min               133
evaluation_0/Rewards Mean                    1.44137
evaluation_0/Rewards Std                     1.14309
evaluation_0/Rewards Max                     5.06598
evaluation_0/Rewards Min                    -1.88732
evaluation_0/Returns Mean                  294.778
evaluation_0/Returns Std                   100.419
evaluation_0/Returns Max                   500.403
evaluation_0/Returns Min                    82.3262
evaluation_0/Num Paths                      39
evaluation_0/Average Returns               294.778
time/epoch (s)                               0
time/total (s)                              85.5144
Epoch                                        6
---------------------------------------  --------------
2022-11-16 16:16:21.826159 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
total_step                               12000
replay_pool/size                         12000
trainer/alpha                                0.182907
trainer/alpha_loss                         -10.5899
trainer/entropy                              0.234872
trainer/qf_loss                              4.94665
trainer/policy_loss                        -54.524
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         54.481
trainer/entropy_penalty                      0.0429597
trainer/entropy_percentage                   0.000788525
trainer/Q1Pred Mean                         51.5795
trainer/Q1Pred Std                          15.7553
trainer/Q1Pred Max                          90.5728
trainer/Q1Pred Min                         -11.2522
trainer/Q2Pred Mean                         51.2357
trainer/Q2Pred Std                          15.8073
trainer/Q2Pred Max                          84.1109
trainer/Q2Pred Min                         -10.0261
trainer/QTargetWithReg Mean                 51.433
trainer/QTargetWithReg Std                  15.8229
trainer/QTargetWithReg Max                  89.3739
trainer/QTargetWithReg Min                 -12.3925
trainer/PolicyLossWithoutReg Mean           54.4811
trainer/PolicyLossWithoutReg Std            12.8978
trainer/PolicyLossWithoutReg Max            82.0613
trainer/PolicyLossWithoutReg Min            -7.55501
exploration/num steps total              12000
exploration/num paths total                318
exploration/path length this epoch Mean    140.333
exploration/path length this epoch Std      43.6068
exploration/path length this epoch Max     220
exploration/path length this epoch Min      95
exploration/Rewards Mean                     1.42252
exploration/Rewards Std                      1.15804
exploration/Rewards Max                      5.62871
exploration/Rewards Min                     -1.17592
exploration/Returns Mean                   199.627
exploration/Returns Std                     76.8705
exploration/Returns Max                    334.354
exploration/Returns Min                     83.7513
exploration/Num Paths                        6
exploration/Average Returns                199.627
evaluation_0/num steps total             54723
evaluation_0/num paths total               276
evaluation_0/path length Mean              198.95
evaluation_0/path length Std                10.1807
evaluation_0/path length Max               212
evaluation_0/path length Min               163
evaluation_0/Rewards Mean                    1.84115
evaluation_0/Rewards Std                     1.19328
evaluation_0/Rewards Max                     7.77397
evaluation_0/Rewards Min                    -0.460866
evaluation_0/Returns Mean                  366.298
evaluation_0/Returns Std                    20.1922
evaluation_0/Returns Max                   394.672
evaluation_0/Returns Min                   297.948
evaluation_0/Num Paths                      40
evaluation_0/Average Returns               366.298
time/epoch (s)                               0
time/total (s)                              99.0164
Epoch                                        7
---------------------------------------  ---------------
2022-11-16 16:16:35.141962 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 8 finished
---------------------------------------  --------------
epoch                                        8
total_step                               13000
replay_pool/size                         13000
trainer/alpha                                0.140394
trainer/alpha_loss                          -9.62131
trainer/entropy                             -1.09882
trainer/qf_loss                              4.68933
trainer/policy_loss                        -60.262
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         60.4162
trainer/entropy_penalty                     -0.154267
trainer/entropy_percentage                  -0.00255341
trainer/Q1Pred Mean                         58.4431
trainer/Q1Pred Std                          17.1037
trainer/Q1Pred Max                         127.778
trainer/Q1Pred Min                         -14.5541
trainer/Q2Pred Mean                         58.61
trainer/Q2Pred Std                          16.9929
trainer/Q2Pred Max                         124.545
trainer/Q2Pred Min                         -13.9587
trainer/QTargetWithReg Mean                 58.5526
trainer/QTargetWithReg Std                  16.9716
trainer/QTargetWithReg Max                 125.841
trainer/QTargetWithReg Min                 -12.8511
trainer/PolicyLossWithoutReg Mean           60.4162
trainer/PolicyLossWithoutReg Std            15.8348
trainer/PolicyLossWithoutReg Max           124.966
trainer/PolicyLossWithoutReg Min           -10.3775
exploration/num steps total              13000
exploration/num paths total                326
exploration/path length this epoch Mean    117
exploration/path length this epoch Std      38.594
exploration/path length this epoch Max     154
exploration/path length this epoch Min      45
exploration/Rewards Mean                     1.66883
exploration/Rewards Std                      1.17677
exploration/Rewards Max                      5.72832
exploration/Rewards Min                     -0.625907
exploration/Returns Mean                   195.253
exploration/Returns Std                     99.0276
exploration/Returns Max                    297.326
exploration/Returns Min                     24.4803
exploration/Num Paths                        8
exploration/Average Returns                195.253
evaluation_0/num steps total             62707
evaluation_0/num paths total               309
evaluation_0/path length Mean              241.939
evaluation_0/path length Std                58.4719
evaluation_0/path length Max               471
evaluation_0/path length Min               163
evaluation_0/Rewards Mean                    1.06896
evaluation_0/Rewards Std                     0.920207
evaluation_0/Rewards Max                     4.32771
evaluation_0/Rewards Min                    -1.26326
evaluation_0/Returns Mean                  258.624
evaluation_0/Returns Std                   109.042
evaluation_0/Returns Max                   578.378
evaluation_0/Returns Min                    88.4797
evaluation_0/Num Paths                      33
evaluation_0/Average Returns               258.624
time/epoch (s)                               0
time/total (s)                             112.332
Epoch                                        8
---------------------------------------  --------------
2022-11-16 16:16:48.120181 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 9 finished
---------------------------------------  --------------
epoch                                        9
total_step                               14000
replay_pool/size                         14000
trainer/alpha                                0.111104
trainer/alpha_loss                          -8.17997
trainer/entropy                             -2.27686
trainer/qf_loss                              5.60474
trainer/policy_loss                        -61.7099
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         61.9629
trainer/entropy_penalty                     -0.252969
trainer/entropy_percentage                  -0.00408259
trainer/Q1Pred Mean                         59.943
trainer/Q1Pred Std                          21.0234
trainer/Q1Pred Max                         106.096
trainer/Q1Pred Min                         -10.0832
trainer/Q2Pred Mean                         59.5791
trainer/Q2Pred Std                          21.2273
trainer/Q2Pred Max                         105.387
trainer/Q2Pred Min                         -11.3659
trainer/QTargetWithReg Mean                 59.7158
trainer/QTargetWithReg Std                  21.6003
trainer/QTargetWithReg Max                 106.098
trainer/QTargetWithReg Min                 -10.5336
trainer/PolicyLossWithoutReg Mean           61.9629
trainer/PolicyLossWithoutReg Std            19.1393
trainer/PolicyLossWithoutReg Max           104.985
trainer/PolicyLossWithoutReg Min            -9.42138
exploration/num steps total              14000
exploration/num paths total                333
exploration/path length this epoch Mean    130
exploration/path length this epoch Std      42.5642
exploration/path length this epoch Max     216
exploration/path length this epoch Min      84
exploration/Rewards Mean                     1.38025
exploration/Rewards Std                      1.18504
exploration/Rewards Max                      5.25957
exploration/Rewards Min                     -2.03596
exploration/Returns Mean                   179.432
exploration/Returns Std                     82.8529
exploration/Returns Max                    309.224
exploration/Returns Min                     62.5342
exploration/Num Paths                        7
exploration/Average Returns                179.432
evaluation_0/num steps total             70638
evaluation_0/num paths total               352
evaluation_0/path length Mean              184.442
evaluation_0/path length Std                36.0364
evaluation_0/path length Max               281
evaluation_0/path length Min               100
evaluation_0/Rewards Mean                    0.601502
evaluation_0/Rewards Std                     0.914599
evaluation_0/Rewards Max                     5.04602
evaluation_0/Rewards Min                    -0.675622
evaluation_0/Returns Mean                  110.942
evaluation_0/Returns Std                    81.0464
evaluation_0/Returns Max                   287.781
evaluation_0/Returns Min                    34.2243
evaluation_0/Num Paths                      43
evaluation_0/Average Returns               110.942
time/epoch (s)                               0
time/total (s)                             125.31
Epoch                                        9
---------------------------------------  --------------
2022-11-16 16:17:03.939464 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 10 finished
---------------------------------------  --------------
epoch                                       10
total_step                               15000
replay_pool/size                         15000
trainer/alpha                                0.0891968
trainer/alpha_loss                          -6.72532
trainer/entropy                             -3.21715
trainer/qf_loss                              6.94491
trainer/policy_loss                        -68.2868
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         68.5738
trainer/entropy_penalty                     -0.28696
trainer/entropy_percentage                  -0.00418469
trainer/Q1Pred Mean                         66.0553
trainer/Q1Pred Std                          21.6435
trainer/Q1Pred Max                         115.52
trainer/Q1Pred Min                         -15.8954
trainer/Q2Pred Mean                         65.6823
trainer/Q2Pred Std                          21.5342
trainer/Q2Pred Max                         114.942
trainer/Q2Pred Min                         -16.094
trainer/QTargetWithReg Mean                 66.0336
trainer/QTargetWithReg Std                  22.1008
trainer/QTargetWithReg Max                 115.081
trainer/QTargetWithReg Min                 -16.7403
trainer/PolicyLossWithoutReg Mean           68.5738
trainer/PolicyLossWithoutReg Std            19.3479
trainer/PolicyLossWithoutReg Max           113.428
trainer/PolicyLossWithoutReg Min           -16.0882
exploration/num steps total              15000
exploration/num paths total                338
exploration/path length this epoch Mean    172.6
exploration/path length this epoch Std      72.8686
exploration/path length this epoch Max     275
exploration/path length this epoch Min      57
exploration/Rewards Mean                     1.252
exploration/Rewards Std                      1.14062
exploration/Rewards Max                      5.54618
exploration/Rewards Min                     -2.77197
exploration/Returns Mean                   216.096
exploration/Returns Std                     93.5061
exploration/Returns Max                    289.986
exploration/Returns Min                     33.3746
exploration/Num Paths                        5
exploration/Average Returns                216.096
evaluation_0/num steps total             78490
evaluation_0/num paths total               376
evaluation_0/path length Mean              327.167
evaluation_0/path length Std               212.276
evaluation_0/path length Max               997
evaluation_0/path length Min                65
evaluation_0/Rewards Mean                    0.731838
evaluation_0/Rewards Std                     1.09828
evaluation_0/Rewards Max                     5.58609
evaluation_0/Rewards Min                    -3.3493
evaluation_0/Returns Mean                  239.433
evaluation_0/Returns Std                   202.109
evaluation_0/Returns Max                   627.267
evaluation_0/Returns Min                   -15.7508
evaluation_0/Num Paths                      24
evaluation_0/Average Returns               239.433
time/epoch (s)                               0
time/total (s)                             141.128
Epoch                                       10
---------------------------------------  --------------
2022-11-16 16:17:17.464546 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 11 finished
---------------------------------------  --------------
epoch                                       11
total_step                               16000
replay_pool/size                         16000
trainer/alpha                                0.0732024
trainer/alpha_loss                          -5.35902
trainer/entropy                             -3.95015
trainer/qf_loss                              5.88074
trainer/policy_loss                        -73.746
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         74.0351
trainer/entropy_penalty                     -0.289161
trainer/entropy_percentage                  -0.00390572
trainer/Q1Pred Mean                         70.4878
trainer/Q1Pred Std                          21.6761
trainer/Q1Pred Max                         122.003
trainer/Q1Pred Min                         -13.3295
trainer/Q2Pred Mean                         70.6184
trainer/Q2Pred Std                          21.8602
trainer/Q2Pred Max                         122.372
trainer/Q2Pred Min                         -13.089
trainer/QTargetWithReg Mean                 70.1396
trainer/QTargetWithReg Std                  22.2422
trainer/QTargetWithReg Max                 120.828
trainer/QTargetWithReg Min                 -14.8132
trainer/PolicyLossWithoutReg Mean           74.0351
trainer/PolicyLossWithoutReg Std            18.0947
trainer/PolicyLossWithoutReg Max           121.579
trainer/PolicyLossWithoutReg Min           -11.4976
exploration/num steps total              16000
exploration/num paths total                346
exploration/path length this epoch Mean    114.75
exploration/path length this epoch Std      80.6392
exploration/path length this epoch Max     232
exploration/path length this epoch Min      35
exploration/Rewards Mean                     0.808495
exploration/Rewards Std                      1.2476
exploration/Rewards Max                      4.92631
exploration/Rewards Min                     -1.83191
exploration/Returns Mean                    92.7748
exploration/Returns Std                    128.596
exploration/Returns Max                    332.186
exploration/Returns Min                    -11.6671
exploration/Num Paths                        8
exploration/Average Returns                 92.7748
evaluation_0/num steps total             86483
evaluation_0/num paths total               416
evaluation_0/path length Mean              199.825
evaluation_0/path length Std                56.5946
evaluation_0/path length Max               433
evaluation_0/path length Min               137
evaluation_0/Rewards Mean                    1.45038
evaluation_0/Rewards Std                     1.13002
evaluation_0/Rewards Max                     5.74925
evaluation_0/Rewards Min                    -2.42513
evaluation_0/Returns Mean                  289.823
evaluation_0/Returns Std                    73.8608
evaluation_0/Returns Max                   458.426
evaluation_0/Returns Min                    93.8333
evaluation_0/Num Paths                      40
evaluation_0/Average Returns               289.823
time/epoch (s)                               0
time/total (s)                             154.654
Epoch                                       11
---------------------------------------  --------------
2022-11-16 16:17:32.126059 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 12 finished
---------------------------------------  --------------
epoch                                       12
total_step                               17000
replay_pool/size                         17000
trainer/alpha                                0.05957
trainer/alpha_loss                          -3.97649
trainer/entropy                             -4.5901
trainer/qf_loss                              5.84394
trainer/policy_loss                        -72.3229
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy         72.5964
trainer/entropy_penalty                     -0.273432
trainer/entropy_percentage                  -0.00376647
trainer/Q1Pred Mean                         69.901
trainer/Q1Pred Std                          25.3763
trainer/Q1Pred Max                         116.344
trainer/Q1Pred Min                         -15.673
trainer/Q2Pred Mean                         70.1547
trainer/Q2Pred Std                          25.5015
trainer/Q2Pred Max                         118.202
trainer/Q2Pred Min                         -15.2134
trainer/QTargetWithReg Mean                 69.5365
trainer/QTargetWithReg Std                  25.767
trainer/QTargetWithReg Max                 116.287
trainer/QTargetWithReg Min                 -14.0513
trainer/PolicyLossWithoutReg Mean           72.5964
trainer/PolicyLossWithoutReg Std            23.4035
trainer/PolicyLossWithoutReg Max           119.458
trainer/PolicyLossWithoutReg Min           -14.123
exploration/num steps total              17000
exploration/num paths total                350
exploration/path length this epoch Mean    218
exploration/path length this epoch Std      63.9492
exploration/path length this epoch Max     296
exploration/path length this epoch Min     131
exploration/Rewards Mean                     1.03733
exploration/Rewards Std                      1.54171
exploration/Rewards Max                      6.32559
exploration/Rewards Min                     -4.01836
exploration/Returns Mean                   226.137
exploration/Returns Std                    180.639
exploration/Returns Max                    379.161
exploration/Returns Min                    -67.29
exploration/Num Paths                        4
exploration/Average Returns                226.137
evaluation_0/num steps total             94402
evaluation_0/num paths total               458
evaluation_0/path length Mean              188.548
evaluation_0/path length Std                82.6707
evaluation_0/path length Max               548
evaluation_0/path length Min               101
evaluation_0/Rewards Mean                    1.92713
evaluation_0/Rewards Std                     1.32023
evaluation_0/Rewards Max                     6.77697
evaluation_0/Rewards Min                    -2.36457
evaluation_0/Returns Mean                  363.355
evaluation_0/Returns Std                   199.291
evaluation_0/Returns Max                   908.675
evaluation_0/Returns Min                   106.155
evaluation_0/Num Paths                      42
evaluation_0/Average Returns               363.355
time/epoch (s)                               0
time/total (s)                             169.314
Epoch                                       12
---------------------------------------  --------------
2022-11-16 16:17:45.156039 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 13 finished
---------------------------------------  ---------------
epoch                                        13
total_step                                18000
replay_pool/size                          18000
trainer/alpha                                 0.0483251
trainer/alpha_loss                           -3.18749
trainer/entropy                              -4.94788
trainer/qf_loss                               7.06842
trainer/policy_loss                         -77.0726
trainer/adversary_policy_loss                 3.29055
trainer/policy_loss_without_entropy          77.3117
trainer/entropy_penalty                      -0.239107
trainer/entropy_percentage                   -0.00309276
trainer/Q1Pred Mean                          74.3766
trainer/Q1Pred Std                           24.9271
trainer/Q1Pred Max                          121.136
trainer/Q1Pred Min                          -15.4056
trainer/Q2Pred Mean                          74.4145
trainer/Q2Pred Std                           24.8483
trainer/Q2Pred Max                          119.97
trainer/Q2Pred Min                          -14.6071
trainer/QTargetWithReg Mean                  74.838
trainer/QTargetWithReg Std                   25.0595
trainer/QTargetWithReg Max                  120.729
trainer/QTargetWithReg Min                  -14.2576
trainer/PolicyLossWithoutReg Mean            77.3117
trainer/PolicyLossWithoutReg Std             22.3957
trainer/PolicyLossWithoutReg Max            120.286
trainer/PolicyLossWithoutReg Min            -14.8649
exploration/num steps total               18000
exploration/num paths total                 356
exploration/path length this epoch Mean     152.5
exploration/path length this epoch Std       62.9252
exploration/path length this epoch Max      238
exploration/path length this epoch Min       45
exploration/Rewards Mean                      1.11281
exploration/Rewards Std                       1.38875
exploration/Rewards Max                       5.29584
exploration/Rewards Min                      -2.76391
exploration/Returns Mean                    169.703
exploration/Returns Std                     117.884
exploration/Returns Max                     314.302
exploration/Returns Min                       6.21506
exploration/Num Paths                         6
exploration/Average Returns                 169.703
evaluation_0/num steps total             102314
evaluation_0/num paths total                510
evaluation_0/path length Mean               152.154
evaluation_0/path length Std                 38.5573
evaluation_0/path length Max                256
evaluation_0/path length Min                 83
evaluation_0/Rewards Mean                     2.13134
evaluation_0/Rewards Std                      1.08265
evaluation_0/Rewards Max                      6.60971
evaluation_0/Rewards Min                     -0.293949
evaluation_0/Returns Mean                   324.291
evaluation_0/Returns Std                    100.182
evaluation_0/Returns Max                    514.277
evaluation_0/Returns Min                    146.685
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                324.291
time/epoch (s)                                0
time/total (s)                              182.344
Epoch                                        13
---------------------------------------  ---------------
2022-11-16 16:17:59.730223 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 14 finished
---------------------------------------  ---------------
epoch                                        14
total_step                                19000
replay_pool/size                          19000
trainer/alpha                                 0.0428678
trainer/alpha_loss                           -0.381076
trainer/entropy                              -5.87901
trainer/qf_loss                               6.89455
trainer/policy_loss                         -75.6236
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          75.8756
trainer/entropy_penalty                      -0.25202
trainer/entropy_percentage                   -0.00332149
trainer/Q1Pred Mean                          73.4997
trainer/Q1Pred Std                           27.9503
trainer/Q1Pred Max                          121.145
trainer/Q1Pred Min                          -18.6847
trainer/Q2Pred Mean                          73.3682
trainer/Q2Pred Std                           28.0797
trainer/Q2Pred Max                          122.352
trainer/Q2Pred Min                          -15.3608
trainer/QTargetWithReg Mean                  73.4287
trainer/QTargetWithReg Std                   28.2468
trainer/QTargetWithReg Max                  121.478
trainer/QTargetWithReg Min                  -16.6349
trainer/PolicyLossWithoutReg Mean            75.8756
trainer/PolicyLossWithoutReg Std             26.5203
trainer/PolicyLossWithoutReg Max            126.334
trainer/PolicyLossWithoutReg Min            -14.9174
exploration/num steps total               19000
exploration/num paths total                 361
exploration/path length this epoch Mean     189.2
exploration/path length this epoch Std       85.1831
exploration/path length this epoch Max      313
exploration/path length this epoch Min       94
exploration/Rewards Mean                      1.66284
exploration/Rewards Std                       1.17855
exploration/Rewards Max                       5.17697
exploration/Rewards Min                      -1.68196
exploration/Returns Mean                    314.61
exploration/Returns Std                     150.361
exploration/Returns Max                     545.858
exploration/Returns Min                     162.014
exploration/Num Paths                         5
exploration/Average Returns                 314.61
evaluation_0/num steps total             110226
evaluation_0/num paths total                558
evaluation_0/path length Mean               164.833
evaluation_0/path length Std                131.183
evaluation_0/path length Max               1000
evaluation_0/path length Min                 83
evaluation_0/Rewards Mean                     1.76729
evaluation_0/Rewards Std                      1.07992
evaluation_0/Rewards Max                      6.32697
evaluation_0/Rewards Min                     -1.22746
evaluation_0/Returns Mean                   291.309
evaluation_0/Returns Std                    152.579
evaluation_0/Returns Max                   1097.22
evaluation_0/Returns Min                    141.731
evaluation_0/Num Paths                       48
evaluation_0/Average Returns                291.309
time/epoch (s)                                0
time/total (s)                              196.918
Epoch                                        14
---------------------------------------  ---------------
2022-11-16 16:18:15.400074 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 15 finished
---------------------------------------  ---------------
epoch                                        15
total_step                                20000
replay_pool/size                          20000
trainer/alpha                                 0.0450532
trainer/alpha_loss                            0.984493
trainer/entropy                              -6.31758
trainer/qf_loss                               5.7406
trainer/policy_loss                         -82.8027
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          83.0873
trainer/entropy_penalty                      -0.284627
trainer/entropy_percentage                   -0.00342564
trainer/Q1Pred Mean                          80.856
trainer/Q1Pred Std                           23.5601
trainer/Q1Pred Max                          134.603
trainer/Q1Pred Min                           -5.70854
trainer/Q2Pred Mean                          80.9963
trainer/Q2Pred Std                           23.6702
trainer/Q2Pred Max                          132.54
trainer/Q2Pred Min                           -7.31698
trainer/QTargetWithReg Mean                  80.862
trainer/QTargetWithReg Std                   23.691
trainer/QTargetWithReg Max                  135.912
trainer/QTargetWithReg Min                   -0.296966
trainer/PolicyLossWithoutReg Mean            83.0873
trainer/PolicyLossWithoutReg Std             21.5552
trainer/PolicyLossWithoutReg Max            135.247
trainer/PolicyLossWithoutReg Min             -2.36522
exploration/num steps total               20000
exploration/num paths total                 367
exploration/path length this epoch Mean     144
exploration/path length this epoch Std       52.1696
exploration/path length this epoch Max      244
exploration/path length this epoch Min       66
exploration/Rewards Mean                      1.54211
exploration/Rewards Std                       1.19023
exploration/Rewards Max                       5.40235
exploration/Rewards Min                      -0.831618
exploration/Returns Mean                    222.063
exploration/Returns Std                      72.7168
exploration/Returns Max                     318.875
exploration/Returns Min                     106.462
exploration/Num Paths                         6
exploration/Average Returns                 222.063
evaluation_0/num steps total             118215
evaluation_0/num paths total                585
evaluation_0/path length Mean               295.889
evaluation_0/path length Std                194.114
evaluation_0/path length Max               1000
evaluation_0/path length Min                135
evaluation_0/Rewards Mean                     1.2575
evaluation_0/Rewards Std                      1.23466
evaluation_0/Rewards Max                      6.33319
evaluation_0/Rewards Min                     -2.57184
evaluation_0/Returns Mean                   372.08
evaluation_0/Returns Std                    214.165
evaluation_0/Returns Max                    976.836
evaluation_0/Returns Min                    -98.7921
evaluation_0/Num Paths                       27
evaluation_0/Average Returns                372.08
time/epoch (s)                                0
time/total (s)                              212.587
Epoch                                        15
---------------------------------------  ---------------
2022-11-16 16:18:28.762056 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 16 finished
---------------------------------------  ---------------
epoch                                        16
total_step                                21000
replay_pool/size                          21000
trainer/alpha                                 0.0499768
trainer/alpha_loss                           -1.25506
trainer/entropy                              -5.5811
trainer/qf_loss                               8.31909
trainer/policy_loss                         -87.313
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          87.5919
trainer/entropy_penalty                      -0.278926
trainer/entropy_percentage                   -0.00318438
trainer/Q1Pred Mean                          85.0277
trainer/Q1Pred Std                           24.9876
trainer/Q1Pred Max                          143.726
trainer/Q1Pred Min                          -11.8955
trainer/Q2Pred Mean                          84.9377
trainer/Q2Pred Std                           25.005
trainer/Q2Pred Max                          144.52
trainer/Q2Pred Min                          -11.707
trainer/QTargetWithReg Mean                  85.3626
trainer/QTargetWithReg Std                   25.1879
trainer/QTargetWithReg Max                  143.634
trainer/QTargetWithReg Min                  -12.9283
trainer/PolicyLossWithoutReg Mean            87.5919
trainer/PolicyLossWithoutReg Std             23.0043
trainer/PolicyLossWithoutReg Max            145.867
trainer/PolicyLossWithoutReg Min            -10.467
exploration/num steps total               21000
exploration/num paths total                 374
exploration/path length this epoch Mean     142.571
exploration/path length this epoch Std       51.8979
exploration/path length this epoch Max      238
exploration/path length this epoch Min       75
exploration/Rewards Mean                      1.10057
exploration/Rewards Std                       1.40944
exploration/Rewards Max                       5.18025
exploration/Rewards Min                      -2.16675
exploration/Returns Mean                    156.909
exploration/Returns Std                     131.9
exploration/Returns Max                     316.129
exploration/Returns Min                     -43.3334
exploration/Num Paths                         7
exploration/Average Returns                 156.909
evaluation_0/num steps total             125827
evaluation_0/num paths total                607
evaluation_0/path length Mean               346
evaluation_0/path length Std                100.875
evaluation_0/path length Max                585
evaluation_0/path length Min                189
evaluation_0/Rewards Mean                     0.110442
evaluation_0/Rewards Std                      0.962683
evaluation_0/Rewards Max                      5.70089
evaluation_0/Rewards Min                     -2.5422
evaluation_0/Returns Mean                    38.2129
evaluation_0/Returns Std                     84.2148
evaluation_0/Returns Max                    231.356
evaluation_0/Returns Min                    -37.1723
evaluation_0/Num Paths                       22
evaluation_0/Average Returns                 38.2129
time/epoch (s)                                0
time/total (s)                              225.948
Epoch                                        16
---------------------------------------  ---------------
2022-11-16 16:18:42.262756 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 17 finished
---------------------------------------  ---------------
epoch                                        17
total_step                                22000
replay_pool/size                          22000
trainer/alpha                                 0.0487798
trainer/alpha_loss                            1.53641
trainer/entropy                              -6.50865
trainer/qf_loss                               6.8233
trainer/policy_loss                         -85.1867
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          85.5041
trainer/entropy_penalty                      -0.31749
trainer/entropy_percentage                   -0.00371316
trainer/Q1Pred Mean                          82.8999
trainer/Q1Pred Std                           27.724
trainer/Q1Pred Max                          144.948
trainer/Q1Pred Min                          -12.3699
trainer/Q2Pred Mean                          82.8759
trainer/Q2Pred Std                           27.2055
trainer/Q2Pred Max                          141.795
trainer/Q2Pred Min                          -11.297
trainer/QTargetWithReg Mean                  82.52
trainer/QTargetWithReg Std                   27.6175
trainer/QTargetWithReg Max                  147.182
trainer/QTargetWithReg Min                  -10.6325
trainer/PolicyLossWithoutReg Mean            85.5041
trainer/PolicyLossWithoutReg Std             24.5742
trainer/PolicyLossWithoutReg Max            143.632
trainer/PolicyLossWithoutReg Min             -5.10388
exploration/num steps total               22000
exploration/num paths total                 379
exploration/path length this epoch Mean     168.6
exploration/path length this epoch Std       61.7466
exploration/path length this epoch Max      272
exploration/path length this epoch Min       95
exploration/Rewards Mean                      0.969469
exploration/Rewards Std                       1.06727
exploration/Rewards Max                       7.44837
exploration/Rewards Min                      -0.951082
exploration/Returns Mean                    163.453
exploration/Returns Std                      95.7421
exploration/Returns Max                     293.007
exploration/Returns Min                      48.2596
exploration/Num Paths                         5
exploration/Average Returns                 163.453
evaluation_0/num steps total             133776
evaluation_0/num paths total                658
evaluation_0/path length Mean               155.863
evaluation_0/path length Std                 34.5985
evaluation_0/path length Max                284
evaluation_0/path length Min                 83
evaluation_0/Rewards Mean                     1.76995
evaluation_0/Rewards Std                      1.06939
evaluation_0/Rewards Max                      5.99341
evaluation_0/Rewards Min                     -0.581867
evaluation_0/Returns Mean                   275.87
evaluation_0/Returns Std                     67.3456
evaluation_0/Returns Max                    499.455
evaluation_0/Returns Min                    117.048
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                275.87
time/epoch (s)                                0
time/total (s)                              239.449
Epoch                                        17
---------------------------------------  ---------------
2022-11-16 16:18:55.442152 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 18 finished
---------------------------------------  --------------
epoch                                        18
total_step                                23000
replay_pool/size                          23000
trainer/alpha                                 0.0459684
trainer/alpha_loss                           -0.0439262
trainer/entropy                              -5.98574
trainer/qf_loss                               7.91689
trainer/policy_loss                         -86.4396
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          86.7148
trainer/entropy_penalty                      -0.275155
trainer/entropy_percentage                   -0.0031731
trainer/Q1Pred Mean                          83.8808
trainer/Q1Pred Std                           28.5378
trainer/Q1Pred Max                          148.345
trainer/Q1Pred Min                          -19.5734
trainer/Q2Pred Mean                          83.9902
trainer/Q2Pred Std                           28.6537
trainer/Q2Pred Max                          149.251
trainer/Q2Pred Min                          -19.6301
trainer/QTargetWithReg Mean                  83.8716
trainer/QTargetWithReg Std                   29.2235
trainer/QTargetWithReg Max                  149.904
trainer/QTargetWithReg Min                  -22.0306
trainer/PolicyLossWithoutReg Mean            86.7148
trainer/PolicyLossWithoutReg Std             26.4971
trainer/PolicyLossWithoutReg Max            148.716
trainer/PolicyLossWithoutReg Min            -17.2291
exploration/num steps total               23000
exploration/num paths total                 384
exploration/path length this epoch Mean     179.8
exploration/path length this epoch Std       78.124
exploration/path length this epoch Max      303
exploration/path length this epoch Min       75
exploration/Rewards Mean                      1.5868
exploration/Rewards Std                       1.14366
exploration/Rewards Max                       5.70866
exploration/Rewards Min                      -1.05524
exploration/Returns Mean                    285.306
exploration/Returns Std                     134.456
exploration/Returns Max                     433.375
exploration/Returns Min                      36.8872
exploration/Num Paths                         5
exploration/Average Returns                 285.306
evaluation_0/num steps total             141766
evaluation_0/num paths total                742
evaluation_0/path length Mean                95.119
evaluation_0/path length Std                 19.6974
evaluation_0/path length Max                176
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     1.89692
evaluation_0/Rewards Std                      1.35912
evaluation_0/Rewards Max                      6.51954
evaluation_0/Rewards Min                     -0.837368
evaluation_0/Returns Mean                   180.433
evaluation_0/Returns Std                     48.9175
evaluation_0/Returns Max                    387.945
evaluation_0/Returns Min                    135.787
evaluation_0/Num Paths                       84
evaluation_0/Average Returns                180.433
time/epoch (s)                                0
time/total (s)                              252.629
Epoch                                        18
---------------------------------------  --------------
2022-11-16 16:19:08.047361 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 19 finished
---------------------------------------  ---------------
epoch                                        19
total_step                                24000
replay_pool/size                          24000
trainer/alpha                                 0.0456734
trainer/alpha_loss                            0.204004
trainer/entropy                              -6.0661
trainer/qf_loss                               6.80175
trainer/policy_loss                         -89.6559
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          89.9329
trainer/entropy_penalty                      -0.277059
trainer/entropy_percentage                   -0.00308073
trainer/Q1Pred Mean                          88.0238
trainer/Q1Pred Std                           26.3405
trainer/Q1Pred Max                          146.927
trainer/Q1Pred Min                           -2.37369
trainer/Q2Pred Mean                          87.9532
trainer/Q2Pred Std                           26.4342
trainer/Q2Pred Max                          142.441
trainer/Q2Pred Min                           -6.56458
trainer/QTargetWithReg Mean                  87.878
trainer/QTargetWithReg Std                   26.5493
trainer/QTargetWithReg Max                  144.849
trainer/QTargetWithReg Min                   -7.76083
trainer/PolicyLossWithoutReg Mean            89.9329
trainer/PolicyLossWithoutReg Std             25.6007
trainer/PolicyLossWithoutReg Max            143.971
trainer/PolicyLossWithoutReg Min             -5.43229
exploration/num steps total               24000
exploration/num paths total                 396
exploration/path length this epoch Mean      75.1667
exploration/path length this epoch Std       36.3406
exploration/path length this epoch Max      146
exploration/path length this epoch Min       23
exploration/Rewards Mean                      1.58853
exploration/Rewards Std                       1.3233
exploration/Rewards Max                       5.99398
exploration/Rewards Min                      -1.08125
exploration/Returns Mean                    119.404
exploration/Returns Std                      90.056
exploration/Returns Max                     263.101
exploration/Returns Min                       3.97037
exploration/Num Paths                        12
exploration/Average Returns                 119.404
evaluation_0/num steps total             149691
evaluation_0/num paths total                827
evaluation_0/path length Mean                93.2353
evaluation_0/path length Std                  5.69137
evaluation_0/path length Max                112
evaluation_0/path length Min                 85
evaluation_0/Rewards Mean                     1.97258
evaluation_0/Rewards Std                      1.46143
evaluation_0/Rewards Max                      6.99261
evaluation_0/Rewards Min                     -0.59073
evaluation_0/Returns Mean                   183.914
evaluation_0/Returns Std                     25.6659
evaluation_0/Returns Max                    278.142
evaluation_0/Returns Min                    148.555
evaluation_0/Num Paths                       85
evaluation_0/Average Returns                183.914
time/epoch (s)                                0
time/total (s)                              265.233
Epoch                                        19
---------------------------------------  ---------------
2022-11-16 16:19:21.847741 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 20 finished
---------------------------------------  ---------------
epoch                                        20
total_step                                25000
replay_pool/size                          25000
trainer/alpha                                 0.0456524
trainer/alpha_loss                            0.471516
trainer/entropy                              -6.15277
trainer/qf_loss                              11.1056
trainer/policy_loss                         -87.5954
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          87.8762
trainer/entropy_penalty                      -0.280889
trainer/entropy_percentage                   -0.00319641
trainer/Q1Pred Mean                          85.7427
trainer/Q1Pred Std                           30.4139
trainer/Q1Pred Max                          134.859
trainer/Q1Pred Min                          -11.8887
trainer/Q2Pred Mean                          86.0619
trainer/Q2Pred Std                           30.4415
trainer/Q2Pred Max                          140.455
trainer/Q2Pred Min                          -14.5027
trainer/QTargetWithReg Mean                  86.1844
trainer/QTargetWithReg Std                   30.8393
trainer/QTargetWithReg Max                  136.517
trainer/QTargetWithReg Min                  -10.9991
trainer/PolicyLossWithoutReg Mean            87.8762
trainer/PolicyLossWithoutReg Std             28.6154
trainer/PolicyLossWithoutReg Max            136.421
trainer/PolicyLossWithoutReg Min            -10.7733
exploration/num steps total               25000
exploration/num paths total                 406
exploration/path length this epoch Mean      98.4
exploration/path length this epoch Std       27.1079
exploration/path length this epoch Max      155
exploration/path length this epoch Min       59
exploration/Rewards Mean                      1.89872
exploration/Rewards Std                       1.45942
exploration/Rewards Max                       6.91766
exploration/Rewards Min                      -0.853985
exploration/Returns Mean                    186.835
exploration/Returns Std                      68.1672
exploration/Returns Max                     315.589
exploration/Returns Min                      64.6296
exploration/Num Paths                        10
exploration/Average Returns                 186.835
evaluation_0/num steps total             157488
evaluation_0/num paths total                900
evaluation_0/path length Mean               106.808
evaluation_0/path length Std                 21.6192
evaluation_0/path length Max                229
evaluation_0/path length Min                 84
evaluation_0/Rewards Mean                     2.30082
evaluation_0/Rewards Std                      1.43868
evaluation_0/Rewards Max                      6.66078
evaluation_0/Rewards Min                     -0.958728
evaluation_0/Returns Mean                   245.747
evaluation_0/Returns Std                     41.8314
evaluation_0/Returns Max                    479.687
evaluation_0/Returns Min                    190.141
evaluation_0/Num Paths                       73
evaluation_0/Average Returns                245.747
time/epoch (s)                                0
time/total (s)                              279.036
Epoch                                        20
---------------------------------------  ---------------
2022-11-16 16:19:36.552449 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 21 finished
---------------------------------------  ---------------
epoch                                        21
total_step                                26000
replay_pool/size                          26000
trainer/alpha                                 0.0474731
trainer/alpha_loss                            1.17866
trainer/entropy                              -6.38673
trainer/qf_loss                              11.7069
trainer/policy_loss                         -91.7119
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          92.0151
trainer/entropy_penalty                      -0.303198
trainer/entropy_percentage                   -0.00329509
trainer/Q1Pred Mean                          88.9091
trainer/Q1Pred Std                           33.6482
trainer/Q1Pred Max                          154.439
trainer/Q1Pred Min                          -15.4253
trainer/Q2Pred Mean                          89.4207
trainer/Q2Pred Std                           33.4615
trainer/Q2Pred Max                          158.925
trainer/Q2Pred Min                           -7.14905
trainer/QTargetWithReg Mean                  89.285
trainer/QTargetWithReg Std                   33.6354
trainer/QTargetWithReg Max                  158.31
trainer/QTargetWithReg Min                   -2.56295
trainer/PolicyLossWithoutReg Mean            92.0151
trainer/PolicyLossWithoutReg Std             31.5232
trainer/PolicyLossWithoutReg Max            155.313
trainer/PolicyLossWithoutReg Min            -14.9311
exploration/num steps total               26000
exploration/num paths total                 418
exploration/path length this epoch Mean      79.75
exploration/path length this epoch Std       51.3438
exploration/path length this epoch Max      169
exploration/path length this epoch Min       19
exploration/Rewards Mean                      1.7962
exploration/Rewards Std                       1.44882
exploration/Rewards Max                       6.13792
exploration/Rewards Min                      -0.925
exploration/Returns Mean                    143.247
exploration/Returns Std                     125.04
exploration/Returns Max                     356.189
exploration/Returns Min                       0.776545
exploration/Num Paths                        12
exploration/Average Returns                 143.247
evaluation_0/num steps total             165410
evaluation_0/num paths total               1059
evaluation_0/path length Mean                49.8239
evaluation_0/path length Std                 41.0215
evaluation_0/path length Max                188
evaluation_0/path length Min                 29
evaluation_0/Rewards Mean                     1.55109
evaluation_0/Rewards Std                      1.30409
evaluation_0/Rewards Max                      6.7725
evaluation_0/Rewards Min                     -1.59748
evaluation_0/Returns Mean                    77.2816
evaluation_0/Returns Std                    109.942
evaluation_0/Returns Max                    452.24
evaluation_0/Returns Min                     20.7559
evaluation_0/Num Paths                      159
evaluation_0/Average Returns                 77.2816
time/epoch (s)                                0
time/total (s)                              293.739
Epoch                                        21
---------------------------------------  ---------------
2022-11-16 16:19:49.057166 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 22 finished
---------------------------------------  ---------------
epoch                                        22
total_step                                27000
replay_pool/size                          27000
trainer/alpha                                 0.0488272
trainer/alpha_loss                            3.08302
trainer/entropy                              -7.02101
trainer/qf_loss                              10.0242
trainer/policy_loss                         -94.1878
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          94.5306
trainer/entropy_penalty                      -0.342816
trainer/entropy_percentage                   -0.00362651
trainer/Q1Pred Mean                          90.909
trainer/Q1Pred Std                           29.9872
trainer/Q1Pred Max                          149.592
trainer/Q1Pred Min                          -11.8068
trainer/Q2Pred Mean                          91.3341
trainer/Q2Pred Std                           29.8833
trainer/Q2Pred Max                          151.077
trainer/Q2Pred Min                           -7.89588
trainer/QTargetWithReg Mean                  91.0414
trainer/QTargetWithReg Std                   30.0071
trainer/QTargetWithReg Max                  153.195
trainer/QTargetWithReg Min                   -3.14073
trainer/PolicyLossWithoutReg Mean            94.5306
trainer/PolicyLossWithoutReg Std             26.3619
trainer/PolicyLossWithoutReg Max            150.567
trainer/PolicyLossWithoutReg Min             -6.44232
exploration/num steps total               27000
exploration/num paths total                 430
exploration/path length this epoch Mean      78.3333
exploration/path length this epoch Std       24.7734
exploration/path length this epoch Max      111
exploration/path length this epoch Min       26
exploration/Rewards Mean                      1.85665
exploration/Rewards Std                       1.52005
exploration/Rewards Max                       6.21615
exploration/Rewards Min                      -3.08712
exploration/Returns Mean                    145.438
exploration/Returns Std                      66.5472
exploration/Returns Max                     213.266
exploration/Returns Min                       6.40059
exploration/Num Paths                        12
exploration/Average Returns                 145.438
evaluation_0/num steps total             173348
evaluation_0/num paths total               1141
evaluation_0/path length Mean                96.8049
evaluation_0/path length Std                  6.47404
evaluation_0/path length Max                110
evaluation_0/path length Min                 81
evaluation_0/Rewards Mean                     2.0814
evaluation_0/Rewards Std                      1.31573
evaluation_0/Rewards Max                      5.54427
evaluation_0/Rewards Min                     -0.468713
evaluation_0/Returns Mean                   201.49
evaluation_0/Returns Std                     15.8466
evaluation_0/Returns Max                    240.507
evaluation_0/Returns Min                    168.003
evaluation_0/Num Paths                       82
evaluation_0/Average Returns                201.49
time/epoch (s)                                0
time/total (s)                              306.242
Epoch                                        22
---------------------------------------  ---------------
2022-11-16 16:20:03.175998 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 23 finished
---------------------------------------  --------------
epoch                                        23
total_step                                28000
replay_pool/size                          28000
trainer/alpha                                 0.051712
trainer/alpha_loss                            2.19218
trainer/entropy                              -6.74001
trainer/qf_loss                              16.5659
trainer/policy_loss                         -94.0605
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          94.4091
trainer/entropy_penalty                      -0.34854
trainer/entropy_percentage                   -0.0036918
trainer/Q1Pred Mean                          92.063
trainer/Q1Pred Std                           35.4028
trainer/Q1Pred Max                          151.461
trainer/Q1Pred Min                          -14.3841
trainer/Q2Pred Mean                          92.1183
trainer/Q2Pred Std                           35.3967
trainer/Q2Pred Max                          150.064
trainer/Q2Pred Min                          -12.1247
trainer/QTargetWithReg Mean                  90.9944
trainer/QTargetWithReg Std                   36.189
trainer/QTargetWithReg Max                  149.977
trainer/QTargetWithReg Min                  -11.7436
trainer/PolicyLossWithoutReg Mean            94.4091
trainer/PolicyLossWithoutReg Std             33.4674
trainer/PolicyLossWithoutReg Max            150.307
trainer/PolicyLossWithoutReg Min            -10.6467
exploration/num steps total               28000
exploration/num paths total                 439
exploration/path length this epoch Mean     110.667
exploration/path length this epoch Std       22.3209
exploration/path length this epoch Max      153
exploration/path length this epoch Min       80
exploration/Rewards Mean                      1.59452
exploration/Rewards Std                       1.6558
exploration/Rewards Max                       5.88026
exploration/Rewards Min                      -3.22469
exploration/Returns Mean                    176.46
exploration/Returns Std                      80.5578
exploration/Returns Max                     230.003
exploration/Returns Min                     -44.5706
exploration/Num Paths                         9
exploration/Average Returns                 176.46
evaluation_0/num steps total             181295
evaluation_0/num paths total               1190
evaluation_0/path length Mean               162.184
evaluation_0/path length Std                 42.231
evaluation_0/path length Max                332
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     2.04786
evaluation_0/Rewards Std                      1.40118
evaluation_0/Rewards Max                      8.19874
evaluation_0/Rewards Min                     -2.4179
evaluation_0/Returns Mean                   332.129
evaluation_0/Returns Std                    108.406
evaluation_0/Returns Max                    637.067
evaluation_0/Returns Min                    129.824
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                332.129
time/epoch (s)                                0
time/total (s)                              320.36
Epoch                                        23
---------------------------------------  --------------
2022-11-16 16:20:16.370826 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 24 finished
---------------------------------------  ---------------
epoch                                        24
total_step                                29000
replay_pool/size                          29000
trainer/alpha                                 0.0531298
trainer/alpha_loss                            1.9084
trainer/entropy                              -6.65022
trainer/qf_loss                               9.49542
trainer/policy_loss                         -94.2206
trainer/adversary_policy_loss                 4.10355
trainer/policy_loss_without_entropy          94.5739
trainer/entropy_penalty                      -0.353325
trainer/entropy_percentage                   -0.00373597
trainer/Q1Pred Mean                          92.0255
trainer/Q1Pred Std                           34.369
trainer/Q1Pred Max                          164.809
trainer/Q1Pred Min                           -8.34634
trainer/Q2Pred Mean                          92.2199
trainer/Q2Pred Std                           34.2747
trainer/Q2Pred Max                          162.925
trainer/Q2Pred Min                           -6.18792
trainer/QTargetWithReg Mean                  92.0728
trainer/QTargetWithReg Std                   34.6608
trainer/QTargetWithReg Max                  164.868
trainer/QTargetWithReg Min                   -6.74107
trainer/PolicyLossWithoutReg Mean            94.5739
trainer/PolicyLossWithoutReg Std             32.3305
trainer/PolicyLossWithoutReg Max            164.594
trainer/PolicyLossWithoutReg Min             -8.59828
exploration/num steps total               29000
exploration/num paths total                 446
exploration/path length this epoch Mean     120.714
exploration/path length this epoch Std       44.9689
exploration/path length this epoch Max      185
exploration/path length this epoch Min       30
exploration/Rewards Mean                      1.88019
exploration/Rewards Std                       1.42845
exploration/Rewards Max                       6.02035
exploration/Rewards Min                      -2.13524
exploration/Returns Mean                    226.965
exploration/Returns Std                      97.0452
exploration/Returns Max                     334.634
exploration/Returns Min                      24.1105
exploration/Num Paths                         7
exploration/Average Returns                 226.965
evaluation_0/num steps total             189099
evaluation_0/num paths total               1236
evaluation_0/path length Mean               169.652
evaluation_0/path length Std                 44.7307
evaluation_0/path length Max                304
evaluation_0/path length Min                110
evaluation_0/Rewards Mean                     2.19641
evaluation_0/Rewards Std                      1.41054
evaluation_0/Rewards Max                      6.75233
evaluation_0/Rewards Min                     -2.78503
evaluation_0/Returns Mean                   372.627
evaluation_0/Returns Std                    101.391
evaluation_0/Returns Max                    577.649
evaluation_0/Returns Min                    160.484
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                372.627
time/epoch (s)                                0
time/total (s)                              333.555
Epoch                                        24
---------------------------------------  ---------------
2022-11-16 16:20:29.362489 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 25 finished
---------------------------------------  ---------------
epoch                                        25
total_step                                30000
replay_pool/size                          30000
trainer/alpha                                 0.0516432
trainer/alpha_loss                           -0.269332
trainer/entropy                              -5.90911
trainer/qf_loss                              10.1066
trainer/policy_loss                         -98.4809
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          98.7861
trainer/entropy_penalty                      -0.305165
trainer/entropy_percentage                   -0.00308915
trainer/Q1Pred Mean                          96.7453
trainer/Q1Pred Std                           30.4968
trainer/Q1Pred Max                          166.72
trainer/Q1Pred Min                           -5.96746
trainer/Q2Pred Mean                          96.7417
trainer/Q2Pred Std                           30.0529
trainer/Q2Pred Max                          163.778
trainer/Q2Pred Min                           -1.96988
trainer/QTargetWithReg Mean                  97.1911
trainer/QTargetWithReg Std                   30.2272
trainer/QTargetWithReg Max                  164.096
trainer/QTargetWithReg Min                   -0.68657
trainer/PolicyLossWithoutReg Mean            98.7861
trainer/PolicyLossWithoutReg Std             28.8058
trainer/PolicyLossWithoutReg Max            165.099
trainer/PolicyLossWithoutReg Min              4.85125
exploration/num steps total               30000
exploration/num paths total                 451
exploration/path length this epoch Mean     176.6
exploration/path length this epoch Std       61.834
exploration/path length this epoch Max      290
exploration/path length this epoch Min      107
exploration/Rewards Mean                      1.34142
exploration/Rewards Std                       1.53942
exploration/Rewards Max                       6.05744
exploration/Rewards Min                      -3.1142
exploration/Returns Mean                    236.894
exploration/Returns Std                     120.806
exploration/Returns Max                     380.737
exploration/Returns Min                      50.2696
exploration/Num Paths                         5
exploration/Average Returns                 236.894
evaluation_0/num steps total             196850
evaluation_0/num paths total               1274
evaluation_0/path length Mean               203.974
evaluation_0/path length Std                 44.8216
evaluation_0/path length Max                321
evaluation_0/path length Min                 92
evaluation_0/Rewards Mean                     1.94454
evaluation_0/Rewards Std                      1.27951
evaluation_0/Rewards Max                      6.74227
evaluation_0/Rewards Min                     -3.97204
evaluation_0/Returns Mean                   396.634
evaluation_0/Returns Std                    118.784
evaluation_0/Returns Max                    542.917
evaluation_0/Returns Min                     64.8419
evaluation_0/Num Paths                       38
evaluation_0/Average Returns                396.634
time/epoch (s)                                0
time/total (s)                              346.546
Epoch                                        25
---------------------------------------  ---------------
2022-11-16 16:20:42.770295 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 26 finished
---------------------------------------  ---------------
epoch                                        26
total_step                                31000
replay_pool/size                          31000
trainer/alpha                                 0.0512121
trainer/alpha_loss                            0.718465
trainer/entropy                              -6.24177
trainer/qf_loss                              14.673
trainer/policy_loss                         -99.3739
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          99.6936
trainer/entropy_penalty                      -0.319654
trainer/entropy_percentage                   -0.00320636
trainer/Q1Pred Mean                          97.3291
trainer/Q1Pred Std                           34.6397
trainer/Q1Pred Max                          169.51
trainer/Q1Pred Min                           -8.09271
trainer/Q2Pred Mean                          97.4918
trainer/Q2Pred Std                           34.6293
trainer/Q2Pred Max                          168.675
trainer/Q2Pred Min                           -9.7533
trainer/QTargetWithReg Mean                  98.1759
trainer/QTargetWithReg Std                   34.955
trainer/QTargetWithReg Max                  169.526
trainer/QTargetWithReg Min                   -5.7524
trainer/PolicyLossWithoutReg Mean            99.6936
trainer/PolicyLossWithoutReg Std             32.8838
trainer/PolicyLossWithoutReg Max            172.007
trainer/PolicyLossWithoutReg Min             -7.58248
exploration/num steps total               31000
exploration/num paths total                 457
exploration/path length this epoch Mean     165
exploration/path length this epoch Std       74.263
exploration/path length this epoch Max      279
exploration/path length this epoch Min       27
exploration/Rewards Mean                      1.77382
exploration/Rewards Std                       1.30404
exploration/Rewards Max                       6.65303
exploration/Rewards Min                      -0.937256
exploration/Returns Mean                    292.68
exploration/Returns Std                     137.774
exploration/Returns Max                     409.351
exploration/Returns Min                      14.2656
exploration/Num Paths                         6
exploration/Average Returns                 292.68
evaluation_0/num steps total             204824
evaluation_0/num paths total               1344
evaluation_0/path length Mean               113.914
evaluation_0/path length Std                 15.9021
evaluation_0/path length Max                180
evaluation_0/path length Min                 81
evaluation_0/Rewards Mean                     2.32903
evaluation_0/Rewards Std                      1.19771
evaluation_0/Rewards Max                      6.19235
evaluation_0/Rewards Min                     -0.241517
evaluation_0/Returns Mean                   265.309
evaluation_0/Returns Std                     46.1053
evaluation_0/Returns Max                    398.326
evaluation_0/Returns Min                    168.285
evaluation_0/Num Paths                       70
evaluation_0/Average Returns                265.309
time/epoch (s)                                0
time/total (s)                              359.954
Epoch                                        26
---------------------------------------  ---------------
2022-11-16 16:20:55.759120 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 27 finished
---------------------------------------  ---------------
epoch                                        27
total_step                                32000
replay_pool/size                          32000
trainer/alpha                                 0.0510379
trainer/alpha_loss                           -1.20818
trainer/entropy                              -5.59389
trainer/qf_loss                              11.2849
trainer/policy_loss                        -100.284
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         100.57
trainer/entropy_penalty                      -0.2855
trainer/entropy_percentage                   -0.00283883
trainer/Q1Pred Mean                          97.4827
trainer/Q1Pred Std                           33.2214
trainer/Q1Pred Max                          171.616
trainer/Q1Pred Min                           -5.77407
trainer/Q2Pred Mean                          97.4606
trainer/Q2Pred Std                           33.3251
trainer/Q2Pred Max                          168.985
trainer/Q2Pred Min                           -6.17537
trainer/QTargetWithReg Mean                  97.5016
trainer/QTargetWithReg Std                   33.4873
trainer/QTargetWithReg Max                  170.27
trainer/QTargetWithReg Min                   -4.43056
trainer/PolicyLossWithoutReg Mean           100.57
trainer/PolicyLossWithoutReg Std             31.2267
trainer/PolicyLossWithoutReg Max            169.77
trainer/PolicyLossWithoutReg Min             -3.51005
exploration/num steps total               32000
exploration/num paths total                 465
exploration/path length this epoch Mean     120.625
exploration/path length this epoch Std       35.5455
exploration/path length this epoch Max      160
exploration/path length this epoch Min       34
exploration/Rewards Mean                      2.00141
exploration/Rewards Std                       1.41864
exploration/Rewards Max                       5.52222
exploration/Rewards Min                      -2.38593
exploration/Returns Mean                    241.42
exploration/Returns Std                     121.943
exploration/Returns Max                     342.7
exploration/Returns Min                      -3.60936
exploration/Num Paths                         8
exploration/Average Returns                 241.42
evaluation_0/num steps total             212776
evaluation_0/num paths total               1390
evaluation_0/path length Mean               172.87
evaluation_0/path length Std                 44.9316
evaluation_0/path length Max                390
evaluation_0/path length Min                104
evaluation_0/Rewards Mean                     2.06294
evaluation_0/Rewards Std                      1.16796
evaluation_0/Rewards Max                      5.52042
evaluation_0/Rewards Min                     -0.548849
evaluation_0/Returns Mean                   356.619
evaluation_0/Returns Std                     70.1781
evaluation_0/Returns Max                    629.648
evaluation_0/Returns Min                    215.585
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                356.619
time/epoch (s)                                0
time/total (s)                              372.943
Epoch                                        27
---------------------------------------  ---------------
2022-11-16 16:21:09.520511 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 28 finished
---------------------------------------  ---------------
epoch                                        28
total_step                                33000
replay_pool/size                          33000
trainer/alpha                                 0.0495458
trainer/alpha_loss                            1.46743
trainer/entropy                              -6.48833
trainer/qf_loss                              13.0895
trainer/policy_loss                         -96.6069
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy          96.9283
trainer/entropy_penalty                      -0.32147
trainer/entropy_percentage                   -0.00331657
trainer/Q1Pred Mean                          93.4418
trainer/Q1Pred Std                           36.8708
trainer/Q1Pred Max                          159.462
trainer/Q1Pred Min                          -15.9661
trainer/Q2Pred Mean                          93.5905
trainer/Q2Pred Std                           36.4706
trainer/Q2Pred Max                          159.144
trainer/Q2Pred Min                          -15.7331
trainer/QTargetWithReg Mean                  94.1489
trainer/QTargetWithReg Std                   36.2871
trainer/QTargetWithReg Max                  159.017
trainer/QTargetWithReg Min                  -17.7528
trainer/PolicyLossWithoutReg Mean            96.9283
trainer/PolicyLossWithoutReg Std             33.8507
trainer/PolicyLossWithoutReg Max            160.053
trainer/PolicyLossWithoutReg Min            -17.1573
exploration/num steps total               33000
exploration/num paths total                 471
exploration/path length this epoch Mean     160.333
exploration/path length this epoch Std       59.3455
exploration/path length this epoch Max      244
exploration/path length this epoch Min       83
exploration/Rewards Mean                      1.86122
exploration/Rewards Std                       1.27892
exploration/Rewards Max                       5.19905
exploration/Rewards Min                      -1.21338
exploration/Returns Mean                    298.416
exploration/Returns Std                     112.564
exploration/Returns Max                     408.5
exploration/Returns Min                      77.5089
exploration/Num Paths                         6
exploration/Average Returns                 298.416
evaluation_0/num steps total             220736
evaluation_0/num paths total               1441
evaluation_0/path length Mean               156.078
evaluation_0/path length Std                 34.4957
evaluation_0/path length Max                308
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     2.29673
evaluation_0/Rewards Std                      1.28941
evaluation_0/Rewards Max                      6.74694
evaluation_0/Rewards Min                     -0.307806
evaluation_0/Returns Mean                   358.47
evaluation_0/Returns Std                     51.4224
evaluation_0/Returns Max                    516.588
evaluation_0/Returns Min                    276.853
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                358.47
time/epoch (s)                                0
time/total (s)                              386.704
Epoch                                        28
---------------------------------------  ---------------
2022-11-16 16:21:22.389696 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 29 finished
---------------------------------------  ---------------
epoch                                        29
total_step                                34000
replay_pool/size                          34000
trainer/alpha                                 0.0481723
trainer/alpha_loss                           -2.16769
trainer/entropy                              -5.28525
trainer/qf_loss                              10.3328
trainer/policy_loss                        -102.309
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         102.563
trainer/entropy_penalty                      -0.254603
trainer/entropy_percentage                   -0.00248239
trainer/Q1Pred Mean                         100.036
trainer/Q1Pred Std                           28.8263
trainer/Q1Pred Max                          163.817
trainer/Q1Pred Min                           -6.19303
trainer/Q2Pred Mean                         100.214
trainer/Q2Pred Std                           28.9625
trainer/Q2Pred Max                          162.559
trainer/Q2Pred Min                           -5.20941
trainer/QTargetWithReg Mean                 100.478
trainer/QTargetWithReg Std                   28.4728
trainer/QTargetWithReg Max                  162.635
trainer/QTargetWithReg Min                   -6.11858
trainer/PolicyLossWithoutReg Mean           102.563
trainer/PolicyLossWithoutReg Std             26.9508
trainer/PolicyLossWithoutReg Max            164.913
trainer/PolicyLossWithoutReg Min             -0.266671
exploration/num steps total               34000
exploration/num paths total                 477
exploration/path length this epoch Mean     151.5
exploration/path length this epoch Std       20.6458
exploration/path length this epoch Max      179
exploration/path length this epoch Min      130
exploration/Rewards Mean                      2.18603
exploration/Rewards Std                       1.28835
exploration/Rewards Max                       5.93241
exploration/Rewards Min                      -0.71178
exploration/Returns Mean                    331.183
exploration/Returns Std                      56.4562
exploration/Returns Max                     397.471
exploration/Returns Min                     251.581
exploration/Num Paths                         6
exploration/Average Returns                 331.183
evaluation_0/num steps total             228705
evaluation_0/num paths total               1486
evaluation_0/path length Mean               177.089
evaluation_0/path length Std                 31.0009
evaluation_0/path length Max                225
evaluation_0/path length Min                 75
evaluation_0/Rewards Mean                     2.40005
evaluation_0/Rewards Std                      1.20414
evaluation_0/Rewards Max                      6.08049
evaluation_0/Rewards Min                     -0.211645
evaluation_0/Returns Mean                   425.022
evaluation_0/Returns Std                     73.7684
evaluation_0/Returns Max                    537.968
evaluation_0/Returns Min                     82.1068
evaluation_0/Num Paths                       45
evaluation_0/Average Returns                425.022
time/epoch (s)                                0
time/total (s)                              399.572
Epoch                                        29
---------------------------------------  ---------------
2022-11-16 16:21:34.795643 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 30 finished
---------------------------------------  ---------------
epoch                                        30
total_step                                35000
replay_pool/size                          35000
trainer/alpha                                 0.0494273
trainer/alpha_loss                           -0.237424
trainer/entropy                              -5.92105
trainer/qf_loss                               8.87829
trainer/policy_loss                        -107.749
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         108.042
trainer/entropy_penalty                      -0.292662
trainer/entropy_percentage                   -0.00270878
trainer/Q1Pred Mean                         106.636
trainer/Q1Pred Std                           31.7249
trainer/Q1Pred Max                          178.353
trainer/Q1Pred Min                          -10.0436
trainer/Q2Pred Mean                         107.241
trainer/Q2Pred Std                           31.8714
trainer/Q2Pred Max                          180.256
trainer/Q2Pred Min                          -10.9579
trainer/QTargetWithReg Mean                 107.242
trainer/QTargetWithReg Std                   31.8036
trainer/QTargetWithReg Max                  178.908
trainer/QTargetWithReg Min                   -8.97013
trainer/PolicyLossWithoutReg Mean           108.042
trainer/PolicyLossWithoutReg Std             30.9833
trainer/PolicyLossWithoutReg Max            178.951
trainer/PolicyLossWithoutReg Min             -7.29783
exploration/num steps total               35000
exploration/num paths total                 484
exploration/path length this epoch Mean     139.286
exploration/path length this epoch Std       51.5467
exploration/path length this epoch Max      218
exploration/path length this epoch Min       55
exploration/Rewards Mean                      1.98381
exploration/Rewards Std                       1.23619
exploration/Rewards Max                       5.60041
exploration/Rewards Min                      -0.266277
exploration/Returns Mean                    276.316
exploration/Returns Std                     147.676
exploration/Returns Max                     457.162
exploration/Returns Min                      39.3718
exploration/Num Paths                         7
exploration/Average Returns                 276.316
evaluation_0/num steps total             236667
evaluation_0/num paths total               1533
evaluation_0/path length Mean               169.404
evaluation_0/path length Std                  3.37487
evaluation_0/path length Max                175
evaluation_0/path length Min                162
evaluation_0/Rewards Mean                     2.34974
evaluation_0/Rewards Std                      1.4447
evaluation_0/Rewards Max                      6.07596
evaluation_0/Rewards Min                     -0.115496
evaluation_0/Returns Mean                   398.055
evaluation_0/Returns Std                      8.91021
evaluation_0/Returns Max                    423.908
evaluation_0/Returns Min                    386.235
evaluation_0/Num Paths                       47
evaluation_0/Average Returns                398.055
time/epoch (s)                                0
time/total (s)                              411.978
Epoch                                        30
---------------------------------------  ---------------
2022-11-16 16:21:48.201068 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 31 finished
---------------------------------------  ---------------
epoch                                        31
total_step                                36000
replay_pool/size                          36000
trainer/alpha                                 0.0505123
trainer/alpha_loss                            0.581216
trainer/entropy                              -6.19467
trainer/qf_loss                              12.7417
trainer/policy_loss                        -103.666
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         103.979
trainer/entropy_penalty                      -0.312907
trainer/entropy_percentage                   -0.00300933
trainer/Q1Pred Mean                         101.549
trainer/Q1Pred Std                           40.6189
trainer/Q1Pred Max                          190.098
trainer/Q1Pred Min                          -23.7913
trainer/Q2Pred Mean                         101.409
trainer/Q2Pred Std                           40.3716
trainer/Q2Pred Max                          189.55
trainer/Q2Pred Min                          -22.9769
trainer/QTargetWithReg Mean                 101.36
trainer/QTargetWithReg Std                   41.0927
trainer/QTargetWithReg Max                  189.964
trainer/QTargetWithReg Min                  -25.3041
trainer/PolicyLossWithoutReg Mean           103.979
trainer/PolicyLossWithoutReg Std             37.8703
trainer/PolicyLossWithoutReg Max            192.639
trainer/PolicyLossWithoutReg Min            -24.2027
exploration/num steps total               36000
exploration/num paths total                 491
exploration/path length this epoch Mean     127.714
exploration/path length this epoch Std       52.2185
exploration/path length this epoch Max      177
exploration/path length this epoch Min       22
exploration/Rewards Mean                      2.41349
exploration/Rewards Std                       1.39165
exploration/Rewards Max                       5.65537
exploration/Rewards Min                      -0.505462
exploration/Returns Mean                    308.238
exploration/Returns Std                     150.057
exploration/Returns Max                     459.86
exploration/Returns Min                       3.24515
exploration/Num Paths                         7
exploration/Average Returns                 308.238
evaluation_0/num steps total             244544
evaluation_0/num paths total               1588
evaluation_0/path length Mean               143.218
evaluation_0/path length Std                  8.64595
evaluation_0/path length Max                165
evaluation_0/path length Min                121
evaluation_0/Rewards Mean                     2.38442
evaluation_0/Rewards Std                      1.38898
evaluation_0/Rewards Max                      5.99602
evaluation_0/Rewards Min                     -0.140652
evaluation_0/Returns Mean                   341.492
evaluation_0/Returns Std                     28.9995
evaluation_0/Returns Max                    414.022
evaluation_0/Returns Min                    264.884
evaluation_0/Num Paths                       55
evaluation_0/Average Returns                341.492
time/epoch (s)                                0
time/total (s)                              425.383
Epoch                                        31
---------------------------------------  ---------------
2022-11-16 16:22:00.701210 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 32 finished
---------------------------------------  ---------------
epoch                                        32
total_step                                37000
replay_pool/size                          37000
trainer/alpha                                 0.0523969
trainer/alpha_loss                           -0.149723
trainer/entropy                              -5.94923
trainer/qf_loss                               8.86688
trainer/policy_loss                        -106.127
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         106.439
trainer/entropy_penalty                      -0.311721
trainer/entropy_percentage                   -0.00292864
trainer/Q1Pred Mean                         104.49
trainer/Q1Pred Std                           37.3699
trainer/Q1Pred Max                          178.116
trainer/Q1Pred Min                          -15.6594
trainer/Q2Pred Mean                         104.272
trainer/Q2Pred Std                           37.5782
trainer/Q2Pred Max                          178.8
trainer/Q2Pred Min                          -15.4624
trainer/QTargetWithReg Mean                 103.981
trainer/QTargetWithReg Std                   37.7218
trainer/QTargetWithReg Max                  176.694
trainer/QTargetWithReg Min                  -13.043
trainer/PolicyLossWithoutReg Mean           106.439
trainer/PolicyLossWithoutReg Std             36.4488
trainer/PolicyLossWithoutReg Max            178.014
trainer/PolicyLossWithoutReg Min            -11.8034
exploration/num steps total               37000
exploration/num paths total                 498
exploration/path length this epoch Mean     136.429
exploration/path length this epoch Std        8.26105
exploration/path length this epoch Max      148
exploration/path length this epoch Min      124
exploration/Rewards Mean                      2.24962
exploration/Rewards Std                       1.34865
exploration/Rewards Max                       6.48298
exploration/Rewards Min                      -0.523351
exploration/Returns Mean                    306.912
exploration/Returns Std                      58.5599
exploration/Returns Max                     385.031
exploration/Returns Min                     200.647
exploration/Num Paths                         7
exploration/Average Returns                 306.912
evaluation_0/num steps total             252513
evaluation_0/num paths total               1646
evaluation_0/path length Mean               137.397
evaluation_0/path length Std                  6.71319
evaluation_0/path length Max                160
evaluation_0/path length Min                119
evaluation_0/Rewards Mean                     2.5319
evaluation_0/Rewards Std                      1.31286
evaluation_0/Rewards Max                      8.20155
evaluation_0/Rewards Min                     -0.194733
evaluation_0/Returns Mean                   347.874
evaluation_0/Returns Std                     30.714
evaluation_0/Returns Max                    434.573
evaluation_0/Returns Min                    281.457
evaluation_0/Num Paths                       58
evaluation_0/Average Returns                347.874
time/epoch (s)                                0
time/total (s)                              437.883
Epoch                                        32
---------------------------------------  ---------------
2022-11-16 16:22:16.781027 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 33 finished
---------------------------------------  --------------
epoch                                        33
total_step                                38000
replay_pool/size                          38000
trainer/alpha                                 0.0521028
trainer/alpha_loss                            0.0207776
trainer/entropy                              -6.00703
trainer/qf_loss                              13.0257
trainer/policy_loss                        -104.821
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         105.134
trainer/entropy_penalty                      -0.312983
trainer/entropy_percentage                   -0.002977
trainer/Q1Pred Mean                         102.725
trainer/Q1Pred Std                           40.698
trainer/Q1Pred Max                          185.432
trainer/Q1Pred Min                          -15.9722
trainer/Q2Pred Mean                         103.141
trainer/Q2Pred Std                           40.5445
trainer/Q2Pred Max                          185.827
trainer/Q2Pred Min                          -16.2493
trainer/QTargetWithReg Mean                 103.237
trainer/QTargetWithReg Std                   41.2518
trainer/QTargetWithReg Max                  189.194
trainer/QTargetWithReg Min                  -19.5777
trainer/PolicyLossWithoutReg Mean           105.134
trainer/PolicyLossWithoutReg Std             40.0761
trainer/PolicyLossWithoutReg Max            185.909
trainer/PolicyLossWithoutReg Min            -11.0682
exploration/num steps total               38000
exploration/num paths total                 504
exploration/path length this epoch Mean     165.167
exploration/path length this epoch Std       30.5909
exploration/path length this epoch Max      212
exploration/path length this epoch Min      127
exploration/Rewards Mean                      2.12181
exploration/Rewards Std                       1.1385
exploration/Rewards Max                       6.14538
exploration/Rewards Min                      -0.43408
exploration/Returns Mean                    350.453
exploration/Returns Std                      71.4386
exploration/Returns Max                     454.942
exploration/Returns Min                     250.684
exploration/Num Paths                         6
exploration/Average Returns                 350.453
evaluation_0/num steps total             260473
evaluation_0/num paths total               1689
evaluation_0/path length Mean               185.116
evaluation_0/path length Std                135.959
evaluation_0/path length Max               1000
evaluation_0/path length Min                107
evaluation_0/Rewards Mean                     1.29393
evaluation_0/Rewards Std                      1.10185
evaluation_0/Rewards Max                      7.12075
evaluation_0/Rewards Min                     -3.45967
evaluation_0/Returns Mean                   239.528
evaluation_0/Returns Std                    180.266
evaluation_0/Returns Max                   1020.75
evaluation_0/Returns Min                     82.7323
evaluation_0/Num Paths                       43
evaluation_0/Average Returns                239.528
time/epoch (s)                                0
time/total (s)                              453.962
Epoch                                        33
---------------------------------------  --------------
2022-11-16 16:22:29.773782 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 34 finished
---------------------------------------  --------------
epoch                                        34
total_step                                39000
replay_pool/size                          39000
trainer/alpha                                 0.0526801
trainer/alpha_loss                            2.49425
trainer/entropy                              -6.84734
trainer/qf_loss                              10.039
trainer/policy_loss                        -106.2
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         106.561
trainer/entropy_penalty                      -0.360718
trainer/entropy_percentage                   -0.0033851
trainer/Q1Pred Mean                         104.411
trainer/Q1Pred Std                           41.024
trainer/Q1Pred Max                          179.771
trainer/Q1Pred Min                          -17.3323
trainer/Q2Pred Mean                         104.871
trainer/Q2Pred Std                           41.1979
trainer/Q2Pred Max                          180.284
trainer/Q2Pred Min                          -17.4773
trainer/QTargetWithReg Mean                 104.72
trainer/QTargetWithReg Std                   41.2622
trainer/QTargetWithReg Max                  179.013
trainer/QTargetWithReg Min                  -18.5402
trainer/PolicyLossWithoutReg Mean           106.561
trainer/PolicyLossWithoutReg Std             39.4027
trainer/PolicyLossWithoutReg Max            180.723
trainer/PolicyLossWithoutReg Min            -17.2265
exploration/num steps total               39000
exploration/num paths total                 510
exploration/path length this epoch Mean     153.667
exploration/path length this epoch Std       24.9043
exploration/path length this epoch Max      198
exploration/path length this epoch Min      125
exploration/Rewards Mean                      1.89866
exploration/Rewards Std                       1.34163
exploration/Rewards Max                       6.44172
exploration/Rewards Min                      -2.165
exploration/Returns Mean                    291.76
exploration/Returns Std                      70.0377
exploration/Returns Max                     387.12
exploration/Returns Min                     209.613
exploration/Num Paths                         6
exploration/Average Returns                 291.76
evaluation_0/num steps total             268431
evaluation_0/num paths total               1743
evaluation_0/path length Mean               147.37
evaluation_0/path length Std                 32.1819
evaluation_0/path length Max                218
evaluation_0/path length Min                 73
evaluation_0/Rewards Mean                     1.81107
evaluation_0/Rewards Std                      1.26572
evaluation_0/Rewards Max                      7.03384
evaluation_0/Rewards Min                     -1.68554
evaluation_0/Returns Mean                   266.898
evaluation_0/Returns Std                     71.0293
evaluation_0/Returns Max                    431.235
evaluation_0/Returns Min                    126.841
evaluation_0/Num Paths                       54
evaluation_0/Average Returns                266.898
time/epoch (s)                                0
time/total (s)                              466.955
Epoch                                        34
---------------------------------------  --------------
2022-11-16 16:22:42.224745 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 35 finished
---------------------------------------  ---------------
epoch                                        35
total_step                                40000
replay_pool/size                          40000
trainer/alpha                                 0.0553696
trainer/alpha_loss                            1.35672
trainer/entropy                              -6.46883
trainer/qf_loss                              11.4969
trainer/policy_loss                        -104.775
trainer/adversary_policy_loss                 4.62473
trainer/policy_loss_without_entropy         105.133
trainer/entropy_penalty                      -0.358176
trainer/entropy_percentage                   -0.00340689
trainer/Q1Pred Mean                         102.876
trainer/Q1Pred Std                           38.1304
trainer/Q1Pred Max                          184.485
trainer/Q1Pred Min                           -6.70763
trainer/Q2Pred Mean                         102.495
trainer/Q2Pred Std                           37.8619
trainer/Q2Pred Max                          184.584
trainer/Q2Pred Min                           -4.89117
trainer/QTargetWithReg Mean                 102.582
trainer/QTargetWithReg Std                   38.1205
trainer/QTargetWithReg Max                  182.517
trainer/QTargetWithReg Min                   -5.34464
trainer/PolicyLossWithoutReg Mean           105.133
trainer/PolicyLossWithoutReg Std             35.692
trainer/PolicyLossWithoutReg Max            183.151
trainer/PolicyLossWithoutReg Min             -7.3056
exploration/num steps total               40000
exploration/num paths total                 518
exploration/path length this epoch Mean     119.875
exploration/path length this epoch Std       29.7928
exploration/path length this epoch Max      185
exploration/path length this epoch Min       92
exploration/Rewards Mean                      2.31912
exploration/Rewards Std                       1.31489
exploration/Rewards Max                       6.49602
exploration/Rewards Min                      -0.496419
exploration/Returns Mean                    278.005
exploration/Returns Std                      88.2613
exploration/Returns Max                     463.522
exploration/Returns Min                     159.23
exploration/Num Paths                         8
exploration/Average Returns                 278.005
evaluation_0/num steps total             276349
evaluation_0/num paths total               1806
evaluation_0/path length Mean               125.683
evaluation_0/path length Std                  9.83002
evaluation_0/path length Max                149
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.4678
evaluation_0/Rewards Std                      1.31989
evaluation_0/Rewards Max                      7.23518
evaluation_0/Rewards Min                     -0.18576
evaluation_0/Returns Mean                   310.16
evaluation_0/Returns Std                     28.8347
evaluation_0/Returns Max                    383.8
evaluation_0/Returns Min                    261.663
evaluation_0/Num Paths                       63
evaluation_0/Average Returns                310.16
time/epoch (s)                                0
time/total (s)                              479.406
Epoch                                        35
---------------------------------------  ---------------
2022-11-16 16:22:55.581620 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 36 finished
---------------------------------------  ---------------
epoch                                        36
total_step                                41000
replay_pool/size                          41000
trainer/alpha                                 0.0576594
trainer/alpha_loss                           -1.36428
trainer/entropy                              -5.52183
trainer/qf_loss                               8.09072
trainer/policy_loss                        -111.922
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         112.241
trainer/entropy_penalty                      -0.318385
trainer/entropy_percentage                   -0.00283662
trainer/Q1Pred Mean                         109.292
trainer/Q1Pred Std                           39.3841
trainer/Q1Pred Max                          180.952
trainer/Q1Pred Min                          -10.8705
trainer/Q2Pred Mean                         109.127
trainer/Q2Pred Std                           39.6022
trainer/Q2Pred Max                          179.102
trainer/Q2Pred Min                          -10.4273
trainer/QTargetWithReg Mean                 108.916
trainer/QTargetWithReg Std                   39.9307
trainer/QTargetWithReg Max                  178.454
trainer/QTargetWithReg Min                  -12.1559
trainer/PolicyLossWithoutReg Mean           112.241
trainer/PolicyLossWithoutReg Std             37.2038
trainer/PolicyLossWithoutReg Max            178.73
trainer/PolicyLossWithoutReg Min             -9.82669
exploration/num steps total               41000
exploration/num paths total                 525
exploration/path length this epoch Mean     136.429
exploration/path length this epoch Std       50.2248
exploration/path length this epoch Max      235
exploration/path length this epoch Min       72
exploration/Rewards Mean                      2.12309
exploration/Rewards Std                       1.32018
exploration/Rewards Max                       5.96883
exploration/Rewards Min                      -1.68434
exploration/Returns Mean                    289.65
exploration/Returns Std                     107.756
exploration/Returns Max                     474.314
exploration/Returns Min                     137.767
exploration/Num Paths                         7
exploration/Average Returns                 289.65
evaluation_0/num steps total             284300
evaluation_0/num paths total               1868
evaluation_0/path length Mean               128.242
evaluation_0/path length Std                 12.0117
evaluation_0/path length Max                166
evaluation_0/path length Min                104
evaluation_0/Rewards Mean                     2.85973
evaluation_0/Rewards Std                      1.57953
evaluation_0/Rewards Max                      8.15643
evaluation_0/Rewards Min                     -0.182659
evaluation_0/Returns Mean                   366.738
evaluation_0/Returns Std                     42.8747
evaluation_0/Returns Max                    502.302
evaluation_0/Returns Min                    259.753
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                366.738
time/epoch (s)                                0
time/total (s)                              492.762
Epoch                                        36
---------------------------------------  ---------------
2022-11-16 16:23:08.255211 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 37 finished
---------------------------------------  ---------------
epoch                                        37
total_step                                42000
replay_pool/size                          42000
trainer/alpha                                 0.0567716
trainer/alpha_loss                           -0.987546
trainer/entropy                              -5.65575
trainer/qf_loss                               9.16193
trainer/policy_loss                        -114.994
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         115.315
trainer/entropy_penalty                      -0.321086
trainer/entropy_percentage                   -0.00278444
trainer/Q1Pred Mean                         113.839
trainer/Q1Pred Std                           35.049
trainer/Q1Pred Max                          177.399
trainer/Q1Pred Min                           -5.89966
trainer/Q2Pred Mean                         114.09
trainer/Q2Pred Std                           35.0073
trainer/Q2Pred Max                          176.339
trainer/Q2Pred Min                           -5.13336
trainer/QTargetWithReg Mean                 114.327
trainer/QTargetWithReg Std                   35.279
trainer/QTargetWithReg Max                  177.287
trainer/QTargetWithReg Min                   -2.99857
trainer/PolicyLossWithoutReg Mean           115.315
trainer/PolicyLossWithoutReg Std             34.1361
trainer/PolicyLossWithoutReg Max            176.759
trainer/PolicyLossWithoutReg Min             -5.32951
exploration/num steps total               42000
exploration/num paths total                 533
exploration/path length this epoch Mean     123.875
exploration/path length this epoch Std       11.8368
exploration/path length this epoch Max      141
exploration/path length this epoch Min      105
exploration/Rewards Mean                      2.58439
exploration/Rewards Std                       1.30778
exploration/Rewards Max                       5.85202
exploration/Rewards Min                      -0.640247
exploration/Returns Mean                    320.142
exploration/Returns Std                      42.5997
exploration/Returns Max                     378.827
exploration/Returns Min                     231.693
exploration/Num Paths                         8
exploration/Average Returns                 320.142
evaluation_0/num steps total             292199
evaluation_0/num paths total               1931
evaluation_0/path length Mean               125.381
evaluation_0/path length Std                 15.2674
evaluation_0/path length Max                160
evaluation_0/path length Min                 97
evaluation_0/Rewards Mean                     2.63788
evaluation_0/Rewards Std                      1.31771
evaluation_0/Rewards Max                      6.71178
evaluation_0/Rewards Min                     -0.23206
evaluation_0/Returns Mean                   330.74
evaluation_0/Returns Std                     46.5827
evaluation_0/Returns Max                    436.925
evaluation_0/Returns Min                    234.16
evaluation_0/Num Paths                       63
evaluation_0/Average Returns                330.74
time/epoch (s)                                0
time/total (s)                              505.436
Epoch                                        37
---------------------------------------  ---------------
2022-11-16 16:23:20.667007 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 38 finished
---------------------------------------  ---------------
epoch                                        38
total_step                                43000
replay_pool/size                          43000
trainer/alpha                                 0.0557655
trainer/alpha_loss                           -0.289188
trainer/entropy                              -5.89981
trainer/qf_loss                               9.69452
trainer/policy_loss                        -113.049
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         113.378
trainer/entropy_penalty                      -0.329006
trainer/entropy_percentage                   -0.00290185
trainer/Q1Pred Mean                         111.106
trainer/Q1Pred Std                           41.2022
trainer/Q1Pred Max                          177.546
trainer/Q1Pred Min                           -3.51572
trainer/Q2Pred Mean                         111.338
trainer/Q2Pred Std                           40.9069
trainer/Q2Pred Max                          177.141
trainer/Q2Pred Min                           -3.02837
trainer/QTargetWithReg Mean                 110.727
trainer/QTargetWithReg Std                   41.0975
trainer/QTargetWithReg Max                  177.61
trainer/QTargetWithReg Min                   -2.43205
trainer/PolicyLossWithoutReg Mean           113.378
trainer/PolicyLossWithoutReg Std             39.8509
trainer/PolicyLossWithoutReg Max            177.413
trainer/PolicyLossWithoutReg Min             -5.21366
exploration/num steps total               43000
exploration/num paths total                 541
exploration/path length this epoch Mean     123.125
exploration/path length this epoch Std       13.1
exploration/path length this epoch Max      144
exploration/path length this epoch Min      101
exploration/Rewards Mean                      2.55134
exploration/Rewards Std                       1.37856
exploration/Rewards Max                       6.5164
exploration/Rewards Min                      -0.863167
exploration/Returns Mean                    314.134
exploration/Returns Std                      53.0331
exploration/Returns Max                     395.055
exploration/Returns Min                     220.658
exploration/Num Paths                         8
exploration/Average Returns                 314.134
evaluation_0/num steps total             300113
evaluation_0/num paths total               1997
evaluation_0/path length Mean               119.909
evaluation_0/path length Std                  4.44061
evaluation_0/path length Max                126
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.72395
evaluation_0/Rewards Std                      1.69244
evaluation_0/Rewards Max                      7.66409
evaluation_0/Rewards Min                     -0.507663
evaluation_0/Returns Mean                   326.627
evaluation_0/Returns Std                     19.1916
evaluation_0/Returns Max                    349.471
evaluation_0/Returns Min                    260.896
evaluation_0/Num Paths                       66
evaluation_0/Average Returns                326.627
time/epoch (s)                                0
time/total (s)                              517.848
Epoch                                        38
---------------------------------------  ---------------
2022-11-16 16:23:33.990752 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 39 finished
---------------------------------------  ---------------
epoch                                        39
total_step                                44000
replay_pool/size                          44000
trainer/alpha                                 0.0550782
trainer/alpha_loss                           -1.24035
trainer/entropy                              -5.57213
trainer/qf_loss                              15.7614
trainer/policy_loss                        -119.928
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         120.235
trainer/entropy_penalty                      -0.306903
trainer/entropy_percentage                   -0.00255254
trainer/Q1Pred Mean                         118.581
trainer/Q1Pred Std                           37.3641
trainer/Q1Pred Max                          182.214
trainer/Q1Pred Min                           -5.14043
trainer/Q2Pred Mean                         118.51
trainer/Q2Pred Std                           37.506
trainer/Q2Pred Max                          184.431
trainer/Q2Pred Min                           -2.72315
trainer/QTargetWithReg Mean                 118.308
trainer/QTargetWithReg Std                   37.7261
trainer/QTargetWithReg Max                  183.206
trainer/QTargetWithReg Min                   -1.083
trainer/PolicyLossWithoutReg Mean           120.235
trainer/PolicyLossWithoutReg Std             35.5223
trainer/PolicyLossWithoutReg Max            182.96
trainer/PolicyLossWithoutReg Min             -3.87482
exploration/num steps total               44000
exploration/num paths total                 548
exploration/path length this epoch Mean     125.857
exploration/path length this epoch Std       19.2757
exploration/path length this epoch Max      160
exploration/path length this epoch Min      101
exploration/Rewards Mean                      2.41044
exploration/Rewards Std                       1.29649
exploration/Rewards Max                       7.11015
exploration/Rewards Min                      -0.623551
exploration/Returns Mean                    303.37
exploration/Returns Std                      30.4457
exploration/Returns Max                     337.679
exploration/Returns Min                     253.065
exploration/Num Paths                         7
exploration/Average Returns                 303.37
evaluation_0/num steps total             308008
evaluation_0/num paths total               2055
evaluation_0/path length Mean               136.121
evaluation_0/path length Std                  5.68749
evaluation_0/path length Max                152
evaluation_0/path length Min                125
evaluation_0/Rewards Mean                     2.32112
evaluation_0/Rewards Std                      1.04894
evaluation_0/Rewards Max                      5.3248
evaluation_0/Rewards Min                     -0.172736
evaluation_0/Returns Mean                   315.952
evaluation_0/Returns Std                     21.9691
evaluation_0/Returns Max                    403.111
evaluation_0/Returns Min                    275.052
evaluation_0/Num Paths                       58
evaluation_0/Average Returns                315.952
time/epoch (s)                                0
time/total (s)                              531.17
Epoch                                        39
---------------------------------------  ---------------
2022-11-16 16:23:46.622251 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 40 finished
---------------------------------------  ---------------
epoch                                        40
total_step                                45000
replay_pool/size                          45000
trainer/alpha                                 0.0543279
trainer/alpha_loss                            1.21666
trainer/entropy                              -6.4177
trainer/qf_loss                               7.39303
trainer/policy_loss                        -119.352
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         119.701
trainer/entropy_penalty                      -0.34866
trainer/entropy_percentage                   -0.00291277
trainer/Q1Pred Mean                         117.323
trainer/Q1Pred Std                           41.3533
trainer/Q1Pred Max                          179.905
trainer/Q1Pred Min                           -4.6737
trainer/Q2Pred Mean                         117.22
trainer/Q2Pred Std                           41.5904
trainer/Q2Pred Max                          180.323
trainer/Q2Pred Min                           -4.90591
trainer/QTargetWithReg Mean                 117.634
trainer/QTargetWithReg Std                   41.7945
trainer/QTargetWithReg Max                  178.514
trainer/QTargetWithReg Min                   -0.62738
trainer/PolicyLossWithoutReg Mean           119.701
trainer/PolicyLossWithoutReg Std             40.1628
trainer/PolicyLossWithoutReg Max            179.55
trainer/PolicyLossWithoutReg Min              0.310994
exploration/num steps total               45000
exploration/num paths total                 555
exploration/path length this epoch Mean     142.571
exploration/path length this epoch Std       11.1977
exploration/path length this epoch Max      157
exploration/path length this epoch Min      127
exploration/Rewards Mean                      2.34833
exploration/Rewards Std                       1.27439
exploration/Rewards Max                       7.0046
exploration/Rewards Min                      -0.649499
exploration/Returns Mean                    334.804
exploration/Returns Std                      42.3913
exploration/Returns Max                     417.829
exploration/Returns Min                     288.594
exploration/Num Paths                         7
exploration/Average Returns                 334.804
evaluation_0/num steps total             316004
evaluation_0/num paths total               2119
evaluation_0/path length Mean               124.938
evaluation_0/path length Std                  4.84728
evaluation_0/path length Max                140
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     2.49256
evaluation_0/Rewards Std                      1.22236
evaluation_0/Rewards Max                      5.45621
evaluation_0/Rewards Min                     -0.379407
evaluation_0/Returns Mean                   311.414
evaluation_0/Returns Std                     21.7931
evaluation_0/Returns Max                    383.047
evaluation_0/Returns Min                    286.326
evaluation_0/Num Paths                       64
evaluation_0/Average Returns                311.414
time/epoch (s)                                0
time/total (s)                              543.802
Epoch                                        40
---------------------------------------  ---------------
2022-11-16 16:23:59.089470 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 41 finished
---------------------------------------  ---------------
epoch                                        41
total_step                                46000
replay_pool/size                          46000
trainer/alpha                                 0.0534539
trainer/alpha_loss                           -0.363335
trainer/entropy                              -5.87595
trainer/qf_loss                               8.46611
trainer/policy_loss                        -116.881
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         117.195
trainer/entropy_penalty                      -0.314092
trainer/entropy_percentage                   -0.00268009
trainer/Q1Pred Mean                         116.039
trainer/Q1Pred Std                           41.4684
trainer/Q1Pred Max                          184.671
trainer/Q1Pred Min                           -3.27188
trainer/Q2Pred Mean                         115.41
trainer/Q2Pred Std                           41.9421
trainer/Q2Pred Max                          184.404
trainer/Q2Pred Min                          -10.1724
trainer/QTargetWithReg Mean                 116.119
trainer/QTargetWithReg Std                   42.0293
trainer/QTargetWithReg Max                  187.306
trainer/QTargetWithReg Min                   -7.15307
trainer/PolicyLossWithoutReg Mean           117.195
trainer/PolicyLossWithoutReg Std             40.0835
trainer/PolicyLossWithoutReg Max            185.712
trainer/PolicyLossWithoutReg Min             -2.46692
exploration/num steps total               46000
exploration/num paths total                 562
exploration/path length this epoch Mean     134.714
exploration/path length this epoch Std       11.1447
exploration/path length this epoch Max      149
exploration/path length this epoch Min      118
exploration/Rewards Mean                      2.37979
exploration/Rewards Std                       1.39855
exploration/Rewards Max                       7.16423
exploration/Rewards Min                      -0.904178
exploration/Returns Mean                    320.592
exploration/Returns Std                      41.8406
exploration/Returns Max                     377.704
exploration/Returns Min                     260.538
exploration/Num Paths                         7
exploration/Average Returns                 320.592
evaluation_0/num steps total             323900
evaluation_0/num paths total               2179
evaluation_0/path length Mean               131.6
evaluation_0/path length Std                  4.51368
evaluation_0/path length Max                150
evaluation_0/path length Min                126
evaluation_0/Rewards Mean                     2.33345
evaluation_0/Rewards Std                      1.17724
evaluation_0/Rewards Max                      6.35598
evaluation_0/Rewards Min                     -0.442801
evaluation_0/Returns Mean                   307.082
evaluation_0/Returns Std                     10.2791
evaluation_0/Returns Max                    341.938
evaluation_0/Returns Min                    291.395
evaluation_0/Num Paths                       60
evaluation_0/Average Returns                307.082
time/epoch (s)                                0
time/total (s)                              556.27
Epoch                                        41
---------------------------------------  ---------------
2022-11-16 16:24:12.828765 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 42 finished
---------------------------------------  ---------------
epoch                                        42
total_step                                47000
replay_pool/size                          47000
trainer/alpha                                 0.0530378
trainer/alpha_loss                            0.787036
trainer/entropy                              -6.26799
trainer/qf_loss                              11.7828
trainer/policy_loss                        -118.102
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         118.434
trainer/entropy_penalty                      -0.332441
trainer/entropy_percentage                   -0.00280697
trainer/Q1Pred Mean                         116.568
trainer/Q1Pred Std                           41.3626
trainer/Q1Pred Max                          179.968
trainer/Q1Pred Min                           -6.57839
trainer/Q2Pred Mean                         116.315
trainer/Q2Pred Std                           41.437
trainer/Q2Pred Max                          181.564
trainer/Q2Pred Min                           -8.84669
trainer/QTargetWithReg Mean                 116.294
trainer/QTargetWithReg Std                   41.8701
trainer/QTargetWithReg Max                  179.37
trainer/QTargetWithReg Min                   -4.68589
trainer/PolicyLossWithoutReg Mean           118.434
trainer/PolicyLossWithoutReg Std             39.9121
trainer/PolicyLossWithoutReg Max            180.782
trainer/PolicyLossWithoutReg Min             -6.05047
exploration/num steps total               47000
exploration/num paths total                 569
exploration/path length this epoch Mean     142
exploration/path length this epoch Std       36.1544
exploration/path length this epoch Max      186
exploration/path length this epoch Min       73
exploration/Rewards Mean                      2.1935
exploration/Rewards Std                       1.20972
exploration/Rewards Max                       6.36416
exploration/Rewards Min                      -0.74678
exploration/Returns Mean                    311.477
exploration/Returns Std                     107.247
exploration/Returns Max                     452.913
exploration/Returns Min                      88.7191
exploration/Num Paths                         7
exploration/Average Returns                 311.477
evaluation_0/num steps total             331785
evaluation_0/num paths total               2229
evaluation_0/path length Mean               157.7
evaluation_0/path length Std                 17.4748
evaluation_0/path length Max                199
evaluation_0/path length Min                135
evaluation_0/Rewards Mean                     2.48668
evaluation_0/Rewards Std                      1.24351
evaluation_0/Rewards Max                      7.58124
evaluation_0/Rewards Min                     -0.51074
evaluation_0/Returns Mean                   392.15
evaluation_0/Returns Std                     47.9911
evaluation_0/Returns Max                    529.605
evaluation_0/Returns Min                    331.137
evaluation_0/Num Paths                       50
evaluation_0/Average Returns                392.15
time/epoch (s)                                0
time/total (s)                              570.008
Epoch                                        42
---------------------------------------  ---------------
2022-11-16 16:24:25.265047 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 43 finished
---------------------------------------  ---------------
epoch                                        43
total_step                                48000
replay_pool/size                          48000
trainer/alpha                                 0.0517514
trainer/alpha_loss                            1.76979
trainer/entropy                              -6.59761
trainer/qf_loss                               6.82795
trainer/policy_loss                        -117.394
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         117.735
trainer/entropy_penalty                      -0.341435
trainer/entropy_percentage                   -0.00290003
trainer/Q1Pred Mean                         115.101
trainer/Q1Pred Std                           45.1619
trainer/Q1Pred Max                          186.42
trainer/Q1Pred Min                          -10.7544
trainer/Q2Pred Mean                         115.382
trainer/Q2Pred Std                           45.3816
trainer/Q2Pred Max                          189.491
trainer/Q2Pred Min                          -11.5073
trainer/QTargetWithReg Mean                 115.492
trainer/QTargetWithReg Std                   45.383
trainer/QTargetWithReg Max                  188.395
trainer/QTargetWithReg Min                  -15.1423
trainer/PolicyLossWithoutReg Mean           117.735
trainer/PolicyLossWithoutReg Std             43.3997
trainer/PolicyLossWithoutReg Max            188.418
trainer/PolicyLossWithoutReg Min             -8.08091
exploration/num steps total               48000
exploration/num paths total                 575
exploration/path length this epoch Mean     159.333
exploration/path length this epoch Std        8.61523
exploration/path length this epoch Max      173
exploration/path length this epoch Min      149
exploration/Rewards Mean                      2.15811
exploration/Rewards Std                       1.16482
exploration/Rewards Max                       6.81036
exploration/Rewards Min                      -0.495013
exploration/Returns Mean                    343.858
exploration/Returns Std                      20.8772
exploration/Returns Max                     382.681
exploration/Returns Min                     323.116
exploration/Num Paths                         6
exploration/Average Returns                 343.858
evaluation_0/num steps total             339632
evaluation_0/num paths total               2282
evaluation_0/path length Mean               148.057
evaluation_0/path length Std                  8.72086
evaluation_0/path length Max                165
evaluation_0/path length Min                130
evaluation_0/Rewards Mean                     2.39575
evaluation_0/Rewards Std                      1.31312
evaluation_0/Rewards Max                      7.65975
evaluation_0/Rewards Min                     -0.528567
evaluation_0/Returns Mean                   354.707
evaluation_0/Returns Std                     26.7228
evaluation_0/Returns Max                    444.253
evaluation_0/Returns Min                    311.686
evaluation_0/Num Paths                       53
evaluation_0/Average Returns                354.707
time/epoch (s)                                0
time/total (s)                              582.444
Epoch                                        43
---------------------------------------  ---------------
2022-11-16 16:24:37.808516 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 44 finished
---------------------------------------  ---------------
epoch                                        44
total_step                                49000
replay_pool/size                          49000
trainer/alpha                                 0.0517779
trainer/alpha_loss                           -1.35673
trainer/entropy                              -5.54172
trainer/qf_loss                              10.0729
trainer/policy_loss                        -122.98
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.267
trainer/entropy_penalty                      -0.286939
trainer/entropy_percentage                   -0.00232778
trainer/Q1Pred Mean                         120.903
trainer/Q1Pred Std                           39.7077
trainer/Q1Pred Max                          185.724
trainer/Q1Pred Min                            1.54362
trainer/Q2Pred Mean                         120.855
trainer/Q2Pred Std                           39.7663
trainer/Q2Pred Max                          185.531
trainer/Q2Pred Min                            3.26225
trainer/QTargetWithReg Mean                 121.625
trainer/QTargetWithReg Std                   39.7803
trainer/QTargetWithReg Max                  187.101
trainer/QTargetWithReg Min                    0.426545
trainer/PolicyLossWithoutReg Mean           123.267
trainer/PolicyLossWithoutReg Std             37.5972
trainer/PolicyLossWithoutReg Max            185.597
trainer/PolicyLossWithoutReg Min             -1.25464
exploration/num steps total               49000
exploration/num paths total                 580
exploration/path length this epoch Mean     181
exploration/path length this epoch Std       25.9461
exploration/path length this epoch Max      212
exploration/path length this epoch Min      149
exploration/Rewards Mean                      2.27733
exploration/Rewards Std                       1.21858
exploration/Rewards Max                       6.91959
exploration/Rewards Min                      -0.888616
exploration/Returns Mean                    412.197
exploration/Returns Std                      59.1645
exploration/Returns Max                     495.608
exploration/Returns Min                     332.15
exploration/Num Paths                         5
exploration/Average Returns                 412.197
evaluation_0/num steps total             347582
evaluation_0/num paths total               2342
evaluation_0/path length Mean               132.5
evaluation_0/path length Std                  8.15578
evaluation_0/path length Max                170
evaluation_0/path length Min                119
evaluation_0/Rewards Mean                     2.4643
evaluation_0/Rewards Std                      1.25058
evaluation_0/Rewards Max                      6.83387
evaluation_0/Rewards Min                     -0.271236
evaluation_0/Returns Mean                   326.519
evaluation_0/Returns Std                     32.3593
evaluation_0/Returns Max                    470.515
evaluation_0/Returns Min                    281.854
evaluation_0/Num Paths                       60
evaluation_0/Average Returns                326.519
time/epoch (s)                                0
time/total (s)                              594.987
Epoch                                        44
---------------------------------------  ---------------
2022-11-16 16:24:50.816939 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 45 finished
---------------------------------------  ---------------
epoch                                        45
total_step                                50000
replay_pool/size                          50000
trainer/alpha                                 0.0512871
trainer/alpha_loss                           -1.49261
trainer/entropy                              -5.49747
trainer/qf_loss                               6.39788
trainer/policy_loss                        -119.728
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         120.01
trainer/entropy_penalty                      -0.281949
trainer/entropy_percentage                   -0.00234939
trainer/Q1Pred Mean                         119.139
trainer/Q1Pred Std                           44.2571
trainer/Q1Pred Max                          182.059
trainer/Q1Pred Min                          -10.7583
trainer/Q2Pred Mean                         118.96
trainer/Q2Pred Std                           44.0646
trainer/Q2Pred Max                          181.712
trainer/Q2Pred Min                           -9.82583
trainer/QTargetWithReg Mean                 119.074
trainer/QTargetWithReg Std                   44.7559
trainer/QTargetWithReg Max                  180.544
trainer/QTargetWithReg Min                   -6.8006
trainer/PolicyLossWithoutReg Mean           120.01
trainer/PolicyLossWithoutReg Std             43.516
trainer/PolicyLossWithoutReg Max            181.295
trainer/PolicyLossWithoutReg Min             -8.00482
exploration/num steps total               50000
exploration/num paths total                 585
exploration/path length this epoch Mean     168.6
exploration/path length this epoch Std       22.5442
exploration/path length this epoch Max      192
exploration/path length this epoch Min      129
exploration/Rewards Mean                      2.36816
exploration/Rewards Std                       1.29852
exploration/Rewards Max                       7.3448
exploration/Rewards Min                      -0.696708
exploration/Returns Mean                    399.272
exploration/Returns Std                      60.8764
exploration/Returns Max                     506.415
exploration/Returns Min                     331.282
exploration/Num Paths                         5
exploration/Average Returns                 399.272
evaluation_0/num steps total             355480
evaluation_0/num paths total               2389
evaluation_0/path length Mean               168.043
evaluation_0/path length Std                 11.0761
evaluation_0/path length Max                187
evaluation_0/path length Min                141
evaluation_0/Rewards Mean                     2.44479
evaluation_0/Rewards Std                      1.18886
evaluation_0/Rewards Max                      7.26206
evaluation_0/Rewards Min                     -0.339881
evaluation_0/Returns Mean                   410.829
evaluation_0/Returns Std                     46.0632
evaluation_0/Returns Max                    489.887
evaluation_0/Returns Min                    308.041
evaluation_0/Num Paths                       47
evaluation_0/Average Returns                410.829
time/epoch (s)                                0
time/total (s)                              607.995
Epoch                                        45
---------------------------------------  ---------------
2022-11-16 16:25:03.306928 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 46 finished
---------------------------------------  --------------
epoch                                        46
total_step                                51000
replay_pool/size                          51000
trainer/alpha                                 0.0496611
trainer/alpha_loss                           -2.25885
trainer/entropy                              -5.24765
trainer/qf_loss                               7.47067
trainer/policy_loss                        -123.848
trainer/adversary_policy_loss                 5.5869
trainer/policy_loss_without_entropy         124.109
trainer/entropy_penalty                      -0.260604
trainer/entropy_percentage                   -0.0020998
trainer/Q1Pred Mean                         122.188
trainer/Q1Pred Std                           42.7961
trainer/Q1Pred Max                          188.441
trainer/Q1Pred Min                           -8.00447
trainer/Q2Pred Mean                         121.714
trainer/Q2Pred Std                           43.0529
trainer/Q2Pred Max                          187.677
trainer/Q2Pred Min                          -12.4806
trainer/QTargetWithReg Mean                 121.892
trainer/QTargetWithReg Std                   43.1234
trainer/QTargetWithReg Max                  188.473
trainer/QTargetWithReg Min                  -10.3039
trainer/PolicyLossWithoutReg Mean           124.109
trainer/PolicyLossWithoutReg Std             41.3633
trainer/PolicyLossWithoutReg Max            186.67
trainer/PolicyLossWithoutReg Min             -4.45828
exploration/num steps total               51000
exploration/num paths total                 592
exploration/path length this epoch Mean     139.857
exploration/path length this epoch Std       53.2606
exploration/path length this epoch Max      181
exploration/path length this epoch Min       17
exploration/Rewards Mean                      2.27087
exploration/Rewards Std                       1.18155
exploration/Rewards Max                       5.89473
exploration/Rewards Min                      -0.475997
exploration/Returns Mean                    317.597
exploration/Returns Std                     136.138
exploration/Returns Max                     448.132
exploration/Returns Min                       1.68777
exploration/Num Paths                         7
exploration/Average Returns                 317.597
evaluation_0/num steps total             363414
evaluation_0/num paths total               2461
evaluation_0/path length Mean               110.194
evaluation_0/path length Std                  5.82533
evaluation_0/path length Max                120
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     2.5531
evaluation_0/Rewards Std                      1.41743
evaluation_0/Rewards Max                      5.81587
evaluation_0/Rewards Min                     -0.404885
evaluation_0/Returns Mean                   281.338
evaluation_0/Returns Std                     23.3336
evaluation_0/Returns Max                    317.644
evaluation_0/Returns Min                    219.894
evaluation_0/Num Paths                       72
evaluation_0/Average Returns                281.338
time/epoch (s)                                0
time/total (s)                              620.485
Epoch                                        46
---------------------------------------  --------------
2022-11-16 16:25:15.769041 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 47 finished
---------------------------------------  ---------------
epoch                                        47
total_step                                52000
replay_pool/size                          52000
trainer/alpha                                 0.0498345
trainer/alpha_loss                            0.399468
trainer/entropy                              -6.1332
trainer/qf_loss                               6.27176
trainer/policy_loss                        -122.699
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.005
trainer/entropy_penalty                      -0.305645
trainer/entropy_percentage                   -0.00248482
trainer/Q1Pred Mean                         120.173
trainer/Q1Pred Std                           44.8922
trainer/Q1Pred Max                          183.707
trainer/Q1Pred Min                          -13.0186
trainer/Q2Pred Mean                         120.584
trainer/Q2Pred Std                           45.2861
trainer/Q2Pred Max                          184.576
trainer/Q2Pred Min                          -14.6226
trainer/QTargetWithReg Mean                 120.323
trainer/QTargetWithReg Std                   44.9147
trainer/QTargetWithReg Max                  187.305
trainer/QTargetWithReg Min                  -10.8889
trainer/PolicyLossWithoutReg Mean           123.005
trainer/PolicyLossWithoutReg Std             43.5551
trainer/PolicyLossWithoutReg Max            188.612
trainer/PolicyLossWithoutReg Min              0.72739
exploration/num steps total               52000
exploration/num paths total                 598
exploration/path length this epoch Mean     159.167
exploration/path length this epoch Std       29.6334
exploration/path length this epoch Max      212
exploration/path length this epoch Min      118
exploration/Rewards Mean                      2.55071
exploration/Rewards Std                       1.27219
exploration/Rewards Max                       6.46092
exploration/Rewards Min                      -0.908636
exploration/Returns Mean                    405.987
exploration/Returns Std                      78.3242
exploration/Returns Max                     561.087
exploration/Returns Min                     322.523
exploration/Num Paths                         6
exploration/Average Returns                 405.987
evaluation_0/num steps total             371320
evaluation_0/num paths total               2526
evaluation_0/path length Mean               121.631
evaluation_0/path length Std                  6.94499
evaluation_0/path length Max                147
evaluation_0/path length Min                107
evaluation_0/Rewards Mean                     2.45547
evaluation_0/Rewards Std                      1.32812
evaluation_0/Rewards Max                      6.9335
evaluation_0/Rewards Min                     -0.180438
evaluation_0/Returns Mean                   298.661
evaluation_0/Returns Std                     26.1359
evaluation_0/Returns Max                    382.746
evaluation_0/Returns Min                    254.895
evaluation_0/Num Paths                       65
evaluation_0/Average Returns                298.661
time/epoch (s)                                0
time/total (s)                              632.947
Epoch                                        47
---------------------------------------  ---------------
2022-11-16 16:25:29.007959 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 48 finished
---------------------------------------  ---------------
epoch                                        48
total_step                                53000
replay_pool/size                          53000
trainer/alpha                                 0.0494691
trainer/alpha_loss                           -0.548786
trainer/entropy                              -5.81747
trainer/qf_loss                               6.29385
trainer/policy_loss                        -123.96
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         124.248
trainer/entropy_penalty                      -0.287785
trainer/entropy_percentage                   -0.00231621
trainer/Q1Pred Mean                         123.159
trainer/Q1Pred Std                           42.1926
trainer/Q1Pred Max                          182.567
trainer/Q1Pred Min                            0.397894
trainer/Q2Pred Mean                         122.898
trainer/Q2Pred Std                           42.1227
trainer/Q2Pred Max                          182.286
trainer/Q2Pred Min                           -1.99197
trainer/QTargetWithReg Mean                 122.772
trainer/QTargetWithReg Std                   42.6047
trainer/QTargetWithReg Max                  183.169
trainer/QTargetWithReg Min                    0.118269
trainer/PolicyLossWithoutReg Mean           124.248
trainer/PolicyLossWithoutReg Std             41.886
trainer/PolicyLossWithoutReg Max            183.267
trainer/PolicyLossWithoutReg Min              1.77254
exploration/num steps total               53000
exploration/num paths total                 605
exploration/path length this epoch Mean     117
exploration/path length this epoch Std       42.5944
exploration/path length this epoch Max      149
exploration/path length this epoch Min       16
exploration/Rewards Mean                      2.41138
exploration/Rewards Std                       1.39754
exploration/Rewards Max                       6.54
exploration/Rewards Min                      -0.460639
exploration/Returns Mean                    282.132
exploration/Returns Std                     117.605
exploration/Returns Max                     361.25
exploration/Returns Min                       1.43267
exploration/Num Paths                         7
exploration/Average Returns                 282.132
evaluation_0/num steps total             379246
evaluation_0/num paths total               2596
evaluation_0/path length Mean               113.229
evaluation_0/path length Std                  5.72257
evaluation_0/path length Max                128
evaluation_0/path length Min                 89
evaluation_0/Rewards Mean                     2.24893
evaluation_0/Rewards Std                      1.29531
evaluation_0/Rewards Max                      6.03823
evaluation_0/Rewards Min                     -0.433347
evaluation_0/Returns Mean                   254.643
evaluation_0/Returns Std                     17.4313
evaluation_0/Returns Max                    307.22
evaluation_0/Returns Min                    200.434
evaluation_0/Num Paths                       70
evaluation_0/Average Returns                254.643
time/epoch (s)                                0
time/total (s)                              646.185
Epoch                                        48
---------------------------------------  ---------------
2022-11-16 16:25:41.833111 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 49 finished
---------------------------------------  ---------------
epoch                                        49
total_step                                54000
replay_pool/size                          54000
trainer/alpha                                 0.0477507
trainer/alpha_loss                           -0.0889752
trainer/entropy                              -5.97075
trainer/qf_loss                               5.88831
trainer/policy_loss                        -123.314
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.599
trainer/entropy_penalty                      -0.285107
trainer/entropy_percentage                   -0.00230672
trainer/Q1Pred Mean                         121.97
trainer/Q1Pred Std                           44.627
trainer/Q1Pred Max                          180.549
trainer/Q1Pred Min                           -7.59885
trainer/Q2Pred Mean                         121.858
trainer/Q2Pred Std                           44.6347
trainer/Q2Pred Max                          180.771
trainer/Q2Pred Min                           -4.70483
trainer/QTargetWithReg Mean                 121.868
trainer/QTargetWithReg Std                   44.8408
trainer/QTargetWithReg Max                  181.705
trainer/QTargetWithReg Min                   -6.34889
trainer/PolicyLossWithoutReg Mean           123.599
trainer/PolicyLossWithoutReg Std             43.3912
trainer/PolicyLossWithoutReg Max            180.113
trainer/PolicyLossWithoutReg Min             -7.17765
exploration/num steps total               54000
exploration/num paths total                 612
exploration/path length this epoch Mean     120.286
exploration/path length this epoch Std       59.7344
exploration/path length this epoch Max      196
exploration/path length this epoch Min       33
exploration/Rewards Mean                      2.4245
exploration/Rewards Std                       1.28556
exploration/Rewards Max                       5.60634
exploration/Rewards Min                      -0.50983
exploration/Returns Mean                    291.633
exploration/Returns Std                     178.484
exploration/Returns Max                     506.614
exploration/Returns Min                      22.5531
exploration/Num Paths                         7
exploration/Average Returns                 291.633
evaluation_0/num steps total             387212
evaluation_0/num paths total               2648
evaluation_0/path length Mean               153.192
evaluation_0/path length Std                 22.1238
evaluation_0/path length Max                216
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     2.5342
evaluation_0/Rewards Std                      1.24325
evaluation_0/Rewards Max                      7.57983
evaluation_0/Rewards Min                     -0.131426
evaluation_0/Returns Mean                   388.22
evaluation_0/Returns Std                     74.0593
evaluation_0/Returns Max                    589.092
evaluation_0/Returns Min                    275.323
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                388.22
time/epoch (s)                                0
time/total (s)                              659.01
Epoch                                        49
---------------------------------------  ---------------
2022-11-16 16:25:54.458712 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 50 finished
---------------------------------------  ---------------
epoch                                        50
total_step                                55000
replay_pool/size                          55000
trainer/alpha                                 0.0461926
trainer/alpha_loss                           -0.0644282
trainer/entropy                              -5.97905
trainer/qf_loss                               6.37494
trainer/policy_loss                        -123.607
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.883
trainer/entropy_penalty                      -0.276188
trainer/entropy_percentage                   -0.00222942
trainer/Q1Pred Mean                         122.266
trainer/Q1Pred Std                           44.3194
trainer/Q1Pred Max                          185.077
trainer/Q1Pred Min                          -14.2451
trainer/Q2Pred Mean                         122.087
trainer/Q2Pred Std                           44.4037
trainer/Q2Pred Max                          185.282
trainer/Q2Pred Min                          -12.0281
trainer/QTargetWithReg Mean                 121.968
trainer/QTargetWithReg Std                   44.2327
trainer/QTargetWithReg Max                  185.124
trainer/QTargetWithReg Min                  -10.1313
trainer/PolicyLossWithoutReg Mean           123.883
trainer/PolicyLossWithoutReg Std             42.9218
trainer/PolicyLossWithoutReg Max            186.329
trainer/PolicyLossWithoutReg Min            -10.7348
exploration/num steps total               55000
exploration/num paths total                 619
exploration/path length this epoch Mean     141.571
exploration/path length this epoch Std       25.4663
exploration/path length this epoch Max      182
exploration/path length this epoch Min       93
exploration/Rewards Mean                      2.56194
exploration/Rewards Std                       1.30687
exploration/Rewards Max                       5.33468
exploration/Rewards Min                      -0.637394
exploration/Returns Mean                    362.697
exploration/Returns Std                      55.7792
exploration/Returns Max                     442.352
exploration/Returns Min                     251.154
exploration/Num Paths                         7
exploration/Average Returns                 362.697
evaluation_0/num steps total             395162
evaluation_0/num paths total               2716
evaluation_0/path length Mean               116.912
evaluation_0/path length Std                  7.12852
evaluation_0/path length Max                136
evaluation_0/path length Min                102
evaluation_0/Rewards Mean                     2.51096
evaluation_0/Rewards Std                      1.4931
evaluation_0/Rewards Max                      6.25699
evaluation_0/Rewards Min                     -0.435793
evaluation_0/Returns Mean                   293.561
evaluation_0/Returns Std                     31.785
evaluation_0/Returns Max                    394.725
evaluation_0/Returns Min                    236.292
evaluation_0/Num Paths                       68
evaluation_0/Average Returns                293.561
time/epoch (s)                                0
time/total (s)                              671.635
Epoch                                        50
---------------------------------------  ---------------
2022-11-16 16:26:07.880432 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 51 finished
---------------------------------------  ---------------
epoch                                        51
total_step                                56000
replay_pool/size                          56000
trainer/alpha                                 0.0462769
trainer/alpha_loss                           -0.801425
trainer/entropy                              -5.7392
trainer/qf_loss                               5.6556
trainer/policy_loss                        -127.91
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         128.175
trainer/entropy_penalty                      -0.265593
trainer/entropy_percentage                   -0.00207211
trainer/Q1Pred Mean                         125.728
trainer/Q1Pred Std                           39.1985
trainer/Q1Pred Max                          183.195
trainer/Q1Pred Min                           -0.74464
trainer/Q2Pred Mean                         125.983
trainer/Q2Pred Std                           39.0169
trainer/Q2Pred Max                          183.46
trainer/Q2Pred Min                            1.62919
trainer/QTargetWithReg Mean                 126.153
trainer/QTargetWithReg Std                   39.1401
trainer/QTargetWithReg Max                  184.291
trainer/QTargetWithReg Min                   -0.28123
trainer/PolicyLossWithoutReg Mean           128.175
trainer/PolicyLossWithoutReg Std             37.2202
trainer/PolicyLossWithoutReg Max            185.545
trainer/PolicyLossWithoutReg Min              3.08987
exploration/num steps total               56000
exploration/num paths total                 626
exploration/path length this epoch Mean     142.143
exploration/path length this epoch Std       32.0733
exploration/path length this epoch Max      189
exploration/path length this epoch Min       87
exploration/Rewards Mean                      2.62218
exploration/Rewards Std                       1.32823
exploration/Rewards Max                       5.6867
exploration/Rewards Min                      -0.580291
exploration/Returns Mean                    372.724
exploration/Returns Std                      85.9053
exploration/Returns Max                     496.658
exploration/Returns Min                     209.526
exploration/Num Paths                         7
exploration/Average Returns                 372.724
evaluation_0/num steps total             403066
evaluation_0/num paths total               2790
evaluation_0/path length Mean               106.811
evaluation_0/path length Std                  8.03989
evaluation_0/path length Max                135
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     2.63603
evaluation_0/Rewards Std                      1.55995
evaluation_0/Rewards Max                      7.34702
evaluation_0/Rewards Min                     -0.368621
evaluation_0/Returns Mean                   281.557
evaluation_0/Returns Std                     30.2442
evaluation_0/Returns Max                    395.634
evaluation_0/Returns Min                    252.261
evaluation_0/Num Paths                       74
evaluation_0/Average Returns                281.557
time/epoch (s)                                0
time/total (s)                              685.057
Epoch                                        51
---------------------------------------  ---------------
2022-11-16 16:26:20.277232 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 52 finished
---------------------------------------  ---------------
epoch                                        52
total_step                                57000
replay_pool/size                          57000
trainer/alpha                                 0.0460941
trainer/alpha_loss                           -0.0394289
trainer/entropy                              -5.98719
trainer/qf_loss                               8.08326
trainer/policy_loss                        -124.64
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         124.916
trainer/entropy_penalty                      -0.275974
trainer/entropy_percentage                   -0.00220927
trainer/Q1Pred Mean                         123.041
trainer/Q1Pred Std                           43.4115
trainer/Q1Pred Max                          181.931
trainer/Q1Pred Min                           -0.469255
trainer/Q2Pred Mean                         123.185
trainer/Q2Pred Std                           43.3982
trainer/Q2Pred Max                          182.47
trainer/Q2Pred Min                            1.33471
trainer/QTargetWithReg Mean                 123.027
trainer/QTargetWithReg Std                   43.7313
trainer/QTargetWithReg Max                  182.691
trainer/QTargetWithReg Min                   -0.638679
trainer/PolicyLossWithoutReg Mean           124.916
trainer/PolicyLossWithoutReg Std             41.7451
trainer/PolicyLossWithoutReg Max            182.95
trainer/PolicyLossWithoutReg Min              0.593143
exploration/num steps total               57000
exploration/num paths total                 634
exploration/path length this epoch Mean     112.625
exploration/path length this epoch Std       38.8296
exploration/path length this epoch Max      168
exploration/path length this epoch Min       42
exploration/Rewards Mean                      2.52591
exploration/Rewards Std                       1.45753
exploration/Rewards Max                       6.746
exploration/Rewards Min                      -0.555562
exploration/Returns Mean                    284.48
exploration/Returns Std                     118.688
exploration/Returns Max                     447.599
exploration/Returns Min                      33.8507
exploration/Num Paths                         8
exploration/Average Returns                 284.48
evaluation_0/num steps total             411010
evaluation_0/num paths total               2845
evaluation_0/path length Mean               144.436
evaluation_0/path length Std                 12.0872
evaluation_0/path length Max                164
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     2.91574
evaluation_0/Rewards Std                      1.47797
evaluation_0/Rewards Max                      7.96478
evaluation_0/Rewards Min                     -0.29767
evaluation_0/Returns Mean                   421.139
evaluation_0/Returns Std                     45.872
evaluation_0/Returns Max                    518.144
evaluation_0/Returns Min                    341.049
evaluation_0/Num Paths                       55
evaluation_0/Average Returns                421.139
time/epoch (s)                                0
time/total (s)                              697.455
Epoch                                        52
---------------------------------------  ---------------
2022-11-16 16:26:33.223114 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 53 finished
---------------------------------------  ---------------
epoch                                        53
total_step                                58000
replay_pool/size                          58000
trainer/alpha                                 0.0436712
trainer/alpha_loss                            1.79176
trainer/entropy                              -6.57226
trainer/qf_loss                               6.69943
trainer/policy_loss                        -123.232
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.519
trainer/entropy_penalty                      -0.287019
trainer/entropy_percentage                   -0.00232369
trainer/Q1Pred Mean                         121.826
trainer/Q1Pred Std                           41.7737
trainer/Q1Pred Max                          183.694
trainer/Q1Pred Min                            3.96748
trainer/Q2Pred Mean                         121.45
trainer/Q2Pred Std                           41.9286
trainer/Q2Pred Max                          183.612
trainer/Q2Pred Min                            4.71826
trainer/QTargetWithReg Mean                 121.909
trainer/QTargetWithReg Std                   42.2768
trainer/QTargetWithReg Max                  181.19
trainer/QTargetWithReg Min                   -0.419735
trainer/PolicyLossWithoutReg Mean           123.519
trainer/PolicyLossWithoutReg Std             40.5332
trainer/PolicyLossWithoutReg Max            182.565
trainer/PolicyLossWithoutReg Min              4.49902
exploration/num steps total               58000
exploration/num paths total                 645
exploration/path length this epoch Mean      82.2727
exploration/path length this epoch Std       56.2593
exploration/path length this epoch Max      176
exploration/path length this epoch Min       22
exploration/Rewards Mean                      2.274
exploration/Rewards Std                       1.51064
exploration/Rewards Max                       6.65558
exploration/Rewards Min                      -0.608627
exploration/Returns Mean                    187.088
exploration/Returns Std                     182.497
exploration/Returns Max                     521.566
exploration/Returns Min                       8.87529
exploration/Num Paths                        11
exploration/Average Returns                 187.088
evaluation_0/num steps total             418969
evaluation_0/num paths total               2920
evaluation_0/path length Mean               106.12
evaluation_0/path length Std                  2.43289
evaluation_0/path length Max                112
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     2.83791
evaluation_0/Rewards Std                      1.83141
evaluation_0/Rewards Max                      6.94847
evaluation_0/Rewards Min                     -0.200552
evaluation_0/Returns Mean                   301.159
evaluation_0/Returns Std                     11.1411
evaluation_0/Returns Max                    324.397
evaluation_0/Returns Min                    272.24
evaluation_0/Num Paths                       75
evaluation_0/Average Returns                301.159
time/epoch (s)                                0
time/total (s)                              710.399
Epoch                                        53
---------------------------------------  ---------------
2022-11-16 16:26:45.858378 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 54 finished
---------------------------------------  ---------------
epoch                                        54
total_step                                59000
replay_pool/size                          59000
trainer/alpha                                 0.0431079
trainer/alpha_loss                            2.95113
trainer/entropy                              -6.9386
trainer/qf_loss                               5.17033
trainer/policy_loss                        -124.59
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         124.889
trainer/entropy_penalty                      -0.299108
trainer/entropy_percentage                   -0.00239499
trainer/Q1Pred Mean                         123.113
trainer/Q1Pred Std                           44.5738
trainer/Q1Pred Max                          184.853
trainer/Q1Pred Min                           -6.07763
trainer/Q2Pred Mean                         123.103
trainer/Q2Pred Std                           44.5629
trainer/Q2Pred Max                          184.83
trainer/Q2Pred Min                           -7.94289
trainer/QTargetWithReg Mean                 123.036
trainer/QTargetWithReg Std                   44.6464
trainer/QTargetWithReg Max                  184.485
trainer/QTargetWithReg Min                   -6.33921
trainer/PolicyLossWithoutReg Mean           124.889
trainer/PolicyLossWithoutReg Std             43.3893
trainer/PolicyLossWithoutReg Max            184.778
trainer/PolicyLossWithoutReg Min             -2.74646
exploration/num steps total               59000
exploration/num paths total                 654
exploration/path length this epoch Mean     106.222
exploration/path length this epoch Std       43.8375
exploration/path length this epoch Max      150
exploration/path length this epoch Min       31
exploration/Rewards Mean                      2.42724
exploration/Rewards Std                       1.30395
exploration/Rewards Max                       5.52096
exploration/Rewards Min                      -0.704615
exploration/Returns Mean                    257.826
exploration/Returns Std                     135.628
exploration/Returns Max                     378.349
exploration/Returns Min                      17.0627
exploration/Num Paths                         9
exploration/Average Returns                 257.826
evaluation_0/num steps total             426908
evaluation_0/num paths total               2982
evaluation_0/path length Mean               128.048
evaluation_0/path length Std                  6.34601
evaluation_0/path length Max                142
evaluation_0/path length Min                117
evaluation_0/Rewards Mean                     2.41671
evaluation_0/Rewards Std                      1.05994
evaluation_0/Rewards Max                      4.85277
evaluation_0/Rewards Min                     -0.62276
evaluation_0/Returns Mean                   309.456
evaluation_0/Returns Std                     21.6085
evaluation_0/Returns Max                    354.842
evaluation_0/Returns Min                    263.411
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                309.456
time/epoch (s)                                0
time/total (s)                              723.034
Epoch                                        54
---------------------------------------  ---------------
2022-11-16 16:26:58.328273 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 55 finished
---------------------------------------  ---------------
epoch                                        55
total_step                                60000
replay_pool/size                          60000
trainer/alpha                                 0.0428658
trainer/alpha_loss                            1.07105
trainer/entropy                              -6.34005
trainer/qf_loss                               6.55041
trainer/policy_loss                        -119.118
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         119.39
trainer/entropy_penalty                      -0.271771
trainer/entropy_percentage                   -0.00227633
trainer/Q1Pred Mean                         117.429
trainer/Q1Pred Std                           45.9491
trainer/Q1Pred Max                          177.443
trainer/Q1Pred Min                          -11.2124
trainer/Q2Pred Mean                         116.97
trainer/Q2Pred Std                           45.9884
trainer/Q2Pred Max                          177.148
trainer/Q2Pred Min                           -8.89231
trainer/QTargetWithReg Mean                 117.514
trainer/QTargetWithReg Std                   46.2441
trainer/QTargetWithReg Max                  178.732
trainer/QTargetWithReg Min                   -7.36929
trainer/PolicyLossWithoutReg Mean           119.39
trainer/PolicyLossWithoutReg Std             44.8962
trainer/PolicyLossWithoutReg Max            178.439
trainer/PolicyLossWithoutReg Min             -6.75007
exploration/num steps total               60000
exploration/num paths total                 661
exploration/path length this epoch Mean     127.143
exploration/path length this epoch Std       26.9414
exploration/path length this epoch Max      172
exploration/path length this epoch Min       92
exploration/Rewards Mean                      2.5392
exploration/Rewards Std                       1.33941
exploration/Rewards Max                       6.92478
exploration/Rewards Min                      -0.587482
exploration/Returns Mean                    322.841
exploration/Returns Std                      87.6181
exploration/Returns Max                     486.544
exploration/Returns Min                     221.977
exploration/Num Paths                         7
exploration/Average Returns                 322.841
evaluation_0/num steps total             434816
evaluation_0/num paths total               3034
evaluation_0/path length Mean               152.077
evaluation_0/path length Std                  9.85246
evaluation_0/path length Max                167
evaluation_0/path length Min                126
evaluation_0/Rewards Mean                     2.35329
evaluation_0/Rewards Std                      1.45805
evaluation_0/Rewards Max                      6.78315
evaluation_0/Rewards Min                     -0.273206
evaluation_0/Returns Mean                   357.881
evaluation_0/Returns Std                     35.5467
evaluation_0/Returns Max                    416.057
evaluation_0/Returns Min                    274.066
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                357.881
time/epoch (s)                                0
time/total (s)                              735.504
Epoch                                        55
---------------------------------------  ---------------
2022-11-16 16:27:10.704478 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 56 finished
---------------------------------------  ---------------
epoch                                        56
total_step                                61000
replay_pool/size                          61000
trainer/alpha                                 0.0405612
trainer/alpha_loss                           -1.65576
trainer/entropy                              -5.48332
trainer/qf_loss                               5.90282
trainer/policy_loss                        -122.155
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         122.377
trainer/entropy_penalty                      -0.22241
trainer/entropy_percentage                   -0.00181741
trainer/Q1Pred Mean                         119.995
trainer/Q1Pred Std                           45.8232
trainer/Q1Pred Max                          181.508
trainer/Q1Pred Min                          -11.5371
trainer/Q2Pred Mean                         119.544
trainer/Q2Pred Std                           45.7888
trainer/Q2Pred Max                          180.715
trainer/Q2Pred Min                          -15.8146
trainer/QTargetWithReg Mean                 119.632
trainer/QTargetWithReg Std                   45.8257
trainer/QTargetWithReg Max                  180.566
trainer/QTargetWithReg Min                   -9.80924
trainer/PolicyLossWithoutReg Mean           122.377
trainer/PolicyLossWithoutReg Std             43.3634
trainer/PolicyLossWithoutReg Max            180.597
trainer/PolicyLossWithoutReg Min             -8.3924
exploration/num steps total               61000
exploration/num paths total                 668
exploration/path length this epoch Mean     137.571
exploration/path length this epoch Std       51.3472
exploration/path length this epoch Max      187
exploration/path length this epoch Min       27
exploration/Rewards Mean                      2.48685
exploration/Rewards Std                       1.44064
exploration/Rewards Max                       6.9176
exploration/Rewards Min                      -0.661476
exploration/Returns Mean                    342.119
exploration/Returns Std                     149.121
exploration/Returns Max                     495.464
exploration/Returns Min                      14.9261
exploration/Num Paths                         7
exploration/Average Returns                 342.119
evaluation_0/num steps total             442716
evaluation_0/num paths total               3091
evaluation_0/path length Mean               138.596
evaluation_0/path length Std                  2.19936
evaluation_0/path length Max                145
evaluation_0/path length Min                133
evaluation_0/Rewards Mean                     2.60699
evaluation_0/Rewards Std                      1.18485
evaluation_0/Rewards Max                      5.04523
evaluation_0/Rewards Min                     -0.3536
evaluation_0/Returns Mean                   361.32
evaluation_0/Returns Std                      5.23848
evaluation_0/Returns Max                    380.23
evaluation_0/Returns Min                    349.491
evaluation_0/Num Paths                       57
evaluation_0/Average Returns                361.32
time/epoch (s)                                0
time/total (s)                              747.88
Epoch                                        56
---------------------------------------  ---------------
2022-11-16 16:27:24.189206 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 57 finished
---------------------------------------  ---------------
epoch                                        57
total_step                                62000
replay_pool/size                          62000
trainer/alpha                                 0.0399794
trainer/alpha_loss                           -1.69658
trainer/entropy                              -5.473
trainer/qf_loss                               6.02254
trainer/policy_loss                        -122.92
trainer/adversary_policy_loss                 5.68081
trainer/policy_loss_without_entropy         123.139
trainer/entropy_penalty                      -0.218807
trainer/entropy_percentage                   -0.00177692
trainer/Q1Pred Mean                         121.485
trainer/Q1Pred Std                           44.4517
trainer/Q1Pred Max                          183.558
trainer/Q1Pred Min                           -3.88848
trainer/Q2Pred Mean                         121.663
trainer/Q2Pred Std                           44.3261
trainer/Q2Pred Max                          179.86
trainer/Q2Pred Min                           -6.54195
trainer/QTargetWithReg Mean                 121.882
trainer/QTargetWithReg Std                   44.4484
trainer/QTargetWithReg Max                  180.906
trainer/QTargetWithReg Min                   -2.83327
trainer/PolicyLossWithoutReg Mean           123.139
trainer/PolicyLossWithoutReg Std             43.8442
trainer/PolicyLossWithoutReg Max            181.07
trainer/PolicyLossWithoutReg Min             -1.50242
exploration/num steps total               62000
exploration/num paths total                 674
exploration/path length this epoch Mean     163.167
exploration/path length this epoch Std       18.1054
exploration/path length this epoch Max      198
exploration/path length this epoch Min      144
exploration/Rewards Mean                      2.41037
exploration/Rewards Std                       1.34307
exploration/Rewards Max                       8.25453
exploration/Rewards Min                      -0.568141
exploration/Returns Mean                    393.293
exploration/Returns Std                      37.981
exploration/Returns Max                     447.47
exploration/Returns Min                     333.024
exploration/Num Paths                         6
exploration/Average Returns                 393.293
evaluation_0/num steps total             450579
evaluation_0/num paths total               3136
evaluation_0/path length Mean               174.733
evaluation_0/path length Std                 15.6864
evaluation_0/path length Max                210
evaluation_0/path length Min                149
evaluation_0/Rewards Mean                     2.6568
evaluation_0/Rewards Std                      1.4741
evaluation_0/Rewards Max                      7.64302
evaluation_0/Rewards Min                     -0.349976
evaluation_0/Returns Mean                   464.232
evaluation_0/Returns Std                     51.5371
evaluation_0/Returns Max                    545.366
evaluation_0/Returns Min                    376.568
evaluation_0/Num Paths                       45
evaluation_0/Average Returns                464.232
time/epoch (s)                                0
time/total (s)                              761.364
Epoch                                        57
---------------------------------------  ---------------
2022-11-16 16:27:36.590083 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 58 finished
---------------------------------------  ---------------
epoch                                        58
total_step                                63000
replay_pool/size                          63000
trainer/alpha                                 0.0397964
trainer/alpha_loss                            0.812551
trainer/entropy                              -6.25204
trainer/qf_loss                               6.24313
trainer/policy_loss                        -125.831
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         126.08
trainer/entropy_penalty                      -0.248808
trainer/entropy_percentage                   -0.00197342
trainer/Q1Pred Mean                         124.408
trainer/Q1Pred Std                           39.4207
trainer/Q1Pred Max                          178.4
trainer/Q1Pred Min                           -8.19446
trainer/Q2Pred Mean                         124.771
trainer/Q2Pred Std                           39.8486
trainer/Q2Pred Max                          180.119
trainer/Q2Pred Min                          -11.6045
trainer/QTargetWithReg Mean                 124.907
trainer/QTargetWithReg Std                   39.8477
trainer/QTargetWithReg Max                  179.166
trainer/QTargetWithReg Min                    0.239723
trainer/PolicyLossWithoutReg Mean           126.08
trainer/PolicyLossWithoutReg Std             37.9401
trainer/PolicyLossWithoutReg Max            178.76
trainer/PolicyLossWithoutReg Min              3.49002
exploration/num steps total               63000
exploration/num paths total                 680
exploration/path length this epoch Mean     150.333
exploration/path length this epoch Std       16.3673
exploration/path length this epoch Max      167
exploration/path length this epoch Min      127
exploration/Rewards Mean                      2.46506
exploration/Rewards Std                       1.20179
exploration/Rewards Max                       5.66824
exploration/Rewards Min                      -0.51747
exploration/Returns Mean                    370.58
exploration/Returns Std                      52.5012
exploration/Returns Max                     428.761
exploration/Returns Min                     297.778
exploration/Num Paths                         6
exploration/Average Returns                 370.58
evaluation_0/num steps total             458506
evaluation_0/num paths total               3182
evaluation_0/path length Mean               172.326
evaluation_0/path length Std                 10.5667
evaluation_0/path length Max                208
evaluation_0/path length Min                157
evaluation_0/Rewards Mean                     2.3363
evaluation_0/Rewards Std                      1.15187
evaluation_0/Rewards Max                      7.56043
evaluation_0/Rewards Min                     -0.445474
evaluation_0/Returns Mean                   402.606
evaluation_0/Returns Std                     40.1644
evaluation_0/Returns Max                    545.981
evaluation_0/Returns Min                    360.568
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                402.606
time/epoch (s)                                0
time/total (s)                              773.764
Epoch                                        58
---------------------------------------  ---------------
2022-11-16 16:27:49.633043 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 59 finished
---------------------------------------  ---------------
epoch                                        59
total_step                                64000
replay_pool/size                          64000
trainer/alpha                                 0.0401733
trainer/alpha_loss                           -1.72663
trainer/entropy                              -5.46285
trainer/qf_loss                               5.42994
trainer/policy_loss                        -126.037
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         126.257
trainer/entropy_penalty                      -0.219461
trainer/entropy_percentage                   -0.00173821
trainer/Q1Pred Mean                         124.606
trainer/Q1Pred Std                           40.9182
trainer/Q1Pred Max                          177.766
trainer/Q1Pred Min                          -12.165
trainer/Q2Pred Mean                         124.359
trainer/Q2Pred Std                           40.8331
trainer/Q2Pred Max                          177.435
trainer/Q2Pred Min                           -8.48232
trainer/QTargetWithReg Mean                 124.242
trainer/QTargetWithReg Std                   40.7611
trainer/QTargetWithReg Max                  178.46
trainer/QTargetWithReg Min                  -10.5237
trainer/PolicyLossWithoutReg Mean           126.257
trainer/PolicyLossWithoutReg Std             40.1349
trainer/PolicyLossWithoutReg Max            178.773
trainer/PolicyLossWithoutReg Min            -15.5213
exploration/num steps total               64000
exploration/num paths total                 686
exploration/path length this epoch Mean     151.833
exploration/path length this epoch Std        9.8728
exploration/path length this epoch Max      170
exploration/path length this epoch Min      136
exploration/Rewards Mean                      2.57621
exploration/Rewards Std                       1.30866
exploration/Rewards Max                       6.15712
exploration/Rewards Min                      -0.390205
exploration/Returns Mean                    391.154
exploration/Returns Std                      38.5088
exploration/Returns Max                     442.839
exploration/Returns Min                     339.015
exploration/Num Paths                         6
exploration/Average Returns                 391.154
evaluation_0/num steps total             466293
evaluation_0/num paths total               3214
evaluation_0/path length Mean               243.344
evaluation_0/path length Std                 32.5304
evaluation_0/path length Max                323
evaluation_0/path length Min                162
evaluation_0/Rewards Mean                     2.57544
evaluation_0/Rewards Std                      1.27747
evaluation_0/Rewards Max                      7.12763
evaluation_0/Rewards Min                     -0.552286
evaluation_0/Returns Mean                   626.718
evaluation_0/Returns Std                    107.564
evaluation_0/Returns Max                    922.746
evaluation_0/Returns Min                    430.023
evaluation_0/Num Paths                       32
evaluation_0/Average Returns                626.718
time/epoch (s)                                0
time/total (s)                              786.807
Epoch                                        59
---------------------------------------  ---------------
2022-11-16 16:28:03.604603 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 60 finished
---------------------------------------  ---------------
epoch                                        60
total_step                                65000
replay_pool/size                          65000
trainer/alpha                                 0.0402924
trainer/alpha_loss                            1.04169
trainer/entropy                              -6.32436
trainer/qf_loss                               6.09418
trainer/policy_loss                        -121.737
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         121.992
trainer/entropy_penalty                      -0.254823
trainer/entropy_percentage                   -0.00208885
trainer/Q1Pred Mean                         119.994
trainer/Q1Pred Std                           43.1544
trainer/Q1Pred Max                          180.268
trainer/Q1Pred Min                           -9.53991
trainer/Q2Pred Mean                         119.975
trainer/Q2Pred Std                           43.0558
trainer/Q2Pred Max                          179.068
trainer/Q2Pred Min                            0.348538
trainer/QTargetWithReg Mean                 120.297
trainer/QTargetWithReg Std                   42.9418
trainer/QTargetWithReg Max                  181.163
trainer/QTargetWithReg Min                   -3.28057
trainer/PolicyLossWithoutReg Mean           121.992
trainer/PolicyLossWithoutReg Std             41.712
trainer/PolicyLossWithoutReg Max            179.736
trainer/PolicyLossWithoutReg Min              4.9742
exploration/num steps total               65000
exploration/num paths total                 692
exploration/path length this epoch Mean     151.667
exploration/path length this epoch Std       35.8825
exploration/path length this epoch Max      209
exploration/path length this epoch Min      112
exploration/Rewards Mean                      2.42658
exploration/Rewards Std                       1.14209
exploration/Rewards Max                       5.74409
exploration/Rewards Min                      -0.560914
exploration/Returns Mean                    368.032
exploration/Returns Std                      97.4409
exploration/Returns Max                     476.209
exploration/Returns Min                     264.676
exploration/Num Paths                         6
exploration/Average Returns                 368.032
evaluation_0/num steps total             474227
evaluation_0/num paths total               3252
evaluation_0/path length Mean               208.789
evaluation_0/path length Std                 60.5984
evaluation_0/path length Max                456
evaluation_0/path length Min                136
evaluation_0/Rewards Mean                     2.63128
evaluation_0/Rewards Std                      1.30808
evaluation_0/Rewards Max                      7.64998
evaluation_0/Rewards Min                     -0.359311
evaluation_0/Returns Mean                   549.383
evaluation_0/Returns Std                    185.486
evaluation_0/Returns Max                   1226.33
evaluation_0/Returns Min                    318.566
evaluation_0/Num Paths                       38
evaluation_0/Average Returns                549.383
time/epoch (s)                                0
time/total (s)                              800.777
Epoch                                        60
---------------------------------------  ---------------
2022-11-16 16:28:16.436628 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 61 finished
---------------------------------------  --------------
epoch                                        61
total_step                                66000
replay_pool/size                          66000
trainer/alpha                                 0.0397618
trainer/alpha_loss                           -0.871939
trainer/entropy                              -5.72963
trainer/qf_loss                               6.01855
trainer/policy_loss                        -123.105
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.332
trainer/entropy_penalty                      -0.22782
trainer/entropy_percentage                   -0.0018472
trainer/Q1Pred Mean                         122.732
trainer/Q1Pred Std                           42.5044
trainer/Q1Pred Max                          183.243
trainer/Q1Pred Min                           -8.44219
trainer/Q2Pred Mean                         122.425
trainer/Q2Pred Std                           42.0537
trainer/Q2Pred Max                          180.108
trainer/Q2Pred Min                           -7.60106
trainer/QTargetWithReg Mean                 122.219
trainer/QTargetWithReg Std                   42.5514
trainer/QTargetWithReg Max                  181.216
trainer/QTargetWithReg Min                  -12.5096
trainer/PolicyLossWithoutReg Mean           123.332
trainer/PolicyLossWithoutReg Std             41.7703
trainer/PolicyLossWithoutReg Max            180.898
trainer/PolicyLossWithoutReg Min            -33.4923
exploration/num steps total               66000
exploration/num paths total                 698
exploration/path length this epoch Mean     142.5
exploration/path length this epoch Std       66.6752
exploration/path length this epoch Max      239
exploration/path length this epoch Min       17
exploration/Rewards Mean                      2.4305
exploration/Rewards Std                       1.28777
exploration/Rewards Max                       5.74516
exploration/Rewards Min                      -0.581682
exploration/Returns Mean                    346.347
exploration/Returns Std                     178.997
exploration/Returns Max                     573.94
exploration/Returns Min                       3.60074
exploration/Num Paths                         6
exploration/Average Returns                 346.347
evaluation_0/num steps total             482140
evaluation_0/num paths total               3303
evaluation_0/path length Mean               155.157
evaluation_0/path length Std                 18.2008
evaluation_0/path length Max                251
evaluation_0/path length Min                144
evaluation_0/Rewards Mean                     2.62145
evaluation_0/Rewards Std                      1.33316
evaluation_0/Rewards Max                      7.07002
evaluation_0/Rewards Min                     -0.229636
evaluation_0/Returns Mean                   406.736
evaluation_0/Returns Std                     72.4699
evaluation_0/Returns Max                    769.13
evaluation_0/Returns Min                    359.141
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                406.736
time/epoch (s)                                0
time/total (s)                              813.61
Epoch                                        61
---------------------------------------  --------------
2022-11-16 16:28:28.851322 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 62 finished
---------------------------------------  ---------------
epoch                                        62
total_step                                67000
replay_pool/size                          67000
trainer/alpha                                 0.0385197
trainer/alpha_loss                            0.0175003
trainer/entropy                              -6.00537
trainer/qf_loss                               5.42344
trainer/policy_loss                        -123.259
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.491
trainer/entropy_penalty                      -0.231325
trainer/entropy_percentage                   -0.00187322
trainer/Q1Pred Mean                         121.928
trainer/Q1Pred Std                           44.3119
trainer/Q1Pred Max                          178.069
trainer/Q1Pred Min                           -9.39891
trainer/Q2Pred Mean                         122.311
trainer/Q2Pred Std                           44.1804
trainer/Q2Pred Max                          178.384
trainer/Q2Pred Min                           -6.45976
trainer/QTargetWithReg Mean                 122.472
trainer/QTargetWithReg Std                   44.2369
trainer/QTargetWithReg Max                  177.999
trainer/QTargetWithReg Min                   -6.67694
trainer/PolicyLossWithoutReg Mean           123.491
trainer/PolicyLossWithoutReg Std             43.6983
trainer/PolicyLossWithoutReg Max            178.428
trainer/PolicyLossWithoutReg Min             -5.75604
exploration/num steps total               67000
exploration/num paths total                 703
exploration/path length this epoch Mean     177.2
exploration/path length this epoch Std       54.0237
exploration/path length this epoch Max      249
exploration/path length this epoch Min      102
exploration/Rewards Mean                      2.78403
exploration/Rewards Std                       1.43282
exploration/Rewards Max                       7.14823
exploration/Rewards Min                      -0.402516
exploration/Returns Mean                    493.33
exploration/Returns Std                     183.048
exploration/Returns Max                     727.845
exploration/Returns Min                     249.134
exploration/Num Paths                         5
exploration/Average Returns                 493.33
evaluation_0/num steps total             490007
evaluation_0/num paths total               3363
evaluation_0/path length Mean               131.117
evaluation_0/path length Std                  3.58744
evaluation_0/path length Max                138
evaluation_0/path length Min                125
evaluation_0/Rewards Mean                     2.66642
evaluation_0/Rewards Std                      1.37863
evaluation_0/Rewards Max                      5.86644
evaluation_0/Rewards Min                     -0.540014
evaluation_0/Returns Mean                   349.612
evaluation_0/Returns Std                     12.7399
evaluation_0/Returns Max                    368.375
evaluation_0/Returns Min                    326.858
evaluation_0/Num Paths                       60
evaluation_0/Average Returns                349.612
time/epoch (s)                                0
time/total (s)                              826.025
Epoch                                        62
---------------------------------------  ---------------
2022-11-16 16:28:42.883042 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 63 finished
---------------------------------------  ---------------
epoch                                        63
total_step                                68000
replay_pool/size                          68000
trainer/alpha                                 0.0389758
trainer/alpha_loss                            1.12106
trainer/entropy                              -6.34547
trainer/qf_loss                               4.83699
trainer/policy_loss                        -123.274
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         123.521
trainer/entropy_penalty                      -0.24732
trainer/entropy_percentage                   -0.00200224
trainer/Q1Pred Mean                         121.815
trainer/Q1Pred Std                           40.1066
trainer/Q1Pred Max                          177.396
trainer/Q1Pred Min                          -10.0901
trainer/Q2Pred Mean                         121.826
trainer/Q2Pred Std                           40.5186
trainer/Q2Pred Max                          176.337
trainer/Q2Pred Min                          -12.5037
trainer/QTargetWithReg Mean                 122.24
trainer/QTargetWithReg Std                   40.3579
trainer/QTargetWithReg Max                  177.233
trainer/QTargetWithReg Min                   -1.18993
trainer/PolicyLossWithoutReg Mean           123.521
trainer/PolicyLossWithoutReg Std             38.7145
trainer/PolicyLossWithoutReg Max            176.74
trainer/PolicyLossWithoutReg Min              1.63976
exploration/num steps total               68000
exploration/num paths total                 709
exploration/path length this epoch Mean     159.333
exploration/path length this epoch Std       24.9644
exploration/path length this epoch Max      206
exploration/path length this epoch Min      136
exploration/Rewards Mean                      2.37271
exploration/Rewards Std                       1.35324
exploration/Rewards Max                       6.81932
exploration/Rewards Min                      -0.827578
exploration/Returns Mean                    378.052
exploration/Returns Std                      56.6393
exploration/Returns Max                     470.276
exploration/Returns Min                     320.929
exploration/Num Paths                         6
exploration/Average Returns                 378.052
evaluation_0/num steps total             497843
evaluation_0/num paths total               3419
evaluation_0/path length Mean               139.929
evaluation_0/path length Std                 35.4868
evaluation_0/path length Max                284
evaluation_0/path length Min                107
evaluation_0/Rewards Mean                     2.51042
evaluation_0/Rewards Std                      1.16545
evaluation_0/Rewards Max                      6.74268
evaluation_0/Rewards Min                     -0.224672
evaluation_0/Returns Mean                   351.279
evaluation_0/Returns Std                     95.8406
evaluation_0/Returns Max                    750.008
evaluation_0/Returns Min                    253.027
evaluation_0/Num Paths                       56
evaluation_0/Average Returns                351.279
time/epoch (s)                                0
time/total (s)                              840.056
Epoch                                        63
---------------------------------------  ---------------
2022-11-16 16:28:55.355808 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 64 finished
---------------------------------------  ---------------
epoch                                        64
total_step                                69000
replay_pool/size                          69000
trainer/alpha                                 0.0390421
trainer/alpha_loss                            0.393738
trainer/entropy                              -6.1214
trainer/qf_loss                               3.98146
trainer/policy_loss                        -124.856
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         125.095
trainer/entropy_penalty                      -0.238992
trainer/entropy_percentage                   -0.00191049
trainer/Q1Pred Mean                         123.975
trainer/Q1Pred Std                           42.7817
trainer/Q1Pred Max                          178.078
trainer/Q1Pred Min                           -8.51454
trainer/Q2Pred Mean                         123.91
trainer/Q2Pred Std                           43.0041
trainer/Q2Pred Max                          179.111
trainer/Q2Pred Min                           -8.70684
trainer/QTargetWithReg Mean                 123.91
trainer/QTargetWithReg Std                   42.7749
trainer/QTargetWithReg Max                  178.877
trainer/QTargetWithReg Min                   -6.65966
trainer/PolicyLossWithoutReg Mean           125.095
trainer/PolicyLossWithoutReg Std             42.0748
trainer/PolicyLossWithoutReg Max            179.71
trainer/PolicyLossWithoutReg Min             -5.21513
exploration/num steps total               69000
exploration/num paths total                 713
exploration/path length this epoch Mean     207
exploration/path length this epoch Std       53.2588
exploration/path length this epoch Max      260
exploration/path length this epoch Min      122
exploration/Rewards Mean                      2.64326
exploration/Rewards Std                       1.40942
exploration/Rewards Max                       6.60018
exploration/Rewards Min                      -0.631058
exploration/Returns Mean                    547.154
exploration/Returns Std                     141.297
exploration/Returns Max                     655.819
exploration/Returns Min                     304.206
exploration/Num Paths                         4
exploration/Average Returns                 547.154
evaluation_0/num steps total             505714
evaluation_0/num paths total               3475
evaluation_0/path length Mean               140.554
evaluation_0/path length Std                  3.59523
evaluation_0/path length Max                150
evaluation_0/path length Min                132
evaluation_0/Rewards Mean                     2.52539
evaluation_0/Rewards Std                      1.26336
evaluation_0/Rewards Max                      5.51971
evaluation_0/Rewards Min                     -0.225991
evaluation_0/Returns Mean                   354.953
evaluation_0/Returns Std                      4.97784
evaluation_0/Returns Max                    367.683
evaluation_0/Returns Min                    342.579
evaluation_0/Num Paths                       56
evaluation_0/Average Returns                354.953
time/epoch (s)                                0
time/total (s)                              852.529
Epoch                                        64
---------------------------------------  ---------------
2022-11-16 16:29:08.305416 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 65 finished
---------------------------------------  ---------------
epoch                                        65
total_step                                70000
replay_pool/size                          70000
trainer/alpha                                 0.0384593
trainer/alpha_loss                            1.08041
trainer/entropy                              -6.33161
trainer/qf_loss                               9.457
trainer/policy_loss                        -124.818
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         125.062
trainer/entropy_penalty                      -0.243509
trainer/entropy_percentage                   -0.00194712
trainer/Q1Pred Mean                         123.833
trainer/Q1Pred Std                           42.8234
trainer/Q1Pred Max                          181.797
trainer/Q1Pred Min                            3.11999
trainer/Q2Pred Mean                         123.694
trainer/Q2Pred Std                           42.78
trainer/Q2Pred Max                          181.334
trainer/Q2Pred Min                            2.3106
trainer/QTargetWithReg Mean                 123.46
trainer/QTargetWithReg Std                   42.829
trainer/QTargetWithReg Max                  180.331
trainer/QTargetWithReg Min                   -2.79257
trainer/PolicyLossWithoutReg Mean           125.062
trainer/PolicyLossWithoutReg Std             41.7296
trainer/PolicyLossWithoutReg Max            180.73
trainer/PolicyLossWithoutReg Min              3.54614
exploration/num steps total               70000
exploration/num paths total                 717
exploration/path length this epoch Mean     183.75
exploration/path length this epoch Std       33.357
exploration/path length this epoch Max      235
exploration/path length this epoch Min      149
exploration/Rewards Mean                      2.63772
exploration/Rewards Std                       1.28736
exploration/Rewards Max                       6.1454
exploration/Rewards Min                      -0.425385
exploration/Returns Mean                    484.681
exploration/Returns Std                     109.594
exploration/Returns Max                     669.193
exploration/Returns Min                     386.165
exploration/Num Paths                         4
exploration/Average Returns                 484.681
evaluation_0/num steps total             513663
evaluation_0/num paths total               3520
evaluation_0/path length Mean               176.644
evaluation_0/path length Std                 24.6389
evaluation_0/path length Max                257
evaluation_0/path length Min                150
evaluation_0/Rewards Mean                     2.88416
evaluation_0/Rewards Std                      1.41655
evaluation_0/Rewards Max                      7.96674
evaluation_0/Rewards Min                     -0.396379
evaluation_0/Returns Mean                   509.47
evaluation_0/Returns Std                    105.717
evaluation_0/Returns Max                    875.441
evaluation_0/Returns Min                    395.647
evaluation_0/Num Paths                       45
evaluation_0/Average Returns                509.47
time/epoch (s)                                0
time/total (s)                              865.477
Epoch                                        65
---------------------------------------  ---------------
2022-11-16 16:29:21.532242 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 66 finished
---------------------------------------  ---------------
epoch                                        66
total_step                                71000
replay_pool/size                          71000
trainer/alpha                                 0.0381915
trainer/alpha_loss                           -0.363265
trainer/entropy                              -5.88874
trainer/qf_loss                               5.36373
trainer/policy_loss                        -122.446
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         122.67
trainer/entropy_penalty                      -0.2249
trainer/entropy_percentage                   -0.00183337
trainer/Q1Pred Mean                         121.366
trainer/Q1Pred Std                           43.0413
trainer/Q1Pred Max                          182.366
trainer/Q1Pred Min                           -0.59637
trainer/Q2Pred Mean                         121.283
trainer/Q2Pred Std                           43.1205
trainer/Q2Pred Max                          181.558
trainer/Q2Pred Min                            1.49063
trainer/QTargetWithReg Mean                 121.123
trainer/QTargetWithReg Std                   43.6333
trainer/QTargetWithReg Max                  182.263
trainer/QTargetWithReg Min                   -0.0729188
trainer/PolicyLossWithoutReg Mean           122.67
trainer/PolicyLossWithoutReg Std             42.3807
trainer/PolicyLossWithoutReg Max            181.322
trainer/PolicyLossWithoutReg Min             -1.2683
exploration/num steps total               71000
exploration/num paths total                 721
exploration/path length this epoch Mean     250
exploration/path length this epoch Std       85.235
exploration/path length this epoch Max      397
exploration/path length this epoch Min      191
exploration/Rewards Mean                      2.84695
exploration/Rewards Std                       1.44933
exploration/Rewards Max                       7.55245
exploration/Rewards Min                      -0.578935
exploration/Returns Mean                    711.739
exploration/Returns Std                     245.884
exploration/Returns Max                    1127.89
exploration/Returns Min                     493.737
exploration/Num Paths                         4
exploration/Average Returns                 711.739
evaluation_0/num steps total             521424
evaluation_0/num paths total               3556
evaluation_0/path length Mean               215.583
evaluation_0/path length Std                 38.9903
evaluation_0/path length Max                286
evaluation_0/path length Min                136
evaluation_0/Rewards Mean                     3.27784
evaluation_0/Rewards Std                      1.59688
evaluation_0/Rewards Max                      9.73956
evaluation_0/Rewards Min                     -0.315474
evaluation_0/Returns Mean                   706.648
evaluation_0/Returns Std                    153.915
evaluation_0/Returns Max                    980.229
evaluation_0/Returns Min                    400.607
evaluation_0/Num Paths                       36
evaluation_0/Average Returns                706.648
time/epoch (s)                                0
time/total (s)                              878.704
Epoch                                        66
---------------------------------------  ---------------
2022-11-16 16:29:35.479107 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 67 finished
---------------------------------------  ---------------
epoch                                        67
total_step                                72000
replay_pool/size                          72000
trainer/alpha                                 0.0374137
trainer/alpha_loss                           -1.94724
trainer/entropy                              -5.40733
trainer/qf_loss                               4.36385
trainer/policy_loss                        -128.967
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         129.17
trainer/entropy_penalty                      -0.202308
trainer/entropy_percentage                   -0.00156622
trainer/Q1Pred Mean                         128.173
trainer/Q1Pred Std                           40.3112
trainer/Q1Pred Max                          186.816
trainer/Q1Pred Min                            0.63166
trainer/Q2Pred Mean                         127.709
trainer/Q2Pred Std                           40.263
trainer/Q2Pred Max                          185.081
trainer/Q2Pred Min                            4.09547
trainer/QTargetWithReg Mean                 128.159
trainer/QTargetWithReg Std                   40.4406
trainer/QTargetWithReg Max                  186.149
trainer/QTargetWithReg Min                   -0.0580932
trainer/PolicyLossWithoutReg Mean           129.17
trainer/PolicyLossWithoutReg Std             39.475
trainer/PolicyLossWithoutReg Max            186.537
trainer/PolicyLossWithoutReg Min              7.40039
exploration/num steps total               72000
exploration/num paths total                 725
exploration/path length this epoch Mean     191.75
exploration/path length this epoch Std       40.9657
exploration/path length this epoch Max      262
exploration/path length this epoch Min      159
exploration/Rewards Mean                      3.10706
exploration/Rewards Std                       1.67492
exploration/Rewards Max                       8.42428
exploration/Rewards Min                      -0.518309
exploration/Returns Mean                    595.778
exploration/Returns Std                     128.342
exploration/Returns Max                     817.031
exploration/Returns Min                     505.356
exploration/Num Paths                         4
exploration/Average Returns                 595.778
evaluation_0/num steps total             529193
evaluation_0/num paths total               3590
evaluation_0/path length Mean               228.5
evaluation_0/path length Std                117.968
evaluation_0/path length Max                748
evaluation_0/path length Min                124
evaluation_0/Rewards Mean                     2.96006
evaluation_0/Rewards Std                      1.40061
evaluation_0/Rewards Max                      7.94993
evaluation_0/Rewards Min                     -0.375168
evaluation_0/Returns Mean                   676.374
evaluation_0/Returns Std                    310.254
evaluation_0/Returns Max                   1686.06
evaluation_0/Returns Min                    342.636
evaluation_0/Num Paths                       34
evaluation_0/Average Returns                676.374
time/epoch (s)                                0
time/total (s)                              892.651
Epoch                                        67
---------------------------------------  ---------------
2022-11-16 16:29:49.305545 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 68 finished
---------------------------------------  --------------
epoch                                        68
total_step                                73000
replay_pool/size                          73000
trainer/alpha                                 0.0381377
trainer/alpha_loss                           -0.797594
trainer/entropy                              -5.75583
trainer/qf_loss                               4.34134
trainer/policy_loss                        -128.054
trainer/adversary_policy_loss                 6.00067
trainer/policy_loss_without_entropy         128.273
trainer/entropy_penalty                      -0.219515
trainer/entropy_percentage                   -0.0017113
trainer/Q1Pred Mean                         126.875
trainer/Q1Pred Std                           41.1807
trainer/Q1Pred Max                          184.177
trainer/Q1Pred Min                          -17.7869
trainer/Q2Pred Mean                         126.598
trainer/Q2Pred Std                           41.2612
trainer/Q2Pred Max                          184.714
trainer/Q2Pred Min                          -25.1085
trainer/QTargetWithReg Mean                 126.878
trainer/QTargetWithReg Std                   41.3297
trainer/QTargetWithReg Max                  184.192
trainer/QTargetWithReg Min                  -22.0897
trainer/PolicyLossWithoutReg Mean           128.273
trainer/PolicyLossWithoutReg Std             39.8343
trainer/PolicyLossWithoutReg Max            184.413
trainer/PolicyLossWithoutReg Min              0.857301
exploration/num steps total               73000
exploration/num paths total                 730
exploration/path length this epoch Mean     164.8
exploration/path length this epoch Std       36.4604
exploration/path length this epoch Max      221
exploration/path length this epoch Min      124
exploration/Rewards Mean                      2.75403
exploration/Rewards Std                       1.38978
exploration/Rewards Max                       7.27954
exploration/Rewards Min                      -0.525798
exploration/Returns Mean                    453.865
exploration/Returns Std                     108.774
exploration/Returns Max                     628.157
exploration/Returns Min                     320.249
exploration/Num Paths                         5
exploration/Average Returns                 453.865
evaluation_0/num steps total             537091
evaluation_0/num paths total               3621
evaluation_0/path length Mean               254.774
evaluation_0/path length Std                 63.04
evaluation_0/path length Max                461
evaluation_0/path length Min                170
evaluation_0/Rewards Mean                     2.94564
evaluation_0/Rewards Std                      1.44557
evaluation_0/Rewards Max                      8.59761
evaluation_0/Rewards Min                     -0.839863
evaluation_0/Returns Mean                   750.473
evaluation_0/Returns Std                    204.155
evaluation_0/Returns Max                   1267.63
evaluation_0/Returns Min                    418.686
evaluation_0/Num Paths                       31
evaluation_0/Average Returns                750.473
time/epoch (s)                                0
time/total (s)                              906.476
Epoch                                        68
---------------------------------------  --------------
2022-11-16 16:30:04.072808 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 69 finished
---------------------------------------  ---------------
epoch                                        69
total_step                                74000
replay_pool/size                          74000
trainer/alpha                                 0.0375318
trainer/alpha_loss                           -0.410433
trainer/entropy                              -5.87497
trainer/qf_loss                               5.34664
trainer/policy_loss                        -126.883
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         127.104
trainer/entropy_penalty                      -0.220498
trainer/entropy_percentage                   -0.00173479
trainer/Q1Pred Mean                         125.184
trainer/Q1Pred Std                           44.6331
trainer/Q1Pred Max                          184.677
trainer/Q1Pred Min                          -21.6459
trainer/Q2Pred Mean                         125.16
trainer/Q2Pred Std                           44.3321
trainer/Q2Pred Max                          184.928
trainer/Q2Pred Min                           -8.60254
trainer/QTargetWithReg Mean                 125.047
trainer/QTargetWithReg Std                   44.6197
trainer/QTargetWithReg Max                  184.968
trainer/QTargetWithReg Min                   -6.91912
trainer/PolicyLossWithoutReg Mean           127.104
trainer/PolicyLossWithoutReg Std             41.9632
trainer/PolicyLossWithoutReg Max            183.684
trainer/PolicyLossWithoutReg Min             -5.95573
exploration/num steps total               74000
exploration/num paths total                 738
exploration/path length this epoch Mean     110.25
exploration/path length this epoch Std       58.3304
exploration/path length this epoch Max      189
exploration/path length this epoch Min       34
exploration/Rewards Mean                      2.61294
exploration/Rewards Std                       1.54431
exploration/Rewards Max                       7.34582
exploration/Rewards Min                      -0.793093
exploration/Returns Mean                    288.077
exploration/Returns Std                     205.329
exploration/Returns Max                     571.124
exploration/Returns Min                      36.9014
exploration/Num Paths                         8
exploration/Average Returns                 288.077
evaluation_0/num steps total             544851
evaluation_0/num paths total               3638
evaluation_0/path length Mean               456.471
evaluation_0/path length Std                256.364
evaluation_0/path length Max               1000
evaluation_0/path length Min                198
evaluation_0/Rewards Mean                     3.18274
evaluation_0/Rewards Std                      1.29606
evaluation_0/Rewards Max                      9.26653
evaluation_0/Rewards Min                     -0.198939
evaluation_0/Returns Mean                  1452.83
evaluation_0/Returns Std                    815.441
evaluation_0/Returns Max                   3138.92
evaluation_0/Returns Min                    632.529
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1452.83
time/epoch (s)                                0
time/total (s)                              921.244
Epoch                                        69
---------------------------------------  ---------------
2022-11-16 16:30:17.133490 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 70 finished
---------------------------------------  ---------------
epoch                                        70
total_step                                75000
replay_pool/size                          75000
trainer/alpha                                 0.0387585
trainer/alpha_loss                           -0.702371
trainer/entropy                              -5.78391
trainer/qf_loss                               5.66081
trainer/policy_loss                        -127.552
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         127.777
trainer/entropy_penalty                      -0.224176
trainer/entropy_percentage                   -0.00175443
trainer/Q1Pred Mean                         126.008
trainer/Q1Pred Std                           43.6771
trainer/Q1Pred Max                          182.186
trainer/Q1Pred Min                           -7.55406
trainer/Q2Pred Mean                         126.356
trainer/Q2Pred Std                           43.5153
trainer/Q2Pred Max                          181.908
trainer/Q2Pred Min                           -0.369797
trainer/QTargetWithReg Mean                 126.745
trainer/QTargetWithReg Std                   43.8649
trainer/QTargetWithReg Max                  183.975
trainer/QTargetWithReg Min                    1.2048
trainer/PolicyLossWithoutReg Mean           127.777
trainer/PolicyLossWithoutReg Std             43.0114
trainer/PolicyLossWithoutReg Max            181.59
trainer/PolicyLossWithoutReg Min             -2.30141
exploration/num steps total               75000
exploration/num paths total                 742
exploration/path length this epoch Mean     221.75
exploration/path length this epoch Std       62.7072
exploration/path length this epoch Max      310
exploration/path length this epoch Min      161
exploration/Rewards Mean                      2.89541
exploration/Rewards Std                       1.23839
exploration/Rewards Max                       7.15062
exploration/Rewards Min                      -0.377358
exploration/Returns Mean                    642.056
exploration/Returns Std                     193.925
exploration/Returns Max                     908.672
exploration/Returns Min                     439.435
exploration/Num Paths                         4
exploration/Average Returns                 642.056
evaluation_0/num steps total             552692
evaluation_0/num paths total               3680
evaluation_0/path length Mean               186.69
evaluation_0/path length Std                 25.8498
evaluation_0/path length Max                300
evaluation_0/path length Min                155
evaluation_0/Rewards Mean                     3.20671
evaluation_0/Rewards Std                      1.50473
evaluation_0/Rewards Max                      8.48818
evaluation_0/Rewards Min                     -0.24978
evaluation_0/Returns Mean                   598.663
evaluation_0/Returns Std                    113.864
evaluation_0/Returns Max                   1092.19
evaluation_0/Returns Min                    474.977
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                598.663
time/epoch (s)                                0
time/total (s)                              934.303
Epoch                                        70
---------------------------------------  ---------------
2022-11-16 16:30:31.247969 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 71 finished
---------------------------------------  ---------------
epoch                                        71
total_step                                76000
replay_pool/size                          76000
trainer/alpha                                 0.039891
trainer/alpha_loss                           -0.0545059
trainer/entropy                              -5.98308
trainer/qf_loss                               5.85633
trainer/policy_loss                        -124.268
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         124.506
trainer/entropy_penalty                      -0.238671
trainer/entropy_percentage                   -0.00191694
trainer/Q1Pred Mean                         123.148
trainer/Q1Pred Std                           44.1125
trainer/Q1Pred Max                          188.686
trainer/Q1Pred Min                          -14.1225
trainer/Q2Pred Mean                         123.568
trainer/Q2Pred Std                           44.1255
trainer/Q2Pred Max                          189.167
trainer/Q2Pred Min                          -15.4151
trainer/QTargetWithReg Mean                 123.243
trainer/QTargetWithReg Std                   43.9038
trainer/QTargetWithReg Max                  190.397
trainer/QTargetWithReg Min                  -10.5354
trainer/PolicyLossWithoutReg Mean           124.506
trainer/PolicyLossWithoutReg Std             43.6849
trainer/PolicyLossWithoutReg Max            189.233
trainer/PolicyLossWithoutReg Min            -15.103
exploration/num steps total               76000
exploration/num paths total                 746
exploration/path length this epoch Mean     193.75
exploration/path length this epoch Std       61.3163
exploration/path length this epoch Max      293
exploration/path length this epoch Min      139
exploration/Rewards Mean                      2.84206
exploration/Rewards Std                       1.35774
exploration/Rewards Max                       7.26461
exploration/Rewards Min                      -0.511325
exploration/Returns Mean                    550.65
exploration/Returns Std                     223.641
exploration/Returns Max                     923.507
exploration/Returns Min                     362.766
exploration/Num Paths                         4
exploration/Average Returns                 550.65
evaluation_0/num steps total             560497
evaluation_0/num paths total               3703
evaluation_0/path length Mean               339.348
evaluation_0/path length Std                144.53
evaluation_0/path length Max                697
evaluation_0/path length Min                193
evaluation_0/Rewards Mean                     3.27205
evaluation_0/Rewards Std                      1.44194
evaluation_0/Rewards Max                      9.34964
evaluation_0/Rewards Min                     -0.352166
evaluation_0/Returns Mean                  1110.36
evaluation_0/Returns Std                    547.87
evaluation_0/Returns Max                   2437.2
evaluation_0/Returns Min                    527.182
evaluation_0/Num Paths                       23
evaluation_0/Average Returns               1110.36
time/epoch (s)                                0
time/total (s)                              948.418
Epoch                                        71
---------------------------------------  ---------------
2022-11-16 16:30:45.250311 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 72 finished
---------------------------------------  ---------------
epoch                                        72
total_step                                77000
replay_pool/size                          77000
trainer/alpha                                 0.0402966
trainer/alpha_loss                            0.180495
trainer/entropy                              -6.0562
trainer/qf_loss                               5.98385
trainer/policy_loss                        -128.287
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         128.531
trainer/entropy_penalty                      -0.244045
trainer/entropy_percentage                   -0.00189872
trainer/Q1Pred Mean                         127.628
trainer/Q1Pred Std                           42.6715
trainer/Q1Pred Max                          183.829
trainer/Q1Pred Min                           -7.54328
trainer/Q2Pred Mean                         127.392
trainer/Q2Pred Std                           42.5943
trainer/Q2Pred Max                          184.417
trainer/Q2Pred Min                           -5.66409
trainer/QTargetWithReg Mean                 127.079
trainer/QTargetWithReg Std                   42.5303
trainer/QTargetWithReg Max                  183.132
trainer/QTargetWithReg Min                   -5.54516
trainer/PolicyLossWithoutReg Mean           128.531
trainer/PolicyLossWithoutReg Std             42.1621
trainer/PolicyLossWithoutReg Max            188.799
trainer/PolicyLossWithoutReg Min             -8.28057
exploration/num steps total               77000
exploration/num paths total                 752
exploration/path length this epoch Mean     137.5
exploration/path length this epoch Std       85.461
exploration/path length this epoch Max      263
exploration/path length this epoch Min       13
exploration/Rewards Mean                      2.85726
exploration/Rewards Std                       1.71283
exploration/Rewards Max                       8.94308
exploration/Rewards Min                      -0.612385
exploration/Returns Mean                    392.873
exploration/Returns Std                     301.4
exploration/Returns Max                     873.494
exploration/Returns Min                      -1.65154
exploration/Num Paths                         6
exploration/Average Returns                 392.873
evaluation_0/num steps total             568394
evaluation_0/num paths total               3720
evaluation_0/path length Mean               464.529
evaluation_0/path length Std                189.252
evaluation_0/path length Max                963
evaluation_0/path length Min                233
evaluation_0/Rewards Mean                     2.89737
evaluation_0/Rewards Std                      1.11109
evaluation_0/Rewards Max                      9.45814
evaluation_0/Rewards Min                     -0.516323
evaluation_0/Returns Mean                  1345.91
evaluation_0/Returns Std                    549.379
evaluation_0/Returns Max                   2856.77
evaluation_0/Returns Min                    672.582
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1345.91
time/epoch (s)                                0
time/total (s)                              962.42
Epoch                                        72
---------------------------------------  ---------------
2022-11-16 16:31:00.694496 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 73 finished
---------------------------------------  --------------
epoch                                        73
total_step                                78000
replay_pool/size                          78000
trainer/alpha                                 0.0409778
trainer/alpha_loss                           -0.952127
trainer/entropy                              -5.70197
trainer/qf_loss                               4.22143
trainer/policy_loss                        -131.122
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         131.355
trainer/entropy_penalty                      -0.233654
trainer/entropy_percentage                   -0.0017788
trainer/Q1Pred Mean                         130.135
trainer/Q1Pred Std                           41.8796
trainer/Q1Pred Max                          186.639
trainer/Q1Pred Min                          -16.5958
trainer/Q2Pred Mean                         129.956
trainer/Q2Pred Std                           41.9492
trainer/Q2Pred Max                          186.252
trainer/Q2Pred Min                          -24.668
trainer/QTargetWithReg Mean                 130.004
trainer/QTargetWithReg Std                   41.9521
trainer/QTargetWithReg Max                  185.639
trainer/QTargetWithReg Min                  -29.3085
trainer/PolicyLossWithoutReg Mean           131.355
trainer/PolicyLossWithoutReg Std             41.093
trainer/PolicyLossWithoutReg Max            185.307
trainer/PolicyLossWithoutReg Min              0.831964
exploration/num steps total               78000
exploration/num paths total                 756
exploration/path length this epoch Mean     242.75
exploration/path length this epoch Std      110.285
exploration/path length this epoch Max      383
exploration/path length this epoch Min      128
exploration/Rewards Mean                      2.90771
exploration/Rewards Std                       1.32389
exploration/Rewards Max                       7.79102
exploration/Rewards Min                      -0.532337
exploration/Returns Mean                    705.847
exploration/Returns Std                     359.298
exploration/Returns Max                    1178.45
exploration/Returns Min                     333.932
exploration/Num Paths                         4
exploration/Average Returns                 705.847
evaluation_0/num steps total             576252
evaluation_0/num paths total               3740
evaluation_0/path length Mean               392.9
evaluation_0/path length Std                191.839
evaluation_0/path length Max               1000
evaluation_0/path length Min                159
evaluation_0/Rewards Mean                     3.11508
evaluation_0/Rewards Std                      1.38142
evaluation_0/Rewards Max                      7.95085
evaluation_0/Rewards Min                     -1.05068
evaluation_0/Returns Mean                  1223.92
evaluation_0/Returns Std                    609.214
evaluation_0/Returns Max                   2945.91
evaluation_0/Returns Min                    458.899
evaluation_0/Num Paths                       20
evaluation_0/Average Returns               1223.92
time/epoch (s)                                0
time/total (s)                              977.864
Epoch                                        73
---------------------------------------  --------------
2022-11-16 16:31:14.683553 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 74 finished
---------------------------------------  ---------------
epoch                                        74
total_step                                79000
replay_pool/size                          79000
trainer/alpha                                 0.042768
trainer/alpha_loss                           -0.927577
trainer/entropy                              -5.7057
trainer/qf_loss                               4.7979
trainer/policy_loss                        -126.201
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         126.445
trainer/entropy_penalty                      -0.244022
trainer/entropy_percentage                   -0.00192986
trainer/Q1Pred Mean                         125.423
trainer/Q1Pred Std                           43.6176
trainer/Q1Pred Max                          187.13
trainer/Q1Pred Min                          -16.3304
trainer/Q2Pred Mean                         125.204
trainer/Q2Pred Std                           43.4349
trainer/Q2Pred Max                          186.239
trainer/Q2Pred Min                          -15.429
trainer/QTargetWithReg Mean                 125.473
trainer/QTargetWithReg Std                   43.4354
trainer/QTargetWithReg Max                  185.941
trainer/QTargetWithReg Min                  -13.2103
trainer/PolicyLossWithoutReg Mean           126.445
trainer/PolicyLossWithoutReg Std             43.1689
trainer/PolicyLossWithoutReg Max            187.352
trainer/PolicyLossWithoutReg Min            -16.1902
exploration/num steps total               79000
exploration/num paths total                 759
exploration/path length this epoch Mean     245
exploration/path length this epoch Std       59.8498
exploration/path length this epoch Max      329
exploration/path length this epoch Min      194
exploration/Rewards Mean                      2.46737
exploration/Rewards Std                       1.19906
exploration/Rewards Max                       7.04307
exploration/Rewards Min                      -0.513776
exploration/Returns Mean                    604.506
exploration/Returns Std                     172.226
exploration/Returns Max                     820.601
exploration/Returns Min                     399.145
exploration/Num Paths                         3
exploration/Average Returns                 604.506
evaluation_0/num steps total             583686
evaluation_0/num paths total               3750
evaluation_0/path length Mean               743.4
evaluation_0/path length Std                227.019
evaluation_0/path length Max               1000
evaluation_0/path length Min                413
evaluation_0/Rewards Mean                     2.82188
evaluation_0/Rewards Std                      1.02646
evaluation_0/Rewards Max                      7.73842
evaluation_0/Rewards Min                     -0.224335
evaluation_0/Returns Mean                  2097.79
evaluation_0/Returns Std                    612.899
evaluation_0/Returns Max                   2879.7
evaluation_0/Returns Min                   1021.38
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2097.79
time/epoch (s)                                0
time/total (s)                              991.852
Epoch                                        74
---------------------------------------  ---------------
2022-11-16 16:31:28.474580 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 75 finished
---------------------------------------  ---------------
epoch                                        75
total_step                                80000
replay_pool/size                          80000
trainer/alpha                                 0.0422268
trainer/alpha_loss                            0.546229
trainer/entropy                              -6.1726
trainer/qf_loss                               5.3835
trainer/policy_loss                        -131.526
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         131.787
trainer/entropy_penalty                      -0.260649
trainer/entropy_percentage                   -0.00197781
trainer/Q1Pred Mean                         130.197
trainer/Q1Pred Std                           41.681
trainer/Q1Pred Max                          186.21
trainer/Q1Pred Min                            2.79679
trainer/Q2Pred Mean                         129.838
trainer/Q2Pred Std                           41.8118
trainer/Q2Pred Max                          185.81
trainer/Q2Pred Min                            4.29666
trainer/QTargetWithReg Mean                 130.305
trainer/QTargetWithReg Std                   41.9072
trainer/QTargetWithReg Max                  185.211
trainer/QTargetWithReg Min                   -0.05878
trainer/PolicyLossWithoutReg Mean           131.787
trainer/PolicyLossWithoutReg Std             40.3085
trainer/PolicyLossWithoutReg Max            185.898
trainer/PolicyLossWithoutReg Min              3.75206
exploration/num steps total               80000
exploration/num paths total                 762
exploration/path length this epoch Mean     259
exploration/path length this epoch Std       87.6964
exploration/path length this epoch Max      375
exploration/path length this epoch Min      163
exploration/Rewards Mean                      2.84101
exploration/Rewards Std                       1.30615
exploration/Rewards Max                       7.54476
exploration/Rewards Min                      -0.439353
exploration/Returns Mean                    735.822
exploration/Returns Std                     309.999
exploration/Returns Max                    1121.62
exploration/Returns Min                     362.588
exploration/Num Paths                         3
exploration/Average Returns                 735.822
evaluation_0/num steps total             590977
evaluation_0/num paths total               3760
evaluation_0/path length Mean               729.1
evaluation_0/path length Std                291.938
evaluation_0/path length Max               1000
evaluation_0/path length Min                292
evaluation_0/Rewards Mean                     2.61736
evaluation_0/Rewards Std                      1.04309
evaluation_0/Rewards Max                      7.78387
evaluation_0/Rewards Min                     -2.67254
evaluation_0/Returns Mean                  1908.32
evaluation_0/Returns Std                    804.367
evaluation_0/Returns Max                   3081.26
evaluation_0/Returns Min                    659.056
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               1908.32
time/epoch (s)                                0
time/total (s)                             1005.64
Epoch                                        75
---------------------------------------  ---------------
2022-11-16 16:31:44.743678 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 76 finished
---------------------------------------  ---------------
epoch                                        76
total_step                                81000
replay_pool/size                          81000
trainer/alpha                                 0.0430746
trainer/alpha_loss                           -0.707558
trainer/entropy                              -5.775
trainer/qf_loss                               6.98304
trainer/policy_loss                        -133.735
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         133.984
trainer/entropy_penalty                      -0.248756
trainer/entropy_percentage                   -0.00185661
trainer/Q1Pred Mean                         133.265
trainer/Q1Pred Std                           40.2234
trainer/Q1Pred Max                          188.177
trainer/Q1Pred Min                          -15.6834
trainer/Q2Pred Mean                         133.523
trainer/Q2Pred Std                           40.2996
trainer/Q2Pred Max                          190.855
trainer/Q2Pred Min                          -16.7371
trainer/QTargetWithReg Mean                 132.803
trainer/QTargetWithReg Std                   40.3808
trainer/QTargetWithReg Max                  188.455
trainer/QTargetWithReg Min                  -15.8955
trainer/PolicyLossWithoutReg Mean           133.984
trainer/PolicyLossWithoutReg Std             40.0289
trainer/PolicyLossWithoutReg Max            188.678
trainer/PolicyLossWithoutReg Min            -14.3426
exploration/num steps total               81000
exploration/num paths total                 763
exploration/path length this epoch Mean     664
exploration/path length this epoch Std        0
exploration/path length this epoch Max      664
exploration/path length this epoch Min      664
exploration/Rewards Mean                      2.80627
exploration/Rewards Std                       1.02617
exploration/Rewards Max                       6.22599
exploration/Rewards Min                      -0.435632
exploration/Returns Mean                   1863.36
exploration/Returns Std                       0
exploration/Returns Max                    1863.36
exploration/Returns Min                    1863.36
exploration/Num Paths                         1
exploration/Average Returns                1863.36
evaluation_0/num steps total             598747
evaluation_0/num paths total               3780
evaluation_0/path length Mean               388.5
evaluation_0/path length Std                353.007
evaluation_0/path length Max               1000
evaluation_0/path length Min                 61
evaluation_0/Rewards Mean                     2.06126
evaluation_0/Rewards Std                      0.995195
evaluation_0/Rewards Max                      6.82108
evaluation_0/Rewards Min                     -0.431237
evaluation_0/Returns Mean                   800.799
evaluation_0/Returns Std                    746.435
evaluation_0/Returns Max                   2159.56
evaluation_0/Returns Min                     71.7299
evaluation_0/Num Paths                       20
evaluation_0/Average Returns                800.799
time/epoch (s)                                0
time/total (s)                             1021.91
Epoch                                        76
---------------------------------------  ---------------
2022-11-16 16:31:58.534180 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 77 finished
---------------------------------------  ---------------
epoch                                        77
total_step                                82000
replay_pool/size                          82000
trainer/alpha                                 0.0433139
trainer/alpha_loss                           -0.291746
trainer/entropy                              -5.90706
trainer/qf_loss                               5.83908
trainer/policy_loss                        -130.196
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         130.451
trainer/entropy_penalty                      -0.255858
trainer/entropy_percentage                   -0.00196133
trainer/Q1Pred Mean                         129.336
trainer/Q1Pred Std                           46.077
trainer/Q1Pred Max                          193.373
trainer/Q1Pred Min                           -2.37769
trainer/Q2Pred Mean                         129.28
trainer/Q2Pred Std                           45.9314
trainer/Q2Pred Max                          191.381
trainer/Q2Pred Min                           -1.35645
trainer/QTargetWithReg Mean                 129.447
trainer/QTargetWithReg Std                   45.7276
trainer/QTargetWithReg Max                  191.452
trainer/QTargetWithReg Min                    2.1984
trainer/PolicyLossWithoutReg Mean           130.451
trainer/PolicyLossWithoutReg Std             45.4377
trainer/PolicyLossWithoutReg Max            191.199
trainer/PolicyLossWithoutReg Min              1.2259
exploration/num steps total               82000
exploration/num paths total                 766
exploration/path length this epoch Mean     254
exploration/path length this epoch Std       11.431
exploration/path length this epoch Max      270
exploration/path length this epoch Min      244
exploration/Rewards Mean                      2.41433
exploration/Rewards Std                       1.15968
exploration/Rewards Max                       6.7312
exploration/Rewards Min                      -0.635622
exploration/Returns Mean                    613.24
exploration/Returns Std                      76.6938
exploration/Returns Max                     716.197
exploration/Returns Min                     532.217
exploration/Num Paths                         3
exploration/Average Returns                 613.24
evaluation_0/num steps total             605930
evaluation_0/num paths total               3789
evaluation_0/path length Mean               798.111
evaluation_0/path length Std                291.207
evaluation_0/path length Max               1000
evaluation_0/path length Min                262
evaluation_0/Rewards Mean                     2.78658
evaluation_0/Rewards Std                      0.888262
evaluation_0/Rewards Max                      7.6643
evaluation_0/Rewards Min                     -0.477864
evaluation_0/Returns Mean                  2224
evaluation_0/Returns Std                    713.174
evaluation_0/Returns Max                   2899.33
evaluation_0/Returns Min                    813.688
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2224
time/epoch (s)                                0
time/total (s)                             1035.7
Epoch                                        77
---------------------------------------  ---------------
2022-11-16 16:32:11.564882 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 78 finished
---------------------------------------  ---------------
epoch                                        78
total_step                                83000
replay_pool/size                          83000
trainer/alpha                                 0.0436802
trainer/alpha_loss                            0.114703
trainer/entropy                              -6.03663
trainer/qf_loss                               7.27095
trainer/policy_loss                        -136.007
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         136.27
trainer/entropy_penalty                      -0.263682
trainer/entropy_percentage                   -0.00193499
trainer/Q1Pred Mean                         135.357
trainer/Q1Pred Std                           44.6685
trainer/Q1Pred Max                          194.319
trainer/Q1Pred Min                           -2.45009
trainer/Q2Pred Mean                         134.903
trainer/Q2Pred Std                           43.9416
trainer/Q2Pred Max                          195.604
trainer/Q2Pred Min                            4.24115
trainer/QTargetWithReg Mean                 134.644
trainer/QTargetWithReg Std                   44.4782
trainer/QTargetWithReg Max                  193.395
trainer/QTargetWithReg Min                    2.6207
trainer/PolicyLossWithoutReg Mean           136.27
trainer/PolicyLossWithoutReg Std             43.4891
trainer/PolicyLossWithoutReg Max            195.255
trainer/PolicyLossWithoutReg Min              2.85062
exploration/num steps total               83000
exploration/num paths total                 769
exploration/path length this epoch Mean     207
exploration/path length this epoch Std      124.226
exploration/path length this epoch Max      315
exploration/path length this epoch Min       33
exploration/Rewards Mean                      2.81552
exploration/Rewards Std                       1.43354
exploration/Rewards Max                       7.58732
exploration/Rewards Min                      -0.643109
exploration/Returns Mean                    582.812
exploration/Returns Std                     404.522
exploration/Returns Max                     878.955
exploration/Returns Min                      10.8523
exploration/Num Paths                         3
exploration/Average Returns                 582.812
evaluation_0/num steps total             613930
evaluation_0/num paths total               3797
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.41438
evaluation_0/Rewards Std                      0.705543
evaluation_0/Rewards Max                      3.89281
evaluation_0/Rewards Min                     -0.525633
evaluation_0/Returns Mean                  2414.38
evaluation_0/Returns Std                    147.391
evaluation_0/Returns Max                   2644.14
evaluation_0/Returns Min                   2245.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2414.38
time/epoch (s)                                0
time/total (s)                             1048.73
Epoch                                        78
---------------------------------------  ---------------
2022-11-16 16:32:25.509621 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 79 finished
---------------------------------------  ---------------
epoch                                        79
total_step                                84000
replay_pool/size                          84000
trainer/alpha                                 0.0440173
trainer/alpha_loss                           -0.12314
trainer/entropy                              -5.96057
trainer/qf_loss                               5.94746
trainer/policy_loss                        -135.941
trainer/adversary_policy_loss                 6.28434
trainer/policy_loss_without_entropy         136.204
trainer/entropy_penalty                      -0.262368
trainer/entropy_percentage                   -0.00192629
trainer/Q1Pred Mean                         134.754
trainer/Q1Pred Std                           43.4779
trainer/Q1Pred Max                          197.761
trainer/Q1Pred Min                            2.49058
trainer/Q2Pred Mean                         134.9
trainer/Q2Pred Std                           43.6752
trainer/Q2Pred Max                          197.545
trainer/Q2Pred Min                           -6.63741
trainer/QTargetWithReg Mean                 134.956
trainer/QTargetWithReg Std                   43.5466
trainer/QTargetWithReg Max                  197.938
trainer/QTargetWithReg Min                   -0.122444
trainer/PolicyLossWithoutReg Mean           136.204
trainer/PolicyLossWithoutReg Std             42.4061
trainer/PolicyLossWithoutReg Max            197.995
trainer/PolicyLossWithoutReg Min             13.1486
exploration/num steps total               84000
exploration/num paths total                 771
exploration/path length this epoch Mean     441.5
exploration/path length this epoch Std      108.5
exploration/path length this epoch Max      550
exploration/path length this epoch Min      333
exploration/Rewards Mean                      2.92221
exploration/Rewards Std                       1.18178
exploration/Rewards Max                       6.95421
exploration/Rewards Min                      -0.432205
exploration/Returns Mean                   1290.16
exploration/Returns Std                     288.36
exploration/Returns Max                    1578.52
exploration/Returns Min                    1001.8
exploration/Num Paths                         2
exploration/Average Returns                1290.16
evaluation_0/num steps total             621794
evaluation_0/num paths total               3805
evaluation_0/path length Mean               983
evaluation_0/path length Std                 44.9778
evaluation_0/path length Max               1000
evaluation_0/path length Min                864
evaluation_0/Rewards Mean                     2.51356
evaluation_0/Rewards Std                      0.640799
evaluation_0/Rewards Max                      4.70917
evaluation_0/Rewards Min                     -0.367882
evaluation_0/Returns Mean                  2470.83
evaluation_0/Returns Std                    126.336
evaluation_0/Returns Max                   2650.4
evaluation_0/Returns Min                   2190.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2470.83
time/epoch (s)                                0
time/total (s)                             1062.68
Epoch                                        79
---------------------------------------  ---------------
2022-11-16 16:32:39.343384 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 80 finished
---------------------------------------  ---------------
epoch                                        80
total_step                                85000
replay_pool/size                          85000
trainer/alpha                                 0.0444096
trainer/alpha_loss                            1.58183
trainer/entropy                              -6.50795
trainer/qf_loss                               4.66544
trainer/policy_loss                        -135.986
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         136.275
trainer/entropy_penalty                      -0.289016
trainer/entropy_percentage                   -0.00212084
trainer/Q1Pred Mean                         134.967
trainer/Q1Pred Std                           47.5884
trainer/Q1Pred Max                          197.634
trainer/Q1Pred Min                          -16.7786
trainer/Q2Pred Mean                         134.792
trainer/Q2Pred Std                           47.4826
trainer/Q2Pred Max                          198.292
trainer/Q2Pred Min                          -17.2597
trainer/QTargetWithReg Mean                 134.57
trainer/QTargetWithReg Std                   47.3978
trainer/QTargetWithReg Max                  197.586
trainer/QTargetWithReg Min                  -15.2725
trainer/PolicyLossWithoutReg Mean           136.275
trainer/PolicyLossWithoutReg Std             46.7655
trainer/PolicyLossWithoutReg Max            199.011
trainer/PolicyLossWithoutReg Min            -14.6942
exploration/num steps total               85000
exploration/num paths total                 773
exploration/path length this epoch Mean     419.5
exploration/path length this epoch Std      217.5
exploration/path length this epoch Max      637
exploration/path length this epoch Min      202
exploration/Rewards Mean                      2.8451
exploration/Rewards Std                       1.10508
exploration/Rewards Max                       7.69104
exploration/Rewards Min                      -0.298301
exploration/Returns Mean                   1193.52
exploration/Returns Std                     597.827
exploration/Returns Max                    1791.35
exploration/Returns Min                     595.693
exploration/Num Paths                         2
exploration/Average Returns                1193.52
evaluation_0/num steps total             629376
evaluation_0/num paths total               3813
evaluation_0/path length Mean               947.75
evaluation_0/path length Std                138.241
evaluation_0/path length Max               1000
evaluation_0/path length Min                582
evaluation_0/Rewards Mean                     2.79225
evaluation_0/Rewards Std                      0.770674
evaluation_0/Rewards Max                      7.36459
evaluation_0/Rewards Min                     -0.406511
evaluation_0/Returns Mean                  2646.36
evaluation_0/Returns Std                    247.869
evaluation_0/Returns Max                   2781.86
evaluation_0/Returns Min                   1995.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2646.36
time/epoch (s)                                0
time/total (s)                             1076.51
Epoch                                        80
---------------------------------------  ---------------
2022-11-16 16:32:52.555164 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 81 finished
---------------------------------------  ---------------
epoch                                        81
total_step                                86000
replay_pool/size                          86000
trainer/alpha                                 0.0453047
trainer/alpha_loss                           -0.92236
trainer/entropy                              -5.70193
trainer/qf_loss                               5.17243
trainer/policy_loss                        -135.905
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         136.163
trainer/entropy_penalty                      -0.258324
trainer/entropy_percentage                   -0.00189717
trainer/Q1Pred Mean                         134.709
trainer/Q1Pred Std                           47.9323
trainer/Q1Pred Max                          197.41
trainer/Q1Pred Min                          -17.0783
trainer/Q2Pred Mean                         134.549
trainer/Q2Pred Std                           47.8008
trainer/Q2Pred Max                          197.594
trainer/Q2Pred Min                          -13.1337
trainer/QTargetWithReg Mean                 134.936
trainer/QTargetWithReg Std                   47.9864
trainer/QTargetWithReg Max                  198.464
trainer/QTargetWithReg Min                  -14.8736
trainer/PolicyLossWithoutReg Mean           136.163
trainer/PolicyLossWithoutReg Std             47.2
trainer/PolicyLossWithoutReg Max            197.424
trainer/PolicyLossWithoutReg Min            -14.7729
exploration/num steps total               86000
exploration/num paths total                 776
exploration/path length this epoch Mean     311.333
exploration/path length this epoch Std      316.325
exploration/path length this epoch Max      751
exploration/path length this epoch Min       20
exploration/Rewards Mean                      2.60387
exploration/Rewards Std                       1.15443
exploration/Rewards Max                       6.63481
exploration/Rewards Min                      -0.410944
exploration/Returns Mean                    810.672
exploration/Returns Std                     906.93
exploration/Returns Max                    2076.9
exploration/Returns Min                       0.686213
exploration/Num Paths                         3
exploration/Average Returns                 810.672
evaluation_0/num steps total             637376
evaluation_0/num paths total               3821
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.22048
evaluation_0/Rewards Std                      0.604436
evaluation_0/Rewards Max                      3.47923
evaluation_0/Rewards Min                     -0.131167
evaluation_0/Returns Mean                  2220.48
evaluation_0/Returns Std                     68.585
evaluation_0/Returns Max                   2290.74
evaluation_0/Returns Min                   2099.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2220.48
time/epoch (s)                                0
time/total (s)                             1089.72
Epoch                                        81
---------------------------------------  ---------------
2022-11-16 16:33:04.899419 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 82 finished
---------------------------------------  ---------------
epoch                                        82
total_step                                87000
replay_pool/size                          87000
trainer/alpha                                 0.0473129
trainer/alpha_loss                           -0.978932
trainer/entropy                              -5.67914
trainer/qf_loss                               5.60145
trainer/policy_loss                        -139.352
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         139.621
trainer/entropy_penalty                      -0.268697
trainer/entropy_percentage                   -0.00192448
trainer/Q1Pred Mean                         137.986
trainer/Q1Pred Std                           46.6995
trainer/Q1Pred Max                          198.068
trainer/Q1Pred Min                          -13.1413
trainer/Q2Pred Mean                         138.338
trainer/Q2Pred Std                           46.779
trainer/Q2Pred Max                          199.444
trainer/Q2Pred Min                          -10.8414
trainer/QTargetWithReg Mean                 138.293
trainer/QTargetWithReg Std                   47.0281
trainer/QTargetWithReg Max                  199.348
trainer/QTargetWithReg Min                   -6.30262
trainer/PolicyLossWithoutReg Mean           139.621
trainer/PolicyLossWithoutReg Std             45.8099
trainer/PolicyLossWithoutReg Max            198.333
trainer/PolicyLossWithoutReg Min             -9.07296
exploration/num steps total               87000
exploration/num paths total                 777
exploration/path length this epoch Mean     483
exploration/path length this epoch Std        0
exploration/path length this epoch Max      483
exploration/path length this epoch Min      483
exploration/Rewards Mean                      2.71444
exploration/Rewards Std                       1.1674
exploration/Rewards Max                       6.63317
exploration/Rewards Min                      -0.0808863
exploration/Returns Mean                   1311.07
exploration/Returns Std                       0
exploration/Returns Max                    1311.07
exploration/Returns Min                    1311.07
exploration/Num Paths                         1
exploration/Average Returns                1311.07
evaluation_0/num steps total             645376
evaluation_0/num paths total               3829
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.68741
evaluation_0/Rewards Std                      0.751349
evaluation_0/Rewards Max                      4.66274
evaluation_0/Rewards Min                     -0.142633
evaluation_0/Returns Mean                  2687.41
evaluation_0/Returns Std                     69.9828
evaluation_0/Returns Max                   2776.86
evaluation_0/Returns Min                   2549.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2687.41
time/epoch (s)                                0
time/total (s)                             1102.07
Epoch                                        82
---------------------------------------  ---------------
2022-11-16 16:33:17.220170 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 83 finished
---------------------------------------  ---------------
epoch                                        83
total_step                                88000
replay_pool/size                          88000
trainer/alpha                                 0.0465189
trainer/alpha_loss                            0.71077
trainer/entropy                              -6.23168
trainer/qf_loss                               6.18937
trainer/policy_loss                        -137.925
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         138.215
trainer/entropy_penalty                      -0.289891
trainer/entropy_percentage                   -0.00209739
trainer/Q1Pred Mean                         137.57
trainer/Q1Pred Std                           44.951
trainer/Q1Pred Max                          201.527
trainer/Q1Pred Min                            2.71744
trainer/Q2Pred Mean                         137.628
trainer/Q2Pred Std                           45.0182
trainer/Q2Pred Max                          200.588
trainer/Q2Pred Min                            4.67983
trainer/QTargetWithReg Mean                 137.161
trainer/QTargetWithReg Std                   45.0622
trainer/QTargetWithReg Max                  201.035
trainer/QTargetWithReg Min                    8.38302
trainer/PolicyLossWithoutReg Mean           138.215
trainer/PolicyLossWithoutReg Std             44.4223
trainer/PolicyLossWithoutReg Max            201.133
trainer/PolicyLossWithoutReg Min              5.42934
exploration/num steps total               88000
exploration/num paths total                 778
exploration/path length this epoch Mean     789
exploration/path length this epoch Std        0
exploration/path length this epoch Max      789
exploration/path length this epoch Min      789
exploration/Rewards Mean                      2.4828
exploration/Rewards Std                       0.692002
exploration/Rewards Max                       4.21049
exploration/Rewards Min                      -0.499036
exploration/Returns Mean                   1958.93
exploration/Returns Std                       0
exploration/Returns Max                    1958.93
exploration/Returns Min                    1958.93
exploration/Num Paths                         1
exploration/Average Returns                1958.93
evaluation_0/num steps total             653376
evaluation_0/num paths total               3837
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.76167
evaluation_0/Rewards Std                      0.68177
evaluation_0/Rewards Max                      4.01223
evaluation_0/Rewards Min                     -0.180041
evaluation_0/Returns Mean                  2761.67
evaluation_0/Returns Std                     22.9386
evaluation_0/Returns Max                   2810.65
evaluation_0/Returns Min                   2733.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2761.67
time/epoch (s)                                0
time/total (s)                             1114.39
Epoch                                        83
---------------------------------------  ---------------
2022-11-16 16:33:31.953087 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 84 finished
---------------------------------------  ---------------
epoch                                        84
total_step                                89000
replay_pool/size                          89000
trainer/alpha                                 0.0471526
trainer/alpha_loss                           -0.0495362
trainer/entropy                              -5.98378
trainer/qf_loss                               8.20508
trainer/policy_loss                        -142.407
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         142.69
trainer/entropy_penalty                      -0.282151
trainer/entropy_percentage                   -0.00197738
trainer/Q1Pred Mean                         140.873
trainer/Q1Pred Std                           46.4576
trainer/Q1Pred Max                          206.265
trainer/Q1Pred Min                          -12.9735
trainer/Q2Pred Mean                         141.047
trainer/Q2Pred Std                           46.3356
trainer/Q2Pred Max                          206.672
trainer/Q2Pred Min                          -12.6633
trainer/QTargetWithReg Mean                 140.199
trainer/QTargetWithReg Std                   46.3298
trainer/QTargetWithReg Max                  205.309
trainer/QTargetWithReg Min                  -16.9139
trainer/PolicyLossWithoutReg Mean           142.69
trainer/PolicyLossWithoutReg Std             44.5022
trainer/PolicyLossWithoutReg Max            205.927
trainer/PolicyLossWithoutReg Min            -12.9355
exploration/num steps total               89000
exploration/num paths total                 780
exploration/path length this epoch Mean     385
exploration/path length this epoch Std      105
exploration/path length this epoch Max      490
exploration/path length this epoch Min      280
exploration/Rewards Mean                      2.50981
exploration/Rewards Std                       1.08485
exploration/Rewards Max                       7.89181
exploration/Rewards Min                      -0.222524
exploration/Returns Mean                    966.278
exploration/Returns Std                     328.384
exploration/Returns Max                    1294.66
exploration/Returns Min                     637.894
exploration/Num Paths                         2
exploration/Average Returns                 966.278
evaluation_0/num steps total             660655
evaluation_0/num paths total               3845
evaluation_0/path length Mean               909.875
evaluation_0/path length Std                238.448
evaluation_0/path length Max               1000
evaluation_0/path length Min                279
evaluation_0/Rewards Mean                     2.65697
evaluation_0/Rewards Std                      0.802355
evaluation_0/Rewards Max                      8.48293
evaluation_0/Rewards Min                     -0.0581689
evaluation_0/Returns Mean                  2417.51
evaluation_0/Returns Std                    574.442
evaluation_0/Returns Max                   2761.21
evaluation_0/Returns Min                    909.015
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2417.51
time/epoch (s)                                0
time/total (s)                             1129.12
Epoch                                        84
---------------------------------------  ---------------
2022-11-16 16:33:44.315047 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 85 finished
---------------------------------------  ---------------
epoch                                        85
total_step                                90000
replay_pool/size                          90000
trainer/alpha                                 0.047165
trainer/alpha_loss                           -0.88951
trainer/entropy                              -5.70875
trainer/qf_loss                               6.52677
trainer/policy_loss                        -141.166
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         141.435
trainer/entropy_penalty                      -0.269254
trainer/entropy_percentage                   -0.00190372
trainer/Q1Pred Mean                         140.284
trainer/Q1Pred Std                           50.1346
trainer/Q1Pred Max                          203.296
trainer/Q1Pred Min                          -14.4214
trainer/Q2Pred Mean                         140.239
trainer/Q2Pred Std                           50.1175
trainer/Q2Pred Max                          202.745
trainer/Q2Pred Min                          -13.0083
trainer/QTargetWithReg Mean                 140.072
trainer/QTargetWithReg Std                   50.0801
trainer/QTargetWithReg Max                  206.059
trainer/QTargetWithReg Min                  -14.0377
trainer/PolicyLossWithoutReg Mean           141.435
trainer/PolicyLossWithoutReg Std             49.5041
trainer/PolicyLossWithoutReg Max            202.779
trainer/PolicyLossWithoutReg Min            -10.6224
exploration/num steps total               90000
exploration/num paths total                 781
exploration/path length this epoch Mean     877
exploration/path length this epoch Std        0
exploration/path length this epoch Max      877
exploration/path length this epoch Min      877
exploration/Rewards Mean                      2.74909
exploration/Rewards Std                       0.756019
exploration/Rewards Max                       4.51841
exploration/Rewards Min                      -0.508764
exploration/Returns Mean                   2410.95
exploration/Returns Std                       0
exploration/Returns Max                    2410.95
exploration/Returns Min                    2410.95
exploration/Num Paths                         1
exploration/Average Returns                2410.95
evaluation_0/num steps total             668655
evaluation_0/num paths total               3853
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.56277
evaluation_0/Rewards Std                      0.763202
evaluation_0/Rewards Max                      5.40908
evaluation_0/Rewards Min                     -0.345741
evaluation_0/Returns Mean                  2562.77
evaluation_0/Returns Std                     53.1968
evaluation_0/Returns Max                   2637.84
evaluation_0/Returns Min                   2464.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2562.77
time/epoch (s)                                0
time/total (s)                             1141.48
Epoch                                        85
---------------------------------------  ---------------
2022-11-16 16:33:56.726891 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 86 finished
---------------------------------------  ---------------
epoch                                        86
total_step                                91000
replay_pool/size                          91000
trainer/alpha                                 0.0492534
trainer/alpha_loss                           -0.22201
trainer/entropy                              -5.92626
trainer/qf_loss                              10.2976
trainer/policy_loss                        -142.991
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         143.283
trainer/entropy_penalty                      -0.291888
trainer/entropy_percentage                   -0.00203714
trainer/Q1Pred Mean                         141.153
trainer/Q1Pred Std                           49.614
trainer/Q1Pred Max                          202.453
trainer/Q1Pred Min                           -6.89068
trainer/Q2Pred Mean                         140.616
trainer/Q2Pred Std                           49.6407
trainer/Q2Pred Max                          202.189
trainer/Q2Pred Min                          -11.2438
trainer/QTargetWithReg Mean                 140.798
trainer/QTargetWithReg Std                   49.6159
trainer/QTargetWithReg Max                  201.7
trainer/QTargetWithReg Min                   -6.03591
trainer/PolicyLossWithoutReg Mean           143.283
trainer/PolicyLossWithoutReg Std             47.3504
trainer/PolicyLossWithoutReg Max            202.884
trainer/PolicyLossWithoutReg Min             -5.25463
exploration/num steps total               91000
exploration/num paths total                 782
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.66377
exploration/Rewards Std                       1.04854
exploration/Rewards Max                       6.50415
exploration/Rewards Min                      -0.79845
exploration/Returns Mean                   2663.77
exploration/Returns Std                       0
exploration/Returns Max                    2663.77
exploration/Returns Min                    2663.77
exploration/Num Paths                         1
exploration/Average Returns                2663.77
evaluation_0/num steps total             676655
evaluation_0/num paths total               3861
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.3157
evaluation_0/Rewards Std                      0.684709
evaluation_0/Rewards Max                      3.69613
evaluation_0/Rewards Min                     -0.222062
evaluation_0/Returns Mean                  2315.7
evaluation_0/Returns Std                     54.9695
evaluation_0/Returns Max                   2404.72
evaluation_0/Returns Min                   2229.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2315.7
time/epoch (s)                                0
time/total (s)                             1153.89
Epoch                                        86
---------------------------------------  ---------------
2022-11-16 16:34:11.521677 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 87 finished
---------------------------------------  ---------------
epoch                                        87
total_step                                92000
replay_pool/size                          92000
trainer/alpha                                 0.0496068
trainer/alpha_loss                            0.88132
trainer/entropy                              -6.29342
trainer/qf_loss                               6.59703
trainer/policy_loss                        -140.588
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         140.9
trainer/entropy_penalty                      -0.312196
trainer/entropy_percentage                   -0.00221572
trainer/Q1Pred Mean                         138.471
trainer/Q1Pred Std                           48.3331
trainer/Q1Pred Max                          209.108
trainer/Q1Pred Min                          -16.2876
trainer/Q2Pred Mean                         138.48
trainer/Q2Pred Std                           48.5661
trainer/Q2Pred Max                          209.085
trainer/Q2Pred Min                          -16.2488
trainer/QTargetWithReg Mean                 138.438
trainer/QTargetWithReg Std                   48.3133
trainer/QTargetWithReg Max                  208.893
trainer/QTargetWithReg Min                  -14.1011
trainer/PolicyLossWithoutReg Mean           140.9
trainer/PolicyLossWithoutReg Std             47.5352
trainer/PolicyLossWithoutReg Max            210.059
trainer/PolicyLossWithoutReg Min            -15.377
exploration/num steps total               92000
exploration/num paths total                 783
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.33926
exploration/Rewards Std                       0.718458
exploration/Rewards Max                       4.39573
exploration/Rewards Min                      -0.207176
exploration/Returns Mean                   2339.26
exploration/Returns Std                       0
exploration/Returns Max                    2339.26
exploration/Returns Min                    2339.26
exploration/Num Paths                         1
exploration/Average Returns                2339.26
evaluation_0/num steps total             683900
evaluation_0/num paths total               3870
evaluation_0/path length Mean               805
evaluation_0/path length Std                364.839
evaluation_0/path length Max               1000
evaluation_0/path length Min                113
evaluation_0/Rewards Mean                     2.46689
evaluation_0/Rewards Std                      0.841121
evaluation_0/Rewards Max                      5.8941
evaluation_0/Rewards Min                     -0.428911
evaluation_0/Returns Mean                  1985.85
evaluation_0/Returns Std                    943.494
evaluation_0/Returns Max                   2684.78
evaluation_0/Returns Min                    200.558
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               1985.85
time/epoch (s)                                0
time/total (s)                             1168.69
Epoch                                        87
---------------------------------------  ---------------
2022-11-16 16:34:25.365746 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 88 finished
---------------------------------------  ---------------
epoch                                        88
total_step                                93000
replay_pool/size                          93000
trainer/alpha                                 0.0508804
trainer/alpha_loss                           -0.843245
trainer/entropy                              -5.71686
trainer/qf_loss                               7.25564
trainer/policy_loss                        -151.922
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         152.213
trainer/entropy_penalty                      -0.290876
trainer/entropy_percentage                   -0.00191098
trainer/Q1Pred Mean                         150.587
trainer/Q1Pred Std                           44.8738
trainer/Q1Pred Max                          207.584
trainer/Q1Pred Min                            3.49111
trainer/Q2Pred Mean                         150.85
trainer/Q2Pred Std                           44.6745
trainer/Q2Pred Max                          208.239
trainer/Q2Pred Min                            3.24252
trainer/QTargetWithReg Mean                 151.625
trainer/QTargetWithReg Std                   45.0387
trainer/QTargetWithReg Max                  209.052
trainer/QTargetWithReg Min                   -0.816786
trainer/PolicyLossWithoutReg Mean           152.213
trainer/PolicyLossWithoutReg Std             43.444
trainer/PolicyLossWithoutReg Max            207.793
trainer/PolicyLossWithoutReg Min              5.53493
exploration/num steps total               93000
exploration/num paths total                 785
exploration/path length this epoch Mean     436.5
exploration/path length this epoch Std       62.5
exploration/path length this epoch Max      499
exploration/path length this epoch Min      374
exploration/Rewards Mean                      2.78648
exploration/Rewards Std                       1.17894
exploration/Rewards Max                       8.06601
exploration/Rewards Min                      -0.678187
exploration/Returns Mean                   1216.3
exploration/Returns Std                     276.322
exploration/Returns Max                    1492.62
exploration/Returns Min                     939.978
exploration/Num Paths                         2
exploration/Average Returns                1216.3
evaluation_0/num steps total             691294
evaluation_0/num paths total               3878
evaluation_0/path length Mean               924.25
evaluation_0/path length Std                200.416
evaluation_0/path length Max               1000
evaluation_0/path length Min                394
evaluation_0/Rewards Mean                     2.69086
evaluation_0/Rewards Std                      0.865406
evaluation_0/Rewards Max                      7.44194
evaluation_0/Rewards Min                     -0.407307
evaluation_0/Returns Mean                  2487.03
evaluation_0/Returns Std                    526.854
evaluation_0/Returns Max                   2795.58
evaluation_0/Returns Min                   1099.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2487.03
time/epoch (s)                                0
time/total (s)                             1182.53
Epoch                                        88
---------------------------------------  ---------------
2022-11-16 16:34:37.683863 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 89 finished
---------------------------------------  ---------------
epoch                                        89
total_step                                94000
replay_pool/size                          94000
trainer/alpha                                 0.0505917
trainer/alpha_loss                           -1.59246
trainer/entropy                              -5.46632
trainer/qf_loss                               5.9896
trainer/policy_loss                        -144.611
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         144.887
trainer/entropy_penalty                      -0.27655
trainer/entropy_percentage                   -0.00190873
trainer/Q1Pred Mean                         143.595
trainer/Q1Pred Std                           51.0789
trainer/Q1Pred Max                          207.136
trainer/Q1Pred Min                          -14.8863
trainer/Q2Pred Mean                         143.598
trainer/Q2Pred Std                           51.5229
trainer/Q2Pred Max                          206.57
trainer/Q2Pred Min                          -16.9631
trainer/QTargetWithReg Mean                 143.686
trainer/QTargetWithReg Std                   51.067
trainer/QTargetWithReg Max                  205.165
trainer/QTargetWithReg Min                  -11.3152
trainer/PolicyLossWithoutReg Mean           144.887
trainer/PolicyLossWithoutReg Std             51.0705
trainer/PolicyLossWithoutReg Max            206.8
trainer/PolicyLossWithoutReg Min            -14.1928
exploration/num steps total               94000
exploration/num paths total                 786
exploration/path length this epoch Mean     394
exploration/path length this epoch Std        0
exploration/path length this epoch Max      394
exploration/path length this epoch Min      394
exploration/Rewards Mean                      2.79477
exploration/Rewards Std                       1.14235
exploration/Rewards Max                       6.52572
exploration/Rewards Min                      -0.612659
exploration/Returns Mean                   1101.14
exploration/Returns Std                       0
exploration/Returns Max                    1101.14
exploration/Returns Min                    1101.14
exploration/Num Paths                         1
exploration/Average Returns                1101.14
evaluation_0/num steps total             699294
evaluation_0/num paths total               3886
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.30445
evaluation_0/Rewards Std                      0.691342
evaluation_0/Rewards Max                      3.71793
evaluation_0/Rewards Min                     -0.48131
evaluation_0/Returns Mean                  2304.45
evaluation_0/Returns Std                     27.8757
evaluation_0/Returns Max                   2356.65
evaluation_0/Returns Min                   2263.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2304.45
time/epoch (s)                                0
time/total (s)                             1194.85
Epoch                                        89
---------------------------------------  ---------------
2022-11-16 16:34:52.277708 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 90 finished
---------------------------------------  ---------------
epoch                                        90
total_step                                95000
replay_pool/size                          95000
trainer/alpha                                 0.0510479
trainer/alpha_loss                            0.987836
trainer/entropy                              -6.33203
trainer/qf_loss                               9.16468
trainer/policy_loss                        -153.978
trainer/adversary_policy_loss                 7.11931
trainer/policy_loss_without_entropy         154.301
trainer/entropy_penalty                      -0.323237
trainer/entropy_percentage                   -0.00209484
trainer/Q1Pred Mean                         153.361
trainer/Q1Pred Std                           44.0888
trainer/Q1Pred Max                          206.448
trainer/Q1Pred Min                          -12.015
trainer/Q2Pred Mean                         153.277
trainer/Q2Pred Std                           43.9659
trainer/Q2Pred Max                          206.437
trainer/Q2Pred Min                          -12.1626
trainer/QTargetWithReg Mean                 154.033
trainer/QTargetWithReg Std                   44.0287
trainer/QTargetWithReg Max                  207.308
trainer/QTargetWithReg Min                   -3.20086
trainer/PolicyLossWithoutReg Mean           154.301
trainer/PolicyLossWithoutReg Std             43.5262
trainer/PolicyLossWithoutReg Max            206.689
trainer/PolicyLossWithoutReg Min             -5.65574
exploration/num steps total               95000
exploration/num paths total                 789
exploration/path length this epoch Mean     323.333
exploration/path length this epoch Std      152.198
exploration/path length this epoch Max      537
exploration/path length this epoch Min      194
exploration/Rewards Mean                      2.36035
exploration/Rewards Std                       1.1167
exploration/Rewards Max                       6.60949
exploration/Rewards Min                      -0.629424
exploration/Returns Mean                    763.179
exploration/Returns Std                     384.962
exploration/Returns Max                    1303.97
exploration/Returns Min                     438.481
exploration/Num Paths                         3
exploration/Average Returns                 763.179
evaluation_0/num steps total             706372
evaluation_0/num paths total               3894
evaluation_0/path length Mean               884.75
evaluation_0/path length Std                200.94
evaluation_0/path length Max               1000
evaluation_0/path length Min                493
evaluation_0/Rewards Mean                     2.65383
evaluation_0/Rewards Std                      0.852876
evaluation_0/Rewards Max                      8.32513
evaluation_0/Rewards Min                     -0.50654
evaluation_0/Returns Mean                  2347.98
evaluation_0/Returns Std                    487.61
evaluation_0/Returns Max                   2783.85
evaluation_0/Returns Min                   1376.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2347.98
time/epoch (s)                                0
time/total (s)                             1209.44
Epoch                                        90
---------------------------------------  ---------------
2022-11-16 16:35:06.135963 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 91 finished
---------------------------------------  ---------------
epoch                                        91
total_step                                96000
replay_pool/size                          96000
trainer/alpha                                 0.0520266
trainer/alpha_loss                            0.705307
trainer/entropy                              -6.23859
trainer/qf_loss                              13.2068
trainer/policy_loss                        -149.951
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         150.276
trainer/entropy_penalty                      -0.324573
trainer/entropy_percentage                   -0.00215984
trainer/Q1Pred Mean                         148.463
trainer/Q1Pred Std                           48.221
trainer/Q1Pred Max                          211.745
trainer/Q1Pred Min                           -1.42805
trainer/Q2Pred Mean                         149.14
trainer/Q2Pred Std                           48.2871
trainer/Q2Pred Max                          210.604
trainer/Q2Pred Min                          -13.6271
trainer/QTargetWithReg Mean                 148.179
trainer/QTargetWithReg Std                   48.7563
trainer/QTargetWithReg Max                  211.157
trainer/QTargetWithReg Min                   -0.124488
trainer/PolicyLossWithoutReg Mean           150.276
trainer/PolicyLossWithoutReg Std             47.2066
trainer/PolicyLossWithoutReg Max            211.71
trainer/PolicyLossWithoutReg Min              0.44512
exploration/num steps total               96000
exploration/num paths total                 791
exploration/path length this epoch Mean     441
exploration/path length this epoch Std       32
exploration/path length this epoch Max      473
exploration/path length this epoch Min      409
exploration/Rewards Mean                      3.00159
exploration/Rewards Std                       1.26142
exploration/Rewards Max                       7.65455
exploration/Rewards Min                      -0.888829
exploration/Returns Mean                   1323.7
exploration/Returns Std                      55.0664
exploration/Returns Max                    1378.77
exploration/Returns Min                    1268.64
exploration/Num Paths                         2
exploration/Average Returns                1323.7
evaluation_0/num steps total             714324
evaluation_0/num paths total               3904
evaluation_0/path length Mean               795.2
evaluation_0/path length Std                310.226
evaluation_0/path length Max               1000
evaluation_0/path length Min                174
evaluation_0/Rewards Mean                     2.45055
evaluation_0/Rewards Std                      0.895261
evaluation_0/Rewards Max                      8.15905
evaluation_0/Rewards Min                     -0.499391
evaluation_0/Returns Mean                  1948.68
evaluation_0/Returns Std                    724.06
evaluation_0/Returns Max                   2539.13
evaluation_0/Returns Min                    456.738
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               1948.68
time/epoch (s)                                0
time/total (s)                             1223.3
Epoch                                        91
---------------------------------------  ---------------
2022-11-16 16:35:20.249018 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 92 finished
---------------------------------------  ---------------
epoch                                        92
total_step                                97000
replay_pool/size                          97000
trainer/alpha                                 0.0527823
trainer/alpha_loss                            0.106414
trainer/entropy                              -6.03617
trainer/qf_loss                               7.51484
trainer/policy_loss                        -147.211
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         147.529
trainer/entropy_penalty                      -0.318603
trainer/entropy_percentage                   -0.00215959
trainer/Q1Pred Mean                         145.823
trainer/Q1Pred Std                           54.9545
trainer/Q1Pred Max                          210.858
trainer/Q1Pred Min                          -20.1491
trainer/Q2Pred Mean                         145.265
trainer/Q2Pred Std                           55.2679
trainer/Q2Pred Max                          210.62
trainer/Q2Pred Min                          -19.1472
trainer/QTargetWithReg Mean                 145.626
trainer/QTargetWithReg Std                   54.7035
trainer/QTargetWithReg Max                  210.01
trainer/QTargetWithReg Min                  -22.0596
trainer/PolicyLossWithoutReg Mean           147.529
trainer/PolicyLossWithoutReg Std             54.0083
trainer/PolicyLossWithoutReg Max            210.666
trainer/PolicyLossWithoutReg Min            -15.5899
exploration/num steps total               97000
exploration/num paths total                 793
exploration/path length this epoch Mean     349
exploration/path length this epoch Std      112
exploration/path length this epoch Max      461
exploration/path length this epoch Min      237
exploration/Rewards Mean                      2.6057
exploration/Rewards Std                       1.3277
exploration/Rewards Max                       7.46159
exploration/Rewards Min                      -0.782479
exploration/Returns Mean                    909.388
exploration/Returns Std                     198.452
exploration/Returns Max                    1107.84
exploration/Returns Min                     710.936
exploration/Num Paths                         2
exploration/Average Returns                 909.388
evaluation_0/num steps total             721797
evaluation_0/num paths total               3917
evaluation_0/path length Mean               574.846
evaluation_0/path length Std                240.645
evaluation_0/path length Max               1000
evaluation_0/path length Min                230
evaluation_0/Rewards Mean                     2.85004
evaluation_0/Rewards Std                      1.06673
evaluation_0/Rewards Max                      7.95852
evaluation_0/Rewards Min                     -0.702023
evaluation_0/Returns Mean                  1638.34
evaluation_0/Returns Std                    749.328
evaluation_0/Returns Max                   2927.62
evaluation_0/Returns Min                    603.533
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               1638.34
time/epoch (s)                                0
time/total (s)                             1237.41
Epoch                                        92
---------------------------------------  ---------------
2022-11-16 16:35:34.444919 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 93 finished
---------------------------------------  --------------
epoch                                        93
total_step                                98000
replay_pool/size                          98000
trainer/alpha                                 0.0531433
trainer/alpha_loss                           -1.32026
trainer/entropy                              -5.55012
trainer/qf_loss                              11.3684
trainer/policy_loss                        -149.298
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         149.593
trainer/entropy_penalty                      -0.294952
trainer/entropy_percentage                   -0.0019717
trainer/Q1Pred Mean                         147.635
trainer/Q1Pred Std                           51.2169
trainer/Q1Pred Max                          210.86
trainer/Q1Pred Min                           -6.69421
trainer/Q2Pred Mean                         147.974
trainer/Q2Pred Std                           51.2865
trainer/Q2Pred Max                          209.665
trainer/Q2Pred Min                           -3.83362
trainer/QTargetWithReg Mean                 148.035
trainer/QTargetWithReg Std                   51.7674
trainer/QTargetWithReg Max                  209.584
trainer/QTargetWithReg Min                   -7.99296
trainer/PolicyLossWithoutReg Mean           149.593
trainer/PolicyLossWithoutReg Std             49.8201
trainer/PolicyLossWithoutReg Max            210.141
trainer/PolicyLossWithoutReg Min             -6.37989
exploration/num steps total               98000
exploration/num paths total                 796
exploration/path length this epoch Mean     287.667
exploration/path length this epoch Std      107.717
exploration/path length this epoch Max      407
exploration/path length this epoch Min      146
exploration/Rewards Mean                      2.5401
exploration/Rewards Std                       1.31424
exploration/Rewards Max                       7.31194
exploration/Rewards Min                      -0.656805
exploration/Returns Mean                    730.701
exploration/Returns Std                     278.266
exploration/Returns Max                     962.806
exploration/Returns Min                     339.433
exploration/Num Paths                         3
exploration/Average Returns                 730.701
evaluation_0/num steps total             729354
evaluation_0/num paths total               3926
evaluation_0/path length Mean               839.667
evaluation_0/path length Std                198.166
evaluation_0/path length Max               1000
evaluation_0/path length Min                451
evaluation_0/Rewards Mean                     2.74549
evaluation_0/Rewards Std                      0.924187
evaluation_0/Rewards Max                      8.90514
evaluation_0/Rewards Min                     -0.505681
evaluation_0/Returns Mean                  2305.29
evaluation_0/Returns Std                    499.429
evaluation_0/Returns Max                   2812.33
evaluation_0/Returns Min                   1212.96
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2305.29
time/epoch (s)                                0
time/total (s)                             1251.61
Epoch                                        93
---------------------------------------  --------------
2022-11-16 16:35:48.355970 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 94 finished
---------------------------------------  ---------------
epoch                                        94
total_step                                99000
replay_pool/size                          99000
trainer/alpha                                 0.0534561
trainer/alpha_loss                           -0.0251508
trainer/entropy                              -5.99141
trainer/qf_loss                               7.43324
trainer/policy_loss                        -153.184
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         153.505
trainer/entropy_penalty                      -0.320278
trainer/entropy_percentage                   -0.00208644
trainer/Q1Pred Mean                         152.173
trainer/Q1Pred Std                           50.4304
trainer/Q1Pred Max                          211.147
trainer/Q1Pred Min                          -10.7442
trainer/Q2Pred Mean                         152.35
trainer/Q2Pred Std                           50.4804
trainer/Q2Pred Max                          211.756
trainer/Q2Pred Min                           -8.82047
trainer/QTargetWithReg Mean                 152.392
trainer/QTargetWithReg Std                   50.7672
trainer/QTargetWithReg Max                  212.29
trainer/QTargetWithReg Min                  -10.8934
trainer/PolicyLossWithoutReg Mean           153.505
trainer/PolicyLossWithoutReg Std             49.5451
trainer/PolicyLossWithoutReg Max            212.964
trainer/PolicyLossWithoutReg Min             -7.56844
exploration/num steps total               99000
exploration/num paths total                 799
exploration/path length this epoch Mean     182.333
exploration/path length this epoch Std       95.9768
exploration/path length this epoch Max      271
exploration/path length this epoch Min       49
exploration/Rewards Mean                      2.29447
exploration/Rewards Std                       1.27471
exploration/Rewards Max                       6.73089
exploration/Rewards Min                      -0.508911
exploration/Returns Mean                    418.358
exploration/Returns Std                     256.274
exploration/Returns Max                     610.713
exploration/Returns Min                      56.1659
exploration/Num Paths                         3
exploration/Average Returns                 418.358
evaluation_0/num steps total             737338
evaluation_0/num paths total               3934
evaluation_0/path length Mean               998
evaluation_0/path length Std                  5.2915
evaluation_0/path length Max               1000
evaluation_0/path length Min                984
evaluation_0/Rewards Mean                     2.61377
evaluation_0/Rewards Std                      0.924909
evaluation_0/Rewards Max                      7.71846
evaluation_0/Rewards Min                     -0.318858
evaluation_0/Returns Mean                  2608.54
evaluation_0/Returns Std                     71.2535
evaluation_0/Returns Max                   2726.14
evaluation_0/Returns Min                   2512.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2608.54
time/epoch (s)                                0
time/total (s)                             1265.52
Epoch                                        94
---------------------------------------  ---------------
2022-11-16 16:36:03.057353 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 95 finished
---------------------------------------  ---------------
epoch                                        95
total_step                               100000
replay_pool/size                         100000
trainer/alpha                                 0.0534094
trainer/alpha_loss                            0.281931
trainer/entropy                              -6.09622
trainer/qf_loss                               7.04843
trainer/policy_loss                        -158.052
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         158.378
trainer/entropy_penalty                      -0.325596
trainer/entropy_percentage                   -0.00205581
trainer/Q1Pred Mean                         156.389
trainer/Q1Pred Std                           46.1562
trainer/Q1Pred Max                          217.529
trainer/Q1Pred Min                           -5.09082
trainer/Q2Pred Mean                         156.538
trainer/Q2Pred Std                           46.2831
trainer/Q2Pred Max                          215.196
trainer/Q2Pred Min                           -4.42504
trainer/QTargetWithReg Mean                 156.592
trainer/QTargetWithReg Std                   45.9287
trainer/QTargetWithReg Max                  215.827
trainer/QTargetWithReg Min                   -0.0520547
trainer/PolicyLossWithoutReg Mean           158.378
trainer/PolicyLossWithoutReg Std             44.5977
trainer/PolicyLossWithoutReg Max            217.094
trainer/PolicyLossWithoutReg Min             11.8582
exploration/num steps total              100000
exploration/num paths total                 800
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.42933
exploration/Rewards Std                       0.864668
exploration/Rewards Max                       5.26124
exploration/Rewards Min                      -0.517949
exploration/Returns Mean                   2429.33
exploration/Returns Std                       0
exploration/Returns Max                    2429.33
exploration/Returns Min                    2429.33
exploration/Num Paths                         1
exploration/Average Returns                2429.33
evaluation_0/num steps total             745083
evaluation_0/num paths total               3945
evaluation_0/path length Mean               704.091
evaluation_0/path length Std                298.534
evaluation_0/path length Max               1000
evaluation_0/path length Min                217
evaluation_0/Rewards Mean                     2.59788
evaluation_0/Rewards Std                      1.10818
evaluation_0/Rewards Max                      8.11588
evaluation_0/Rewards Min                     -0.646321
evaluation_0/Returns Mean                  1829.14
evaluation_0/Returns Std                    706.94
evaluation_0/Returns Max                   2560.21
evaluation_0/Returns Min                    584.474
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               1829.14
time/epoch (s)                                0
time/total (s)                             1280.22
Epoch                                        95
---------------------------------------  ---------------
2022-11-16 16:36:17.001305 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 96 finished
---------------------------------------  ---------------
epoch                                        96
total_step                               101000
replay_pool/size                         101000
trainer/alpha                                 0.0529716
trainer/alpha_loss                            1.50525
trainer/entropy                              -6.51231
trainer/qf_loss                               9.45324
trainer/policy_loss                        -156.173
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         156.518
trainer/entropy_penalty                      -0.344968
trainer/entropy_percentage                   -0.00220401
trainer/Q1Pred Mean                         154.098
trainer/Q1Pred Std                           49.6498
trainer/Q1Pred Max                          214.928
trainer/Q1Pred Min                           -9.66207
trainer/Q2Pred Mean                         154.115
trainer/Q2Pred Std                           49.7572
trainer/Q2Pred Max                          217.173
trainer/Q2Pred Min                          -19.6471
trainer/QTargetWithReg Mean                 153.751
trainer/QTargetWithReg Std                   49.5855
trainer/QTargetWithReg Max                  215.726
trainer/QTargetWithReg Min                   -0.599456
trainer/PolicyLossWithoutReg Mean           156.518
trainer/PolicyLossWithoutReg Std             47.1658
trainer/PolicyLossWithoutReg Max            216.964
trainer/PolicyLossWithoutReg Min             -0.226071
exploration/num steps total              101000
exploration/num paths total                 802
exploration/path length this epoch Mean     311
exploration/path length this epoch Std      136
exploration/path length this epoch Max      447
exploration/path length this epoch Min      175
exploration/Rewards Mean                      2.68016
exploration/Rewards Std                       1.27692
exploration/Rewards Max                       5.54136
exploration/Rewards Min                      -1.03453
exploration/Returns Mean                    833.529
exploration/Returns Std                     526.575
exploration/Returns Max                    1360.1
exploration/Returns Min                     306.954
exploration/Num Paths                         2
exploration/Average Returns                 833.529
evaluation_0/num steps total             752872
evaluation_0/num paths total               3954
evaluation_0/path length Mean               865.444
evaluation_0/path length Std                259.138
evaluation_0/path length Max               1000
evaluation_0/path length Min                264
evaluation_0/Rewards Mean                     2.3183
evaluation_0/Rewards Std                      0.945096
evaluation_0/Rewards Max                      7.12736
evaluation_0/Rewards Min                     -1.01397
evaluation_0/Returns Mean                  2006.36
evaluation_0/Returns Std                    623.543
evaluation_0/Returns Max                   2409.8
evaluation_0/Returns Min                    450.493
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2006.36
time/epoch (s)                                0
time/total (s)                             1294.16
Epoch                                        96
---------------------------------------  ---------------
2022-11-16 16:36:31.225236 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 97 finished
---------------------------------------  ---------------
epoch                                        97
total_step                               102000
replay_pool/size                         102000
trainer/alpha                                 0.0531567
trainer/alpha_loss                           -0.150031
trainer/entropy                              -5.94887
trainer/qf_loss                               7.28763
trainer/policy_loss                        -163.173
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         163.489
trainer/entropy_penalty                      -0.316223
trainer/entropy_percentage                   -0.00193421
trainer/Q1Pred Mean                         161.518
trainer/Q1Pred Std                           45.6057
trainer/Q1Pred Max                          216.021
trainer/Q1Pred Min                          -12.7296
trainer/Q2Pred Mean                         161.631
trainer/Q2Pred Std                           45.8068
trainer/Q2Pred Max                          216.285
trainer/Q2Pred Min                          -15.5853
trainer/QTargetWithReg Mean                 161.807
trainer/QTargetWithReg Std                   45.8571
trainer/QTargetWithReg Max                  215.559
trainer/QTargetWithReg Min                  -10.4929
trainer/PolicyLossWithoutReg Mean           163.489
trainer/PolicyLossWithoutReg Std             44.2693
trainer/PolicyLossWithoutReg Max            216.833
trainer/PolicyLossWithoutReg Min            -16.2577
exploration/num steps total              102000
exploration/num paths total                 803
exploration/path length this epoch Mean     964
exploration/path length this epoch Std        0
exploration/path length this epoch Max      964
exploration/path length this epoch Min      964
exploration/Rewards Mean                      2.61517
exploration/Rewards Std                       1.29966
exploration/Rewards Max                       7.11653
exploration/Rewards Min                      -0.912422
exploration/Returns Mean                   2521.02
exploration/Returns Std                       0
exploration/Returns Max                    2521.02
exploration/Returns Min                    2521.02
exploration/Num Paths                         1
exploration/Average Returns                2521.02
evaluation_0/num steps total             759986
evaluation_0/num paths total               3965
evaluation_0/path length Mean               646.727
evaluation_0/path length Std                305.813
evaluation_0/path length Max               1000
evaluation_0/path length Min                327
evaluation_0/Rewards Mean                     2.50242
evaluation_0/Rewards Std                      1.07536
evaluation_0/Rewards Max                      8.05134
evaluation_0/Rewards Min                     -0.617311
evaluation_0/Returns Mean                  1618.38
evaluation_0/Returns Std                    812.284
evaluation_0/Returns Max                   2746.3
evaluation_0/Returns Min                    702.573
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               1618.38
time/epoch (s)                                0
time/total (s)                             1308.39
Epoch                                        97
---------------------------------------  ---------------
2022-11-16 16:36:45.310970 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 98 finished
---------------------------------------  ---------------
epoch                                        98
total_step                               103000
replay_pool/size                         103000
trainer/alpha                                 0.0512575
trainer/alpha_loss                           -0.549784
trainer/entropy                              -5.81494
trainer/qf_loss                               6.54846
trainer/policy_loss                        -158.054
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         158.352
trainer/entropy_penalty                      -0.29806
trainer/entropy_percentage                   -0.00188226
trainer/Q1Pred Mean                         156.78
trainer/Q1Pred Std                           50.3194
trainer/Q1Pred Max                          219.836
trainer/Q1Pred Min                            5.21915
trainer/Q2Pred Mean                         156.315
trainer/Q2Pred Std                           50.1453
trainer/Q2Pred Max                          219.271
trainer/Q2Pred Min                            2.47733
trainer/QTargetWithReg Mean                 156.929
trainer/QTargetWithReg Std                   50.3399
trainer/QTargetWithReg Max                  219.866
trainer/QTargetWithReg Min                    2.82222
trainer/PolicyLossWithoutReg Mean           158.352
trainer/PolicyLossWithoutReg Std             49.3074
trainer/PolicyLossWithoutReg Max            220.427
trainer/PolicyLossWithoutReg Min              5.81994
exploration/num steps total              103000
exploration/num paths total                 806
exploration/path length this epoch Mean     191.667
exploration/path length this epoch Std       83.1117
exploration/path length this epoch Max      309
exploration/path length this epoch Min      127
exploration/Rewards Mean                      2.4596
exploration/Rewards Std                       1.36724
exploration/Rewards Max                       8.15625
exploration/Rewards Min                      -0.60895
exploration/Returns Mean                    471.423
exploration/Returns Std                     207.977
exploration/Returns Max                     765.23
exploration/Returns Min                     312.709
exploration/Num Paths                         3
exploration/Average Returns                 471.423
evaluation_0/num steps total             767761
evaluation_0/num paths total               3976
evaluation_0/path length Mean               706.818
evaluation_0/path length Std                224.033
evaluation_0/path length Max               1000
evaluation_0/path length Min                398
evaluation_0/Rewards Mean                     2.85264
evaluation_0/Rewards Std                      1.04908
evaluation_0/Rewards Max                      7.31761
evaluation_0/Rewards Min                     -0.537917
evaluation_0/Returns Mean                  2016.3
evaluation_0/Returns Std                    634.91
evaluation_0/Returns Max                   2893.4
evaluation_0/Returns Min                    963.714
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2016.3
time/epoch (s)                                0
time/total (s)                             1322.47
Epoch                                        98
---------------------------------------  ---------------
2022-11-16 16:36:59.247325 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 99 finished
---------------------------------------  ---------------
epoch                                        99
total_step                               104000
replay_pool/size                         104000
trainer/alpha                                 0.0517935
trainer/alpha_loss                            1.18631
trainer/entropy                              -6.40069
trainer/qf_loss                               6.91703
trainer/policy_loss                        -163.976
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         164.307
trainer/entropy_penalty                      -0.331514
trainer/entropy_percentage                   -0.00201765
trainer/Q1Pred Mean                         163.479
trainer/Q1Pred Std                           42.6545
trainer/Q1Pred Max                          219.8
trainer/Q1Pred Min                            2.42751
trainer/Q2Pred Mean                         163.122
trainer/Q2Pred Std                           42.5511
trainer/Q2Pred Max                          219.464
trainer/Q2Pred Min                            2.61616
trainer/QTargetWithReg Mean                 162.884
trainer/QTargetWithReg Std                   42.7833
trainer/QTargetWithReg Max                  220.326
trainer/QTargetWithReg Min                    1.75868
trainer/PolicyLossWithoutReg Mean           164.307
trainer/PolicyLossWithoutReg Std             42.0795
trainer/PolicyLossWithoutReg Max            219.322
trainer/PolicyLossWithoutReg Min              1.7389
exploration/num steps total              104000
exploration/num paths total                 808
exploration/path length this epoch Mean     288.5
exploration/path length this epoch Std      104.5
exploration/path length this epoch Max      393
exploration/path length this epoch Min      184
exploration/Rewards Mean                      2.30004
exploration/Rewards Std                       1.2665
exploration/Rewards Max                       6.02237
exploration/Rewards Min                      -0.642782
exploration/Returns Mean                    663.563
exploration/Returns Std                     270.838
exploration/Returns Max                     934.401
exploration/Returns Min                     392.725
exploration/Num Paths                         2
exploration/Average Returns                 663.563
evaluation_0/num steps total             775200
evaluation_0/num paths total               3987
evaluation_0/path length Mean               676.273
evaluation_0/path length Std                267.414
evaluation_0/path length Max               1000
evaluation_0/path length Min                319
evaluation_0/Rewards Mean                     2.84434
evaluation_0/Rewards Std                      1.19814
evaluation_0/Rewards Max                      8.59107
evaluation_0/Rewards Min                     -0.616492
evaluation_0/Returns Mean                  1923.55
evaluation_0/Returns Std                    782.273
evaluation_0/Returns Max                   3141.04
evaluation_0/Returns Min                    864.582
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               1923.55
time/epoch (s)                                0
time/total (s)                             1336.41
Epoch                                        99
---------------------------------------  ---------------
2022-11-16 16:37:13.804885 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 100 finished
---------------------------------------  ---------------
epoch                                       100
total_step                               105000
replay_pool/size                         105000
trainer/alpha                                 0.0511655
trainer/alpha_loss                           -0.306842
trainer/entropy                              -5.89678
trainer/qf_loss                               9.30734
trainer/policy_loss                        -169.852
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         170.154
trainer/entropy_penalty                      -0.301711
trainer/entropy_percentage                   -0.00177317
trainer/Q1Pred Mean                         167.609
trainer/Q1Pred Std                           44.9871
trainer/Q1Pred Max                          218.324
trainer/Q1Pred Min                           -4.05471
trainer/Q2Pred Mean                         167.745
trainer/Q2Pred Std                           45.0431
trainer/Q2Pred Max                          219.287
trainer/Q2Pred Min                           -0.308938
trainer/QTargetWithReg Mean                 167.601
trainer/QTargetWithReg Std                   45.259
trainer/QTargetWithReg Max                  219.784
trainer/QTargetWithReg Min                    1.2048
trainer/PolicyLossWithoutReg Mean           170.154
trainer/PolicyLossWithoutReg Std             42.9863
trainer/PolicyLossWithoutReg Max            220.229
trainer/PolicyLossWithoutReg Min              1.3605
exploration/num steps total              105000
exploration/num paths total                 810
exploration/path length this epoch Mean     236.5
exploration/path length this epoch Std       85.5
exploration/path length this epoch Max      322
exploration/path length this epoch Min      151
exploration/Rewards Mean                      2.53062
exploration/Rewards Std                       1.04329
exploration/Rewards Max                       4.86213
exploration/Rewards Min                      -0.708081
exploration/Returns Mean                    598.493
exploration/Returns Std                     202.435
exploration/Returns Max                     800.928
exploration/Returns Min                     396.057
exploration/Num Paths                         2
exploration/Average Returns                 598.493
evaluation_0/num steps total             782822
evaluation_0/num paths total               4001
evaluation_0/path length Mean               544.429
evaluation_0/path length Std                240.453
evaluation_0/path length Max               1000
evaluation_0/path length Min                187
evaluation_0/Rewards Mean                     2.90307
evaluation_0/Rewards Std                      1.14949
evaluation_0/Rewards Max                      7.89521
evaluation_0/Rewards Min                     -0.43409
evaluation_0/Returns Mean                  1580.51
evaluation_0/Returns Std                    740.135
evaluation_0/Returns Max                   2755.81
evaluation_0/Returns Min                    531.775
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               1580.51
time/epoch (s)                                0
time/total (s)                             1350.96
Epoch                                       100
---------------------------------------  ---------------
2022-11-16 16:37:27.728043 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 101 finished
---------------------------------------  ---------------
epoch                                       101
total_step                               106000
replay_pool/size                         106000
trainer/alpha                                 0.0508023
trainer/alpha_loss                           -0.962262
trainer/entropy                              -5.67708
trainer/qf_loss                              12.3962
trainer/policy_loss                        -163.632
trainer/adversary_policy_loss                 7.66794
trainer/policy_loss_without_entropy         163.92
trainer/entropy_penalty                      -0.288409
trainer/entropy_percentage                   -0.00175945
trainer/Q1Pred Mean                         163.677
trainer/Q1Pred Std                           46.2932
trainer/Q1Pred Max                          221.787
trainer/Q1Pred Min                            2.6785
trainer/Q2Pred Mean                         163.816
trainer/Q2Pred Std                           46.3526
trainer/Q2Pred Max                          221.528
trainer/Q2Pred Min                            0.558671
trainer/QTargetWithReg Mean                 163.227
trainer/QTargetWithReg Std                   46.6912
trainer/QTargetWithReg Max                  221.618
trainer/QTargetWithReg Min                    2.71154
trainer/PolicyLossWithoutReg Mean           163.92
trainer/PolicyLossWithoutReg Std             45.8318
trainer/PolicyLossWithoutReg Max            221.149
trainer/PolicyLossWithoutReg Min              0.940094
exploration/num steps total              106000
exploration/num paths total                 811
exploration/path length this epoch Mean     223
exploration/path length this epoch Std        0
exploration/path length this epoch Max      223
exploration/path length this epoch Min      223
exploration/Rewards Mean                      2.1412
exploration/Rewards Std                       0.983341
exploration/Rewards Max                       3.9833
exploration/Rewards Min                      -0.302701
exploration/Returns Mean                    477.486
exploration/Returns Std                       0
exploration/Returns Max                     477.486
exploration/Returns Min                     477.486
exploration/Num Paths                         1
exploration/Average Returns                 477.486
evaluation_0/num steps total             790547
evaluation_0/num paths total               4010
evaluation_0/path length Mean               858.333
evaluation_0/path length Std                198.155
evaluation_0/path length Max               1000
evaluation_0/path length Min                560
evaluation_0/Rewards Mean                     2.64759
evaluation_0/Rewards Std                      0.955004
evaluation_0/Rewards Max                      7.68652
evaluation_0/Rewards Min                     -0.443519
evaluation_0/Returns Mean                  2272.51
evaluation_0/Returns Std                    580.258
evaluation_0/Returns Max                   2901.9
evaluation_0/Returns Min                   1453.55
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2272.51
time/epoch (s)                                0
time/total (s)                             1364.89
Epoch                                       101
---------------------------------------  ---------------
2022-11-16 16:37:41.682016 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 102 finished
---------------------------------------  ---------------
epoch                                       102
total_step                               107000
replay_pool/size                         107000
trainer/alpha                                 0.050695
trainer/alpha_loss                           -0.0549446
trainer/entropy                              -5.98157
trainer/qf_loss                               7.63183
trainer/policy_loss                        -162.759
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         163.062
trainer/entropy_penalty                      -0.303236
trainer/entropy_percentage                   -0.00185964
trainer/Q1Pred Mean                         162.199
trainer/Q1Pred Std                           49.3007
trainer/Q1Pred Max                          221.451
trainer/Q1Pred Min                            8.31709
trainer/Q2Pred Mean                         161.826
trainer/Q2Pred Std                           48.6081
trainer/Q2Pred Max                          222.405
trainer/Q2Pred Min                           10.457
trainer/QTargetWithReg Mean                 162.217
trainer/QTargetWithReg Std                   49.2898
trainer/QTargetWithReg Max                  222.632
trainer/QTargetWithReg Min                    3.71532
trainer/PolicyLossWithoutReg Mean           163.062
trainer/PolicyLossWithoutReg Std             48.2895
trainer/PolicyLossWithoutReg Max            222.081
trainer/PolicyLossWithoutReg Min             11.9627
exploration/num steps total              107000
exploration/num paths total                 812
exploration/path length this epoch Mean     334
exploration/path length this epoch Std        0
exploration/path length this epoch Max      334
exploration/path length this epoch Min      334
exploration/Rewards Mean                      2.81102
exploration/Rewards Std                       1.0357
exploration/Rewards Max                       4.73017
exploration/Rewards Min                      -0.427181
exploration/Returns Mean                    938.881
exploration/Returns Std                       0
exploration/Returns Max                     938.881
exploration/Returns Min                     938.881
exploration/Num Paths                         1
exploration/Average Returns                 938.881
evaluation_0/num steps total             797972
evaluation_0/num paths total               4022
evaluation_0/path length Mean               618.75
evaluation_0/path length Std                280.574
evaluation_0/path length Max               1000
evaluation_0/path length Min                304
evaluation_0/Rewards Mean                     2.42545
evaluation_0/Rewards Std                      0.999677
evaluation_0/Rewards Max                      8.69593
evaluation_0/Rewards Min                     -0.998065
evaluation_0/Returns Mean                  1500.75
evaluation_0/Returns Std                    661.263
evaluation_0/Returns Max                   2561.28
evaluation_0/Returns Min                    699.403
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               1500.75
time/epoch (s)                                0
time/total (s)                             1378.84
Epoch                                       102
---------------------------------------  ---------------
2022-11-16 16:37:57.958857 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 103 finished
---------------------------------------  ---------------
epoch                                       103
total_step                               108000
replay_pool/size                         108000
trainer/alpha                                 0.0498922
trainer/alpha_loss                            2.01616
trainer/entropy                              -6.67249
trainer/qf_loss                              13.2223
trainer/policy_loss                        -163.042
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         163.375
trainer/entropy_penalty                      -0.332905
trainer/entropy_percentage                   -0.00203768
trainer/Q1Pred Mean                         161.896
trainer/Q1Pred Std                           48.9126
trainer/Q1Pred Max                          220.345
trainer/Q1Pred Min                            4.5914
trainer/Q2Pred Mean                         162.107
trainer/Q2Pred Std                           48.8099
trainer/Q2Pred Max                          220.563
trainer/Q2Pred Min                            1.71707
trainer/QTargetWithReg Mean                 161.535
trainer/QTargetWithReg Std                   49.1859
trainer/QTargetWithReg Max                  220.869
trainer/QTargetWithReg Min                    2.82801
trainer/PolicyLossWithoutReg Mean           163.375
trainer/PolicyLossWithoutReg Std             48.5471
trainer/PolicyLossWithoutReg Max            219.572
trainer/PolicyLossWithoutReg Min              1.11746
exploration/num steps total              108000
exploration/num paths total                 813
exploration/path length this epoch Mean     838
exploration/path length this epoch Std        0
exploration/path length this epoch Max      838
exploration/path length this epoch Min      838
exploration/Rewards Mean                      2.90788
exploration/Rewards Std                       1.03288
exploration/Rewards Max                       6.16684
exploration/Rewards Min                      -0.242191
exploration/Returns Mean                   2436.8
exploration/Returns Std                       0
exploration/Returns Max                    2436.8
exploration/Returns Min                    2436.8
exploration/Num Paths                         1
exploration/Average Returns                2436.8
evaluation_0/num steps total             805966
evaluation_0/num paths total               4038
evaluation_0/path length Mean               499.625
evaluation_0/path length Std                315.644
evaluation_0/path length Max               1000
evaluation_0/path length Min                 91
evaluation_0/Rewards Mean                     2.86921
evaluation_0/Rewards Std                      1.02763
evaluation_0/Rewards Max                      9.13253
evaluation_0/Rewards Min                     -0.48762
evaluation_0/Returns Mean                  1433.53
evaluation_0/Returns Std                    822.318
evaluation_0/Returns Max                   2819.87
evaluation_0/Returns Min                    254.447
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               1433.53
time/epoch (s)                                0
time/total (s)                             1395.12
Epoch                                       103
---------------------------------------  ---------------
2022-11-16 16:38:11.890780 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 104 finished
---------------------------------------  ---------------
epoch                                       104
total_step                               109000
replay_pool/size                         109000
trainer/alpha                                 0.0509935
trainer/alpha_loss                           -0.214887
trainer/entropy                              -5.9278
trainer/qf_loss                               7.53504
trainer/policy_loss                        -165.118
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         165.42
trainer/entropy_penalty                      -0.302279
trainer/entropy_percentage                   -0.00182734
trainer/Q1Pred Mean                         164.072
trainer/Q1Pred Std                           49.9987
trainer/Q1Pred Max                          222.629
trainer/Q1Pred Min                           -7.31986
trainer/Q2Pred Mean                         164.333
trainer/Q2Pred Std                           50.0257
trainer/Q2Pred Max                          222.86
trainer/Q2Pred Min                           -5.10747
trainer/QTargetWithReg Mean                 164.119
trainer/QTargetWithReg Std                   49.8491
trainer/QTargetWithReg Max                  221.468
trainer/QTargetWithReg Min                    0.665452
trainer/PolicyLossWithoutReg Mean           165.42
trainer/PolicyLossWithoutReg Std             48.663
trainer/PolicyLossWithoutReg Max            222.586
trainer/PolicyLossWithoutReg Min             -7.08863
exploration/num steps total              109000
exploration/num paths total                 814
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.07532
exploration/Rewards Std                       0.983194
exploration/Rewards Max                       5.65306
exploration/Rewards Min                      -0.511343
exploration/Returns Mean                   3075.32
exploration/Returns Std                       0
exploration/Returns Max                    3075.32
exploration/Returns Min                    3075.32
exploration/Num Paths                         1
exploration/Average Returns                3075.32
evaluation_0/num steps total             813790
evaluation_0/num paths total               4046
evaluation_0/path length Mean               978
evaluation_0/path length Std                 58.2065
evaluation_0/path length Max               1000
evaluation_0/path length Min                824
evaluation_0/Rewards Mean                     3.12629
evaluation_0/Rewards Std                      0.87711
evaluation_0/Rewards Max                      6.4552
evaluation_0/Rewards Min                     -0.743264
evaluation_0/Returns Mean                  3057.51
evaluation_0/Returns Std                    263.242
evaluation_0/Returns Max                   3322.54
evaluation_0/Returns Min                   2444.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3057.51
time/epoch (s)                                0
time/total (s)                             1409.05
Epoch                                       104
---------------------------------------  ---------------
2022-11-16 16:38:24.516208 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 105 finished
---------------------------------------  ---------------
epoch                                       105
total_step                               110000
replay_pool/size                         110000
trainer/alpha                                 0.0532817
trainer/alpha_loss                           -2.45719
trainer/entropy                              -5.16191
trainer/qf_loss                               7.4903
trainer/policy_loss                        -167.813
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         168.088
trainer/entropy_penalty                      -0.275035
trainer/entropy_percentage                   -0.00163626
trainer/Q1Pred Mean                         165.887
trainer/Q1Pred Std                           53.1717
trainer/Q1Pred Max                          224.223
trainer/Q1Pred Min                            2.95386
trainer/Q2Pred Mean                         165.297
trainer/Q2Pred Std                           52.8926
trainer/Q2Pred Max                          223.8
trainer/Q2Pred Min                            4.54905
trainer/QTargetWithReg Mean                 166.177
trainer/QTargetWithReg Std                   52.8248
trainer/QTargetWithReg Max                  224.306
trainer/QTargetWithReg Min                    4.69545
trainer/PolicyLossWithoutReg Mean           168.088
trainer/PolicyLossWithoutReg Std             51.9083
trainer/PolicyLossWithoutReg Max            225.475
trainer/PolicyLossWithoutReg Min              4.32215
exploration/num steps total              110000
exploration/num paths total                 816
exploration/path length this epoch Mean     396
exploration/path length this epoch Std       12
exploration/path length this epoch Max      408
exploration/path length this epoch Min      384
exploration/Rewards Mean                      2.92673
exploration/Rewards Std                       1.34892
exploration/Rewards Max                       7.7115
exploration/Rewards Min                      -0.974313
exploration/Returns Mean                   1158.99
exploration/Returns Std                      18.891
exploration/Returns Max                    1177.88
exploration/Returns Min                    1140.1
exploration/Num Paths                         2
exploration/Average Returns                1158.99
evaluation_0/num steps total             821790
evaluation_0/num paths total               4054
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.1809
evaluation_0/Rewards Std                      0.778044
evaluation_0/Rewards Max                      4.74431
evaluation_0/Rewards Min                     -0.547336
evaluation_0/Returns Mean                  3180.9
evaluation_0/Returns Std                     39.4457
evaluation_0/Returns Max                   3262.33
evaluation_0/Returns Min                   3117.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3180.9
time/epoch (s)                                0
time/total (s)                             1421.67
Epoch                                       105
---------------------------------------  ---------------
2022-11-16 16:38:37.236816 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 106 finished
---------------------------------------  --------------
epoch                                       106
total_step                               111000
replay_pool/size                         111000
trainer/alpha                                 0.0533633
trainer/alpha_loss                            0.176362
trainer/entropy                              -6.06018
trainer/qf_loss                               8.86118
trainer/policy_loss                        -168.664
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         168.987
trainer/entropy_penalty                      -0.323391
trainer/entropy_percentage                   -0.0019137
trainer/Q1Pred Mean                         168.108
trainer/Q1Pred Std                           52.0764
trainer/Q1Pred Max                          226.642
trainer/Q1Pred Min                            4.88031
trainer/Q2Pred Mean                         167.951
trainer/Q2Pred Std                           52.5476
trainer/Q2Pred Max                          225.703
trainer/Q2Pred Min                            1.43616
trainer/QTargetWithReg Mean                 167.675
trainer/QTargetWithReg Std                   52.3811
trainer/QTargetWithReg Max                  226.154
trainer/QTargetWithReg Min                    2.98104
trainer/PolicyLossWithoutReg Mean           168.987
trainer/PolicyLossWithoutReg Std             51.5458
trainer/PolicyLossWithoutReg Max            225.698
trainer/PolicyLossWithoutReg Min              1.92302
exploration/num steps total              111000
exploration/num paths total                 818
exploration/path length this epoch Mean     397
exploration/path length this epoch Std      259
exploration/path length this epoch Max      656
exploration/path length this epoch Min      138
exploration/Rewards Mean                      2.84797
exploration/Rewards Std                       1.03728
exploration/Rewards Max                       6.13386
exploration/Rewards Min                      -0.978187
exploration/Returns Mean                   1130.65
exploration/Returns Std                     790.591
exploration/Returns Max                    1921.24
exploration/Returns Min                     340.054
exploration/Num Paths                         2
exploration/Average Returns                1130.65
evaluation_0/num steps total             829790
evaluation_0/num paths total               4062
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.06106
evaluation_0/Rewards Std                      0.761906
evaluation_0/Rewards Max                      5.10305
evaluation_0/Rewards Min                     -0.739979
evaluation_0/Returns Mean                  3061.06
evaluation_0/Returns Std                     76.3915
evaluation_0/Returns Max                   3202.22
evaluation_0/Returns Min                   2978.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3061.06
time/epoch (s)                                0
time/total (s)                             1434.4
Epoch                                       106
---------------------------------------  --------------
2022-11-16 16:38:51.147287 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 107 finished
---------------------------------------  ---------------
epoch                                       107
total_step                               112000
replay_pool/size                         112000
trainer/alpha                                 0.0521239
trainer/alpha_loss                           -2.06498
trainer/entropy                              -5.30093
trainer/qf_loss                               6.43209
trainer/policy_loss                        -171.987
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         172.263
trainer/entropy_penalty                      -0.276305
trainer/entropy_percentage                   -0.00160397
trainer/Q1Pred Mean                         171.475
trainer/Q1Pred Std                           45.6953
trainer/Q1Pred Max                          229.82
trainer/Q1Pred Min                           -3.78675
trainer/Q2Pred Mean                         171.393
trainer/Q2Pred Std                           45.585
trainer/Q2Pred Max                          229.436
trainer/Q2Pred Min                           -5.47873
trainer/QTargetWithReg Mean                 171.445
trainer/QTargetWithReg Std                   45.7093
trainer/QTargetWithReg Max                  229.649
trainer/QTargetWithReg Min                   -3.40541
trainer/PolicyLossWithoutReg Mean           172.263
trainer/PolicyLossWithoutReg Std             45.0866
trainer/PolicyLossWithoutReg Max            230.642
trainer/PolicyLossWithoutReg Min             -1.32039
exploration/num steps total              112000
exploration/num paths total                 819
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.16004
exploration/Rewards Std                       0.908936
exploration/Rewards Max                       5.65909
exploration/Rewards Min                      -0.883523
exploration/Returns Mean                   3160.04
exploration/Returns Std                       0
exploration/Returns Max                    3160.04
exploration/Returns Min                    3160.04
exploration/Num Paths                         1
exploration/Average Returns                3160.04
evaluation_0/num steps total             837535
evaluation_0/num paths total               4070
evaluation_0/path length Mean               968.125
evaluation_0/path length Std                 84.3333
evaluation_0/path length Max               1000
evaluation_0/path length Min                745
evaluation_0/Rewards Mean                     3.1923
evaluation_0/Rewards Std                      0.840731
evaluation_0/Rewards Max                      6.17325
evaluation_0/Rewards Min                     -0.879841
evaluation_0/Returns Mean                  3090.54
evaluation_0/Returns Std                    272.128
evaluation_0/Returns Max                   3318.09
evaluation_0/Returns Min                   2404.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3090.54
time/epoch (s)                                0
time/total (s)                             1448.3
Epoch                                       107
---------------------------------------  ---------------
2022-11-16 16:39:04.192303 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 108 finished
---------------------------------------  ---------------
epoch                                       108
total_step                               113000
replay_pool/size                         113000
trainer/alpha                                 0.0515836
trainer/alpha_loss                           -1.2136
trainer/entropy                              -5.59063
trainer/qf_loss                               7.10946
trainer/policy_loss                        -170.868
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         171.156
trainer/entropy_penalty                      -0.288385
trainer/entropy_percentage                   -0.00168492
trainer/Q1Pred Mean                         170.165
trainer/Q1Pred Std                           48.7448
trainer/Q1Pred Max                          226.112
trainer/Q1Pred Min                            0.758895
trainer/Q2Pred Mean                         170.381
trainer/Q2Pred Std                           49.0778
trainer/Q2Pred Max                          225.935
trainer/Q2Pred Min                            2.68651
trainer/QTargetWithReg Mean                 170.013
trainer/QTargetWithReg Std                   48.8391
trainer/QTargetWithReg Max                  224.576
trainer/QTargetWithReg Min                    0.181247
trainer/PolicyLossWithoutReg Mean           171.156
trainer/PolicyLossWithoutReg Std             48.4882
trainer/PolicyLossWithoutReg Max            226.194
trainer/PolicyLossWithoutReg Min              1.33535
exploration/num steps total              113000
exploration/num paths total                 820
exploration/path length this epoch Mean     530
exploration/path length this epoch Std        0
exploration/path length this epoch Max      530
exploration/path length this epoch Min      530
exploration/Rewards Mean                      3.30753
exploration/Rewards Std                       1.08755
exploration/Rewards Max                       7.81197
exploration/Rewards Min                      -0.880844
exploration/Returns Mean                   1752.99
exploration/Returns Std                       0
exploration/Returns Max                    1752.99
exploration/Returns Min                    1752.99
exploration/Num Paths                         1
exploration/Average Returns                1752.99
evaluation_0/num steps total             845535
evaluation_0/num paths total               4078
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.01813
evaluation_0/Rewards Std                      0.763603
evaluation_0/Rewards Max                      4.97188
evaluation_0/Rewards Min                     -0.590538
evaluation_0/Returns Mean                  3018.13
evaluation_0/Returns Std                     81.7626
evaluation_0/Returns Max                   3168.99
evaluation_0/Returns Min                   2896.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3018.13
time/epoch (s)                                0
time/total (s)                             1461.35
Epoch                                       108
---------------------------------------  ---------------
2022-11-16 16:39:16.623895 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 109 finished
---------------------------------------  ---------------
epoch                                       109
total_step                               114000
replay_pool/size                         114000
trainer/alpha                                 0.0528939
trainer/alpha_loss                            1.00327
trainer/entropy                              -6.34131
trainer/qf_loss                               9.64504
trainer/policy_loss                        -166.098
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         166.434
trainer/entropy_penalty                      -0.335416
trainer/entropy_percentage                   -0.00201532
trainer/Q1Pred Mean                         165.066
trainer/Q1Pred Std                           50.7559
trainer/Q1Pred Max                          224.883
trainer/Q1Pred Min                            4.88878
trainer/Q2Pred Mean                         165.744
trainer/Q2Pred Std                           50.5749
trainer/Q2Pred Max                          227.201
trainer/Q2Pred Min                            7.29643
trainer/QTargetWithReg Mean                 165.937
trainer/QTargetWithReg Std                   50.7138
trainer/QTargetWithReg Max                  227.434
trainer/QTargetWithReg Min                    1.79231
trainer/PolicyLossWithoutReg Mean           166.434
trainer/PolicyLossWithoutReg Std             50.605
trainer/PolicyLossWithoutReg Max            227.044
trainer/PolicyLossWithoutReg Min              1.17799
exploration/num steps total              114000
exploration/num paths total                 821
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.11236
exploration/Rewards Std                       0.867505
exploration/Rewards Max                       5.35952
exploration/Rewards Min                      -0.654531
exploration/Returns Mean                   3112.36
exploration/Returns Std                       0
exploration/Returns Max                    3112.36
exploration/Returns Min                    3112.36
exploration/Num Paths                         1
exploration/Average Returns                3112.36
evaluation_0/num steps total             853535
evaluation_0/num paths total               4086
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.10503
evaluation_0/Rewards Std                      0.739524
evaluation_0/Rewards Max                      5.02842
evaluation_0/Rewards Min                     -0.475195
evaluation_0/Returns Mean                  3105.03
evaluation_0/Returns Std                    206.29
evaluation_0/Returns Max                   3307.76
evaluation_0/Returns Min                   2661.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3105.03
time/epoch (s)                                0
time/total (s)                             1473.78
Epoch                                       109
---------------------------------------  ---------------
2022-11-16 16:39:30.564251 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 110 finished
---------------------------------------  ---------------
epoch                                       110
total_step                               115000
replay_pool/size                         115000
trainer/alpha                                 0.0530093
trainer/alpha_loss                            1.94503
trainer/entropy                              -6.66215
trainer/qf_loss                               9.93588
trainer/policy_loss                        -163.94
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         164.294
trainer/entropy_penalty                      -0.353156
trainer/entropy_percentage                   -0.00214954
trainer/Q1Pred Mean                         162.551
trainer/Q1Pred Std                           57.2935
trainer/Q1Pred Max                          227.801
trainer/Q1Pred Min                           -4.12864
trainer/Q2Pred Mean                         162.58
trainer/Q2Pred Std                           57.8656
trainer/Q2Pred Max                          231.295
trainer/Q2Pred Min                           -2.35697
trainer/QTargetWithReg Mean                 162.409
trainer/QTargetWithReg Std                   57.3633
trainer/QTargetWithReg Max                  228.649
trainer/QTargetWithReg Min                   -0.271352
trainer/PolicyLossWithoutReg Mean           164.293
trainer/PolicyLossWithoutReg Std             56.5813
trainer/PolicyLossWithoutReg Max            228.774
trainer/PolicyLossWithoutReg Min              3.30831
exploration/num steps total              115000
exploration/num paths total                 822
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.23512
exploration/Rewards Std                       1.02473
exploration/Rewards Max                       6.94687
exploration/Rewards Min                      -0.706933
exploration/Returns Mean                   3235.12
exploration/Returns Std                       0
exploration/Returns Max                    3235.12
exploration/Returns Min                    3235.12
exploration/Num Paths                         1
exploration/Average Returns                3235.12
evaluation_0/num steps total             861167
evaluation_0/num paths total               4095
evaluation_0/path length Mean               848
evaluation_0/path length Std                177.296
evaluation_0/path length Max               1000
evaluation_0/path length Min                552
evaluation_0/Rewards Mean                     3.24437
evaluation_0/Rewards Std                      0.902702
evaluation_0/Rewards Max                      8.83152
evaluation_0/Rewards Min                     -0.523489
evaluation_0/Returns Mean                  2751.22
evaluation_0/Returns Std                    527.873
evaluation_0/Returns Max                   3269.6
evaluation_0/Returns Min                   1896.53
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2751.22
time/epoch (s)                                0
time/total (s)                             1487.72
Epoch                                       110
---------------------------------------  ---------------
2022-11-16 16:39:46.170384 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 111 finished
---------------------------------------  ---------------
epoch                                       111
total_step                               116000
replay_pool/size                         116000
trainer/alpha                                 0.0534649
trainer/alpha_loss                           -0.289962
trainer/entropy                              -5.901
trainer/qf_loss                              10.0596
trainer/policy_loss                        -166.366
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         166.682
trainer/entropy_penalty                      -0.315497
trainer/entropy_percentage                   -0.00189281
trainer/Q1Pred Mean                         165.322
trainer/Q1Pred Std                           54.8371
trainer/Q1Pred Max                          230.604
trainer/Q1Pred Min                          -11.7502
trainer/Q2Pred Mean                         165.054
trainer/Q2Pred Std                           55.1821
trainer/Q2Pred Max                          231.327
trainer/Q2Pred Min                           -2.31797
trainer/QTargetWithReg Mean                 165.249
trainer/QTargetWithReg Std                   55.3845
trainer/QTargetWithReg Max                  230.472
trainer/QTargetWithReg Min                   -0.729221
trainer/PolicyLossWithoutReg Mean           166.681
trainer/PolicyLossWithoutReg Std             53.5742
trainer/PolicyLossWithoutReg Max            230.867
trainer/PolicyLossWithoutReg Min              5.54112
exploration/num steps total              116000
exploration/num paths total                 823
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.12186
exploration/Rewards Std                       0.927059
exploration/Rewards Max                       5.93856
exploration/Rewards Min                      -0.49447
exploration/Returns Mean                   3121.86
exploration/Returns Std                       0
exploration/Returns Max                    3121.86
exploration/Returns Min                    3121.86
exploration/Num Paths                         1
exploration/Average Returns                3121.86
evaluation_0/num steps total             868565
evaluation_0/num paths total               4111
evaluation_0/path length Mean               462.375
evaluation_0/path length Std                156.173
evaluation_0/path length Max                953
evaluation_0/path length Min                295
evaluation_0/Rewards Mean                     3.60464
evaluation_0/Rewards Std                      1.21669
evaluation_0/Rewards Max                      9.63566
evaluation_0/Rewards Min                     -0.767183
evaluation_0/Returns Mean                  1666.7
evaluation_0/Returns Std                    642.897
evaluation_0/Returns Max                   3728.37
evaluation_0/Returns Min                   1000.44
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               1666.7
time/epoch (s)                                0
time/total (s)                             1503.33
Epoch                                       111
---------------------------------------  ---------------
2022-11-16 16:39:58.502621 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 112 finished
---------------------------------------  --------------
epoch                                       112
total_step                               117000
replay_pool/size                         117000
trainer/alpha                                 0.0540931
trainer/alpha_loss                           -1.16544
trainer/entropy                              -5.60046
trainer/qf_loss                              10.8748
trainer/policy_loss                        -181.975
trainer/adversary_policy_loss                 8.53686
trainer/policy_loss_without_entropy         182.278
trainer/entropy_penalty                      -0.302946
trainer/entropy_percentage                   -0.001662
trainer/Q1Pred Mean                         181.423
trainer/Q1Pred Std                           40.8219
trainer/Q1Pred Max                          233.677
trainer/Q1Pred Min                           27.6369
trainer/Q2Pred Mean                         181.247
trainer/Q2Pred Std                           40.4886
trainer/Q2Pred Max                          234.118
trainer/Q2Pred Min                           26.6285
trainer/QTargetWithReg Mean                 181.182
trainer/QTargetWithReg Std                   40.6757
trainer/QTargetWithReg Max                  233.435
trainer/QTargetWithReg Min                   27.8653
trainer/PolicyLossWithoutReg Mean           182.278
trainer/PolicyLossWithoutReg Std             39.6641
trainer/PolicyLossWithoutReg Max            234.216
trainer/PolicyLossWithoutReg Min             29.1862
exploration/num steps total              117000
exploration/num paths total                 824
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.52598
exploration/Rewards Std                       0.876312
exploration/Rewards Max                       7.01015
exploration/Rewards Min                      -0.65335
exploration/Returns Mean                   3525.98
exploration/Returns Std                       0
exploration/Returns Max                    3525.98
exploration/Returns Min                    3525.98
exploration/Num Paths                         1
exploration/Average Returns                3525.98
evaluation_0/num steps total             876565
evaluation_0/num paths total               4119
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.87615
evaluation_0/Rewards Std                      0.818966
evaluation_0/Rewards Max                      5.35971
evaluation_0/Rewards Min                     -0.38335
evaluation_0/Returns Mean                  2876.15
evaluation_0/Returns Std                    202.706
evaluation_0/Returns Max                   3384.29
evaluation_0/Returns Min                   2727.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2876.15
time/epoch (s)                                0
time/total (s)                             1515.66
Epoch                                       112
---------------------------------------  --------------
2022-11-16 16:40:12.460371 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 113 finished
---------------------------------------  ---------------
epoch                                       113
total_step                               118000
replay_pool/size                         118000
trainer/alpha                                 0.0541446
trainer/alpha_loss                           -0.65874
trainer/entropy                              -5.77408
trainer/qf_loss                               8.77861
trainer/policy_loss                        -172.444
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         172.756
trainer/entropy_penalty                      -0.312635
trainer/entropy_percentage                   -0.00180969
trainer/Q1Pred Mean                         172.197
trainer/Q1Pred Std                           53.3793
trainer/Q1Pred Max                          231.511
trainer/Q1Pred Min                           -6.92437
trainer/Q2Pred Mean                         172.199
trainer/Q2Pred Std                           53.5145
trainer/Q2Pred Max                          233.019
trainer/Q2Pred Min                          -16.478
trainer/QTargetWithReg Mean                 172.226
trainer/QTargetWithReg Std                   53.4719
trainer/QTargetWithReg Max                  232.8
trainer/QTargetWithReg Min                   -0.812105
trainer/PolicyLossWithoutReg Mean           172.756
trainer/PolicyLossWithoutReg Std             52.1149
trainer/PolicyLossWithoutReg Max            232.687
trainer/PolicyLossWithoutReg Min              2.03004
exploration/num steps total              118000
exploration/num paths total                 825
exploration/path length this epoch Mean     816
exploration/path length this epoch Std        0
exploration/path length this epoch Max      816
exploration/path length this epoch Min      816
exploration/Rewards Mean                      3.09902
exploration/Rewards Std                       0.986392
exploration/Rewards Max                       5.8419
exploration/Rewards Min                      -0.357942
exploration/Returns Mean                   2528.8
exploration/Returns Std                       0
exploration/Returns Max                    2528.8
exploration/Returns Min                    2528.8
exploration/Num Paths                         1
exploration/Average Returns                2528.8
evaluation_0/num steps total             884126
evaluation_0/num paths total               4135
evaluation_0/path length Mean               472.562
evaluation_0/path length Std                133.463
evaluation_0/path length Max                797
evaluation_0/path length Min                310
evaluation_0/Rewards Mean                     3.4906
evaluation_0/Rewards Std                      1.14604
evaluation_0/Rewards Max                      9.51998
evaluation_0/Rewards Min                     -0.622231
evaluation_0/Returns Mean                  1649.53
evaluation_0/Returns Std                    509.89
evaluation_0/Returns Max                   2888.16
evaluation_0/Returns Min                   1020.16
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               1649.53
time/epoch (s)                                0
time/total (s)                             1529.62
Epoch                                       113
---------------------------------------  ---------------
2022-11-16 16:40:27.216325 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 114 finished
---------------------------------------  ---------------
epoch                                       114
total_step                               119000
replay_pool/size                         119000
trainer/alpha                                 0.0545113
trainer/alpha_loss                           -1.14801
trainer/entropy                              -5.6054
trainer/qf_loss                               8.74078
trainer/policy_loss                        -174.598
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         174.904
trainer/entropy_penalty                      -0.305558
trainer/entropy_percentage                   -0.00174701
trainer/Q1Pred Mean                         172.87
trainer/Q1Pred Std                           55.8812
trainer/Q1Pred Max                          231.914
trainer/Q1Pred Min                          -23.0673
trainer/Q2Pred Mean                         172.481
trainer/Q2Pred Std                           55.718
trainer/Q2Pred Max                          230.888
trainer/Q2Pred Min                          -18.9312
trainer/QTargetWithReg Mean                 172.253
trainer/QTargetWithReg Std                   56.3762
trainer/QTargetWithReg Max                  230.73
trainer/QTargetWithReg Min                  -14.2178
trainer/PolicyLossWithoutReg Mean           174.904
trainer/PolicyLossWithoutReg Std             53.3666
trainer/PolicyLossWithoutReg Max            232.539
trainer/PolicyLossWithoutReg Min              5.29795
exploration/num steps total              119000
exploration/num paths total                 826
exploration/path length this epoch Mean     635
exploration/path length this epoch Std        0
exploration/path length this epoch Max      635
exploration/path length this epoch Min      635
exploration/Rewards Mean                      2.85771
exploration/Rewards Std                       0.891198
exploration/Rewards Max                       5.21059
exploration/Rewards Min                      -0.816945
exploration/Returns Mean                   1814.64
exploration/Returns Std                       0
exploration/Returns Max                    1814.64
exploration/Returns Min                    1814.64
exploration/Num Paths                         1
exploration/Average Returns                1814.64
evaluation_0/num steps total             892069
evaluation_0/num paths total               4145
evaluation_0/path length Mean               794.3
evaluation_0/path length Std                184.734
evaluation_0/path length Max               1000
evaluation_0/path length Min                502
evaluation_0/Rewards Mean                     3.79392
evaluation_0/Rewards Std                      1.02509
evaluation_0/Rewards Max                      9.67678
evaluation_0/Rewards Min                     -0.557372
evaluation_0/Returns Mean                  3013.51
evaluation_0/Returns Std                    695.71
evaluation_0/Returns Max                   3811.26
evaluation_0/Returns Min                   1829.84
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3013.51
time/epoch (s)                                0
time/total (s)                             1544.37
Epoch                                       114
---------------------------------------  ---------------
2022-11-16 16:40:39.529903 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 115 finished
---------------------------------------  ---------------
epoch                                       115
total_step                               120000
replay_pool/size                         120000
trainer/alpha                                 0.0552654
trainer/alpha_loss                            0.799771
trainer/entropy                              -6.27618
trainer/qf_loss                               8.10007
trainer/policy_loss                        -181.922
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         182.269
trainer/entropy_penalty                      -0.346856
trainer/entropy_percentage                   -0.00190299
trainer/Q1Pred Mean                         180.613
trainer/Q1Pred Std                           44.7809
trainer/Q1Pred Max                          235.578
trainer/Q1Pred Min                           -3.80499
trainer/Q2Pred Mean                         180.348
trainer/Q2Pred Std                           44.9253
trainer/Q2Pred Max                          234.619
trainer/Q2Pred Min                           -5.0107
trainer/QTargetWithReg Mean                 180.598
trainer/QTargetWithReg Std                   44.8014
trainer/QTargetWithReg Max                  233.445
trainer/QTargetWithReg Min                   -4.40991
trainer/PolicyLossWithoutReg Mean           182.269
trainer/PolicyLossWithoutReg Std             43.343
trainer/PolicyLossWithoutReg Max            235.905
trainer/PolicyLossWithoutReg Min              3.01421
exploration/num steps total              120000
exploration/num paths total                 827
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.32946
exploration/Rewards Std                       0.900543
exploration/Rewards Max                       6.13836
exploration/Rewards Min                      -0.623723
exploration/Returns Mean                   3329.46
exploration/Returns Std                       0
exploration/Returns Max                    3329.46
exploration/Returns Min                    3329.46
exploration/Num Paths                         1
exploration/Average Returns                3329.46
evaluation_0/num steps total             900069
evaluation_0/num paths total               4153
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.91796
evaluation_0/Rewards Std                      0.853803
evaluation_0/Rewards Max                      5.51577
evaluation_0/Rewards Min                     -0.545964
evaluation_0/Returns Mean                  2917.96
evaluation_0/Returns Std                    106.414
evaluation_0/Returns Max                   3098.04
evaluation_0/Returns Min                   2809.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2917.96
time/epoch (s)                                0
time/total (s)                             1556.69
Epoch                                       115
---------------------------------------  ---------------
2022-11-16 16:40:51.877859 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 116 finished
---------------------------------------  ---------------
epoch                                       116
total_step                               121000
replay_pool/size                         121000
trainer/alpha                                 0.0546292
trainer/alpha_loss                           -0.668698
trainer/entropy                              -5.76999
trainer/qf_loss                              10.0741
trainer/policy_loss                        -175.232
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         175.547
trainer/entropy_penalty                      -0.31521
trainer/entropy_percentage                   -0.00179559
trainer/Q1Pred Mean                         174.175
trainer/Q1Pred Std                           54.4039
trainer/Q1Pred Max                          234.844
trainer/Q1Pred Min                          -11.1157
trainer/Q2Pred Mean                         173.958
trainer/Q2Pred Std                           54.4669
trainer/Q2Pred Max                          235.342
trainer/Q2Pred Min                          -20.885
trainer/QTargetWithReg Mean                 173.48
trainer/QTargetWithReg Std                   54.5095
trainer/QTargetWithReg Max                  234.276
trainer/QTargetWithReg Min                  -21.5311
trainer/PolicyLossWithoutReg Mean           175.547
trainer/PolicyLossWithoutReg Std             52.3344
trainer/PolicyLossWithoutReg Max            236.379
trainer/PolicyLossWithoutReg Min              3.57185
exploration/num steps total              121000
exploration/num paths total                 828
exploration/path length this epoch Mean     936
exploration/path length this epoch Std        0
exploration/path length this epoch Max      936
exploration/path length this epoch Min      936
exploration/Rewards Mean                      3.2622
exploration/Rewards Std                       0.889933
exploration/Rewards Max                       6.01591
exploration/Rewards Min                      -0.892491
exploration/Returns Mean                   3053.42
exploration/Returns Std                       0
exploration/Returns Max                    3053.42
exploration/Returns Min                    3053.42
exploration/Num Paths                         1
exploration/Average Returns                3053.42
evaluation_0/num steps total             908069
evaluation_0/num paths total               4161
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.36922
evaluation_0/Rewards Std                      0.791307
evaluation_0/Rewards Max                      6.23899
evaluation_0/Rewards Min                     -0.549289
evaluation_0/Returns Mean                  3369.22
evaluation_0/Returns Std                     50.4155
evaluation_0/Returns Max                   3443.9
evaluation_0/Returns Min                   3299.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3369.22
time/epoch (s)                                0
time/total (s)                             1569.03
Epoch                                       116
---------------------------------------  ---------------
2022-11-16 16:41:06.399696 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 117 finished
---------------------------------------  ---------------
epoch                                       117
total_step                               122000
replay_pool/size                         122000
trainer/alpha                                 0.0556789
trainer/alpha_loss                            3.01555
trainer/entropy                              -7.04401
trainer/qf_loss                              10.0472
trainer/policy_loss                        -171.963
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         172.356
trainer/entropy_penalty                      -0.392203
trainer/entropy_percentage                   -0.00227554
trainer/Q1Pred Mean                         169.294
trainer/Q1Pred Std                           57.9986
trainer/Q1Pred Max                          228.2
trainer/Q1Pred Min                          -12.9504
trainer/Q2Pred Mean                         168.887
trainer/Q2Pred Std                           58.0391
trainer/Q2Pred Max                          230.839
trainer/Q2Pred Min                          -12.2346
trainer/QTargetWithReg Mean                 169.408
trainer/QTargetWithReg Std                   58.6149
trainer/QTargetWithReg Max                  229.107
trainer/QTargetWithReg Min                   -1.10209
trainer/PolicyLossWithoutReg Mean           172.356
trainer/PolicyLossWithoutReg Std             55.1749
trainer/PolicyLossWithoutReg Max            230.913
trainer/PolicyLossWithoutReg Min            -24.1154
exploration/num steps total              122000
exploration/num paths total                 829
exploration/path length this epoch Mean     830
exploration/path length this epoch Std        0
exploration/path length this epoch Max      830
exploration/path length this epoch Min      830
exploration/Rewards Mean                      3.38846
exploration/Rewards Std                       1.07703
exploration/Rewards Max                       7.18256
exploration/Rewards Min                      -0.45207
exploration/Returns Mean                   2812.42
exploration/Returns Std                       0
exploration/Returns Max                    2812.42
exploration/Returns Min                    2812.42
exploration/Num Paths                         1
exploration/Average Returns                2812.42
evaluation_0/num steps total             915822
evaluation_0/num paths total               4174
evaluation_0/path length Mean               596.385
evaluation_0/path length Std                187.655
evaluation_0/path length Max                891
evaluation_0/path length Min                281
evaluation_0/Rewards Mean                     3.63854
evaluation_0/Rewards Std                      1.09445
evaluation_0/Rewards Max                      9.70615
evaluation_0/Rewards Min                     -0.61506
evaluation_0/Returns Mean                  2169.97
evaluation_0/Returns Std                    703.664
evaluation_0/Returns Max                   3318.29
evaluation_0/Returns Min                    951.2
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2169.97
time/epoch (s)                                0
time/total (s)                             1583.55
Epoch                                       117
---------------------------------------  ---------------
2022-11-16 16:41:20.275674 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 118 finished
---------------------------------------  ---------------
epoch                                       118
total_step                               123000
replay_pool/size                         123000
trainer/alpha                                 0.0563492
trainer/alpha_loss                           -0.342171
trainer/entropy                              -5.88103
trainer/qf_loss                               9.15767
trainer/policy_loss                        -178.412
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         178.743
trainer/entropy_penalty                      -0.331391
trainer/entropy_percentage                   -0.00185401
trainer/Q1Pred Mean                         177.541
trainer/Q1Pred Std                           55.8037
trainer/Q1Pred Max                          232.344
trainer/Q1Pred Min                           -9.42919
trainer/Q2Pred Mean                         177.613
trainer/Q2Pred Std                           55.7086
trainer/Q2Pred Max                          232.257
trainer/Q2Pred Min                          -10.0149
trainer/QTargetWithReg Mean                 177.943
trainer/QTargetWithReg Std                   56.0235
trainer/QTargetWithReg Max                  234.214
trainer/QTargetWithReg Min                   -8.16772
trainer/PolicyLossWithoutReg Mean           178.743
trainer/PolicyLossWithoutReg Std             55.4846
trainer/PolicyLossWithoutReg Max            233.303
trainer/PolicyLossWithoutReg Min             -8.90953
exploration/num steps total              123000
exploration/num paths total                 830
exploration/path length this epoch Mean     629
exploration/path length this epoch Std        0
exploration/path length this epoch Max      629
exploration/path length this epoch Min      629
exploration/Rewards Mean                      3.00863
exploration/Rewards Std                       0.992217
exploration/Rewards Max                       5.95875
exploration/Rewards Min                      -0.395834
exploration/Returns Mean                   1892.43
exploration/Returns Std                       0
exploration/Returns Max                    1892.43
exploration/Returns Min                    1892.43
exploration/Num Paths                         1
exploration/Average Returns                1892.43
evaluation_0/num steps total             923314
evaluation_0/num paths total               4183
evaluation_0/path length Mean               832.444
evaluation_0/path length Std                242.678
evaluation_0/path length Max               1000
evaluation_0/path length Min                389
evaluation_0/Rewards Mean                     3.53722
evaluation_0/Rewards Std                      0.905582
evaluation_0/Rewards Max                      8.27064
evaluation_0/Rewards Min                     -0.508465
evaluation_0/Returns Mean                  2944.54
evaluation_0/Returns Std                    849.056
evaluation_0/Returns Max                   3558.31
evaluation_0/Returns Min                   1408.42
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2944.54
time/epoch (s)                                0
time/total (s)                             1597.43
Epoch                                       118
---------------------------------------  ---------------
2022-11-16 16:41:32.801163 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 119 finished
---------------------------------------  ---------------
epoch                                       119
total_step                               124000
replay_pool/size                         124000
trainer/alpha                                 0.0555285
trainer/alpha_loss                            1.38829
trainer/entropy                              -6.48025
trainer/qf_loss                              12.0041
trainer/policy_loss                        -174.115
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         174.475
trainer/entropy_penalty                      -0.359838
trainer/entropy_percentage                   -0.00206241
trainer/Q1Pred Mean                         172.707
trainer/Q1Pred Std                           61.2047
trainer/Q1Pred Max                          245.308
trainer/Q1Pred Min                          -14.0911
trainer/Q2Pred Mean                         172.101
trainer/Q2Pred Std                           60.8943
trainer/Q2Pred Max                          243.635
trainer/Q2Pred Min                           -3.26959
trainer/QTargetWithReg Mean                 172.043
trainer/QTargetWithReg Std                   60.7563
trainer/QTargetWithReg Max                  242.368
trainer/QTargetWithReg Min                   -3.79386
trainer/PolicyLossWithoutReg Mean           174.475
trainer/PolicyLossWithoutReg Std             58.9202
trainer/PolicyLossWithoutReg Max            242.862
trainer/PolicyLossWithoutReg Min             -2.71746
exploration/num steps total              124000
exploration/num paths total                 833
exploration/path length this epoch Mean     307.333
exploration/path length this epoch Std      135.441
exploration/path length this epoch Max      487
exploration/path length this epoch Min      160
exploration/Rewards Mean                      3.07143
exploration/Rewards Std                       1.3231
exploration/Rewards Max                       9.63753
exploration/Rewards Min                      -0.658161
exploration/Returns Mean                    943.953
exploration/Returns Std                     489.442
exploration/Returns Max                    1591.35
exploration/Returns Min                     408.143
exploration/Num Paths                         3
exploration/Average Returns                 943.953
evaluation_0/num steps total             931314
evaluation_0/num paths total               4191
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.1644
evaluation_0/Rewards Std                      0.736864
evaluation_0/Rewards Max                      4.84269
evaluation_0/Rewards Min                     -0.721195
evaluation_0/Returns Mean                  3164.4
evaluation_0/Returns Std                     42.4046
evaluation_0/Returns Max                   3233.31
evaluation_0/Returns Min                   3119.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3164.4
time/epoch (s)                                0
time/total (s)                             1609.95
Epoch                                       119
---------------------------------------  ---------------
2022-11-16 16:41:45.660165 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 120 finished
---------------------------------------  ---------------
epoch                                       120
total_step                               125000
replay_pool/size                         125000
trainer/alpha                                 0.0558355
trainer/alpha_loss                           -1.6769
trainer/entropy                              -5.41879
trainer/qf_loss                              11.7628
trainer/policy_loss                        -181.571
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         181.873
trainer/entropy_penalty                      -0.302561
trainer/entropy_percentage                   -0.00166358
trainer/Q1Pred Mean                         180.199
trainer/Q1Pred Std                           48.4851
trainer/Q1Pred Max                          235.11
trainer/Q1Pred Min                           11.3419
trainer/Q2Pred Mean                         179.738
trainer/Q2Pred Std                           48.5954
trainer/Q2Pred Max                          237.428
trainer/Q2Pred Min                            8.00919
trainer/QTargetWithReg Mean                 179.863
trainer/QTargetWithReg Std                   48.9683
trainer/QTargetWithReg Max                  236.132
trainer/QTargetWithReg Min                    6.71659
trainer/PolicyLossWithoutReg Mean           181.873
trainer/PolicyLossWithoutReg Std             47.1386
trainer/PolicyLossWithoutReg Max            235.026
trainer/PolicyLossWithoutReg Min             10.3439
exploration/num steps total              125000
exploration/num paths total                 834
exploration/path length this epoch Mean     707
exploration/path length this epoch Std        0
exploration/path length this epoch Max      707
exploration/path length this epoch Min      707
exploration/Rewards Mean                      3.32929
exploration/Rewards Std                       0.982351
exploration/Rewards Max                       5.27014
exploration/Rewards Min                      -0.620186
exploration/Returns Mean                   2353.81
exploration/Returns Std                       0
exploration/Returns Max                    2353.81
exploration/Returns Min                    2353.81
exploration/Num Paths                         1
exploration/Average Returns                2353.81
evaluation_0/num steps total             939314
evaluation_0/num paths total               4199
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.08573
evaluation_0/Rewards Std                      0.791903
evaluation_0/Rewards Max                      4.97186
evaluation_0/Rewards Min                     -0.594004
evaluation_0/Returns Mean                  3085.73
evaluation_0/Returns Std                     65.224
evaluation_0/Returns Max                   3164.62
evaluation_0/Returns Min                   2940.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3085.73
time/epoch (s)                                0
time/total (s)                             1622.81
Epoch                                       120
---------------------------------------  ---------------
2022-11-16 16:41:59.497489 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 121 finished
---------------------------------------  ---------------
epoch                                       121
total_step                               126000
replay_pool/size                         126000
trainer/alpha                                 0.0573506
trainer/alpha_loss                            0.226123
trainer/entropy                              -6.0791
trainer/qf_loss                              12.6533
trainer/policy_loss                        -178.186
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         178.535
trainer/entropy_penalty                      -0.34864
trainer/entropy_percentage                   -0.00195279
trainer/Q1Pred Mean                         176.397
trainer/Q1Pred Std                           55.5687
trainer/Q1Pred Max                          235.336
trainer/Q1Pred Min                           -5.21887
trainer/Q2Pred Mean                         176.583
trainer/Q2Pred Std                           55.883
trainer/Q2Pred Max                          235.872
trainer/Q2Pred Min                          -14.4714
trainer/QTargetWithReg Mean                 176.859
trainer/QTargetWithReg Std                   56.2904
trainer/QTargetWithReg Max                  236.971
trainer/QTargetWithReg Min                   -0.285756
trainer/PolicyLossWithoutReg Mean           178.535
trainer/PolicyLossWithoutReg Std             53.4833
trainer/PolicyLossWithoutReg Max            235.682
trainer/PolicyLossWithoutReg Min              3.8586
exploration/num steps total              126000
exploration/num paths total                 835
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.17244
exploration/Rewards Std                       0.91736
exploration/Rewards Max                       6.05306
exploration/Rewards Min                      -0.686325
exploration/Returns Mean                   3172.44
exploration/Returns Std                       0
exploration/Returns Max                    3172.44
exploration/Returns Min                    3172.44
exploration/Num Paths                         1
exploration/Average Returns                3172.44
evaluation_0/num steps total             947261
evaluation_0/num paths total               4207
evaluation_0/path length Mean               993.375
evaluation_0/path length Std                 17.5281
evaluation_0/path length Max               1000
evaluation_0/path length Min                947
evaluation_0/Rewards Mean                     3.1245
evaluation_0/Rewards Std                      0.754528
evaluation_0/Rewards Max                      7.32803
evaluation_0/Rewards Min                     -0.79116
evaluation_0/Returns Mean                  3103.8
evaluation_0/Returns Std                    115.177
evaluation_0/Returns Max                   3360.01
evaluation_0/Returns Min                   2997.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3103.8
time/epoch (s)                                0
time/total (s)                             1636.65
Epoch                                       121
---------------------------------------  ---------------
2022-11-16 16:42:12.096332 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 122 finished
---------------------------------------  ---------------
epoch                                       122
total_step                               127000
replay_pool/size                         127000
trainer/alpha                                 0.0570857
trainer/alpha_loss                            0.343544
trainer/entropy                              -6.11998
trainer/qf_loss                               7.98588
trainer/policy_loss                        -178.831
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         179.18
trainer/entropy_penalty                      -0.349363
trainer/entropy_percentage                   -0.00194979
trainer/Q1Pred Mean                         177.464
trainer/Q1Pred Std                           57.7787
trainer/Q1Pred Max                          239.889
trainer/Q1Pred Min                           -0.511032
trainer/Q2Pred Mean                         177.286
trainer/Q2Pred Std                           57.687
trainer/Q2Pred Max                          242.261
trainer/Q2Pred Min                           -9.56199
trainer/QTargetWithReg Mean                 177.471
trainer/QTargetWithReg Std                   57.3961
trainer/QTargetWithReg Max                  240.702
trainer/QTargetWithReg Min                    0.307718
trainer/PolicyLossWithoutReg Mean           179.18
trainer/PolicyLossWithoutReg Std             55.5535
trainer/PolicyLossWithoutReg Max            240.756
trainer/PolicyLossWithoutReg Min              7.36574
exploration/num steps total              127000
exploration/num paths total                 836
exploration/path length this epoch Mean     931
exploration/path length this epoch Std        0
exploration/path length this epoch Max      931
exploration/path length this epoch Min      931
exploration/Rewards Mean                      3.20998
exploration/Rewards Std                       1.14328
exploration/Rewards Max                       6.75814
exploration/Rewards Min                      -0.842355
exploration/Returns Mean                   2988.5
exploration/Returns Std                       0
exploration/Returns Max                    2988.5
exploration/Returns Min                    2988.5
exploration/Num Paths                         1
exploration/Average Returns                2988.5
evaluation_0/num steps total             955261
evaluation_0/num paths total               4215
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.97138
evaluation_0/Rewards Std                      0.743085
evaluation_0/Rewards Max                      4.74442
evaluation_0/Rewards Min                     -0.693908
evaluation_0/Returns Mean                  2971.38
evaluation_0/Returns Std                     20.1146
evaluation_0/Returns Max                   3011.73
evaluation_0/Returns Min                   2946.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2971.38
time/epoch (s)                                0
time/total (s)                             1649.25
Epoch                                       122
---------------------------------------  ---------------
2022-11-16 16:42:24.942921 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 123 finished
---------------------------------------  ---------------
epoch                                       123
total_step                               128000
replay_pool/size                         128000
trainer/alpha                                 0.0568841
trainer/alpha_loss                            1.03155
trainer/entropy                              -6.35982
trainer/qf_loss                              12.2954
trainer/policy_loss                        -189.892
trainer/adversary_policy_loss                 8.87341
trainer/policy_loss_without_entropy         190.254
trainer/entropy_penalty                      -0.361773
trainer/entropy_percentage                   -0.00190153
trainer/Q1Pred Mean                         189.316
trainer/Q1Pred Std                           45.4051
trainer/Q1Pred Max                          254.969
trainer/Q1Pred Min                            4.10777
trainer/Q2Pred Mean                         189.386
trainer/Q2Pred Std                           45.2287
trainer/Q2Pred Max                          255.251
trainer/Q2Pred Min                            3.79531
trainer/QTargetWithReg Mean                 189.543
trainer/QTargetWithReg Std                   45.3086
trainer/QTargetWithReg Max                  254.584
trainer/QTargetWithReg Min                    4.07771
trainer/PolicyLossWithoutReg Mean           190.254
trainer/PolicyLossWithoutReg Std             44.7198
trainer/PolicyLossWithoutReg Max            254.81
trainer/PolicyLossWithoutReg Min              6.15292
exploration/num steps total              128000
exploration/num paths total                 839
exploration/path length this epoch Mean     285
exploration/path length this epoch Std      250.656
exploration/path length this epoch Max      628
exploration/path length this epoch Min       36
exploration/Rewards Mean                      2.90223
exploration/Rewards Std                       1.24477
exploration/Rewards Max                       8.3714
exploration/Rewards Min                      -0.638172
exploration/Returns Mean                    827.135
exploration/Returns Std                     782.672
exploration/Returns Max                    1892.8
exploration/Returns Min                      35.2077
exploration/Num Paths                         3
exploration/Average Returns                 827.135
evaluation_0/num steps total             963261
evaluation_0/num paths total               4223
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.38519
evaluation_0/Rewards Std                      0.77634
evaluation_0/Rewards Max                      5.468
evaluation_0/Rewards Min                     -0.83609
evaluation_0/Returns Mean                  3385.19
evaluation_0/Returns Std                     59.8427
evaluation_0/Returns Max                   3479.96
evaluation_0/Returns Min                   3290.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3385.19
time/epoch (s)                                0
time/total (s)                             1662.1
Epoch                                       123
---------------------------------------  ---------------
2022-11-16 16:42:38.843835 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 124 finished
---------------------------------------  ---------------
epoch                                       124
total_step                               129000
replay_pool/size                         129000
trainer/alpha                                 0.0574972
trainer/alpha_loss                           -0.661127
trainer/entropy                              -5.7685
trainer/qf_loss                              10.9251
trainer/policy_loss                        -185.832
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         186.163
trainer/entropy_penalty                      -0.331673
trainer/entropy_percentage                   -0.00178162
trainer/Q1Pred Mean                         184.04
trainer/Q1Pred Std                           54.8293
trainer/Q1Pred Max                          242.536
trainer/Q1Pred Min                           -9.16756
trainer/Q2Pred Mean                         184.238
trainer/Q2Pred Std                           54.7567
trainer/Q2Pred Max                          243.501
trainer/Q2Pred Min                           -5.58495
trainer/QTargetWithReg Mean                 183.89
trainer/QTargetWithReg Std                   54.7462
trainer/QTargetWithReg Max                  241.712
trainer/QTargetWithReg Min                    3.309
trainer/PolicyLossWithoutReg Mean           186.163
trainer/PolicyLossWithoutReg Std             52.6681
trainer/PolicyLossWithoutReg Max            243.694
trainer/PolicyLossWithoutReg Min             10.3672
exploration/num steps total              129000
exploration/num paths total                 840
exploration/path length this epoch Mean     854
exploration/path length this epoch Std        0
exploration/path length this epoch Max      854
exploration/path length this epoch Min      854
exploration/Rewards Mean                      3.21582
exploration/Rewards Std                       0.881417
exploration/Rewards Max                       5.86781
exploration/Rewards Min                      -0.846002
exploration/Returns Mean                   2746.31
exploration/Returns Std                       0
exploration/Returns Max                    2746.31
exploration/Returns Min                    2746.31
exploration/Num Paths                         1
exploration/Average Returns                2746.31
evaluation_0/num steps total             970952
evaluation_0/num paths total               4233
evaluation_0/path length Mean               769.1
evaluation_0/path length Std                352.75
evaluation_0/path length Max               1000
evaluation_0/path length Min                217
evaluation_0/Rewards Mean                     2.5716
evaluation_0/Rewards Std                      0.892987
evaluation_0/Rewards Max                      5.39908
evaluation_0/Rewards Min                     -1.7766
evaluation_0/Returns Mean                  1977.82
evaluation_0/Returns Std                    947.218
evaluation_0/Returns Max                   2944.45
evaluation_0/Returns Min                    514.299
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               1977.82
time/epoch (s)                                0
time/total (s)                             1676
Epoch                                       124
---------------------------------------  ---------------
2022-11-16 16:42:51.693854 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 125 finished
---------------------------------------  ---------------
epoch                                       125
total_step                               130000
replay_pool/size                         130000
trainer/alpha                                 0.0577855
trainer/alpha_loss                           -0.938723
trainer/entropy                              -5.67074
trainer/qf_loss                              10.5102
trainer/policy_loss                        -185.6
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         185.928
trainer/entropy_penalty                      -0.327686
trainer/entropy_percentage                   -0.00176244
trainer/Q1Pred Mean                         185.022
trainer/Q1Pred Std                           52.9728
trainer/Q1Pred Max                          245.515
trainer/Q1Pred Min                            3.47471
trainer/Q2Pred Mean                         184.802
trainer/Q2Pred Std                           53.0264
trainer/Q2Pred Max                          246.104
trainer/Q2Pred Min                            4.26721
trainer/QTargetWithReg Mean                 184.395
trainer/QTargetWithReg Std                   53.6619
trainer/QTargetWithReg Max                  245.42
trainer/QTargetWithReg Min                   -0.638679
trainer/PolicyLossWithoutReg Mean           185.928
trainer/PolicyLossWithoutReg Std             51.6579
trainer/PolicyLossWithoutReg Max            246.706
trainer/PolicyLossWithoutReg Min              3.55204
exploration/num steps total              130000
exploration/num paths total                 841
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.75835
exploration/Rewards Std                       0.795825
exploration/Rewards Max                       4.90012
exploration/Rewards Min                      -0.86177
exploration/Returns Mean                   2758.35
exploration/Returns Std                       0
exploration/Returns Max                    2758.35
exploration/Returns Min                    2758.35
exploration/Num Paths                         1
exploration/Average Returns                2758.35
evaluation_0/num steps total             978952
evaluation_0/num paths total               4241
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.69956
evaluation_0/Rewards Std                      0.909408
evaluation_0/Rewards Max                      5.03852
evaluation_0/Rewards Min                     -1.6544
evaluation_0/Returns Mean                  2699.56
evaluation_0/Returns Std                    282.21
evaluation_0/Returns Max                   3128.96
evaluation_0/Returns Min                   2142.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2699.56
time/epoch (s)                                0
time/total (s)                             1688.85
Epoch                                       125
---------------------------------------  ---------------
2022-11-16 16:43:05.849565 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 126 finished
---------------------------------------  ---------------
epoch                                       126
total_step                               131000
replay_pool/size                         131000
trainer/alpha                                 0.0578365
trainer/alpha_loss                            1.17403
trainer/entropy                              -6.41193
trainer/qf_loss                              12.355
trainer/policy_loss                        -190.449
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         190.82
trainer/entropy_penalty                      -0.370844
trainer/entropy_percentage                   -0.00194342
trainer/Q1Pred Mean                         187.895
trainer/Q1Pred Std                           50.6918
trainer/Q1Pred Max                          242.858
trainer/Q1Pred Min                           -5.33081
trainer/Q2Pred Mean                         187.867
trainer/Q2Pred Std                           51.015
trainer/Q2Pred Max                          241.793
trainer/Q2Pred Min                           -8.07168
trainer/QTargetWithReg Mean                 187.867
trainer/QTargetWithReg Std                   51.187
trainer/QTargetWithReg Max                  243.26
trainer/QTargetWithReg Min                   -4.65894
trainer/PolicyLossWithoutReg Mean           190.82
trainer/PolicyLossWithoutReg Std             47.8067
trainer/PolicyLossWithoutReg Max            242.971
trainer/PolicyLossWithoutReg Min             -1.46096
exploration/num steps total              131000
exploration/num paths total                 842
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.47868
exploration/Rewards Std                       0.87491
exploration/Rewards Max                       4.86656
exploration/Rewards Min                      -0.567454
exploration/Returns Mean                   2478.68
exploration/Returns Std                       0
exploration/Returns Max                    2478.68
exploration/Returns Min                    2478.68
exploration/Num Paths                         1
exploration/Average Returns                2478.68
evaluation_0/num steps total             986888
evaluation_0/num paths total               4250
evaluation_0/path length Mean               881.778
evaluation_0/path length Std                221.936
evaluation_0/path length Max               1000
evaluation_0/path length Min                429
evaluation_0/Rewards Mean                     2.63293
evaluation_0/Rewards Std                      0.93557
evaluation_0/Rewards Max                      8.73895
evaluation_0/Rewards Min                     -0.517976
evaluation_0/Returns Mean                  2321.66
evaluation_0/Returns Std                    610.733
evaluation_0/Returns Max                   2916.48
evaluation_0/Returns Min                   1209.52
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2321.66
time/epoch (s)                                0
time/total (s)                             1703
Epoch                                       126
---------------------------------------  ---------------
2022-11-16 16:43:18.186908 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 127 finished
---------------------------------------  ---------------
epoch                                       127
total_step                               132000
replay_pool/size                         132000
trainer/alpha                                 0.057417
trainer/alpha_loss                           -0.317958
trainer/entropy                              -5.88873
trainer/qf_loss                               9.8391
trainer/policy_loss                        -185.541
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         185.879
trainer/entropy_penalty                      -0.338113
trainer/entropy_percentage                   -0.00181899
trainer/Q1Pred Mean                         183.217
trainer/Q1Pred Std                           59.2032
trainer/Q1Pred Max                          243.992
trainer/Q1Pred Min                          -15.8176
trainer/Q2Pred Mean                         183.248
trainer/Q2Pred Std                           58.8434
trainer/Q2Pred Max                          245.334
trainer/Q2Pred Min                           -0.272371
trainer/QTargetWithReg Mean                 183.272
trainer/QTargetWithReg Std                   58.9606
trainer/QTargetWithReg Max                  249.161
trainer/QTargetWithReg Min                   -0.236336
trainer/PolicyLossWithoutReg Mean           185.879
trainer/PolicyLossWithoutReg Std             56.1972
trainer/PolicyLossWithoutReg Max            244.609
trainer/PolicyLossWithoutReg Min             19.1568
exploration/num steps total              132000
exploration/num paths total                 843
exploration/path length this epoch Mean     389
exploration/path length this epoch Std        0
exploration/path length this epoch Max      389
exploration/path length this epoch Min      389
exploration/Rewards Mean                      2.80567
exploration/Rewards Std                       1.32703
exploration/Rewards Max                       5.82173
exploration/Rewards Min                      -0.406553
exploration/Returns Mean                   1091.4
exploration/Returns Std                       0
exploration/Returns Max                    1091.4
exploration/Returns Min                    1091.4
exploration/Num Paths                         1
exploration/Average Returns                1091.4
evaluation_0/num steps total             994888
evaluation_0/num paths total               4258
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.32159
evaluation_0/Rewards Std                      0.856306
evaluation_0/Rewards Max                      5.62768
evaluation_0/Rewards Min                     -0.631283
evaluation_0/Returns Mean                  3321.59
evaluation_0/Returns Std                    285.416
evaluation_0/Returns Max                   3710.09
evaluation_0/Returns Min                   2776.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3321.59
time/epoch (s)                                0
time/total (s)                             1715.34
Epoch                                       127
---------------------------------------  ---------------
2022-11-16 16:43:31.307058 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 128 finished
---------------------------------------  ----------------
epoch                                       128
total_step                               133000
replay_pool/size                         133000
trainer/alpha                                 0.0574555
trainer/alpha_loss                           -0.032606
trainer/entropy                              -5.98859
trainer/qf_loss                               9.77577
trainer/policy_loss                        -188.603
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         188.947
trainer/entropy_penalty                      -0.344077
trainer/entropy_percentage                   -0.00182103
trainer/Q1Pred Mean                         187.125
trainer/Q1Pred Std                           53.5373
trainer/Q1Pred Max                          250.222
trainer/Q1Pred Min                            2.90644
trainer/Q2Pred Mean                         187.435
trainer/Q2Pred Std                           53.3916
trainer/Q2Pred Max                          248.404
trainer/Q2Pred Min                            4.19481
trainer/QTargetWithReg Mean                 187.091
trainer/QTargetWithReg Std                   53.5938
trainer/QTargetWithReg Max                  249.979
trainer/QTargetWithReg Min                   -2.59774
trainer/PolicyLossWithoutReg Mean           188.947
trainer/PolicyLossWithoutReg Std             52.5367
trainer/PolicyLossWithoutReg Max            252.679
trainer/PolicyLossWithoutReg Min              7.55808
exploration/num steps total              133000
exploration/num paths total                 844
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.66892
exploration/Rewards Std                       1.07018
exploration/Rewards Max                       5.62847
exploration/Rewards Min                      -0.734253
exploration/Returns Mean                   2668.92
exploration/Returns Std                       0
exploration/Returns Max                    2668.92
exploration/Returns Min                    2668.92
exploration/Num Paths                         1
exploration/Average Returns                2668.92
evaluation_0/num steps total                  1.00289e+06
evaluation_0/num paths total               4266
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.12722
evaluation_0/Rewards Std                      0.850397
evaluation_0/Rewards Max                      4.89373
evaluation_0/Rewards Min                     -0.95694
evaluation_0/Returns Mean                  3127.22
evaluation_0/Returns Std                    119.794
evaluation_0/Returns Max                   3274.7
evaluation_0/Returns Min                   2870.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3127.22
time/epoch (s)                                0
time/total (s)                             1728.46
Epoch                                       128
---------------------------------------  ----------------
2022-11-16 16:43:43.717349 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 129 finished
---------------------------------------  ----------------
epoch                                       129
total_step                               134000
replay_pool/size                         134000
trainer/alpha                                 0.055855
trainer/alpha_loss                            0.137583
trainer/entropy                              -6.04769
trainer/qf_loss                              11.3612
trainer/policy_loss                        -191.682
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         192.02
trainer/entropy_penalty                      -0.337793
trainer/entropy_percentage                   -0.00175916
trainer/Q1Pred Mean                         191.214
trainer/Q1Pred Std                           52.8383
trainer/Q1Pred Max                          244.647
trainer/Q1Pred Min                            1.74981
trainer/Q2Pred Mean                         191.304
trainer/Q2Pred Std                           52.9374
trainer/Q2Pred Max                          246.238
trainer/Q2Pred Min                           -4.15729
trainer/QTargetWithReg Mean                 190.613
trainer/QTargetWithReg Std                   52.8816
trainer/QTargetWithReg Max                  244.197
trainer/QTargetWithReg Min                    2.3182
trainer/PolicyLossWithoutReg Mean           192.02
trainer/PolicyLossWithoutReg Std             52.2618
trainer/PolicyLossWithoutReg Max            244.798
trainer/PolicyLossWithoutReg Min             -3.10521
exploration/num steps total              134000
exploration/num paths total                 845
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.6073
exploration/Rewards Std                       1.04311
exploration/Rewards Max                       4.9498
exploration/Rewards Min                      -1.27442
exploration/Returns Mean                   2607.3
exploration/Returns Std                       0
exploration/Returns Max                    2607.3
exploration/Returns Min                    2607.3
exploration/Num Paths                         1
exploration/Average Returns                2607.3
evaluation_0/num steps total                  1.01089e+06
evaluation_0/num paths total               4274
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.189
evaluation_0/Rewards Std                      0.889689
evaluation_0/Rewards Max                      5.14377
evaluation_0/Rewards Min                     -0.676889
evaluation_0/Returns Mean                  3189
evaluation_0/Returns Std                    151.917
evaluation_0/Returns Max                   3432.79
evaluation_0/Returns Min                   2989.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3189
time/epoch (s)                                0
time/total (s)                             1740.87
Epoch                                       129
---------------------------------------  ----------------
2022-11-16 16:43:57.577670 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 130 finished
---------------------------------------  ----------------
epoch                                       130
total_step                               135000
replay_pool/size                         135000
trainer/alpha                                 0.0562352
trainer/alpha_loss                            0.068471
trainer/entropy                              -6.02379
trainer/qf_loss                               9.95192
trainer/policy_loss                        -189.829
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         190.167
trainer/entropy_penalty                      -0.338749
trainer/entropy_percentage                   -0.00178132
trainer/Q1Pred Mean                         188.387
trainer/Q1Pred Std                           52.5014
trainer/Q1Pred Max                          244.175
trainer/Q1Pred Min                            4.70292
trainer/Q2Pred Mean                         189.001
trainer/Q2Pred Std                           52.5565
trainer/Q2Pred Max                          245.173
trainer/Q2Pred Min                            4.37362
trainer/QTargetWithReg Mean                 189.772
trainer/QTargetWithReg Std                   52.5285
trainer/QTargetWithReg Max                  245.929
trainer/QTargetWithReg Min                    4.43293
trainer/PolicyLossWithoutReg Mean           190.167
trainer/PolicyLossWithoutReg Std             51.6408
trainer/PolicyLossWithoutReg Max            246.161
trainer/PolicyLossWithoutReg Min              5.24301
exploration/num steps total              135000
exploration/num paths total                 846
exploration/path length this epoch Mean     384
exploration/path length this epoch Std        0
exploration/path length this epoch Max      384
exploration/path length this epoch Min      384
exploration/Rewards Mean                      3.22523
exploration/Rewards Std                       1.19903
exploration/Rewards Max                       6.85792
exploration/Rewards Min                      -0.695655
exploration/Returns Mean                   1238.49
exploration/Returns Std                       0
exploration/Returns Max                    1238.49
exploration/Returns Min                    1238.49
exploration/Num Paths                         1
exploration/Average Returns                1238.49
evaluation_0/num steps total                  1.01848e+06
evaluation_0/num paths total               4282
evaluation_0/path length Mean               948.5
evaluation_0/path length Std                136.256
evaluation_0/path length Max               1000
evaluation_0/path length Min                588
evaluation_0/Rewards Mean                     3.76512
evaluation_0/Rewards Std                      0.816022
evaluation_0/Rewards Max                      8.36285
evaluation_0/Rewards Min                     -0.593566
evaluation_0/Returns Mean                  3571.21
evaluation_0/Returns Std                    492.917
evaluation_0/Returns Max                   3808.92
evaluation_0/Returns Min                   2274.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3571.21
time/epoch (s)                                0
time/total (s)                             1754.73
Epoch                                       130
---------------------------------------  ----------------
2022-11-16 16:44:10.850625 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 131 finished
---------------------------------------  ----------------
epoch                                       131
total_step                               136000
replay_pool/size                         136000
trainer/alpha                                 0.0547517
trainer/alpha_loss                            0.302066
trainer/entropy                              -6.10399
trainer/qf_loss                               9.21422
trainer/policy_loss                        -193.908
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         194.242
trainer/entropy_penalty                      -0.334204
trainer/entropy_percentage                   -0.00172055
trainer/Q1Pred Mean                         192.111
trainer/Q1Pred Std                           52.5702
trainer/Q1Pred Max                          248.706
trainer/Q1Pred Min                            4.44846
trainer/Q2Pred Mean                         191.981
trainer/Q2Pred Std                           52.3694
trainer/Q2Pred Max                          246.085
trainer/Q2Pred Min                            5.45094
trainer/QTargetWithReg Mean                 192.796
trainer/QTargetWithReg Std                   52.8844
trainer/QTargetWithReg Max                  249.187
trainer/QTargetWithReg Min                   -0.98634
trainer/PolicyLossWithoutReg Mean           194.242
trainer/PolicyLossWithoutReg Std             51.1368
trainer/PolicyLossWithoutReg Max            249.719
trainer/PolicyLossWithoutReg Min              3.98458
exploration/num steps total              136000
exploration/num paths total                 847
exploration/path length this epoch Mean     656
exploration/path length this epoch Std        0
exploration/path length this epoch Max      656
exploration/path length this epoch Min      656
exploration/Rewards Mean                      3.29882
exploration/Rewards Std                       1.25013
exploration/Rewards Max                       7.15767
exploration/Rewards Min                      -0.651833
exploration/Returns Mean                   2164.03
exploration/Returns Std                       0
exploration/Returns Max                    2164.03
exploration/Returns Min                    2164.03
exploration/Num Paths                         1
exploration/Average Returns                2164.03
evaluation_0/num steps total                  1.02648e+06
evaluation_0/num paths total               4290
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.46108
evaluation_0/Rewards Std                      0.855642
evaluation_0/Rewards Max                      4.87578
evaluation_0/Rewards Min                     -0.667953
evaluation_0/Returns Mean                  3461.08
evaluation_0/Returns Std                    100.392
evaluation_0/Returns Max                   3611.21
evaluation_0/Returns Min                   3296.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3461.08
time/epoch (s)                                0
time/total (s)                             1768
Epoch                                       131
---------------------------------------  ----------------
2022-11-16 16:44:23.219621 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 132 finished
---------------------------------------  ----------------
epoch                                       132
total_step                               137000
replay_pool/size                         137000
trainer/alpha                                 0.0551278
trainer/alpha_loss                           -0.757429
trainer/entropy                              -5.73865
trainer/qf_loss                              11.4824
trainer/policy_loss                        -189.196
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         189.513
trainer/entropy_penalty                      -0.316359
trainer/entropy_percentage                   -0.00166933
trainer/Q1Pred Mean                         187.586
trainer/Q1Pred Std                           61.5253
trainer/Q1Pred Max                          249.839
trainer/Q1Pred Min                           -3.53055
trainer/Q2Pred Mean                         187.367
trainer/Q2Pred Std                           61.5436
trainer/Q2Pred Max                          249.649
trainer/Q2Pred Min                            1.88266
trainer/QTargetWithReg Mean                 187.672
trainer/QTargetWithReg Std                   61.7583
trainer/QTargetWithReg Max                  248.117
trainer/QTargetWithReg Min                   -0.303584
trainer/PolicyLossWithoutReg Mean           189.513
trainer/PolicyLossWithoutReg Std             60.0295
trainer/PolicyLossWithoutReg Max            250.949
trainer/PolicyLossWithoutReg Min              4.86711
exploration/num steps total              137000
exploration/num paths total                 848
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.35608
exploration/Rewards Std                       0.886085
exploration/Rewards Max                       6.53413
exploration/Rewards Min                      -0.47118
exploration/Returns Mean                   3356.08
exploration/Returns Std                       0
exploration/Returns Max                    3356.08
exploration/Returns Min                    3356.08
exploration/Num Paths                         1
exploration/Average Returns                3356.08
evaluation_0/num steps total                  1.03448e+06
evaluation_0/num paths total               4298
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.48654
evaluation_0/Rewards Std                      0.791984
evaluation_0/Rewards Max                      4.93215
evaluation_0/Rewards Min                     -0.713692
evaluation_0/Returns Mean                  3486.54
evaluation_0/Returns Std                     31.8231
evaluation_0/Returns Max                   3552.67
evaluation_0/Returns Min                   3444.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3486.54
time/epoch (s)                                0
time/total (s)                             1780.37
Epoch                                       132
---------------------------------------  ----------------
2022-11-16 16:44:35.524620 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 133 finished
---------------------------------------  ----------------
epoch                                       133
total_step                               138000
replay_pool/size                         138000
trainer/alpha                                 0.0534442
trainer/alpha_loss                           -0.405577
trainer/entropy                              -5.86153
trainer/qf_loss                               9.8041
trainer/policy_loss                        -192.176
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         192.489
trainer/entropy_penalty                      -0.313265
trainer/entropy_percentage                   -0.00162744
trainer/Q1Pred Mean                         191.767
trainer/Q1Pred Std                           55.4644
trainer/Q1Pred Max                          247.414
trainer/Q1Pred Min                           -0.0801888
trainer/Q2Pred Mean                         191.104
trainer/Q2Pred Std                           55.5388
trainer/Q2Pred Max                          247.118
trainer/Q2Pred Min                           -0.430063
trainer/QTargetWithReg Mean                 191.447
trainer/QTargetWithReg Std                   55.5204
trainer/QTargetWithReg Max                  248.364
trainer/QTargetWithReg Min                    0.674597
trainer/PolicyLossWithoutReg Mean           192.489
trainer/PolicyLossWithoutReg Std             54.7898
trainer/PolicyLossWithoutReg Max            247.414
trainer/PolicyLossWithoutReg Min             -0.476157
exploration/num steps total              138000
exploration/num paths total                 849
exploration/path length this epoch Mean     833
exploration/path length this epoch Std        0
exploration/path length this epoch Max      833
exploration/path length this epoch Min      833
exploration/Rewards Mean                      3.26596
exploration/Rewards Std                       1.10162
exploration/Rewards Max                       6.56833
exploration/Rewards Min                      -0.649688
exploration/Returns Mean                   2720.54
exploration/Returns Std                       0
exploration/Returns Max                    2720.54
exploration/Returns Min                    2720.54
exploration/Num Paths                         1
exploration/Average Returns                2720.54
evaluation_0/num steps total                  1.04248e+06
evaluation_0/num paths total               4306
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.31332
evaluation_0/Rewards Std                      1.01361
evaluation_0/Rewards Max                      5.51234
evaluation_0/Rewards Min                     -0.787834
evaluation_0/Returns Mean                  3313.32
evaluation_0/Returns Std                    149.797
evaluation_0/Returns Max                   3531.89
evaluation_0/Returns Min                   3086.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3313.32
time/epoch (s)                                0
time/total (s)                             1792.67
Epoch                                       133
---------------------------------------  ----------------
2022-11-16 16:44:50.223291 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 134 finished
---------------------------------------  ----------------
epoch                                       134
total_step                               139000
replay_pool/size                         139000
trainer/alpha                                 0.0553887
trainer/alpha_loss                           -0.43528
trainer/entropy                              -5.84955
trainer/qf_loss                              11.1387
trainer/policy_loss                        -187.962
trainer/adversary_policy_loss                 8.91383
trainer/policy_loss_without_entropy         188.286
trainer/entropy_penalty                      -0.323999
trainer/entropy_percentage                   -0.00172078
trainer/Q1Pred Mean                         187.248
trainer/Q1Pred Std                           56.4954
trainer/Q1Pred Max                          249.194
trainer/Q1Pred Min                           -4.41897
trainer/Q2Pred Mean                         187.126
trainer/Q2Pred Std                           56.3909
trainer/Q2Pred Max                          251.114
trainer/Q2Pred Min                           -2.13634
trainer/QTargetWithReg Mean                 187.562
trainer/QTargetWithReg Std                   56.418
trainer/QTargetWithReg Max                  250.897
trainer/QTargetWithReg Min                    2.84889
trainer/PolicyLossWithoutReg Mean           188.286
trainer/PolicyLossWithoutReg Std             55.8119
trainer/PolicyLossWithoutReg Max            249.907
trainer/PolicyLossWithoutReg Min              1.00346
exploration/num steps total              139000
exploration/num paths total                 850
exploration/path length this epoch Mean     870
exploration/path length this epoch Std        0
exploration/path length this epoch Max      870
exploration/path length this epoch Min      870
exploration/Rewards Mean                      3.30488
exploration/Rewards Std                       1.18916
exploration/Rewards Max                       7.34258
exploration/Rewards Min                      -0.847454
exploration/Returns Mean                   2875.25
exploration/Returns Std                       0
exploration/Returns Max                    2875.25
exploration/Returns Min                    2875.25
exploration/Num Paths                         1
exploration/Average Returns                2875.25
evaluation_0/num steps total                  1.05046e+06
evaluation_0/num paths total               4314
evaluation_0/path length Mean               997.5
evaluation_0/path length Std                  6.61438
evaluation_0/path length Max               1000
evaluation_0/path length Min                980
evaluation_0/Rewards Mean                     3.84597
evaluation_0/Rewards Std                      0.943609
evaluation_0/Rewards Max                      9.42318
evaluation_0/Rewards Min                     -0.918444
evaluation_0/Returns Mean                  3836.36
evaluation_0/Returns Std                     48.3369
evaluation_0/Returns Max                   3910.34
evaluation_0/Returns Min                   3780.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3836.36
time/epoch (s)                                0
time/total (s)                             1807.37
Epoch                                       134
---------------------------------------  ----------------
2022-11-16 16:45:04.098092 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 135 finished
---------------------------------------  ----------------
epoch                                       135
total_step                               140000
replay_pool/size                         140000
trainer/alpha                                 0.0553808
trainer/alpha_loss                            0.807384
trainer/entropy                              -6.27903
trainer/qf_loss                              12.5869
trainer/policy_loss                        -197.662
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         198.01
trainer/entropy_penalty                      -0.347738
trainer/entropy_percentage                   -0.00175617
trainer/Q1Pred Mean                         196.127
trainer/Q1Pred Std                           53.3291
trainer/Q1Pred Max                          255.462
trainer/Q1Pred Min                          -21.8055
trainer/Q2Pred Mean                         196.605
trainer/Q2Pred Std                           52.3043
trainer/Q2Pred Max                          256.617
trainer/Q2Pred Min                          -10.5555
trainer/QTargetWithReg Mean                 196.486
trainer/QTargetWithReg Std                   52.5004
trainer/QTargetWithReg Max                  252.906
trainer/QTargetWithReg Min                   -0.946737
trainer/PolicyLossWithoutReg Mean           198.01
trainer/PolicyLossWithoutReg Std             50.5116
trainer/PolicyLossWithoutReg Max            255.662
trainer/PolicyLossWithoutReg Min              4.65238
exploration/num steps total              140000
exploration/num paths total                 851
exploration/path length this epoch Mean     481
exploration/path length this epoch Std        0
exploration/path length this epoch Max      481
exploration/path length this epoch Min      481
exploration/Rewards Mean                      3.44144
exploration/Rewards Std                       1.15606
exploration/Rewards Max                       7.89696
exploration/Rewards Min                      -0.890699
exploration/Returns Mean                   1655.33
exploration/Returns Std                       0
exploration/Returns Max                    1655.33
exploration/Returns Min                    1655.33
exploration/Num Paths                         1
exploration/Average Returns                1655.33
evaluation_0/num steps total                  1.05766e+06
evaluation_0/num paths total               4322
evaluation_0/path length Mean               900.5
evaluation_0/path length Std                263.252
evaluation_0/path length Max               1000
evaluation_0/path length Min                204
evaluation_0/Rewards Mean                     3.37295
evaluation_0/Rewards Std                      0.903384
evaluation_0/Rewards Max                      5.59109
evaluation_0/Rewards Min                     -0.687824
evaluation_0/Returns Mean                  3037.34
evaluation_0/Returns Std                    945.273
evaluation_0/Returns Max                   3598.24
evaluation_0/Returns Min                    553.313
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3037.34
time/epoch (s)                                0
time/total (s)                             1821.25
Epoch                                       135
---------------------------------------  ----------------
2022-11-16 16:45:20.226956 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 136 finished
---------------------------------------  ----------------
epoch                                       136
total_step                               141000
replay_pool/size                         141000
trainer/alpha                                 0.0544851
trainer/alpha_loss                            1.12576
trainer/entropy                              -6.38688
trainer/qf_loss                               9.45895
trainer/policy_loss                        -190.924
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         191.272
trainer/entropy_penalty                      -0.34799
trainer/entropy_percentage                   -0.00181934
trainer/Q1Pred Mean                         189.54
trainer/Q1Pred Std                           58.9488
trainer/Q1Pred Max                          253.565
trainer/Q1Pred Min                           -3.26337
trainer/Q2Pred Mean                         189.418
trainer/Q2Pred Std                           58.7269
trainer/Q2Pred Max                          254.272
trainer/Q2Pred Min                           -3.0906
trainer/QTargetWithReg Mean                 189.593
trainer/QTargetWithReg Std                   59.5134
trainer/QTargetWithReg Max                  253.17
trainer/QTargetWithReg Min                   -0.469087
trainer/PolicyLossWithoutReg Mean           191.272
trainer/PolicyLossWithoutReg Std             57.324
trainer/PolicyLossWithoutReg Max            253.512
trainer/PolicyLossWithoutReg Min              2.54117
exploration/num steps total              141000
exploration/num paths total                 852
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.40092
exploration/Rewards Std                       0.817272
exploration/Rewards Max                       5.62393
exploration/Rewards Min                      -0.809416
exploration/Returns Mean                   3400.92
exploration/Returns Std                       0
exploration/Returns Max                    3400.92
exploration/Returns Min                    3400.92
exploration/Num Paths                         1
exploration/Average Returns                3400.92
evaluation_0/num steps total                  1.06546e+06
evaluation_0/num paths total               4339
evaluation_0/path length Mean               459
evaluation_0/path length Std                351.83
evaluation_0/path length Max               1000
evaluation_0/path length Min                152
evaluation_0/Rewards Mean                     3.12184
evaluation_0/Rewards Std                      1.14209
evaluation_0/Rewards Max                      8.99471
evaluation_0/Rewards Min                     -0.640708
evaluation_0/Returns Mean                  1432.92
evaluation_0/Returns Std                   1215.4
evaluation_0/Returns Max                   3413.28
evaluation_0/Returns Min                    350.07
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1432.92
time/epoch (s)                                0
time/total (s)                             1837.38
Epoch                                       136
---------------------------------------  ----------------
2022-11-16 16:45:34.267949 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 137 finished
---------------------------------------  ---------------
epoch                                       137
total_step                               142000
replay_pool/size                         142000
trainer/alpha                                 0.054371
trainer/alpha_loss                           -1.00862
trainer/entropy                              -5.65362
trainer/qf_loss                              11.6488
trainer/policy_loss                        -197.288
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         197.596
trainer/entropy_penalty                      -0.307393
trainer/entropy_percentage                   -0.00155567
trainer/Q1Pred Mean                         195.426
trainer/Q1Pred Std                           53.6718
trainer/Q1Pred Max                          255.366
trainer/Q1Pred Min                            1.4281
trainer/Q2Pred Mean                         195.48
trainer/Q2Pred Std                           53.8942
trainer/Q2Pred Max                          257.217
trainer/Q2Pred Min                           -1.1429
trainer/QTargetWithReg Mean                 196.467
trainer/QTargetWithReg Std                   54.0647
trainer/QTargetWithReg Max                  256.135
trainer/QTargetWithReg Min                    0.0689679
trainer/PolicyLossWithoutReg Mean           197.596
trainer/PolicyLossWithoutReg Std             51.2129
trainer/PolicyLossWithoutReg Max            255.573
trainer/PolicyLossWithoutReg Min             14.4926
exploration/num steps total              142000
exploration/num paths total                 853
exploration/path length this epoch Mean     836
exploration/path length this epoch Std        0
exploration/path length this epoch Max      836
exploration/path length this epoch Min      836
exploration/Rewards Mean                      3.07181
exploration/Rewards Std                       0.86673
exploration/Rewards Max                       5.1169
exploration/Rewards Min                      -0.609472
exploration/Returns Mean                   2568.04
exploration/Returns Std                       0
exploration/Returns Max                    2568.04
exploration/Returns Min                    2568.04
exploration/Num Paths                         1
exploration/Average Returns                2568.04
evaluation_0/num steps total                  1.0733e+06
evaluation_0/num paths total               4347
evaluation_0/path length Mean               979.875
evaluation_0/path length Std                 53.2457
evaluation_0/path length Max               1000
evaluation_0/path length Min                839
evaluation_0/Rewards Mean                     3.54914
evaluation_0/Rewards Std                      0.899663
evaluation_0/Rewards Max                      6.72882
evaluation_0/Rewards Min                     -0.847559
evaluation_0/Returns Mean                  3477.71
evaluation_0/Returns Std                    174.49
evaluation_0/Returns Max                   3573.59
evaluation_0/Returns Min                   3022.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3477.71
time/epoch (s)                                0
time/total (s)                             1851.42
Epoch                                       137
---------------------------------------  ---------------
2022-11-16 16:45:48.206224 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 138 finished
---------------------------------------  ----------------
epoch                                       138
total_step                               143000
replay_pool/size                         143000
trainer/alpha                                 0.0550918
trainer/alpha_loss                            0.653525
trainer/entropy                              -6.22544
trainer/qf_loss                              10.5578
trainer/policy_loss                        -200.169
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         200.511
trainer/entropy_penalty                      -0.342971
trainer/entropy_percentage                   -0.00171048
trainer/Q1Pred Mean                         198.881
trainer/Q1Pred Std                           52.2468
trainer/Q1Pred Max                          257.093
trainer/Q1Pred Min                           16.0933
trainer/Q2Pred Mean                         198.974
trainer/Q2Pred Std                           52.2313
trainer/Q2Pred Max                          258.942
trainer/Q2Pred Min                            6.23701
trainer/QTargetWithReg Mean                 198.009
trainer/QTargetWithReg Std                   52.121
trainer/QTargetWithReg Max                  256.488
trainer/QTargetWithReg Min                   -0.0927605
trainer/PolicyLossWithoutReg Mean           200.511
trainer/PolicyLossWithoutReg Std             50.16
trainer/PolicyLossWithoutReg Max            256.535
trainer/PolicyLossWithoutReg Min             26.3775
exploration/num steps total              143000
exploration/num paths total                 854
exploration/path length this epoch Mean     431
exploration/path length this epoch Std        0
exploration/path length this epoch Max      431
exploration/path length this epoch Min      431
exploration/Rewards Mean                      3.13227
exploration/Rewards Std                       1.05923
exploration/Rewards Max                       4.99758
exploration/Rewards Min                      -0.810865
exploration/Returns Mean                   1350.01
exploration/Returns Std                       0
exploration/Returns Max                    1350.01
exploration/Returns Min                    1350.01
exploration/Num Paths                         1
exploration/Average Returns                1350.01
evaluation_0/num steps total                  1.08083e+06
evaluation_0/num paths total               4355
evaluation_0/path length Mean               940.875
evaluation_0/path length Std                156.43
evaluation_0/path length Max               1000
evaluation_0/path length Min                527
evaluation_0/Rewards Mean                     3.5551
evaluation_0/Rewards Std                      0.839594
evaluation_0/Rewards Max                      7.26093
evaluation_0/Rewards Min                     -0.786699
evaluation_0/Returns Mean                  3344.91
evaluation_0/Returns Std                    565.42
evaluation_0/Returns Max                   3579.32
evaluation_0/Returns Min                   1849.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3344.91
time/epoch (s)                                0
time/total (s)                             1865.35
Epoch                                       138
---------------------------------------  ----------------
2022-11-16 16:46:01.449659 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 139 finished
---------------------------------------  ----------------
epoch                                       139
total_step                               144000
replay_pool/size                         144000
trainer/alpha                                 0.0554456
trainer/alpha_loss                            0.553346
trainer/entropy                              -6.19132
trainer/qf_loss                              12.1213
trainer/policy_loss                        -193.279
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         193.623
trainer/entropy_penalty                      -0.343281
trainer/entropy_percentage                   -0.00177294
trainer/Q1Pred Mean                         191.603
trainer/Q1Pred Std                           57.7725
trainer/Q1Pred Max                          252.577
trainer/Q1Pred Min                          -16.6224
trainer/Q2Pred Mean                         191.324
trainer/Q2Pred Std                           57.352
trainer/Q2Pred Max                          250.959
trainer/Q2Pred Min                           -9.28371
trainer/QTargetWithReg Mean                 191.418
trainer/QTargetWithReg Std                   57.7059
trainer/QTargetWithReg Max                  252.06
trainer/QTargetWithReg Min                   -5.11402
trainer/PolicyLossWithoutReg Mean           193.623
trainer/PolicyLossWithoutReg Std             55.683
trainer/PolicyLossWithoutReg Max            252.219
trainer/PolicyLossWithoutReg Min             -1.4677
exploration/num steps total              144000
exploration/num paths total                 855
exploration/path length this epoch Mean     914
exploration/path length this epoch Std        0
exploration/path length this epoch Max      914
exploration/path length this epoch Min      914
exploration/Rewards Mean                      3.44799
exploration/Rewards Std                       0.979727
exploration/Rewards Max                       7.79756
exploration/Rewards Min                      -0.759469
exploration/Returns Mean                   3151.46
exploration/Returns Std                       0
exploration/Returns Max                    3151.46
exploration/Returns Min                    3151.46
exploration/Num Paths                         1
exploration/Average Returns                3151.46
evaluation_0/num steps total                  1.08883e+06
evaluation_0/num paths total               4363
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.47465
evaluation_0/Rewards Std                      0.874194
evaluation_0/Rewards Max                      5.03979
evaluation_0/Rewards Min                     -0.624789
evaluation_0/Returns Mean                  3474.65
evaluation_0/Returns Std                    140.731
evaluation_0/Returns Max                   3672.57
evaluation_0/Returns Min                   3238.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3474.65
time/epoch (s)                                0
time/total (s)                             1878.6
Epoch                                       139
---------------------------------------  ----------------
2022-11-16 16:46:13.840938 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 140 finished
---------------------------------------  ----------------
epoch                                       140
total_step                               145000
replay_pool/size                         145000
trainer/alpha                                 0.0548625
trainer/alpha_loss                            0.166149
trainer/entropy                              -6.05723
trainer/qf_loss                              12.4132
trainer/policy_loss                        -197.904
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         198.237
trainer/entropy_penalty                      -0.332315
trainer/entropy_percentage                   -0.00167636
trainer/Q1Pred Mean                         197.486
trainer/Q1Pred Std                           53.604
trainer/Q1Pred Max                          257.982
trainer/Q1Pred Min                            0.0584753
trainer/Q2Pred Mean                         197.749
trainer/Q2Pred Std                           53.4301
trainer/Q2Pred Max                          259.697
trainer/Q2Pred Min                           -0.181775
trainer/QTargetWithReg Mean                 197.125
trainer/QTargetWithReg Std                   53.7649
trainer/QTargetWithReg Max                  256.617
trainer/QTargetWithReg Min                   -3.39158
trainer/PolicyLossWithoutReg Mean           198.237
trainer/PolicyLossWithoutReg Std             52.7317
trainer/PolicyLossWithoutReg Max            256.602
trainer/PolicyLossWithoutReg Min             -0.370596
exploration/num steps total              145000
exploration/num paths total                 856
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.27359
exploration/Rewards Std                       0.877659
exploration/Rewards Max                       5.03126
exploration/Rewards Min                      -0.669336
exploration/Returns Mean                   3273.59
exploration/Returns Std                       0
exploration/Returns Max                    3273.59
exploration/Returns Min                    3273.59
exploration/Num Paths                         1
exploration/Average Returns                3273.59
evaluation_0/num steps total                  1.09683e+06
evaluation_0/num paths total               4371
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.37364
evaluation_0/Rewards Std                      0.798185
evaluation_0/Rewards Max                      4.98862
evaluation_0/Rewards Min                     -0.467897
evaluation_0/Returns Mean                  3373.64
evaluation_0/Returns Std                     63.822
evaluation_0/Returns Max                   3450
evaluation_0/Returns Min                   3267.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3373.64
time/epoch (s)                                0
time/total (s)                             1890.99
Epoch                                       140
---------------------------------------  ----------------
2022-11-16 16:46:27.886541 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 141 finished
---------------------------------------  ----------------
epoch                                       141
total_step                               146000
replay_pool/size                         146000
trainer/alpha                                 0.0547849
trainer/alpha_loss                            0.0850219
trainer/entropy                              -6.02927
trainer/qf_loss                               8.7736
trainer/policy_loss                        -199.587
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         199.917
trainer/entropy_penalty                      -0.330313
trainer/entropy_percentage                   -0.00165225
trainer/Q1Pred Mean                         197.854
trainer/Q1Pred Std                           56.2204
trainer/Q1Pred Max                          253.675
trainer/Q1Pred Min                           -5.96643
trainer/Q2Pred Mean                         198.323
trainer/Q2Pred Std                           56.2057
trainer/Q2Pred Max                          255.688
trainer/Q2Pred Min                           -2.43566
trainer/QTargetWithReg Mean                 198.429
trainer/QTargetWithReg Std                   56.2047
trainer/QTargetWithReg Max                  255.196
trainer/QTargetWithReg Min                   -0.136972
trainer/PolicyLossWithoutReg Mean           199.917
trainer/PolicyLossWithoutReg Std             54.6433
trainer/PolicyLossWithoutReg Max            253.905
trainer/PolicyLossWithoutReg Min              0.108479
exploration/num steps total              146000
exploration/num paths total                 858
exploration/path length this epoch Mean     477.5
exploration/path length this epoch Std      240.5
exploration/path length this epoch Max      718
exploration/path length this epoch Min      237
exploration/Rewards Mean                      3.05809
exploration/Rewards Std                       1.10628
exploration/Rewards Max                       7.25355
exploration/Rewards Min                      -0.545565
exploration/Returns Mean                   1460.24
exploration/Returns Std                     728.428
exploration/Returns Max                    2188.66
exploration/Returns Min                     731.808
exploration/Num Paths                         2
exploration/Average Returns                1460.24
evaluation_0/num steps total                  1.10394e+06
evaluation_0/num paths total               4380
evaluation_0/path length Mean               789.889
evaluation_0/path length Std                319.908
evaluation_0/path length Max               1000
evaluation_0/path length Min                190
evaluation_0/Rewards Mean                     2.91285
evaluation_0/Rewards Std                      0.905409
evaluation_0/Rewards Max                      6.14763
evaluation_0/Rewards Min                     -1.22993
evaluation_0/Returns Mean                  2300.82
evaluation_0/Returns Std                    970.818
evaluation_0/Returns Max                   3185.74
evaluation_0/Returns Min                    557.177
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2300.82
time/epoch (s)                                0
time/total (s)                             1905.03
Epoch                                       141
---------------------------------------  ----------------
2022-11-16 16:46:40.772274 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 142 finished
---------------------------------------  ----------------
epoch                                       142
total_step                               147000
replay_pool/size                         147000
trainer/alpha                                 0.0545374
trainer/alpha_loss                            0.348952
trainer/entropy                              -6.11996
trainer/qf_loss                               8.77344
trainer/policy_loss                        -205.161
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         205.495
trainer/entropy_penalty                      -0.333767
trainer/entropy_percentage                   -0.00162421
trainer/Q1Pred Mean                         204.114
trainer/Q1Pred Std                           50.2668
trainer/Q1Pred Max                          266.566
trainer/Q1Pred Min                           -1.88749
trainer/Q2Pred Mean                         203.605
trainer/Q2Pred Std                           50.068
trainer/Q2Pred Max                          264.694
trainer/Q2Pred Min                            4.42237
trainer/QTargetWithReg Mean                 203.79
trainer/QTargetWithReg Std                   50.265
trainer/QTargetWithReg Max                  263.961
trainer/QTargetWithReg Min                    0.545637
trainer/PolicyLossWithoutReg Mean           205.495
trainer/PolicyLossWithoutReg Std             48.0678
trainer/PolicyLossWithoutReg Max            265.608
trainer/PolicyLossWithoutReg Min              6.15836
exploration/num steps total              147000
exploration/num paths total                 859
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.32201
exploration/Rewards Std                       0.930289
exploration/Rewards Max                       5.74674
exploration/Rewards Min                      -0.719278
exploration/Returns Mean                   3322.01
exploration/Returns Std                       0
exploration/Returns Max                    3322.01
exploration/Returns Min                    3322.01
exploration/Num Paths                         1
exploration/Average Returns                3322.01
evaluation_0/num steps total                  1.11194e+06
evaluation_0/num paths total               4388
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.44701
evaluation_0/Rewards Std                      0.842039
evaluation_0/Rewards Max                      4.97341
evaluation_0/Rewards Min                     -0.38762
evaluation_0/Returns Mean                  3447.01
evaluation_0/Returns Std                     69.986
evaluation_0/Returns Max                   3529.2
evaluation_0/Returns Min                   3299.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3447.01
time/epoch (s)                                0
time/total (s)                             1917.92
Epoch                                       142
---------------------------------------  ----------------
2022-11-16 16:46:53.136559 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 143 finished
---------------------------------------  ----------------
epoch                                       143
total_step                               148000
replay_pool/size                         148000
trainer/alpha                                 0.0550484
trainer/alpha_loss                            0.917651
trainer/entropy                              -6.31645
trainer/qf_loss                              13.2837
trainer/policy_loss                        -196.317
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         196.664
trainer/entropy_penalty                      -0.347711
trainer/entropy_percentage                   -0.00176804
trainer/Q1Pred Mean                         194.279
trainer/Q1Pred Std                           57.3363
trainer/Q1Pred Max                          255.052
trainer/Q1Pred Min                           -5.12367
trainer/Q2Pred Mean                         194.424
trainer/Q2Pred Std                           56.4609
trainer/Q2Pred Max                          255.497
trainer/Q2Pred Min                            7.41274
trainer/QTargetWithReg Mean                 193.82
trainer/QTargetWithReg Std                   56.9164
trainer/QTargetWithReg Max                  254.329
trainer/QTargetWithReg Min                   -0.56777
trainer/PolicyLossWithoutReg Mean           196.664
trainer/PolicyLossWithoutReg Std             53.4929
trainer/PolicyLossWithoutReg Max            254.75
trainer/PolicyLossWithoutReg Min              6.62455
exploration/num steps total              148000
exploration/num paths total                 860
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.19198
exploration/Rewards Std                       0.914319
exploration/Rewards Max                       5.1696
exploration/Rewards Min                      -0.326428
exploration/Returns Mean                   3191.98
exploration/Returns Std                       0
exploration/Returns Max                    3191.98
exploration/Returns Min                    3191.98
exploration/Num Paths                         1
exploration/Average Returns                3191.98
evaluation_0/num steps total                  1.11994e+06
evaluation_0/num paths total               4396
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.12253
evaluation_0/Rewards Std                      0.876615
evaluation_0/Rewards Max                      5.29227
evaluation_0/Rewards Min                     -0.514273
evaluation_0/Returns Mean                  3122.53
evaluation_0/Returns Std                    143.663
evaluation_0/Returns Max                   3367.82
evaluation_0/Returns Min                   2861.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3122.53
time/epoch (s)                                0
time/total (s)                             1930.28
Epoch                                       143
---------------------------------------  ----------------
2022-11-16 16:47:05.560150 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 144 finished
---------------------------------------  ----------------
epoch                                       144
total_step                               149000
replay_pool/size                         149000
trainer/alpha                                 0.0538868
trainer/alpha_loss                           -1.10992
trainer/entropy                              -5.62
trainer/qf_loss                              12.3894
trainer/policy_loss                        -205.325
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         205.628
trainer/entropy_penalty                      -0.302844
trainer/entropy_percentage                   -0.00147278
trainer/Q1Pred Mean                         204.309
trainer/Q1Pred Std                           46.872
trainer/Q1Pred Max                          250.856
trainer/Q1Pred Min                           -9.76742
trainer/Q2Pred Mean                         204.331
trainer/Q2Pred Std                           46.5743
trainer/Q2Pred Max                          252.361
trainer/Q2Pred Min                            1.42399
trainer/QTargetWithReg Mean                 204.514
trainer/QTargetWithReg Std                   46.6699
trainer/QTargetWithReg Max                  253.263
trainer/QTargetWithReg Min                   -0.729221
trainer/PolicyLossWithoutReg Mean           205.628
trainer/PolicyLossWithoutReg Std             45.221
trainer/PolicyLossWithoutReg Max            251.2
trainer/PolicyLossWithoutReg Min              3.56489
exploration/num steps total              149000
exploration/num paths total                 861
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.33657
exploration/Rewards Std                       0.885561
exploration/Rewards Max                       5.74039
exploration/Rewards Min                      -0.523326
exploration/Returns Mean                   3336.57
exploration/Returns Std                       0
exploration/Returns Max                    3336.57
exploration/Returns Min                    3336.57
exploration/Num Paths                         1
exploration/Average Returns                3336.57
evaluation_0/num steps total                  1.12794e+06
evaluation_0/num paths total               4404
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.28041
evaluation_0/Rewards Std                      0.799371
evaluation_0/Rewards Max                      4.91796
evaluation_0/Rewards Min                     -0.737184
evaluation_0/Returns Mean                  3280.41
evaluation_0/Returns Std                     56.6153
evaluation_0/Returns Max                   3366.21
evaluation_0/Returns Min                   3201.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3280.41
time/epoch (s)                                0
time/total (s)                             1942.71
Epoch                                       144
---------------------------------------  ----------------
2022-11-16 16:47:18.531616 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 145 finished
---------------------------------------  ----------------
epoch                                       145
total_step                               150000
replay_pool/size                         150000
trainer/alpha                                 0.0538322
trainer/alpha_loss                            1.55444
trainer/entropy                              -6.53195
trainer/qf_loss                              13.7104
trainer/policy_loss                        -201.831
trainer/adversary_policy_loss                 9.40776
trainer/policy_loss_without_entropy         202.182
trainer/entropy_penalty                      -0.35163
trainer/entropy_percentage                   -0.00173917
trainer/Q1Pred Mean                         199.564
trainer/Q1Pred Std                           54.1708
trainer/Q1Pred Max                          255.756
trainer/Q1Pred Min                           -0.607986
trainer/Q2Pred Mean                         199.882
trainer/Q2Pred Std                           54.1584
trainer/Q2Pred Max                          256.625
trainer/Q2Pred Min                           11.6219
trainer/QTargetWithReg Mean                 200.522
trainer/QTargetWithReg Std                   54.4509
trainer/QTargetWithReg Max                  260.922
trainer/QTargetWithReg Min                   -0.244027
trainer/PolicyLossWithoutReg Mean           202.182
trainer/PolicyLossWithoutReg Std             51.7131
trainer/PolicyLossWithoutReg Max            255.669
trainer/PolicyLossWithoutReg Min             14.892
exploration/num steps total              150000
exploration/num paths total                 862
exploration/path length this epoch Mean      87
exploration/path length this epoch Std        0
exploration/path length this epoch Max       87
exploration/path length this epoch Min       87
exploration/Rewards Mean                      2.67094
exploration/Rewards Std                       1.59211
exploration/Rewards Max                       5.42942
exploration/Rewards Min                      -0.429511
exploration/Returns Mean                    232.372
exploration/Returns Std                       0
exploration/Returns Max                     232.372
exploration/Returns Min                     232.372
exploration/Num Paths                         1
exploration/Average Returns                 232.372
evaluation_0/num steps total                  1.13594e+06
evaluation_0/num paths total               4412
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.906
evaluation_0/Rewards Std                      0.901061
evaluation_0/Rewards Max                      5.9098
evaluation_0/Rewards Min                     -0.655292
evaluation_0/Returns Mean                  2906
evaluation_0/Returns Std                    180.947
evaluation_0/Returns Max                   3178.38
evaluation_0/Returns Min                   2627.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2906
time/epoch (s)                                0
time/total (s)                             1955.68
Epoch                                       145
---------------------------------------  ----------------
2022-11-16 16:47:32.436313 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 146 finished
---------------------------------------  ----------------
epoch                                       146
total_step                               151000
replay_pool/size                         151000
trainer/alpha                                 0.053588
trainer/alpha_loss                            0.0563468
trainer/entropy                              -6.01926
trainer/qf_loss                               8.7899
trainer/policy_loss                        -203.949
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         204.272
trainer/entropy_penalty                      -0.32256
trainer/entropy_percentage                   -0.00157907
trainer/Q1Pred Mean                         203.754
trainer/Q1Pred Std                           56.4548
trainer/Q1Pred Max                          259.415
trainer/Q1Pred Min                           11.3799
trainer/Q2Pred Mean                         202.831
trainer/Q2Pred Std                           56.4557
trainer/Q2Pred Max                          259.299
trainer/Q2Pred Min                            8.97794
trainer/QTargetWithReg Mean                 202.996
trainer/QTargetWithReg Std                   56.1943
trainer/QTargetWithReg Max                  257.222
trainer/QTargetWithReg Min                   11.1173
trainer/PolicyLossWithoutReg Mean           204.272
trainer/PolicyLossWithoutReg Std             55.936
trainer/PolicyLossWithoutReg Max            257.431
trainer/PolicyLossWithoutReg Min             12.5756
exploration/num steps total              151000
exploration/num paths total                 863
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.2884
exploration/Rewards Std                       0.927529
exploration/Rewards Max                       5.78515
exploration/Rewards Min                      -0.532553
exploration/Returns Mean                   3288.4
exploration/Returns Std                       0
exploration/Returns Max                    3288.4
exploration/Returns Min                    3288.4
exploration/Num Paths                         1
exploration/Average Returns                3288.4
evaluation_0/num steps total                  1.14368e+06
evaluation_0/num paths total               4420
evaluation_0/path length Mean               968
evaluation_0/path length Std                 84.664
evaluation_0/path length Max               1000
evaluation_0/path length Min                744
evaluation_0/Rewards Mean                     3.03266
evaluation_0/Rewards Std                      0.866177
evaluation_0/Rewards Max                      6.04514
evaluation_0/Rewards Min                     -0.622358
evaluation_0/Returns Mean                  2935.62
evaluation_0/Returns Std                    217.242
evaluation_0/Returns Max                   3220.61
evaluation_0/Returns Min                   2406.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2935.62
time/epoch (s)                                0
time/total (s)                             1969.58
Epoch                                       146
---------------------------------------  ----------------
2022-11-16 16:47:46.639703 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 147 finished
---------------------------------------  ----------------
epoch                                       147
total_step                               152000
replay_pool/size                         152000
trainer/alpha                                 0.0550338
trainer/alpha_loss                           -0.570358
trainer/entropy                              -5.80329
trainer/qf_loss                              11.6532
trainer/policy_loss                        -198.428
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         198.747
trainer/entropy_penalty                      -0.319378
trainer/entropy_percentage                   -0.00160695
trainer/Q1Pred Mean                         197.391
trainer/Q1Pred Std                           58.8612
trainer/Q1Pred Max                          261.699
trainer/Q1Pred Min                            7.05855
trainer/Q2Pred Mean                         198.187
trainer/Q2Pred Std                           59.1389
trainer/Q2Pred Max                          262.557
trainer/Q2Pred Min                           -5.31749
trainer/QTargetWithReg Mean                 197.235
trainer/QTargetWithReg Std                   59.3765
trainer/QTargetWithReg Max                  260.764
trainer/QTargetWithReg Min                   -0.853362
trainer/PolicyLossWithoutReg Mean           198.747
trainer/PolicyLossWithoutReg Std             57.5288
trainer/PolicyLossWithoutReg Max            260.728
trainer/PolicyLossWithoutReg Min              6.56628
exploration/num steps total              152000
exploration/num paths total                 864
exploration/path length this epoch Mean     622
exploration/path length this epoch Std        0
exploration/path length this epoch Max      622
exploration/path length this epoch Min      622
exploration/Rewards Mean                      3.50801
exploration/Rewards Std                       1.0523
exploration/Rewards Max                       5.95775
exploration/Rewards Min                      -0.569939
exploration/Returns Mean                   2181.98
exploration/Returns Std                       0
exploration/Returns Max                    2181.98
exploration/Returns Min                    2181.98
exploration/Num Paths                         1
exploration/Average Returns                2181.98
evaluation_0/num steps total                  1.15135e+06
evaluation_0/num paths total               4430
evaluation_0/path length Mean               766.9
evaluation_0/path length Std                315.225
evaluation_0/path length Max               1000
evaluation_0/path length Min                182
evaluation_0/Rewards Mean                     3.83438
evaluation_0/Rewards Std                      1.02474
evaluation_0/Rewards Max                     10.999
evaluation_0/Rewards Min                     -0.59546
evaluation_0/Returns Mean                  2940.59
evaluation_0/Returns Std                   1262.78
evaluation_0/Returns Max                   3905.49
evaluation_0/Returns Min                    560.063
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2940.59
time/epoch (s)                                0
time/total (s)                             1983.78
Epoch                                       147
---------------------------------------  ----------------
2022-11-16 16:47:59.397050 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 148 finished
---------------------------------------  ----------------
epoch                                       148
total_step                               153000
replay_pool/size                         153000
trainer/alpha                                 0.0548895
trainer/alpha_loss                            2.13506
trainer/entropy                              -6.73559
trainer/qf_loss                              11.1619
trainer/policy_loss                        -203.37
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         203.74
trainer/entropy_penalty                      -0.369713
trainer/entropy_percentage                   -0.00181463
trainer/Q1Pred Mean                         203.177
trainer/Q1Pred Std                           52.0806
trainer/Q1Pred Max                          259.593
trainer/Q1Pred Min                            0.122836
trainer/Q2Pred Mean                         203.037
trainer/Q2Pred Std                           51.9742
trainer/Q2Pred Max                          254.9
trainer/Q2Pred Min                           -0.50507
trainer/QTargetWithReg Mean                 203.109
trainer/QTargetWithReg Std                   52.0965
trainer/QTargetWithReg Max                  255.518
trainer/QTargetWithReg Min                    2.80846
trainer/PolicyLossWithoutReg Mean           203.74
trainer/PolicyLossWithoutReg Std             51.0183
trainer/PolicyLossWithoutReg Max            257.361
trainer/PolicyLossWithoutReg Min              2.08418
exploration/num steps total              153000
exploration/num paths total                 866
exploration/path length this epoch Mean     468
exploration/path length this epoch Std      187
exploration/path length this epoch Max      655
exploration/path length this epoch Min      281
exploration/Rewards Mean                      3.27586
exploration/Rewards Std                       1.18899
exploration/Rewards Max                       8.85359
exploration/Rewards Min                      -0.698051
exploration/Returns Mean                   1533.1
exploration/Returns Std                     756.207
exploration/Returns Max                    2289.31
exploration/Returns Min                     776.894
exploration/Num Paths                         2
exploration/Average Returns                1533.1
evaluation_0/num steps total                  1.15935e+06
evaluation_0/num paths total               4438
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.54082
evaluation_0/Rewards Std                      0.869494
evaluation_0/Rewards Max                      5.10851
evaluation_0/Rewards Min                     -0.545393
evaluation_0/Returns Mean                  3540.82
evaluation_0/Returns Std                     78.6677
evaluation_0/Returns Max                   3652.31
evaluation_0/Returns Min                   3380.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3540.82
time/epoch (s)                                0
time/total (s)                             1996.54
Epoch                                       148
---------------------------------------  ----------------
2022-11-16 16:48:11.717912 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 149 finished
---------------------------------------  ----------------
epoch                                       149
total_step                               154000
replay_pool/size                         154000
trainer/alpha                                 0.0558401
trainer/alpha_loss                           -2.51837
trainer/entropy                              -5.12715
trainer/qf_loss                              11.302
trainer/policy_loss                        -209.661
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         209.947
trainer/entropy_penalty                      -0.286301
trainer/entropy_percentage                   -0.00136368
trainer/Q1Pred Mean                         208.239
trainer/Q1Pred Std                           48.7453
trainer/Q1Pred Max                          256.259
trainer/Q1Pred Min                           12.9122
trainer/Q2Pred Mean                         208.387
trainer/Q2Pred Std                           48.8222
trainer/Q2Pred Max                          257.96
trainer/Q2Pred Min                           13.8613
trainer/QTargetWithReg Mean                 207.975
trainer/QTargetWithReg Std                   49.1618
trainer/QTargetWithReg Max                  256.967
trainer/QTargetWithReg Min                   14.1054
trainer/PolicyLossWithoutReg Mean           209.947
trainer/PolicyLossWithoutReg Std             46.8607
trainer/PolicyLossWithoutReg Max            256.456
trainer/PolicyLossWithoutReg Min             15.6096
exploration/num steps total              154000
exploration/num paths total                 867
exploration/path length this epoch Mean     381
exploration/path length this epoch Std        0
exploration/path length this epoch Max      381
exploration/path length this epoch Min      381
exploration/Rewards Mean                      3.03038
exploration/Rewards Std                       1.02585
exploration/Rewards Max                       5.26681
exploration/Rewards Min                      -0.863263
exploration/Returns Mean                   1154.58
exploration/Returns Std                       0
exploration/Returns Max                    1154.58
exploration/Returns Min                    1154.58
exploration/Num Paths                         1
exploration/Average Returns                1154.58
evaluation_0/num steps total                  1.16735e+06
evaluation_0/num paths total               4446
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.28943
evaluation_0/Rewards Std                      0.847328
evaluation_0/Rewards Max                      4.95288
evaluation_0/Rewards Min                     -0.605297
evaluation_0/Returns Mean                  3289.43
evaluation_0/Returns Std                    136.611
evaluation_0/Returns Max                   3526.61
evaluation_0/Returns Min                   3167.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3289.43
time/epoch (s)                                0
time/total (s)                             2008.86
Epoch                                       149
---------------------------------------  ----------------
2022-11-16 16:48:26.371316 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 150 finished
---------------------------------------  ----------------
epoch                                       150
total_step                               155000
replay_pool/size                         155000
trainer/alpha                                 0.0548685
trainer/alpha_loss                           -1.21713
trainer/entropy                              -5.5807
trainer/qf_loss                              10.4548
trainer/policy_loss                        -206.666
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         206.972
trainer/entropy_penalty                      -0.306205
trainer/entropy_percentage                   -0.00147945
trainer/Q1Pred Mean                         205.811
trainer/Q1Pred Std                           49.4193
trainer/Q1Pred Max                          270.771
trainer/Q1Pred Min                           25.1469
trainer/Q2Pred Mean                         205.501
trainer/Q2Pred Std                           49.1812
trainer/Q2Pred Max                          267.954
trainer/Q2Pred Min                           26.1482
trainer/QTargetWithReg Mean                 205.828
trainer/QTargetWithReg Std                   49.1146
trainer/QTargetWithReg Max                  273.447
trainer/QTargetWithReg Min                   22.6266
trainer/PolicyLossWithoutReg Mean           206.972
trainer/PolicyLossWithoutReg Std             48.3875
trainer/PolicyLossWithoutReg Max            272.683
trainer/PolicyLossWithoutReg Min             24.498
exploration/num steps total              155000
exploration/num paths total                 868
exploration/path length this epoch Mean      11
exploration/path length this epoch Std        0
exploration/path length this epoch Max       11
exploration/path length this epoch Min       11
exploration/Rewards Mean                     -0.367675
exploration/Rewards Std                       0.382793
exploration/Rewards Max                       0.615702
exploration/Rewards Min                      -0.801314
exploration/Returns Mean                     -4.04442
exploration/Returns Std                       0
exploration/Returns Max                      -4.04442
exploration/Returns Min                      -4.04442
exploration/Num Paths                         1
exploration/Average Returns                  -4.04442
evaluation_0/num steps total                  1.17509e+06
evaluation_0/num paths total               4454
evaluation_0/path length Mean               967.25
evaluation_0/path length Std                 86.6484
evaluation_0/path length Max               1000
evaluation_0/path length Min                738
evaluation_0/Rewards Mean                     3.3459
evaluation_0/Rewards Std                      0.969494
evaluation_0/Rewards Max                      7.12822
evaluation_0/Rewards Min                     -0.664532
evaluation_0/Returns Mean                  3236.32
evaluation_0/Returns Std                    370.774
evaluation_0/Returns Max                   3604.71
evaluation_0/Returns Min                   2400.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3236.32
time/epoch (s)                                0
time/total (s)                             2023.51
Epoch                                       150
---------------------------------------  ----------------
2022-11-16 16:48:38.755690 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 151 finished
---------------------------------------  ----------------
epoch                                       151
total_step                               156000
replay_pool/size                         156000
trainer/alpha                                 0.0545696
trainer/alpha_loss                            0.210277
trainer/entropy                              -6.0723
trainer/qf_loss                              10.8666
trainer/policy_loss                        -205.627
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         205.958
trainer/entropy_penalty                      -0.331363
trainer/entropy_percentage                   -0.00160889
trainer/Q1Pred Mean                         203.524
trainer/Q1Pred Std                           54.9812
trainer/Q1Pred Max                          262.386
trainer/Q1Pred Min                            7.44695
trainer/Q2Pred Mean                         203.5
trainer/Q2Pred Std                           55.0067
trainer/Q2Pred Max                          265.558
trainer/Q2Pred Min                            3.39646
trainer/QTargetWithReg Mean                 203.927
trainer/QTargetWithReg Std                   55.1021
trainer/QTargetWithReg Max                  264.637
trainer/QTargetWithReg Min                    5.59633
trainer/PolicyLossWithoutReg Mean           205.958
trainer/PolicyLossWithoutReg Std             53.3
trainer/PolicyLossWithoutReg Max            263.26
trainer/PolicyLossWithoutReg Min              4.15427
exploration/num steps total              156000
exploration/num paths total                 869
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.41405
exploration/Rewards Std                       0.984816
exploration/Rewards Max                       6.13333
exploration/Rewards Min                      -0.626517
exploration/Returns Mean                   3414.05
exploration/Returns Std                       0
exploration/Returns Max                    3414.05
exploration/Returns Min                    3414.05
exploration/Num Paths                         1
exploration/Average Returns                3414.05
evaluation_0/num steps total                  1.18309e+06
evaluation_0/num paths total               4462
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.23876
evaluation_0/Rewards Std                      0.84104
evaluation_0/Rewards Max                      5.17575
evaluation_0/Rewards Min                     -0.638645
evaluation_0/Returns Mean                  3238.76
evaluation_0/Returns Std                     67.1852
evaluation_0/Returns Max                   3334.8
evaluation_0/Returns Min                   3121.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3238.76
time/epoch (s)                                0
time/total (s)                             2035.9
Epoch                                       151
---------------------------------------  ----------------
2022-11-16 16:48:52.620019 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 152 finished
---------------------------------------  ----------------
epoch                                       152
total_step                               157000
replay_pool/size                         157000
trainer/alpha                                 0.0547908
trainer/alpha_loss                           -0.551564
trainer/entropy                              -5.81007
trainer/qf_loss                               8.76099
trainer/policy_loss                        -199.505
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         199.823
trainer/entropy_penalty                      -0.318338
trainer/entropy_percentage                   -0.0015931
trainer/Q1Pred Mean                         198.732
trainer/Q1Pred Std                           62.9063
trainer/Q1Pred Max                          270.787
trainer/Q1Pred Min                           13.5711
trainer/Q2Pred Mean                         198.905
trainer/Q2Pred Std                           62.8849
trainer/Q2Pred Max                          271.753
trainer/Q2Pred Min                           11.5176
trainer/QTargetWithReg Mean                 198.536
trainer/QTargetWithReg Std                   62.8365
trainer/QTargetWithReg Max                  271.965
trainer/QTargetWithReg Min                    7.62733
trainer/PolicyLossWithoutReg Mean           199.823
trainer/PolicyLossWithoutReg Std             62.11
trainer/PolicyLossWithoutReg Max            270.176
trainer/PolicyLossWithoutReg Min             11.6836
exploration/num steps total              157000
exploration/num paths total                 870
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.86325
exploration/Rewards Std                       0.990934
exploration/Rewards Max                       5.38429
exploration/Rewards Min                      -0.990925
exploration/Returns Mean                   2863.25
exploration/Returns Std                       0
exploration/Returns Max                    2863.25
exploration/Returns Min                    2863.25
exploration/Num Paths                         1
exploration/Average Returns                2863.25
evaluation_0/num steps total                  1.19029e+06
evaluation_0/num paths total               4470
evaluation_0/path length Mean               899.75
evaluation_0/path length Std                265.237
evaluation_0/path length Max               1000
evaluation_0/path length Min                198
evaluation_0/Rewards Mean                     3.23582
evaluation_0/Rewards Std                      0.899134
evaluation_0/Rewards Max                      5.67399
evaluation_0/Rewards Min                     -0.603535
evaluation_0/Returns Mean                  2911.43
evaluation_0/Returns Std                    931.859
evaluation_0/Returns Max                   3490.4
evaluation_0/Returns Min                    474.965
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2911.43
time/epoch (s)                                0
time/total (s)                             2049.76
Epoch                                       152
---------------------------------------  ----------------
2022-11-16 16:49:07.346181 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 153 finished
---------------------------------------  ----------------
epoch                                       153
total_step                               158000
replay_pool/size                         158000
trainer/alpha                                 0.054319
trainer/alpha_loss                           -0.443831
trainer/entropy                              -5.84762
trainer/qf_loss                               9.18797
trainer/policy_loss                        -207.915
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         208.233
trainer/entropy_penalty                      -0.317637
trainer/entropy_percentage                   -0.00152539
trainer/Q1Pred Mean                         207.647
trainer/Q1Pred Std                           55.9979
trainer/Q1Pred Max                          267.214
trainer/Q1Pred Min                            2.15736
trainer/Q2Pred Mean                         206.898
trainer/Q2Pred Std                           55.8587
trainer/Q2Pred Max                          266.578
trainer/Q2Pred Min                            1.74038
trainer/QTargetWithReg Mean                 207.096
trainer/QTargetWithReg Std                   55.5787
trainer/QTargetWithReg Max                  269.33
trainer/QTargetWithReg Min                    3.59186
trainer/PolicyLossWithoutReg Mean           208.233
trainer/PolicyLossWithoutReg Std             55.5188
trainer/PolicyLossWithoutReg Max            267.101
trainer/PolicyLossWithoutReg Min              1.39451
exploration/num steps total              158000
exploration/num paths total                 871
exploration/path length this epoch Mean     729
exploration/path length this epoch Std        0
exploration/path length this epoch Max      729
exploration/path length this epoch Min      729
exploration/Rewards Mean                      3.227
exploration/Rewards Std                       0.933365
exploration/Rewards Max                       5.15575
exploration/Rewards Min                      -0.670592
exploration/Returns Mean                   2352.48
exploration/Returns Std                       0
exploration/Returns Max                    2352.48
exploration/Returns Min                    2352.48
exploration/Num Paths                         1
exploration/Average Returns                2352.48
evaluation_0/num steps total                  1.19801e+06
evaluation_0/num paths total               4479
evaluation_0/path length Mean               858.111
evaluation_0/path length Std                141.291
evaluation_0/path length Max               1000
evaluation_0/path length Min                680
evaluation_0/Rewards Mean                     3.21408
evaluation_0/Rewards Std                      1.02989
evaluation_0/Rewards Max                      5.59176
evaluation_0/Rewards Min                     -1.41271
evaluation_0/Returns Mean                  2758.03
evaluation_0/Returns Std                    466.588
evaluation_0/Returns Max                   3397.27
evaluation_0/Returns Min                   2148.3
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2758.03
time/epoch (s)                                0
time/total (s)                             2064.49
Epoch                                       153
---------------------------------------  ----------------
2022-11-16 16:49:21.268158 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 154 finished
---------------------------------------  ---------------
epoch                                       154
total_step                               159000
replay_pool/size                         159000
trainer/alpha                                 0.0547602
trainer/alpha_loss                            1.01305
trainer/entropy                              -6.34875
trainer/qf_loss                              13.7697
trainer/policy_loss                        -209.127
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         209.474
trainer/entropy_penalty                      -0.347659
trainer/entropy_percentage                   -0.00165967
trainer/Q1Pred Mean                         207.882
trainer/Q1Pred Std                           55.5731
trainer/Q1Pred Max                          278.361
trainer/Q1Pred Min                           -7.73821
trainer/Q2Pred Mean                         207.223
trainer/Q2Pred Std                           55.5405
trainer/Q2Pred Max                          274.385
trainer/Q2Pred Min                          -12.6546
trainer/QTargetWithReg Mean                 208.145
trainer/QTargetWithReg Std                   55.243
trainer/QTargetWithReg Max                  276.686
trainer/QTargetWithReg Min                   -2.85238
trainer/PolicyLossWithoutReg Mean           209.474
trainer/PolicyLossWithoutReg Std             52.86
trainer/PolicyLossWithoutReg Max            275.223
trainer/PolicyLossWithoutReg Min              3.25743
exploration/num steps total              159000
exploration/num paths total                 872
exploration/path length this epoch Mean     893
exploration/path length this epoch Std        0
exploration/path length this epoch Max      893
exploration/path length this epoch Min      893
exploration/Rewards Mean                      3.47651
exploration/Rewards Std                       0.989771
exploration/Rewards Max                       6.15486
exploration/Rewards Min                      -0.503154
exploration/Returns Mean                   3104.52
exploration/Returns Std                       0
exploration/Returns Max                    3104.52
exploration/Returns Min                    3104.52
exploration/Num Paths                         1
exploration/Average Returns                3104.52
evaluation_0/num steps total                  1.206e+06
evaluation_0/num paths total               4487
evaluation_0/path length Mean               998.875
evaluation_0/path length Std                  2.97647
evaluation_0/path length Max               1000
evaluation_0/path length Min                991
evaluation_0/Rewards Mean                     3.06599
evaluation_0/Rewards Std                      0.964931
evaluation_0/Rewards Max                      5.05659
evaluation_0/Rewards Min                     -2.05548
evaluation_0/Returns Mean                  3062.54
evaluation_0/Returns Std                    244.108
evaluation_0/Returns Max                   3457.24
evaluation_0/Returns Min                   2599.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3062.54
time/epoch (s)                                0
time/total (s)                             2078.41
Epoch                                       154
---------------------------------------  ---------------
2022-11-16 16:49:33.700123 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 155 finished
---------------------------------------  ---------------
epoch                                       155
total_step                               160000
replay_pool/size                         160000
trainer/alpha                                 0.0552953
trainer/alpha_loss                            1.60583
trainer/entropy                              -6.55464
trainer/qf_loss                              10.769
trainer/policy_loss                        -201.522
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         201.884
trainer/entropy_penalty                      -0.362441
trainer/entropy_percentage                   -0.00179529
trainer/Q1Pred Mean                         200.278
trainer/Q1Pred Std                           61.3699
trainer/Q1Pred Max                          265.185
trainer/Q1Pred Min                            0.17248
trainer/Q2Pred Mean                         200.289
trainer/Q2Pred Std                           61.2916
trainer/Q2Pred Max                          266.299
trainer/Q2Pred Min                            1.24382
trainer/QTargetWithReg Mean                 200.408
trainer/QTargetWithReg Std                   60.6971
trainer/QTargetWithReg Max                  263.933
trainer/QTargetWithReg Min                    1.53774
trainer/PolicyLossWithoutReg Mean           201.884
trainer/PolicyLossWithoutReg Std             60.7041
trainer/PolicyLossWithoutReg Max            265.152
trainer/PolicyLossWithoutReg Min              3.82711
exploration/num steps total              160000
exploration/num paths total                 873
exploration/path length this epoch Mean      89
exploration/path length this epoch Std        0
exploration/path length this epoch Max       89
exploration/path length this epoch Min       89
exploration/Rewards Mean                      2.52939
exploration/Rewards Std                       1.48504
exploration/Rewards Max                       5.36852
exploration/Rewards Min                      -0.528111
exploration/Returns Mean                    225.116
exploration/Returns Std                       0
exploration/Returns Max                     225.116
exploration/Returns Min                     225.116
exploration/Num Paths                         1
exploration/Average Returns                 225.116
evaluation_0/num steps total                  1.214e+06
evaluation_0/num paths total               4495
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.75208
evaluation_0/Rewards Std                      0.85512
evaluation_0/Rewards Max                      5.47029
evaluation_0/Rewards Min                     -0.629757
evaluation_0/Returns Mean                  3752.08
evaluation_0/Returns Std                     99.7901
evaluation_0/Returns Max                   3924.13
evaluation_0/Returns Min                   3546.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3752.08
time/epoch (s)                                0
time/total (s)                             2090.84
Epoch                                       155
---------------------------------------  ---------------
2022-11-16 16:49:46.799591 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 156 finished
---------------------------------------  --------------
epoch                                       156
total_step                               161000
replay_pool/size                         161000
trainer/alpha                                 0.0551367
trainer/alpha_loss                           -1.64134
trainer/entropy                              -5.4336
trainer/qf_loss                              13.5579
trainer/policy_loss                        -206.815
trainer/adversary_policy_loss                 9.7944
trainer/policy_loss_without_entropy         207.115
trainer/entropy_penalty                      -0.299591
trainer/entropy_percentage                   -0.0014465
trainer/Q1Pred Mean                         205.204
trainer/Q1Pred Std                           61.2603
trainer/Q1Pred Max                          262.988
trainer/Q1Pred Min                           -1.62555
trainer/Q2Pred Mean                         205.258
trainer/Q2Pred Std                           61.4348
trainer/Q2Pred Max                          264.302
trainer/Q2Pred Min                            0.31164
trainer/QTargetWithReg Mean                 206.344
trainer/QTargetWithReg Std                   61.6864
trainer/QTargetWithReg Max                  266.599
trainer/QTargetWithReg Min                    0.0353072
trainer/PolicyLossWithoutReg Mean           207.115
trainer/PolicyLossWithoutReg Std             60.9979
trainer/PolicyLossWithoutReg Max            263.688
trainer/PolicyLossWithoutReg Min              1.96745
exploration/num steps total              161000
exploration/num paths total                 874
exploration/path length this epoch Mean     743
exploration/path length this epoch Std        0
exploration/path length this epoch Max      743
exploration/path length this epoch Min      743
exploration/Rewards Mean                      3.04323
exploration/Rewards Std                       1.04452
exploration/Rewards Max                       5.95389
exploration/Rewards Min                      -0.687041
exploration/Returns Mean                   2261.12
exploration/Returns Std                       0
exploration/Returns Max                    2261.12
exploration/Returns Min                    2261.12
exploration/Num Paths                         1
exploration/Average Returns                2261.12
evaluation_0/num steps total                  1.222e+06
evaluation_0/num paths total               4503
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.4293
evaluation_0/Rewards Std                      0.878347
evaluation_0/Rewards Max                      5.78191
evaluation_0/Rewards Min                     -0.820531
evaluation_0/Returns Mean                  3429.3
evaluation_0/Returns Std                    106.927
evaluation_0/Returns Max                   3632.57
evaluation_0/Returns Min                   3306.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3429.3
time/epoch (s)                                0
time/total (s)                             2103.94
Epoch                                       156
---------------------------------------  --------------
2022-11-16 16:49:59.204957 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 157 finished
---------------------------------------  ---------------
epoch                                       157
total_step                               162000
replay_pool/size                         162000
trainer/alpha                                 0.0534043
trainer/alpha_loss                            1.2739
trainer/entropy                              -6.43479
trainer/qf_loss                              10.9702
trainer/policy_loss                        -208.336
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         208.68
trainer/entropy_penalty                      -0.343646
trainer/entropy_percentage                   -0.00164676
trainer/Q1Pred Mean                         206.474
trainer/Q1Pred Std                           60.1846
trainer/Q1Pred Max                          269.342
trainer/Q1Pred Min                           -2.8331
trainer/Q2Pred Mean                         205.973
trainer/Q2Pred Std                           60.7222
trainer/Q2Pred Max                          266.524
trainer/Q2Pred Min                           -6.2203
trainer/QTargetWithReg Mean                 206.248
trainer/QTargetWithReg Std                   60.5141
trainer/QTargetWithReg Max                  268.683
trainer/QTargetWithReg Min                   -0.693946
trainer/PolicyLossWithoutReg Mean           208.679
trainer/PolicyLossWithoutReg Std             57.0077
trainer/PolicyLossWithoutReg Max            266.91
trainer/PolicyLossWithoutReg Min              4.12544
exploration/num steps total              162000
exploration/num paths total                 875
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.3586
exploration/Rewards Std                       0.967515
exploration/Rewards Max                       5.47642
exploration/Rewards Min                      -0.867286
exploration/Returns Mean                   3358.6
exploration/Returns Std                       0
exploration/Returns Max                    3358.6
exploration/Returns Min                    3358.6
exploration/Num Paths                         1
exploration/Average Returns                3358.6
evaluation_0/num steps total                  1.23e+06
evaluation_0/num paths total               4511
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.28528
evaluation_0/Rewards Std                      0.83186
evaluation_0/Rewards Max                      5.66237
evaluation_0/Rewards Min                     -0.60044
evaluation_0/Returns Mean                  3285.28
evaluation_0/Returns Std                     72.42
evaluation_0/Returns Max                   3413.56
evaluation_0/Returns Min                   3160.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3285.28
time/epoch (s)                                0
time/total (s)                             2116.35
Epoch                                       157
---------------------------------------  ---------------
2022-11-16 16:50:11.619931 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 158 finished
---------------------------------------  ---------------
epoch                                       158
total_step                               163000
replay_pool/size                         163000
trainer/alpha                                 0.054399
trainer/alpha_loss                            1.36085
trainer/entropy                              -6.46741
trainer/qf_loss                              16.3358
trainer/policy_loss                        -204.895
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         205.247
trainer/entropy_penalty                      -0.35182
trainer/entropy_percentage                   -0.00171413
trainer/Q1Pred Mean                         203.724
trainer/Q1Pred Std                           62.9485
trainer/Q1Pred Max                          265.015
trainer/Q1Pred Min                            7.56173
trainer/Q2Pred Mean                         203.567
trainer/Q2Pred Std                           63.2079
trainer/Q2Pred Max                          263.506
trainer/Q2Pred Min                           -8.26279
trainer/QTargetWithReg Mean                 203.608
trainer/QTargetWithReg Std                   62.7599
trainer/QTargetWithReg Max                  263.274
trainer/QTargetWithReg Min                   -0.573629
trainer/PolicyLossWithoutReg Mean           205.247
trainer/PolicyLossWithoutReg Std             60.9949
trainer/PolicyLossWithoutReg Max            263.495
trainer/PolicyLossWithoutReg Min              9.85318
exploration/num steps total              163000
exploration/num paths total                 876
exploration/path length this epoch Mean     967
exploration/path length this epoch Std        0
exploration/path length this epoch Max      967
exploration/path length this epoch Min      967
exploration/Rewards Mean                      3.48467
exploration/Rewards Std                       0.918987
exploration/Rewards Max                       5.95815
exploration/Rewards Min                      -0.50242
exploration/Returns Mean                   3369.67
exploration/Returns Std                       0
exploration/Returns Max                    3369.67
exploration/Returns Min                    3369.67
exploration/Num Paths                         1
exploration/Average Returns                3369.67
evaluation_0/num steps total                  1.238e+06
evaluation_0/num paths total               4519
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.38379
evaluation_0/Rewards Std                      0.927565
evaluation_0/Rewards Max                      5.16392
evaluation_0/Rewards Min                     -0.493893
evaluation_0/Returns Mean                  3383.79
evaluation_0/Returns Std                    184.421
evaluation_0/Returns Max                   3591.27
evaluation_0/Returns Min                   3062.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3383.79
time/epoch (s)                                0
time/total (s)                             2128.76
Epoch                                       158
---------------------------------------  ---------------
2022-11-16 16:50:24.636494 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 159 finished
---------------------------------------  ---------------
epoch                                       159
total_step                               164000
replay_pool/size                         164000
trainer/alpha                                 0.0534241
trainer/alpha_loss                            1.11354
trainer/entropy                              -6.38011
trainer/qf_loss                              10.2202
trainer/policy_loss                        -206.115
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         206.456
trainer/entropy_penalty                      -0.340852
trainer/entropy_percentage                   -0.00165097
trainer/Q1Pred Mean                         204.153
trainer/Q1Pred Std                           60.0132
trainer/Q1Pred Max                          264.317
trainer/Q1Pred Min                           -3.35113
trainer/Q2Pred Mean                         204.286
trainer/Q2Pred Std                           60.1752
trainer/Q2Pred Max                          264.361
trainer/Q2Pred Min                           -2.62124
trainer/QTargetWithReg Mean                 204.634
trainer/QTargetWithReg Std                   59.7886
trainer/QTargetWithReg Max                  263.558
trainer/QTargetWithReg Min                   -1.84261
trainer/PolicyLossWithoutReg Mean           206.456
trainer/PolicyLossWithoutReg Std             58.481
trainer/PolicyLossWithoutReg Max            264.796
trainer/PolicyLossWithoutReg Min             -2.39732
exploration/num steps total              164000
exploration/num paths total                 877
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.26799
exploration/Rewards Std                       0.970154
exploration/Rewards Max                       5.66514
exploration/Rewards Min                      -0.479885
exploration/Returns Mean                   3267.99
exploration/Returns Std                       0
exploration/Returns Max                    3267.99
exploration/Returns Min                    3267.99
exploration/Num Paths                         1
exploration/Average Returns                3267.99
evaluation_0/num steps total                  1.246e+06
evaluation_0/num paths total               4527
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.18542
evaluation_0/Rewards Std                      0.873915
evaluation_0/Rewards Max                      5.10839
evaluation_0/Rewards Min                     -0.704941
evaluation_0/Returns Mean                  3185.42
evaluation_0/Returns Std                    152.235
evaluation_0/Returns Max                   3401.08
evaluation_0/Returns Min                   2922.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3185.42
time/epoch (s)                                0
time/total (s)                             2141.78
Epoch                                       159
---------------------------------------  ---------------
2022-11-16 16:50:36.981338 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 160 finished
---------------------------------------  ---------------
epoch                                       160
total_step                               165000
replay_pool/size                         165000
trainer/alpha                                 0.0541328
trainer/alpha_loss                            0.0619301
trainer/entropy                              -6.02124
trainer/qf_loss                               9.58177
trainer/policy_loss                        -206.924
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         207.25
trainer/entropy_penalty                      -0.325947
trainer/entropy_percentage                   -0.00157272
trainer/Q1Pred Mean                         205.62
trainer/Q1Pred Std                           61.909
trainer/Q1Pred Max                          268.169
trainer/Q1Pred Min                           -3.90976
trainer/Q2Pred Mean                         205.494
trainer/Q2Pred Std                           62.5052
trainer/Q2Pred Max                          269.552
trainer/Q2Pred Min                           -2.05848
trainer/QTargetWithReg Mean                 205.781
trainer/QTargetWithReg Std                   62.1429
trainer/QTargetWithReg Max                  268.687
trainer/QTargetWithReg Min                   -2.34073
trainer/PolicyLossWithoutReg Mean           207.25
trainer/PolicyLossWithoutReg Std             60.3869
trainer/PolicyLossWithoutReg Max            267.863
trainer/PolicyLossWithoutReg Min              3.09047
exploration/num steps total              165000
exploration/num paths total                 878
exploration/path length this epoch Mean     390
exploration/path length this epoch Std        0
exploration/path length this epoch Max      390
exploration/path length this epoch Min      390
exploration/Rewards Mean                      2.94323
exploration/Rewards Std                       0.967566
exploration/Rewards Max                       4.59753
exploration/Rewards Min                      -0.840437
exploration/Returns Mean                   1147.86
exploration/Returns Std                       0
exploration/Returns Max                    1147.86
exploration/Returns Min                    1147.86
exploration/Num Paths                         1
exploration/Average Returns                1147.86
evaluation_0/num steps total                  1.254e+06
evaluation_0/num paths total               4535
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.11595
evaluation_0/Rewards Std                      0.898952
evaluation_0/Rewards Max                      5.47588
evaluation_0/Rewards Min                     -0.550047
evaluation_0/Returns Mean                  3115.95
evaluation_0/Returns Std                     96.0934
evaluation_0/Returns Max                   3297.37
evaluation_0/Returns Min                   3003.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3115.95
time/epoch (s)                                0
time/total (s)                             2154.12
Epoch                                       160
---------------------------------------  ---------------
2022-11-16 16:50:49.342703 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 161 finished
---------------------------------------  ---------------
epoch                                       161
total_step                               166000
replay_pool/size                         166000
trainer/alpha                                 0.0532424
trainer/alpha_loss                           -0.674399
trainer/entropy                              -5.77006
trainer/qf_loss                              16.8329
trainer/policy_loss                        -212.131
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         212.438
trainer/entropy_penalty                      -0.307212
trainer/entropy_percentage                   -0.00144612
trainer/Q1Pred Mean                         211.842
trainer/Q1Pred Std                           53.0327
trainer/Q1Pred Max                          267.843
trainer/Q1Pred Min                            0.975921
trainer/Q2Pred Mean                         211.104
trainer/Q2Pred Std                           52.7376
trainer/Q2Pred Max                          267.313
trainer/Q2Pred Min                           12.3752
trainer/QTargetWithReg Mean                 211.314
trainer/QTargetWithReg Std                   53.5356
trainer/QTargetWithReg Max                  268.125
trainer/QTargetWithReg Min                    5.5479
trainer/PolicyLossWithoutReg Mean           212.438
trainer/PolicyLossWithoutReg Std             51.7001
trainer/PolicyLossWithoutReg Max            266.866
trainer/PolicyLossWithoutReg Min              9.56992
exploration/num steps total              166000
exploration/num paths total                 881
exploration/path length this epoch Mean     327.333
exploration/path length this epoch Std      346.035
exploration/path length this epoch Max      811
exploration/path length this epoch Min       21
exploration/Rewards Mean                      3.39501
exploration/Rewards Std                       1.27562
exploration/Rewards Max                       9.29556
exploration/Rewards Min                      -0.703716
exploration/Returns Mean                   1111.3
exploration/Returns Std                    1297.74
exploration/Returns Max                    2933.08
exploration/Returns Min                       7.97528
exploration/Num Paths                         3
exploration/Average Returns                1111.3
evaluation_0/num steps total                  1.262e+06
evaluation_0/num paths total               4543
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.39881
evaluation_0/Rewards Std                      0.912575
evaluation_0/Rewards Max                      5.73774
evaluation_0/Rewards Min                     -0.780236
evaluation_0/Returns Mean                  3398.81
evaluation_0/Returns Std                    146.441
evaluation_0/Returns Max                   3748
evaluation_0/Returns Min                   3259.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3398.81
time/epoch (s)                                0
time/total (s)                             2166.48
Epoch                                       161
---------------------------------------  ---------------
2022-11-16 16:51:02.422069 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 162 finished
---------------------------------------  --------------
epoch                                       162
total_step                               167000
replay_pool/size                         167000
trainer/alpha                                 0.0532872
trainer/alpha_loss                            1.26938
trainer/entropy                              -6.43294
trainer/qf_loss                              14.1733
trainer/policy_loss                        -206.097
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         206.44
trainer/entropy_penalty                      -0.342794
trainer/entropy_percentage                   -0.0016605
trainer/Q1Pred Mean                         204.063
trainer/Q1Pred Std                           60.5076
trainer/Q1Pred Max                          267.223
trainer/Q1Pred Min                           -9.66743
trainer/Q2Pred Mean                         203.759
trainer/Q2Pred Std                           60.7428
trainer/Q2Pred Max                          267.615
trainer/Q2Pred Min                          -14.1036
trainer/QTargetWithReg Mean                 204.125
trainer/QTargetWithReg Std                   60.6518
trainer/QTargetWithReg Max                  270.774
trainer/QTargetWithReg Min                   -0.255357
trainer/PolicyLossWithoutReg Mean           206.44
trainer/PolicyLossWithoutReg Std             56.9168
trainer/PolicyLossWithoutReg Max            267.199
trainer/PolicyLossWithoutReg Min             -3.04964
exploration/num steps total              167000
exploration/num paths total                 882
exploration/path length this epoch Mean     728
exploration/path length this epoch Std        0
exploration/path length this epoch Max      728
exploration/path length this epoch Min      728
exploration/Rewards Mean                      3.52702
exploration/Rewards Std                       1.02035
exploration/Rewards Max                       5.90153
exploration/Rewards Min                      -0.376623
exploration/Returns Mean                   2567.67
exploration/Returns Std                       0
exploration/Returns Max                    2567.67
exploration/Returns Min                    2567.67
exploration/Num Paths                         1
exploration/Average Returns                2567.67
evaluation_0/num steps total                  1.27e+06
evaluation_0/num paths total               4551
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.28239
evaluation_0/Rewards Std                      0.938347
evaluation_0/Rewards Max                      5.16997
evaluation_0/Rewards Min                     -0.615614
evaluation_0/Returns Mean                  3282.39
evaluation_0/Returns Std                    159.899
evaluation_0/Returns Max                   3470.06
evaluation_0/Returns Min                   2933.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3282.39
time/epoch (s)                                0
time/total (s)                             2179.56
Epoch                                       162
---------------------------------------  --------------
2022-11-16 16:51:16.306102 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 163 finished
---------------------------------------  ----------------
epoch                                       163
total_step                               168000
replay_pool/size                         168000
trainer/alpha                                 0.0538134
trainer/alpha_loss                           -0.712766
trainer/entropy                              -5.75608
trainer/qf_loss                              11
trainer/policy_loss                        -215.56
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         215.87
trainer/entropy_penalty                      -0.309755
trainer/entropy_percentage                   -0.00143492
trainer/Q1Pred Mean                         214.325
trainer/Q1Pred Std                           55.6817
trainer/Q1Pred Max                          272.068
trainer/Q1Pred Min                           -1.23269
trainer/Q2Pred Mean                         214.209
trainer/Q2Pred Std                           55.489
trainer/Q2Pred Max                          274.831
trainer/Q2Pred Min                            2.94197
trainer/QTargetWithReg Mean                 214.64
trainer/QTargetWithReg Std                   55.5575
trainer/QTargetWithReg Max                  270.308
trainer/QTargetWithReg Min                    3.8804
trainer/PolicyLossWithoutReg Mean           215.87
trainer/PolicyLossWithoutReg Std             55.0476
trainer/PolicyLossWithoutReg Max            270.616
trainer/PolicyLossWithoutReg Min             -4.4836
exploration/num steps total              168000
exploration/num paths total                 883
exploration/path length this epoch Mean     974
exploration/path length this epoch Std        0
exploration/path length this epoch Max      974
exploration/path length this epoch Min      974
exploration/Rewards Mean                      3.38847
exploration/Rewards Std                       1.38033
exploration/Rewards Max                       9.53404
exploration/Rewards Min                      -0.62325
exploration/Returns Mean                   3300.37
exploration/Returns Std                       0
exploration/Returns Max                    3300.37
exploration/Returns Min                    3300.37
exploration/Num Paths                         1
exploration/Average Returns                3300.37
evaluation_0/num steps total                  1.27733e+06
evaluation_0/num paths total               4559
evaluation_0/path length Mean               915.875
evaluation_0/path length Std                222.574
evaluation_0/path length Max               1000
evaluation_0/path length Min                327
evaluation_0/Rewards Mean                     3.24109
evaluation_0/Rewards Std                      0.987408
evaluation_0/Rewards Max                      5.51663
evaluation_0/Rewards Min                     -0.523814
evaluation_0/Returns Mean                  2968.43
evaluation_0/Returns Std                    855.279
evaluation_0/Returns Max                   3360.22
evaluation_0/Returns Min                    711.278
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2968.43
time/epoch (s)                                0
time/total (s)                             2193.44
Epoch                                       163
---------------------------------------  ----------------
2022-11-16 16:51:30.263713 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 164 finished
---------------------------------------  ----------------
epoch                                       164
total_step                               169000
replay_pool/size                         169000
trainer/alpha                                 0.05465
trainer/alpha_loss                            0.548865
trainer/entropy                              -6.18882
trainer/qf_loss                              12.6119
trainer/policy_loss                        -207.935
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         208.273
trainer/entropy_penalty                      -0.338219
trainer/entropy_percentage                   -0.00162392
trainer/Q1Pred Mean                         205.019
trainer/Q1Pred Std                           64.6403
trainer/Q1Pred Max                          278.231
trainer/Q1Pred Min                          -13.051
trainer/Q2Pred Mean                         204.283
trainer/Q2Pred Std                           64.8507
trainer/Q2Pred Max                          278.958
trainer/Q2Pred Min                           -9.20093
trainer/QTargetWithReg Mean                 205.381
trainer/QTargetWithReg Std                   63.9807
trainer/QTargetWithReg Max                  278.817
trainer/QTargetWithReg Min                   -2.48017
trainer/PolicyLossWithoutReg Mean           208.273
trainer/PolicyLossWithoutReg Std             61.4063
trainer/PolicyLossWithoutReg Max            277.944
trainer/PolicyLossWithoutReg Min             -9.2333
exploration/num steps total              169000
exploration/num paths total                 884
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.67162
exploration/Rewards Std                       1.00511
exploration/Rewards Max                       6.45386
exploration/Rewards Min                      -0.635683
exploration/Returns Mean                   3671.62
exploration/Returns Std                       0
exploration/Returns Max                    3671.62
exploration/Returns Min                    3671.62
exploration/Num Paths                         1
exploration/Average Returns                3671.62
evaluation_0/num steps total                  1.28526e+06
evaluation_0/num paths total               4567
evaluation_0/path length Mean               992.125
evaluation_0/path length Std                 20.8353
evaluation_0/path length Max               1000
evaluation_0/path length Min                937
evaluation_0/Rewards Mean                     3.92657
evaluation_0/Rewards Std                      0.962494
evaluation_0/Rewards Max                      8.45762
evaluation_0/Rewards Min                     -0.484365
evaluation_0/Returns Mean                  3895.65
evaluation_0/Returns Std                    127.478
evaluation_0/Returns Max                   4035.14
evaluation_0/Returns Min                   3677.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3895.65
time/epoch (s)                                0
time/total (s)                             2207.4
Epoch                                       164
---------------------------------------  ----------------
2022-11-16 16:51:43.414820 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 165 finished
---------------------------------------  ----------------
epoch                                       165
total_step                               170000
replay_pool/size                         170000
trainer/alpha                                 0.0545958
trainer/alpha_loss                           -1.40732
trainer/entropy                              -5.516
trainer/qf_loss                               9.85907
trainer/policy_loss                        -218.47
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         218.771
trainer/entropy_penalty                      -0.30115
trainer/entropy_percentage                   -0.00137655
trainer/Q1Pred Mean                         217.429
trainer/Q1Pred Std                           55.2774
trainer/Q1Pred Max                          274.635
trainer/Q1Pred Min                           -6.75477
trainer/Q2Pred Mean                         217.139
trainer/Q2Pred Std                           54.7552
trainer/Q2Pred Max                          274.783
trainer/Q2Pred Min                           -2.92605
trainer/QTargetWithReg Mean                 217.314
trainer/QTargetWithReg Std                   55.3661
trainer/QTargetWithReg Max                  274.809
trainer/QTargetWithReg Min                   -4.28172
trainer/PolicyLossWithoutReg Mean           218.771
trainer/PolicyLossWithoutReg Std             54.0482
trainer/PolicyLossWithoutReg Max            276.028
trainer/PolicyLossWithoutReg Min              2.84488
exploration/num steps total              170000
exploration/num paths total                 885
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.91929
exploration/Rewards Std                       0.955323
exploration/Rewards Max                       6.14534
exploration/Rewards Min                      -0.525796
exploration/Returns Mean                   3919.29
exploration/Returns Std                       0
exploration/Returns Max                    3919.29
exploration/Returns Min                    3919.29
exploration/Num Paths                         1
exploration/Average Returns                3919.29
evaluation_0/num steps total                  1.29326e+06
evaluation_0/num paths total               4575
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.75415
evaluation_0/Rewards Std                      0.941103
evaluation_0/Rewards Max                      6.17126
evaluation_0/Rewards Min                     -0.619144
evaluation_0/Returns Mean                  3754.15
evaluation_0/Returns Std                    145.733
evaluation_0/Returns Max                   4031.04
evaluation_0/Returns Min                   3574.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3754.15
time/epoch (s)                                0
time/total (s)                             2220.55
Epoch                                       165
---------------------------------------  ----------------
2022-11-16 16:51:55.805248 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 166 finished
---------------------------------------  ----------------
epoch                                       166
total_step                               171000
replay_pool/size                         171000
trainer/alpha                                 0.0526988
trainer/alpha_loss                            0.87042
trainer/entropy                              -6.29575
trainer/qf_loss                              12.0315
trainer/policy_loss                        -204.259
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         204.59
trainer/entropy_penalty                      -0.331778
trainer/entropy_percentage                   -0.00162167
trainer/Q1Pred Mean                         203.511
trainer/Q1Pred Std                           67.1544
trainer/Q1Pred Max                          276.033
trainer/Q1Pred Min                           -0.612934
trainer/Q2Pred Mean                         203.311
trainer/Q2Pred Std                           67.1092
trainer/Q2Pred Max                          276.639
trainer/Q2Pred Min                           -2.0219
trainer/QTargetWithReg Mean                 203.131
trainer/QTargetWithReg Std                   67.1858
trainer/QTargetWithReg Max                  276.407
trainer/QTargetWithReg Min                    2.67278
trainer/PolicyLossWithoutReg Mean           204.59
trainer/PolicyLossWithoutReg Std             66.4827
trainer/PolicyLossWithoutReg Max            275.752
trainer/PolicyLossWithoutReg Min             -0.177553
exploration/num steps total              171000
exploration/num paths total                 886
exploration/path length this epoch Mean     287
exploration/path length this epoch Std        0
exploration/path length this epoch Max      287
exploration/path length this epoch Min      287
exploration/Rewards Mean                      3.4642
exploration/Rewards Std                       1.57173
exploration/Rewards Max                       8.47827
exploration/Rewards Min                      -0.538066
exploration/Returns Mean                    994.226
exploration/Returns Std                       0
exploration/Returns Max                     994.226
exploration/Returns Min                     994.226
exploration/Num Paths                         1
exploration/Average Returns                 994.226
evaluation_0/num steps total                  1.30126e+06
evaluation_0/num paths total               4583
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.20802
evaluation_0/Rewards Std                      0.919784
evaluation_0/Rewards Max                      6.32264
evaluation_0/Rewards Min                     -0.572256
evaluation_0/Returns Mean                  3208.02
evaluation_0/Returns Std                    120.374
evaluation_0/Returns Max                   3426.75
evaluation_0/Returns Min                   3067.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3208.02
time/epoch (s)                                0
time/total (s)                             2232.94
Epoch                                       166
---------------------------------------  ----------------
2022-11-16 16:52:08.042912 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 167 finished
---------------------------------------  ----------------
epoch                                       167
total_step                               172000
replay_pool/size                         172000
trainer/alpha                                 0.0548205
trainer/alpha_loss                            0.0533953
trainer/entropy                              -6.01839
trainer/qf_loss                               8.76605
trainer/policy_loss                        -215.702
trainer/adversary_policy_loss                10.1609
trainer/policy_loss_without_entropy         216.032
trainer/entropy_penalty                      -0.329931
trainer/entropy_percentage                   -0.00152723
trainer/Q1Pred Mean                         214.182
trainer/Q1Pred Std                           59.148
trainer/Q1Pred Max                          285.099
trainer/Q1Pred Min                            4.91659
trainer/Q2Pred Mean                         214.237
trainer/Q2Pred Std                           59.0923
trainer/Q2Pred Max                          283.778
trainer/Q2Pred Min                            1.9625
trainer/QTargetWithReg Mean                 214.224
trainer/QTargetWithReg Std                   59.2603
trainer/QTargetWithReg Max                  284.865
trainer/QTargetWithReg Min                    5.07358
trainer/PolicyLossWithoutReg Mean           216.032
trainer/PolicyLossWithoutReg Std             57.3131
trainer/PolicyLossWithoutReg Max            284.291
trainer/PolicyLossWithoutReg Min              1.65565
exploration/num steps total              172000
exploration/num paths total                 888
exploration/path length this epoch Mean     402
exploration/path length this epoch Std      177
exploration/path length this epoch Max      579
exploration/path length this epoch Min      225
exploration/Rewards Mean                      3.72936
exploration/Rewards Std                       1.26491
exploration/Rewards Max                       6.24581
exploration/Rewards Min                      -0.71582
exploration/Returns Mean                   1499.2
exploration/Returns Std                     824.531
exploration/Returns Max                    2323.73
exploration/Returns Min                     674.671
exploration/Num Paths                         2
exploration/Average Returns                1499.2
evaluation_0/num steps total                  1.30926e+06
evaluation_0/num paths total               4591
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.5608
evaluation_0/Rewards Std                      0.861021
evaluation_0/Rewards Max                      5.52141
evaluation_0/Rewards Min                     -0.609835
evaluation_0/Returns Mean                  3560.8
evaluation_0/Returns Std                     52.9235
evaluation_0/Returns Max                   3646.57
evaluation_0/Returns Min                   3489.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3560.8
time/epoch (s)                                0
time/total (s)                             2245.18
Epoch                                       167
---------------------------------------  ----------------
2022-11-16 16:52:21.180370 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 168 finished
---------------------------------------  ----------------
epoch                                       168
total_step                               173000
replay_pool/size                         173000
trainer/alpha                                 0.0543672
trainer/alpha_loss                            0.610082
trainer/entropy                              -6.20951
trainer/qf_loss                              11.7295
trainer/policy_loss                        -214.302
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         214.64
trainer/entropy_penalty                      -0.337594
trainer/entropy_percentage                   -0.00157284
trainer/Q1Pred Mean                         212.593
trainer/Q1Pred Std                           65.708
trainer/Q1Pred Max                          282.008
trainer/Q1Pred Min                           -6.78473
trainer/Q2Pred Mean                         212.595
trainer/Q2Pred Std                           65.2536
trainer/Q2Pred Max                          281.2
trainer/Q2Pred Min                           -0.493113
trainer/QTargetWithReg Mean                 212.335
trainer/QTargetWithReg Std                   65.7123
trainer/QTargetWithReg Max                  280.904
trainer/QTargetWithReg Min                   -0.779277
trainer/PolicyLossWithoutReg Mean           214.64
trainer/PolicyLossWithoutReg Std             62.799
trainer/PolicyLossWithoutReg Max            280.968
trainer/PolicyLossWithoutReg Min              4.61966
exploration/num steps total              173000
exploration/num paths total                 889
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.81471
exploration/Rewards Std                       1.00648
exploration/Rewards Max                       7.5231
exploration/Rewards Min                      -0.577462
exploration/Returns Mean                   3814.71
exploration/Returns Std                       0
exploration/Returns Max                    3814.71
exploration/Returns Min                    3814.71
exploration/Num Paths                         1
exploration/Average Returns                3814.71
evaluation_0/num steps total                  1.31726e+06
evaluation_0/num paths total               4599
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.39771
evaluation_0/Rewards Std                      0.931327
evaluation_0/Rewards Max                      6.08594
evaluation_0/Rewards Min                     -0.806856
evaluation_0/Returns Mean                  3397.71
evaluation_0/Returns Std                     64.9045
evaluation_0/Returns Max                   3489.49
evaluation_0/Returns Min                   3278.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3397.71
time/epoch (s)                                0
time/total (s)                             2258.32
Epoch                                       168
---------------------------------------  ----------------
2022-11-16 16:52:33.449169 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 169 finished
---------------------------------------  ----------------
epoch                                       169
total_step                               174000
replay_pool/size                         174000
trainer/alpha                                 0.0557897
trainer/alpha_loss                            1.44162
trainer/entropy                              -6.4995
trainer/qf_loss                              11.3096
trainer/policy_loss                        -219.172
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         219.534
trainer/entropy_penalty                      -0.362605
trainer/entropy_percentage                   -0.0016517
trainer/Q1Pred Mean                         217.792
trainer/Q1Pred Std                           50.6289
trainer/Q1Pred Max                          274.825
trainer/Q1Pred Min                           -4.07674
trainer/Q2Pred Mean                         218.29
trainer/Q2Pred Std                           50.2694
trainer/Q2Pred Max                          274.264
trainer/Q2Pred Min                          -10.0815
trainer/QTargetWithReg Mean                 218.382
trainer/QTargetWithReg Std                   50.3728
trainer/QTargetWithReg Max                  274.758
trainer/QTargetWithReg Min                    0.301685
trainer/PolicyLossWithoutReg Mean           219.534
trainer/PolicyLossWithoutReg Std             47.9034
trainer/PolicyLossWithoutReg Max            273.805
trainer/PolicyLossWithoutReg Min              0.169496
exploration/num steps total              174000
exploration/num paths total                 891
exploration/path length this epoch Mean     452.5
exploration/path length this epoch Std      102.5
exploration/path length this epoch Max      555
exploration/path length this epoch Min      350
exploration/Rewards Mean                      3.28962
exploration/Rewards Std                       1.02126
exploration/Rewards Max                       5.55531
exploration/Rewards Min                      -0.633721
exploration/Returns Mean                   1488.55
exploration/Returns Std                     418.182
exploration/Returns Max                    1906.74
exploration/Returns Min                    1070.37
exploration/Num Paths                         2
exploration/Average Returns                1488.55
evaluation_0/num steps total                  1.32526e+06
evaluation_0/num paths total               4607
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.4588
evaluation_0/Rewards Std                      0.957814
evaluation_0/Rewards Max                      6.10973
evaluation_0/Rewards Min                     -0.539669
evaluation_0/Returns Mean                  3458.8
evaluation_0/Returns Std                    154.562
evaluation_0/Returns Max                   3694.78
evaluation_0/Returns Min                   3299.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3458.8
time/epoch (s)                                0
time/total (s)                             2270.59
Epoch                                       169
---------------------------------------  ----------------
2022-11-16 16:52:45.736488 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 170 finished
---------------------------------------  ----------------
epoch                                       170
total_step                               175000
replay_pool/size                         175000
trainer/alpha                                 0.0550966
trainer/alpha_loss                           -0.867843
trainer/entropy                              -5.7006
trainer/qf_loss                              12.2847
trainer/policy_loss                        -216.115
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         216.429
trainer/entropy_penalty                      -0.314084
trainer/entropy_percentage                   -0.00145121
trainer/Q1Pred Mean                         214.988
trainer/Q1Pred Std                           61.0141
trainer/Q1Pred Max                          285.696
trainer/Q1Pred Min                          -20.8024
trainer/Q2Pred Mean                         214.848
trainer/Q2Pred Std                           61.2219
trainer/Q2Pred Max                          286.584
trainer/Q2Pred Min                          -19.1114
trainer/QTargetWithReg Mean                 214.846
trainer/QTargetWithReg Std                   60.9564
trainer/QTargetWithReg Max                  287.771
trainer/QTargetWithReg Min                  -17.9783
trainer/PolicyLossWithoutReg Mean           216.429
trainer/PolicyLossWithoutReg Std             59.1923
trainer/PolicyLossWithoutReg Max            284.994
trainer/PolicyLossWithoutReg Min            -14.7013
exploration/num steps total              175000
exploration/num paths total                 892
exploration/path length this epoch Mean     981
exploration/path length this epoch Std        0
exploration/path length this epoch Max      981
exploration/path length this epoch Min      981
exploration/Rewards Mean                      3.5131
exploration/Rewards Std                       1.16712
exploration/Rewards Max                       7.13093
exploration/Rewards Min                      -0.595904
exploration/Returns Mean                   3446.35
exploration/Returns Std                       0
exploration/Returns Max                    3446.35
exploration/Returns Min                    3446.35
exploration/Num Paths                         1
exploration/Average Returns                3446.35
evaluation_0/num steps total                  1.33326e+06
evaluation_0/num paths total               4615
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.33272
evaluation_0/Rewards Std                      0.82782
evaluation_0/Rewards Max                      5.95625
evaluation_0/Rewards Min                     -0.703356
evaluation_0/Returns Mean                  3332.72
evaluation_0/Returns Std                    101.674
evaluation_0/Returns Max                   3532.49
evaluation_0/Returns Min                   3221.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3332.72
time/epoch (s)                                0
time/total (s)                             2282.87
Epoch                                       170
---------------------------------------  ----------------
2022-11-16 16:52:59.001269 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 171 finished
---------------------------------------  ----------------
epoch                                       171
total_step                               176000
replay_pool/size                         176000
trainer/alpha                                 0.0550077
trainer/alpha_loss                            1.29907
trainer/entropy                              -6.44793
trainer/qf_loss                              13.7204
trainer/policy_loss                        -216.757
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         217.112
trainer/entropy_penalty                      -0.354686
trainer/entropy_percentage                   -0.00163365
trainer/Q1Pred Mean                         216.205
trainer/Q1Pred Std                           57.1797
trainer/Q1Pred Max                          278.792
trainer/Q1Pred Min                            2.28442
trainer/Q2Pred Mean                         216.194
trainer/Q2Pred Std                           57.4769
trainer/Q2Pred Max                          277.138
trainer/Q2Pred Min                            1.95497
trainer/QTargetWithReg Mean                 215.385
trainer/QTargetWithReg Std                   57.6044
trainer/QTargetWithReg Max                  277.422
trainer/QTargetWithReg Min                   -0.481857
trainer/PolicyLossWithoutReg Mean           217.112
trainer/PolicyLossWithoutReg Std             56.662
trainer/PolicyLossWithoutReg Max            278.004
trainer/PolicyLossWithoutReg Min              1.14158
exploration/num steps total              176000
exploration/num paths total                 894
exploration/path length this epoch Mean     237.5
exploration/path length this epoch Std      107.5
exploration/path length this epoch Max      345
exploration/path length this epoch Min      130
exploration/Rewards Mean                      3.41918
exploration/Rewards Std                       1.46782
exploration/Rewards Max                       7.22721
exploration/Rewards Min                      -0.734465
exploration/Returns Mean                    812.054
exploration/Returns Std                     458.355
exploration/Returns Max                    1270.41
exploration/Returns Min                     353.7
exploration/Num Paths                         2
exploration/Average Returns                 812.054
evaluation_0/num steps total                  1.34126e+06
evaluation_0/num paths total               4623
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.49175
evaluation_0/Rewards Std                      0.91067
evaluation_0/Rewards Max                      6.05121
evaluation_0/Rewards Min                     -0.695089
evaluation_0/Returns Mean                  3491.75
evaluation_0/Returns Std                    121.382
evaluation_0/Returns Max                   3695.66
evaluation_0/Returns Min                   3336.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3491.75
time/epoch (s)                                0
time/total (s)                             2296.14
Epoch                                       171
---------------------------------------  ----------------
2022-11-16 16:53:11.335431 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 172 finished
---------------------------------------  ----------------
epoch                                       172
total_step                               177000
replay_pool/size                         177000
trainer/alpha                                 0.055299
trainer/alpha_loss                           -0.609874
trainer/entropy                              -5.78933
trainer/qf_loss                              12.5644
trainer/policy_loss                        -214.997
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         215.317
trainer/entropy_penalty                      -0.320144
trainer/entropy_percentage                   -0.00148685
trainer/Q1Pred Mean                         212.733
trainer/Q1Pred Std                           61.3784
trainer/Q1Pred Max                          274.538
trainer/Q1Pred Min                           -9.1883
trainer/Q2Pred Mean                         212.471
trainer/Q2Pred Std                           61.5727
trainer/Q2Pred Max                          273.939
trainer/Q2Pred Min                          -14.9574
trainer/QTargetWithReg Mean                 213.537
trainer/QTargetWithReg Std                   61.5665
trainer/QTargetWithReg Max                  278.447
trainer/QTargetWithReg Min                  -10.4454
trainer/PolicyLossWithoutReg Mean           215.317
trainer/PolicyLossWithoutReg Std             58.6389
trainer/PolicyLossWithoutReg Max            275.952
trainer/PolicyLossWithoutReg Min             -6.69356
exploration/num steps total              177000
exploration/num paths total                 895
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.60983
exploration/Rewards Std                       1.01427
exploration/Rewards Max                       6.3319
exploration/Rewards Min                      -0.562757
exploration/Returns Mean                   3609.83
exploration/Returns Std                       0
exploration/Returns Max                    3609.83
exploration/Returns Min                    3609.83
exploration/Num Paths                         1
exploration/Average Returns                3609.83
evaluation_0/num steps total                  1.34926e+06
evaluation_0/num paths total               4631
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.89585
evaluation_0/Rewards Std                      0.893756
evaluation_0/Rewards Max                      6.58689
evaluation_0/Rewards Min                     -0.616795
evaluation_0/Returns Mean                  3895.85
evaluation_0/Returns Std                     67.999
evaluation_0/Returns Max                   4026.18
evaluation_0/Returns Min                   3814.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3895.85
time/epoch (s)                                0
time/total (s)                             2308.47
Epoch                                       172
---------------------------------------  ----------------
2022-11-16 16:53:25.743439 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 173 finished
---------------------------------------  ----------------
epoch                                       173
total_step                               178000
replay_pool/size                         178000
trainer/alpha                                 0.0550003
trainer/alpha_loss                           -0.829536
trainer/entropy                              -5.71399
trainer/qf_loss                              10.47
trainer/policy_loss                        -223.172
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         223.486
trainer/entropy_penalty                      -0.314271
trainer/entropy_percentage                   -0.00140622
trainer/Q1Pred Mean                         221.335
trainer/Q1Pred Std                           53.3039
trainer/Q1Pred Max                          288.546
trainer/Q1Pred Min                           -8.83178
trainer/Q2Pred Mean                         221.472
trainer/Q2Pred Std                           53.1263
trainer/Q2Pred Max                          290.335
trainer/Q2Pred Min                           -8.88396
trainer/QTargetWithReg Mean                 221.151
trainer/QTargetWithReg Std                   53.0686
trainer/QTargetWithReg Max                  290.404
trainer/QTargetWithReg Min                  -12.4248
trainer/PolicyLossWithoutReg Mean           223.486
trainer/PolicyLossWithoutReg Std             51.0275
trainer/PolicyLossWithoutReg Max            288.404
trainer/PolicyLossWithoutReg Min             -7.13499
exploration/num steps total              178000
exploration/num paths total                 897
exploration/path length this epoch Mean     348
exploration/path length this epoch Std       46
exploration/path length this epoch Max      394
exploration/path length this epoch Min      302
exploration/Rewards Mean                      3.27945
exploration/Rewards Std                       1.16063
exploration/Rewards Max                       6.77359
exploration/Rewards Min                      -0.546184
exploration/Returns Mean                   1141.25
exploration/Returns Std                     162.819
exploration/Returns Max                    1304.07
exploration/Returns Min                     978.431
exploration/Num Paths                         2
exploration/Average Returns                1141.25
evaluation_0/num steps total                  1.35714e+06
evaluation_0/num paths total               4640
evaluation_0/path length Mean               874.889
evaluation_0/path length Std                188.026
evaluation_0/path length Max               1000
evaluation_0/path length Min                536
evaluation_0/Rewards Mean                     3.51488
evaluation_0/Rewards Std                      0.930665
evaluation_0/Rewards Max                      5.86036
evaluation_0/Rewards Min                     -0.682681
evaluation_0/Returns Mean                  3075.13
evaluation_0/Returns Std                    740.526
evaluation_0/Returns Max                   3764.57
evaluation_0/Returns Min                   1737.91
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3075.13
time/epoch (s)                                0
time/total (s)                             2322.88
Epoch                                       173
---------------------------------------  ----------------
2022-11-16 16:53:39.796728 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 174 finished
---------------------------------------  ----------------
epoch                                       174
total_step                               179000
replay_pool/size                         179000
trainer/alpha                                 0.0565098
trainer/alpha_loss                            0.0809268
trainer/entropy                              -6.02817
trainer/qf_loss                              14.9628
trainer/policy_loss                        -216.131
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         216.471
trainer/entropy_penalty                      -0.34065
trainer/entropy_percentage                   -0.00157365
trainer/Q1Pred Mean                         215.088
trainer/Q1Pred Std                           60.7154
trainer/Q1Pred Max                          284.017
trainer/Q1Pred Min                           -4.18975
trainer/Q2Pred Mean                         216.032
trainer/Q2Pred Std                           60.617
trainer/Q2Pred Max                          283.462
trainer/Q2Pred Min                           -5.92472
trainer/QTargetWithReg Mean                 215.454
trainer/QTargetWithReg Std                   61.1245
trainer/QTargetWithReg Max                  282.52
trainer/QTargetWithReg Min                   -0.778057
trainer/PolicyLossWithoutReg Mean           216.471
trainer/PolicyLossWithoutReg Std             59.958
trainer/PolicyLossWithoutReg Max            282.442
trainer/PolicyLossWithoutReg Min             -2.99565
exploration/num steps total              179000
exploration/num paths total                 898
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.69333
exploration/Rewards Std                       0.892928
exploration/Rewards Max                       5.95416
exploration/Rewards Min                      -0.730552
exploration/Returns Mean                   3693.33
exploration/Returns Std                       0
exploration/Returns Max                    3693.33
exploration/Returns Min                    3693.33
exploration/Num Paths                         1
exploration/Average Returns                3693.33
evaluation_0/num steps total                  1.36508e+06
evaluation_0/num paths total               4650
evaluation_0/path length Mean               793.8
evaluation_0/path length Std                172.975
evaluation_0/path length Max               1000
evaluation_0/path length Min                527
evaluation_0/Rewards Mean                     3.89617
evaluation_0/Rewards Std                      1.22767
evaluation_0/Rewards Max                     10.774
evaluation_0/Rewards Min                     -0.720811
evaluation_0/Returns Mean                  3092.78
evaluation_0/Returns Std                    803.629
evaluation_0/Returns Max                   4110.55
evaluation_0/Returns Min                   1662.35
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3092.78
time/epoch (s)                                0
time/total (s)                             2336.94
Epoch                                       174
---------------------------------------  ----------------
2022-11-16 16:53:52.166863 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 175 finished
---------------------------------------  ----------------
epoch                                       175
total_step                               180000
replay_pool/size                         180000
trainer/alpha                                 0.0556269
trainer/alpha_loss                           -0.88377
trainer/entropy                              -5.69409
trainer/qf_loss                              10.9771
trainer/policy_loss                        -221.688
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         222.004
trainer/entropy_penalty                      -0.316745
trainer/entropy_percentage                   -0.00142675
trainer/Q1Pred Mean                         219.682
trainer/Q1Pred Std                           59.3275
trainer/Q1Pred Max                          286.6
trainer/Q1Pred Min                            9.54939
trainer/Q2Pred Mean                         220.033
trainer/Q2Pred Std                           59.5853
trainer/Q2Pred Max                          288.484
trainer/Q2Pred Min                            7.99757
trainer/QTargetWithReg Mean                 219.901
trainer/QTargetWithReg Std                   59.595
trainer/QTargetWithReg Max                  286.71
trainer/QTargetWithReg Min                   11.4064
trainer/PolicyLossWithoutReg Mean           222.004
trainer/PolicyLossWithoutReg Std             57.7536
trainer/PolicyLossWithoutReg Max            287.479
trainer/PolicyLossWithoutReg Min              8.87859
exploration/num steps total              180000
exploration/num paths total                 900
exploration/path length this epoch Mean     492.5
exploration/path length this epoch Std      119.5
exploration/path length this epoch Max      612
exploration/path length this epoch Min      373
exploration/Rewards Mean                      3.45048
exploration/Rewards Std                       1.02596
exploration/Rewards Max                       6.49335
exploration/Rewards Min                      -0.833368
exploration/Returns Mean                   1699.36
exploration/Returns Std                     447.098
exploration/Returns Max                    2146.46
exploration/Returns Min                    1252.26
exploration/Num Paths                         2
exploration/Average Returns                1699.36
evaluation_0/num steps total                  1.37308e+06
evaluation_0/num paths total               4658
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.54022
evaluation_0/Rewards Std                      0.78357
evaluation_0/Rewards Max                      5.74541
evaluation_0/Rewards Min                     -0.782711
evaluation_0/Returns Mean                  3540.22
evaluation_0/Returns Std                     80.2747
evaluation_0/Returns Max                   3694.59
evaluation_0/Returns Min                   3450.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3540.22
time/epoch (s)                                0
time/total (s)                             2349.3
Epoch                                       175
---------------------------------------  ----------------
2022-11-16 16:54:05.192287 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 176 finished
---------------------------------------  ----------------
epoch                                       176
total_step                               181000
replay_pool/size                         181000
trainer/alpha                                 0.0567075
trainer/alpha_loss                           -0.182566
trainer/entropy                              -5.93639
trainer/qf_loss                              17.4187
trainer/policy_loss                        -219.441
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         219.778
trainer/entropy_penalty                      -0.336637
trainer/entropy_percentage                   -0.00153172
trainer/Q1Pred Mean                         217.975
trainer/Q1Pred Std                           60.74
trainer/Q1Pred Max                          291.121
trainer/Q1Pred Min                            0.683425
trainer/Q2Pred Mean                         217.538
trainer/Q2Pred Std                           61.0755
trainer/Q2Pred Max                          291.28
trainer/Q2Pred Min                           -6.02416
trainer/QTargetWithReg Mean                 218.392
trainer/QTargetWithReg Std                   60.8985
trainer/QTargetWithReg Max                  293.216
trainer/QTargetWithReg Min                    0.245291
trainer/PolicyLossWithoutReg Mean           219.778
trainer/PolicyLossWithoutReg Std             60.5292
trainer/PolicyLossWithoutReg Max            291.016
trainer/PolicyLossWithoutReg Min             -5.9989
exploration/num steps total              181000
exploration/num paths total                 901
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.75355
exploration/Rewards Std                       0.957014
exploration/Rewards Max                       6.18322
exploration/Rewards Min                      -0.908606
exploration/Returns Mean                   3753.55
exploration/Returns Std                       0
exploration/Returns Max                    3753.55
exploration/Returns Min                    3753.55
exploration/Num Paths                         1
exploration/Average Returns                3753.55
evaluation_0/num steps total                  1.38108e+06
evaluation_0/num paths total               4666
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.54904
evaluation_0/Rewards Std                      0.829186
evaluation_0/Rewards Max                      5.64205
evaluation_0/Rewards Min                     -0.505766
evaluation_0/Returns Mean                  3549.04
evaluation_0/Returns Std                     91.0966
evaluation_0/Returns Max                   3753.06
evaluation_0/Returns Min                   3458.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3549.04
time/epoch (s)                                0
time/total (s)                             2362.33
Epoch                                       176
---------------------------------------  ----------------
2022-11-16 16:54:19.148936 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 177 finished
---------------------------------------  ----------------
epoch                                       177
total_step                               182000
replay_pool/size                         182000
trainer/alpha                                 0.0542231
trainer/alpha_loss                            0.585392
trainer/entropy                              -6.20084
trainer/qf_loss                              10.8591
trainer/policy_loss                        -217.729
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         218.066
trainer/entropy_penalty                      -0.336229
trainer/entropy_percentage                   -0.00154187
trainer/Q1Pred Mean                         216.071
trainer/Q1Pred Std                           65.7075
trainer/Q1Pred Max                          286.337
trainer/Q1Pred Min                            3.7838
trainer/Q2Pred Mean                         215.78
trainer/Q2Pred Std                           65.592
trainer/Q2Pred Max                          284.778
trainer/Q2Pred Min                           -1.59172
trainer/QTargetWithReg Mean                 216.041
trainer/QTargetWithReg Std                   65.9497
trainer/QTargetWithReg Max                  284.652
trainer/QTargetWithReg Min                   -0.32117
trainer/PolicyLossWithoutReg Mean           218.066
trainer/PolicyLossWithoutReg Std             63.5861
trainer/PolicyLossWithoutReg Max            284.467
trainer/PolicyLossWithoutReg Min              5.44643
exploration/num steps total              182000
exploration/num paths total                 902
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.06695
exploration/Rewards Std                       1.04182
exploration/Rewards Max                       6.82432
exploration/Rewards Min                      -0.493455
exploration/Returns Mean                   4066.95
exploration/Returns Std                       0
exploration/Returns Max                    4066.95
exploration/Returns Min                    4066.95
exploration/Num Paths                         1
exploration/Average Returns                4066.95
evaluation_0/num steps total                  1.38837e+06
evaluation_0/num paths total               4675
evaluation_0/path length Mean               810.667
evaluation_0/path length Std                354.512
evaluation_0/path length Max               1000
evaluation_0/path length Min                117
evaluation_0/Rewards Mean                     3.64146
evaluation_0/Rewards Std                      0.839568
evaluation_0/Rewards Max                      5.81655
evaluation_0/Rewards Min                     -0.603895
evaluation_0/Returns Mean                  2952.01
evaluation_0/Returns Std                   1345.94
evaluation_0/Returns Max                   3748.77
evaluation_0/Returns Min                    324.104
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2952.01
time/epoch (s)                                0
time/total (s)                             2376.28
Epoch                                       177
---------------------------------------  ----------------
2022-11-16 16:54:31.500642 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 178 finished
---------------------------------------  ----------------
epoch                                       178
total_step                               183000
replay_pool/size                         183000
trainer/alpha                                 0.0559825
trainer/alpha_loss                           -0.913607
trainer/entropy                              -5.68306
trainer/qf_loss                              12.3186
trainer/policy_loss                        -224.934
trainer/adversary_policy_loss                10.6067
trainer/policy_loss_without_entropy         225.252
trainer/entropy_penalty                      -0.318152
trainer/entropy_percentage                   -0.00141242
trainer/Q1Pred Mean                         223.979
trainer/Q1Pred Std                           54.9821
trainer/Q1Pred Max                          295.934
trainer/Q1Pred Min                           10.1605
trainer/Q2Pred Mean                         223.786
trainer/Q2Pred Std                           54.5126
trainer/Q2Pred Max                          297.1
trainer/Q2Pred Min                           12.2689
trainer/QTargetWithReg Mean                 224.359
trainer/QTargetWithReg Std                   54.7486
trainer/QTargetWithReg Max                  297.35
trainer/QTargetWithReg Min                    4.55725
trainer/PolicyLossWithoutReg Mean           225.252
trainer/PolicyLossWithoutReg Std             53.8811
trainer/PolicyLossWithoutReg Max            294.677
trainer/PolicyLossWithoutReg Min              7.89823
exploration/num steps total              183000
exploration/num paths total                 903
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.52657
exploration/Rewards Std                       0.894391
exploration/Rewards Max                       6.51601
exploration/Rewards Min                      -0.481559
exploration/Returns Mean                   3526.57
exploration/Returns Std                       0
exploration/Returns Max                    3526.57
exploration/Returns Min                    3526.57
exploration/Num Paths                         1
exploration/Average Returns                3526.57
evaluation_0/num steps total                  1.39637e+06
evaluation_0/num paths total               4683
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.45152
evaluation_0/Rewards Std                      0.880643
evaluation_0/Rewards Max                      6.23764
evaluation_0/Rewards Min                     -1.28559
evaluation_0/Returns Mean                  3451.52
evaluation_0/Returns Std                    203.415
evaluation_0/Returns Max                   3731.7
evaluation_0/Returns Min                   2981.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3451.52
time/epoch (s)                                0
time/total (s)                             2388.63
Epoch                                       178
---------------------------------------  ----------------
2022-11-16 16:54:43.843347 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 179 finished
---------------------------------------  ----------------
epoch                                       179
total_step                               184000
replay_pool/size                         184000
trainer/alpha                                 0.0551536
trainer/alpha_loss                           -0.521444
trainer/entropy                              -5.82004
trainer/qf_loss                              16.454
trainer/policy_loss                        -228.17
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         228.491
trainer/entropy_penalty                      -0.320996
trainer/entropy_percentage                   -0.00140485
trainer/Q1Pred Mean                         227.049
trainer/Q1Pred Std                           54.973
trainer/Q1Pred Max                          290.106
trainer/Q1Pred Min                           -0.260301
trainer/Q2Pred Mean                         227.462
trainer/Q2Pred Std                           54.3858
trainer/Q2Pred Max                          288.339
trainer/Q2Pred Min                            2.48712
trainer/QTargetWithReg Mean                 227.297
trainer/QTargetWithReg Std                   55.1955
trainer/QTargetWithReg Max                  288.522
trainer/QTargetWithReg Min                    4.11565
trainer/PolicyLossWithoutReg Mean           228.491
trainer/PolicyLossWithoutReg Std             53.8759
trainer/PolicyLossWithoutReg Max            288.59
trainer/PolicyLossWithoutReg Min             -0.249252
exploration/num steps total              184000
exploration/num paths total                 904
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.66459
exploration/Rewards Std                       0.844171
exploration/Rewards Max                       6.31676
exploration/Rewards Min                      -0.427761
exploration/Returns Mean                   3664.59
exploration/Returns Std                       0
exploration/Returns Max                    3664.59
exploration/Returns Min                    3664.59
exploration/Num Paths                         1
exploration/Average Returns                3664.59
evaluation_0/num steps total                  1.40437e+06
evaluation_0/num paths total               4691
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.5257
evaluation_0/Rewards Std                      0.808275
evaluation_0/Rewards Max                      5.83122
evaluation_0/Rewards Min                     -0.611473
evaluation_0/Returns Mean                  3525.7
evaluation_0/Returns Std                     73.8471
evaluation_0/Returns Max                   3668.11
evaluation_0/Returns Min                   3425.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3525.7
time/epoch (s)                                0
time/total (s)                             2400.98
Epoch                                       179
---------------------------------------  ----------------
2022-11-16 16:55:19.135751 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 180 finished
---------------------------------------  ----------------
epoch                                       180
total_step                               185000
replay_pool/size                         185000
trainer/alpha                                 0.055989
trainer/alpha_loss                           -1.2066
trainer/entropy                              -5.58143
trainer/qf_loss                              15.3163
trainer/policy_loss                        -227.303
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         227.615
trainer/entropy_penalty                      -0.312499
trainer/entropy_percentage                   -0.00137292
trainer/Q1Pred Mean                         225.561
trainer/Q1Pred Std                           58.6894
trainer/Q1Pred Max                          294.545
trainer/Q1Pred Min                            4.8109
trainer/Q2Pred Mean                         226.039
trainer/Q2Pred Std                           58.2577
trainer/Q2Pred Max                          294.639
trainer/Q2Pred Min                            7.69086
trainer/QTargetWithReg Mean                 225.959
trainer/QTargetWithReg Std                   59.1361
trainer/QTargetWithReg Max                  295.745
trainer/QTargetWithReg Min                   -0.319668
trainer/PolicyLossWithoutReg Mean           227.615
trainer/PolicyLossWithoutReg Std             56.5438
trainer/PolicyLossWithoutReg Max            295.349
trainer/PolicyLossWithoutReg Min             12.0344
exploration/num steps total              185000
exploration/num paths total                 905
exploration/path length this epoch Mean     263
exploration/path length this epoch Std        0
exploration/path length this epoch Max      263
exploration/path length this epoch Min      263
exploration/Rewards Mean                      3.27631
exploration/Rewards Std                       1.28671
exploration/Rewards Max                       7.957
exploration/Rewards Min                      -0.597798
exploration/Returns Mean                    861.668
exploration/Returns Std                       0
exploration/Returns Max                     861.668
exploration/Returns Min                     861.668
exploration/Num Paths                         1
exploration/Average Returns                 861.668
evaluation_0/num steps total                  1.41164e+06
evaluation_0/num paths total               4699
evaluation_0/path length Mean               908.75
evaluation_0/path length Std                241.425
evaluation_0/path length Max               1000
evaluation_0/path length Min                270
evaluation_0/Rewards Mean                     3.82141
evaluation_0/Rewards Std                      0.904774
evaluation_0/Rewards Max                      9.3043
evaluation_0/Rewards Min                     -0.537999
evaluation_0/Returns Mean                  3472.7
evaluation_0/Returns Std                    950.696
evaluation_0/Returns Max                   3960.97
evaluation_0/Returns Min                    964.204
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3472.7
time/epoch (s)                                0
time/total (s)                             2436.27
Epoch                                       180
---------------------------------------  ----------------
2022-11-16 16:56:11.340596 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 181 finished
---------------------------------------  ----------------
epoch                                       181
total_step                               186000
replay_pool/size                         186000
trainer/alpha                                 0.0582801
trainer/alpha_loss                            0.758698
trainer/entropy                              -6.26689
trainer/qf_loss                              14.5337
trainer/policy_loss                        -221.675
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         222.04
trainer/entropy_penalty                      -0.365235
trainer/entropy_percentage                   -0.00164491
trainer/Q1Pred Mean                         221.276
trainer/Q1Pred Std                           64.0179
trainer/Q1Pred Max                          291.89
trainer/Q1Pred Min                           -1.70875
trainer/Q2Pred Mean                         221.533
trainer/Q2Pred Std                           64.4911
trainer/Q2Pred Max                          291.366
trainer/Q2Pred Min                           -1.74499
trainer/QTargetWithReg Mean                 221.026
trainer/QTargetWithReg Std                   64.1839
trainer/QTargetWithReg Max                  291.135
trainer/QTargetWithReg Min                   -0.711067
trainer/PolicyLossWithoutReg Mean           222.04
trainer/PolicyLossWithoutReg Std             63.1034
trainer/PolicyLossWithoutReg Max            289.351
trainer/PolicyLossWithoutReg Min             -0.132305
exploration/num steps total              186000
exploration/num paths total                 906
exploration/path length this epoch Mean     452
exploration/path length this epoch Std        0
exploration/path length this epoch Max      452
exploration/path length this epoch Min      452
exploration/Rewards Mean                      3.11621
exploration/Rewards Std                       1.1639
exploration/Rewards Max                       5.24111
exploration/Rewards Min                      -0.519128
exploration/Returns Mean                   1408.53
exploration/Returns Std                       0
exploration/Returns Max                    1408.53
exploration/Returns Min                    1408.53
exploration/Num Paths                         1
exploration/Average Returns                1408.53
evaluation_0/num steps total                  1.41964e+06
evaluation_0/num paths total               4707
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.65958
evaluation_0/Rewards Std                      0.851371
evaluation_0/Rewards Max                      5.58342
evaluation_0/Rewards Min                     -0.731646
evaluation_0/Returns Mean                  3659.58
evaluation_0/Returns Std                    137.72
evaluation_0/Returns Max                   3779.29
evaluation_0/Returns Min                   3359.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3659.58
time/epoch (s)                                0
time/total (s)                             2488.47
Epoch                                       181
---------------------------------------  ----------------
2022-11-16 16:57:03.580291 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 182 finished
---------------------------------------  ----------------
epoch                                       182
total_step                               187000
replay_pool/size                         187000
trainer/alpha                                 0.057903
trainer/alpha_loss                            0.997294
trainer/entropy                              -6.35005
trainer/qf_loss                              11.4882
trainer/policy_loss                        -227.162
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         227.529
trainer/entropy_penalty                      -0.367686
trainer/entropy_percentage                   -0.00161599
trainer/Q1Pred Mean                         226.788
trainer/Q1Pred Std                           56.6817
trainer/Q1Pred Max                          294.601
trainer/Q1Pred Min                           11.4008
trainer/Q2Pred Mean                         226.614
trainer/Q2Pred Std                           56.7461
trainer/Q2Pred Max                          290.986
trainer/Q2Pred Min                           11.5166
trainer/QTargetWithReg Mean                 226.898
trainer/QTargetWithReg Std                   57.1454
trainer/QTargetWithReg Max                  294.609
trainer/QTargetWithReg Min                    8.56726
trainer/PolicyLossWithoutReg Mean           227.529
trainer/PolicyLossWithoutReg Std             56.477
trainer/PolicyLossWithoutReg Max            297.121
trainer/PolicyLossWithoutReg Min             12.2382
exploration/num steps total              187000
exploration/num paths total                 907
exploration/path length this epoch Mean     529
exploration/path length this epoch Std        0
exploration/path length this epoch Max      529
exploration/path length this epoch Min      529
exploration/Rewards Mean                      3.77282
exploration/Rewards Std                       1.2365
exploration/Rewards Max                       6.57321
exploration/Rewards Min                      -0.678252
exploration/Returns Mean                   1995.82
exploration/Returns Std                       0
exploration/Returns Max                    1995.82
exploration/Returns Min                    1995.82
exploration/Num Paths                         1
exploration/Average Returns                1995.82
evaluation_0/num steps total                  1.42745e+06
evaluation_0/num paths total               4716
evaluation_0/path length Mean               867.556
evaluation_0/path length Std                253.542
evaluation_0/path length Max               1000
evaluation_0/path length Min                290
evaluation_0/Rewards Mean                     3.54496
evaluation_0/Rewards Std                      1.00591
evaluation_0/Rewards Max                      6.19793
evaluation_0/Rewards Min                     -0.99619
evaluation_0/Returns Mean                  3075.45
evaluation_0/Returns Std                   1022.83
evaluation_0/Returns Max                   3953.72
evaluation_0/Returns Min                    767.385
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3075.45
time/epoch (s)                                0
time/total (s)                             2540.71
Epoch                                       182
---------------------------------------  ----------------
2022-11-16 16:58:36.313864 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 183 finished
---------------------------------------  ----------------
epoch                                       183
total_step                               188000
replay_pool/size                         188000
trainer/alpha                                 0.0578226
trainer/alpha_loss                           -0.0394923
trainer/entropy                              -5.98614
trainer/qf_loss                              14.567
trainer/policy_loss                        -222.84
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         223.186
trainer/entropy_penalty                      -0.346134
trainer/entropy_percentage                   -0.00155088
trainer/Q1Pred Mean                         222.556
trainer/Q1Pred Std                           62.2959
trainer/Q1Pred Max                          289.025
trainer/Q1Pred Min                          -18.1847
trainer/Q2Pred Mean                         222.603
trainer/Q2Pred Std                           62.5213
trainer/Q2Pred Max                          289.585
trainer/Q2Pred Min                          -19.6461
trainer/QTargetWithReg Mean                 222.708
trainer/QTargetWithReg Std                   62.8878
trainer/QTargetWithReg Max                  290.674
trainer/QTargetWithReg Min                  -12.8989
trainer/PolicyLossWithoutReg Mean           223.186
trainer/PolicyLossWithoutReg Std             61.6212
trainer/PolicyLossWithoutReg Max            288.401
trainer/PolicyLossWithoutReg Min            -15.8112
exploration/num steps total              188000
exploration/num paths total                 908
exploration/path length this epoch Mean     811
exploration/path length this epoch Std        0
exploration/path length this epoch Max      811
exploration/path length this epoch Min      811
exploration/Rewards Mean                      3.87545
exploration/Rewards Std                       1.08243
exploration/Rewards Max                       6.97118
exploration/Rewards Min                      -0.675693
exploration/Returns Mean                   3142.99
exploration/Returns Std                       0
exploration/Returns Max                    3142.99
exploration/Returns Min                    3142.99
exploration/Num Paths                         1
exploration/Average Returns                3142.99
evaluation_0/num steps total                  1.43523e+06
evaluation_0/num paths total               4724
evaluation_0/path length Mean               971.875
evaluation_0/path length Std                 74.4118
evaluation_0/path length Max               1000
evaluation_0/path length Min                775
evaluation_0/Rewards Mean                     3.61468
evaluation_0/Rewards Std                      0.856632
evaluation_0/Rewards Max                      5.95171
evaluation_0/Rewards Min                     -0.627905
evaluation_0/Returns Mean                  3513.02
evaluation_0/Returns Std                    330.822
evaluation_0/Returns Max                   3767.48
evaluation_0/Returns Min                   2733.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3513.02
time/epoch (s)                                0
time/total (s)                             2633.45
Epoch                                       183
---------------------------------------  ----------------
2022-11-16 16:59:35.428408 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 184 finished
---------------------------------------  ----------------
epoch                                       184
total_step                               189000
replay_pool/size                         189000
trainer/alpha                                 0.0563516
trainer/alpha_loss                           -1.3204
trainer/entropy                              -5.54088
trainer/qf_loss                              15.0317
trainer/policy_loss                        -227.242
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         227.554
trainer/entropy_penalty                      -0.312237
trainer/entropy_percentage                   -0.00137215
trainer/Q1Pred Mean                         225.755
trainer/Q1Pred Std                           61.4528
trainer/Q1Pred Max                          301.78
trainer/Q1Pred Min                           -3.83425
trainer/Q2Pred Mean                         226.217
trainer/Q2Pred Std                           61.6824
trainer/Q2Pred Max                          302.892
trainer/Q2Pred Min                           -4.82585
trainer/QTargetWithReg Mean                 226.411
trainer/QTargetWithReg Std                   61.45
trainer/QTargetWithReg Max                  302.557
trainer/QTargetWithReg Min                    1.09381
trainer/PolicyLossWithoutReg Mean           227.554
trainer/PolicyLossWithoutReg Std             61.1045
trainer/PolicyLossWithoutReg Max            303.603
trainer/PolicyLossWithoutReg Min             -4.303
exploration/num steps total              189000
exploration/num paths total                 909
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.74265
exploration/Rewards Std                       0.932305
exploration/Rewards Max                       6.41908
exploration/Rewards Min                      -0.666945
exploration/Returns Mean                   3742.65
exploration/Returns Std                       0
exploration/Returns Max                    3742.65
exploration/Returns Min                    3742.65
exploration/Num Paths                         1
exploration/Average Returns                3742.65
evaluation_0/num steps total                  1.44323e+06
evaluation_0/num paths total               4732
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.51253
evaluation_0/Rewards Std                      1.14803
evaluation_0/Rewards Max                      6.49797
evaluation_0/Rewards Min                     -2.44871
evaluation_0/Returns Mean                  3512.53
evaluation_0/Returns Std                    228.46
evaluation_0/Returns Max                   3779.93
evaluation_0/Returns Min                   3125.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3512.53
time/epoch (s)                                0
time/total (s)                             2692.56
Epoch                                       184
---------------------------------------  ----------------
2022-11-16 17:00:27.266997 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 185 finished
---------------------------------------  ----------------
epoch                                       185
total_step                               190000
replay_pool/size                         190000
trainer/alpha                                 0.0580839
trainer/alpha_loss                            0.0622076
trainer/entropy                              -6.02186
trainer/qf_loss                              10.4818
trainer/policy_loss                        -229.434
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         229.784
trainer/entropy_penalty                      -0.349773
trainer/entropy_percentage                   -0.00152218
trainer/Q1Pred Mean                         228.985
trainer/Q1Pred Std                           57.8315
trainer/Q1Pred Max                          308.947
trainer/Q1Pred Min                            3.76835
trainer/Q2Pred Mean                         229.173
trainer/Q2Pred Std                           58.5163
trainer/Q2Pred Max                          312.362
trainer/Q2Pred Min                            2.51668
trainer/QTargetWithReg Mean                 228.997
trainer/QTargetWithReg Std                   58.2027
trainer/QTargetWithReg Max                  305.252
trainer/QTargetWithReg Min                    0.654926
trainer/PolicyLossWithoutReg Mean           229.784
trainer/PolicyLossWithoutReg Std             57.0852
trainer/PolicyLossWithoutReg Max            309.465
trainer/PolicyLossWithoutReg Min            -17.7474
exploration/num steps total              190000
exploration/num paths total                 910
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.51735
exploration/Rewards Std                       0.887312
exploration/Rewards Max                       5.8898
exploration/Rewards Min                      -0.633437
exploration/Returns Mean                   3517.35
exploration/Returns Std                       0
exploration/Returns Max                    3517.35
exploration/Returns Min                    3517.35
exploration/Num Paths                         1
exploration/Average Returns                3517.35
evaluation_0/num steps total                  1.45110e+06
evaluation_0/num paths total               4740
evaluation_0/path length Mean               984.875
evaluation_0/path length Std                 40.017
evaluation_0/path length Max               1000
evaluation_0/path length Min                879
evaluation_0/Rewards Mean                     3.64458
evaluation_0/Rewards Std                      0.962952
evaluation_0/Rewards Max                      6.45197
evaluation_0/Rewards Min                     -0.562217
evaluation_0/Returns Mean                  3589.46
evaluation_0/Returns Std                    182.084
evaluation_0/Returns Max                   3769.81
evaluation_0/Returns Min                   3150.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3589.46
time/epoch (s)                                0
time/total (s)                             2744.4
Epoch                                       185
---------------------------------------  ----------------
2022-11-16 17:00:46.772578 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 186 finished
---------------------------------------  ----------------
epoch                                       186
total_step                               191000
replay_pool/size                         191000
trainer/alpha                                 0.0593884
trainer/alpha_loss                           -0.705494
trainer/entropy                              -5.75013
trainer/qf_loss                              11.8828
trainer/policy_loss                        -232.571
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         232.913
trainer/entropy_penalty                      -0.341491
trainer/entropy_percentage                   -0.00146618
trainer/Q1Pred Mean                         232.777
trainer/Q1Pred Std                           54.0982
trainer/Q1Pred Max                          303.859
trainer/Q1Pred Min                           -0.461216
trainer/Q2Pred Mean                         231.796
trainer/Q2Pred Std                           54.093
trainer/Q2Pred Max                          307.895
trainer/Q2Pred Min                            0.868091
trainer/QTargetWithReg Mean                 231.636
trainer/QTargetWithReg Std                   54.3064
trainer/QTargetWithReg Max                  309.886
trainer/QTargetWithReg Min                    1.9713
trainer/PolicyLossWithoutReg Mean           232.913
trainer/PolicyLossWithoutReg Std             53.1757
trainer/PolicyLossWithoutReg Max            302.337
trainer/PolicyLossWithoutReg Min              1.27364
exploration/num steps total              191000
exploration/num paths total                 911
exploration/path length this epoch Mean     886
exploration/path length this epoch Std        0
exploration/path length this epoch Max      886
exploration/path length this epoch Min      886
exploration/Rewards Mean                      3.41194
exploration/Rewards Std                       1.05335
exploration/Rewards Max                       5.65826
exploration/Rewards Min                      -0.563252
exploration/Returns Mean                   3022.98
exploration/Returns Std                       0
exploration/Returns Max                    3022.98
exploration/Returns Min                    3022.98
exploration/Num Paths                         1
exploration/Average Returns                3022.98
evaluation_0/num steps total                  1.45884e+06
evaluation_0/num paths total               4748
evaluation_0/path length Mean               967
evaluation_0/path length Std                 87.3098
evaluation_0/path length Max               1000
evaluation_0/path length Min                736
evaluation_0/Rewards Mean                     3.41583
evaluation_0/Rewards Std                      0.834961
evaluation_0/Rewards Max                      6.49071
evaluation_0/Rewards Min                     -0.540759
evaluation_0/Returns Mean                  3303.11
evaluation_0/Returns Std                    249.503
evaluation_0/Returns Max                   3487.21
evaluation_0/Returns Min                   2669.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3303.11
time/epoch (s)                                0
time/total (s)                             2763.9
Epoch                                       186
---------------------------------------  ----------------
2022-11-16 17:00:59.274873 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 187 finished
---------------------------------------  ----------------
epoch                                       187
total_step                               192000
replay_pool/size                         192000
trainer/alpha                                 0.058345
trainer/alpha_loss                           -0.106284
trainer/entropy                              -5.96259
trainer/qf_loss                              11.6891
trainer/policy_loss                        -229.379
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         229.727
trainer/entropy_penalty                      -0.347887
trainer/entropy_percentage                   -0.00151435
trainer/Q1Pred Mean                         228.453
trainer/Q1Pred Std                           64.2804
trainer/Q1Pred Max                          302.942
trainer/Q1Pred Min                           -4.90141
trainer/Q2Pred Mean                         228.409
trainer/Q2Pred Std                           63.5184
trainer/Q2Pred Max                          299.57
trainer/Q2Pred Min                           -3.17532
trainer/QTargetWithReg Mean                 227.77
trainer/QTargetWithReg Std                   64.0727
trainer/QTargetWithReg Max                  300.524
trainer/QTargetWithReg Min                   -3.27828
trainer/PolicyLossWithoutReg Mean           229.727
trainer/PolicyLossWithoutReg Std             61.7394
trainer/PolicyLossWithoutReg Max            299.644
trainer/PolicyLossWithoutReg Min             -1.48495
exploration/num steps total              192000
exploration/num paths total                 912
exploration/path length this epoch Mean     690
exploration/path length this epoch Std        0
exploration/path length this epoch Max      690
exploration/path length this epoch Min      690
exploration/Rewards Mean                      3.90874
exploration/Rewards Std                       1.3092
exploration/Rewards Max                       7.52104
exploration/Rewards Min                      -0.381243
exploration/Returns Mean                   2697.03
exploration/Returns Std                       0
exploration/Returns Max                    2697.03
exploration/Returns Min                    2697.03
exploration/Num Paths                         1
exploration/Average Returns                2697.03
evaluation_0/num steps total                  1.46616e+06
evaluation_0/num paths total               4757
evaluation_0/path length Mean               812.778
evaluation_0/path length Std                350.263
evaluation_0/path length Max               1000
evaluation_0/path length Min                155
evaluation_0/Rewards Mean                     3.7352
evaluation_0/Rewards Std                      1.01508
evaluation_0/Rewards Max                      5.88065
evaluation_0/Rewards Min                     -3.41213
evaluation_0/Returns Mean                  3035.89
evaluation_0/Returns Std                   1464.15
evaluation_0/Returns Max                   3935.29
evaluation_0/Returns Min                    290.36
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3035.89
time/epoch (s)                                0
time/total (s)                             2776.4
Epoch                                       187
---------------------------------------  ----------------
2022-11-16 17:01:57.803647 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 188 finished
---------------------------------------  ----------------
epoch                                       188
total_step                               193000
replay_pool/size                         193000
trainer/alpha                                 0.0594507
trainer/alpha_loss                           -0.592809
trainer/entropy                              -5.78998
trainer/qf_loss                              16.6937
trainer/policy_loss                        -236.947
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         237.291
trainer/entropy_penalty                      -0.344218
trainer/entropy_percentage                   -0.00145062
trainer/Q1Pred Mean                         236
trainer/Q1Pred Std                           50.3836
trainer/Q1Pred Max                          304.612
trainer/Q1Pred Min                           13.3837
trainer/Q2Pred Mean                         235.873
trainer/Q2Pred Std                           50.944
trainer/Q2Pred Max                          305.764
trainer/Q2Pred Min                           12.7077
trainer/QTargetWithReg Mean                 235.501
trainer/QTargetWithReg Std                   50.5816
trainer/QTargetWithReg Max                  305.805
trainer/QTargetWithReg Min                   16.7654
trainer/PolicyLossWithoutReg Mean           237.291
trainer/PolicyLossWithoutReg Std             49.1588
trainer/PolicyLossWithoutReg Max            304.236
trainer/PolicyLossWithoutReg Min             14.2343
exploration/num steps total              193000
exploration/num paths total                 913
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.70523
exploration/Rewards Std                       0.872613
exploration/Rewards Max                       5.9516
exploration/Rewards Min                      -0.694845
exploration/Returns Mean                   3705.23
exploration/Returns Std                       0
exploration/Returns Max                    3705.23
exploration/Returns Min                    3705.23
exploration/Num Paths                         1
exploration/Average Returns                3705.23
evaluation_0/num steps total                  1.47416e+06
evaluation_0/num paths total               4765
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.76041
evaluation_0/Rewards Std                      0.883529
evaluation_0/Rewards Max                      6.41475
evaluation_0/Rewards Min                     -0.503578
evaluation_0/Returns Mean                  3760.41
evaluation_0/Returns Std                     91.8059
evaluation_0/Returns Max                   3978.96
evaluation_0/Returns Min                   3680.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3760.41
time/epoch (s)                                0
time/total (s)                             2834.95
Epoch                                       188
---------------------------------------  ----------------
2022-11-16 17:03:32.385399 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 189 finished
---------------------------------------  ----------------
epoch                                       189
total_step                               194000
replay_pool/size                         194000
trainer/alpha                                 0.0595788
trainer/alpha_loss                            0.263043
trainer/entropy                              -6.09326
trainer/qf_loss                              13.7543
trainer/policy_loss                        -229.832
trainer/adversary_policy_loss                10.8248
trainer/policy_loss_without_entropy         230.195
trainer/entropy_penalty                      -0.36303
trainer/entropy_percentage                   -0.00157705
trainer/Q1Pred Mean                         229.31
trainer/Q1Pred Std                           64.4395
trainer/Q1Pred Max                          308.428
trainer/Q1Pred Min                            1.79808
trainer/Q2Pred Mean                         228.983
trainer/Q2Pred Std                           64.6499
trainer/Q2Pred Max                          303.672
trainer/Q2Pred Min                           -0.776178
trainer/QTargetWithReg Mean                 228.567
trainer/QTargetWithReg Std                   64.5144
trainer/QTargetWithReg Max                  304.657
trainer/QTargetWithReg Min                    3.65977
trainer/PolicyLossWithoutReg Mean           230.195
trainer/PolicyLossWithoutReg Std             63.8049
trainer/PolicyLossWithoutReg Max            303.876
trainer/PolicyLossWithoutReg Min              6.29278
exploration/num steps total              194000
exploration/num paths total                 915
exploration/path length this epoch Mean     480.5
exploration/path length this epoch Std        7.5
exploration/path length this epoch Max      488
exploration/path length this epoch Min      473
exploration/Rewards Mean                      3.66865
exploration/Rewards Std                       1.25368
exploration/Rewards Max                       7.80567
exploration/Rewards Min                      -0.644798
exploration/Returns Mean                   1762.79
exploration/Returns Std                      23.0143
exploration/Returns Max                    1785.8
exploration/Returns Min                    1739.77
exploration/Num Paths                         2
exploration/Average Returns                1762.79
evaluation_0/num steps total                  1.48127e+06
evaluation_0/num paths total               4773
evaluation_0/path length Mean               889.125
evaluation_0/path length Std                277.452
evaluation_0/path length Max               1000
evaluation_0/path length Min                156
evaluation_0/Rewards Mean                     3.39625
evaluation_0/Rewards Std                      1.04606
evaluation_0/Rewards Max                      7.92956
evaluation_0/Rewards Min                     -2.59404
evaluation_0/Returns Mean                  3019.69
evaluation_0/Returns Std                    971.062
evaluation_0/Returns Max                   3749.13
evaluation_0/Returns Min                    512.801
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3019.69
time/epoch (s)                                0
time/total (s)                             2929.51
Epoch                                       189
---------------------------------------  ----------------
2022-11-16 17:05:15.961899 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 190 finished
---------------------------------------  ----------------
epoch                                       190
total_step                               195000
replay_pool/size                         195000
trainer/alpha                                 0.0597337
trainer/alpha_loss                            0.574737
trainer/entropy                              -6.20396
trainer/qf_loss                              13.8587
trainer/policy_loss                        -227.718
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         228.089
trainer/entropy_penalty                      -0.370585
trainer/entropy_percentage                   -0.00162474
trainer/Q1Pred Mean                         225.768
trainer/Q1Pred Std                           66.6635
trainer/Q1Pred Max                          306.576
trainer/Q1Pred Min                           -2.96566
trainer/Q2Pred Mean                         225.831
trainer/Q2Pred Std                           66.3049
trainer/Q2Pred Max                          304.542
trainer/Q2Pred Min                            2.49407
trainer/QTargetWithReg Mean                 225.911
trainer/QTargetWithReg Std                   66.1595
trainer/QTargetWithReg Max                  309.589
trainer/QTargetWithReg Min                   -6.64928
trainer/PolicyLossWithoutReg Mean           228.089
trainer/PolicyLossWithoutReg Std             63.706
trainer/PolicyLossWithoutReg Max            304.873
trainer/PolicyLossWithoutReg Min             -0.560665
exploration/num steps total              195000
exploration/num paths total                 917
exploration/path length this epoch Mean     239
exploration/path length this epoch Std       36
exploration/path length this epoch Max      275
exploration/path length this epoch Min      203
exploration/Rewards Mean                      2.67756
exploration/Rewards Std                       1.09126
exploration/Rewards Max                       5.38359
exploration/Rewards Min                      -0.742653
exploration/Returns Mean                    639.937
exploration/Returns Std                      56.4861
exploration/Returns Max                     696.423
exploration/Returns Min                     583.451
exploration/Num Paths                         2
exploration/Average Returns                 639.937
evaluation_0/num steps total                  1.48911e+06
evaluation_0/num paths total               4781
evaluation_0/path length Mean               980.125
evaluation_0/path length Std                 52.5843
evaluation_0/path length Max               1000
evaluation_0/path length Min                841
evaluation_0/Rewards Mean                     4.11925
evaluation_0/Rewards Std                      0.962283
evaluation_0/Rewards Max                      9.12254
evaluation_0/Rewards Min                     -0.597728
evaluation_0/Returns Mean                  4037.38
evaluation_0/Returns Std                    220.515
evaluation_0/Returns Max                   4195.05
evaluation_0/Returns Min                   3468.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4037.38
time/epoch (s)                                0
time/total (s)                             3033.09
Epoch                                       190
---------------------------------------  ----------------
2022-11-16 17:06:55.169239 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 191 finished
---------------------------------------  ---------------
epoch                                       191
total_step                               196000
replay_pool/size                         196000
trainer/alpha                                 0.0609903
trainer/alpha_loss                            0.204178
trainer/entropy                              -6.073
trainer/qf_loss                              14.6608
trainer/policy_loss                        -229.865
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         230.236
trainer/entropy_penalty                      -0.370394
trainer/entropy_percentage                   -0.00160876
trainer/Q1Pred Mean                         227.594
trainer/Q1Pred Std                           62.256
trainer/Q1Pred Max                          299.598
trainer/Q1Pred Min                          -48.4072
trainer/Q2Pred Mean                         227.508
trainer/Q2Pred Std                           63.0179
trainer/Q2Pred Max                          302.572
trainer/Q2Pred Min                          -64.7257
trainer/QTargetWithReg Mean                 226.757
trainer/QTargetWithReg Std                   62.8199
trainer/QTargetWithReg Max                  297.946
trainer/QTargetWithReg Min                  -46.0794
trainer/PolicyLossWithoutReg Mean           230.236
trainer/PolicyLossWithoutReg Std             57.7087
trainer/PolicyLossWithoutReg Max            300.392
trainer/PolicyLossWithoutReg Min              3.06022
exploration/num steps total              196000
exploration/num paths total                 918
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.40775
exploration/Rewards Std                       1.26178
exploration/Rewards Max                       6.71357
exploration/Rewards Min                      -0.702105
exploration/Returns Mean                   3407.75
exploration/Returns Std                       0
exploration/Returns Max                    3407.75
exploration/Returns Min                    3407.75
exploration/Num Paths                         1
exploration/Average Returns                3407.75
evaluation_0/num steps total                  1.4962e+06
evaluation_0/num paths total               4789
evaluation_0/path length Mean               886.25
evaluation_0/path length Std                300.954
evaluation_0/path length Max               1000
evaluation_0/path length Min                 90
evaluation_0/Rewards Mean                     3.93674
evaluation_0/Rewards Std                      0.895914
evaluation_0/Rewards Max                      6.08234
evaluation_0/Rewards Min                     -0.479035
evaluation_0/Returns Mean                  3488.94
evaluation_0/Returns Std                   1231.77
evaluation_0/Returns Max                   4041.95
evaluation_0/Returns Min                    232.561
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3488.94
time/epoch (s)                                0
time/total (s)                             3132.3
Epoch                                       191
---------------------------------------  ---------------
2022-11-16 17:07:06.390512 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 192 finished
---------------------------------------  ---------------
epoch                                       192
total_step                               197000
replay_pool/size                         197000
trainer/alpha                                 0.0595712
trainer/alpha_loss                           -0.475971
trainer/entropy                              -5.83125
trainer/qf_loss                              18.2069
trainer/policy_loss                        -236.002
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         236.349
trainer/entropy_penalty                      -0.347375
trainer/entropy_percentage                   -0.00146975
trainer/Q1Pred Mean                         234.958
trainer/Q1Pred Std                           56.7485
trainer/Q1Pred Max                          305.257
trainer/Q1Pred Min                           10.598
trainer/Q2Pred Mean                         234.915
trainer/Q2Pred Std                           56.3895
trainer/Q2Pred Max                          305.525
trainer/Q2Pred Min                            3.23107
trainer/QTargetWithReg Mean                 235.523
trainer/QTargetWithReg Std                   55.813
trainer/QTargetWithReg Max                  306.364
trainer/QTargetWithReg Min                    3.79346
trainer/PolicyLossWithoutReg Mean           236.349
trainer/PolicyLossWithoutReg Std             55.6934
trainer/PolicyLossWithoutReg Max            305.955
trainer/PolicyLossWithoutReg Min              6.42141
exploration/num steps total              197000
exploration/num paths total                 919
exploration/path length this epoch Mean     159
exploration/path length this epoch Std        0
exploration/path length this epoch Max      159
exploration/path length this epoch Min      159
exploration/Rewards Mean                      3.47885
exploration/Rewards Std                       1.90353
exploration/Rewards Max                       8.00661
exploration/Rewards Min                      -0.567043
exploration/Returns Mean                    553.137
exploration/Returns Std                       0
exploration/Returns Max                     553.137
exploration/Returns Min                     553.137
exploration/Num Paths                         1
exploration/Average Returns                 553.137
evaluation_0/num steps total                  1.5042e+06
evaluation_0/num paths total               4797
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.65468
evaluation_0/Rewards Std                      0.836988
evaluation_0/Rewards Max                      5.69962
evaluation_0/Rewards Min                     -0.552803
evaluation_0/Returns Mean                  3654.68
evaluation_0/Returns Std                     93.4667
evaluation_0/Returns Max                   3825.57
evaluation_0/Returns Min                   3498.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3654.68
time/epoch (s)                                0
time/total (s)                             3143.51
Epoch                                       192
---------------------------------------  ---------------
2022-11-16 17:07:18.659489 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 193 finished
---------------------------------------  ---------------
epoch                                       193
total_step                               198000
replay_pool/size                         198000
trainer/alpha                                 0.0591709
trainer/alpha_loss                           -0.547828
trainer/entropy                              -5.80624
trainer/qf_loss                              14.7448
trainer/policy_loss                        -229.903
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         230.247
trainer/entropy_penalty                      -0.34356
trainer/entropy_percentage                   -0.00149214
trainer/Q1Pred Mean                         229.421
trainer/Q1Pred Std                           60.4716
trainer/Q1Pred Max                          307.187
trainer/Q1Pred Min                          -19.2402
trainer/Q2Pred Mean                         229.028
trainer/Q2Pred Std                           60.0438
trainer/Q2Pred Max                          303.722
trainer/Q2Pred Min                          -12.5909
trainer/QTargetWithReg Mean                 229.182
trainer/QTargetWithReg Std                   59.758
trainer/QTargetWithReg Max                  305.59
trainer/QTargetWithReg Min                    2.90309
trainer/PolicyLossWithoutReg Mean           230.247
trainer/PolicyLossWithoutReg Std             59.2663
trainer/PolicyLossWithoutReg Max            304.895
trainer/PolicyLossWithoutReg Min            -13.8666
exploration/num steps total              198000
exploration/num paths total                 920
exploration/path length this epoch Mean     861
exploration/path length this epoch Std        0
exploration/path length this epoch Max      861
exploration/path length this epoch Min      861
exploration/Rewards Mean                      3.9029
exploration/Rewards Std                       0.932159
exploration/Rewards Max                       6.7264
exploration/Rewards Min                      -0.471406
exploration/Returns Mean                   3360.39
exploration/Returns Std                       0
exploration/Returns Max                    3360.39
exploration/Returns Min                    3360.39
exploration/Num Paths                         1
exploration/Average Returns                3360.39
evaluation_0/num steps total                  1.5122e+06
evaluation_0/num paths total               4805
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.61626
evaluation_0/Rewards Std                      0.948578
evaluation_0/Rewards Max                      6.1664
evaluation_0/Rewards Min                     -0.446782
evaluation_0/Returns Mean                  3616.26
evaluation_0/Returns Std                     93.5979
evaluation_0/Returns Max                   3795.19
evaluation_0/Returns Min                   3481.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3616.26
time/epoch (s)                                0
time/total (s)                             3155.78
Epoch                                       193
---------------------------------------  ---------------
2022-11-16 17:07:31.746349 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 194 finished
---------------------------------------  ---------------
epoch                                       194
total_step                               199000
replay_pool/size                         199000
trainer/alpha                                 0.0597371
trainer/alpha_loss                            0.763413
trainer/entropy                              -6.27092
trainer/qf_loss                              20.3066
trainer/policy_loss                        -226.417
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         226.792
trainer/entropy_penalty                      -0.374607
trainer/entropy_percentage                   -0.00165177
trainer/Q1Pred Mean                         224.843
trainer/Q1Pred Std                           63.8948
trainer/Q1Pred Max                          310.442
trainer/Q1Pred Min                            3.43208
trainer/Q2Pred Mean                         224.764
trainer/Q2Pred Std                           63.8815
trainer/Q2Pred Max                          309.712
trainer/Q2Pred Min                            3.34219
trainer/QTargetWithReg Mean                 224.536
trainer/QTargetWithReg Std                   63.9108
trainer/QTargetWithReg Max                  310.22
trainer/QTargetWithReg Min                    3.39355
trainer/PolicyLossWithoutReg Mean           226.792
trainer/PolicyLossWithoutReg Std             62.023
trainer/PolicyLossWithoutReg Max            309.861
trainer/PolicyLossWithoutReg Min              4.6582
exploration/num steps total              199000
exploration/num paths total                 922
exploration/path length this epoch Mean     421
exploration/path length this epoch Std       79
exploration/path length this epoch Max      500
exploration/path length this epoch Min      342
exploration/Rewards Mean                      3.4523
exploration/Rewards Std                       1.18517
exploration/Rewards Max                       6.69746
exploration/Rewards Min                      -0.646846
exploration/Returns Mean                   1453.42
exploration/Returns Std                     253.248
exploration/Returns Max                    1706.67
exploration/Returns Min                    1200.17
exploration/Num Paths                         2
exploration/Average Returns                1453.42
evaluation_0/num steps total                  1.5202e+06
evaluation_0/num paths total               4813
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.99336
evaluation_0/Rewards Std                      0.799372
evaluation_0/Rewards Max                      6.13595
evaluation_0/Rewards Min                     -0.505554
evaluation_0/Returns Mean                  3993.36
evaluation_0/Returns Std                     74.0254
evaluation_0/Returns Max                   4072.71
evaluation_0/Returns Min                   3855.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3993.36
time/epoch (s)                                0
time/total (s)                             3168.87
Epoch                                       194
---------------------------------------  ---------------
2022-11-16 17:07:45.696021 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 195 finished
---------------------------------------  ----------------
epoch                                       195
total_step                               200000
replay_pool/size                         200000
trainer/alpha                                 0.0602119
trainer/alpha_loss                            0.825567
trainer/entropy                              -6.29381
trainer/qf_loss                              18.4784
trainer/policy_loss                        -229.508
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         229.887
trainer/entropy_penalty                      -0.378963
trainer/entropy_percentage                   -0.00164847
trainer/Q1Pred Mean                         228.378
trainer/Q1Pred Std                           65.1082
trainer/Q1Pred Max                          304.9
trainer/Q1Pred Min                          -77.1584
trainer/Q2Pred Mean                         228.454
trainer/Q2Pred Std                           64.2123
trainer/Q2Pred Max                          309.348
trainer/Q2Pred Min                          -29.8299
trainer/QTargetWithReg Mean                 228.114
trainer/QTargetWithReg Std                   64.8506
trainer/QTargetWithReg Max                  307.273
trainer/QTargetWithReg Min                  -77.5748
trainer/PolicyLossWithoutReg Mean           229.887
trainer/PolicyLossWithoutReg Std             63.1013
trainer/PolicyLossWithoutReg Max            304.843
trainer/PolicyLossWithoutReg Min            -69.1185
exploration/num steps total              200000
exploration/num paths total                 923
exploration/path length this epoch Mean     554
exploration/path length this epoch Std        0
exploration/path length this epoch Max      554
exploration/path length this epoch Min      554
exploration/Rewards Mean                      3.55438
exploration/Rewards Std                       0.949937
exploration/Rewards Max                       6.75996
exploration/Rewards Min                      -0.387075
exploration/Returns Mean                   1969.13
exploration/Returns Std                       0
exploration/Returns Max                    1969.13
exploration/Returns Min                    1969.13
exploration/Num Paths                         1
exploration/Average Returns                1969.13
evaluation_0/num steps total                  1.52732e+06
evaluation_0/num paths total               4821
evaluation_0/path length Mean               889.625
evaluation_0/path length Std                292.025
evaluation_0/path length Max               1000
evaluation_0/path length Min                117
evaluation_0/Rewards Mean                     3.88646
evaluation_0/Rewards Std                      0.896685
evaluation_0/Rewards Max                      6.39113
evaluation_0/Rewards Min                     -0.512617
evaluation_0/Returns Mean                  3457.49
evaluation_0/Returns Std                   1198.62
evaluation_0/Returns Max                   4013.14
evaluation_0/Returns Min                    291.698
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3457.49
time/epoch (s)                                0
time/total (s)                             3182.82
Epoch                                       195
---------------------------------------  ----------------
2022-11-16 17:07:59.678591 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 196 finished
---------------------------------------  ----------------
epoch                                       196
total_step                               201000
replay_pool/size                         201000
trainer/alpha                                 0.0602175
trainer/alpha_loss                            1.5929
trainer/entropy                              -6.56691
trainer/qf_loss                              16.7572
trainer/policy_loss                        -224.056
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         224.451
trainer/entropy_penalty                      -0.395443
trainer/entropy_percentage                   -0.00176182
trainer/Q1Pred Mean                         222.626
trainer/Q1Pred Std                           72.4031
trainer/Q1Pred Max                          307.469
trainer/Q1Pred Min                          -48.0805
trainer/Q2Pred Mean                         222.402
trainer/Q2Pred Std                           71.8216
trainer/Q2Pred Max                          305.838
trainer/Q2Pred Min                          -42.0407
trainer/QTargetWithReg Mean                 222.931
trainer/QTargetWithReg Std                   71.2533
trainer/QTargetWithReg Max                  308.004
trainer/QTargetWithReg Min                  -24.4552
trainer/PolicyLossWithoutReg Mean           224.451
trainer/PolicyLossWithoutReg Std             70.8918
trainer/PolicyLossWithoutReg Max            305.694
trainer/PolicyLossWithoutReg Min            -35.18
exploration/num steps total              201000
exploration/num paths total                 924
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.10433
exploration/Rewards Std                       0.976801
exploration/Rewards Max                       6.63019
exploration/Rewards Min                      -0.435672
exploration/Returns Mean                   4104.33
exploration/Returns Std                       0
exploration/Returns Max                    4104.33
exploration/Returns Min                    4104.33
exploration/Num Paths                         1
exploration/Average Returns                4104.33
evaluation_0/num steps total                  1.53502e+06
evaluation_0/num paths total               4829
evaluation_0/path length Mean               962.625
evaluation_0/path length Std                 81.3402
evaluation_0/path length Max               1000
evaluation_0/path length Min                752
evaluation_0/Rewards Mean                     3.9557
evaluation_0/Rewards Std                      0.785058
evaluation_0/Rewards Max                      7.10242
evaluation_0/Rewards Min                     -0.582152
evaluation_0/Returns Mean                  3807.86
evaluation_0/Returns Std                    367.936
evaluation_0/Returns Max                   4069.42
evaluation_0/Returns Min                   2852.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3807.86
time/epoch (s)                                0
time/total (s)                             3196.8
Epoch                                       196
---------------------------------------  ----------------
2022-11-16 17:08:14.639809 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 197 finished
---------------------------------------  ----------------
epoch                                       197
total_step                               202000
replay_pool/size                         202000
trainer/alpha                                 0.0587591
trainer/alpha_loss                           -2.07715
trainer/entropy                              -5.26711
trainer/qf_loss                              13.3011
trainer/policy_loss                        -237.291
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         237.601
trainer/entropy_penalty                      -0.309491
trainer/entropy_percentage                   -0.00130257
trainer/Q1Pred Mean                         236.446
trainer/Q1Pred Std                           51.3153
trainer/Q1Pred Max                          308.683
trainer/Q1Pred Min                           -1.78001
trainer/Q2Pred Mean                         237.314
trainer/Q2Pred Std                           51.2846
trainer/Q2Pred Max                          310.083
trainer/Q2Pred Min                           -2.34685
trainer/QTargetWithReg Mean                 237.087
trainer/QTargetWithReg Std                   51.3643
trainer/QTargetWithReg Max                  308.513
trainer/QTargetWithReg Min                    0.539181
trainer/PolicyLossWithoutReg Mean           237.601
trainer/PolicyLossWithoutReg Std             50.561
trainer/PolicyLossWithoutReg Max            307.809
trainer/PolicyLossWithoutReg Min             -5.89741
exploration/num steps total              202000
exploration/num paths total                 925
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.86571
exploration/Rewards Std                       0.782531
exploration/Rewards Max                       6.04521
exploration/Rewards Min                      -0.642546
exploration/Returns Mean                   3865.71
exploration/Returns Std                       0
exploration/Returns Max                    3865.71
exploration/Returns Min                    3865.71
exploration/Num Paths                         1
exploration/Average Returns                3865.71
evaluation_0/num steps total                  1.54205e+06
evaluation_0/num paths total               4837
evaluation_0/path length Mean               878.625
evaluation_0/path length Std                167.516
evaluation_0/path length Max               1000
evaluation_0/path length Min                603
evaluation_0/Rewards Mean                     4.0417
evaluation_0/Rewards Std                      0.970609
evaluation_0/Rewards Max                      8.12027
evaluation_0/Rewards Min                     -0.526839
evaluation_0/Returns Mean                  3551.14
evaluation_0/Returns Std                    708.522
evaluation_0/Returns Max                   4169.09
evaluation_0/Returns Min                   2351.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3551.14
time/epoch (s)                                0
time/total (s)                             3211.76
Epoch                                       197
---------------------------------------  ----------------
2022-11-16 17:08:27.027953 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 198 finished
---------------------------------------  ----------------
epoch                                       198
total_step                               203000
replay_pool/size                         203000
trainer/alpha                                 0.0597428
trainer/alpha_loss                           -0.0650714
trainer/entropy                              -5.97691
trainer/qf_loss                              18.6921
trainer/policy_loss                        -231.008
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         231.365
trainer/entropy_penalty                      -0.357077
trainer/entropy_percentage                   -0.00154335
trainer/Q1Pred Mean                         229.57
trainer/Q1Pred Std                           66.5092
trainer/Q1Pred Max                          309.851
trainer/Q1Pred Min                           -1.85039
trainer/Q2Pred Mean                         229.735
trainer/Q2Pred Std                           66.0283
trainer/Q2Pred Max                          312.444
trainer/Q2Pred Min                           -2.88997
trainer/QTargetWithReg Mean                 230.416
trainer/QTargetWithReg Std                   67.1703
trainer/QTargetWithReg Max                  317.665
trainer/QTargetWithReg Min                    0.578625
trainer/PolicyLossWithoutReg Mean           231.365
trainer/PolicyLossWithoutReg Std             63.9712
trainer/PolicyLossWithoutReg Max            311.43
trainer/PolicyLossWithoutReg Min              5.46118
exploration/num steps total              203000
exploration/num paths total                 926
exploration/path length this epoch Mean     956
exploration/path length this epoch Std        0
exploration/path length this epoch Max      956
exploration/path length this epoch Min      956
exploration/Rewards Mean                      3.82683
exploration/Rewards Std                       0.835027
exploration/Rewards Max                       5.57522
exploration/Rewards Min                      -0.526693
exploration/Returns Mean                   3658.44
exploration/Returns Std                       0
exploration/Returns Max                    3658.44
exploration/Returns Min                    3658.44
exploration/Num Paths                         1
exploration/Average Returns                3658.44
evaluation_0/num steps total                  1.55005e+06
evaluation_0/num paths total               4845
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.88887
evaluation_0/Rewards Std                      0.844213
evaluation_0/Rewards Max                      6.44666
evaluation_0/Rewards Min                     -0.545013
evaluation_0/Returns Mean                  3888.87
evaluation_0/Returns Std                     98.2143
evaluation_0/Returns Max                   4038.84
evaluation_0/Returns Min                   3778.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3888.87
time/epoch (s)                                0
time/total (s)                             3224.15
Epoch                                       198
---------------------------------------  ----------------
2022-11-16 17:08:42.364006 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 199 finished
---------------------------------------  ----------------
epoch                                       199
total_step                               204000
replay_pool/size                         204000
trainer/alpha                                 0.0613187
trainer/alpha_loss                            0.250548
trainer/entropy                              -6.08975
trainer/qf_loss                              15.1554
trainer/policy_loss                        -228.136
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         228.51
trainer/entropy_penalty                      -0.373416
trainer/entropy_percentage                   -0.00163413
trainer/Q1Pred Mean                         226.868
trainer/Q1Pred Std                           68.7057
trainer/Q1Pred Max                          316.903
trainer/Q1Pred Min                           -0.625922
trainer/Q2Pred Mean                         227.019
trainer/Q2Pred Std                           68.982
trainer/Q2Pred Max                          320.979
trainer/Q2Pred Min                            2.02588
trainer/QTargetWithReg Mean                 226.887
trainer/QTargetWithReg Std                   68.9238
trainer/QTargetWithReg Max                  314.733
trainer/QTargetWithReg Min                   -1.42223
trainer/PolicyLossWithoutReg Mean           228.51
trainer/PolicyLossWithoutReg Std             67.0338
trainer/PolicyLossWithoutReg Max            317.272
trainer/PolicyLossWithoutReg Min              5.75025
exploration/num steps total              204000
exploration/num paths total                 927
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.86179
exploration/Rewards Std                       0.871835
exploration/Rewards Max                       5.90031
exploration/Rewards Min                      -0.583937
exploration/Returns Mean                   3861.79
exploration/Returns Std                       0
exploration/Returns Max                    3861.79
exploration/Returns Min                    3861.79
exploration/Num Paths                         1
exploration/Average Returns                3861.79
evaluation_0/num steps total                  1.55709e+06
evaluation_0/num paths total               4867
evaluation_0/path length Mean               320.227
evaluation_0/path length Std                364.086
evaluation_0/path length Max               1000
evaluation_0/path length Min                 77
evaluation_0/Rewards Mean                     3.76547
evaluation_0/Rewards Std                      1.21197
evaluation_0/Rewards Max                      8.78313
evaluation_0/Rewards Min                     -0.586258
evaluation_0/Returns Mean                  1205.81
evaluation_0/Returns Std                   1516.66
evaluation_0/Returns Max                   4055.01
evaluation_0/Returns Min                    182.049
evaluation_0/Num Paths                       22
evaluation_0/Average Returns               1205.81
time/epoch (s)                                0
time/total (s)                             3239.48
Epoch                                       199
---------------------------------------  ----------------
2022-11-16 17:08:56.431718 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 200 finished
---------------------------------------  ---------------
epoch                                       200
total_step                               205000
replay_pool/size                         205000
trainer/alpha                                 0.0604245
trainer/alpha_loss                           -0.337447
trainer/entropy                              -5.87976
trainer/qf_loss                              15.5812
trainer/policy_loss                        -246.626
trainer/adversary_policy_loss                11.8104
trainer/policy_loss_without_entropy         246.981
trainer/entropy_penalty                      -0.355282
trainer/entropy_percentage                   -0.0014385
trainer/Q1Pred Mean                         246.503
trainer/Q1Pred Std                           48.0457
trainer/Q1Pred Max                          318.634
trainer/Q1Pred Min                           14.3528
trainer/Q2Pred Mean                         246.635
trainer/Q2Pred Std                           47.8792
trainer/Q2Pred Max                          311.456
trainer/Q2Pred Min                           15.0502
trainer/QTargetWithReg Mean                 246.384
trainer/QTargetWithReg Std                   47.8549
trainer/QTargetWithReg Max                  315.876
trainer/QTargetWithReg Min                   15.7737
trainer/PolicyLossWithoutReg Mean           246.981
trainer/PolicyLossWithoutReg Std             46.549
trainer/PolicyLossWithoutReg Max            311.379
trainer/PolicyLossWithoutReg Min             15.7573
exploration/num steps total              205000
exploration/num paths total                 928
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.89316
exploration/Rewards Std                       0.987569
exploration/Rewards Max                       5.90119
exploration/Rewards Min                      -0.585959
exploration/Returns Mean                   3893.16
exploration/Returns Std                       0
exploration/Returns Max                    3893.16
exploration/Returns Min                    3893.16
exploration/Num Paths                         1
exploration/Average Returns                3893.16
evaluation_0/num steps total                  1.5647e+06
evaluation_0/num paths total               4875
evaluation_0/path length Mean               950.375
evaluation_0/path length Std                115.901
evaluation_0/path length Max               1000
evaluation_0/path length Min                646
evaluation_0/Rewards Mean                     3.94548
evaluation_0/Rewards Std                      0.890479
evaluation_0/Rewards Max                      7.16635
evaluation_0/Rewards Min                     -0.528936
evaluation_0/Returns Mean                  3749.69
evaluation_0/Returns Std                    497.487
evaluation_0/Returns Max                   4125.48
evaluation_0/Returns Min                   2460.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3749.69
time/epoch (s)                                0
time/total (s)                             3253.55
Epoch                                       200
---------------------------------------  ---------------
2022-11-16 17:09:08.836649 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 201 finished
---------------------------------------  ---------------
epoch                                       201
total_step                               206000
replay_pool/size                         206000
trainer/alpha                                 0.0620686
trainer/alpha_loss                            0.775421
trainer/entropy                              -6.27898
trainer/qf_loss                              19.6809
trainer/policy_loss                        -234.519
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         234.909
trainer/entropy_penalty                      -0.389728
trainer/entropy_percentage                   -0.00165906
trainer/Q1Pred Mean                         232.946
trainer/Q1Pred Std                           64.6308
trainer/Q1Pred Max                          307.061
trainer/Q1Pred Min                            3.16599
trainer/Q2Pred Mean                         233.684
trainer/Q2Pred Std                           65.0872
trainer/Q2Pred Max                          307.913
trainer/Q2Pred Min                            1.85508
trainer/QTargetWithReg Mean                 233.039
trainer/QTargetWithReg Std                   65.7832
trainer/QTargetWithReg Max                  309.797
trainer/QTargetWithReg Min                  -22.4079
trainer/PolicyLossWithoutReg Mean           234.909
trainer/PolicyLossWithoutReg Std             62.5398
trainer/PolicyLossWithoutReg Max            307.064
trainer/PolicyLossWithoutReg Min              3.45148
exploration/num steps total              206000
exploration/num paths total                 929
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.10149
exploration/Rewards Std                       0.898092
exploration/Rewards Max                       6.24577
exploration/Rewards Min                      -0.677152
exploration/Returns Mean                   4101.49
exploration/Returns Std                       0
exploration/Returns Max                    4101.49
exploration/Returns Min                    4101.49
exploration/Num Paths                         1
exploration/Average Returns                4101.49
evaluation_0/num steps total                  1.5727e+06
evaluation_0/num paths total               4883
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.78412
evaluation_0/Rewards Std                      0.80507
evaluation_0/Rewards Max                      5.64981
evaluation_0/Rewards Min                     -0.61222
evaluation_0/Returns Mean                  3784.12
evaluation_0/Returns Std                     77.3056
evaluation_0/Returns Max                   3864.59
evaluation_0/Returns Min                   3638.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3784.12
time/epoch (s)                                0
time/total (s)                             3265.96
Epoch                                       201
---------------------------------------  ---------------
2022-11-16 17:09:23.616083 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 202 finished
---------------------------------------  ----------------
epoch                                       202
total_step                               207000
replay_pool/size                         207000
trainer/alpha                                 0.0606401
trainer/alpha_loss                            0.415223
trainer/entropy                              -6.14815
trainer/qf_loss                              20.9941
trainer/policy_loss                        -233.627
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         234
trainer/entropy_penalty                      -0.372824
trainer/entropy_percentage                   -0.00159327
trainer/Q1Pred Mean                         232.798
trainer/Q1Pred Std                           60.9477
trainer/Q1Pred Max                          311.434
trainer/Q1Pred Min                            0.127626
trainer/Q2Pred Mean                         232.662
trainer/Q2Pred Std                           60.8319
trainer/Q2Pred Max                          307.578
trainer/Q2Pred Min                            2.06815
trainer/QTargetWithReg Mean                 233.094
trainer/QTargetWithReg Std                   60.3823
trainer/QTargetWithReg Max                  306.156
trainer/QTargetWithReg Min                    3.31533
trainer/PolicyLossWithoutReg Mean           234
trainer/PolicyLossWithoutReg Std             59.4289
trainer/PolicyLossWithoutReg Max            305.473
trainer/PolicyLossWithoutReg Min              3.87859
exploration/num steps total              207000
exploration/num paths total                 930
exploration/path length this epoch Mean     779
exploration/path length this epoch Std        0
exploration/path length this epoch Max      779
exploration/path length this epoch Min      779
exploration/Rewards Mean                      3.68127
exploration/Rewards Std                       1.04875
exploration/Rewards Max                       7.60159
exploration/Rewards Min                      -0.596744
exploration/Returns Mean                   2867.71
exploration/Returns Std                       0
exploration/Returns Max                    2867.71
exploration/Returns Min                    2867.71
exploration/Num Paths                         1
exploration/Average Returns                2867.71
evaluation_0/num steps total                  1.58026e+06
evaluation_0/num paths total               4891
evaluation_0/path length Mean               946
evaluation_0/path length Std                142.871
evaluation_0/path length Max               1000
evaluation_0/path length Min                568
evaluation_0/Rewards Mean                     3.99992
evaluation_0/Rewards Std                      0.906054
evaluation_0/Rewards Max                     10.9794
evaluation_0/Rewards Min                     -0.539033
evaluation_0/Returns Mean                  3783.92
evaluation_0/Returns Std                    593.244
evaluation_0/Returns Max                   4104.77
evaluation_0/Returns Min                   2229.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3783.92
time/epoch (s)                                0
time/total (s)                             3280.73
Epoch                                       202
---------------------------------------  ----------------
2022-11-16 17:09:37.529144 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 203 finished
---------------------------------------  ----------------
epoch                                       203
total_step                               208000
replay_pool/size                         208000
trainer/alpha                                 0.0603103
trainer/alpha_loss                           -0.0977824
trainer/entropy                              -5.96518
trainer/qf_loss                              14.5379
trainer/policy_loss                        -239.248
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         239.608
trainer/entropy_penalty                      -0.359762
trainer/entropy_percentage                   -0.00150146
trainer/Q1Pred Mean                         238.023
trainer/Q1Pred Std                           58.7438
trainer/Q1Pred Max                          322.633
trainer/Q1Pred Min                            1.65665
trainer/Q2Pred Mean                         238.134
trainer/Q2Pred Std                           58.3362
trainer/Q2Pred Max                          320.089
trainer/Q2Pred Min                            3.78902
trainer/QTargetWithReg Mean                 239.095
trainer/QTargetWithReg Std                   58.5811
trainer/QTargetWithReg Max                  323.393
trainer/QTargetWithReg Min                    4.25013
trainer/PolicyLossWithoutReg Mean           239.608
trainer/PolicyLossWithoutReg Std             57.5717
trainer/PolicyLossWithoutReg Max            324.026
trainer/PolicyLossWithoutReg Min              2.29543
exploration/num steps total              208000
exploration/num paths total                 931
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.79725
exploration/Rewards Std                       0.888923
exploration/Rewards Max                       5.65872
exploration/Rewards Min                      -0.632782
exploration/Returns Mean                   3797.25
exploration/Returns Std                       0
exploration/Returns Max                    3797.25
exploration/Returns Min                    3797.25
exploration/Num Paths                         1
exploration/Average Returns                3797.25
evaluation_0/num steps total                  1.58821e+06
evaluation_0/num paths total               4899
evaluation_0/path length Mean               993.625
evaluation_0/path length Std                 16.8667
evaluation_0/path length Max               1000
evaluation_0/path length Min                949
evaluation_0/Rewards Mean                     4.17289
evaluation_0/Rewards Std                      0.954494
evaluation_0/Rewards Max                      9.24698
evaluation_0/Rewards Min                     -0.618294
evaluation_0/Returns Mean                  4146.29
evaluation_0/Returns Std                    136.973
evaluation_0/Returns Max                   4309.24
evaluation_0/Returns Min                   3862.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4146.29
time/epoch (s)                                0
time/total (s)                             3294.65
Epoch                                       203
---------------------------------------  ----------------
2022-11-16 17:09:49.864147 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 204 finished
---------------------------------------  ----------------
epoch                                       204
total_step                               209000
replay_pool/size                         209000
trainer/alpha                                 0.0597674
trainer/alpha_loss                           -1.32241
trainer/entropy                              -5.5306
trainer/qf_loss                              19.7893
trainer/policy_loss                        -239.323
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         239.654
trainer/entropy_penalty                      -0.33055
trainer/entropy_percentage                   -0.00137928
trainer/Q1Pred Mean                         238.227
trainer/Q1Pred Std                           62.5695
trainer/Q1Pred Max                          313.344
trainer/Q1Pred Min                            1.1999
trainer/Q2Pred Mean                         238.475
trainer/Q2Pred Std                           61.7585
trainer/Q2Pred Max                          313.59
trainer/Q2Pred Min                            1.78524
trainer/QTargetWithReg Mean                 238.296
trainer/QTargetWithReg Std                   62.2434
trainer/QTargetWithReg Max                  316.148
trainer/QTargetWithReg Min                    0.435899
trainer/PolicyLossWithoutReg Mean           239.654
trainer/PolicyLossWithoutReg Std             60.9996
trainer/PolicyLossWithoutReg Max            313.151
trainer/PolicyLossWithoutReg Min              2.17097
exploration/num steps total              209000
exploration/num paths total                 932
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.6134
exploration/Rewards Std                       0.880683
exploration/Rewards Max                       5.60128
exploration/Rewards Min                      -0.614071
exploration/Returns Mean                   3613.4
exploration/Returns Std                       0
exploration/Returns Max                    3613.4
exploration/Returns Min                    3613.4
exploration/Num Paths                         1
exploration/Average Returns                3613.4
evaluation_0/num steps total                  1.59621e+06
evaluation_0/num paths total               4907
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.90567
evaluation_0/Rewards Std                      1.00878
evaluation_0/Rewards Max                      9.42989
evaluation_0/Rewards Min                     -0.537693
evaluation_0/Returns Mean                  3905.67
evaluation_0/Returns Std                     92.471
evaluation_0/Returns Max                   4047.21
evaluation_0/Returns Min                   3777.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3905.67
time/epoch (s)                                0
time/total (s)                             3306.98
Epoch                                       204
---------------------------------------  ----------------
2022-11-16 17:10:04.635203 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 205 finished
---------------------------------------  ----------------
epoch                                       205
total_step                               210000
replay_pool/size                         210000
trainer/alpha                                 0.0606748
trainer/alpha_loss                            1.59485
trainer/entropy                              -6.5691
trainer/qf_loss                              21.7357
trainer/policy_loss                        -232.661
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         233.059
trainer/entropy_penalty                      -0.398579
trainer/entropy_percentage                   -0.0017102
trainer/Q1Pred Mean                         231.118
trainer/Q1Pred Std                           66.9894
trainer/Q1Pred Max                          316.118
trainer/Q1Pred Min                          -28.2054
trainer/Q2Pred Mean                         231.048
trainer/Q2Pred Std                           66.7444
trainer/Q2Pred Max                          314.32
trainer/Q2Pred Min                          -16.214
trainer/QTargetWithReg Mean                 232.099
trainer/QTargetWithReg Std                   66.2706
trainer/QTargetWithReg Max                  318.592
trainer/QTargetWithReg Min                   -0.481857
trainer/PolicyLossWithoutReg Mean           233.059
trainer/PolicyLossWithoutReg Std             64.983
trainer/PolicyLossWithoutReg Max            318.039
trainer/PolicyLossWithoutReg Min            -15.9712
exploration/num steps total              210000
exploration/num paths total                 933
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.86444
exploration/Rewards Std                       0.901978
exploration/Rewards Max                       5.89758
exploration/Rewards Min                      -0.565642
exploration/Returns Mean                   3864.44
exploration/Returns Std                       0
exploration/Returns Max                    3864.44
exploration/Returns Min                    3864.44
exploration/Num Paths                         1
exploration/Average Returns                3864.44
evaluation_0/num steps total                  1.60386e+06
evaluation_0/num paths total               4915
evaluation_0/path length Mean               956.625
evaluation_0/path length Std                 75.6355
evaluation_0/path length Max               1000
evaluation_0/path length Min                809
evaluation_0/Rewards Mean                     4.06434
evaluation_0/Rewards Std                      0.934642
evaluation_0/Rewards Max                      7.37525
evaluation_0/Rewards Min                     -0.656157
evaluation_0/Returns Mean                  3888.05
evaluation_0/Returns Std                    426.347
evaluation_0/Returns Max                   4385.24
evaluation_0/Returns Min                   3083.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3888.05
time/epoch (s)                                0
time/total (s)                             3321.75
Epoch                                       205
---------------------------------------  ----------------
2022-11-16 17:10:18.485250 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 206 finished
---------------------------------------  ----------------
epoch                                       206
total_step                               211000
replay_pool/size                         211000
trainer/alpha                                 0.0608383
trainer/alpha_loss                           -0.701743
trainer/entropy                              -5.74934
trainer/qf_loss                              14.5457
trainer/policy_loss                        -243.367
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         243.717
trainer/entropy_penalty                      -0.34978
trainer/entropy_percentage                   -0.00143519
trainer/Q1Pred Mean                         242.352
trainer/Q1Pred Std                           59.9743
trainer/Q1Pred Max                          316.168
trainer/Q1Pred Min                            2.63544
trainer/Q2Pred Mean                         242.281
trainer/Q2Pred Std                           60.1925
trainer/Q2Pred Max                          315.949
trainer/Q2Pred Min                           -1.51418
trainer/QTargetWithReg Mean                 241.984
trainer/QTargetWithReg Std                   60.0874
trainer/QTargetWithReg Max                  316.331
trainer/QTargetWithReg Min                    2.53971
trainer/PolicyLossWithoutReg Mean           243.717
trainer/PolicyLossWithoutReg Std             58.8492
trainer/PolicyLossWithoutReg Max            315.598
trainer/PolicyLossWithoutReg Min              0.647164
exploration/num steps total              211000
exploration/num paths total                 936
exploration/path length this epoch Mean     279
exploration/path length this epoch Std      245.442
exploration/path length this epoch Max      626
exploration/path length this epoch Min       98
exploration/Rewards Mean                      3.3311
exploration/Rewards Std                       1.23203
exploration/Rewards Max                       7.25517
exploration/Rewards Min                      -0.650235
exploration/Returns Mean                    929.376
exploration/Returns Std                     986.065
exploration/Returns Max                    2323.57
exploration/Returns Min                     206.865
exploration/Num Paths                         3
exploration/Average Returns                 929.376
evaluation_0/num steps total                  1.61119e+06
evaluation_0/num paths total               4923
evaluation_0/path length Mean               915.625
evaluation_0/path length Std                169.442
evaluation_0/path length Max               1000
evaluation_0/path length Min                491
evaluation_0/Rewards Mean                     4.04502
evaluation_0/Rewards Std                      1.04838
evaluation_0/Rewards Max                      8.35242
evaluation_0/Rewards Min                     -0.38562
evaluation_0/Returns Mean                  3703.72
evaluation_0/Returns Std                    762.867
evaluation_0/Returns Max                   4200.17
evaluation_0/Returns Min                   1798.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3703.72
time/epoch (s)                                0
time/total (s)                             3335.6
Epoch                                       206
---------------------------------------  ----------------
2022-11-16 17:10:31.265489 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 207 finished
---------------------------------------  ----------------
epoch                                       207
total_step                               212000
replay_pool/size                         212000
trainer/alpha                                 0.0611258
trainer/alpha_loss                            1.47177
trainer/entropy                              -6.52657
trainer/qf_loss                              14.361
trainer/policy_loss                        -237.696
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         238.095
trainer/entropy_penalty                      -0.398942
trainer/entropy_percentage                   -0.00167556
trainer/Q1Pred Mean                         236.954
trainer/Q1Pred Std                           65.2008
trainer/Q1Pred Max                          312.165
trainer/Q1Pred Min                            4.7506
trainer/Q2Pred Mean                         237.206
trainer/Q2Pred Std                           64.8717
trainer/Q2Pred Max                          313.084
trainer/Q2Pred Min                            5.20909
trainer/QTargetWithReg Mean                 236.559
trainer/QTargetWithReg Std                   65.0459
trainer/QTargetWithReg Max                  314.643
trainer/QTargetWithReg Min                    2.12073
trainer/PolicyLossWithoutReg Mean           238.095
trainer/PolicyLossWithoutReg Std             64.0847
trainer/PolicyLossWithoutReg Max            311.793
trainer/PolicyLossWithoutReg Min              7.12335
exploration/num steps total              212000
exploration/num paths total                 938
exploration/path length this epoch Mean     432.5
exploration/path length this epoch Std      237.5
exploration/path length this epoch Max      670
exploration/path length this epoch Min      195
exploration/Rewards Mean                      3.49504
exploration/Rewards Std                       1.13256
exploration/Rewards Max                       5.99961
exploration/Rewards Min                      -0.704058
exploration/Returns Mean                   1511.61
exploration/Returns Std                    1029.04
exploration/Returns Max                    2540.65
exploration/Returns Min                     482.567
exploration/Num Paths                         2
exploration/Average Returns                1511.61
evaluation_0/num steps total                  1.61919e+06
evaluation_0/num paths total               4931
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.85952
evaluation_0/Rewards Std                      0.956764
evaluation_0/Rewards Max                      6.90757
evaluation_0/Rewards Min                     -0.619078
evaluation_0/Returns Mean                  3859.52
evaluation_0/Returns Std                    193.546
evaluation_0/Returns Max                   4126.07
evaluation_0/Returns Min                   3470.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3859.52
time/epoch (s)                                0
time/total (s)                             3348.38
Epoch                                       207
---------------------------------------  ----------------
2022-11-16 17:10:43.874332 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 208 finished
---------------------------------------  ----------------
epoch                                       208
total_step                               213000
replay_pool/size                         213000
trainer/alpha                                 0.0613329
trainer/alpha_loss                            2.00441
trainer/entropy                              -6.71803
trainer/qf_loss                              18.0557
trainer/policy_loss                        -234.808
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         235.22
trainer/entropy_penalty                      -0.412037
trainer/entropy_percentage                   -0.00175171
trainer/Q1Pred Mean                         233.686
trainer/Q1Pred Std                           62.6411
trainer/Q1Pred Max                          307.679
trainer/Q1Pred Min                            7.04657
trainer/Q2Pred Mean                         233.309
trainer/Q2Pred Std                           62.7842
trainer/Q2Pred Max                          307.982
trainer/Q2Pred Min                            4.76797
trainer/QTargetWithReg Mean                 233.447
trainer/QTargetWithReg Std                   62.4333
trainer/QTargetWithReg Max                  308.298
trainer/QTargetWithReg Min                    1.94915
trainer/PolicyLossWithoutReg Mean           235.22
trainer/PolicyLossWithoutReg Std             61.2952
trainer/PolicyLossWithoutReg Max            307.486
trainer/PolicyLossWithoutReg Min              4.76354
exploration/num steps total              213000
exploration/num paths total                 940
exploration/path length this epoch Mean     288.5
exploration/path length this epoch Std      218.5
exploration/path length this epoch Max      507
exploration/path length this epoch Min       70
exploration/Rewards Mean                      3.17071
exploration/Rewards Std                       1.24629
exploration/Rewards Max                       6.61613
exploration/Rewards Min                      -0.640921
exploration/Returns Mean                    914.75
exploration/Returns Std                     767.538
exploration/Returns Max                    1682.29
exploration/Returns Min                     147.212
exploration/Num Paths                         2
exploration/Average Returns                 914.75
evaluation_0/num steps total                  1.62719e+06
evaluation_0/num paths total               4939
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.02814
evaluation_0/Rewards Std                      1.01142
evaluation_0/Rewards Max                      7.08063
evaluation_0/Rewards Min                     -0.378984
evaluation_0/Returns Mean                  4028.14
evaluation_0/Returns Std                    119.847
evaluation_0/Returns Max                   4319.53
evaluation_0/Returns Min                   3916.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4028.14
time/epoch (s)                                0
time/total (s)                             3360.99
Epoch                                       208
---------------------------------------  ----------------
2022-11-16 17:10:57.712591 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 209 finished
---------------------------------------  ----------------
epoch                                       209
total_step                               214000
replay_pool/size                         214000
trainer/alpha                                 0.0617009
trainer/alpha_loss                           -0.370537
trainer/entropy                              -5.86697
trainer/qf_loss                              15.3449
trainer/policy_loss                        -245.007
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         245.369
trainer/entropy_penalty                      -0.361997
trainer/entropy_percentage                   -0.00147532
trainer/Q1Pred Mean                         243.694
trainer/Q1Pred Std                           58.7239
trainer/Q1Pred Max                          312.401
trainer/Q1Pred Min                           -4.90238
trainer/Q2Pred Mean                         243.884
trainer/Q2Pred Std                           58.8064
trainer/Q2Pred Max                          313.263
trainer/Q2Pred Min                          -14.7163
trainer/QTargetWithReg Mean                 243.984
trainer/QTargetWithReg Std                   58.7615
trainer/QTargetWithReg Max                  312.523
trainer/QTargetWithReg Min                   -4.65352
trainer/PolicyLossWithoutReg Mean           245.369
trainer/PolicyLossWithoutReg Std             57.7482
trainer/PolicyLossWithoutReg Max            312.003
trainer/PolicyLossWithoutReg Min            -13.5214
exploration/num steps total              214000
exploration/num paths total                 941
exploration/path length this epoch Mean     815
exploration/path length this epoch Std        0
exploration/path length this epoch Max      815
exploration/path length this epoch Min      815
exploration/Rewards Mean                      3.81888
exploration/Rewards Std                       0.96257
exploration/Rewards Max                       6.00806
exploration/Rewards Min                      -0.280134
exploration/Returns Mean                   3112.39
exploration/Returns Std                       0
exploration/Returns Max                    3112.39
exploration/Returns Min                    3112.39
exploration/Num Paths                         1
exploration/Average Returns                3112.39
evaluation_0/num steps total                  1.63511e+06
evaluation_0/num paths total               4950
evaluation_0/path length Mean               719.909
evaluation_0/path length Std                380.159
evaluation_0/path length Max               1000
evaluation_0/path length Min                147
evaluation_0/Rewards Mean                     3.80651
evaluation_0/Rewards Std                      1.10929
evaluation_0/Rewards Max                      7.33918
evaluation_0/Rewards Min                     -0.53637
evaluation_0/Returns Mean                  2740.34
evaluation_0/Returns Std                   1627.53
evaluation_0/Returns Max                   4048.74
evaluation_0/Returns Min                    305.963
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2740.34
time/epoch (s)                                0
time/total (s)                             3374.83
Epoch                                       209
---------------------------------------  ----------------
2022-11-16 17:11:10.956808 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 210 finished
---------------------------------------  ----------------
epoch                                       210
total_step                               215000
replay_pool/size                         215000
trainer/alpha                                 0.0622331
trainer/alpha_loss                           -0.263162
trainer/entropy                              -5.90523
trainer/qf_loss                              15.6964
trainer/policy_loss                        -239.029
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         239.396
trainer/entropy_penalty                      -0.367501
trainer/entropy_percentage                   -0.00153512
trainer/Q1Pred Mean                         237.9
trainer/Q1Pred Std                           67.1075
trainer/Q1Pred Max                          313.393
trainer/Q1Pred Min                           -0.199352
trainer/Q2Pred Mean                         238.439
trainer/Q2Pred Std                           66.8173
trainer/Q2Pred Max                          314.61
trainer/Q2Pred Min                            8.38742
trainer/QTargetWithReg Mean                 238.165
trainer/QTargetWithReg Std                   66.7978
trainer/QTargetWithReg Max                  315.998
trainer/QTargetWithReg Min                    2.61439
trainer/PolicyLossWithoutReg Mean           239.396
trainer/PolicyLossWithoutReg Std             66.5271
trainer/PolicyLossWithoutReg Max            315.093
trainer/PolicyLossWithoutReg Min              6.63475
exploration/num steps total              215000
exploration/num paths total                 943
exploration/path length this epoch Mean     235.5
exploration/path length this epoch Std      195.5
exploration/path length this epoch Max      431
exploration/path length this epoch Min       40
exploration/Rewards Mean                      3.36676
exploration/Rewards Std                       1.375
exploration/Rewards Max                       6.5728
exploration/Rewards Min                      -0.652577
exploration/Returns Mean                    792.872
exploration/Returns Std                     740.701
exploration/Returns Max                    1533.57
exploration/Returns Min                      52.1704
exploration/Num Paths                         2
exploration/Average Returns                 792.872
evaluation_0/num steps total                  1.64311e+06
evaluation_0/num paths total               4958
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.94194
evaluation_0/Rewards Std                      0.856122
evaluation_0/Rewards Max                      6.3859
evaluation_0/Rewards Min                     -0.55306
evaluation_0/Returns Mean                  3941.94
evaluation_0/Returns Std                    113.858
evaluation_0/Returns Max                   4077.03
evaluation_0/Returns Min                   3689.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3941.94
time/epoch (s)                                0
time/total (s)                             3388.07
Epoch                                       210
---------------------------------------  ----------------
2022-11-16 17:11:24.901084 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 211 finished
---------------------------------------  ----------------
epoch                                       211
total_step                               216000
replay_pool/size                         216000
trainer/alpha                                 0.062415
trainer/alpha_loss                            0.0324515
trainer/entropy                              -6.0117
trainer/qf_loss                              19.2655
trainer/policy_loss                        -246.57
trainer/adversary_policy_loss                11.5668
trainer/policy_loss_without_entropy         246.945
trainer/entropy_penalty                      -0.37522
trainer/entropy_percentage                   -0.00151945
trainer/Q1Pred Mean                         246.173
trainer/Q1Pred Std                           57.2661
trainer/Q1Pred Max                          324.899
trainer/Q1Pred Min                            5.7668
trainer/Q2Pred Mean                         246.289
trainer/Q2Pred Std                           57.6451
trainer/Q2Pred Max                          325.209
trainer/Q2Pred Min                            7.85054
trainer/QTargetWithReg Mean                 244.829
trainer/QTargetWithReg Std                   58.2813
trainer/QTargetWithReg Max                  324.451
trainer/QTargetWithReg Min                    2.99894
trainer/PolicyLossWithoutReg Mean           246.945
trainer/PolicyLossWithoutReg Std             56.0347
trainer/PolicyLossWithoutReg Max            324.953
trainer/PolicyLossWithoutReg Min              5.91018
exploration/num steps total              216000
exploration/num paths total                 944
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.00909
exploration/Rewards Std                       0.883411
exploration/Rewards Max                       5.98723
exploration/Rewards Min                      -0.596826
exploration/Returns Mean                   4009.09
exploration/Returns Std                       0
exploration/Returns Max                    4009.09
exploration/Returns Min                    4009.09
exploration/Num Paths                         1
exploration/Average Returns                4009.09
evaluation_0/num steps total                  1.65086e+06
evaluation_0/num paths total               4968
evaluation_0/path length Mean               774.7
evaluation_0/path length Std                223.95
evaluation_0/path length Max               1000
evaluation_0/path length Min                469
evaluation_0/Rewards Mean                     3.96544
evaluation_0/Rewards Std                      1.08761
evaluation_0/Rewards Max                      9.01961
evaluation_0/Rewards Min                     -0.576262
evaluation_0/Returns Mean                  3072.02
evaluation_0/Returns Std                   1023.09
evaluation_0/Returns Max                   4232.68
evaluation_0/Returns Min                   1801.24
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3072.02
time/epoch (s)                                0
time/total (s)                             3402.02
Epoch                                       211
---------------------------------------  ----------------
2022-11-16 17:11:37.341044 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 212 finished
---------------------------------------  ----------------
epoch                                       212
total_step                               217000
replay_pool/size                         217000
trainer/alpha                                 0.0634856
trainer/alpha_loss                            0.446045
trainer/entropy                              -6.16179
trainer/qf_loss                              12.3471
trainer/policy_loss                        -238.162
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         238.553
trainer/entropy_penalty                      -0.391185
trainer/entropy_percentage                   -0.00163982
trainer/Q1Pred Mean                         236.748
trainer/Q1Pred Std                           68.0653
trainer/Q1Pred Max                          313.168
trainer/Q1Pred Min                           -5.33155
trainer/Q2Pred Mean                         236.895
trainer/Q2Pred Std                           68.0974
trainer/Q2Pred Max                          314.333
trainer/Q2Pred Min                           -8.5181
trainer/QTargetWithReg Mean                 237.512
trainer/QTargetWithReg Std                   68.5218
trainer/QTargetWithReg Max                  314.594
trainer/QTargetWithReg Min                   -6.92343
trainer/PolicyLossWithoutReg Mean           238.553
trainer/PolicyLossWithoutReg Std             66.1021
trainer/PolicyLossWithoutReg Max            312.38
trainer/PolicyLossWithoutReg Min              6.36864
exploration/num steps total              217000
exploration/num paths total                 945
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.96484
exploration/Rewards Std                       0.958481
exploration/Rewards Max                       6.23079
exploration/Rewards Min                      -1.27869
exploration/Returns Mean                   3964.84
exploration/Returns Std                       0
exploration/Returns Max                    3964.84
exploration/Returns Min                    3964.84
exploration/Num Paths                         1
exploration/Average Returns                3964.84
evaluation_0/num steps total                  1.65886e+06
evaluation_0/num paths total               4976
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.83691
evaluation_0/Rewards Std                      0.892563
evaluation_0/Rewards Max                      5.90902
evaluation_0/Rewards Min                     -0.554184
evaluation_0/Returns Mean                  3836.91
evaluation_0/Returns Std                     58.0138
evaluation_0/Returns Max                   3906.07
evaluation_0/Returns Min                   3764.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3836.91
time/epoch (s)                                0
time/total (s)                             3414.46
Epoch                                       212
---------------------------------------  ----------------
2022-11-16 17:11:50.487628 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 213 finished
---------------------------------------  ----------------
epoch                                       213
total_step                               218000
replay_pool/size                         218000
trainer/alpha                                 0.0616925
trainer/alpha_loss                           -1.50426
trainer/entropy                              -5.45996
trainer/qf_loss                              16.5444
trainer/policy_loss                        -238.889
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         239.226
trainer/entropy_penalty                      -0.336839
trainer/entropy_percentage                   -0.00140804
trainer/Q1Pred Mean                         238.506
trainer/Q1Pred Std                           70.1465
trainer/Q1Pred Max                          326.01
trainer/Q1Pred Min                          -22.156
trainer/Q2Pred Mean                         238.738
trainer/Q2Pred Std                           70.1148
trainer/Q2Pred Max                          326.758
trainer/Q2Pred Min                          -18.3453
trainer/QTargetWithReg Mean                 238.361
trainer/QTargetWithReg Std                   70.6939
trainer/QTargetWithReg Max                  329.471
trainer/QTargetWithReg Min                  -17.7837
trainer/PolicyLossWithoutReg Mean           239.226
trainer/PolicyLossWithoutReg Std             69.6461
trainer/PolicyLossWithoutReg Max            325.819
trainer/PolicyLossWithoutReg Min            -11.8669
exploration/num steps total              218000
exploration/num paths total                 946
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.77895
exploration/Rewards Std                       0.843989
exploration/Rewards Max                       6.19631
exploration/Rewards Min                      -0.405328
exploration/Returns Mean                   3778.95
exploration/Returns Std                       0
exploration/Returns Max                    3778.95
exploration/Returns Min                    3778.95
exploration/Num Paths                         1
exploration/Average Returns                3778.95
evaluation_0/num steps total                  1.66686e+06
evaluation_0/num paths total               4984
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.10565
evaluation_0/Rewards Std                      0.903955
evaluation_0/Rewards Max                      6.80736
evaluation_0/Rewards Min                     -0.469407
evaluation_0/Returns Mean                  4105.65
evaluation_0/Returns Std                    133.529
evaluation_0/Returns Max                   4365.74
evaluation_0/Returns Min                   3948.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4105.65
time/epoch (s)                                0
time/total (s)                             3427.6
Epoch                                       213
---------------------------------------  ----------------
2022-11-16 17:12:02.861229 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 214 finished
---------------------------------------  ----------------
epoch                                       214
total_step                               219000
replay_pool/size                         219000
trainer/alpha                                 0.0623949
trainer/alpha_loss                           -0.956841
trainer/entropy                              -5.65509
trainer/qf_loss                              16.4877
trainer/policy_loss                        -249.443
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         249.796
trainer/entropy_penalty                      -0.352849
trainer/entropy_percentage                   -0.00141255
trainer/Q1Pred Mean                         248.024
trainer/Q1Pred Std                           56.5965
trainer/Q1Pred Max                          324.325
trainer/Q1Pred Min                           10.2973
trainer/Q2Pred Mean                         248.575
trainer/Q2Pred Std                           56.4496
trainer/Q2Pred Max                          322.717
trainer/Q2Pred Min                            9.1941
trainer/QTargetWithReg Mean                 248.745
trainer/QTargetWithReg Std                   57.548
trainer/QTargetWithReg Max                  322.519
trainer/QTargetWithReg Min                    1.98424
trainer/PolicyLossWithoutReg Mean           249.796
trainer/PolicyLossWithoutReg Std             54.3018
trainer/PolicyLossWithoutReg Max            321.853
trainer/PolicyLossWithoutReg Min             10.7614
exploration/num steps total              219000
exploration/num paths total                 947
exploration/path length this epoch Mean     101
exploration/path length this epoch Std        0
exploration/path length this epoch Max      101
exploration/path length this epoch Min      101
exploration/Rewards Mean                      2.55365
exploration/Rewards Std                       1.40828
exploration/Rewards Max                       5.05943
exploration/Rewards Min                      -0.580523
exploration/Returns Mean                    257.919
exploration/Returns Std                       0
exploration/Returns Max                     257.919
exploration/Returns Min                     257.919
exploration/Num Paths                         1
exploration/Average Returns                 257.919
evaluation_0/num steps total                  1.67486e+06
evaluation_0/num paths total               4992
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.6686
evaluation_0/Rewards Std                      0.826879
evaluation_0/Rewards Max                      5.98033
evaluation_0/Rewards Min                     -0.600433
evaluation_0/Returns Mean                  3668.6
evaluation_0/Returns Std                    142.875
evaluation_0/Returns Max                   3869.4
evaluation_0/Returns Min                   3411.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3668.6
time/epoch (s)                                0
time/total (s)                             3439.97
Epoch                                       214
---------------------------------------  ----------------
2022-11-16 17:12:16.946136 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 215 finished
---------------------------------------  ----------------
epoch                                       215
total_step                               220000
replay_pool/size                         220000
trainer/alpha                                 0.0614554
trainer/alpha_loss                            0.0987909
trainer/entropy                              -6.03541
trainer/qf_loss                              12.4341
trainer/policy_loss                        -245.529
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         245.9
trainer/entropy_penalty                      -0.370909
trainer/entropy_percentage                   -0.00150837
trainer/Q1Pred Mean                         243.667
trainer/Q1Pred Std                           63.1143
trainer/Q1Pred Max                          315.438
trainer/Q1Pred Min                          -16.6681
trainer/Q2Pred Mean                         243.593
trainer/Q2Pred Std                           63.456
trainer/Q2Pred Max                          314.472
trainer/Q2Pred Min                           -9.45384
trainer/QTargetWithReg Mean                 243.381
trainer/QTargetWithReg Std                   63.9914
trainer/QTargetWithReg Max                  314.993
trainer/QTargetWithReg Min                  -13.2525
trainer/PolicyLossWithoutReg Mean           245.9
trainer/PolicyLossWithoutReg Std             60.6066
trainer/PolicyLossWithoutReg Max            315.513
trainer/PolicyLossWithoutReg Min              3.70097
exploration/num steps total              220000
exploration/num paths total                 948
exploration/path length this epoch Mean     704
exploration/path length this epoch Std        0
exploration/path length this epoch Max      704
exploration/path length this epoch Min      704
exploration/Rewards Mean                      4.0113
exploration/Rewards Std                       1.18931
exploration/Rewards Max                       7.93108
exploration/Rewards Min                      -0.559423
exploration/Returns Mean                   2823.96
exploration/Returns Std                       0
exploration/Returns Max                    2823.96
exploration/Returns Min                    2823.96
exploration/Num Paths                         1
exploration/Average Returns                2823.96
evaluation_0/num steps total                  1.68271e+06
evaluation_0/num paths total               5002
evaluation_0/path length Mean               785.8
evaluation_0/path length Std                334.224
evaluation_0/path length Max               1000
evaluation_0/path length Min                110
evaluation_0/Rewards Mean                     4.01485
evaluation_0/Rewards Std                      0.965386
evaluation_0/Rewards Max                      8.59771
evaluation_0/Rewards Min                     -0.572598
evaluation_0/Returns Mean                  3154.87
evaluation_0/Returns Std                   1425.26
evaluation_0/Returns Max                   4349.34
evaluation_0/Returns Min                    306.93
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3154.87
time/epoch (s)                                0
time/total (s)                             3454.06
Epoch                                       215
---------------------------------------  ----------------
2022-11-16 17:12:29.902645 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 216 finished
---------------------------------------  ----------------
epoch                                       216
total_step                               221000
replay_pool/size                         221000
trainer/alpha                                 0.0604896
trainer/alpha_loss                            1.33257
trainer/entropy                              -6.47502
trainer/qf_loss                              16.0614
trainer/policy_loss                        -246.829
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         247.22
trainer/entropy_penalty                      -0.391671
trainer/entropy_percentage                   -0.0015843
trainer/Q1Pred Mean                         245.884
trainer/Q1Pred Std                           62.8678
trainer/Q1Pred Max                          325.504
trainer/Q1Pred Min                           -8.27238
trainer/Q2Pred Mean                         245.971
trainer/Q2Pred Std                           62.4115
trainer/Q2Pred Max                          323.043
trainer/Q2Pred Min                           -7.26729
trainer/QTargetWithReg Mean                 245.889
trainer/QTargetWithReg Std                   62.2973
trainer/QTargetWithReg Max                  322.778
trainer/QTargetWithReg Min                   11.3043
trainer/PolicyLossWithoutReg Mean           247.22
trainer/PolicyLossWithoutReg Std             61.1813
trainer/PolicyLossWithoutReg Max            323.321
trainer/PolicyLossWithoutReg Min             -5.76535
exploration/num steps total              221000
exploration/num paths total                 949
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.81352
exploration/Rewards Std                       1.01879
exploration/Rewards Max                       5.85043
exploration/Rewards Min                      -0.59597
exploration/Returns Mean                   3813.52
exploration/Returns Std                       0
exploration/Returns Max                    3813.52
exploration/Returns Min                    3813.52
exploration/Num Paths                         1
exploration/Average Returns                3813.52
evaluation_0/num steps total                  1.69071e+06
evaluation_0/num paths total               5010
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.00845
evaluation_0/Rewards Std                      0.986592
evaluation_0/Rewards Max                      7.10443
evaluation_0/Rewards Min                     -0.590789
evaluation_0/Returns Mean                  4008.45
evaluation_0/Returns Std                    136.447
evaluation_0/Returns Max                   4195.15
evaluation_0/Returns Min                   3791.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4008.45
time/epoch (s)                                0
time/total (s)                             3467.02
Epoch                                       216
---------------------------------------  ----------------
2022-11-16 17:12:43.804801 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 217 finished
---------------------------------------  ----------------
epoch                                       217
total_step                               222000
replay_pool/size                         222000
trainer/alpha                                 0.0619423
trainer/alpha_loss                           -0.802405
trainer/entropy                              -5.71151
trainer/qf_loss                              15.8977
trainer/policy_loss                        -247.214
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         247.568
trainer/entropy_penalty                      -0.353784
trainer/entropy_percentage                   -0.00142904
trainer/Q1Pred Mean                         246.103
trainer/Q1Pred Std                           63.7548
trainer/Q1Pred Max                          310.555
trainer/Q1Pred Min                           18.3156
trainer/Q2Pred Mean                         246.056
trainer/Q2Pred Std                           64.2971
trainer/Q2Pred Max                          309.934
trainer/Q2Pred Min                           20.2402
trainer/QTargetWithReg Mean                 245.325
trainer/QTargetWithReg Std                   64.5063
trainer/QTargetWithReg Max                  312.37
trainer/QTargetWithReg Min                   13.7038
trainer/PolicyLossWithoutReg Mean           247.568
trainer/PolicyLossWithoutReg Std             61.9353
trainer/PolicyLossWithoutReg Max            310.777
trainer/PolicyLossWithoutReg Min             16.3092
exploration/num steps total              222000
exploration/num paths total                 950
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.73276
exploration/Rewards Std                       0.910362
exploration/Rewards Max                       5.77325
exploration/Rewards Min                      -0.631197
exploration/Returns Mean                   3732.76
exploration/Returns Std                       0
exploration/Returns Max                    3732.76
exploration/Returns Min                    3732.76
exploration/Num Paths                         1
exploration/Average Returns                3732.76
evaluation_0/num steps total                  1.69792e+06
evaluation_0/num paths total               5018
evaluation_0/path length Mean               900.5
evaluation_0/path length Std                263.252
evaluation_0/path length Max               1000
evaluation_0/path length Min                204
evaluation_0/Rewards Mean                     3.85178
evaluation_0/Rewards Std                      0.873041
evaluation_0/Rewards Max                      6.49516
evaluation_0/Rewards Min                     -0.603209
evaluation_0/Returns Mean                  3468.53
evaluation_0/Returns Std                   1104.76
evaluation_0/Returns Max                   4029.63
evaluation_0/Returns Min                    556.018
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3468.53
time/epoch (s)                                0
time/total (s)                             3480.92
Epoch                                       217
---------------------------------------  ----------------
2022-11-16 17:12:58.167482 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 218 finished
---------------------------------------  ----------------
epoch                                       218
total_step                               223000
replay_pool/size                         223000
trainer/alpha                                 0.0623253
trainer/alpha_loss                           -0.629583
trainer/entropy                              -5.77316
trainer/qf_loss                              21.1912
trainer/policy_loss                        -245.704
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         246.064
trainer/entropy_penalty                      -0.359814
trainer/entropy_percentage                   -0.00146228
trainer/Q1Pred Mean                         244.224
trainer/Q1Pred Std                           59.0079
trainer/Q1Pred Max                          320.161
trainer/Q1Pred Min                            7.03251
trainer/Q2Pred Mean                         244.646
trainer/Q2Pred Std                           59.4539
trainer/Q2Pred Max                          320.146
trainer/Q2Pred Min                           -1.90736
trainer/QTargetWithReg Mean                 244.146
trainer/QTargetWithReg Std                   59.9407
trainer/QTargetWithReg Max                  315.127
trainer/QTargetWithReg Min                    0.245932
trainer/PolicyLossWithoutReg Mean           246.064
trainer/PolicyLossWithoutReg Std             57.2663
trainer/PolicyLossWithoutReg Max            319.936
trainer/PolicyLossWithoutReg Min             10.9602
exploration/num steps total              223000
exploration/num paths total                 951
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.85758
exploration/Rewards Std                       0.863782
exploration/Rewards Max                       5.65187
exploration/Rewards Min                      -0.599543
exploration/Returns Mean                   3857.58
exploration/Returns Std                       0
exploration/Returns Max                    3857.58
exploration/Returns Min                    3857.58
exploration/Num Paths                         1
exploration/Average Returns                3857.58
evaluation_0/num steps total                  1.70578e+06
evaluation_0/num paths total               5026
evaluation_0/path length Mean               982.875
evaluation_0/path length Std                 45.3085
evaluation_0/path length Max               1000
evaluation_0/path length Min                863
evaluation_0/Rewards Mean                     4.11308
evaluation_0/Rewards Std                      1.03757
evaluation_0/Rewards Max                      6.45225
evaluation_0/Rewards Min                     -0.501415
evaluation_0/Returns Mean                  4042.65
evaluation_0/Returns Std                    202.011
evaluation_0/Returns Max                   4203.13
evaluation_0/Returns Min                   3524.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4042.65
time/epoch (s)                                0
time/total (s)                             3495.28
Epoch                                       218
---------------------------------------  ----------------
2022-11-16 17:13:10.677330 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 219 finished
---------------------------------------  ----------------
epoch                                       219
total_step                               224000
replay_pool/size                         224000
trainer/alpha                                 0.0613249
trainer/alpha_loss                           -0.77617
trainer/entropy                              -5.72194
trainer/qf_loss                              15.8497
trainer/policy_loss                        -254.732
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         255.083
trainer/entropy_penalty                      -0.350898
trainer/entropy_percentage                   -0.00137562
trainer/Q1Pred Mean                         253.615
trainer/Q1Pred Std                           49.0756
trainer/Q1Pred Max                          326.321
trainer/Q1Pred Min                           22.1502
trainer/Q2Pred Mean                         254.342
trainer/Q2Pred Std                           48.7446
trainer/Q2Pred Max                          325.763
trainer/Q2Pred Min                           20.892
trainer/QTargetWithReg Mean                 253.644
trainer/QTargetWithReg Std                   49.1606
trainer/QTargetWithReg Max                  324.915
trainer/QTargetWithReg Min                   23.4364
trainer/PolicyLossWithoutReg Mean           255.083
trainer/PolicyLossWithoutReg Std             48.2066
trainer/PolicyLossWithoutReg Max            325.101
trainer/PolicyLossWithoutReg Min             21.6721
exploration/num steps total              224000
exploration/num paths total                 954
exploration/path length this epoch Mean     276
exploration/path length this epoch Std      221.636
exploration/path length this epoch Max      566
exploration/path length this epoch Min       28
exploration/Rewards Mean                      3.58056
exploration/Rewards Std                       1.46491
exploration/Rewards Max                       8.88011
exploration/Rewards Min                      -0.559121
exploration/Returns Mean                    988.235
exploration/Returns Std                     910.758
exploration/Returns Max                    2207.39
exploration/Returns Min                      18.8418
exploration/Num Paths                         3
exploration/Average Returns                 988.235
evaluation_0/num steps total                  1.71378e+06
evaluation_0/num paths total               5034
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.94725
evaluation_0/Rewards Std                      0.831128
evaluation_0/Rewards Max                      5.52695
evaluation_0/Rewards Min                     -0.595803
evaluation_0/Returns Mean                  3947.25
evaluation_0/Returns Std                     56.4674
evaluation_0/Returns Max                   4021.17
evaluation_0/Returns Min                   3855.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3947.25
time/epoch (s)                                0
time/total (s)                             3507.79
Epoch                                       219
---------------------------------------  ----------------
2022-11-16 17:13:23.006368 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 220 finished
---------------------------------------  ----------------
epoch                                       220
total_step                               225000
replay_pool/size                         225000
trainer/alpha                                 0.0609265
trainer/alpha_loss                           -1.2894
trainer/entropy                              -5.53915
trainer/qf_loss                              19.4236
trainer/policy_loss                        -248.588
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         248.925
trainer/entropy_penalty                      -0.337481
trainer/entropy_percentage                   -0.00135575
trainer/Q1Pred Mean                         247.406
trainer/Q1Pred Std                           64.0699
trainer/Q1Pred Max                          316.335
trainer/Q1Pred Min                           -0.172322
trainer/Q2Pred Mean                         247.793
trainer/Q2Pred Std                           64.1534
trainer/Q2Pred Max                          319.654
trainer/Q2Pred Min                           -9.54607
trainer/QTargetWithReg Mean                 247.753
trainer/QTargetWithReg Std                   64.9432
trainer/QTargetWithReg Max                  320.749
trainer/QTargetWithReg Min                   -5.13756
trainer/PolicyLossWithoutReg Mean           248.925
trainer/PolicyLossWithoutReg Std             63.1221
trainer/PolicyLossWithoutReg Max            317.544
trainer/PolicyLossWithoutReg Min             -2.82257
exploration/num steps total              225000
exploration/num paths total                 955
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.80668
exploration/Rewards Std                       1.04955
exploration/Rewards Max                       6.50167
exploration/Rewards Min                      -0.433663
exploration/Returns Mean                   3806.68
exploration/Returns Std                       0
exploration/Returns Max                    3806.68
exploration/Returns Min                    3806.68
exploration/Num Paths                         1
exploration/Average Returns                3806.68
evaluation_0/num steps total                  1.72178e+06
evaluation_0/num paths total               5042
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.7791
evaluation_0/Rewards Std                      0.825051
evaluation_0/Rewards Max                      5.88012
evaluation_0/Rewards Min                     -0.546025
evaluation_0/Returns Mean                  3779.1
evaluation_0/Returns Std                     67.8793
evaluation_0/Returns Max                   3902.5
evaluation_0/Returns Min                   3704.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3779.1
time/epoch (s)                                0
time/total (s)                             3520.12
Epoch                                       220
---------------------------------------  ----------------
2022-11-16 17:13:35.789066 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 221 finished
---------------------------------------  ----------------
epoch                                       221
total_step                               226000
replay_pool/size                         226000
trainer/alpha                                 0.0595563
trainer/alpha_loss                           -0.712549
trainer/entropy                              -5.7474
trainer/qf_loss                              17.4432
trainer/policy_loss                        -245.978
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         246.321
trainer/entropy_penalty                      -0.342293
trainer/entropy_percentage                   -0.00138963
trainer/Q1Pred Mean                         244.247
trainer/Q1Pred Std                           60.0797
trainer/Q1Pred Max                          324.48
trainer/Q1Pred Min                           -4.93972
trainer/Q2Pred Mean                         244.483
trainer/Q2Pred Std                           59.5419
trainer/Q2Pred Max                          323.47
trainer/Q2Pred Min                            6.7491
trainer/QTargetWithReg Mean                 244.865
trainer/QTargetWithReg Std                   60.2391
trainer/QTargetWithReg Max                  329.082
trainer/QTargetWithReg Min                   -4.53337
trainer/PolicyLossWithoutReg Mean           246.321
trainer/PolicyLossWithoutReg Std             57.0929
trainer/PolicyLossWithoutReg Max            324.204
trainer/PolicyLossWithoutReg Min             17.0363
exploration/num steps total              226000
exploration/num paths total                 956
exploration/path length this epoch Mean     905
exploration/path length this epoch Std        0
exploration/path length this epoch Max      905
exploration/path length this epoch Min      905
exploration/Rewards Mean                      3.88356
exploration/Rewards Std                       0.982828
exploration/Rewards Max                       6.14365
exploration/Rewards Min                      -0.415176
exploration/Returns Mean                   3514.63
exploration/Returns Std                       0
exploration/Returns Max                    3514.63
exploration/Returns Min                    3514.63
exploration/Num Paths                         1
exploration/Average Returns                3514.63
evaluation_0/num steps total                  1.72978e+06
evaluation_0/num paths total               5050
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.0247
evaluation_0/Rewards Std                      0.95535
evaluation_0/Rewards Max                      6.81592
evaluation_0/Rewards Min                     -0.384512
evaluation_0/Returns Mean                  4024.7
evaluation_0/Returns Std                    119.311
evaluation_0/Returns Max                   4202.74
evaluation_0/Returns Min                   3861.05
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4024.7
time/epoch (s)                                0
time/total (s)                             3532.9
Epoch                                       221
---------------------------------------  ----------------
2022-11-16 17:13:48.393741 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 222 finished
---------------------------------------  ----------------
epoch                                       222
total_step                               227000
replay_pool/size                         227000
trainer/alpha                                 0.0595815
trainer/alpha_loss                            1.65658
trainer/entropy                              -6.58735
trainer/qf_loss                              18.7273
trainer/policy_loss                        -246.013
trainer/adversary_policy_loss                11.6828
trainer/policy_loss_without_entropy         246.405
trainer/entropy_penalty                      -0.392484
trainer/entropy_percentage                   -0.00159284
trainer/Q1Pred Mean                         245.017
trainer/Q1Pred Std                           64.4622
trainer/Q1Pred Max                          315.931
trainer/Q1Pred Min                            2.7252
trainer/Q2Pred Mean                         244.874
trainer/Q2Pred Std                           64.5982
trainer/Q2Pred Max                          316.901
trainer/Q2Pred Min                            0.909964
trainer/QTargetWithReg Mean                 246.371
trainer/QTargetWithReg Std                   65.0313
trainer/QTargetWithReg Max                  316.832
trainer/QTargetWithReg Min                   -4.91606
trainer/PolicyLossWithoutReg Mean           246.405
trainer/PolicyLossWithoutReg Std             63.5038
trainer/PolicyLossWithoutReg Max            316.826
trainer/PolicyLossWithoutReg Min              7.15983
exploration/num steps total              227000
exploration/num paths total                 957
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15923
exploration/Rewards Std                       1.00425
exploration/Rewards Max                       6.55194
exploration/Rewards Min                      -0.53817
exploration/Returns Mean                   4159.23
exploration/Returns Std                       0
exploration/Returns Max                    4159.23
exploration/Returns Min                    4159.23
exploration/Num Paths                         1
exploration/Average Returns                4159.23
evaluation_0/num steps total                  1.73778e+06
evaluation_0/num paths total               5058
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.03282
evaluation_0/Rewards Std                      0.957843
evaluation_0/Rewards Max                      6.2862
evaluation_0/Rewards Min                     -0.56098
evaluation_0/Returns Mean                  4032.82
evaluation_0/Returns Std                     54.8413
evaluation_0/Returns Max                   4128.03
evaluation_0/Returns Min                   3962.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4032.82
time/epoch (s)                                0
time/total (s)                             3545.5
Epoch                                       222
---------------------------------------  ----------------
2022-11-16 17:14:00.711987 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 223 finished
---------------------------------------  ----------------
epoch                                       223
total_step                               228000
replay_pool/size                         228000
trainer/alpha                                 0.0602081
trainer/alpha_loss                            0.458818
trainer/entropy                              -6.16329
trainer/qf_loss                              22.4165
trainer/policy_loss                        -247.452
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         247.823
trainer/entropy_penalty                      -0.37108
trainer/entropy_percentage                   -0.00149736
trainer/Q1Pred Mean                         245.542
trainer/Q1Pred Std                           61.4584
trainer/Q1Pred Max                          322.497
trainer/Q1Pred Min                            4.33378
trainer/Q2Pred Mean                         246.535
trainer/Q2Pred Std                           61.8695
trainer/Q2Pred Max                          324.305
trainer/Q2Pred Min                            2.38212
trainer/QTargetWithReg Mean                 246.084
trainer/QTargetWithReg Std                   62.5279
trainer/QTargetWithReg Max                  323.848
trainer/QTargetWithReg Min                   -0.05878
trainer/PolicyLossWithoutReg Mean           247.823
trainer/PolicyLossWithoutReg Std             58.3679
trainer/PolicyLossWithoutReg Max            322.531
trainer/PolicyLossWithoutReg Min              2.19253
exploration/num steps total              228000
exploration/num paths total                 958
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.99547
exploration/Rewards Std                       0.918666
exploration/Rewards Max                       6.41998
exploration/Rewards Min                      -0.689664
exploration/Returns Mean                   3995.47
exploration/Returns Std                       0
exploration/Returns Max                    3995.47
exploration/Returns Min                    3995.47
exploration/Num Paths                         1
exploration/Average Returns                3995.47
evaluation_0/num steps total                  1.74578e+06
evaluation_0/num paths total               5066
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.04423
evaluation_0/Rewards Std                      0.94657
evaluation_0/Rewards Max                      5.93652
evaluation_0/Rewards Min                     -0.283511
evaluation_0/Returns Mean                  4044.23
evaluation_0/Returns Std                     33.9056
evaluation_0/Returns Max                   4106.92
evaluation_0/Returns Min                   4012.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4044.23
time/epoch (s)                                0
time/total (s)                             3557.82
Epoch                                       223
---------------------------------------  ----------------
2022-11-16 17:14:13.595283 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 224 finished
---------------------------------------  ----------------
epoch                                       224
total_step                               229000
replay_pool/size                         229000
trainer/alpha                                 0.0608926
trainer/alpha_loss                            1.20776
trainer/entropy                              -6.43156
trainer/qf_loss                              16.2602
trainer/policy_loss                        -246.24
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         246.632
trainer/entropy_penalty                      -0.391635
trainer/entropy_percentage                   -0.00158793
trainer/Q1Pred Mean                         245.233
trainer/Q1Pred Std                           64.616
trainer/Q1Pred Max                          320.314
trainer/Q1Pred Min                           -1.73491
trainer/Q2Pred Mean                         245.273
trainer/Q2Pred Std                           64.425
trainer/Q2Pred Max                          319.353
trainer/Q2Pred Min                            3.79775
trainer/QTargetWithReg Mean                 244.876
trainer/QTargetWithReg Std                   65.3515
trainer/QTargetWithReg Max                  322.107
trainer/QTargetWithReg Min                    2.61429
trainer/PolicyLossWithoutReg Mean           246.632
trainer/PolicyLossWithoutReg Std             63.2126
trainer/PolicyLossWithoutReg Max            319.583
trainer/PolicyLossWithoutReg Min              9.68396
exploration/num steps total              229000
exploration/num paths total                 959
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.22218
exploration/Rewards Std                       0.919627
exploration/Rewards Max                       6.24341
exploration/Rewards Min                      -0.29601
exploration/Returns Mean                   4222.18
exploration/Returns Std                       0
exploration/Returns Max                    4222.18
exploration/Returns Min                    4222.18
exploration/Num Paths                         1
exploration/Average Returns                4222.18
evaluation_0/num steps total                  1.75378e+06
evaluation_0/num paths total               5074
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.21636
evaluation_0/Rewards Std                      0.867439
evaluation_0/Rewards Max                      6.26441
evaluation_0/Rewards Min                     -0.562094
evaluation_0/Returns Mean                  4216.36
evaluation_0/Returns Std                     70.4776
evaluation_0/Returns Max                   4316.44
evaluation_0/Returns Min                   4082.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4216.36
time/epoch (s)                                0
time/total (s)                             3570.71
Epoch                                       224
---------------------------------------  ----------------
2022-11-16 17:14:26.105575 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 225 finished
---------------------------------------  ----------------
epoch                                       225
total_step                               230000
replay_pool/size                         230000
trainer/alpha                                 0.0598512
trainer/alpha_loss                            0.141058
trainer/entropy                              -6.0501
trainer/qf_loss                              16.9166
trainer/policy_loss                        -250.622
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         250.984
trainer/entropy_penalty                      -0.362105
trainer/entropy_percentage                   -0.00144274
trainer/Q1Pred Mean                         249.204
trainer/Q1Pred Std                           60.944
trainer/Q1Pred Max                          331.748
trainer/Q1Pred Min                          -18.1388
trainer/Q2Pred Mean                         248.681
trainer/Q2Pred Std                           60.7889
trainer/Q2Pred Max                          332.577
trainer/Q2Pred Min                          -19.2005
trainer/QTargetWithReg Mean                 249.165
trainer/QTargetWithReg Std                   60.8091
trainer/QTargetWithReg Max                  331.447
trainer/QTargetWithReg Min                   -0.120938
trainer/PolicyLossWithoutReg Mean           250.984
trainer/PolicyLossWithoutReg Std             57.1056
trainer/PolicyLossWithoutReg Max            332.972
trainer/PolicyLossWithoutReg Min             22.4389
exploration/num steps total              230000
exploration/num paths total                 960
exploration/path length this epoch Mean     163
exploration/path length this epoch Std        0
exploration/path length this epoch Max      163
exploration/path length this epoch Min      163
exploration/Rewards Mean                      2.96357
exploration/Rewards Std                       1.47539
exploration/Rewards Max                       6.70911
exploration/Rewards Min                      -0.409046
exploration/Returns Mean                    483.061
exploration/Returns Std                       0
exploration/Returns Max                     483.061
exploration/Returns Min                     483.061
exploration/Num Paths                         1
exploration/Average Returns                 483.061
evaluation_0/num steps total                  1.76178e+06
evaluation_0/num paths total               5082
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.96345
evaluation_0/Rewards Std                      0.929662
evaluation_0/Rewards Max                      6.39243
evaluation_0/Rewards Min                     -0.502282
evaluation_0/Returns Mean                  3963.45
evaluation_0/Returns Std                    118.305
evaluation_0/Returns Max                   4087.38
evaluation_0/Returns Min                   3702.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3963.45
time/epoch (s)                                0
time/total (s)                             3583.22
Epoch                                       225
---------------------------------------  ----------------
2022-11-16 17:14:38.432206 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 226 finished
---------------------------------------  ----------------
epoch                                       226
total_step                               231000
replay_pool/size                         231000
trainer/alpha                                 0.0613975
trainer/alpha_loss                            1.60732
trainer/entropy                              -6.57602
trainer/qf_loss                              27.461
trainer/policy_loss                        -241.802
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         242.206
trainer/entropy_penalty                      -0.403751
trainer/entropy_percentage                   -0.00166697
trainer/Q1Pred Mean                         239.402
trainer/Q1Pred Std                           75.3917
trainer/Q1Pred Max                          328.732
trainer/Q1Pred Min                          -31.5057
trainer/Q2Pred Mean                         239.637
trainer/Q2Pred Std                           75.2839
trainer/Q2Pred Max                          329.575
trainer/Q2Pred Min                          -24.0184
trainer/QTargetWithReg Mean                 239.92
trainer/QTargetWithReg Std                   75.4379
trainer/QTargetWithReg Max                  330.195
trainer/QTargetWithReg Min                  -12.5165
trainer/PolicyLossWithoutReg Mean           242.206
trainer/PolicyLossWithoutReg Std             73.229
trainer/PolicyLossWithoutReg Max            329.369
trainer/PolicyLossWithoutReg Min            -16.1999
exploration/num steps total              231000
exploration/num paths total                 961
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.83694
exploration/Rewards Std                       0.936779
exploration/Rewards Max                       6.27022
exploration/Rewards Min                      -0.478974
exploration/Returns Mean                   3836.94
exploration/Returns Std                       0
exploration/Returns Max                    3836.94
exploration/Returns Min                    3836.94
exploration/Num Paths                         1
exploration/Average Returns                3836.94
evaluation_0/num steps total                  1.76978e+06
evaluation_0/num paths total               5090
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.90506
evaluation_0/Rewards Std                      0.976199
evaluation_0/Rewards Max                      6.71923
evaluation_0/Rewards Min                     -0.557534
evaluation_0/Returns Mean                  3905.06
evaluation_0/Returns Std                     93.0957
evaluation_0/Returns Max                   4062.66
evaluation_0/Returns Min                   3758.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3905.06
time/epoch (s)                                0
time/total (s)                             3595.54
Epoch                                       226
---------------------------------------  ----------------
2022-11-16 17:14:53.111752 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 227 finished
---------------------------------------  ----------------
epoch                                       227
total_step                               232000
replay_pool/size                         232000
trainer/alpha                                 0.0605308
trainer/alpha_loss                            0.0267302
trainer/entropy                              -6.00953
trainer/qf_loss                              11.583
trainer/policy_loss                        -252.398
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         252.762
trainer/entropy_penalty                      -0.363762
trainer/entropy_percentage                   -0.00143915
trainer/Q1Pred Mean                         252.355
trainer/Q1Pred Std                           59.1759
trainer/Q1Pred Max                          330.818
trainer/Q1Pred Min                           20.5168
trainer/Q2Pred Mean                         251.713
trainer/Q2Pred Std                           59.4925
trainer/Q2Pred Max                          326.388
trainer/Q2Pred Min                           22.1033
trainer/QTargetWithReg Mean                 252.43
trainer/QTargetWithReg Std                   59.3216
trainer/QTargetWithReg Max                  326.678
trainer/QTargetWithReg Min                   17.3062
trainer/PolicyLossWithoutReg Mean           252.762
trainer/PolicyLossWithoutReg Std             59.0279
trainer/PolicyLossWithoutReg Max            328.161
trainer/PolicyLossWithoutReg Min             23.1839
exploration/num steps total              232000
exploration/num paths total                 962
exploration/path length this epoch Mean     436
exploration/path length this epoch Std        0
exploration/path length this epoch Max      436
exploration/path length this epoch Min      436
exploration/Rewards Mean                      3.36106
exploration/Rewards Std                       1.26574
exploration/Rewards Max                       8.45601
exploration/Rewards Min                      -0.506077
exploration/Returns Mean                   1465.42
exploration/Returns Std                       0
exploration/Returns Max                    1465.42
exploration/Returns Min                    1465.42
exploration/Num Paths                         1
exploration/Average Returns                1465.42
evaluation_0/num steps total                  1.77694e+06
evaluation_0/num paths total               5098
evaluation_0/path length Mean               895.25
evaluation_0/path length Std                277.142
evaluation_0/path length Max               1000
evaluation_0/path length Min                162
evaluation_0/Rewards Mean                     3.97069
evaluation_0/Rewards Std                      1.01871
evaluation_0/Rewards Max                      6.30755
evaluation_0/Rewards Min                     -0.379646
evaluation_0/Returns Mean                  3554.76
evaluation_0/Returns Std                   1203.32
evaluation_0/Returns Max                   4085.74
evaluation_0/Returns Min                    374.242
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3554.76
time/epoch (s)                                0
time/total (s)                             3610.22
Epoch                                       227
---------------------------------------  ----------------
2022-11-16 17:15:05.509925 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 228 finished
---------------------------------------  ----------------
epoch                                       228
total_step                               233000
replay_pool/size                         233000
trainer/alpha                                 0.0612651
trainer/alpha_loss                           -0.0284898
trainer/entropy                              -5.9898
trainer/qf_loss                              17.4725
trainer/policy_loss                        -249.266
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         249.633
trainer/entropy_penalty                      -0.366965
trainer/entropy_percentage                   -0.00147002
trainer/Q1Pred Mean                         247.355
trainer/Q1Pred Std                           65.3866
trainer/Q1Pred Max                          326.876
trainer/Q1Pred Min                           -6.75768
trainer/Q2Pred Mean                         247.593
trainer/Q2Pred Std                           65.3046
trainer/Q2Pred Max                          324.512
trainer/Q2Pred Min                          -26.8557
trainer/QTargetWithReg Mean                 247.809
trainer/QTargetWithReg Std                   65.1488
trainer/QTargetWithReg Max                  326.542
trainer/QTargetWithReg Min                   -2.69571
trainer/PolicyLossWithoutReg Mean           249.633
trainer/PolicyLossWithoutReg Std             63.0366
trainer/PolicyLossWithoutReg Max            326.297
trainer/PolicyLossWithoutReg Min              8.96079
exploration/num steps total              233000
exploration/num paths total                 963
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.05133
exploration/Rewards Std                       0.906962
exploration/Rewards Max                       6.45032
exploration/Rewards Min                      -0.303128
exploration/Returns Mean                   4051.33
exploration/Returns Std                       0
exploration/Returns Max                    4051.33
exploration/Returns Min                    4051.33
exploration/Num Paths                         1
exploration/Average Returns                4051.33
evaluation_0/num steps total                  1.78494e+06
evaluation_0/num paths total               5106
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.01147
evaluation_0/Rewards Std                      0.996435
evaluation_0/Rewards Max                      6.63761
evaluation_0/Rewards Min                     -0.514913
evaluation_0/Returns Mean                  4011.47
evaluation_0/Returns Std                    104.443
evaluation_0/Returns Max                   4218.3
evaluation_0/Returns Min                   3883.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4011.47
time/epoch (s)                                0
time/total (s)                             3622.62
Epoch                                       228
---------------------------------------  ----------------
2022-11-16 17:15:19.568093 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 229 finished
---------------------------------------  ----------------
epoch                                       229
total_step                               234000
replay_pool/size                         234000
trainer/alpha                                 0.0616175
trainer/alpha_loss                            2.15215
trainer/entropy                              -6.77225
trainer/qf_loss                              18.1672
trainer/policy_loss                        -245.895
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         246.312
trainer/entropy_penalty                      -0.417289
trainer/entropy_percentage                   -0.00169415
trainer/Q1Pred Mean                         244.522
trainer/Q1Pred Std                           71.4547
trainer/Q1Pred Max                          331.988
trainer/Q1Pred Min                          -22.459
trainer/Q2Pred Mean                         244.369
trainer/Q2Pred Std                           71.6556
trainer/Q2Pred Max                          333.123
trainer/Q2Pred Min                          -25.7009
trainer/QTargetWithReg Mean                 244.544
trainer/QTargetWithReg Std                   72.0618
trainer/QTargetWithReg Max                  330.45
trainer/QTargetWithReg Min                  -21.9759
trainer/PolicyLossWithoutReg Mean           246.312
trainer/PolicyLossWithoutReg Std             68.9531
trainer/PolicyLossWithoutReg Max            332.116
trainer/PolicyLossWithoutReg Min            -20.8875
exploration/num steps total              234000
exploration/num paths total                 964
exploration/path length this epoch Mean     613
exploration/path length this epoch Std        0
exploration/path length this epoch Max      613
exploration/path length this epoch Min      613
exploration/Rewards Mean                      3.78287
exploration/Rewards Std                       1.05414
exploration/Rewards Max                       7.21871
exploration/Rewards Min                      -0.435581
exploration/Returns Mean                   2318.9
exploration/Returns Std                       0
exploration/Returns Max                    2318.9
exploration/Returns Min                    2318.9
exploration/Num Paths                         1
exploration/Average Returns                2318.9
evaluation_0/num steps total                  1.79266e+06
evaluation_0/num paths total               5114
evaluation_0/path length Mean               964.625
evaluation_0/path length Std                 93.5935
evaluation_0/path length Max               1000
evaluation_0/path length Min                717
evaluation_0/Rewards Mean                     4.12951
evaluation_0/Rewards Std                      1.05157
evaluation_0/Rewards Max                      7.03895
evaluation_0/Rewards Min                     -0.5163
evaluation_0/Returns Mean                  3983.43
evaluation_0/Returns Std                    456.662
evaluation_0/Returns Max                   4328.64
evaluation_0/Returns Min                   2842.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3983.43
time/epoch (s)                                0
time/total (s)                             3636.68
Epoch                                       229
---------------------------------------  ----------------
2022-11-16 17:15:32.521758 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 230 finished
---------------------------------------  ----------------
epoch                                       230
total_step                               235000
replay_pool/size                         235000
trainer/alpha                                 0.0624169
trainer/alpha_loss                            0.970785
trainer/entropy                              -6.34997
trainer/qf_loss                              16.3165
trainer/policy_loss                        -248.649
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         249.046
trainer/entropy_penalty                      -0.396346
trainer/entropy_percentage                   -0.00159146
trainer/Q1Pred Mean                         247.955
trainer/Q1Pred Std                           69.6189
trainer/Q1Pred Max                          321.739
trainer/Q1Pred Min                          -10.1434
trainer/Q2Pred Mean                         248.263
trainer/Q2Pred Std                           68.7192
trainer/Q2Pred Max                          319.605
trainer/Q2Pred Min                          -12.1634
trainer/QTargetWithReg Mean                 247.814
trainer/QTargetWithReg Std                   69.8666
trainer/QTargetWithReg Max                  321.152
trainer/QTargetWithReg Min                   -7.49786
trainer/PolicyLossWithoutReg Mean           249.046
trainer/PolicyLossWithoutReg Std             67.8256
trainer/PolicyLossWithoutReg Max            321.604
trainer/PolicyLossWithoutReg Min             -7.60062
exploration/num steps total              235000
exploration/num paths total                 965
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.8109
exploration/Rewards Std                       1.00788
exploration/Rewards Max                       6.61737
exploration/Rewards Min                      -0.519832
exploration/Returns Mean                   3810.9
exploration/Returns Std                       0
exploration/Returns Max                    3810.9
exploration/Returns Min                    3810.9
exploration/Num Paths                         1
exploration/Average Returns                3810.9
evaluation_0/num steps total                  1.80066e+06
evaluation_0/num paths total               5122
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.30306
evaluation_0/Rewards Std                      1.03156
evaluation_0/Rewards Max                      6.60852
evaluation_0/Rewards Min                     -0.467531
evaluation_0/Returns Mean                  4303.06
evaluation_0/Returns Std                     87.9705
evaluation_0/Returns Max                   4499.8
evaluation_0/Returns Min                   4211
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4303.06
time/epoch (s)                                0
time/total (s)                             3649.63
Epoch                                       230
---------------------------------------  ----------------
2022-11-16 17:15:44.836556 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 231 finished
---------------------------------------  ----------------
epoch                                       231
total_step                               236000
replay_pool/size                         236000
trainer/alpha                                 0.0616792
trainer/alpha_loss                           -0.75504
trainer/entropy                              -5.72897
trainer/qf_loss                              14.0921
trainer/policy_loss                        -251.023
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         251.377
trainer/entropy_penalty                      -0.353358
trainer/entropy_percentage                   -0.00140569
trainer/Q1Pred Mean                         249.343
trainer/Q1Pred Std                           69.7722
trainer/Q1Pred Max                          332.735
trainer/Q1Pred Min                          -13.1759
trainer/Q2Pred Mean                         249.717
trainer/Q2Pred Std                           69.2673
trainer/Q2Pred Max                          330.477
trainer/Q2Pred Min                          -11.9519
trainer/QTargetWithReg Mean                 249.16
trainer/QTargetWithReg Std                   69.0666
trainer/QTargetWithReg Max                  330.73
trainer/QTargetWithReg Min                   -0.271924
trainer/PolicyLossWithoutReg Mean           251.377
trainer/PolicyLossWithoutReg Std             67.1171
trainer/PolicyLossWithoutReg Max            330.108
trainer/PolicyLossWithoutReg Min             -2.94948
exploration/num steps total              236000
exploration/num paths total                 966
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.08724
exploration/Rewards Std                       0.92391
exploration/Rewards Max                       6.41395
exploration/Rewards Min                      -0.493572
exploration/Returns Mean                   4087.24
exploration/Returns Std                       0
exploration/Returns Max                    4087.24
exploration/Returns Min                    4087.24
exploration/Num Paths                         1
exploration/Average Returns                4087.24
evaluation_0/num steps total                  1.80866e+06
evaluation_0/num paths total               5130
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.06922
evaluation_0/Rewards Std                      0.915249
evaluation_0/Rewards Max                      6.75635
evaluation_0/Rewards Min                     -0.500364
evaluation_0/Returns Mean                  4069.22
evaluation_0/Returns Std                    146.968
evaluation_0/Returns Max                   4251.35
evaluation_0/Returns Min                   3737.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4069.22
time/epoch (s)                                0
time/total (s)                             3661.94
Epoch                                       231
---------------------------------------  ----------------
2022-11-16 17:15:57.737613 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 232 finished
---------------------------------------  ----------------
epoch                                       232
total_step                               237000
replay_pool/size                         237000
trainer/alpha                                 0.0611263
trainer/alpha_loss                            0.917516
trainer/entropy                              -6.32828
trainer/qf_loss                              17.5369
trainer/policy_loss                        -252.76
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         253.147
trainer/entropy_penalty                      -0.386825
trainer/entropy_percentage                   -0.00152806
trainer/Q1Pred Mean                         251.438
trainer/Q1Pred Std                           58.3807
trainer/Q1Pred Max                          348.756
trainer/Q1Pred Min                            3.72953
trainer/Q2Pred Mean                         251.809
trainer/Q2Pred Std                           58.0682
trainer/Q2Pred Max                          345.234
trainer/Q2Pred Min                           -0.101326
trainer/QTargetWithReg Mean                 251.825
trainer/QTargetWithReg Std                   58.677
trainer/QTargetWithReg Max                  347.579
trainer/QTargetWithReg Min                    3.5789
trainer/PolicyLossWithoutReg Mean           253.147
trainer/PolicyLossWithoutReg Std             57.7278
trainer/PolicyLossWithoutReg Max            346.391
trainer/PolicyLossWithoutReg Min              2.57993
exploration/num steps total              237000
exploration/num paths total                 967
exploration/path length this epoch Mean      87
exploration/path length this epoch Std        0
exploration/path length this epoch Max       87
exploration/path length this epoch Min       87
exploration/Rewards Mean                      2.03746
exploration/Rewards Std                       1.18934
exploration/Rewards Max                       4.53821
exploration/Rewards Min                      -0.455643
exploration/Returns Mean                    177.259
exploration/Returns Std                       0
exploration/Returns Max                     177.259
exploration/Returns Min                     177.259
exploration/Num Paths                         1
exploration/Average Returns                 177.259
evaluation_0/num steps total                  1.81666e+06
evaluation_0/num paths total               5138
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.26035
evaluation_0/Rewards Std                      0.98227
evaluation_0/Rewards Max                      7.2789
evaluation_0/Rewards Min                     -0.446415
evaluation_0/Returns Mean                  4260.35
evaluation_0/Returns Std                    105.828
evaluation_0/Returns Max                   4415.99
evaluation_0/Returns Min                   4069.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4260.35
time/epoch (s)                                0
time/total (s)                             3674.84
Epoch                                       232
---------------------------------------  ----------------
2022-11-16 17:16:11.763123 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 233 finished
---------------------------------------  ----------------
epoch                                       233
total_step                               238000
replay_pool/size                         238000
trainer/alpha                                 0.0607487
trainer/alpha_loss                            0.750291
trainer/entropy                              -6.26787
trainer/qf_loss                              15.186
trainer/policy_loss                        -258.327
trainer/adversary_policy_loss                12.2948
trainer/policy_loss_without_entropy         258.707
trainer/entropy_penalty                      -0.380765
trainer/entropy_percentage                   -0.0014718
trainer/Q1Pred Mean                         256.6
trainer/Q1Pred Std                           56.6854
trainer/Q1Pred Max                          325.133
trainer/Q1Pred Min                            7.43914
trainer/Q2Pred Mean                         257.765
trainer/Q2Pred Std                           57.1311
trainer/Q2Pred Max                          325.89
trainer/Q2Pred Min                            3.52575
trainer/QTargetWithReg Mean                 257.168
trainer/QTargetWithReg Std                   56.8422
trainer/QTargetWithReg Max                  326.152
trainer/QTargetWithReg Min                    6.42725
trainer/PolicyLossWithoutReg Mean           258.707
trainer/PolicyLossWithoutReg Std             55.4137
trainer/PolicyLossWithoutReg Max            325.546
trainer/PolicyLossWithoutReg Min             14.3478
exploration/num steps total              238000
exploration/num paths total                 968
exploration/path length this epoch Mean     446
exploration/path length this epoch Std        0
exploration/path length this epoch Max      446
exploration/path length this epoch Min      446
exploration/Rewards Mean                      4.25995
exploration/Rewards Std                       1.55687
exploration/Rewards Max                       7.91307
exploration/Rewards Min                      -0.596427
exploration/Returns Mean                   1899.94
exploration/Returns Std                       0
exploration/Returns Max                    1899.94
exploration/Returns Min                    1899.94
exploration/Num Paths                         1
exploration/Average Returns                1899.94
evaluation_0/num steps total                  1.82413e+06
evaluation_0/num paths total               5146
evaluation_0/path length Mean               933.75
evaluation_0/path length Std                127.904
evaluation_0/path length Max               1000
evaluation_0/path length Min                622
evaluation_0/Rewards Mean                     4.13424
evaluation_0/Rewards Std                      1.01665
evaluation_0/Rewards Max                      7.28906
evaluation_0/Rewards Min                     -0.54322
evaluation_0/Returns Mean                  3860.35
evaluation_0/Returns Std                    602.598
evaluation_0/Returns Max                   4281.7
evaluation_0/Returns Min                   2430.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3860.35
time/epoch (s)                                0
time/total (s)                             3688.87
Epoch                                       233
---------------------------------------  ----------------
2022-11-16 17:16:24.202731 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 234 finished
---------------------------------------  ----------------
epoch                                       234
total_step                               239000
replay_pool/size                         239000
trainer/alpha                                 0.0603087
trainer/alpha_loss                           -1.87349
trainer/entropy                              -5.33285
trainer/qf_loss                              13.5453
trainer/policy_loss                        -251.462
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         251.783
trainer/entropy_penalty                      -0.321617
trainer/entropy_percentage                   -0.00127736
trainer/Q1Pred Mean                         250.15
trainer/Q1Pred Std                           70.6075
trainer/Q1Pred Max                          335.081
trainer/Q1Pred Min                           -5.7069
trainer/Q2Pred Mean                         250.381
trainer/Q2Pred Std                           70.5738
trainer/Q2Pred Max                          336.063
trainer/Q2Pred Min                          -10.74
trainer/QTargetWithReg Mean                 250.284
trainer/QTargetWithReg Std                   70.3024
trainer/QTargetWithReg Max                  334.444
trainer/QTargetWithReg Min                   -2.00197
trainer/PolicyLossWithoutReg Mean           251.783
trainer/PolicyLossWithoutReg Std             69.6215
trainer/PolicyLossWithoutReg Max            335.198
trainer/PolicyLossWithoutReg Min             -1.00443
exploration/num steps total              239000
exploration/num paths total                 969
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.90522
exploration/Rewards Std                       0.89456
exploration/Rewards Max                       6.53608
exploration/Rewards Min                      -0.497155
exploration/Returns Mean                   3905.22
exploration/Returns Std                       0
exploration/Returns Max                    3905.22
exploration/Returns Min                    3905.22
exploration/Num Paths                         1
exploration/Average Returns                3905.22
evaluation_0/num steps total                  1.83213e+06
evaluation_0/num paths total               5154
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.16544
evaluation_0/Rewards Std                      0.99977
evaluation_0/Rewards Max                      7.28047
evaluation_0/Rewards Min                     -0.642755
evaluation_0/Returns Mean                  4165.44
evaluation_0/Returns Std                     42.7182
evaluation_0/Returns Max                   4246.85
evaluation_0/Returns Min                   4115.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4165.44
time/epoch (s)                                0
time/total (s)                             3701.31
Epoch                                       234
---------------------------------------  ----------------
2022-11-16 17:16:37.382529 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 235 finished
---------------------------------------  ----------------
epoch                                       235
total_step                               240000
replay_pool/size                         240000
trainer/alpha                                 0.0611842
trainer/alpha_loss                            0.444635
trainer/entropy                              -6.15914
trainer/qf_loss                              17.435
trainer/policy_loss                        -255.536
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         255.913
trainer/entropy_penalty                      -0.376842
trainer/entropy_percentage                   -0.00147254
trainer/Q1Pred Mean                         254.948
trainer/Q1Pred Std                           68.7893
trainer/Q1Pred Max                          331.617
trainer/Q1Pred Min                            6.34755
trainer/Q2Pred Mean                         254.848
trainer/Q2Pred Std                           68.3833
trainer/Q2Pred Max                          333.035
trainer/Q2Pred Min                            6.15848
trainer/QTargetWithReg Mean                 255.336
trainer/QTargetWithReg Std                   68.6615
trainer/QTargetWithReg Max                  335.463
trainer/QTargetWithReg Min                   10.0996
trainer/PolicyLossWithoutReg Mean           255.913
trainer/PolicyLossWithoutReg Std             67.6908
trainer/PolicyLossWithoutReg Max            332.916
trainer/PolicyLossWithoutReg Min              7.7324
exploration/num steps total              240000
exploration/num paths total                 970
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.06686
exploration/Rewards Std                       1.0182
exploration/Rewards Max                       6.49477
exploration/Rewards Min                      -0.596733
exploration/Returns Mean                   4066.86
exploration/Returns Std                       0
exploration/Returns Max                    4066.86
exploration/Returns Min                    4066.86
exploration/Num Paths                         1
exploration/Average Returns                4066.86
evaluation_0/num steps total                  1.84013e+06
evaluation_0/num paths total               5162
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.88789
evaluation_0/Rewards Std                      0.881323
evaluation_0/Rewards Max                      6.33538
evaluation_0/Rewards Min                     -0.553643
evaluation_0/Returns Mean                  3887.89
evaluation_0/Returns Std                     82.2763
evaluation_0/Returns Max                   4053.5
evaluation_0/Returns Min                   3810.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3887.89
time/epoch (s)                                0
time/total (s)                             3714.49
Epoch                                       235
---------------------------------------  ----------------
2022-11-16 17:16:49.884176 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 236 finished
---------------------------------------  ----------------
epoch                                       236
total_step                               241000
replay_pool/size                         241000
trainer/alpha                                 0.0626331
trainer/alpha_loss                           -1.40009
trainer/entropy                              -5.49465
trainer/qf_loss                              12.2471
trainer/policy_loss                        -255.617
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         255.961
trainer/entropy_penalty                      -0.344147
trainer/entropy_percentage                   -0.00134453
trainer/Q1Pred Mean                         254.641
trainer/Q1Pred Std                           69.3181
trainer/Q1Pred Max                          335.911
trainer/Q1Pred Min                            1.89421
trainer/Q2Pred Mean                         255.261
trainer/Q2Pred Std                           69.4484
trainer/Q2Pred Max                          336.302
trainer/Q2Pred Min                            3.17143
trainer/QTargetWithReg Mean                 254.823
trainer/QTargetWithReg Std                   68.9761
trainer/QTargetWithReg Max                  334.089
trainer/QTargetWithReg Min                    2.872
trainer/PolicyLossWithoutReg Mean           255.961
trainer/PolicyLossWithoutReg Std             68.5598
trainer/PolicyLossWithoutReg Max            337.804
trainer/PolicyLossWithoutReg Min              5.59785
exploration/num steps total              241000
exploration/num paths total                 971
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.17659
exploration/Rewards Std                       0.880195
exploration/Rewards Max                       6.10288
exploration/Rewards Min                      -0.427966
exploration/Returns Mean                   4176.59
exploration/Returns Std                       0
exploration/Returns Max                    4176.59
exploration/Returns Min                    4176.59
exploration/Num Paths                         1
exploration/Average Returns                4176.59
evaluation_0/num steps total                  1.84813e+06
evaluation_0/num paths total               5170
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.80677
evaluation_0/Rewards Std                      0.998465
evaluation_0/Rewards Max                      6.16427
evaluation_0/Rewards Min                     -0.678968
evaluation_0/Returns Mean                  3806.77
evaluation_0/Returns Std                    186.635
evaluation_0/Returns Max                   4191.56
evaluation_0/Returns Min                   3616.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3806.77
time/epoch (s)                                0
time/total (s)                             3726.99
Epoch                                       236
---------------------------------------  ----------------
2022-11-16 17:17:02.270809 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 237 finished
---------------------------------------  ----------------
epoch                                       237
total_step                               242000
replay_pool/size                         242000
trainer/alpha                                 0.0614154
trainer/alpha_loss                           -0.401854
trainer/entropy                              -5.85596
trainer/qf_loss                              20.9879
trainer/policy_loss                        -261.516
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         261.876
trainer/entropy_penalty                      -0.359646
trainer/entropy_percentage                   -0.00137335
trainer/Q1Pred Mean                         261.505
trainer/Q1Pred Std                           60.9415
trainer/Q1Pred Max                          338.087
trainer/Q1Pred Min                           21.2143
trainer/Q2Pred Mean                         261.214
trainer/Q2Pred Std                           61.4838
trainer/Q2Pred Max                          336.343
trainer/Q2Pred Min                           15.0275
trainer/QTargetWithReg Mean                 261.53
trainer/QTargetWithReg Std                   61.7312
trainer/QTargetWithReg Max                  334.804
trainer/QTargetWithReg Min                    1.13598
trainer/PolicyLossWithoutReg Mean           261.876
trainer/PolicyLossWithoutReg Std             60.3134
trainer/PolicyLossWithoutReg Max            337.805
trainer/PolicyLossWithoutReg Min             14.7749
exploration/num steps total              242000
exploration/num paths total                 972
exploration/path length this epoch Mean     932
exploration/path length this epoch Std        0
exploration/path length this epoch Max      932
exploration/path length this epoch Min      932
exploration/Rewards Mean                      3.97353
exploration/Rewards Std                       1.16121
exploration/Rewards Max                       6.21206
exploration/Rewards Min                      -0.569758
exploration/Returns Mean                   3703.33
exploration/Returns Std                       0
exploration/Returns Max                    3703.33
exploration/Returns Min                    3703.33
exploration/Num Paths                         1
exploration/Average Returns                3703.33
evaluation_0/num steps total                  1.85613e+06
evaluation_0/num paths total               5178
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.11826
evaluation_0/Rewards Std                      0.833453
evaluation_0/Rewards Max                      6.67634
evaluation_0/Rewards Min                     -0.464589
evaluation_0/Returns Mean                  4118.26
evaluation_0/Returns Std                     97.3471
evaluation_0/Returns Max                   4227.44
evaluation_0/Returns Min                   3963.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4118.26
time/epoch (s)                                0
time/total (s)                             3739.38
Epoch                                       237
---------------------------------------  ----------------
2022-11-16 17:17:15.590890 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 238 finished
---------------------------------------  ----------------
epoch                                       238
total_step                               243000
replay_pool/size                         243000
trainer/alpha                                 0.0612686
trainer/alpha_loss                           -1.14965
trainer/entropy                              -5.58831
trainer/qf_loss                              11.6335
trainer/policy_loss                        -257.271
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         257.614
trainer/entropy_penalty                      -0.342388
trainer/entropy_percentage                   -0.00132907
trainer/Q1Pred Mean                         256.758
trainer/Q1Pred Std                           64.5695
trainer/Q1Pred Max                          332.726
trainer/Q1Pred Min                           -5.26251
trainer/Q2Pred Mean                         256.545
trainer/Q2Pred Std                           64.9931
trainer/Q2Pred Max                          330.585
trainer/Q2Pred Min                           -9.67091
trainer/QTargetWithReg Mean                 256.758
trainer/QTargetWithReg Std                   64.9703
trainer/QTargetWithReg Max                  330.985
trainer/QTargetWithReg Min                  -10.9316
trainer/PolicyLossWithoutReg Mean           257.614
trainer/PolicyLossWithoutReg Std             62.4577
trainer/PolicyLossWithoutReg Max            328.462
trainer/PolicyLossWithoutReg Min              2.91226
exploration/num steps total              243000
exploration/num paths total                 973
exploration/path length this epoch Mean     847
exploration/path length this epoch Std        0
exploration/path length this epoch Max      847
exploration/path length this epoch Min      847
exploration/Rewards Mean                      3.99423
exploration/Rewards Std                       1.02022
exploration/Rewards Max                       6.03056
exploration/Rewards Min                      -0.527809
exploration/Returns Mean                   3383.11
exploration/Returns Std                       0
exploration/Returns Max                    3383.11
exploration/Returns Min                    3383.11
exploration/Num Paths                         1
exploration/Average Returns                3383.11
evaluation_0/num steps total                  1.86413e+06
evaluation_0/num paths total               5186
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.93762
evaluation_0/Rewards Std                      0.912837
evaluation_0/Rewards Max                      6.73851
evaluation_0/Rewards Min                     -0.497906
evaluation_0/Returns Mean                  3937.62
evaluation_0/Returns Std                     82.4122
evaluation_0/Returns Max                   4116.33
evaluation_0/Returns Min                   3849.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3937.62
time/epoch (s)                                0
time/total (s)                             3752.7
Epoch                                       238
---------------------------------------  ----------------
2022-11-16 17:17:27.917932 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 239 finished
---------------------------------------  ----------------
epoch                                       239
total_step                               244000
replay_pool/size                         244000
trainer/alpha                                 0.0604558
trainer/alpha_loss                           -0.582886
trainer/entropy                              -5.79226
trainer/qf_loss                              13.1945
trainer/policy_loss                        -263.503
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         263.853
trainer/entropy_penalty                      -0.350176
trainer/entropy_percentage                   -0.00132716
trainer/Q1Pred Mean                         263.659
trainer/Q1Pred Std                           58.1884
trainer/Q1Pred Max                          341.445
trainer/Q1Pred Min                            0.536007
trainer/Q2Pred Mean                         263.981
trainer/Q2Pred Std                           57.9226
trainer/Q2Pred Max                          343.868
trainer/Q2Pred Min                            4.58402
trainer/QTargetWithReg Mean                 263.164
trainer/QTargetWithReg Std                   57.7938
trainer/QTargetWithReg Max                  342.77
trainer/QTargetWithReg Min                    7.08211
trainer/PolicyLossWithoutReg Mean           263.853
trainer/PolicyLossWithoutReg Std             57.3264
trainer/PolicyLossWithoutReg Max            341.562
trainer/PolicyLossWithoutReg Min              3.82757
exploration/num steps total              244000
exploration/num paths total                 974
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15082
exploration/Rewards Std                       0.986131
exploration/Rewards Max                       6.81946
exploration/Rewards Min                      -0.325985
exploration/Returns Mean                   4150.82
exploration/Returns Std                       0
exploration/Returns Max                    4150.82
exploration/Returns Min                    4150.82
exploration/Num Paths                         1
exploration/Average Returns                4150.82
evaluation_0/num steps total                  1.87213e+06
evaluation_0/num paths total               5194
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.30464
evaluation_0/Rewards Std                      0.90932
evaluation_0/Rewards Max                      7.0626
evaluation_0/Rewards Min                     -0.482299
evaluation_0/Returns Mean                  4304.64
evaluation_0/Returns Std                     74.5502
evaluation_0/Returns Max                   4436.03
evaluation_0/Returns Min                   4231.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4304.64
time/epoch (s)                                0
time/total (s)                             3765.02
Epoch                                       239
---------------------------------------  ----------------
2022-11-16 17:17:40.308591 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 240 finished
---------------------------------------  ----------------
epoch                                       240
total_step                               245000
replay_pool/size                         245000
trainer/alpha                                 0.0619283
trainer/alpha_loss                            0.0220813
trainer/entropy                              -6.00794
trainer/qf_loss                              15.0901
trainer/policy_loss                        -267.653
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         268.025
trainer/entropy_penalty                      -0.372061
trainer/entropy_percentage                   -0.00138816
trainer/Q1Pred Mean                         266.457
trainer/Q1Pred Std                           53.5135
trainer/Q1Pred Max                          347.783
trainer/Q1Pred Min                           -5.01859
trainer/Q2Pred Mean                         266.027
trainer/Q2Pred Std                           53.194
trainer/Q2Pred Max                          344.592
trainer/Q2Pred Min                           -7.61759
trainer/QTargetWithReg Mean                 265.976
trainer/QTargetWithReg Std                   53.5228
trainer/QTargetWithReg Max                  343.542
trainer/QTargetWithReg Min                   -7.22176
trainer/PolicyLossWithoutReg Mean           268.025
trainer/PolicyLossWithoutReg Std             51.4613
trainer/PolicyLossWithoutReg Max            343.446
trainer/PolicyLossWithoutReg Min              6.69524
exploration/num steps total              245000
exploration/num paths total                 975
exploration/path length this epoch Mean     187
exploration/path length this epoch Std        0
exploration/path length this epoch Max      187
exploration/path length this epoch Min      187
exploration/Rewards Mean                      2.76535
exploration/Rewards Std                       1.36015
exploration/Rewards Max                       5.61822
exploration/Rewards Min                      -0.500259
exploration/Returns Mean                    517.121
exploration/Returns Std                       0
exploration/Returns Max                     517.121
exploration/Returns Min                     517.121
exploration/Num Paths                         1
exploration/Average Returns                 517.121
evaluation_0/num steps total                  1.88013e+06
evaluation_0/num paths total               5202
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.19056
evaluation_0/Rewards Std                      0.948862
evaluation_0/Rewards Max                      6.15175
evaluation_0/Rewards Min                     -0.550783
evaluation_0/Returns Mean                  4190.56
evaluation_0/Returns Std                     96.1444
evaluation_0/Returns Max                   4397.41
evaluation_0/Returns Min                   4065.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4190.56
time/epoch (s)                                0
time/total (s)                             3777.41
Epoch                                       240
---------------------------------------  ----------------
2022-11-16 17:17:53.518574 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 241 finished
---------------------------------------  ----------------
epoch                                       241
total_step                               246000
replay_pool/size                         246000
trainer/alpha                                 0.0619741
trainer/alpha_loss                            0.257917
trainer/entropy                              -6.09274
trainer/qf_loss                              14.4335
trainer/policy_loss                        -257.234
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         257.612
trainer/entropy_penalty                      -0.377592
trainer/entropy_percentage                   -0.00146574
trainer/Q1Pred Mean                         256.551
trainer/Q1Pred Std                           67.883
trainer/Q1Pred Max                          330.262
trainer/Q1Pred Min                          -12.2168
trainer/Q2Pred Mean                         256.984
trainer/Q2Pred Std                           67.5154
trainer/Q2Pred Max                          327.434
trainer/Q2Pred Min                          -11.4168
trainer/QTargetWithReg Mean                 256.34
trainer/QTargetWithReg Std                   67.7664
trainer/QTargetWithReg Max                  328.459
trainer/QTargetWithReg Min                  -11.8965
trainer/PolicyLossWithoutReg Mean           257.612
trainer/PolicyLossWithoutReg Std             66.9713
trainer/PolicyLossWithoutReg Max            333.657
trainer/PolicyLossWithoutReg Min             -7.97048
exploration/num steps total              246000
exploration/num paths total                 976
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.85047
exploration/Rewards Std                       1.03029
exploration/Rewards Max                       5.93116
exploration/Rewards Min                      -0.494357
exploration/Returns Mean                   3850.47
exploration/Returns Std                       0
exploration/Returns Max                    3850.47
exploration/Returns Min                    3850.47
exploration/Num Paths                         1
exploration/Average Returns                3850.47
evaluation_0/num steps total                  1.88813e+06
evaluation_0/num paths total               5210
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.89695
evaluation_0/Rewards Std                      0.915967
evaluation_0/Rewards Max                      5.72272
evaluation_0/Rewards Min                     -0.55722
evaluation_0/Returns Mean                  3896.95
evaluation_0/Returns Std                     63.6839
evaluation_0/Returns Max                   3956.03
evaluation_0/Returns Min                   3747.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3896.95
time/epoch (s)                                0
time/total (s)                             3790.62
Epoch                                       241
---------------------------------------  ----------------
2022-11-16 17:18:05.910747 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 242 finished
---------------------------------------  ----------------
epoch                                       242
total_step                               247000
replay_pool/size                         247000
trainer/alpha                                 0.0615305
trainer/alpha_loss                           -0.0754676
trainer/entropy                              -5.97293
trainer/qf_loss                              11.9328
trainer/policy_loss                        -266.453
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         266.82
trainer/entropy_penalty                      -0.367518
trainer/entropy_percentage                   -0.0013774
trainer/Q1Pred Mean                         265.816
trainer/Q1Pred Std                           57.5321
trainer/Q1Pred Max                          343.205
trainer/Q1Pred Min                           -0.874928
trainer/Q2Pred Mean                         265.619
trainer/Q2Pred Std                           57.5985
trainer/Q2Pred Max                          343.889
trainer/Q2Pred Min                           -2.69289
trainer/QTargetWithReg Mean                 265.838
trainer/QTargetWithReg Std                   57.2345
trainer/QTargetWithReg Max                  342.481
trainer/QTargetWithReg Min                    3.73918
trainer/PolicyLossWithoutReg Mean           266.82
trainer/PolicyLossWithoutReg Std             56.5612
trainer/PolicyLossWithoutReg Max            342.912
trainer/PolicyLossWithoutReg Min              1.75742
exploration/num steps total              247000
exploration/num paths total                 978
exploration/path length this epoch Mean     417
exploration/path length this epoch Std      362
exploration/path length this epoch Max      779
exploration/path length this epoch Min       55
exploration/Rewards Mean                      3.81073
exploration/Rewards Std                       1.32938
exploration/Rewards Max                       6.55726
exploration/Rewards Min                      -0.763115
exploration/Returns Mean                   1589.07
exploration/Returns Std                    1522.4
exploration/Returns Max                    3111.48
exploration/Returns Min                      66.6704
exploration/Num Paths                         2
exploration/Average Returns                1589.07
evaluation_0/num steps total                  1.89613e+06
evaluation_0/num paths total               5218
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.21282
evaluation_0/Rewards Std                      0.964265
evaluation_0/Rewards Max                      7.39652
evaluation_0/Rewards Min                     -0.540309
evaluation_0/Returns Mean                  4212.82
evaluation_0/Returns Std                     64.1434
evaluation_0/Returns Max                   4307.11
evaluation_0/Returns Min                   4084.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4212.82
time/epoch (s)                                0
time/total (s)                             3803.01
Epoch                                       242
---------------------------------------  ----------------
2022-11-16 17:18:20.193149 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 243 finished
---------------------------------------  ----------------
epoch                                       243
total_step                               248000
replay_pool/size                         248000
trainer/alpha                                 0.0623049
trainer/alpha_loss                           -0.719935
trainer/entropy                              -5.74062
trainer/qf_loss                              17.9456
trainer/policy_loss                        -257.385
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         257.743
trainer/entropy_penalty                      -0.357669
trainer/entropy_percentage                   -0.0013877
trainer/Q1Pred Mean                         255.87
trainer/Q1Pred Std                           71.3806
trainer/Q1Pred Max                          338.931
trainer/Q1Pred Min                            5.14714
trainer/Q2Pred Mean                         255.894
trainer/Q2Pred Std                           70.8886
trainer/Q2Pred Max                          342.713
trainer/Q2Pred Min                           -8.71591
trainer/QTargetWithReg Mean                 256.326
trainer/QTargetWithReg Std                   71.0453
trainer/QTargetWithReg Max                  346.391
trainer/QTargetWithReg Min                    0.245932
trainer/PolicyLossWithoutReg Mean           257.743
trainer/PolicyLossWithoutReg Std             69.1513
trainer/PolicyLossWithoutReg Max            337.629
trainer/PolicyLossWithoutReg Min              1.93794
exploration/num steps total              248000
exploration/num paths total                 979
exploration/path length this epoch Mean     807
exploration/path length this epoch Std        0
exploration/path length this epoch Max      807
exploration/path length this epoch Min      807
exploration/Rewards Mean                      4.05324
exploration/Rewards Std                       1.118
exploration/Rewards Max                       6.49271
exploration/Rewards Min                      -0.52257
exploration/Returns Mean                   3270.97
exploration/Returns Std                       0
exploration/Returns Max                    3270.97
exploration/Returns Min                    3270.97
exploration/Num Paths                         1
exploration/Average Returns                3270.97
evaluation_0/num steps total                  1.90349e+06
evaluation_0/num paths total               5227
evaluation_0/path length Mean               817.556
evaluation_0/path length Std                341.338
evaluation_0/path length Max               1000
evaluation_0/path length Min                172
evaluation_0/Rewards Mean                     3.85012
evaluation_0/Rewards Std                      1.00093
evaluation_0/Rewards Max                      6.47407
evaluation_0/Rewards Min                     -0.502424
evaluation_0/Returns Mean                  3147.69
evaluation_0/Returns Std                   1467.42
evaluation_0/Returns Max                   4086.59
evaluation_0/Returns Min                    388.341
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3147.69
time/epoch (s)                                0
time/total (s)                             3817.3
Epoch                                       243
---------------------------------------  ----------------
2022-11-16 17:18:32.780210 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 244 finished
---------------------------------------  ----------------
epoch                                       244
total_step                               249000
replay_pool/size                         249000
trainer/alpha                                 0.0604332
trainer/alpha_loss                           -0.238373
trainer/entropy                              -5.91505
trainer/qf_loss                              20.7254
trainer/policy_loss                        -260.078
trainer/adversary_policy_loss                12.4114
trainer/policy_loss_without_entropy         260.435
trainer/entropy_penalty                      -0.357466
trainer/entropy_percentage                   -0.00137257
trainer/Q1Pred Mean                         259.062
trainer/Q1Pred Std                           65.3753
trainer/Q1Pred Max                          334.101
trainer/Q1Pred Min                          -24.2758
trainer/Q2Pred Mean                         258.294
trainer/Q2Pred Std                           66.1882
trainer/Q2Pred Max                          331.492
trainer/Q2Pred Min                          -25.4242
trainer/QTargetWithReg Mean                 259.058
trainer/QTargetWithReg Std                   65.6569
trainer/QTargetWithReg Max                  332.757
trainer/QTargetWithReg Min                  -22.7423
trainer/PolicyLossWithoutReg Mean           260.435
trainer/PolicyLossWithoutReg Std             64.2896
trainer/PolicyLossWithoutReg Max            331.521
trainer/PolicyLossWithoutReg Min            -24.1066
exploration/num steps total              249000
exploration/num paths total                 980
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.12953
exploration/Rewards Std                       1.0754
exploration/Rewards Max                       7.28442
exploration/Rewards Min                      -0.486182
exploration/Returns Mean                   4129.53
exploration/Returns Std                       0
exploration/Returns Max                    4129.53
exploration/Returns Min                    4129.53
exploration/Num Paths                         1
exploration/Average Returns                4129.53
evaluation_0/num steps total                  1.91149e+06
evaluation_0/num paths total               5235
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.93515
evaluation_0/Rewards Std                      1.03727
evaluation_0/Rewards Max                      6.22824
evaluation_0/Rewards Min                     -0.656543
evaluation_0/Returns Mean                  3935.15
evaluation_0/Returns Std                    119.826
evaluation_0/Returns Max                   4116.72
evaluation_0/Returns Min                   3716.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3935.15
time/epoch (s)                                0
time/total (s)                             3829.88
Epoch                                       244
---------------------------------------  ----------------
2022-11-16 17:18:45.135284 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 245 finished
---------------------------------------  ----------------
epoch                                       245
total_step                               250000
replay_pool/size                         250000
trainer/alpha                                 0.0617047
trainer/alpha_loss                            0.0556171
trainer/entropy                              -6.01997
trainer/qf_loss                              14.4657
trainer/policy_loss                        -259.316
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         259.687
trainer/entropy_penalty                      -0.37146
trainer/entropy_percentage                   -0.00143041
trainer/Q1Pred Mean                         258.783
trainer/Q1Pred Std                           63.8433
trainer/Q1Pred Max                          337.968
trainer/Q1Pred Min                           24.8108
trainer/Q2Pred Mean                         258.759
trainer/Q2Pred Std                           64.0886
trainer/Q2Pred Max                          335.764
trainer/Q2Pred Min                           26.243
trainer/QTargetWithReg Mean                 258.079
trainer/QTargetWithReg Std                   63.8554
trainer/QTargetWithReg Max                  336.309
trainer/QTargetWithReg Min                   29.6245
trainer/PolicyLossWithoutReg Mean           259.687
trainer/PolicyLossWithoutReg Std             62.7405
trainer/PolicyLossWithoutReg Max            336.816
trainer/PolicyLossWithoutReg Min             25.3784
exploration/num steps total              250000
exploration/num paths total                 981
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.25288
exploration/Rewards Std                       1.00223
exploration/Rewards Max                       6.63227
exploration/Rewards Min                      -0.654783
exploration/Returns Mean                   4252.88
exploration/Returns Std                       0
exploration/Returns Max                    4252.88
exploration/Returns Min                    4252.88
exploration/Num Paths                         1
exploration/Average Returns                4252.88
evaluation_0/num steps total                  1.91949e+06
evaluation_0/num paths total               5243
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.38777
evaluation_0/Rewards Std                      1.07747
evaluation_0/Rewards Max                      6.86657
evaluation_0/Rewards Min                     -0.588547
evaluation_0/Returns Mean                  4387.77
evaluation_0/Returns Std                    114.065
evaluation_0/Returns Max                   4497.94
evaluation_0/Returns Min                   4181.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4387.77
time/epoch (s)                                0
time/total (s)                             3842.24
Epoch                                       245
---------------------------------------  ----------------
2022-11-16 17:18:57.514600 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 246 finished
---------------------------------------  ----------------
epoch                                       246
total_step                               251000
replay_pool/size                         251000
trainer/alpha                                 0.0612506
trainer/alpha_loss                            0.985892
trainer/entropy                              -6.35299
trainer/qf_loss                              19.9406
trainer/policy_loss                        -270.346
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         270.735
trainer/entropy_penalty                      -0.389124
trainer/entropy_percentage                   -0.00143729
trainer/Q1Pred Mean                         269.857
trainer/Q1Pred Std                           58.3012
trainer/Q1Pred Max                          342.409
trainer/Q1Pred Min                           12.3179
trainer/Q2Pred Mean                         269.803
trainer/Q2Pred Std                           58.4435
trainer/Q2Pred Max                          347.423
trainer/Q2Pred Min                           13.2068
trainer/QTargetWithReg Mean                 267.765
trainer/QTargetWithReg Std                   58.8313
trainer/QTargetWithReg Max                  348.192
trainer/QTargetWithReg Min                    9.5003
trainer/PolicyLossWithoutReg Mean           270.735
trainer/PolicyLossWithoutReg Std             57.1178
trainer/PolicyLossWithoutReg Max            343.497
trainer/PolicyLossWithoutReg Min             11.8449
exploration/num steps total              251000
exploration/num paths total                 982
exploration/path length this epoch Mean     403
exploration/path length this epoch Std        0
exploration/path length this epoch Max      403
exploration/path length this epoch Min      403
exploration/Rewards Mean                      3.23944
exploration/Rewards Std                       1.35373
exploration/Rewards Max                       5.89338
exploration/Rewards Min                      -0.434116
exploration/Returns Mean                   1305.49
exploration/Returns Std                       0
exploration/Returns Max                    1305.49
exploration/Returns Min                    1305.49
exploration/Num Paths                         1
exploration/Average Returns                1305.49
evaluation_0/num steps total                  1.92749e+06
evaluation_0/num paths total               5251
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.15541
evaluation_0/Rewards Std                      0.974723
evaluation_0/Rewards Max                      7.1556
evaluation_0/Rewards Min                     -0.46535
evaluation_0/Returns Mean                  4155.41
evaluation_0/Returns Std                    202.477
evaluation_0/Returns Max                   4410.75
evaluation_0/Returns Min                   3856
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4155.41
time/epoch (s)                                0
time/total (s)                             3854.62
Epoch                                       246
---------------------------------------  ----------------
2022-11-16 17:19:12.330599 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 247 finished
---------------------------------------  ----------------
epoch                                       247
total_step                               252000
replay_pool/size                         252000
trainer/alpha                                 0.0618108
trainer/alpha_loss                           -0.235986
trainer/entropy                              -5.91522
trainer/qf_loss                              19.1934
trainer/policy_loss                        -257.482
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         257.848
trainer/entropy_penalty                      -0.365625
trainer/entropy_percentage                   -0.00141798
trainer/Q1Pred Mean                         255.554
trainer/Q1Pred Std                           68.8974
trainer/Q1Pred Max                          344.561
trainer/Q1Pred Min                           -1.21626
trainer/Q2Pred Mean                         255.916
trainer/Q2Pred Std                           68.7397
trainer/Q2Pred Max                          343.968
trainer/Q2Pred Min                           -1.47855
trainer/QTargetWithReg Mean                 255.994
trainer/QTargetWithReg Std                   68.8637
trainer/QTargetWithReg Max                  342.112
trainer/QTargetWithReg Min                    5.61597
trainer/PolicyLossWithoutReg Mean           257.848
trainer/PolicyLossWithoutReg Std             66.5707
trainer/PolicyLossWithoutReg Max            343.772
trainer/PolicyLossWithoutReg Min              1.30579
exploration/num steps total              252000
exploration/num paths total                 983
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55167
exploration/Rewards Std                       1.19867
exploration/Rewards Max                       7.08723
exploration/Rewards Min                      -0.454474
exploration/Returns Mean                   4551.67
exploration/Returns Std                       0
exploration/Returns Max                    4551.67
exploration/Returns Min                    4551.67
exploration/Num Paths                         1
exploration/Average Returns                4551.67
evaluation_0/num steps total                  1.93522e+06
evaluation_0/num paths total               5260
evaluation_0/path length Mean               859
evaluation_0/path length Std                204.496
evaluation_0/path length Max               1000
evaluation_0/path length Min                425
evaluation_0/Rewards Mean                     4.13564
evaluation_0/Rewards Std                      1.07358
evaluation_0/Rewards Max                      8.07687
evaluation_0/Rewards Min                     -0.434185
evaluation_0/Returns Mean                  3552.51
evaluation_0/Returns Std                    926.806
evaluation_0/Returns Max                   4274.47
evaluation_0/Returns Min                   1574.14
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3552.51
time/epoch (s)                                0
time/total (s)                             3869.43
Epoch                                       247
---------------------------------------  ----------------
2022-11-16 17:19:26.220176 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 248 finished
---------------------------------------  ----------------
epoch                                       248
total_step                               253000
replay_pool/size                         253000
trainer/alpha                                 0.0601484
trainer/alpha_loss                           -0.106688
trainer/entropy                              -5.96205
trainer/qf_loss                              18.9004
trainer/policy_loss                        -265.93
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         266.289
trainer/entropy_penalty                      -0.358608
trainer/entropy_percentage                   -0.00134669
trainer/Q1Pred Mean                         265.223
trainer/Q1Pred Std                           64.7105
trainer/Q1Pred Max                          340.381
trainer/Q1Pred Min                            4.23962
trainer/Q2Pred Mean                         266.136
trainer/Q2Pred Std                           64.9156
trainer/Q2Pred Max                          343.04
trainer/Q2Pred Min                            9.64915
trainer/QTargetWithReg Mean                 265.57
trainer/QTargetWithReg Std                   64.5821
trainer/QTargetWithReg Max                  340.346
trainer/QTargetWithReg Min                   10.9681
trainer/PolicyLossWithoutReg Mean           266.289
trainer/PolicyLossWithoutReg Std             63.2613
trainer/PolicyLossWithoutReg Max            339.38
trainer/PolicyLossWithoutReg Min             10.7907
exploration/num steps total              253000
exploration/num paths total                 984
exploration/path length this epoch Mean     818
exploration/path length this epoch Std        0
exploration/path length this epoch Max      818
exploration/path length this epoch Min      818
exploration/Rewards Mean                      3.87477
exploration/Rewards Std                       1.10926
exploration/Rewards Max                       6.0168
exploration/Rewards Min                      -0.150189
exploration/Returns Mean                   3169.56
exploration/Returns Std                       0
exploration/Returns Max                    3169.56
exploration/Returns Min                    3169.56
exploration/Num Paths                         1
exploration/Average Returns                3169.56
evaluation_0/num steps total                  1.94274e+06
evaluation_0/num paths total               5269
evaluation_0/path length Mean               836.222
evaluation_0/path length Std                229.199
evaluation_0/path length Max               1000
evaluation_0/path length Min                400
evaluation_0/Rewards Mean                     4.29232
evaluation_0/Rewards Std                      1.20009
evaluation_0/Rewards Max                      8.65095
evaluation_0/Rewards Min                     -0.579952
evaluation_0/Returns Mean                  3589.33
evaluation_0/Returns Std                   1162.62
evaluation_0/Returns Max                   4489.31
evaluation_0/Returns Min                   1401.44
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3589.33
time/epoch (s)                                0
time/total (s)                             3883.32
Epoch                                       248
---------------------------------------  ----------------
2022-11-16 17:19:40.748522 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 249 finished
---------------------------------------  ----------------
epoch                                       249
total_step                               254000
replay_pool/size                         254000
trainer/alpha                                 0.0615511
trainer/alpha_loss                           -0.00672689
trainer/entropy                              -5.99759
trainer/qf_loss                              14.2139
trainer/policy_loss                        -264.564
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         264.933
trainer/entropy_penalty                      -0.369158
trainer/entropy_percentage                   -0.0013934
trainer/Q1Pred Mean                         262.809
trainer/Q1Pred Std                           66.1315
trainer/Q1Pred Max                          343.184
trainer/Q1Pred Min                           12.5398
trainer/Q2Pred Mean                         262.555
trainer/Q2Pred Std                           65.9856
trainer/Q2Pred Max                          343.205
trainer/Q2Pred Min                           13.226
trainer/QTargetWithReg Mean                 262.575
trainer/QTargetWithReg Std                   66.6136
trainer/QTargetWithReg Max                  345.763
trainer/QTargetWithReg Min                    6.56174
trainer/PolicyLossWithoutReg Mean           264.933
trainer/PolicyLossWithoutReg Std             64.3253
trainer/PolicyLossWithoutReg Max            344.835
trainer/PolicyLossWithoutReg Min             14.3168
exploration/num steps total              254000
exploration/num paths total                 985
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.83002
exploration/Rewards Std                       1.03432
exploration/Rewards Max                       6.26973
exploration/Rewards Min                      -0.613284
exploration/Returns Mean                   3830.02
exploration/Returns Std                       0
exploration/Returns Max                    3830.02
exploration/Returns Min                    3830.02
exploration/Num Paths                         1
exploration/Average Returns                3830.02
evaluation_0/num steps total                  1.95040e+06
evaluation_0/num paths total               5277
evaluation_0/path length Mean               957.5
evaluation_0/path length Std                112.444
evaluation_0/path length Max               1000
evaluation_0/path length Min                660
evaluation_0/Rewards Mean                     4.1701
evaluation_0/Rewards Std                      0.974402
evaluation_0/Rewards Max                      7.54197
evaluation_0/Rewards Min                     -0.703776
evaluation_0/Returns Mean                  3992.87
evaluation_0/Returns Std                    470.658
evaluation_0/Returns Max                   4353.82
evaluation_0/Returns Min                   2779.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3992.87
time/epoch (s)                                0
time/total (s)                             3897.85
Epoch                                       249
---------------------------------------  ----------------
2022-11-16 17:19:54.800695 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 250 finished
---------------------------------------  ----------------
epoch                                       250
total_step                               255000
replay_pool/size                         255000
trainer/alpha                                 0.0612012
trainer/alpha_loss                           -0.100163
trainer/entropy                              -5.96414
trainer/qf_loss                              15.7149
trainer/policy_loss                        -274.995
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         275.36
trainer/entropy_penalty                      -0.365013
trainer/entropy_percentage                   -0.00132558
trainer/Q1Pred Mean                         274.844
trainer/Q1Pred Std                           54.899
trainer/Q1Pred Max                          348.588
trainer/Q1Pred Min                           -4.93914
trainer/Q2Pred Mean                         275.199
trainer/Q2Pred Std                           54.4705
trainer/Q2Pred Max                          349.647
trainer/Q2Pred Min                            0.507031
trainer/QTargetWithReg Mean                 274.644
trainer/QTargetWithReg Std                   54.7338
trainer/QTargetWithReg Max                  347.619
trainer/QTargetWithReg Min                   -2.44153
trainer/PolicyLossWithoutReg Mean           275.36
trainer/PolicyLossWithoutReg Std             53.7525
trainer/PolicyLossWithoutReg Max            348.137
trainer/PolicyLossWithoutReg Min              2.9541
exploration/num steps total              255000
exploration/num paths total                 986
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.01526
exploration/Rewards Std                       1.08422
exploration/Rewards Max                       6.61138
exploration/Rewards Min                      -0.603865
exploration/Returns Mean                   4015.26
exploration/Returns Std                       0
exploration/Returns Max                    4015.26
exploration/Returns Min                    4015.26
exploration/Num Paths                         1
exploration/Average Returns                4015.26
evaluation_0/num steps total                  1.95776e+06
evaluation_0/num paths total               5285
evaluation_0/path length Mean               919.625
evaluation_0/path length Std                140.102
evaluation_0/path length Max               1000
evaluation_0/path length Min                647
evaluation_0/Rewards Mean                     4.19739
evaluation_0/Rewards Std                      1.12072
evaluation_0/Rewards Max                      7.10047
evaluation_0/Rewards Min                     -0.505294
evaluation_0/Returns Mean                  3860.03
evaluation_0/Returns Std                    717.305
evaluation_0/Returns Max                   4324.76
evaluation_0/Returns Min                   2520.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3860.03
time/epoch (s)                                0
time/total (s)                             3911.9
Epoch                                       250
---------------------------------------  ----------------
2022-11-16 17:20:08.739567 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 251 finished
---------------------------------------  ----------------
epoch                                       251
total_step                               256000
replay_pool/size                         256000
trainer/alpha                                 0.0614084
trainer/alpha_loss                           -0.252168
trainer/entropy                              -5.90963
trainer/qf_loss                              28.5431
trainer/policy_loss                        -259.68
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         260.043
trainer/entropy_penalty                      -0.362901
trainer/entropy_percentage                   -0.00139554
trainer/Q1Pred Mean                         258.222
trainer/Q1Pred Std                           70.7255
trainer/Q1Pred Max                          340.531
trainer/Q1Pred Min                            7.5287
trainer/Q2Pred Mean                         258.572
trainer/Q2Pred Std                           70.7152
trainer/Q2Pred Max                          342.328
trainer/Q2Pred Min                           -1.78446
trainer/QTargetWithReg Mean                 259.054
trainer/QTargetWithReg Std                   71.2358
trainer/QTargetWithReg Max                  343.599
trainer/QTargetWithReg Min                    2.48223
trainer/PolicyLossWithoutReg Mean           260.043
trainer/PolicyLossWithoutReg Std             69.8178
trainer/PolicyLossWithoutReg Max            339.63
trainer/PolicyLossWithoutReg Min              8.39571
exploration/num steps total              256000
exploration/num paths total                 987
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.1678
exploration/Rewards Std                       0.94634
exploration/Rewards Max                       6.44186
exploration/Rewards Min                      -0.313294
exploration/Returns Mean                   4167.8
exploration/Returns Std                       0
exploration/Returns Max                    4167.8
exploration/Returns Min                    4167.8
exploration/Num Paths                         1
exploration/Average Returns                4167.8
evaluation_0/num steps total                  1.96537e+06
evaluation_0/num paths total               5293
evaluation_0/path length Mean               950.75
evaluation_0/path length Std                130.303
evaluation_0/path length Max               1000
evaluation_0/path length Min                606
evaluation_0/Rewards Mean                     4.2105
evaluation_0/Rewards Std                      1.06666
evaluation_0/Rewards Max                      7.65861
evaluation_0/Rewards Min                     -0.383917
evaluation_0/Returns Mean                  4003.14
evaluation_0/Returns Std                    520.579
evaluation_0/Returns Max                   4366.59
evaluation_0/Returns Min                   2646.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4003.14
time/epoch (s)                                0
time/total (s)                             3925.84
Epoch                                       251
---------------------------------------  ----------------
2022-11-16 17:20:23.451638 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 252 finished
---------------------------------------  ----------------
epoch                                       252
total_step                               257000
replay_pool/size                         257000
trainer/alpha                                 0.0610629
trainer/alpha_loss                           -0.201698
trainer/entropy                              -5.92786
trainer/qf_loss                              19.9981
trainer/policy_loss                        -268.234
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         268.596
trainer/entropy_penalty                      -0.361972
trainer/entropy_percentage                   -0.00134765
trainer/Q1Pred Mean                         266.687
trainer/Q1Pred Std                           59.1178
trainer/Q1Pred Max                          340.158
trainer/Q1Pred Min                            6.7137
trainer/Q2Pred Mean                         267.019
trainer/Q2Pred Std                           59.0063
trainer/Q2Pred Max                          339.975
trainer/Q2Pred Min                            5.68831
trainer/QTargetWithReg Mean                 266.705
trainer/QTargetWithReg Std                   58.5982
trainer/QTargetWithReg Max                  339.632
trainer/QTargetWithReg Min                   -0.271352
trainer/PolicyLossWithoutReg Mean           268.596
trainer/PolicyLossWithoutReg Std             56.4727
trainer/PolicyLossWithoutReg Max            339.136
trainer/PolicyLossWithoutReg Min              8.02026
exploration/num steps total              257000
exploration/num paths total                 988
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.91538
exploration/Rewards Std                       1.25169
exploration/Rewards Max                       6.3823
exploration/Rewards Min                      -0.46782
exploration/Returns Mean                   3915.38
exploration/Returns Std                       0
exploration/Returns Max                    3915.38
exploration/Returns Min                    3915.38
exploration/Num Paths                         1
exploration/Average Returns                3915.38
evaluation_0/num steps total                  1.97288e+06
evaluation_0/num paths total               5301
evaluation_0/path length Mean               939
evaluation_0/path length Std                151.803
evaluation_0/path length Max               1000
evaluation_0/path length Min                538
evaluation_0/Rewards Mean                     4.28382
evaluation_0/Rewards Std                      1.08883
evaluation_0/Rewards Max                      8.00648
evaluation_0/Rewards Min                     -0.435843
evaluation_0/Returns Mean                  4022.51
evaluation_0/Returns Std                    639.214
evaluation_0/Returns Max                   4541.99
evaluation_0/Returns Min                   2367.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4022.51
time/epoch (s)                                0
time/total (s)                             3940.55
Epoch                                       252
---------------------------------------  ----------------
2022-11-16 17:20:37.420774 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 253 finished
---------------------------------------  ----------------
epoch                                       253
total_step                               258000
replay_pool/size                         258000
trainer/alpha                                 0.0615355
trainer/alpha_loss                           -0.488708
trainer/entropy                              -5.82472
trainer/qf_loss                              17.566
trainer/policy_loss                        -273.06
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         273.419
trainer/entropy_penalty                      -0.358427
trainer/entropy_percentage                   -0.00131091
trainer/Q1Pred Mean                         272.581
trainer/Q1Pred Std                           55.9121
trainer/Q1Pred Max                          348.054
trainer/Q1Pred Min                           18.4484
trainer/Q2Pred Mean                         272.7
trainer/Q2Pred Std                           55.3455
trainer/Q2Pred Max                          347.707
trainer/Q2Pred Min                           21.0592
trainer/QTargetWithReg Mean                 272.385
trainer/QTargetWithReg Std                   56.8065
trainer/QTargetWithReg Max                  348.386
trainer/QTargetWithReg Min                   -0.0834447
trainer/PolicyLossWithoutReg Mean           273.419
trainer/PolicyLossWithoutReg Std             54.1793
trainer/PolicyLossWithoutReg Max            347.099
trainer/PolicyLossWithoutReg Min             20.5474
exploration/num steps total              258000
exploration/num paths total                 989
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.24062
exploration/Rewards Std                       1.12361
exploration/Rewards Max                       7.33314
exploration/Rewards Min                      -0.522724
exploration/Returns Mean                   4240.62
exploration/Returns Std                       0
exploration/Returns Max                    4240.62
exploration/Returns Min                    4240.62
exploration/Num Paths                         1
exploration/Average Returns                4240.62
evaluation_0/num steps total                  1.98027e+06
evaluation_0/num paths total               5309
evaluation_0/path length Mean               924
evaluation_0/path length Std                131.651
evaluation_0/path length Max               1000
evaluation_0/path length Min                692
evaluation_0/Rewards Mean                     4.09211
evaluation_0/Rewards Std                      0.961321
evaluation_0/Rewards Max                      6.76428
evaluation_0/Rewards Min                     -0.614747
evaluation_0/Returns Mean                  3781.11
evaluation_0/Returns Std                    639.961
evaluation_0/Returns Max                   4430.26
evaluation_0/Returns Min                   2684.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3781.11
time/epoch (s)                                0
time/total (s)                             3954.52
Epoch                                       253
---------------------------------------  ----------------
2022-11-16 17:20:51.352371 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 254 finished
---------------------------------------  ---------------
epoch                                       254
total_step                               259000
replay_pool/size                         259000
trainer/alpha                                 0.0627059
trainer/alpha_loss                           -0.188887
trainer/entropy                              -5.93179
trainer/qf_loss                              17.4784
trainer/policy_loss                        -268.267
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         268.639
trainer/entropy_penalty                      -0.371958
trainer/entropy_percentage                   -0.0013846
trainer/Q1Pred Mean                         267.457
trainer/Q1Pred Std                           65.2567
trainer/Q1Pred Max                          340.832
trainer/Q1Pred Min                            0.788451
trainer/Q2Pred Mean                         267.283
trainer/Q2Pred Std                           65.4464
trainer/Q2Pred Max                          342.148
trainer/Q2Pred Min                           -2.44986
trainer/QTargetWithReg Mean                 266.391
trainer/QTargetWithReg Std                   66.0701
trainer/QTargetWithReg Max                  343.476
trainer/QTargetWithReg Min                   -0.347572
trainer/PolicyLossWithoutReg Mean           268.639
trainer/PolicyLossWithoutReg Std             63.52
trainer/PolicyLossWithoutReg Max            338.814
trainer/PolicyLossWithoutReg Min              6.4863
exploration/num steps total              259000
exploration/num paths total                 990
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2189
exploration/Rewards Std                       1.05759
exploration/Rewards Max                       6.49106
exploration/Rewards Min                      -0.679601
exploration/Returns Mean                   4218.9
exploration/Returns Std                       0
exploration/Returns Max                    4218.9
exploration/Returns Min                    4218.9
exploration/Num Paths                         1
exploration/Average Returns                4218.9
evaluation_0/num steps total                  1.9878e+06
evaluation_0/num paths total               5317
evaluation_0/path length Mean               941.25
evaluation_0/path length Std                150.584
evaluation_0/path length Max               1000
evaluation_0/path length Min                543
evaluation_0/Rewards Mean                     3.96151
evaluation_0/Rewards Std                      1.05211
evaluation_0/Rewards Max                      7.85804
evaluation_0/Rewards Min                     -0.517862
evaluation_0/Returns Mean                  3728.77
evaluation_0/Returns Std                    670.041
evaluation_0/Returns Max                   4136.06
evaluation_0/Returns Min                   1971.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3728.77
time/epoch (s)                                0
time/total (s)                             3968.45
Epoch                                       254
---------------------------------------  ---------------
2022-11-16 17:21:04.457385 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 255 finished
---------------------------------------  ---------------
epoch                                       255
total_step                               260000
replay_pool/size                         260000
trainer/alpha                                 0.0606034
trainer/alpha_loss                           -1.78103
trainer/entropy                              -5.36467
trainer/qf_loss                              15.8961
trainer/policy_loss                        -268.813
trainer/adversary_policy_loss                12.8705
trainer/policy_loss_without_entropy         269.138
trainer/entropy_penalty                      -0.325117
trainer/entropy_percentage                   -0.001208
trainer/Q1Pred Mean                         268.197
trainer/Q1Pred Std                           62.0199
trainer/Q1Pred Max                          346.947
trainer/Q1Pred Min                           -5.78176
trainer/Q2Pred Mean                         268.509
trainer/Q2Pred Std                           61.4856
trainer/Q2Pred Max                          350.718
trainer/Q2Pred Min                           10.3053
trainer/QTargetWithReg Mean                 269.376
trainer/QTargetWithReg Std                   62.0682
trainer/QTargetWithReg Max                  353.149
trainer/QTargetWithReg Min                   -0.143368
trainer/PolicyLossWithoutReg Mean           269.138
trainer/PolicyLossWithoutReg Std             59.639
trainer/PolicyLossWithoutReg Max            350.54
trainer/PolicyLossWithoutReg Min             17.5311
exploration/num steps total              260000
exploration/num paths total                 991
exploration/path length this epoch Mean     931
exploration/path length this epoch Std        0
exploration/path length this epoch Max      931
exploration/path length this epoch Min      931
exploration/Rewards Mean                      3.8319
exploration/Rewards Std                       1.18622
exploration/Rewards Max                       6.59452
exploration/Rewards Min                      -0.460132
exploration/Returns Mean                   3567.5
exploration/Returns Std                       0
exploration/Returns Max                    3567.5
exploration/Returns Min                    3567.5
exploration/Num Paths                         1
exploration/Average Returns                3567.5
evaluation_0/num steps total                  1.9958e+06
evaluation_0/num paths total               5325
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.13217
evaluation_0/Rewards Std                      1.05479
evaluation_0/Rewards Max                      6.95629
evaluation_0/Rewards Min                     -0.438419
evaluation_0/Returns Mean                  4132.17
evaluation_0/Returns Std                    103.741
evaluation_0/Returns Max                   4257.02
evaluation_0/Returns Min                   3952.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4132.17
time/epoch (s)                                0
time/total (s)                             3981.56
Epoch                                       255
---------------------------------------  ---------------
2022-11-16 17:21:18.376316 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 256 finished
---------------------------------------  ----------------
epoch                                       256
total_step                               261000
replay_pool/size                         261000
trainer/alpha                                 0.0608535
trainer/alpha_loss                            0.0196526
trainer/entropy                              -6.00702
trainer/qf_loss                              24.0264
trainer/policy_loss                        -271.818
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         272.184
trainer/entropy_penalty                      -0.365548
trainer/entropy_percentage                   -0.00134302
trainer/Q1Pred Mean                         270.993
trainer/Q1Pred Std                           63.9588
trainer/Q1Pred Max                          355.208
trainer/Q1Pred Min                          -22.8382
trainer/Q2Pred Mean                         271.159
trainer/Q2Pred Std                           64.1191
trainer/Q2Pred Max                          355.559
trainer/Q2Pred Min                          -28.5375
trainer/QTargetWithReg Mean                 270.218
trainer/QTargetWithReg Std                   64.1376
trainer/QTargetWithReg Max                  355.857
trainer/QTargetWithReg Min                  -37.0121
trainer/PolicyLossWithoutReg Mean           272.184
trainer/PolicyLossWithoutReg Std             60.7458
trainer/PolicyLossWithoutReg Max            353.405
trainer/PolicyLossWithoutReg Min              1.04209
exploration/num steps total              261000
exploration/num paths total                 992
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.95985
exploration/Rewards Std                       1.1969
exploration/Rewards Max                       6.92857
exploration/Rewards Min                      -0.808361
exploration/Returns Mean                   3959.85
exploration/Returns Std                       0
exploration/Returns Max                    3959.85
exploration/Returns Min                    3959.85
exploration/Num Paths                         1
exploration/Average Returns                3959.85
evaluation_0/num steps total                  2.00368e+06
evaluation_0/num paths total               5333
evaluation_0/path length Mean               985.25
evaluation_0/path length Std                 39.0248
evaluation_0/path length Max               1000
evaluation_0/path length Min                882
evaluation_0/Rewards Mean                     4.04724
evaluation_0/Rewards Std                      1.05131
evaluation_0/Rewards Max                      7.38656
evaluation_0/Rewards Min                     -0.411971
evaluation_0/Returns Mean                  3987.55
evaluation_0/Returns Std                    130.307
evaluation_0/Returns Max                   4203.48
evaluation_0/Returns Min                   3737.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3987.55
time/epoch (s)                                0
time/total (s)                             3995.48
Epoch                                       256
---------------------------------------  ----------------
2022-11-16 17:21:32.681503 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 257 finished
---------------------------------------  ---------------
epoch                                       257
total_step                               262000
replay_pool/size                         262000
trainer/alpha                                 0.0611072
trainer/alpha_loss                            1.15913
trainer/entropy                              -6.41469
trainer/qf_loss                              30.6222
trainer/policy_loss                        -270.326
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         270.718
trainer/entropy_penalty                      -0.391984
trainer/entropy_percentage                   -0.00144794
trainer/Q1Pred Mean                         268.531
trainer/Q1Pred Std                           64.2781
trainer/Q1Pred Max                          348.11
trainer/Q1Pred Min                           -0.649113
trainer/Q2Pred Mean                         269.114
trainer/Q2Pred Std                           64.5904
trainer/Q2Pred Max                          348.612
trainer/Q2Pred Min                          -16.315
trainer/QTargetWithReg Mean                 269.193
trainer/QTargetWithReg Std                   63.7587
trainer/QTargetWithReg Max                  353.202
trainer/QTargetWithReg Min                   -0.68657
trainer/PolicyLossWithoutReg Mean           270.718
trainer/PolicyLossWithoutReg Std             62.6591
trainer/PolicyLossWithoutReg Max            364.75
trainer/PolicyLossWithoutReg Min              8.3104
exploration/num steps total              262000
exploration/num paths total                 993
exploration/path length this epoch Mean     762
exploration/path length this epoch Std        0
exploration/path length this epoch Max      762
exploration/path length this epoch Min      762
exploration/Rewards Mean                      3.96493
exploration/Rewards Std                       1.1638
exploration/Rewards Max                       6.90501
exploration/Rewards Min                      -0.388742
exploration/Returns Mean                   3021.28
exploration/Returns Std                       0
exploration/Returns Max                    3021.28
exploration/Returns Min                    3021.28
exploration/Num Paths                         1
exploration/Average Returns                3021.28
evaluation_0/num steps total                  2.0109e+06
evaluation_0/num paths total               5341
evaluation_0/path length Mean               901.75
evaluation_0/path length Std                259.945
evaluation_0/path length Max               1000
evaluation_0/path length Min                214
evaluation_0/Rewards Mean                     3.91751
evaluation_0/Rewards Std                      1.11271
evaluation_0/Rewards Max                      7.24161
evaluation_0/Rewards Min                     -0.712576
evaluation_0/Returns Mean                  3532.61
evaluation_0/Returns Std                   1133.89
evaluation_0/Returns Max                   4060.51
evaluation_0/Returns Min                    536.543
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3532.61
time/epoch (s)                                0
time/total (s)                             4009.78
Epoch                                       257
---------------------------------------  ---------------
2022-11-16 17:21:45.314001 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 258 finished
---------------------------------------  ---------------
epoch                                       258
total_step                               263000
replay_pool/size                         263000
trainer/alpha                                 0.0617957
trainer/alpha_loss                           -0.633001
trainer/entropy                              -5.77262
trainer/qf_loss                              12.2749
trainer/policy_loss                        -267.406
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         267.763
trainer/entropy_penalty                      -0.356723
trainer/entropy_percentage                   -0.00133224
trainer/Q1Pred Mean                         266.448
trainer/Q1Pred Std                           65.4147
trainer/Q1Pred Max                          351.783
trainer/Q1Pred Min                           10.4132
trainer/Q2Pred Mean                         266.634
trainer/Q2Pred Std                           65.2951
trainer/Q2Pred Max                          356.486
trainer/Q2Pred Min                            8.41718
trainer/QTargetWithReg Mean                 266.674
trainer/QTargetWithReg Std                   65.5485
trainer/QTargetWithReg Max                  355.728
trainer/QTargetWithReg Min                    9.6861
trainer/PolicyLossWithoutReg Mean           267.763
trainer/PolicyLossWithoutReg Std             64.2351
trainer/PolicyLossWithoutReg Max            356.17
trainer/PolicyLossWithoutReg Min             11.5601
exploration/num steps total              263000
exploration/num paths total                 994
exploration/path length this epoch Mean     931
exploration/path length this epoch Std        0
exploration/path length this epoch Max      931
exploration/path length this epoch Min      931
exploration/Rewards Mean                      4.14284
exploration/Rewards Std                       1.03499
exploration/Rewards Max                       8.0546
exploration/Rewards Min                      -0.706839
exploration/Returns Mean                   3856.98
exploration/Returns Std                       0
exploration/Returns Max                    3856.98
exploration/Returns Min                    3856.98
exploration/Num Paths                         1
exploration/Average Returns                3856.98
evaluation_0/num steps total                  2.0189e+06
evaluation_0/num paths total               5349
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.19599
evaluation_0/Rewards Std                      1.09658
evaluation_0/Rewards Max                      7.09127
evaluation_0/Rewards Min                     -0.521414
evaluation_0/Returns Mean                  4195.99
evaluation_0/Returns Std                     62.4371
evaluation_0/Returns Max                   4292.84
evaluation_0/Returns Min                   4092.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4195.99
time/epoch (s)                                0
time/total (s)                             4022.41
Epoch                                       258
---------------------------------------  ---------------
2022-11-16 17:21:59.237814 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 259 finished
---------------------------------------  ----------------
epoch                                       259
total_step                               264000
replay_pool/size                         264000
trainer/alpha                                 0.0610059
trainer/alpha_loss                           -0.864492
trainer/entropy                              -5.6909
trainer/qf_loss                              18.9298
trainer/policy_loss                        -268.64
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         268.987
trainer/entropy_penalty                      -0.347179
trainer/entropy_percentage                   -0.00129069
trainer/Q1Pred Mean                         268.748
trainer/Q1Pred Std                           62.9814
trainer/Q1Pred Max                          356.769
trainer/Q1Pred Min                           15.7088
trainer/Q2Pred Mean                         268.149
trainer/Q2Pred Std                           62.9023
trainer/Q2Pred Max                          359.694
trainer/Q2Pred Min                           15.9408
trainer/QTargetWithReg Mean                 267.25
trainer/QTargetWithReg Std                   63.0339
trainer/QTargetWithReg Max                  353.198
trainer/QTargetWithReg Min                   16.3879
trainer/PolicyLossWithoutReg Mean           268.987
trainer/PolicyLossWithoutReg Std             62.2077
trainer/PolicyLossWithoutReg Max            354.468
trainer/PolicyLossWithoutReg Min             15.6764
exploration/num steps total              264000
exploration/num paths total                 996
exploration/path length this epoch Mean     140
exploration/path length this epoch Std       28
exploration/path length this epoch Max      168
exploration/path length this epoch Min      112
exploration/Rewards Mean                      1.90618
exploration/Rewards Std                       1.0666
exploration/Rewards Max                       4.77561
exploration/Rewards Min                      -0.602303
exploration/Returns Mean                    266.866
exploration/Returns Std                      39.9027
exploration/Returns Max                     306.768
exploration/Returns Min                     226.963
exploration/Num Paths                         2
exploration/Average Returns                 266.866
evaluation_0/num steps total                  2.02663e+06
evaluation_0/num paths total               5357
evaluation_0/path length Mean               966.75
evaluation_0/path length Std                 87.9712
evaluation_0/path length Max               1000
evaluation_0/path length Min                734
evaluation_0/Rewards Mean                     4.30693
evaluation_0/Rewards Std                      1.09482
evaluation_0/Rewards Max                      7.75151
evaluation_0/Rewards Min                     -0.501841
evaluation_0/Returns Mean                  4163.72
evaluation_0/Returns Std                    351.844
evaluation_0/Returns Max                   4500.83
evaluation_0/Returns Min                   3279.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4163.72
time/epoch (s)                                0
time/total (s)                             4036.34
Epoch                                       259
---------------------------------------  ----------------
2022-11-16 17:22:12.220103 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 260 finished
---------------------------------------  ----------------
epoch                                       260
total_step                               265000
replay_pool/size                         265000
trainer/alpha                                 0.059909
trainer/alpha_loss                           -0.168804
trainer/entropy                              -5.94003
trainer/qf_loss                              18.8625
trainer/policy_loss                        -270.012
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         270.368
trainer/entropy_penalty                      -0.355861
trainer/entropy_percentage                   -0.00131621
trainer/Q1Pred Mean                         269.234
trainer/Q1Pred Std                           63.8511
trainer/Q1Pred Max                          345.145
trainer/Q1Pred Min                            8.63813
trainer/Q2Pred Mean                         268.965
trainer/Q2Pred Std                           64.1531
trainer/Q2Pred Max                          341.847
trainer/Q2Pred Min                            2.92479
trainer/QTargetWithReg Mean                 269.295
trainer/QTargetWithReg Std                   64.1149
trainer/QTargetWithReg Max                  344.018
trainer/QTargetWithReg Min                    0.0864739
trainer/PolicyLossWithoutReg Mean           270.368
trainer/PolicyLossWithoutReg Std             62.2855
trainer/PolicyLossWithoutReg Max            342.782
trainer/PolicyLossWithoutReg Min             15.8571
exploration/num steps total              265000
exploration/num paths total                 997
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.79549
exploration/Rewards Std                       1.10657
exploration/Rewards Max                       6.27952
exploration/Rewards Min                      -0.581237
exploration/Returns Mean                   3795.49
exploration/Returns Std                       0
exploration/Returns Max                    3795.49
exploration/Returns Min                    3795.49
exploration/Num Paths                         1
exploration/Average Returns                3795.49
evaluation_0/num steps total                  2.03463e+06
evaluation_0/num paths total               5365
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.03127
evaluation_0/Rewards Std                      1.04002
evaluation_0/Rewards Max                      6.87318
evaluation_0/Rewards Min                     -0.320398
evaluation_0/Returns Mean                  4031.27
evaluation_0/Returns Std                    266.383
evaluation_0/Returns Max                   4357.3
evaluation_0/Returns Min                   3622.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4031.27
time/epoch (s)                                0
time/total (s)                             4049.32
Epoch                                       260
---------------------------------------  ----------------
2022-11-16 17:22:26.219315 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 261 finished
---------------------------------------  ----------------
epoch                                       261
total_step                               266000
replay_pool/size                         266000
trainer/alpha                                 0.060879
trainer/alpha_loss                           -0.660596
trainer/entropy                              -5.76398
trainer/qf_loss                              20.8965
trainer/policy_loss                        -269.204
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         269.555
trainer/entropy_penalty                      -0.350905
trainer/entropy_percentage                   -0.0013018
trainer/Q1Pred Mean                         267.998
trainer/Q1Pred Std                           63.5891
trainer/Q1Pred Max                          347.263
trainer/Q1Pred Min                           -0.309644
trainer/Q2Pred Mean                         267.841
trainer/Q2Pred Std                           63.539
trainer/Q2Pred Max                          352.236
trainer/Q2Pred Min                            0.83628
trainer/QTargetWithReg Mean                 267.98
trainer/QTargetWithReg Std                   63.6824
trainer/QTargetWithReg Max                  347.366
trainer/QTargetWithReg Min                    1.97458
trainer/PolicyLossWithoutReg Mean           269.555
trainer/PolicyLossWithoutReg Std             62.6904
trainer/PolicyLossWithoutReg Max            346.839
trainer/PolicyLossWithoutReg Min              1.23233
exploration/num steps total              266000
exploration/num paths total                 998
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.93026
exploration/Rewards Std                       1.03265
exploration/Rewards Max                       5.87552
exploration/Rewards Min                      -0.446563
exploration/Returns Mean                   3930.26
exploration/Returns Std                       0
exploration/Returns Max                    3930.26
exploration/Returns Min                    3930.26
exploration/Num Paths                         1
exploration/Average Returns                3930.26
evaluation_0/num steps total                  2.04247e+06
evaluation_0/num paths total               5374
evaluation_0/path length Mean               871.333
evaluation_0/path length Std                182.359
evaluation_0/path length Max               1000
evaluation_0/path length Min                585
evaluation_0/Rewards Mean                     4.5468
evaluation_0/Rewards Std                      1.16033
evaluation_0/Rewards Max                     11.7533
evaluation_0/Rewards Min                     -0.631724
evaluation_0/Returns Mean                  3961.78
evaluation_0/Returns Std                    942.715
evaluation_0/Returns Max                   4916.44
evaluation_0/Returns Min                   2543.88
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3961.78
time/epoch (s)                                0
time/total (s)                             4063.32
Epoch                                       261
---------------------------------------  ----------------
2022-11-16 17:22:40.094846 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 262 finished
---------------------------------------  ----------------
epoch                                       262
total_step                               267000
replay_pool/size                         267000
trainer/alpha                                 0.0620332
trainer/alpha_loss                            1.1567
trainer/entropy                              -6.41606
trainer/qf_loss                              21.9914
trainer/policy_loss                        -269.349
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         269.747
trainer/entropy_penalty                      -0.398009
trainer/entropy_percentage                   -0.00147549
trainer/Q1Pred Mean                         268.386
trainer/Q1Pred Std                           71.3464
trainer/Q1Pred Max                          346.555
trainer/Q1Pred Min                            5.72764
trainer/Q2Pred Mean                         268.051
trainer/Q2Pred Std                           71.1674
trainer/Q2Pred Max                          347.814
trainer/Q2Pred Min                            4.36957
trainer/QTargetWithReg Mean                 269.463
trainer/QTargetWithReg Std                   71.868
trainer/QTargetWithReg Max                  349.359
trainer/QTargetWithReg Min                    3.58375
trainer/PolicyLossWithoutReg Mean           269.747
trainer/PolicyLossWithoutReg Std             69.9479
trainer/PolicyLossWithoutReg Max            347.928
trainer/PolicyLossWithoutReg Min              8.94848
exploration/num steps total              267000
exploration/num paths total                 999
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.07367
exploration/Rewards Std                       1.08685
exploration/Rewards Max                       6.84718
exploration/Rewards Min                      -0.479771
exploration/Returns Mean                   4073.67
exploration/Returns Std                       0
exploration/Returns Max                    4073.67
exploration/Returns Min                    4073.67
exploration/Num Paths                         1
exploration/Average Returns                4073.67
evaluation_0/num steps total                  2.04975e+06
evaluation_0/num paths total               5382
evaluation_0/path length Mean               909
evaluation_0/path length Std                213.155
evaluation_0/path length Max               1000
evaluation_0/path length Min                349
evaluation_0/Rewards Mean                     4.27178
evaluation_0/Rewards Std                      1.18663
evaluation_0/Rewards Max                      8.24419
evaluation_0/Rewards Min                     -0.460355
evaluation_0/Returns Mean                  3883.05
evaluation_0/Returns Std                    996.31
evaluation_0/Returns Max                   4431.79
evaluation_0/Returns Min                   1267.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3883.05
time/epoch (s)                                0
time/total (s)                             4077.19
Epoch                                       262
---------------------------------------  ----------------
2022-11-16 17:22:52.969402 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 263 finished
---------------------------------------  ----------------
epoch                                       263
total_step                               268000
replay_pool/size                         268000
trainer/alpha                                 0.0603374
trainer/alpha_loss                           -0.879076
trainer/entropy                              -5.68692
trainer/qf_loss                              18.6335
trainer/policy_loss                        -268.817
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         269.16
trainer/entropy_penalty                      -0.343134
trainer/entropy_percentage                   -0.00127483
trainer/Q1Pred Mean                         268.748
trainer/Q1Pred Std                           64.1967
trainer/Q1Pred Max                          346.509
trainer/Q1Pred Min                            8.20747
trainer/Q2Pred Mean                         268.613
trainer/Q2Pred Std                           63.8359
trainer/Q2Pred Max                          349.122
trainer/Q2Pred Min                           15.9133
trainer/QTargetWithReg Mean                 268.61
trainer/QTargetWithReg Std                   64.1221
trainer/QTargetWithReg Max                  346.211
trainer/QTargetWithReg Min                   11.5267
trainer/PolicyLossWithoutReg Mean           269.16
trainer/PolicyLossWithoutReg Std             63.1229
trainer/PolicyLossWithoutReg Max            345.263
trainer/PolicyLossWithoutReg Min             12.9077
exploration/num steps total              268000
exploration/num paths total                1000
exploration/path length this epoch Mean     577
exploration/path length this epoch Std        0
exploration/path length this epoch Max      577
exploration/path length this epoch Min      577
exploration/Rewards Mean                      3.47833
exploration/Rewards Std                       1.27304
exploration/Rewards Max                       5.61152
exploration/Rewards Min                      -0.412022
exploration/Returns Mean                   2007
exploration/Returns Std                       0
exploration/Returns Max                    2007
exploration/Returns Min                    2007
exploration/Num Paths                         1
exploration/Average Returns                2007
evaluation_0/num steps total                  2.05775e+06
evaluation_0/num paths total               5390
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.82221
evaluation_0/Rewards Std                      1.10323
evaluation_0/Rewards Max                      7.08174
evaluation_0/Rewards Min                     -0.43159
evaluation_0/Returns Mean                  3822.21
evaluation_0/Returns Std                    139.078
evaluation_0/Returns Max                   3966.69
evaluation_0/Returns Min                   3629.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3822.21
time/epoch (s)                                0
time/total (s)                             4090.07
Epoch                                       263
---------------------------------------  ----------------
2022-11-16 17:23:06.257738 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 264 finished
---------------------------------------  ----------------
epoch                                       264
total_step                               269000
replay_pool/size                         269000
trainer/alpha                                 0.0610989
trainer/alpha_loss                           -0.0962941
trainer/entropy                              -5.96555
trainer/qf_loss                              14.6297
trainer/policy_loss                        -273.937
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         274.301
trainer/entropy_penalty                      -0.364489
trainer/entropy_percentage                   -0.00132879
trainer/Q1Pred Mean                         272.227
trainer/Q1Pred Std                           58.2688
trainer/Q1Pred Max                          348.225
trainer/Q1Pred Min                            3.26217
trainer/Q2Pred Mean                         272.516
trainer/Q2Pred Std                           58.343
trainer/Q2Pred Max                          346.75
trainer/Q2Pred Min                           -5.29642
trainer/QTargetWithReg Mean                 272.512
trainer/QTargetWithReg Std                   58.2304
trainer/QTargetWithReg Max                  345.757
trainer/QTargetWithReg Min                    3.40855
trainer/PolicyLossWithoutReg Mean           274.301
trainer/PolicyLossWithoutReg Std             55.9106
trainer/PolicyLossWithoutReg Max            346.938
trainer/PolicyLossWithoutReg Min             -2.50731
exploration/num steps total              269000
exploration/num paths total                1001
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.33135
exploration/Rewards Std                       1.1639
exploration/Rewards Max                       6.81882
exploration/Rewards Min                      -0.58242
exploration/Returns Mean                   4331.35
exploration/Returns Std                       0
exploration/Returns Max                    4331.35
exploration/Returns Min                    4331.35
exploration/Num Paths                         1
exploration/Average Returns                4331.35
evaluation_0/num steps total                  2.06575e+06
evaluation_0/num paths total               5398
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.85326
evaluation_0/Rewards Std                      1.12863
evaluation_0/Rewards Max                      8.30119
evaluation_0/Rewards Min                     -0.544246
evaluation_0/Returns Mean                  3853.26
evaluation_0/Returns Std                    186.563
evaluation_0/Returns Max                   4246.39
evaluation_0/Returns Min                   3624.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3853.26
time/epoch (s)                                0
time/total (s)                             4103.35
Epoch                                       264
---------------------------------------  ----------------
2022-11-16 17:23:23.013913 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 265 finished
---------------------------------------  ----------------
epoch                                       265
total_step                               270000
replay_pool/size                         270000
trainer/alpha                                 0.0599785
trainer/alpha_loss                            1.00526
trainer/entropy                              -6.35726
trainer/qf_loss                              18.8735
trainer/policy_loss                        -267.28
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         267.661
trainer/entropy_penalty                      -0.381299
trainer/entropy_percentage                   -0.00142456
trainer/Q1Pred Mean                         266.437
trainer/Q1Pred Std                           65.7922
trainer/Q1Pred Max                          352.254
trainer/Q1Pred Min                           -5.34863
trainer/Q2Pred Mean                         266.81
trainer/Q2Pred Std                           65.5912
trainer/Q2Pred Max                          351.078
trainer/Q2Pred Min                          -12.0618
trainer/QTargetWithReg Mean                 266.796
trainer/QTargetWithReg Std                   66.082
trainer/QTargetWithReg Max                  351.752
trainer/QTargetWithReg Min                   -2.69044
trainer/PolicyLossWithoutReg Mean           267.661
trainer/PolicyLossWithoutReg Std             64.43
trainer/PolicyLossWithoutReg Max            351.175
trainer/PolicyLossWithoutReg Min             10.966
exploration/num steps total              270000
exploration/num paths total                1002
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.84198
exploration/Rewards Std                       1.53134
exploration/Rewards Max                       7.76577
exploration/Rewards Min                      -0.772817
exploration/Returns Mean                   3841.98
exploration/Returns Std                       0
exploration/Returns Max                    3841.98
exploration/Returns Min                    3841.98
exploration/Num Paths                         1
exploration/Average Returns                3841.98
evaluation_0/num steps total                  2.07352e+06
evaluation_0/num paths total               5406
evaluation_0/path length Mean               972.125
evaluation_0/path length Std                 48.5423
evaluation_0/path length Max               1000
evaluation_0/path length Min                851
evaluation_0/Rewards Mean                     4.27221
evaluation_0/Rewards Std                      1.15451
evaluation_0/Rewards Max                      8.50412
evaluation_0/Rewards Min                     -0.474936
evaluation_0/Returns Mean                  4153.12
evaluation_0/Returns Std                    245.582
evaluation_0/Returns Max                   4383.56
evaluation_0/Returns Min                   3544.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4153.12
time/epoch (s)                                0
time/total (s)                             4120.11
Epoch                                       265
---------------------------------------  ----------------
2022-11-16 17:23:39.225871 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 266 finished
---------------------------------------  ----------------
epoch                                       266
total_step                               271000
replay_pool/size                         271000
trainer/alpha                                 0.0612788
trainer/alpha_loss                           -0.0313475
trainer/entropy                              -5.98877
trainer/qf_loss                              16.4972
trainer/policy_loss                        -264.004
trainer/adversary_policy_loss                12.5233
trainer/policy_loss_without_entropy         264.371
trainer/entropy_penalty                      -0.366985
trainer/entropy_percentage                   -0.00138814
trainer/Q1Pred Mean                         262.84
trainer/Q1Pred Std                           71.4235
trainer/Q1Pred Max                          353.39
trainer/Q1Pred Min                           -2.22053
trainer/Q2Pred Mean                         262.825
trainer/Q2Pred Std                           71.9215
trainer/Q2Pred Max                          352.626
trainer/Q2Pred Min                          -24.2825
trainer/QTargetWithReg Mean                 262.347
trainer/QTargetWithReg Std                   71.7211
trainer/QTargetWithReg Max                  351.225
trainer/QTargetWithReg Min                   -0.271924
trainer/PolicyLossWithoutReg Mean           264.371
trainer/PolicyLossWithoutReg Std             69.5939
trainer/PolicyLossWithoutReg Max            352.456
trainer/PolicyLossWithoutReg Min             10.1792
exploration/num steps total              271000
exploration/num paths total                1003
exploration/path length this epoch Mean     453
exploration/path length this epoch Std        0
exploration/path length this epoch Max      453
exploration/path length this epoch Min      453
exploration/Rewards Mean                      3.97033
exploration/Rewards Std                       1.2115
exploration/Rewards Max                       5.79581
exploration/Rewards Min                      -0.507213
exploration/Returns Mean                   1798.56
exploration/Returns Std                       0
exploration/Returns Max                    1798.56
exploration/Returns Min                    1798.56
exploration/Num Paths                         1
exploration/Average Returns                1798.56
evaluation_0/num steps total                  2.08087e+06
evaluation_0/num paths total               5414
evaluation_0/path length Mean               918.5
evaluation_0/path length Std                215.629
evaluation_0/path length Max               1000
evaluation_0/path length Min                348
evaluation_0/Rewards Mean                     4.16073
evaluation_0/Rewards Std                      1.06769
evaluation_0/Rewards Max                      7.08501
evaluation_0/Rewards Min                     -0.46781
evaluation_0/Returns Mean                  3821.63
evaluation_0/Returns Std                    994.31
evaluation_0/Returns Max                   4394.86
evaluation_0/Returns Min                   1221.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3821.63
time/epoch (s)                                0
time/total (s)                             4136.32
Epoch                                       266
---------------------------------------  ----------------
2022-11-16 17:23:54.016693 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 267 finished
---------------------------------------  ----------------
epoch                                       267
total_step                               272000
replay_pool/size                         272000
trainer/alpha                                 0.0610215
trainer/alpha_loss                           -0.0185729
trainer/entropy                              -5.99336
trainer/qf_loss                              30.1111
trainer/policy_loss                        -277.74
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         278.106
trainer/entropy_penalty                      -0.365723
trainer/entropy_percentage                   -0.00131505
trainer/Q1Pred Mean                         276.637
trainer/Q1Pred Std                           59.462
trainer/Q1Pred Max                          360.423
trainer/Q1Pred Min                           -1.62346
trainer/Q2Pred Mean                         276.146
trainer/Q2Pred Std                           59.1506
trainer/Q2Pred Max                          358.511
trainer/Q2Pred Min                           14.6061
trainer/QTargetWithReg Mean                 276.013
trainer/QTargetWithReg Std                   61.3321
trainer/QTargetWithReg Max                  355.636
trainer/QTargetWithReg Min                  -30.0759
trainer/PolicyLossWithoutReg Mean           278.106
trainer/PolicyLossWithoutReg Std             56.8711
trainer/PolicyLossWithoutReg Max            357.577
trainer/PolicyLossWithoutReg Min             -8.12049
exploration/num steps total              272000
exploration/num paths total                1005
exploration/path length this epoch Mean     373
exploration/path length this epoch Std      224
exploration/path length this epoch Max      597
exploration/path length this epoch Min      149
exploration/Rewards Mean                      3.44958
exploration/Rewards Std                       1.31327
exploration/Rewards Max                       7.0082
exploration/Rewards Min                      -0.430014
exploration/Returns Mean                   1286.69
exploration/Returns Std                     859.89
exploration/Returns Max                    2146.58
exploration/Returns Min                     426.802
exploration/Num Paths                         2
exploration/Average Returns                1286.69
evaluation_0/num steps total                  2.08887e+06
evaluation_0/num paths total               5422
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.70387
evaluation_0/Rewards Std                      0.990961
evaluation_0/Rewards Max                      5.89132
evaluation_0/Rewards Min                     -0.48264
evaluation_0/Returns Mean                  3703.87
evaluation_0/Returns Std                     70.5563
evaluation_0/Returns Max                   3793.85
evaluation_0/Returns Min                   3559.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3703.87
time/epoch (s)                                0
time/total (s)                             4151.11
Epoch                                       267
---------------------------------------  ----------------
2022-11-16 17:24:11.003034 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 268 finished
---------------------------------------  ----------------
epoch                                       268
total_step                               273000
replay_pool/size                         273000
trainer/alpha                                 0.0607236
trainer/alpha_loss                           -0.196377
trainer/entropy                              -5.9299
trainer/qf_loss                              28.2487
trainer/policy_loss                        -279.366
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         279.726
trainer/entropy_penalty                      -0.360085
trainer/entropy_percentage                   -0.00128728
trainer/Q1Pred Mean                         277.606
trainer/Q1Pred Std                           59.1168
trainer/Q1Pred Max                          348.957
trainer/Q1Pred Min                           16.7763
trainer/Q2Pred Mean                         277.148
trainer/Q2Pred Std                           59.2288
trainer/Q2Pred Max                          345.015
trainer/Q2Pred Min                           14.6589
trainer/QTargetWithReg Mean                 277.07
trainer/QTargetWithReg Std                   60.0835
trainer/QTargetWithReg Max                  345.734
trainer/QTargetWithReg Min                  -22.7081
trainer/PolicyLossWithoutReg Mean           279.726
trainer/PolicyLossWithoutReg Std             55.7155
trainer/PolicyLossWithoutReg Max            345.393
trainer/PolicyLossWithoutReg Min             14.2295
exploration/num steps total              273000
exploration/num paths total                1006
exploration/path length this epoch Mean     797
exploration/path length this epoch Std        0
exploration/path length this epoch Max      797
exploration/path length this epoch Min      797
exploration/Rewards Mean                      4.08695
exploration/Rewards Std                       1.07459
exploration/Rewards Max                       6.39796
exploration/Rewards Min                      -0.387031
exploration/Returns Mean                   3257.3
exploration/Returns Std                       0
exploration/Returns Max                    3257.3
exploration/Returns Min                    3257.3
exploration/Num Paths                         1
exploration/Average Returns                3257.3
evaluation_0/num steps total                  2.09673e+06
evaluation_0/num paths total               5433
evaluation_0/path length Mean               714.091
evaluation_0/path length Std                329.395
evaluation_0/path length Max               1000
evaluation_0/path length Min                245
evaluation_0/Rewards Mean                     4.42191
evaluation_0/Rewards Std                      1.19394
evaluation_0/Rewards Max                      7.52551
evaluation_0/Rewards Min                     -0.503144
evaluation_0/Returns Mean                  3157.65
evaluation_0/Returns Std                   1680.13
evaluation_0/Returns Max                   4761.37
evaluation_0/Returns Min                    795.716
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3157.65
time/epoch (s)                                0
time/total (s)                             4168.1
Epoch                                       268
---------------------------------------  ----------------
2022-11-16 17:24:25.709649 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 269 finished
---------------------------------------  ----------------
epoch                                       269
total_step                               274000
replay_pool/size                         274000
trainer/alpha                                 0.0598176
trainer/alpha_loss                            0.160331
trainer/entropy                              -6.05693
trainer/qf_loss                              34.2643
trainer/policy_loss                        -264.839
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         265.201
trainer/entropy_penalty                      -0.362311
trainer/entropy_percentage                   -0.00136617
trainer/Q1Pred Mean                         265.236
trainer/Q1Pred Std                           70.0855
trainer/Q1Pred Max                          353.179
trainer/Q1Pred Min                            2.12788
trainer/Q2Pred Mean                         264.814
trainer/Q2Pred Std                           70.2274
trainer/Q2Pred Max                          351.927
trainer/Q2Pred Min                           -8.0114
trainer/QTargetWithReg Mean                 263.279
trainer/QTargetWithReg Std                   71.1342
trainer/QTargetWithReg Max                  352.035
trainer/QTargetWithReg Min                   -3.95712
trainer/PolicyLossWithoutReg Mean           265.201
trainer/PolicyLossWithoutReg Std             68.8312
trainer/PolicyLossWithoutReg Max            351.199
trainer/PolicyLossWithoutReg Min              0.818391
exploration/num steps total              274000
exploration/num paths total                1008
exploration/path length this epoch Mean     447
exploration/path length this epoch Std       68
exploration/path length this epoch Max      515
exploration/path length this epoch Min      379
exploration/Rewards Mean                      3.98462
exploration/Rewards Std                       1.40901
exploration/Rewards Max                       8.27204
exploration/Rewards Min                      -0.474038
exploration/Returns Mean                   1781.13
exploration/Returns Std                     471.042
exploration/Returns Max                    2252.17
exploration/Returns Min                    1310.08
exploration/Num Paths                         2
exploration/Average Returns                1781.13
evaluation_0/num steps total                  2.10473e+06
evaluation_0/num paths total               5441
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.49816
evaluation_0/Rewards Std                      1.08159
evaluation_0/Rewards Max                      6.97749
evaluation_0/Rewards Min                     -0.591615
evaluation_0/Returns Mean                  4498.16
evaluation_0/Returns Std                     69.473
evaluation_0/Returns Max                   4569.72
evaluation_0/Returns Min                   4386.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4498.16
time/epoch (s)                                0
time/total (s)                             4182.81
Epoch                                       269
---------------------------------------  ----------------
2022-11-16 17:24:42.497494 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 270 finished
---------------------------------------  ----------------
epoch                                       270
total_step                               275000
replay_pool/size                         275000
trainer/alpha                                 0.0608497
trainer/alpha_loss                            0.387121
trainer/entropy                              -6.13829
trainer/qf_loss                              22.4948
trainer/policy_loss                        -266.419
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         266.793
trainer/entropy_penalty                      -0.373513
trainer/entropy_percentage                   -0.00140001
trainer/Q1Pred Mean                         264.937
trainer/Q1Pred Std                           77.1189
trainer/Q1Pred Max                          354.287
trainer/Q1Pred Min                           10.4156
trainer/Q2Pred Mean                         264.806
trainer/Q2Pred Std                           77.2391
trainer/Q2Pred Max                          352.905
trainer/Q2Pred Min                            1.26433
trainer/QTargetWithReg Mean                 265.382
trainer/QTargetWithReg Std                   77.2791
trainer/QTargetWithReg Max                  353.706
trainer/QTargetWithReg Min                    3.09408
trainer/PolicyLossWithoutReg Mean           266.793
trainer/PolicyLossWithoutReg Std             75.9213
trainer/PolicyLossWithoutReg Max            353.353
trainer/PolicyLossWithoutReg Min             13.6249
exploration/num steps total              275000
exploration/num paths total                1009
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.19893
exploration/Rewards Std                       1.18142
exploration/Rewards Max                       6.71652
exploration/Rewards Min                      -0.432482
exploration/Returns Mean                   4198.93
exploration/Returns Std                       0
exploration/Returns Max                    4198.93
exploration/Returns Min                    4198.93
exploration/Num Paths                         1
exploration/Average Returns                4198.93
evaluation_0/num steps total                  2.11233e+06
evaluation_0/num paths total               5450
evaluation_0/path length Mean               845.333
evaluation_0/path length Std                234.821
evaluation_0/path length Max               1000
evaluation_0/path length Min                364
evaluation_0/Rewards Mean                     4.5473
evaluation_0/Rewards Std                      1.12531
evaluation_0/Rewards Max                      9.07224
evaluation_0/Rewards Min                     -0.590937
evaluation_0/Returns Mean                  3843.98
evaluation_0/Returns Std                   1159.77
evaluation_0/Returns Max                   4716.27
evaluation_0/Returns Min                   1463.34
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3843.98
time/epoch (s)                                0
time/total (s)                             4199.59
Epoch                                       270
---------------------------------------  ----------------
2022-11-16 17:24:54.128742 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 271 finished
---------------------------------------  ----------------
epoch                                       271
total_step                               276000
replay_pool/size                         276000
trainer/alpha                                 0.0601864
trainer/alpha_loss                            1.16974
trainer/entropy                              -6.41623
trainer/qf_loss                              20.368
trainer/policy_loss                        -276.869
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         277.255
trainer/entropy_penalty                      -0.38617
trainer/entropy_percentage                   -0.00139283
trainer/Q1Pred Mean                         275.528
trainer/Q1Pred Std                           61.4059
trainer/Q1Pred Max                          349.101
trainer/Q1Pred Min                           25.6929
trainer/Q2Pred Mean                         275.488
trainer/Q2Pred Std                           62.11
trainer/Q2Pred Max                          351.838
trainer/Q2Pred Min                           17.3844
trainer/QTargetWithReg Mean                 275.081
trainer/QTargetWithReg Std                   61.8614
trainer/QTargetWithReg Max                  351.93
trainer/QTargetWithReg Min                   22.3241
trainer/PolicyLossWithoutReg Mean           277.255
trainer/PolicyLossWithoutReg Std             60.7783
trainer/PolicyLossWithoutReg Max            352.654
trainer/PolicyLossWithoutReg Min             20.8946
exploration/num steps total              276000
exploration/num paths total                1010
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45657
exploration/Rewards Std                       1.1275
exploration/Rewards Max                       6.82714
exploration/Rewards Min                      -0.736816
exploration/Returns Mean                   4456.57
exploration/Returns Std                       0
exploration/Returns Max                    4456.57
exploration/Returns Min                    4456.57
exploration/Num Paths                         1
exploration/Average Returns                4456.57
evaluation_0/num steps total                  2.12033e+06
evaluation_0/num paths total               5458
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.33116
evaluation_0/Rewards Std                      1.09091
evaluation_0/Rewards Max                      6.63578
evaluation_0/Rewards Min                     -0.341794
evaluation_0/Returns Mean                  4331.16
evaluation_0/Returns Std                     57.2212
evaluation_0/Returns Max                   4420.31
evaluation_0/Returns Min                   4219.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4331.16
time/epoch (s)                                0
time/total (s)                             4211.22
Epoch                                       271
---------------------------------------  ----------------
2022-11-16 17:25:09.481601 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 272 finished
---------------------------------------  ----------------
epoch                                       272
total_step                               277000
replay_pool/size                         277000
trainer/alpha                                 0.0615008
trainer/alpha_loss                           -0.823637
trainer/entropy                              -5.70465
trainer/qf_loss                              15.5168
trainer/policy_loss                        -278.581
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         278.932
trainer/entropy_penalty                      -0.350841
trainer/entropy_percentage                   -0.0012578
trainer/Q1Pred Mean                         276.72
trainer/Q1Pred Std                           60.9681
trainer/Q1Pred Max                          355.253
trainer/Q1Pred Min                           12.7789
trainer/Q2Pred Mean                         277.169
trainer/Q2Pred Std                           61.1579
trainer/Q2Pred Max                          352.933
trainer/Q2Pred Min                           15.0637
trainer/QTargetWithReg Mean                 277.339
trainer/QTargetWithReg Std                   60.6909
trainer/QTargetWithReg Max                  354.919
trainer/QTargetWithReg Min                   13.0146
trainer/PolicyLossWithoutReg Mean           278.932
trainer/PolicyLossWithoutReg Std             59.5455
trainer/PolicyLossWithoutReg Max            352.97
trainer/PolicyLossWithoutReg Min             16.0603
exploration/num steps total              277000
exploration/num paths total                1011
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2525
exploration/Rewards Std                       1.1687
exploration/Rewards Max                       6.73512
exploration/Rewards Min                      -0.283219
exploration/Returns Mean                   4252.5
exploration/Returns Std                       0
exploration/Returns Max                    4252.5
exploration/Returns Min                    4252.5
exploration/Num Paths                         1
exploration/Average Returns                4252.5
evaluation_0/num steps total                  2.12748e+06
evaluation_0/num paths total               5466
evaluation_0/path length Mean               893.875
evaluation_0/path length Std                185.278
evaluation_0/path length Max               1000
evaluation_0/path length Min                529
evaluation_0/Rewards Mean                     4.42049
evaluation_0/Rewards Std                      1.08395
evaluation_0/Rewards Max                      8.43811
evaluation_0/Rewards Min                     -0.588506
evaluation_0/Returns Mean                  3951.36
evaluation_0/Returns Std                    863.893
evaluation_0/Returns Max                   4711.6
evaluation_0/Returns Min                   2285.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3951.36
time/epoch (s)                                0
time/total (s)                             4226.57
Epoch                                       272
---------------------------------------  ----------------
2022-11-16 17:25:25.331879 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 273 finished
---------------------------------------  ----------------
epoch                                       273
total_step                               278000
replay_pool/size                         278000
trainer/alpha                                 0.0603057
trainer/alpha_loss                           -1.97155
trainer/entropy                              -5.29791
trainer/qf_loss                              12.1492
trainer/policy_loss                        -276.763
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         277.082
trainer/entropy_penalty                      -0.319494
trainer/entropy_percentage                   -0.00115307
trainer/Q1Pred Mean                         275.886
trainer/Q1Pred Std                           56.7056
trainer/Q1Pred Max                          355.839
trainer/Q1Pred Min                           14.756
trainer/Q2Pred Mean                         276.535
trainer/Q2Pred Std                           56.9895
trainer/Q2Pred Max                          355.356
trainer/Q2Pred Min                           13.8231
trainer/QTargetWithReg Mean                 276.859
trainer/QTargetWithReg Std                   56.8552
trainer/QTargetWithReg Max                  356.578
trainer/QTargetWithReg Min                   18.7647
trainer/PolicyLossWithoutReg Mean           277.082
trainer/PolicyLossWithoutReg Std             55.6556
trainer/PolicyLossWithoutReg Max            354.394
trainer/PolicyLossWithoutReg Min             21.8783
exploration/num steps total              278000
exploration/num paths total                1012
exploration/path length this epoch Mean     607
exploration/path length this epoch Std        0
exploration/path length this epoch Max      607
exploration/path length this epoch Min      607
exploration/Rewards Mean                      3.79658
exploration/Rewards Std                       1.00274
exploration/Rewards Max                       5.47318
exploration/Rewards Min                      -0.411353
exploration/Returns Mean                   2304.52
exploration/Returns Std                       0
exploration/Returns Max                    2304.52
exploration/Returns Min                    2304.52
exploration/Num Paths                         1
exploration/Average Returns                2304.52
evaluation_0/num steps total                  2.13468e+06
evaluation_0/num paths total               5474
evaluation_0/path length Mean               898.75
evaluation_0/path length Std                188.51
evaluation_0/path length Max               1000
evaluation_0/path length Min                445
evaluation_0/Rewards Mean                     4.23705
evaluation_0/Rewards Std                      1.10761
evaluation_0/Rewards Max                      8.08744
evaluation_0/Rewards Min                     -0.585949
evaluation_0/Returns Mean                  3808.05
evaluation_0/Returns Std                    870.057
evaluation_0/Returns Max                   4485.25
evaluation_0/Returns Min                   1733.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3808.05
time/epoch (s)                                0
time/total (s)                             4242.42
Epoch                                       273
---------------------------------------  ----------------
2022-11-16 17:25:40.299498 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 274 finished
---------------------------------------  ----------------
epoch                                       274
total_step                               279000
replay_pool/size                         279000
trainer/alpha                                 0.0595364
trainer/alpha_loss                            0.821367
trainer/entropy                              -6.29114
trainer/qf_loss                              24.7834
trainer/policy_loss                        -274.376
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         274.751
trainer/entropy_penalty                      -0.374552
trainer/entropy_percentage                   -0.00136324
trainer/Q1Pred Mean                         273.612
trainer/Q1Pred Std                           60.0924
trainer/Q1Pred Max                          356.7
trainer/Q1Pred Min                           29.1616
trainer/Q2Pred Mean                         273.346
trainer/Q2Pred Std                           60.1195
trainer/Q2Pred Max                          354.726
trainer/Q2Pred Min                           25.1356
trainer/QTargetWithReg Mean                 273.699
trainer/QTargetWithReg Std                   59.6641
trainer/QTargetWithReg Max                  355.099
trainer/QTargetWithReg Min                   26.7208
trainer/PolicyLossWithoutReg Mean           274.751
trainer/PolicyLossWithoutReg Std             58.327
trainer/PolicyLossWithoutReg Max            352.953
trainer/PolicyLossWithoutReg Min             30.7991
exploration/num steps total              279000
exploration/num paths total                1014
exploration/path length this epoch Mean      33.5
exploration/path length this epoch Std        0.5
exploration/path length this epoch Max       34
exploration/path length this epoch Min       33
exploration/Rewards Mean                      0.929611
exploration/Rewards Std                       0.882065
exploration/Rewards Max                       2.48363
exploration/Rewards Min                      -0.564878
exploration/Returns Mean                     31.142
exploration/Returns Std                       0.151765
exploration/Returns Max                      31.2937
exploration/Returns Min                      30.9902
exploration/Num Paths                         2
exploration/Average Returns                  31.142
evaluation_0/num steps total                  2.14209e+06
evaluation_0/num paths total               5482
evaluation_0/path length Mean               927
evaluation_0/path length Std                126.607
evaluation_0/path length Max               1000
evaluation_0/path length Min                695
evaluation_0/Rewards Mean                     4.34851
evaluation_0/Rewards Std                      1.19715
evaluation_0/Rewards Max                     10.5125
evaluation_0/Rewards Min                     -0.501419
evaluation_0/Returns Mean                  4031.07
evaluation_0/Returns Std                    626.963
evaluation_0/Returns Max                   4455.99
evaluation_0/Returns Min                   2815.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4031.07
time/epoch (s)                                0
time/total (s)                             4257.39
Epoch                                       274
---------------------------------------  ----------------
2022-11-16 17:25:54.577138 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 275 finished
---------------------------------------  ----------------
epoch                                       275
total_step                               280000
replay_pool/size                         280000
trainer/alpha                                 0.0626798
trainer/alpha_loss                           -0.690988
trainer/entropy                              -5.75051
trainer/qf_loss                              23.0793
trainer/policy_loss                        -278.943
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         279.304
trainer/entropy_penalty                      -0.360441
trainer/entropy_percentage                   -0.0012905
trainer/Q1Pred Mean                         277.882
trainer/Q1Pred Std                           64.6252
trainer/Q1Pred Max                          353.436
trainer/Q1Pred Min                           15.1677
trainer/Q2Pred Mean                         277.932
trainer/Q2Pred Std                           64.8683
trainer/Q2Pred Max                          354.76
trainer/Q2Pred Min                            6.89575
trainer/QTargetWithReg Mean                 277.166
trainer/QTargetWithReg Std                   64.8025
trainer/QTargetWithReg Max                  352.094
trainer/QTargetWithReg Min                    7.56205
trainer/PolicyLossWithoutReg Mean           279.304
trainer/PolicyLossWithoutReg Std             63.2292
trainer/PolicyLossWithoutReg Max            353.239
trainer/PolicyLossWithoutReg Min             15.8592
exploration/num steps total              280000
exploration/num paths total                1015
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.14754
exploration/Rewards Std                       1.37134
exploration/Rewards Max                       7.29164
exploration/Rewards Min                      -1.15454
exploration/Returns Mean                   4147.54
exploration/Returns Std                       0
exploration/Returns Max                    4147.54
exploration/Returns Min                    4147.54
exploration/Num Paths                         1
exploration/Average Returns                4147.54
evaluation_0/num steps total                  2.14962e+06
evaluation_0/num paths total               5491
evaluation_0/path length Mean               836.333
evaluation_0/path length Std                193.528
evaluation_0/path length Max               1000
evaluation_0/path length Min                431
evaluation_0/Rewards Mean                     4.21496
evaluation_0/Rewards Std                      1.11104
evaluation_0/Rewards Max                      8.15605
evaluation_0/Rewards Min                     -0.673649
evaluation_0/Returns Mean                  3525.11
evaluation_0/Returns Std                    901.651
evaluation_0/Returns Max                   4434.69
evaluation_0/Returns Min                   1643.21
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3525.11
time/epoch (s)                                0
time/total (s)                             4271.67
Epoch                                       275
---------------------------------------  ----------------
2022-11-16 17:26:09.256193 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 276 finished
---------------------------------------  ----------------
epoch                                       276
total_step                               281000
replay_pool/size                         281000
trainer/alpha                                 0.0618526
trainer/alpha_loss                            0.364671
trainer/entropy                              -6.13104
trainer/qf_loss                              15.7969
trainer/policy_loss                        -269.116
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         269.495
trainer/entropy_penalty                      -0.379221
trainer/entropy_percentage                   -0.00140715
trainer/Q1Pred Mean                         268.486
trainer/Q1Pred Std                           74.6797
trainer/Q1Pred Max                          358.631
trainer/Q1Pred Min                            1.84053
trainer/Q2Pred Mean                         268.367
trainer/Q2Pred Std                           74.8529
trainer/Q2Pred Max                          359.717
trainer/Q2Pred Min                           -1.34451
trainer/QTargetWithReg Mean                 267.547
trainer/QTargetWithReg Std                   74.6203
trainer/QTargetWithReg Max                  359.255
trainer/QTargetWithReg Min                    3.35318
trainer/PolicyLossWithoutReg Mean           269.495
trainer/PolicyLossWithoutReg Std             74.2549
trainer/PolicyLossWithoutReg Max            359.41
trainer/PolicyLossWithoutReg Min              2.36495
exploration/num steps total              281000
exploration/num paths total                1016
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.28481
exploration/Rewards Std                       1.08998
exploration/Rewards Max                       6.70953
exploration/Rewards Min                      -0.843354
exploration/Returns Mean                   4284.81
exploration/Returns Std                       0
exploration/Returns Max                    4284.81
exploration/Returns Min                    4284.81
exploration/Num Paths                         1
exploration/Average Returns                4284.81
evaluation_0/num steps total                  2.15738e+06
evaluation_0/num paths total               5499
evaluation_0/path length Mean               970.125
evaluation_0/path length Std                 79.0418
evaluation_0/path length Max               1000
evaluation_0/path length Min                761
evaluation_0/Rewards Mean                     3.95599
evaluation_0/Rewards Std                      1.09771
evaluation_0/Rewards Max                      6.54345
evaluation_0/Rewards Min                     -0.582977
evaluation_0/Returns Mean                  3837.81
evaluation_0/Returns Std                    446.682
evaluation_0/Returns Max                   4220.53
evaluation_0/Returns Min                   2853
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3837.81
time/epoch (s)                                0
time/total (s)                             4286.35
Epoch                                       276
---------------------------------------  ----------------
2022-11-16 17:26:21.672442 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 277 finished
---------------------------------------  ----------------
epoch                                       277
total_step                               282000
replay_pool/size                         282000
trainer/alpha                                 0.0615658
trainer/alpha_loss                           -0.624526
trainer/entropy                              -5.77597
trainer/qf_loss                              26.2868
trainer/policy_loss                        -277.366
trainer/adversary_policy_loss                13.2405
trainer/policy_loss_without_entropy         277.722
trainer/entropy_penalty                      -0.355602
trainer/entropy_percentage                   -0.00128042
trainer/Q1Pred Mean                         276.517
trainer/Q1Pred Std                           64.186
trainer/Q1Pred Max                          351.978
trainer/Q1Pred Min                           12.4049
trainer/Q2Pred Mean                         276.805
trainer/Q2Pred Std                           64.5329
trainer/Q2Pred Max                          351.255
trainer/Q2Pred Min                           18.5846
trainer/QTargetWithReg Mean                 276.776
trainer/QTargetWithReg Std                   64.7381
trainer/QTargetWithReg Max                  348.556
trainer/QTargetWithReg Min                   22.0773
trainer/PolicyLossWithoutReg Mean           277.722
trainer/PolicyLossWithoutReg Std             62.7816
trainer/PolicyLossWithoutReg Max            353.108
trainer/PolicyLossWithoutReg Min             12.2477
exploration/num steps total              282000
exploration/num paths total                1017
exploration/path length this epoch Mean     930
exploration/path length this epoch Std        0
exploration/path length this epoch Max      930
exploration/path length this epoch Min      930
exploration/Rewards Mean                      4.22051
exploration/Rewards Std                       1.25843
exploration/Rewards Max                      10.0464
exploration/Rewards Min                      -0.663226
exploration/Returns Mean                   3925.07
exploration/Returns Std                       0
exploration/Returns Max                    3925.07
exploration/Returns Min                    3925.07
exploration/Num Paths                         1
exploration/Average Returns                3925.07
evaluation_0/num steps total                  2.16538e+06
evaluation_0/num paths total               5507
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.30416
evaluation_0/Rewards Std                      1.08972
evaluation_0/Rewards Max                      6.97805
evaluation_0/Rewards Min                     -0.594941
evaluation_0/Returns Mean                  4304.16
evaluation_0/Returns Std                    121.77
evaluation_0/Returns Max                   4523.66
evaluation_0/Returns Min                   4112.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4304.16
time/epoch (s)                                0
time/total (s)                             4298.76
Epoch                                       277
---------------------------------------  ----------------
2022-11-16 17:26:34.314039 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 278 finished
---------------------------------------  ----------------
epoch                                       278
total_step                               283000
replay_pool/size                         283000
trainer/alpha                                 0.0597416
trainer/alpha_loss                            1.6888
trainer/entropy                              -6.59933
trainer/qf_loss                              27.1185
trainer/policy_loss                        -276.428
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         276.823
trainer/entropy_penalty                      -0.394255
trainer/entropy_percentage                   -0.00142422
trainer/Q1Pred Mean                         275.429
trainer/Q1Pred Std                           65.5639
trainer/Q1Pred Max                          357.46
trainer/Q1Pred Min                            2.29945
trainer/Q2Pred Mean                         275.12
trainer/Q2Pred Std                           65.6442
trainer/Q2Pred Max                          357.938
trainer/Q2Pred Min                           -9.45321
trainer/QTargetWithReg Mean                 274.193
trainer/QTargetWithReg Std                   66.3842
trainer/QTargetWithReg Max                  359.082
trainer/QTargetWithReg Min                   -0.599456
trainer/PolicyLossWithoutReg Mean           276.822
trainer/PolicyLossWithoutReg Std             63.1103
trainer/PolicyLossWithoutReg Max            357.697
trainer/PolicyLossWithoutReg Min              1.00435
exploration/num steps total              283000
exploration/num paths total                1018
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.16308
exploration/Rewards Std                       1.12289
exploration/Rewards Max                       7.42275
exploration/Rewards Min                      -0.447521
exploration/Returns Mean                   4163.08
exploration/Returns Std                       0
exploration/Returns Max                    4163.08
exploration/Returns Min                    4163.08
exploration/Num Paths                         1
exploration/Average Returns                4163.08
evaluation_0/num steps total                  2.17338e+06
evaluation_0/num paths total               5515
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.18399
evaluation_0/Rewards Std                      0.902502
evaluation_0/Rewards Max                      5.84488
evaluation_0/Rewards Min                     -0.646252
evaluation_0/Returns Mean                  4183.99
evaluation_0/Returns Std                    114.052
evaluation_0/Returns Max                   4388.93
evaluation_0/Returns Min                   3954.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4183.99
time/epoch (s)                                0
time/total (s)                             4311.41
Epoch                                       278
---------------------------------------  ----------------
2022-11-16 17:26:47.925876 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 279 finished
---------------------------------------  ----------------
epoch                                       279
total_step                               284000
replay_pool/size                         284000
trainer/alpha                                 0.0605684
trainer/alpha_loss                            0.503085
trainer/entropy                              -6.17942
trainer/qf_loss                              18.2946
trainer/policy_loss                        -279.506
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         279.88
trainer/entropy_penalty                      -0.374278
trainer/entropy_percentage                   -0.00133728
trainer/Q1Pred Mean                         278.522
trainer/Q1Pred Std                           61.4045
trainer/Q1Pred Max                          370.48
trainer/Q1Pred Min                           24.8445
trainer/Q2Pred Mean                         278.746
trainer/Q2Pred Std                           61.1955
trainer/Q2Pred Max                          370.924
trainer/Q2Pred Min                           19.9774
trainer/QTargetWithReg Mean                 278.588
trainer/QTargetWithReg Std                   60.8853
trainer/QTargetWithReg Max                  367.858
trainer/QTargetWithReg Min                   29.6093
trainer/PolicyLossWithoutReg Mean           279.88
trainer/PolicyLossWithoutReg Std             60.4757
trainer/PolicyLossWithoutReg Max            370.671
trainer/PolicyLossWithoutReg Min             26.9499
exploration/num steps total              284000
exploration/num paths total                1019
exploration/path length this epoch Mean     613
exploration/path length this epoch Std        0
exploration/path length this epoch Max      613
exploration/path length this epoch Min      613
exploration/Rewards Mean                      3.92728
exploration/Rewards Std                       1.16276
exploration/Rewards Max                       7.07239
exploration/Rewards Min                      -0.544486
exploration/Returns Mean                   2407.42
exploration/Returns Std                       0
exploration/Returns Max                    2407.42
exploration/Returns Min                    2407.42
exploration/Num Paths                         1
exploration/Average Returns                2407.42
evaluation_0/num steps total                  2.18138e+06
evaluation_0/num paths total               5523
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.97223
evaluation_0/Rewards Std                      0.940345
evaluation_0/Rewards Max                      6.79862
evaluation_0/Rewards Min                     -0.428773
evaluation_0/Returns Mean                  3972.23
evaluation_0/Returns Std                    211.9
evaluation_0/Returns Max                   4302.74
evaluation_0/Returns Min                   3739.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3972.23
time/epoch (s)                                0
time/total (s)                             4325.02
Epoch                                       279
---------------------------------------  ----------------
2022-11-16 17:27:00.819236 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 280 finished
---------------------------------------  ----------------
epoch                                       280
total_step                               285000
replay_pool/size                         285000
trainer/alpha                                 0.0602202
trainer/alpha_loss                           -0.950174
trainer/entropy                              -5.66183
trainer/qf_loss                              16.3613
trainer/policy_loss                        -275.594
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         275.935
trainer/entropy_penalty                      -0.340957
trainer/entropy_percentage                   -0.00123564
trainer/Q1Pred Mean                         275.148
trainer/Q1Pred Std                           68.8794
trainer/Q1Pred Max                          361.09
trainer/Q1Pred Min                          -19.6827
trainer/Q2Pred Mean                         275.574
trainer/Q2Pred Std                           68.8077
trainer/Q2Pred Max                          360.688
trainer/Q2Pred Min                           -7.32527
trainer/QTargetWithReg Mean                 274.806
trainer/QTargetWithReg Std                   68.7408
trainer/QTargetWithReg Max                  359.053
trainer/QTargetWithReg Min                    4.73677
trainer/PolicyLossWithoutReg Mean           275.935
trainer/PolicyLossWithoutReg Std             67.6345
trainer/PolicyLossWithoutReg Max            360.213
trainer/PolicyLossWithoutReg Min            -16.5845
exploration/num steps total              285000
exploration/num paths total                1020
exploration/path length this epoch Mean     106
exploration/path length this epoch Std        0
exploration/path length this epoch Max      106
exploration/path length this epoch Min      106
exploration/Rewards Mean                      2.39695
exploration/Rewards Std                       1.19955
exploration/Rewards Max                       4.4897
exploration/Rewards Min                      -0.407261
exploration/Returns Mean                    254.077
exploration/Returns Std                       0
exploration/Returns Max                     254.077
exploration/Returns Min                     254.077
exploration/Num Paths                         1
exploration/Average Returns                 254.077
evaluation_0/num steps total                  2.18851e+06
evaluation_0/num paths total               5531
evaluation_0/path length Mean               891.375
evaluation_0/path length Std                287.395
evaluation_0/path length Max               1000
evaluation_0/path length Min                131
evaluation_0/Rewards Mean                     3.61682
evaluation_0/Rewards Std                      1.28125
evaluation_0/Rewards Max                      5.90639
evaluation_0/Rewards Min                     -0.581593
evaluation_0/Returns Mean                  3223.94
evaluation_0/Returns Std                   1252.79
evaluation_0/Returns Max                   4058.33
evaluation_0/Returns Min                    208.917
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3223.94
time/epoch (s)                                0
time/total (s)                             4337.91
Epoch                                       280
---------------------------------------  ----------------
2022-11-16 17:27:15.200794 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 281 finished
---------------------------------------  ----------------
epoch                                       281
total_step                               286000
replay_pool/size                         286000
trainer/alpha                                 0.0607934
trainer/alpha_loss                            0.629904
trainer/entropy                              -6.22494
trainer/qf_loss                              22.565
trainer/policy_loss                        -277.298
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         277.677
trainer/entropy_penalty                      -0.378435
trainer/entropy_percentage                   -0.00136286
trainer/Q1Pred Mean                         276.178
trainer/Q1Pred Std                           67.3094
trainer/Q1Pred Max                          362.72
trainer/Q1Pred Min                            1.79749
trainer/Q2Pred Mean                         276.625
trainer/Q2Pred Std                           67.0147
trainer/Q2Pred Max                          366.389
trainer/Q2Pred Min                           -4.49488
trainer/QTargetWithReg Mean                 276.306
trainer/QTargetWithReg Std                   67.5765
trainer/QTargetWithReg Max                  362.72
trainer/QTargetWithReg Min                    4.52927
trainer/PolicyLossWithoutReg Mean           277.676
trainer/PolicyLossWithoutReg Std             65.9319
trainer/PolicyLossWithoutReg Max            363.858
trainer/PolicyLossWithoutReg Min              1.55581
exploration/num steps total              286000
exploration/num paths total                1021
exploration/path length this epoch Mean     554
exploration/path length this epoch Std        0
exploration/path length this epoch Max      554
exploration/path length this epoch Min      554
exploration/Rewards Mean                      3.55768
exploration/Rewards Std                       1.23832
exploration/Rewards Max                       6.01903
exploration/Rewards Min                      -0.662098
exploration/Returns Mean                   1970.96
exploration/Returns Std                       0
exploration/Returns Max                    1970.96
exploration/Returns Min                    1970.96
exploration/Num Paths                         1
exploration/Average Returns                1970.96
evaluation_0/num steps total                  2.19639e+06
evaluation_0/num paths total               5540
evaluation_0/path length Mean               875.222
evaluation_0/path length Std                156.887
evaluation_0/path length Max               1000
evaluation_0/path length Min                629
evaluation_0/Rewards Mean                     4.1143
evaluation_0/Rewards Std                      1.12352
evaluation_0/Rewards Max                      9.24075
evaluation_0/Rewards Min                     -0.874842
evaluation_0/Returns Mean                  3600.93
evaluation_0/Returns Std                    703.323
evaluation_0/Returns Max                   4421.52
evaluation_0/Returns Min                   2553.86
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3600.93
time/epoch (s)                                0
time/total (s)                             4352.29
Epoch                                       281
---------------------------------------  ----------------
2022-11-16 17:27:29.950319 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 282 finished
---------------------------------------  ----------------
epoch                                       282
total_step                               287000
replay_pool/size                         287000
trainer/alpha                                 0.0628787
trainer/alpha_loss                            0.813581
trainer/entropy                              -6.29408
trainer/qf_loss                              23.2054
trainer/policy_loss                        -278.654
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         279.05
trainer/entropy_penalty                      -0.395764
trainer/entropy_percentage                   -0.00141825
trainer/Q1Pred Mean                         276.779
trainer/Q1Pred Std                           59.0398
trainer/Q1Pred Max                          360.141
trainer/Q1Pred Min                           -5.87234
trainer/Q2Pred Mean                         277.573
trainer/Q2Pred Std                           59.1961
trainer/Q2Pred Max                          360.115
trainer/Q2Pred Min                           -5.11729
trainer/QTargetWithReg Mean                 277.605
trainer/QTargetWithReg Std                   59.0829
trainer/QTargetWithReg Max                  360.364
trainer/QTargetWithReg Min                   -0.214114
trainer/PolicyLossWithoutReg Mean           279.05
trainer/PolicyLossWithoutReg Std             55.8641
trainer/PolicyLossWithoutReg Max            360.038
trainer/PolicyLossWithoutReg Min              7.52617
exploration/num steps total              287000
exploration/num paths total                1022
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.14053
exploration/Rewards Std                       1.104
exploration/Rewards Max                       6.50542
exploration/Rewards Min                      -0.913894
exploration/Returns Mean                   4140.53
exploration/Returns Std                       0
exploration/Returns Max                    4140.53
exploration/Returns Min                    4140.53
exploration/Num Paths                         1
exploration/Average Returns                4140.53
evaluation_0/num steps total                  2.20439e+06
evaluation_0/num paths total               5548
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.09358
evaluation_0/Rewards Std                      1.06936
evaluation_0/Rewards Max                      6.73485
evaluation_0/Rewards Min                     -0.666548
evaluation_0/Returns Mean                  4093.58
evaluation_0/Returns Std                    167.124
evaluation_0/Returns Max                   4345.02
evaluation_0/Returns Min                   3841.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4093.58
time/epoch (s)                                0
time/total (s)                             4367.04
Epoch                                       282
---------------------------------------  ----------------
2022-11-16 17:27:46.089437 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 283 finished
---------------------------------------  ----------------
epoch                                       283
total_step                               288000
replay_pool/size                         288000
trainer/alpha                                 0.0606881
trainer/alpha_loss                           -0.693125
trainer/entropy                              -5.75263
trainer/qf_loss                              19.7645
trainer/policy_loss                        -283.002
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.351
trainer/entropy_penalty                      -0.349116
trainer/entropy_percentage                   -0.0012321
trainer/Q1Pred Mean                         280.943
trainer/Q1Pred Std                           63.5351
trainer/Q1Pred Max                          357.801
trainer/Q1Pred Min                          -79.3689
trainer/Q2Pred Mean                         281.574
trainer/Q2Pred Std                           63.8121
trainer/Q2Pred Max                          358.816
trainer/Q2Pred Min                          -79.3071
trainer/QTargetWithReg Mean                 280.915
trainer/QTargetWithReg Std                   64.5982
trainer/QTargetWithReg Max                  358.952
trainer/QTargetWithReg Min                 -105.828
trainer/PolicyLossWithoutReg Mean           283.351
trainer/PolicyLossWithoutReg Std             57.4324
trainer/PolicyLossWithoutReg Max            358.034
trainer/PolicyLossWithoutReg Min             16.2087
exploration/num steps total              288000
exploration/num paths total                1023
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.88501
exploration/Rewards Std                       1.2327
exploration/Rewards Max                       7.75571
exploration/Rewards Min                      -0.710077
exploration/Returns Mean                   3885.01
exploration/Returns Std                       0
exploration/Returns Max                    3885.01
exploration/Returns Min                    3885.01
exploration/Num Paths                         1
exploration/Average Returns                3885.01
evaluation_0/num steps total                  2.21216e+06
evaluation_0/num paths total               5557
evaluation_0/path length Mean               863.333
evaluation_0/path length Std                185.42
evaluation_0/path length Max               1000
evaluation_0/path length Min                548
evaluation_0/Rewards Mean                     4.20327
evaluation_0/Rewards Std                      1.06768
evaluation_0/Rewards Max                      9.51042
evaluation_0/Rewards Min                     -0.618822
evaluation_0/Returns Mean                  3628.82
evaluation_0/Returns Std                    802.126
evaluation_0/Returns Max                   4355.23
evaluation_0/Returns Min                   2218.6
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3628.82
time/epoch (s)                                0
time/total (s)                             4383.18
Epoch                                       283
---------------------------------------  ----------------
2022-11-16 17:28:02.773399 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 284 finished
---------------------------------------  ----------------
epoch                                       284
total_step                               289000
replay_pool/size                         289000
trainer/alpha                                 0.0607434
trainer/alpha_loss                            1.11639
trainer/entropy                              -6.39855
trainer/qf_loss                              18.5099
trainer/policy_loss                        -280.901
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         281.29
trainer/entropy_penalty                      -0.38867
trainer/entropy_percentage                   -0.00138174
trainer/Q1Pred Mean                         279.968
trainer/Q1Pred Std                           61.5478
trainer/Q1Pred Max                          359.13
trainer/Q1Pred Min                            8.13645
trainer/Q2Pred Mean                         278.998
trainer/Q2Pred Std                           61.6101
trainer/Q2Pred Max                          363.421
trainer/Q2Pred Min                            1.83637
trainer/QTargetWithReg Mean                 279.689
trainer/QTargetWithReg Std                   62.2846
trainer/QTargetWithReg Max                  359.504
trainer/QTargetWithReg Min                    3.90916
trainer/PolicyLossWithoutReg Mean           281.29
trainer/PolicyLossWithoutReg Std             59.7915
trainer/PolicyLossWithoutReg Max            358.957
trainer/PolicyLossWithoutReg Min              3.70684
exploration/num steps total              289000
exploration/num paths total                1024
exploration/path length this epoch Mean     513
exploration/path length this epoch Std        0
exploration/path length this epoch Max      513
exploration/path length this epoch Min      513
exploration/Rewards Mean                      3.64617
exploration/Rewards Std                       1.18177
exploration/Rewards Max                       5.62168
exploration/Rewards Min                      -0.686641
exploration/Returns Mean                   1870.49
exploration/Returns Std                       0
exploration/Returns Max                    1870.49
exploration/Returns Min                    1870.49
exploration/Num Paths                         1
exploration/Average Returns                1870.49
evaluation_0/num steps total                  2.21961e+06
evaluation_0/num paths total               5565
evaluation_0/path length Mean               931.25
evaluation_0/path length Std                181.895
evaluation_0/path length Max               1000
evaluation_0/path length Min                450
evaluation_0/Rewards Mean                     4.21087
evaluation_0/Rewards Std                      1.06089
evaluation_0/Rewards Max                      6.83502
evaluation_0/Rewards Min                     -0.555365
evaluation_0/Returns Mean                  3921.38
evaluation_0/Returns Std                    821.333
evaluation_0/Returns Max                   4465.74
evaluation_0/Returns Min                   1791.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3921.38
time/epoch (s)                                0
time/total (s)                             4399.86
Epoch                                       284
---------------------------------------  ----------------
2022-11-16 17:28:17.503342 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 285 finished
---------------------------------------  ----------------
epoch                                       285
total_step                               290000
replay_pool/size                         290000
trainer/alpha                                 0.0630195
trainer/alpha_loss                           -2.29645
trainer/entropy                              -5.16919
trainer/qf_loss                              17.5136
trainer/policy_loss                        -281.861
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         282.187
trainer/entropy_penalty                      -0.32576
trainer/entropy_percentage                   -0.00115441
trainer/Q1Pred Mean                         281.415
trainer/Q1Pred Std                           62.265
trainer/Q1Pred Max                          374.338
trainer/Q1Pred Min                           14.5835
trainer/Q2Pred Mean                         281.56
trainer/Q2Pred Std                           62.0419
trainer/Q2Pred Max                          372.672
trainer/Q2Pred Min                           14.7807
trainer/QTargetWithReg Mean                 281.83
trainer/QTargetWithReg Std                   63.0424
trainer/QTargetWithReg Max                  375.387
trainer/QTargetWithReg Min                   17.5137
trainer/PolicyLossWithoutReg Mean           282.187
trainer/PolicyLossWithoutReg Std             61.342
trainer/PolicyLossWithoutReg Max            373.315
trainer/PolicyLossWithoutReg Min             14.366
exploration/num steps total              290000
exploration/num paths total                1025
exploration/path length this epoch Mean     832
exploration/path length this epoch Std        0
exploration/path length this epoch Max      832
exploration/path length this epoch Min      832
exploration/Rewards Mean                      4.05842
exploration/Rewards Std                       1.16403
exploration/Rewards Max                       7.95757
exploration/Rewards Min                      -0.587264
exploration/Returns Mean                   3376.6
exploration/Returns Std                       0
exploration/Returns Max                    3376.6
exploration/Returns Min                    3376.6
exploration/Num Paths                         1
exploration/Average Returns                3376.6
evaluation_0/num steps total                  2.22761e+06
evaluation_0/num paths total               5573
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.11985
evaluation_0/Rewards Std                      0.964236
evaluation_0/Rewards Max                      6.76541
evaluation_0/Rewards Min                     -0.541935
evaluation_0/Returns Mean                  4119.85
evaluation_0/Returns Std                     59.9594
evaluation_0/Returns Max                   4208.67
evaluation_0/Returns Min                   4018.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4119.85
time/epoch (s)                                0
time/total (s)                             4414.59
Epoch                                       285
---------------------------------------  ----------------
2022-11-16 17:28:34.214918 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 286 finished
---------------------------------------  ----------------
epoch                                       286
total_step                               291000
replay_pool/size                         291000
trainer/alpha                                 0.0620934
trainer/alpha_loss                            0.510448
trainer/entropy                              -6.18366
trainer/qf_loss                              21.6033
trainer/policy_loss                        -282.455
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         282.839
trainer/entropy_penalty                      -0.383964
trainer/entropy_percentage                   -0.00135754
trainer/Q1Pred Mean                         281.697
trainer/Q1Pred Std                           62.7632
trainer/Q1Pred Max                          368.986
trainer/Q1Pred Min                           13.2037
trainer/Q2Pred Mean                         281.693
trainer/Q2Pred Std                           63.6071
trainer/Q2Pred Max                          370.495
trainer/Q2Pred Min                           17.9023
trainer/QTargetWithReg Mean                 281.408
trainer/QTargetWithReg Std                   63.8626
trainer/QTargetWithReg Max                  367.839
trainer/QTargetWithReg Min                   13.5502
trainer/PolicyLossWithoutReg Mean           282.839
trainer/PolicyLossWithoutReg Std             60.3428
trainer/PolicyLossWithoutReg Max            368.757
trainer/PolicyLossWithoutReg Min             15.5095
exploration/num steps total              291000
exploration/num paths total                1026
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45502
exploration/Rewards Std                       0.999823
exploration/Rewards Max                       6.71917
exploration/Rewards Min                      -0.66345
exploration/Returns Mean                   4455.02
exploration/Returns Std                       0
exploration/Returns Max                    4455.02
exploration/Returns Min                    4455.02
exploration/Num Paths                         1
exploration/Average Returns                4455.02
evaluation_0/num steps total                  2.23547e+06
evaluation_0/num paths total               5584
evaluation_0/path length Mean               714.727
evaluation_0/path length Std                302.488
evaluation_0/path length Max               1000
evaluation_0/path length Min                196
evaluation_0/Rewards Mean                     4.37529
evaluation_0/Rewards Std                      1.06806
evaluation_0/Rewards Max                      9.10571
evaluation_0/Rewards Min                     -0.72382
evaluation_0/Returns Mean                  3127.14
evaluation_0/Returns Std                   1436.05
evaluation_0/Returns Max                   4549.57
evaluation_0/Returns Min                    617.102
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3127.14
time/epoch (s)                                0
time/total (s)                             4431.3
Epoch                                       286
---------------------------------------  ----------------
2022-11-16 17:28:50.795915 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 287 finished
---------------------------------------  ----------------
epoch                                       287
total_step                               292000
replay_pool/size                         292000
trainer/alpha                                 0.0629505
trainer/alpha_loss                            0.854327
trainer/entropy                              -6.30893
trainer/qf_loss                              17.2795
trainer/policy_loss                        -278.36
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         278.757
trainer/entropy_penalty                      -0.39715
trainer/entropy_percentage                   -0.00142472
trainer/Q1Pred Mean                         277.153
trainer/Q1Pred Std                           70.5825
trainer/Q1Pred Max                          369.576
trainer/Q1Pred Min                          -15.907
trainer/Q2Pred Mean                         277.212
trainer/Q2Pred Std                           70.2947
trainer/Q2Pred Max                          372.542
trainer/Q2Pred Min                          -22.5594
trainer/QTargetWithReg Mean                 276.146
trainer/QTargetWithReg Std                   70.9794
trainer/QTargetWithReg Max                  369.592
trainer/QTargetWithReg Min                  -36.0124
trainer/PolicyLossWithoutReg Mean           278.757
trainer/PolicyLossWithoutReg Std             67.5215
trainer/PolicyLossWithoutReg Max            368.981
trainer/PolicyLossWithoutReg Min             10.3892
exploration/num steps total              292000
exploration/num paths total                1028
exploration/path length this epoch Mean     407.5
exploration/path length this epoch Std       10.5
exploration/path length this epoch Max      418
exploration/path length this epoch Min      397
exploration/Rewards Mean                      3.45447
exploration/Rewards Std                       1.11476
exploration/Rewards Max                       5.51553
exploration/Rewards Min                      -0.752844
exploration/Returns Mean                   1407.7
exploration/Returns Std                      37.7293
exploration/Returns Max                    1445.43
exploration/Returns Min                    1369.97
exploration/Num Paths                         2
exploration/Average Returns                1407.7
evaluation_0/num steps total                  2.24260e+06
evaluation_0/num paths total               5592
evaluation_0/path length Mean               892
evaluation_0/path length Std                225.539
evaluation_0/path length Max               1000
evaluation_0/path length Min                316
evaluation_0/Rewards Mean                     4.17203
evaluation_0/Rewards Std                      1.00193
evaluation_0/Rewards Max                      7.60658
evaluation_0/Rewards Min                     -0.533831
evaluation_0/Returns Mean                  3721.45
evaluation_0/Returns Std                    989.5
evaluation_0/Returns Max                   4365.34
evaluation_0/Returns Min                   1147.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3721.45
time/epoch (s)                                0
time/total (s)                             4447.88
Epoch                                       287
---------------------------------------  ----------------
2022-11-16 17:29:07.533115 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 288 finished
---------------------------------------  ---------------
epoch                                       288
total_step                               293000
replay_pool/size                         293000
trainer/alpha                                 0.0638238
trainer/alpha_loss                           -0.429449
trainer/entropy                              -5.84393
trainer/qf_loss                              17.4834
trainer/policy_loss                        -280.91
trainer/adversary_policy_loss                13.3331
trainer/policy_loss_without_entropy         281.283
trainer/entropy_penalty                      -0.372982
trainer/entropy_percentage                   -0.001326
trainer/Q1Pred Mean                         280.036
trainer/Q1Pred Std                           61.6525
trainer/Q1Pred Max                          364.329
trainer/Q1Pred Min                            6.28117
trainer/Q2Pred Mean                         280.887
trainer/Q2Pred Std                           61.2124
trainer/Q2Pred Max                          361.432
trainer/Q2Pred Min                            8.8307
trainer/QTargetWithReg Mean                 280.808
trainer/QTargetWithReg Std                   61.5969
trainer/QTargetWithReg Max                  370.143
trainer/QTargetWithReg Min                   10.0692
trainer/PolicyLossWithoutReg Mean           281.283
trainer/PolicyLossWithoutReg Std             60.4039
trainer/PolicyLossWithoutReg Max            358.755
trainer/PolicyLossWithoutReg Min              7.00974
exploration/num steps total              293000
exploration/num paths total                1029
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.29537
exploration/Rewards Std                       0.995511
exploration/Rewards Max                       6.90692
exploration/Rewards Min                      -0.631588
exploration/Returns Mean                   4295.37
exploration/Returns Std                       0
exploration/Returns Max                    4295.37
exploration/Returns Min                    4295.37
exploration/Num Paths                         1
exploration/Average Returns                4295.37
evaluation_0/num steps total                  2.2497e+06
evaluation_0/num paths total               5600
evaluation_0/path length Mean               887
evaluation_0/path length Std                298.97
evaluation_0/path length Max               1000
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     4.33028
evaluation_0/Rewards Std                      1.03163
evaluation_0/Rewards Max                      7.7955
evaluation_0/Rewards Min                     -0.584445
evaluation_0/Returns Mean                  3840.96
evaluation_0/Returns Std                   1371.39
evaluation_0/Returns Max                   4546.79
evaluation_0/Returns Min                    226.786
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3840.96
time/epoch (s)                                0
time/total (s)                             4464.62
Epoch                                       288
---------------------------------------  ---------------
2022-11-16 17:29:22.460362 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 289 finished
---------------------------------------  ---------------
epoch                                       289
total_step                               294000
replay_pool/size                         294000
trainer/alpha                                 0.0627673
trainer/alpha_loss                            0.129963
trainer/entropy                              -6.04695
trainer/qf_loss                              16.1835
trainer/policy_loss                        -279.746
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         280.126
trainer/entropy_penalty                      -0.37955
trainer/entropy_percentage                   -0.00135493
trainer/Q1Pred Mean                         279.878
trainer/Q1Pred Std                           65.4887
trainer/Q1Pred Max                          359.577
trainer/Q1Pred Min                           -8.34696
trainer/Q2Pred Mean                         279.486
trainer/Q2Pred Std                           66.4545
trainer/Q2Pred Max                          357.753
trainer/Q2Pred Min                           -8.04728
trainer/QTargetWithReg Mean                 280.056
trainer/QTargetWithReg Std                   66.0203
trainer/QTargetWithReg Max                  357.88
trainer/QTargetWithReg Min                   -1.43792
trainer/PolicyLossWithoutReg Mean           280.126
trainer/PolicyLossWithoutReg Std             65.0446
trainer/PolicyLossWithoutReg Max            358.092
trainer/PolicyLossWithoutReg Min             -1.40673
exploration/num steps total              294000
exploration/num paths total                1031
exploration/path length this epoch Mean     486.5
exploration/path length this epoch Std      394.5
exploration/path length this epoch Max      881
exploration/path length this epoch Min       92
exploration/Rewards Mean                      4.14711
exploration/Rewards Std                       1.46574
exploration/Rewards Max                       7.9556
exploration/Rewards Min                      -0.581679
exploration/Returns Mean                   2017.57
exploration/Returns Std                    1836.32
exploration/Returns Max                    3853.88
exploration/Returns Min                     181.253
exploration/Num Paths                         2
exploration/Average Returns                2017.57
evaluation_0/num steps total                  2.2577e+06
evaluation_0/num paths total               5608
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.42222
evaluation_0/Rewards Std                      0.999966
evaluation_0/Rewards Max                      7.38229
evaluation_0/Rewards Min                     -0.735698
evaluation_0/Returns Mean                  4422.22
evaluation_0/Returns Std                    161.504
evaluation_0/Returns Max                   4757.91
evaluation_0/Returns Min                   4186.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4422.22
time/epoch (s)                                0
time/total (s)                             4479.55
Epoch                                       289
---------------------------------------  ---------------
2022-11-16 17:29:37.165697 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 290 finished
---------------------------------------  ---------------
epoch                                       290
total_step                               295000
replay_pool/size                         295000
trainer/alpha                                 0.0634121
trainer/alpha_loss                           -0.19074
trainer/entropy                              -5.93084
trainer/qf_loss                              22.8386
trainer/policy_loss                        -283.275
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.651
trainer/entropy_penalty                      -0.376087
trainer/entropy_percentage                   -0.00132588
trainer/Q1Pred Mean                         283.454
trainer/Q1Pred Std                           54.0467
trainer/Q1Pred Max                          374.605
trainer/Q1Pred Min                           -4.48674
trainer/Q2Pred Mean                         282.96
trainer/Q2Pred Std                           53.9909
trainer/Q2Pred Max                          372.775
trainer/Q2Pred Min                          -14.2871
trainer/QTargetWithReg Mean                 282.837
trainer/QTargetWithReg Std                   53.9077
trainer/QTargetWithReg Max                  372.693
trainer/QTargetWithReg Min                    3.63029
trainer/PolicyLossWithoutReg Mean           283.651
trainer/PolicyLossWithoutReg Std             52.3456
trainer/PolicyLossWithoutReg Max            373.269
trainer/PolicyLossWithoutReg Min             -0.100151
exploration/num steps total              295000
exploration/num paths total                1032
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27462
exploration/Rewards Std                       1.03074
exploration/Rewards Max                       6.70855
exploration/Rewards Min                      -0.689624
exploration/Returns Mean                   4274.62
exploration/Returns Std                       0
exploration/Returns Max                    4274.62
exploration/Returns Min                    4274.62
exploration/Num Paths                         1
exploration/Average Returns                4274.62
evaluation_0/num steps total                  2.2657e+06
evaluation_0/num paths total               5616
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.24447
evaluation_0/Rewards Std                      0.881728
evaluation_0/Rewards Max                      6.83579
evaluation_0/Rewards Min                     -0.682887
evaluation_0/Returns Mean                  4244.47
evaluation_0/Returns Std                    116.647
evaluation_0/Returns Max                   4459.51
evaluation_0/Returns Min                   4089.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4244.47
time/epoch (s)                                0
time/total (s)                             4494.25
Epoch                                       290
---------------------------------------  ---------------
2022-11-16 17:29:54.395479 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 291 finished
---------------------------------------  ----------------
epoch                                       291
total_step                               296000
replay_pool/size                         296000
trainer/alpha                                 0.0621858
trainer/alpha_loss                           -0.189104
trainer/entropy                              -5.93192
trainer/qf_loss                              15.5117
trainer/policy_loss                        -281.792
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         282.16
trainer/entropy_penalty                      -0.368881
trainer/entropy_percentage                   -0.00130735
trainer/Q1Pred Mean                         281.096
trainer/Q1Pred Std                           65.3696
trainer/Q1Pred Max                          358.821
trainer/Q1Pred Min                          -23.7176
trainer/Q2Pred Mean                         281.181
trainer/Q2Pred Std                           65.2452
trainer/Q2Pred Max                          357.863
trainer/Q2Pred Min                          -26.54
trainer/QTargetWithReg Mean                 280.697
trainer/QTargetWithReg Std                   65.0106
trainer/QTargetWithReg Max                  359.537
trainer/QTargetWithReg Min                   -0.103547
trainer/PolicyLossWithoutReg Mean           282.16
trainer/PolicyLossWithoutReg Std             62.7775
trainer/PolicyLossWithoutReg Max            363.783
trainer/PolicyLossWithoutReg Min             15.0905
exploration/num steps total              296000
exploration/num paths total                1033
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.25963
exploration/Rewards Std                       1.09254
exploration/Rewards Max                       6.86428
exploration/Rewards Min                      -0.647075
exploration/Returns Mean                   4259.63
exploration/Returns Std                       0
exploration/Returns Max                    4259.63
exploration/Returns Min                    4259.63
exploration/Num Paths                         1
exploration/Average Returns                4259.63
evaluation_0/num steps total                  2.27309e+06
evaluation_0/num paths total               5624
evaluation_0/path length Mean               923.125
evaluation_0/path length Std                113.968
evaluation_0/path length Max               1000
evaluation_0/path length Min                701
evaluation_0/Rewards Mean                     4.10603
evaluation_0/Rewards Std                      0.913781
evaluation_0/Rewards Max                      6.66474
evaluation_0/Rewards Min                     -0.436502
evaluation_0/Returns Mean                  3790.38
evaluation_0/Returns Std                    569.779
evaluation_0/Returns Max                   4230.9
evaluation_0/Returns Min                   2635.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3790.38
time/epoch (s)                                0
time/total (s)                             4511.48
Epoch                                       291
---------------------------------------  ----------------
2022-11-16 17:30:11.221916 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 292 finished
---------------------------------------  ----------------
epoch                                       292
total_step                               297000
replay_pool/size                         297000
trainer/alpha                                 0.0623157
trainer/alpha_loss                           -0.387643
trainer/entropy                              -5.86033
trainer/qf_loss                              20.284
trainer/policy_loss                        -280.703
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         281.068
trainer/entropy_penalty                      -0.365191
trainer/entropy_percentage                   -0.0012993
trainer/Q1Pred Mean                         279.26
trainer/Q1Pred Std                           67.0083
trainer/Q1Pred Max                          352.732
trainer/Q1Pred Min                           -6.69295
trainer/Q2Pred Mean                         279.93
trainer/Q2Pred Std                           67.6575
trainer/Q2Pred Max                          352.349
trainer/Q2Pred Min                           -8.03674
trainer/QTargetWithReg Mean                 279.622
trainer/QTargetWithReg Std                   66.5082
trainer/QTargetWithReg Max                  351.417
trainer/QTargetWithReg Min                   -0.12187
trainer/PolicyLossWithoutReg Mean           281.068
trainer/PolicyLossWithoutReg Std             64.7565
trainer/PolicyLossWithoutReg Max            351.106
trainer/PolicyLossWithoutReg Min             -9.22081
exploration/num steps total              297000
exploration/num paths total                1034
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.12103
exploration/Rewards Std                       0.971175
exploration/Rewards Max                       6.63967
exploration/Rewards Min                      -0.378048
exploration/Returns Mean                   4121.03
exploration/Returns Std                       0
exploration/Returns Max                    4121.03
exploration/Returns Min                    4121.03
exploration/Num Paths                         1
exploration/Average Returns                4121.03
evaluation_0/num steps total                  2.28059e+06
evaluation_0/num paths total               5632
evaluation_0/path length Mean               938.25
evaluation_0/path length Std                163.375
evaluation_0/path length Max               1000
evaluation_0/path length Min                506
evaluation_0/Rewards Mean                     4.05079
evaluation_0/Rewards Std                      0.930961
evaluation_0/Rewards Max                      6.90255
evaluation_0/Rewards Min                     -0.51821
evaluation_0/Returns Mean                  3800.65
evaluation_0/Returns Std                    733.195
evaluation_0/Returns Max                   4338.68
evaluation_0/Returns Min                   1904.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3800.65
time/epoch (s)                                0
time/total (s)                             4528.31
Epoch                                       292
---------------------------------------  ----------------
2022-11-16 17:30:28.272573 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 293 finished
---------------------------------------  ----------------
epoch                                       293
total_step                               298000
replay_pool/size                         298000
trainer/alpha                                 0.0627713
trainer/alpha_loss                           -1.3359
trainer/entropy                              -5.51742
trainer/qf_loss                              22.5896
trainer/policy_loss                        -280.294
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         280.641
trainer/entropy_penalty                      -0.346336
trainer/entropy_percentage                   -0.00123409
trainer/Q1Pred Mean                         279.127
trainer/Q1Pred Std                           68.9567
trainer/Q1Pred Max                          364.204
trainer/Q1Pred Min                            5.17035
trainer/Q2Pred Mean                         279.84
trainer/Q2Pred Std                           68.3669
trainer/Q2Pred Max                          363.656
trainer/Q2Pred Min                           12.1622
trainer/QTargetWithReg Mean                 279.608
trainer/QTargetWithReg Std                   69.4245
trainer/QTargetWithReg Max                  363.656
trainer/QTargetWithReg Min                    7.00143
trainer/PolicyLossWithoutReg Mean           280.641
trainer/PolicyLossWithoutReg Std             67.0334
trainer/PolicyLossWithoutReg Max            362.757
trainer/PolicyLossWithoutReg Min             10.117
exploration/num steps total              298000
exploration/num paths total                1035
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.08627
exploration/Rewards Std                       0.935457
exploration/Rewards Max                       6.61744
exploration/Rewards Min                      -0.486578
exploration/Returns Mean                   4086.27
exploration/Returns Std                       0
exploration/Returns Max                    4086.27
exploration/Returns Min                    4086.27
exploration/Num Paths                         1
exploration/Average Returns                4086.27
evaluation_0/num steps total                  2.28766e+06
evaluation_0/num paths total               5640
evaluation_0/path length Mean               884.125
evaluation_0/path length Std                219.65
evaluation_0/path length Max               1000
evaluation_0/path length Min                320
evaluation_0/Rewards Mean                     4.43711
evaluation_0/Rewards Std                      1.07271
evaluation_0/Rewards Max                     10.2353
evaluation_0/Rewards Min                     -0.608777
evaluation_0/Returns Mean                  3922.96
evaluation_0/Returns Std                   1060.76
evaluation_0/Returns Max                   4719.51
evaluation_0/Returns Min                   1182.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3922.96
time/epoch (s)                                0
time/total (s)                             4545.36
Epoch                                       293
---------------------------------------  ----------------
2022-11-16 17:30:45.027576 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 294 finished
---------------------------------------  ----------------
epoch                                       294
total_step                               299000
replay_pool/size                         299000
trainer/alpha                                 0.0631557
trainer/alpha_loss                            0.541464
trainer/entropy                              -6.19602
trainer/qf_loss                              20.5354
trainer/policy_loss                        -283.828
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         284.219
trainer/entropy_penalty                      -0.391314
trainer/entropy_percentage                   -0.0013768
trainer/Q1Pred Mean                         283.791
trainer/Q1Pred Std                           65.3984
trainer/Q1Pred Max                          363.717
trainer/Q1Pred Min                          -21.9467
trainer/Q2Pred Mean                         284.292
trainer/Q2Pred Std                           65.2029
trainer/Q2Pred Max                          364.31
trainer/Q2Pred Min                          -25.1831
trainer/QTargetWithReg Mean                 283.982
trainer/QTargetWithReg Std                   65.6904
trainer/QTargetWithReg Max                  360.752
trainer/QTargetWithReg Min                   -9.01787
trainer/PolicyLossWithoutReg Mean           284.219
trainer/PolicyLossWithoutReg Std             64.4835
trainer/PolicyLossWithoutReg Max            361.429
trainer/PolicyLossWithoutReg Min            -21.6662
exploration/num steps total              299000
exploration/num paths total                1036
exploration/path length this epoch Mean     396
exploration/path length this epoch Std        0
exploration/path length this epoch Max      396
exploration/path length this epoch Min      396
exploration/Rewards Mean                      3.99728
exploration/Rewards Std                       1.42184
exploration/Rewards Max                       7.87138
exploration/Rewards Min                      -0.822688
exploration/Returns Mean                   1582.92
exploration/Returns Std                       0
exploration/Returns Max                    1582.92
exploration/Returns Min                    1582.92
exploration/Num Paths                         1
exploration/Average Returns                1582.92
evaluation_0/num steps total                  2.29491e+06
evaluation_0/num paths total               5648
evaluation_0/path length Mean               905.625
evaluation_0/path length Std                165.478
evaluation_0/path length Max               1000
evaluation_0/path length Min                571
evaluation_0/Rewards Mean                     4.56732
evaluation_0/Rewards Std                      1.14283
evaluation_0/Rewards Max                      9.01801
evaluation_0/Rewards Min                     -0.599638
evaluation_0/Returns Mean                  4136.28
evaluation_0/Returns Std                    877.408
evaluation_0/Returns Max                   4786.16
evaluation_0/Returns Min                   2285.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4136.28
time/epoch (s)                                0
time/total (s)                             4562.11
Epoch                                       294
---------------------------------------  ----------------
2022-11-16 17:31:01.715462 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 295 finished
---------------------------------------  ----------------
epoch                                       295
total_step                               300000
replay_pool/size                         300000
trainer/alpha                                 0.0645886
trainer/alpha_loss                            0.14188
trainer/entropy                              -6.05179
trainer/qf_loss                              20.4786
trainer/policy_loss                        -281.683
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         282.074
trainer/entropy_penalty                      -0.390876
trainer/entropy_percentage                   -0.00138572
trainer/Q1Pred Mean                         281.042
trainer/Q1Pred Std                           70.1994
trainer/Q1Pred Max                          372.764
trainer/Q1Pred Min                          -23.727
trainer/Q2Pred Mean                         281.193
trainer/Q2Pred Std                           70.7052
trainer/Q2Pred Max                          370.485
trainer/Q2Pred Min                          -27.474
trainer/QTargetWithReg Mean                 281.64
trainer/QTargetWithReg Std                   69.483
trainer/QTargetWithReg Max                  370.91
trainer/QTargetWithReg Min                  -21.2916
trainer/PolicyLossWithoutReg Mean           282.074
trainer/PolicyLossWithoutReg Std             68.2616
trainer/PolicyLossWithoutReg Max            370.045
trainer/PolicyLossWithoutReg Min            -22.5185
exploration/num steps total              300000
exploration/num paths total                1037
exploration/path length this epoch Mean     416
exploration/path length this epoch Std        0
exploration/path length this epoch Max      416
exploration/path length this epoch Min      416
exploration/Rewards Mean                      3.75006
exploration/Rewards Std                       1.05929
exploration/Rewards Max                       5.74112
exploration/Rewards Min                      -0.42548
exploration/Returns Mean                   1560.03
exploration/Returns Std                       0
exploration/Returns Max                    1560.03
exploration/Returns Min                    1560.03
exploration/Num Paths                         1
exploration/Average Returns                1560.03
evaluation_0/num steps total                  2.30229e+06
evaluation_0/num paths total               5656
evaluation_0/path length Mean               922.25
evaluation_0/path length Std                129.743
evaluation_0/path length Max               1000
evaluation_0/path length Min                668
evaluation_0/Rewards Mean                     4.47881
evaluation_0/Rewards Std                      1.11217
evaluation_0/Rewards Max                     11.0941
evaluation_0/Rewards Min                     -0.736737
evaluation_0/Returns Mean                  4130.58
evaluation_0/Returns Std                    636.613
evaluation_0/Returns Max                   4645.58
evaluation_0/Returns Min                   2826.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4130.58
time/epoch (s)                                0
time/total (s)                             4578.8
Epoch                                       295
---------------------------------------  ----------------
2022-11-16 17:31:18.518379 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 296 finished
---------------------------------------  ---------------
epoch                                       296
total_step                               301000
replay_pool/size                         301000
trainer/alpha                                 0.063576
trainer/alpha_loss                            0.942738
trainer/entropy                              -6.34209
trainer/qf_loss                              16.1924
trainer/policy_loss                        -283.089
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.492
trainer/entropy_penalty                      -0.403205
trainer/entropy_percentage                   -0.00142228
trainer/Q1Pred Mean                         282.124
trainer/Q1Pred Std                           59.1534
trainer/Q1Pred Max                          365.534
trainer/Q1Pred Min                           10.965
trainer/Q2Pred Mean                         282.519
trainer/Q2Pred Std                           59.5729
trainer/Q2Pred Max                          362.639
trainer/Q2Pred Min                           10.4214
trainer/QTargetWithReg Mean                 282.431
trainer/QTargetWithReg Std                   59.3911
trainer/QTargetWithReg Max                  365.5
trainer/QTargetWithReg Min                   13.9222
trainer/PolicyLossWithoutReg Mean           283.492
trainer/PolicyLossWithoutReg Std             58.2116
trainer/PolicyLossWithoutReg Max            363.346
trainer/PolicyLossWithoutReg Min             12.8651
exploration/num steps total              301000
exploration/num paths total                1038
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.23783
exploration/Rewards Std                       1.33426
exploration/Rewards Max                       6.84873
exploration/Rewards Min                      -0.599061
exploration/Returns Mean                   4237.83
exploration/Returns Std                       0
exploration/Returns Max                    4237.83
exploration/Returns Min                    4237.83
exploration/Num Paths                         1
exploration/Average Returns                4237.83
evaluation_0/num steps total                  2.3095e+06
evaluation_0/num paths total               5664
evaluation_0/path length Mean               900.875
evaluation_0/path length Std                171.995
evaluation_0/path length Max               1000
evaluation_0/path length Min                583
evaluation_0/Rewards Mean                     4.10001
evaluation_0/Rewards Std                      1.18025
evaluation_0/Rewards Max                      8.22236
evaluation_0/Rewards Min                     -0.675928
evaluation_0/Returns Mean                  3693.6
evaluation_0/Returns Std                    803.336
evaluation_0/Returns Max                   4375.45
evaluation_0/Returns Min                   2207.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3693.6
time/epoch (s)                                0
time/total (s)                             4595.6
Epoch                                       296
---------------------------------------  ---------------
2022-11-16 17:31:33.870039 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 297 finished
---------------------------------------  ----------------
epoch                                       297
total_step                               302000
replay_pool/size                         302000
trainer/alpha                                 0.0638499
trainer/alpha_loss                            0.37612
trainer/entropy                              -6.1367
trainer/qf_loss                              18.9711
trainer/policy_loss                        -286.773
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         287.165
trainer/entropy_penalty                      -0.391827
trainer/entropy_percentage                   -0.00136447
trainer/Q1Pred Mean                         286.109
trainer/Q1Pred Std                           63.5626
trainer/Q1Pred Max                          360.303
trainer/Q1Pred Min                           -2.20577
trainer/Q2Pred Mean                         285.928
trainer/Q2Pred Std                           63.4873
trainer/Q2Pred Max                          362.528
trainer/Q2Pred Min                           -9.05809
trainer/QTargetWithReg Mean                 286.053
trainer/QTargetWithReg Std                   63.6425
trainer/QTargetWithReg Max                  360.077
trainer/QTargetWithReg Min                    7.83297
trainer/PolicyLossWithoutReg Mean           287.165
trainer/PolicyLossWithoutReg Std             62.5542
trainer/PolicyLossWithoutReg Max            360.901
trainer/PolicyLossWithoutReg Min              7.40906
exploration/num steps total              302000
exploration/num paths total                1039
exploration/path length this epoch Mean     420
exploration/path length this epoch Std        0
exploration/path length this epoch Max      420
exploration/path length this epoch Min      420
exploration/Rewards Mean                      3.13959
exploration/Rewards Std                       0.937295
exploration/Rewards Max                       5.11001
exploration/Rewards Min                      -0.634598
exploration/Returns Mean                   1318.63
exploration/Returns Std                       0
exploration/Returns Max                    1318.63
exploration/Returns Min                    1318.63
exploration/Num Paths                         1
exploration/Average Returns                1318.63
evaluation_0/num steps total                  2.31718e+06
evaluation_0/num paths total               5673
evaluation_0/path length Mean               853.556
evaluation_0/path length Std                214.206
evaluation_0/path length Max               1000
evaluation_0/path length Min                377
evaluation_0/Rewards Mean                     4.46658
evaluation_0/Rewards Std                      1.06757
evaluation_0/Rewards Max                      7.82713
evaluation_0/Rewards Min                     -0.486396
evaluation_0/Returns Mean                  3812.47
evaluation_0/Returns Std                   1093.27
evaluation_0/Returns Max                   4673.98
evaluation_0/Returns Min                   1437.08
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3812.47
time/epoch (s)                                0
time/total (s)                             4610.95
Epoch                                       297
---------------------------------------  ----------------
2022-11-16 17:31:48.609738 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 298 finished
---------------------------------------  ----------------
epoch                                       298
total_step                               303000
replay_pool/size                         303000
trainer/alpha                                 0.0641366
trainer/alpha_loss                           -0.0777249
trainer/entropy                              -5.9717
trainer/qf_loss                              25.9227
trainer/policy_loss                        -285.252
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         285.635
trainer/entropy_penalty                      -0.383005
trainer/entropy_percentage                   -0.00134089
trainer/Q1Pred Mean                         284.331
trainer/Q1Pred Std                           58.6162
trainer/Q1Pred Max                          372.878
trainer/Q1Pred Min                           -0.00506827
trainer/Q2Pred Mean                         283.487
trainer/Q2Pred Std                           58.8511
trainer/Q2Pred Max                          370.817
trainer/Q2Pred Min                            2.23433
trainer/QTargetWithReg Mean                 284.637
trainer/QTargetWithReg Std                   58.8167
trainer/QTargetWithReg Max                  370.822
trainer/QTargetWithReg Min                   -0.977584
trainer/PolicyLossWithoutReg Mean           285.635
trainer/PolicyLossWithoutReg Std             57.6863
trainer/PolicyLossWithoutReg Max            376.92
trainer/PolicyLossWithoutReg Min              5.23392
exploration/num steps total              303000
exploration/num paths total                1041
exploration/path length this epoch Mean     294.5
exploration/path length this epoch Std      196.5
exploration/path length this epoch Max      491
exploration/path length this epoch Min       98
exploration/Rewards Mean                      3.61822
exploration/Rewards Std                       1.36474
exploration/Rewards Max                       6.39397
exploration/Rewards Min                      -0.621438
exploration/Returns Mean                   1065.56
exploration/Returns Std                     834.136
exploration/Returns Max                    1899.7
exploration/Returns Min                     231.428
exploration/Num Paths                         2
exploration/Average Returns                1065.56
evaluation_0/num steps total                  2.32518e+06
evaluation_0/num paths total               5681
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.46405
evaluation_0/Rewards Std                      0.901202
evaluation_0/Rewards Max                      6.86188
evaluation_0/Rewards Min                     -0.534665
evaluation_0/Returns Mean                  4464.05
evaluation_0/Returns Std                     79.9165
evaluation_0/Returns Max                   4556.73
evaluation_0/Returns Min                   4368.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4464.05
time/epoch (s)                                0
time/total (s)                             4625.69
Epoch                                       298
---------------------------------------  ----------------
2022-11-16 17:32:02.792809 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 299 finished
---------------------------------------  ----------------
epoch                                       299
total_step                               304000
replay_pool/size                         304000
trainer/alpha                                 0.063637
trainer/alpha_loss                           -0.170304
trainer/entropy                              -5.93818
trainer/qf_loss                              16.2253
trainer/policy_loss                        -286.453
trainer/adversary_policy_loss                13.679
trainer/policy_loss_without_entropy         286.831
trainer/entropy_penalty                      -0.377888
trainer/entropy_percentage                   -0.00131746
trainer/Q1Pred Mean                         285.206
trainer/Q1Pred Std                           62.3222
trainer/Q1Pred Max                          371.839
trainer/Q1Pred Min                           -0.757791
trainer/Q2Pred Mean                         285.892
trainer/Q2Pred Std                           62.6024
trainer/Q2Pred Max                          370.968
trainer/Q2Pred Min                            1.0316
trainer/QTargetWithReg Mean                 285.955
trainer/QTargetWithReg Std                   62.1395
trainer/QTargetWithReg Max                  372.136
trainer/QTargetWithReg Min                    2.2463
trainer/PolicyLossWithoutReg Mean           286.831
trainer/PolicyLossWithoutReg Std             60.8105
trainer/PolicyLossWithoutReg Max            370.998
trainer/PolicyLossWithoutReg Min              7.60676
exploration/num steps total              304000
exploration/num paths total                1042
exploration/path length this epoch Mean     464
exploration/path length this epoch Std        0
exploration/path length this epoch Max      464
exploration/path length this epoch Min      464
exploration/Rewards Mean                      3.97653
exploration/Rewards Std                       1.05163
exploration/Rewards Max                       5.67344
exploration/Rewards Min                      -0.568019
exploration/Returns Mean                   1845.11
exploration/Returns Std                       0
exploration/Returns Max                    1845.11
exploration/Returns Min                    1845.11
exploration/Num Paths                         1
exploration/Average Returns                1845.11
evaluation_0/num steps total                  2.33318e+06
evaluation_0/num paths total               5689
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.22375
evaluation_0/Rewards Std                      0.917874
evaluation_0/Rewards Max                      6.69388
evaluation_0/Rewards Min                     -0.604689
evaluation_0/Returns Mean                  4223.75
evaluation_0/Returns Std                     98.7926
evaluation_0/Returns Max                   4389.14
evaluation_0/Returns Min                   4070.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4223.75
time/epoch (s)                                0
time/total (s)                             4639.88
Epoch                                       299
---------------------------------------  ----------------
2022-11-16 17:32:19.077754 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 300 finished
---------------------------------------  ----------------
epoch                                       300
total_step                               305000
replay_pool/size                         305000
trainer/alpha                                 0.0635812
trainer/alpha_loss                            1.00482
trainer/entropy                              -6.36465
trainer/qf_loss                              19.2069
trainer/policy_loss                        -280.868
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         281.273
trainer/entropy_penalty                      -0.404672
trainer/entropy_percentage                   -0.00143871
trainer/Q1Pred Mean                         279.327
trainer/Q1Pred Std                           67.4027
trainer/Q1Pred Max                          366.053
trainer/Q1Pred Min                          -20.8518
trainer/Q2Pred Mean                         279.233
trainer/Q2Pred Std                           67.8565
trainer/Q2Pred Max                          364.455
trainer/Q2Pred Min                          -16.2624
trainer/QTargetWithReg Mean                 279.567
trainer/QTargetWithReg Std                   67.7783
trainer/QTargetWithReg Max                  366.7
trainer/QTargetWithReg Min                   -9.98137
trainer/PolicyLossWithoutReg Mean           281.273
trainer/PolicyLossWithoutReg Std             66.6921
trainer/PolicyLossWithoutReg Max            364.285
trainer/PolicyLossWithoutReg Min            -11.9485
exploration/num steps total              305000
exploration/num paths total                1043
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.26152
exploration/Rewards Std                       1.07165
exploration/Rewards Max                       6.62406
exploration/Rewards Min                      -0.688618
exploration/Returns Mean                   4261.52
exploration/Returns Std                       0
exploration/Returns Max                    4261.52
exploration/Returns Min                    4261.52
exploration/Num Paths                         1
exploration/Average Returns                4261.52
evaluation_0/num steps total                  2.34106e+06
evaluation_0/num paths total               5697
evaluation_0/path length Mean               985.25
evaluation_0/path length Std                 30.6869
evaluation_0/path length Max               1000
evaluation_0/path length Min                907
evaluation_0/Rewards Mean                     4.51721
evaluation_0/Rewards Std                      1.07113
evaluation_0/Rewards Max                      7.78581
evaluation_0/Rewards Min                     -0.644336
evaluation_0/Returns Mean                  4450.58
evaluation_0/Returns Std                    245.654
evaluation_0/Returns Max                   4723.66
evaluation_0/Returns Min                   3893.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4450.58
time/epoch (s)                                0
time/total (s)                             4656.16
Epoch                                       300
---------------------------------------  ----------------
2022-11-16 17:32:33.832386 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 301 finished
---------------------------------------  ----------------
epoch                                       301
total_step                               306000
replay_pool/size                         306000
trainer/alpha                                 0.0639209
trainer/alpha_loss                            1.19025
trainer/entropy                              -6.43281
trainer/qf_loss                              19.0637
trainer/policy_loss                        -277.53
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         277.941
trainer/entropy_penalty                      -0.411191
trainer/entropy_percentage                   -0.00147942
trainer/Q1Pred Mean                         275.714
trainer/Q1Pred Std                           74.8684
trainer/Q1Pred Max                          366.887
trainer/Q1Pred Min                            6.88322
trainer/Q2Pred Mean                         276.19
trainer/Q2Pred Std                           75.0353
trainer/Q2Pred Max                          368.33
trainer/Q2Pred Min                            8.87539
trainer/QTargetWithReg Mean                 275.219
trainer/QTargetWithReg Std                   75.4036
trainer/QTargetWithReg Max                  366.379
trainer/QTargetWithReg Min                    0.412732
trainer/PolicyLossWithoutReg Mean           277.941
trainer/PolicyLossWithoutReg Std             72.5293
trainer/PolicyLossWithoutReg Max            367.852
trainer/PolicyLossWithoutReg Min              9.89787
exploration/num steps total              306000
exploration/num paths total                1044
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.40431
exploration/Rewards Std                       1.08545
exploration/Rewards Max                       6.99222
exploration/Rewards Min                      -0.701385
exploration/Returns Mean                   4404.31
exploration/Returns Std                       0
exploration/Returns Max                    4404.31
exploration/Returns Min                    4404.31
exploration/Num Paths                         1
exploration/Average Returns                4404.31
evaluation_0/num steps total                  2.34906e+06
evaluation_0/num paths total               5705
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.23268
evaluation_0/Rewards Std                      1.00689
evaluation_0/Rewards Max                      6.28251
evaluation_0/Rewards Min                     -0.644967
evaluation_0/Returns Mean                  4232.68
evaluation_0/Returns Std                    101.232
evaluation_0/Returns Max                   4368.71
evaluation_0/Returns Min                   4114.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4232.68
time/epoch (s)                                0
time/total (s)                             4670.92
Epoch                                       301
---------------------------------------  ----------------
2022-11-16 17:32:50.259150 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 302 finished
---------------------------------------  ----------------
epoch                                       302
total_step                               307000
replay_pool/size                         307000
trainer/alpha                                 0.0641498
trainer/alpha_loss                           -0.214101
trainer/entropy                              -5.92204
trainer/qf_loss                              22.4134
trainer/policy_loss                        -281.784
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         282.164
trainer/entropy_penalty                      -0.379898
trainer/entropy_percentage                   -0.00134638
trainer/Q1Pred Mean                         279.003
trainer/Q1Pred Std                           75.6524
trainer/Q1Pred Max                          376.537
trainer/Q1Pred Min                           -7.38941
trainer/Q2Pred Mean                         279.224
trainer/Q2Pred Std                           76.0766
trainer/Q2Pred Max                          376.163
trainer/Q2Pred Min                          -15.0904
trainer/QTargetWithReg Mean                 278.943
trainer/QTargetWithReg Std                   75.691
trainer/QTargetWithReg Max                  376.485
trainer/QTargetWithReg Min                   -6.27846
trainer/PolicyLossWithoutReg Mean           282.164
trainer/PolicyLossWithoutReg Std             73.1425
trainer/PolicyLossWithoutReg Max            377.445
trainer/PolicyLossWithoutReg Min              4.49
exploration/num steps total              307000
exploration/num paths total                1045
exploration/path length this epoch Mean     810
exploration/path length this epoch Std        0
exploration/path length this epoch Max      810
exploration/path length this epoch Min      810
exploration/Rewards Mean                      4.53939
exploration/Rewards Std                       1.15817
exploration/Rewards Max                       6.53812
exploration/Rewards Min                      -0.71213
exploration/Returns Mean                   3676.91
exploration/Returns Std                       0
exploration/Returns Max                    3676.91
exploration/Returns Min                    3676.91
exploration/Num Paths                         1
exploration/Average Returns                3676.91
evaluation_0/num steps total                  2.35643e+06
evaluation_0/num paths total               5713
evaluation_0/path length Mean               921.375
evaluation_0/path length Std                 83.8256
evaluation_0/path length Max               1000
evaluation_0/path length Min                806
evaluation_0/Rewards Mean                     4.76106
evaluation_0/Rewards Std                      1.17864
evaluation_0/Rewards Max                      9.03582
evaluation_0/Rewards Min                     -0.567302
evaluation_0/Returns Mean                  4386.72
evaluation_0/Returns Std                    505.201
evaluation_0/Returns Max                   4918.08
evaluation_0/Returns Min                   3553.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4386.72
time/epoch (s)                                0
time/total (s)                             4687.34
Epoch                                       302
---------------------------------------  ----------------
2022-11-16 17:33:05.531662 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 303 finished
---------------------------------------  ----------------
epoch                                       303
total_step                               308000
replay_pool/size                         308000
trainer/alpha                                 0.0647634
trainer/alpha_loss                            0.948599
trainer/entropy                              -6.34658
trainer/qf_loss                              14.108
trainer/policy_loss                        -285.256
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         285.667
trainer/entropy_penalty                      -0.411026
trainer/entropy_percentage                   -0.00143883
trainer/Q1Pred Mean                         284.6
trainer/Q1Pred Std                           64.0614
trainer/Q1Pred Max                          367.839
trainer/Q1Pred Min                           -2.5699
trainer/Q2Pred Mean                         284.748
trainer/Q2Pred Std                           64.2006
trainer/Q2Pred Max                          363.785
trainer/Q2Pred Min                          -15.5682
trainer/QTargetWithReg Mean                 284.399
trainer/QTargetWithReg Std                   64.3047
trainer/QTargetWithReg Max                  363.636
trainer/QTargetWithReg Min                    0.384265
trainer/PolicyLossWithoutReg Mean           285.667
trainer/PolicyLossWithoutReg Std             63.1444
trainer/PolicyLossWithoutReg Max            363.147
trainer/PolicyLossWithoutReg Min             13.5447
exploration/num steps total              308000
exploration/num paths total                1046
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.22763
exploration/Rewards Std                       1.20202
exploration/Rewards Max                       6.66139
exploration/Rewards Min                      -0.67714
exploration/Returns Mean                   4227.63
exploration/Returns Std                       0
exploration/Returns Max                    4227.63
exploration/Returns Min                    4227.63
exploration/Num Paths                         1
exploration/Average Returns                4227.63
evaluation_0/num steps total                  2.36443e+06
evaluation_0/num paths total               5721
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64635
evaluation_0/Rewards Std                      1.15733
evaluation_0/Rewards Max                      7.48015
evaluation_0/Rewards Min                     -0.607095
evaluation_0/Returns Mean                  4646.35
evaluation_0/Returns Std                    100.607
evaluation_0/Returns Max                   4809.24
evaluation_0/Returns Min                   4468.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4646.35
time/epoch (s)                                0
time/total (s)                             4702.61
Epoch                                       303
---------------------------------------  ----------------
2022-11-16 17:33:22.384075 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 304 finished
---------------------------------------  ----------------
epoch                                       304
total_step                               309000
replay_pool/size                         309000
trainer/alpha                                 0.0662037
trainer/alpha_loss                            0.652662
trainer/entropy                              -6.24039
trainer/qf_loss                              22.4066
trainer/policy_loss                        -281.172
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         281.585
trainer/entropy_penalty                      -0.413137
trainer/entropy_percentage                   -0.00146718
trainer/Q1Pred Mean                         280.531
trainer/Q1Pred Std                           69.6662
trainer/Q1Pred Max                          370.775
trainer/Q1Pred Min                           -3.11201
trainer/Q2Pred Mean                         280.54
trainer/Q2Pred Std                           69.1733
trainer/Q2Pred Max                          373.843
trainer/Q2Pred Min                           -8.03374
trainer/QTargetWithReg Mean                 280.337
trainer/QTargetWithReg Std                   70.8176
trainer/QTargetWithReg Max                  369.457
trainer/QTargetWithReg Min                   -2.78607
trainer/PolicyLossWithoutReg Mean           281.585
trainer/PolicyLossWithoutReg Std             68.3166
trainer/PolicyLossWithoutReg Max            371.102
trainer/PolicyLossWithoutReg Min            -10.7648
exploration/num steps total              309000
exploration/num paths total                1047
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.24419
exploration/Rewards Std                       1.02923
exploration/Rewards Max                       6.99218
exploration/Rewards Min                      -0.575754
exploration/Returns Mean                   4244.19
exploration/Returns Std                       0
exploration/Returns Max                    4244.19
exploration/Returns Min                    4244.19
exploration/Num Paths                         1
exploration/Average Returns                4244.19
evaluation_0/num steps total                  2.37194e+06
evaluation_0/num paths total               5729
evaluation_0/path length Mean               938.375
evaluation_0/path length Std                 66.7925
evaluation_0/path length Max               1000
evaluation_0/path length Min                835
evaluation_0/Rewards Mean                     4.7537
evaluation_0/Rewards Std                      1.23091
evaluation_0/Rewards Max                      9.20247
evaluation_0/Rewards Min                     -0.571115
evaluation_0/Returns Mean                  4460.75
evaluation_0/Returns Std                    342.274
evaluation_0/Returns Max                   4883.6
evaluation_0/Returns Min                   3771.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4460.75
time/epoch (s)                                0
time/total (s)                             4719.47
Epoch                                       304
---------------------------------------  ----------------
2022-11-16 17:33:38.898329 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 305 finished
---------------------------------------  ---------------
epoch                                       305
total_step                               310000
replay_pool/size                         310000
trainer/alpha                                 0.0641488
trainer/alpha_loss                            0.255649
trainer/entropy                              -6.09307
trainer/qf_loss                              31.0577
trainer/policy_loss                        -285.795
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         286.186
trainer/entropy_penalty                      -0.390863
trainer/entropy_percentage                   -0.00136577
trainer/Q1Pred Mean                         285.951
trainer/Q1Pred Std                           65.5715
trainer/Q1Pred Max                          377.9
trainer/Q1Pred Min                          -84.465
trainer/Q2Pred Mean                         285.037
trainer/Q2Pred Std                           66.0033
trainer/Q2Pred Max                          376.523
trainer/Q2Pred Min                          -66.7486
trainer/QTargetWithReg Mean                 284.502
trainer/QTargetWithReg Std                   64.2321
trainer/QTargetWithReg Max                  377.357
trainer/QTargetWithReg Min                  -31.7151
trainer/PolicyLossWithoutReg Mean           286.186
trainer/PolicyLossWithoutReg Std             64.6165
trainer/PolicyLossWithoutReg Max            376.602
trainer/PolicyLossWithoutReg Min            -64.2338
exploration/num steps total              310000
exploration/num paths total                1048
exploration/path length this epoch Mean     596
exploration/path length this epoch Std        0
exploration/path length this epoch Max      596
exploration/path length this epoch Min      596
exploration/Rewards Mean                      4.45159
exploration/Rewards Std                       1.40094
exploration/Rewards Max                      10.1451
exploration/Rewards Min                      -0.633097
exploration/Returns Mean                   2653.15
exploration/Returns Std                       0
exploration/Returns Max                    2653.15
exploration/Returns Min                    2653.15
exploration/Num Paths                         1
exploration/Average Returns                2653.15
evaluation_0/num steps total                  2.3796e+06
evaluation_0/num paths total               5737
evaluation_0/path length Mean               957.25
evaluation_0/path length Std                113.106
evaluation_0/path length Max               1000
evaluation_0/path length Min                658
evaluation_0/Rewards Mean                     4.4645
evaluation_0/Rewards Std                      1.07996
evaluation_0/Rewards Max                      9.3387
evaluation_0/Rewards Min                     -0.698747
evaluation_0/Returns Mean                  4273.64
evaluation_0/Returns Std                    555.577
evaluation_0/Returns Max                   4632.56
evaluation_0/Returns Min                   2828.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4273.64
time/epoch (s)                                0
time/total (s)                             4735.98
Epoch                                       305
---------------------------------------  ---------------
2022-11-16 17:33:55.932141 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 306 finished
---------------------------------------  ---------------
epoch                                       306
total_step                               311000
replay_pool/size                         311000
trainer/alpha                                 0.0641292
trainer/alpha_loss                            0.528186
trainer/entropy                              -6.19228
trainer/qf_loss                              18.6934
trainer/policy_loss                        -284.276
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         284.673
trainer/entropy_penalty                      -0.397106
trainer/entropy_percentage                   -0.00139496
trainer/Q1Pred Mean                         283.08
trainer/Q1Pred Std                           72.0274
trainer/Q1Pred Max                          373.776
trainer/Q1Pred Min                           18.8931
trainer/Q2Pred Mean                         282.638
trainer/Q2Pred Std                           71.7136
trainer/Q2Pred Max                          371.769
trainer/Q2Pred Min                           19.2726
trainer/QTargetWithReg Mean                 281.967
trainer/QTargetWithReg Std                   72.2247
trainer/QTargetWithReg Max                  370.882
trainer/QTargetWithReg Min                   13.2154
trainer/PolicyLossWithoutReg Mean           284.673
trainer/PolicyLossWithoutReg Std             70.4312
trainer/PolicyLossWithoutReg Max            373.611
trainer/PolicyLossWithoutReg Min             18.3446
exploration/num steps total              311000
exploration/num paths total                1049
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.3053
exploration/Rewards Std                       1.01612
exploration/Rewards Max                       6.86778
exploration/Rewards Min                      -0.718326
exploration/Returns Mean                   4305.3
exploration/Returns Std                       0
exploration/Returns Max                    4305.3
exploration/Returns Min                    4305.3
exploration/Num Paths                         1
exploration/Average Returns                4305.3
evaluation_0/num steps total                  2.3871e+06
evaluation_0/num paths total               5746
evaluation_0/path length Mean               834.111
evaluation_0/path length Std                241.024
evaluation_0/path length Max               1000
evaluation_0/path length Min                368
evaluation_0/Rewards Mean                     4.64302
evaluation_0/Rewards Std                      1.19705
evaluation_0/Rewards Max                      9.60632
evaluation_0/Rewards Min                     -0.721085
evaluation_0/Returns Mean                  3872.79
evaluation_0/Returns Std                   1253.71
evaluation_0/Returns Max                   4840.5
evaluation_0/Returns Min                   1559.5
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3872.79
time/epoch (s)                                0
time/total (s)                             4753.01
Epoch                                       306
---------------------------------------  ---------------
2022-11-16 17:34:10.970413 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 307 finished
---------------------------------------  ---------------
epoch                                       307
total_step                               312000
replay_pool/size                         312000
trainer/alpha                                 0.0641318
trainer/alpha_loss                            2.45786
trainer/entropy                              -6.89474
trainer/qf_loss                              24.5225
trainer/policy_loss                        -277.851
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         278.294
trainer/entropy_penalty                      -0.442172
trainer/entropy_percentage                   -0.00158887
trainer/Q1Pred Mean                         276.742
trainer/Q1Pred Std                           67.2379
trainer/Q1Pred Max                          365.812
trainer/Q1Pred Min                           -2.49111
trainer/Q2Pred Mean                         276.681
trainer/Q2Pred Std                           67.8358
trainer/Q2Pred Max                          363.432
trainer/Q2Pred Min                            2.31151
trainer/QTargetWithReg Mean                 276.292
trainer/QTargetWithReg Std                   68.1089
trainer/QTargetWithReg Max                  366.439
trainer/QTargetWithReg Min                   -0.38093
trainer/PolicyLossWithoutReg Mean           278.294
trainer/PolicyLossWithoutReg Std             64.6356
trainer/PolicyLossWithoutReg Max            363.054
trainer/PolicyLossWithoutReg Min             -1.34489
exploration/num steps total              312000
exploration/num paths total                1050
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.35582
exploration/Rewards Std                       1.00853
exploration/Rewards Max                       6.97813
exploration/Rewards Min                      -0.748251
exploration/Returns Mean                   4355.82
exploration/Returns Std                       0
exploration/Returns Max                    4355.82
exploration/Returns Min                    4355.82
exploration/Num Paths                         1
exploration/Average Returns                4355.82
evaluation_0/num steps total                  2.3951e+06
evaluation_0/num paths total               5754
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.22576
evaluation_0/Rewards Std                      0.963134
evaluation_0/Rewards Max                      7.0529
evaluation_0/Rewards Min                     -0.481684
evaluation_0/Returns Mean                  4225.76
evaluation_0/Returns Std                    177.832
evaluation_0/Returns Max                   4453.77
evaluation_0/Returns Min                   3928.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4225.76
time/epoch (s)                                0
time/total (s)                             4768.05
Epoch                                       307
---------------------------------------  ---------------
2022-11-16 17:34:27.756617 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 308 finished
---------------------------------------  ----------------
epoch                                       308
total_step                               313000
replay_pool/size                         313000
trainer/alpha                                 0.066158
trainer/alpha_loss                            0.0829829
trainer/entropy                              -6.03056
trainer/qf_loss                              18.6515
trainer/policy_loss                        -282.85
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.249
trainer/entropy_penalty                      -0.39897
trainer/entropy_percentage                   -0.00140855
trainer/Q1Pred Mean                         280.852
trainer/Q1Pred Std                           71.5025
trainer/Q1Pred Max                          367.493
trainer/Q1Pred Min                            1.0782
trainer/Q2Pred Mean                         280.657
trainer/Q2Pred Std                           71.6737
trainer/Q2Pred Max                          366.805
trainer/Q2Pred Min                            0.633345
trainer/QTargetWithReg Mean                 281.398
trainer/QTargetWithReg Std                   71.3532
trainer/QTargetWithReg Max                  373.205
trainer/QTargetWithReg Min                    0.027975
trainer/PolicyLossWithoutReg Mean           283.249
trainer/PolicyLossWithoutReg Std             68.4515
trainer/PolicyLossWithoutReg Max            367.381
trainer/PolicyLossWithoutReg Min              3.98932
exploration/num steps total              313000
exploration/num paths total                1051
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27942
exploration/Rewards Std                       1.03384
exploration/Rewards Max                       6.5817
exploration/Rewards Min                      -0.621087
exploration/Returns Mean                   4279.42
exploration/Returns Std                       0
exploration/Returns Max                    4279.42
exploration/Returns Min                    4279.42
exploration/Num Paths                         1
exploration/Average Returns                4279.42
evaluation_0/num steps total                  2.40272e+06
evaluation_0/num paths total               5762
evaluation_0/path length Mean               952.25
evaluation_0/path length Std                126.335
evaluation_0/path length Max               1000
evaluation_0/path length Min                618
evaluation_0/Rewards Mean                     4.47144
evaluation_0/Rewards Std                      1.09435
evaluation_0/Rewards Max                      7.58932
evaluation_0/Rewards Min                     -0.668
evaluation_0/Returns Mean                  4257.93
evaluation_0/Returns Std                    603.866
evaluation_0/Returns Max                   4646.59
evaluation_0/Returns Min                   2699.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4257.93
time/epoch (s)                                0
time/total (s)                             4784.84
Epoch                                       308
---------------------------------------  ----------------
2022-11-16 17:34:43.932017 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 309 finished
---------------------------------------  ----------------
epoch                                       309
total_step                               314000
replay_pool/size                         314000
trainer/alpha                                 0.0648967
trainer/alpha_loss                            1.48778
trainer/entropy                              -6.54399
trainer/qf_loss                              20.3103
trainer/policy_loss                        -282.785
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.209
trainer/entropy_penalty                      -0.424683
trainer/entropy_percentage                   -0.00149954
trainer/Q1Pred Mean                         282.646
trainer/Q1Pred Std                           68.614
trainer/Q1Pred Max                          361.794
trainer/Q1Pred Min                            8.09412
trainer/Q2Pred Mean                         282.598
trainer/Q2Pred Std                           69.1259
trainer/Q2Pred Max                          364.577
trainer/Q2Pred Min                           -0.624077
trainer/QTargetWithReg Mean                 281.938
trainer/QTargetWithReg Std                   69.1638
trainer/QTargetWithReg Max                  362.821
trainer/QTargetWithReg Min                    2.13268
trainer/PolicyLossWithoutReg Mean           283.209
trainer/PolicyLossWithoutReg Std             68.2829
trainer/PolicyLossWithoutReg Max            362.811
trainer/PolicyLossWithoutReg Min              1.51031
exploration/num steps total              314000
exploration/num paths total                1052
exploration/path length this epoch Mean     779
exploration/path length this epoch Std        0
exploration/path length this epoch Max      779
exploration/path length this epoch Min      779
exploration/Rewards Mean                      4.07272
exploration/Rewards Std                       1.12075
exploration/Rewards Max                       9.42138
exploration/Rewards Min                      -0.565363
exploration/Returns Mean                   3172.65
exploration/Returns Std                       0
exploration/Returns Max                    3172.65
exploration/Returns Min                    3172.65
exploration/Num Paths                         1
exploration/Average Returns                3172.65
evaluation_0/num steps total                  2.41039e+06
evaluation_0/num paths total               5770
evaluation_0/path length Mean               959.125
evaluation_0/path length Std                108.145
evaluation_0/path length Max               1000
evaluation_0/path length Min                673
evaluation_0/Rewards Mean                     4.5886
evaluation_0/Rewards Std                      1.07595
evaluation_0/Rewards Max                      7.98422
evaluation_0/Rewards Min                     -0.630957
evaluation_0/Returns Mean                  4401.04
evaluation_0/Returns Std                    571.288
evaluation_0/Returns Max                   4823.22
evaluation_0/Returns Min                   2932.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4401.04
time/epoch (s)                                0
time/total (s)                             4801.01
Epoch                                       309
---------------------------------------  ----------------
2022-11-16 17:35:00.770421 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 310 finished
---------------------------------------  ----------------
epoch                                       310
total_step                               315000
replay_pool/size                         315000
trainer/alpha                                 0.064699
trainer/alpha_loss                           -0.0185423
trainer/entropy                              -5.99323
trainer/qf_loss                              17.2322
trainer/policy_loss                        -285.21
trainer/adversary_policy_loss                13.6018
trainer/policy_loss_without_entropy         285.598
trainer/entropy_penalty                      -0.387756
trainer/entropy_percentage                   -0.0013577
trainer/Q1Pred Mean                         284.306
trainer/Q1Pred Std                           67.2037
trainer/Q1Pred Max                          379.839
trainer/Q1Pred Min                            1.12881
trainer/Q2Pred Mean                         283.871
trainer/Q2Pred Std                           66.5098
trainer/Q2Pred Max                          377.461
trainer/Q2Pred Min                            9.46256
trainer/QTargetWithReg Mean                 284.025
trainer/QTargetWithReg Std                   67.4913
trainer/QTargetWithReg Max                  379.485
trainer/QTargetWithReg Min                    7.15935
trainer/PolicyLossWithoutReg Mean           285.598
trainer/PolicyLossWithoutReg Std             64.0126
trainer/PolicyLossWithoutReg Max            378.881
trainer/PolicyLossWithoutReg Min              9.70218
exploration/num steps total              315000
exploration/num paths total                1053
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.24198
exploration/Rewards Std                       0.928237
exploration/Rewards Max                       6.73375
exploration/Rewards Min                      -0.540043
exploration/Returns Mean                   4241.98
exploration/Returns Std                       0
exploration/Returns Max                    4241.98
exploration/Returns Min                    4241.98
exploration/Num Paths                         1
exploration/Average Returns                4241.98
evaluation_0/num steps total                  2.41804e+06
evaluation_0/num paths total               5778
evaluation_0/path length Mean               955.625
evaluation_0/path length Std                 77.034
evaluation_0/path length Max               1000
evaluation_0/path length Min                779
evaluation_0/Rewards Mean                     4.50754
evaluation_0/Rewards Std                      1.12864
evaluation_0/Rewards Max                      8.77584
evaluation_0/Rewards Min                     -0.591728
evaluation_0/Returns Mean                  4307.51
evaluation_0/Returns Std                    354.796
evaluation_0/Returns Max                   4678.45
evaluation_0/Returns Min                   3542.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4307.51
time/epoch (s)                                0
time/total (s)                             4817.85
Epoch                                       310
---------------------------------------  ----------------
2022-11-16 17:35:17.485295 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 311 finished
---------------------------------------  ----------------
epoch                                       311
total_step                               316000
replay_pool/size                         316000
trainer/alpha                                 0.0662438
trainer/alpha_loss                            1.04837
trainer/entropy                              -6.38624
trainer/qf_loss                              19.8916
trainer/policy_loss                        -281.465
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         281.888
trainer/entropy_penalty                      -0.423049
trainer/entropy_percentage                   -0.00150077
trainer/Q1Pred Mean                         280.611
trainer/Q1Pred Std                           74.0008
trainer/Q1Pred Max                          371.448
trainer/Q1Pred Min                           -2.50505
trainer/Q2Pred Mean                         279.918
trainer/Q2Pred Std                           73.9702
trainer/Q2Pred Max                          371.698
trainer/Q2Pred Min                           -3.1447
trainer/QTargetWithReg Mean                 280.568
trainer/QTargetWithReg Std                   73.8238
trainer/QTargetWithReg Max                  369.781
trainer/QTargetWithReg Min                   -9.76833
trainer/PolicyLossWithoutReg Mean           281.888
trainer/PolicyLossWithoutReg Std             72.3204
trainer/PolicyLossWithoutReg Max            370.074
trainer/PolicyLossWithoutReg Min              5.40747
exploration/num steps total              316000
exploration/num paths total                1054
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5177
exploration/Rewards Std                       1.05733
exploration/Rewards Max                       6.86508
exploration/Rewards Min                      -0.511656
exploration/Returns Mean                   4517.7
exploration/Returns Std                       0
exploration/Returns Max                    4517.7
exploration/Returns Min                    4517.7
exploration/Num Paths                         1
exploration/Average Returns                4517.7
evaluation_0/num steps total                  2.42602e+06
evaluation_0/num paths total               5786
evaluation_0/path length Mean               997.375
evaluation_0/path length Std                  4.5535
evaluation_0/path length Max               1000
evaluation_0/path length Min                989
evaluation_0/Rewards Mean                     4.72183
evaluation_0/Rewards Std                      1.25586
evaluation_0/Rewards Max                      9.04215
evaluation_0/Rewards Min                     -0.704536
evaluation_0/Returns Mean                  4709.43
evaluation_0/Returns Std                    198.404
evaluation_0/Returns Max                   4938.45
evaluation_0/Returns Min                   4272.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4709.43
time/epoch (s)                                0
time/total (s)                             4834.57
Epoch                                       311
---------------------------------------  ----------------
2022-11-16 17:35:34.790839 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 312 finished
---------------------------------------  ----------------
epoch                                       312
total_step                               317000
replay_pool/size                         317000
trainer/alpha                                 0.0650709
trainer/alpha_loss                           -1.02142
trainer/entropy                              -5.62617
trainer/qf_loss                              16.6508
trainer/policy_loss                        -297.953
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.319
trainer/entropy_penalty                      -0.3661
trainer/entropy_percentage                   -0.00122721
trainer/Q1Pred Mean                         297.475
trainer/Q1Pred Std                           50.9312
trainer/Q1Pred Max                          372.376
trainer/Q1Pred Min                           22.9086
trainer/Q2Pred Mean                         297.123
trainer/Q2Pred Std                           50.9205
trainer/Q2Pred Max                          370.29
trainer/Q2Pred Min                           26.6761
trainer/QTargetWithReg Mean                 297.083
trainer/QTargetWithReg Std                   50.7528
trainer/QTargetWithReg Max                  368.517
trainer/QTargetWithReg Min                   37.6397
trainer/PolicyLossWithoutReg Mean           298.319
trainer/PolicyLossWithoutReg Std             49.9037
trainer/PolicyLossWithoutReg Max            368.992
trainer/PolicyLossWithoutReg Min             34.4591
exploration/num steps total              317000
exploration/num paths total                1055
exploration/path length this epoch Mean     568
exploration/path length this epoch Std        0
exploration/path length this epoch Max      568
exploration/path length this epoch Min      568
exploration/Rewards Mean                      3.67802
exploration/Rewards Std                       0.994061
exploration/Rewards Max                       5.74517
exploration/Rewards Min                      -0.882402
exploration/Returns Mean                   2089.11
exploration/Returns Std                       0
exploration/Returns Max                    2089.11
exploration/Returns Min                    2089.11
exploration/Num Paths                         1
exploration/Average Returns                2089.11
evaluation_0/num steps total                  2.43361e+06
evaluation_0/num paths total               5794
evaluation_0/path length Mean               949.625
evaluation_0/path length Std                100.192
evaluation_0/path length Max               1000
evaluation_0/path length Min                700
evaluation_0/Rewards Mean                     4.42232
evaluation_0/Rewards Std                      1.14067
evaluation_0/Rewards Max                      8.51307
evaluation_0/Rewards Min                     -0.63337
evaluation_0/Returns Mean                  4199.55
evaluation_0/Returns Std                    628.915
evaluation_0/Returns Max                   4830.96
evaluation_0/Returns Min                   2703.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4199.55
time/epoch (s)                                0
time/total (s)                             4851.87
Epoch                                       312
---------------------------------------  ----------------
2022-11-16 17:35:51.439697 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 313 finished
---------------------------------------  ----------------
epoch                                       313
total_step                               318000
replay_pool/size                         318000
trainer/alpha                                 0.0639462
trainer/alpha_loss                            0.674139
trainer/entropy                              -6.24516
trainer/qf_loss                              27.9906
trainer/policy_loss                        -290.541
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         290.941
trainer/entropy_penalty                      -0.399355
trainer/entropy_percentage                   -0.00137263
trainer/Q1Pred Mean                         288.739
trainer/Q1Pred Std                           63.5679
trainer/Q1Pred Max                          374.953
trainer/Q1Pred Min                           -6.76504
trainer/Q2Pred Mean                         289.423
trainer/Q2Pred Std                           63.3524
trainer/Q2Pred Max                          369.865
trainer/Q2Pred Min                            0.801444
trainer/QTargetWithReg Mean                 290.222
trainer/QTargetWithReg Std                   63.8638
trainer/QTargetWithReg Max                  372.747
trainer/QTargetWithReg Min                   -2.82279
trainer/PolicyLossWithoutReg Mean           290.941
trainer/PolicyLossWithoutReg Std             61.1959
trainer/PolicyLossWithoutReg Max            372.016
trainer/PolicyLossWithoutReg Min             -4.45491
exploration/num steps total              318000
exploration/num paths total                1056
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37
exploration/Rewards Std                       1.02995
exploration/Rewards Max                       7.1049
exploration/Rewards Min                      -0.68615
exploration/Returns Mean                   4370
exploration/Returns Std                       0
exploration/Returns Max                    4370
exploration/Returns Min                    4370
exploration/Num Paths                         1
exploration/Average Returns                4370
evaluation_0/num steps total                  2.44157e+06
evaluation_0/num paths total               5802
evaluation_0/path length Mean               994.5
evaluation_0/path length Std                 14.5516
evaluation_0/path length Max               1000
evaluation_0/path length Min                956
evaluation_0/Rewards Mean                     4.67426
evaluation_0/Rewards Std                      1.1705
evaluation_0/Rewards Max                      9.33133
evaluation_0/Rewards Min                     -0.731262
evaluation_0/Returns Mean                  4648.55
evaluation_0/Returns Std                    110.13
evaluation_0/Returns Max                   4757.73
evaluation_0/Returns Min                   4456.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4648.55
time/epoch (s)                                0
time/total (s)                             4868.52
Epoch                                       313
---------------------------------------  ----------------
2022-11-16 17:36:08.344921 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 314 finished
---------------------------------------  ----------------
epoch                                       314
total_step                               319000
replay_pool/size                         319000
trainer/alpha                                 0.0622164
trainer/alpha_loss                            2.01529
trainer/entropy                              -6.72562
trainer/qf_loss                              21.9504
trainer/policy_loss                        -293.158
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.577
trainer/entropy_penalty                      -0.418444
trainer/entropy_percentage                   -0.00142533
trainer/Q1Pred Mean                         291.652
trainer/Q1Pred Std                           56.1862
trainer/Q1Pred Max                          377.283
trainer/Q1Pred Min                           19.747
trainer/Q2Pred Mean                         292.149
trainer/Q2Pred Std                           55.398
trainer/Q2Pred Max                          381.836
trainer/Q2Pred Min                           19.5451
trainer/QTargetWithReg Mean                 292.008
trainer/QTargetWithReg Std                   55.5765
trainer/QTargetWithReg Max                  378.528
trainer/QTargetWithReg Min                   24.2625
trainer/PolicyLossWithoutReg Mean           293.577
trainer/PolicyLossWithoutReg Std             54.5083
trainer/PolicyLossWithoutReg Max            380.594
trainer/PolicyLossWithoutReg Min             18.4427
exploration/num steps total              319000
exploration/num paths total                1057
exploration/path length this epoch Mean     497
exploration/path length this epoch Std        0
exploration/path length this epoch Max      497
exploration/path length this epoch Min      497
exploration/Rewards Mean                      4.33234
exploration/Rewards Std                       1.22922
exploration/Rewards Max                       7.03729
exploration/Rewards Min                      -0.749425
exploration/Returns Mean                   2153.18
exploration/Returns Std                       0
exploration/Returns Max                    2153.18
exploration/Returns Min                    2153.18
exploration/Num Paths                         1
exploration/Average Returns                2153.18
evaluation_0/num steps total                  2.44927e+06
evaluation_0/num paths total               5810
evaluation_0/path length Mean               962.25
evaluation_0/path length Std                 65.3868
evaluation_0/path length Max               1000
evaluation_0/path length Min                848
evaluation_0/Rewards Mean                     4.77936
evaluation_0/Rewards Std                      1.21307
evaluation_0/Rewards Max                      8.98323
evaluation_0/Rewards Min                     -0.529805
evaluation_0/Returns Mean                  4598.94
evaluation_0/Returns Std                    275.202
evaluation_0/Returns Max                   4883.2
evaluation_0/Returns Min                   3963.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4598.94
time/epoch (s)                                0
time/total (s)                             4885.42
Epoch                                       314
---------------------------------------  ----------------
2022-11-16 17:36:24.937666 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 315 finished
---------------------------------------  ----------------
epoch                                       315
total_step                               320000
replay_pool/size                         320000
trainer/alpha                                 0.0638085
trainer/alpha_loss                            0.228911
trainer/entropy                              -6.08318
trainer/qf_loss                              29.5235
trainer/policy_loss                        -293.672
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.06
trainer/entropy_penalty                      -0.388159
trainer/entropy_percentage                   -0.00132
trainer/Q1Pred Mean                         291.535
trainer/Q1Pred Std                           60.6376
trainer/Q1Pred Max                          368.908
trainer/Q1Pred Min                           -2.37085
trainer/Q2Pred Mean                         290.559
trainer/Q2Pred Std                           60.5574
trainer/Q2Pred Max                          371.511
trainer/Q2Pred Min                           -3.47468
trainer/QTargetWithReg Mean                 291.614
trainer/QTargetWithReg Std                   59.9541
trainer/QTargetWithReg Max                  368.655
trainer/QTargetWithReg Min                   -0.131678
trainer/PolicyLossWithoutReg Mean           294.06
trainer/PolicyLossWithoutReg Std             58.2249
trainer/PolicyLossWithoutReg Max            369.197
trainer/PolicyLossWithoutReg Min             17.226
exploration/num steps total              320000
exploration/num paths total                1058
exploration/path length this epoch Mean     390
exploration/path length this epoch Std        0
exploration/path length this epoch Max      390
exploration/path length this epoch Min      390
exploration/Rewards Mean                      3.43482
exploration/Rewards Std                       1.20618
exploration/Rewards Max                       5.97344
exploration/Rewards Min                      -0.434965
exploration/Returns Mean                   1339.58
exploration/Returns Std                       0
exploration/Returns Max                    1339.58
exploration/Returns Min                    1339.58
exploration/Num Paths                         1
exploration/Average Returns                1339.58
evaluation_0/num steps total                  2.45726e+06
evaluation_0/num paths total               5821
evaluation_0/path length Mean               726.636
evaluation_0/path length Std                154.848
evaluation_0/path length Max                942
evaluation_0/path length Min                489
evaluation_0/Rewards Mean                     4.81816
evaluation_0/Rewards Std                      1.39528
evaluation_0/Rewards Max                     10.7487
evaluation_0/Rewards Min                     -0.769671
evaluation_0/Returns Mean                  3501.05
evaluation_0/Returns Std                    894.363
evaluation_0/Returns Max                   4809.73
evaluation_0/Returns Min                   2121.76
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3501.05
time/epoch (s)                                0
time/total (s)                             4902.02
Epoch                                       315
---------------------------------------  ----------------
2022-11-16 17:36:41.475517 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 316 finished
---------------------------------------  ----------------
epoch                                       316
total_step                               321000
replay_pool/size                         321000
trainer/alpha                                 0.0654711
trainer/alpha_loss                           -0.317743
trainer/entropy                              -5.88345
trainer/qf_loss                              17.7051
trainer/policy_loss                        -288.483
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         288.868
trainer/entropy_penalty                      -0.385196
trainer/entropy_percentage                   -0.00133347
trainer/Q1Pred Mean                         287.767
trainer/Q1Pred Std                           66.6575
trainer/Q1Pred Max                          381.535
trainer/Q1Pred Min                           14.7696
trainer/Q2Pred Mean                         288.82
trainer/Q2Pred Std                           66.6979
trainer/Q2Pred Max                          384.677
trainer/Q2Pred Min                           15.3308
trainer/QTargetWithReg Mean                 288.114
trainer/QTargetWithReg Std                   66.7406
trainer/QTargetWithReg Max                  381.985
trainer/QTargetWithReg Min                   11.632
trainer/PolicyLossWithoutReg Mean           288.868
trainer/PolicyLossWithoutReg Std             65.4132
trainer/PolicyLossWithoutReg Max            383.628
trainer/PolicyLossWithoutReg Min             12.8084
exploration/num steps total              321000
exploration/num paths total                1059
exploration/path length this epoch Mean     693
exploration/path length this epoch Std        0
exploration/path length this epoch Max      693
exploration/path length this epoch Min      693
exploration/Rewards Mean                      4.15141
exploration/Rewards Std                       1.2049
exploration/Rewards Max                       7.5169
exploration/Rewards Min                      -0.810357
exploration/Returns Mean                   2876.93
exploration/Returns Std                       0
exploration/Returns Max                    2876.93
exploration/Returns Min                    2876.93
exploration/Num Paths                         1
exploration/Average Returns                2876.93
evaluation_0/num steps total                  2.46501e+06
evaluation_0/num paths total               5829
evaluation_0/path length Mean               968.5
evaluation_0/path length Std                 83.3412
evaluation_0/path length Max               1000
evaluation_0/path length Min                748
evaluation_0/Rewards Mean                     4.29296
evaluation_0/Rewards Std                      1.07929
evaluation_0/Rewards Max                      8.15415
evaluation_0/Rewards Min                     -0.492065
evaluation_0/Returns Mean                  4157.73
evaluation_0/Returns Std                    436.394
evaluation_0/Returns Max                   4587.2
evaluation_0/Returns Min                   3135.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4157.73
time/epoch (s)                                0
time/total (s)                             4918.55
Epoch                                       316
---------------------------------------  ----------------
2022-11-16 17:36:58.279936 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 317 finished
---------------------------------------  ----------------
epoch                                       317
total_step                               322000
replay_pool/size                         322000
trainer/alpha                                 0.0643328
trainer/alpha_loss                            1.17411
trainer/entropy                              -6.42791
trainer/qf_loss                              26.4487
trainer/policy_loss                        -278.161
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         278.574
trainer/entropy_penalty                      -0.413526
trainer/entropy_percentage                   -0.00148444
trainer/Q1Pred Mean                         276.851
trainer/Q1Pred Std                           78.9503
trainer/Q1Pred Max                          373.686
trainer/Q1Pred Min                            1.19734
trainer/Q2Pred Mean                         276.919
trainer/Q2Pred Std                           78.6969
trainer/Q2Pred Max                          375.042
trainer/Q2Pred Min                           11.4407
trainer/QTargetWithReg Mean                 276.62
trainer/QTargetWithReg Std                   79.4855
trainer/QTargetWithReg Max                  374.837
trainer/QTargetWithReg Min                    2.64738
trainer/PolicyLossWithoutReg Mean           278.574
trainer/PolicyLossWithoutReg Std             77.1271
trainer/PolicyLossWithoutReg Max            374.597
trainer/PolicyLossWithoutReg Min              3.61808
exploration/num steps total              322000
exploration/num paths total                1060
exploration/path length this epoch Mean     632
exploration/path length this epoch Std        0
exploration/path length this epoch Max      632
exploration/path length this epoch Min      632
exploration/Rewards Mean                      4.21353
exploration/Rewards Std                       1.19321
exploration/Rewards Max                       6.41525
exploration/Rewards Min                      -0.761225
exploration/Returns Mean                   2662.95
exploration/Returns Std                       0
exploration/Returns Max                    2662.95
exploration/Returns Min                    2662.95
exploration/Num Paths                         1
exploration/Average Returns                2662.95
evaluation_0/num steps total                  2.47265e+06
evaluation_0/num paths total               5839
evaluation_0/path length Mean               764.1
evaluation_0/path length Std                242.34
evaluation_0/path length Max               1000
evaluation_0/path length Min                336
evaluation_0/Rewards Mean                     4.73064
evaluation_0/Rewards Std                      1.2621
evaluation_0/Rewards Max                      9.90797
evaluation_0/Rewards Min                     -0.580449
evaluation_0/Returns Mean                  3614.68
evaluation_0/Returns Std                   1311.16
evaluation_0/Returns Max                   5052.96
evaluation_0/Returns Min                   1367.76
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3614.68
time/epoch (s)                                0
time/total (s)                             4935.36
Epoch                                       317
---------------------------------------  ----------------
2022-11-16 17:37:15.006962 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 318 finished
---------------------------------------  ----------------
epoch                                       318
total_step                               323000
replay_pool/size                         323000
trainer/alpha                                 0.0646843
trainer/alpha_loss                            0.241654
trainer/entropy                              -6.08824
trainer/qf_loss                              22.8628
trainer/policy_loss                        -283.471
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         283.865
trainer/entropy_penalty                      -0.393814
trainer/entropy_percentage                   -0.00138733
trainer/Q1Pred Mean                         282.895
trainer/Q1Pred Std                           75.6545
trainer/Q1Pred Max                          374.247
trainer/Q1Pred Min                            0.0480909
trainer/Q2Pred Mean                         283.037
trainer/Q2Pred Std                           76.2205
trainer/Q2Pred Max                          378.959
trainer/Q2Pred Min                           -4.78954
trainer/QTargetWithReg Mean                 282.634
trainer/QTargetWithReg Std                   75.9996
trainer/QTargetWithReg Max                  377.391
trainer/QTargetWithReg Min                   -1.52456
trainer/PolicyLossWithoutReg Mean           283.865
trainer/PolicyLossWithoutReg Std             74.8522
trainer/PolicyLossWithoutReg Max            377.53
trainer/PolicyLossWithoutReg Min             -5.33324
exploration/num steps total              323000
exploration/num paths total                1061
exploration/path length this epoch Mean     736
exploration/path length this epoch Std        0
exploration/path length this epoch Max      736
exploration/path length this epoch Min      736
exploration/Rewards Mean                      4.17999
exploration/Rewards Std                       1.12804
exploration/Rewards Max                       6.56097
exploration/Rewards Min                      -0.567516
exploration/Returns Mean                   3076.47
exploration/Returns Std                       0
exploration/Returns Max                    3076.47
exploration/Returns Min                    3076.47
exploration/Num Paths                         1
exploration/Average Returns                3076.47
evaluation_0/num steps total                  2.48032e+06
evaluation_0/num paths total               5847
evaluation_0/path length Mean               958.875
evaluation_0/path length Std                108.807
evaluation_0/path length Max               1000
evaluation_0/path length Min                671
evaluation_0/Rewards Mean                     4.3987
evaluation_0/Rewards Std                      1.06482
evaluation_0/Rewards Max                      8.6155
evaluation_0/Rewards Min                     -0.78902
evaluation_0/Returns Mean                  4217.81
evaluation_0/Returns Std                    594.131
evaluation_0/Returns Max                   4793.67
evaluation_0/Returns Min                   2790.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4217.81
time/epoch (s)                                0
time/total (s)                             4952.08
Epoch                                       318
---------------------------------------  ----------------
2022-11-16 17:37:31.957584 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 319 finished
---------------------------------------  ---------------
epoch                                       319
total_step                               324000
replay_pool/size                         324000
trainer/alpha                                 0.0653056
trainer/alpha_loss                            0.724258
trainer/entropy                              -6.26543
trainer/qf_loss                              19.2444
trainer/policy_loss                        -291.489
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         291.898
trainer/entropy_penalty                      -0.409168
trainer/entropy_percentage                   -0.00140175
trainer/Q1Pred Mean                         290.295
trainer/Q1Pred Std                           68.1871
trainer/Q1Pred Max                          370.673
trainer/Q1Pred Min                          -10.6188
trainer/Q2Pred Mean                         290.339
trainer/Q2Pred Std                           68.7841
trainer/Q2Pred Max                          371.658
trainer/Q2Pred Min                          -28.6855
trainer/QTargetWithReg Mean                 290.334
trainer/QTargetWithReg Std                   69.2173
trainer/QTargetWithReg Max                  374.159
trainer/QTargetWithReg Min                   -1.38498
trainer/PolicyLossWithoutReg Mean           291.898
trainer/PolicyLossWithoutReg Std             67.0097
trainer/PolicyLossWithoutReg Max            370.309
trainer/PolicyLossWithoutReg Min            -13.39
exploration/num steps total              324000
exploration/num paths total                1062
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.3515
exploration/Rewards Std                       1.05139
exploration/Rewards Max                       7.48202
exploration/Rewards Min                      -0.785587
exploration/Returns Mean                   4351.5
exploration/Returns Std                       0
exploration/Returns Max                    4351.5
exploration/Returns Min                    4351.5
exploration/Num Paths                         1
exploration/Average Returns                4351.5
evaluation_0/num steps total                  2.4882e+06
evaluation_0/num paths total               5856
evaluation_0/path length Mean               875.111
evaluation_0/path length Std                109.308
evaluation_0/path length Max               1000
evaluation_0/path length Min                714
evaluation_0/Rewards Mean                     4.10209
evaluation_0/Rewards Std                      1.30719
evaluation_0/Rewards Max                      8.88331
evaluation_0/Rewards Min                     -0.725911
evaluation_0/Returns Mean                  3589.78
evaluation_0/Returns Std                    453.536
evaluation_0/Returns Max                   4116.82
evaluation_0/Returns Min                   2724.78
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3589.78
time/epoch (s)                                0
time/total (s)                             4969.03
Epoch                                       319
---------------------------------------  ---------------
2022-11-16 17:37:46.687897 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 320 finished
---------------------------------------  ---------------
epoch                                       320
total_step                               325000
replay_pool/size                         325000
trainer/alpha                                 0.0659331
trainer/alpha_loss                            1.56946
trainer/entropy                              -6.57718
trainer/qf_loss                              15.3636
trainer/policy_loss                        -293.114
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.548
trainer/entropy_penalty                      -0.433654
trainer/entropy_percentage                   -0.00147729
trainer/Q1Pred Mean                         291.302
trainer/Q1Pred Std                           57.9496
trainer/Q1Pred Max                          373.77
trainer/Q1Pred Min                          -11.4686
trainer/Q2Pred Mean                         291.331
trainer/Q2Pred Std                           57.6564
trainer/Q2Pred Max                          375.226
trainer/Q2Pred Min                          -11.9388
trainer/QTargetWithReg Mean                 291.721
trainer/QTargetWithReg Std                   58.5186
trainer/QTargetWithReg Max                  377.932
trainer/QTargetWithReg Min                  -24.8595
trainer/PolicyLossWithoutReg Mean           293.548
trainer/PolicyLossWithoutReg Std             55.7807
trainer/PolicyLossWithoutReg Max            375.181
trainer/PolicyLossWithoutReg Min             -3.14332
exploration/num steps total              325000
exploration/num paths total                1063
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.40463
exploration/Rewards Std                       1.08002
exploration/Rewards Max                       6.70701
exploration/Rewards Min                      -0.640485
exploration/Returns Mean                   4404.63
exploration/Returns Std                       0
exploration/Returns Max                    4404.63
exploration/Returns Min                    4404.63
exploration/Num Paths                         1
exploration/Average Returns                4404.63
evaluation_0/num steps total                  2.4962e+06
evaluation_0/num paths total               5864
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.04438
evaluation_0/Rewards Std                      0.934953
evaluation_0/Rewards Max                      6.91926
evaluation_0/Rewards Min                     -0.744895
evaluation_0/Returns Mean                  4044.38
evaluation_0/Returns Std                    184.595
evaluation_0/Returns Max                   4357.4
evaluation_0/Returns Min                   3792.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4044.38
time/epoch (s)                                0
time/total (s)                             4983.76
Epoch                                       320
---------------------------------------  ---------------
2022-11-16 17:38:03.412971 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 321 finished
---------------------------------------  ----------------
epoch                                       321
total_step                               326000
replay_pool/size                         326000
trainer/alpha                                 0.0654318
trainer/alpha_loss                           -0.445871
trainer/entropy                              -5.83648
trainer/qf_loss                              16.7514
trainer/policy_loss                        -293.176
trainer/adversary_policy_loss                14.1041
trainer/policy_loss_without_entropy         293.558
trainer/entropy_penalty                      -0.381892
trainer/entropy_percentage                   -0.00130091
trainer/Q1Pred Mean                         291.484
trainer/Q1Pred Std                           64.1282
trainer/Q1Pred Max                          378.529
trainer/Q1Pred Min                            1.31962
trainer/Q2Pred Mean                         292.403
trainer/Q2Pred Std                           63.7543
trainer/Q2Pred Max                          378.181
trainer/Q2Pred Min                            3.73426
trainer/QTargetWithReg Mean                 292.353
trainer/QTargetWithReg Std                   63.6695
trainer/QTargetWithReg Max                  380.918
trainer/QTargetWithReg Min                    2.85709
trainer/PolicyLossWithoutReg Mean           293.558
trainer/PolicyLossWithoutReg Std             62.2919
trainer/PolicyLossWithoutReg Max            378.821
trainer/PolicyLossWithoutReg Min              6.82093
exploration/num steps total              326000
exploration/num paths total                1064
exploration/path length this epoch Mean     639
exploration/path length this epoch Std        0
exploration/path length this epoch Max      639
exploration/path length this epoch Min      639
exploration/Rewards Mean                      4.08768
exploration/Rewards Std                       1.13481
exploration/Rewards Max                       6.19769
exploration/Rewards Min                      -0.512471
exploration/Returns Mean                   2612.03
exploration/Returns Std                       0
exploration/Returns Max                    2612.03
exploration/Returns Min                    2612.03
exploration/Num Paths                         1
exploration/Average Returns                2612.03
evaluation_0/num steps total                  2.50391e+06
evaluation_0/num paths total               5873
evaluation_0/path length Mean               857.222
evaluation_0/path length Std                200.761
evaluation_0/path length Max               1000
evaluation_0/path length Min                500
evaluation_0/Rewards Mean                     4.5797
evaluation_0/Rewards Std                      1.23982
evaluation_0/Rewards Max                      8.26761
evaluation_0/Rewards Min                     -0.743099
evaluation_0/Returns Mean                  3925.82
evaluation_0/Returns Std                    994.129
evaluation_0/Returns Max                   4961.61
evaluation_0/Returns Min                   2184.57
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3925.82
time/epoch (s)                                0
time/total (s)                             5000.49
Epoch                                       321
---------------------------------------  ----------------
2022-11-16 17:38:20.195795 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 322 finished
---------------------------------------  ----------------
epoch                                       322
total_step                               327000
replay_pool/size                         327000
trainer/alpha                                 0.0664439
trainer/alpha_loss                            0.269201
trainer/entropy                              -6.09928
trainer/qf_loss                             109.918
trainer/policy_loss                        -295.239
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.645
trainer/entropy_penalty                      -0.40526
trainer/entropy_percentage                   -0.00137077
trainer/Q1Pred Mean                         295.45
trainer/Q1Pred Std                           65.6306
trainer/Q1Pred Max                          377.597
trainer/Q1Pred Min                           20.7221
trainer/Q2Pred Mean                         294.832
trainer/Q2Pred Std                           65.0539
trainer/Q2Pred Max                          377.479
trainer/Q2Pred Min                           18.6425
trainer/QTargetWithReg Mean                 294.665
trainer/QTargetWithReg Std                   67.775
trainer/QTargetWithReg Max                  377.022
trainer/QTargetWithReg Min                    4.41075
trainer/PolicyLossWithoutReg Mean           295.645
trainer/PolicyLossWithoutReg Std             63.5764
trainer/PolicyLossWithoutReg Max            376.647
trainer/PolicyLossWithoutReg Min             19.2975
exploration/num steps total              327000
exploration/num paths total                1065
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49409
exploration/Rewards Std                       1.21752
exploration/Rewards Max                       7.05507
exploration/Rewards Min                      -0.749607
exploration/Returns Mean                   4494.09
exploration/Returns Std                       0
exploration/Returns Max                    4494.09
exploration/Returns Min                    4494.09
exploration/Num Paths                         1
exploration/Average Returns                4494.09
evaluation_0/num steps total                  2.51107e+06
evaluation_0/num paths total               5882
evaluation_0/path length Mean               795
evaluation_0/path length Std                239.691
evaluation_0/path length Max               1000
evaluation_0/path length Min                368
evaluation_0/Rewards Mean                     4.34614
evaluation_0/Rewards Std                      1.44091
evaluation_0/Rewards Max                      9.31649
evaluation_0/Rewards Min                     -0.713661
evaluation_0/Returns Mean                  3455.18
evaluation_0/Returns Std                   1275.56
evaluation_0/Returns Max                   4901.01
evaluation_0/Returns Min                   1236.23
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3455.18
time/epoch (s)                                0
time/total (s)                             5017.27
Epoch                                       322
---------------------------------------  ----------------
2022-11-16 17:38:37.238143 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 323 finished
---------------------------------------  ----------------
epoch                                       323
total_step                               328000
replay_pool/size                         328000
trainer/alpha                                 0.0645211
trainer/alpha_loss                           -0.398183
trainer/entropy                              -5.85472
trainer/qf_loss                              21.721
trainer/policy_loss                        -288.096
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         288.474
trainer/entropy_penalty                      -0.377753
trainer/entropy_percentage                   -0.00130949
trainer/Q1Pred Mean                         287.146
trainer/Q1Pred Std                           65.3979
trainer/Q1Pred Max                          374.683
trainer/Q1Pred Min                          -15.8707
trainer/Q2Pred Mean                         286.853
trainer/Q2Pred Std                           64.8982
trainer/Q2Pred Max                          374.652
trainer/Q2Pred Min                          -22.766
trainer/QTargetWithReg Mean                 287.221
trainer/QTargetWithReg Std                   64.8897
trainer/QTargetWithReg Max                  374.896
trainer/QTargetWithReg Min                  -27.1595
trainer/PolicyLossWithoutReg Mean           288.474
trainer/PolicyLossWithoutReg Std             62.0743
trainer/PolicyLossWithoutReg Max            374.313
trainer/PolicyLossWithoutReg Min             -4.19913
exploration/num steps total              328000
exploration/num paths total                1066
exploration/path length this epoch Mean     796
exploration/path length this epoch Std        0
exploration/path length this epoch Max      796
exploration/path length this epoch Min      796
exploration/Rewards Mean                      3.88671
exploration/Rewards Std                       1.04873
exploration/Rewards Max                       6.91238
exploration/Rewards Min                      -0.766872
exploration/Returns Mean                   3093.82
exploration/Returns Std                       0
exploration/Returns Max                    3093.82
exploration/Returns Min                    3093.82
exploration/Num Paths                         1
exploration/Average Returns                3093.82
evaluation_0/num steps total                  2.51886e+06
evaluation_0/num paths total               5892
evaluation_0/path length Mean               778.9
evaluation_0/path length Std                194.462
evaluation_0/path length Max               1000
evaluation_0/path length Min                403
evaluation_0/Rewards Mean                     4.48502
evaluation_0/Rewards Std                      1.29677
evaluation_0/Rewards Max                      9.3002
evaluation_0/Rewards Min                     -0.699018
evaluation_0/Returns Mean                  3493.38
evaluation_0/Returns Std                    990.264
evaluation_0/Returns Max                   4726.67
evaluation_0/Returns Min                   1565.62
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3493.38
time/epoch (s)                                0
time/total (s)                             5034.31
Epoch                                       323
---------------------------------------  ----------------
2022-11-16 17:38:51.383810 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 324 finished
---------------------------------------  ----------------
epoch                                       324
total_step                               329000
replay_pool/size                         329000
trainer/alpha                                 0.0646482
trainer/alpha_loss                            0.4124
trainer/entropy                              -6.15057
trainer/qf_loss                              17.3037
trainer/policy_loss                        -288.807
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         289.205
trainer/entropy_penalty                      -0.397623
trainer/entropy_percentage                   -0.00137488
trainer/Q1Pred Mean                         288.383
trainer/Q1Pred Std                           72.539
trainer/Q1Pred Max                          378.398
trainer/Q1Pred Min                           -9.96659
trainer/Q2Pred Mean                         287.957
trainer/Q2Pred Std                           73.262
trainer/Q2Pred Max                          374.632
trainer/Q2Pred Min                          -12.9461
trainer/QTargetWithReg Mean                 287.696
trainer/QTargetWithReg Std                   72.7962
trainer/QTargetWithReg Max                  376.041
trainer/QTargetWithReg Min                  -12.8363
trainer/PolicyLossWithoutReg Mean           289.205
trainer/PolicyLossWithoutReg Std             71.1529
trainer/PolicyLossWithoutReg Max            374.111
trainer/PolicyLossWithoutReg Min             -6.74748
exploration/num steps total              329000
exploration/num paths total                1067
exploration/path length this epoch Mean     355
exploration/path length this epoch Std        0
exploration/path length this epoch Max      355
exploration/path length this epoch Min      355
exploration/Rewards Mean                      3.46861
exploration/Rewards Std                       1.13233
exploration/Rewards Max                       6.67475
exploration/Rewards Min                      -0.660107
exploration/Returns Mean                   1231.36
exploration/Returns Std                       0
exploration/Returns Max                    1231.36
exploration/Returns Min                    1231.36
exploration/Num Paths                         1
exploration/Average Returns                1231.36
evaluation_0/num steps total                  2.52686e+06
evaluation_0/num paths total               5900
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.35946
evaluation_0/Rewards Std                      1.07287
evaluation_0/Rewards Max                      7.67375
evaluation_0/Rewards Min                     -0.489331
evaluation_0/Returns Mean                  4359.46
evaluation_0/Returns Std                    248.257
evaluation_0/Returns Max                   4773.36
evaluation_0/Returns Min                   3974.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4359.46
time/epoch (s)                                0
time/total (s)                             5048.46
Epoch                                       324
---------------------------------------  ----------------
2022-11-16 17:39:04.328986 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 325 finished
---------------------------------------  ----------------
epoch                                       325
total_step                               330000
replay_pool/size                         330000
trainer/alpha                                 0.0655679
trainer/alpha_loss                           -1.2884
trainer/entropy                              -5.5271
trainer/qf_loss                              22.8565
trainer/policy_loss                        -294.65
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.012
trainer/entropy_penalty                      -0.3624
trainer/entropy_percentage                   -0.00122843
trainer/Q1Pred Mean                         292.946
trainer/Q1Pred Std                           69.8045
trainer/Q1Pred Max                          373.594
trainer/Q1Pred Min                            9.13263
trainer/Q2Pred Mean                         292.921
trainer/Q2Pred Std                           70.1065
trainer/Q2Pred Max                          375.398
trainer/Q2Pred Min                            0.689581
trainer/QTargetWithReg Mean                 292.959
trainer/QTargetWithReg Std                   70.7667
trainer/QTargetWithReg Max                  373.754
trainer/QTargetWithReg Min                    2.13268
trainer/PolicyLossWithoutReg Mean           295.012
trainer/PolicyLossWithoutReg Std             67.6069
trainer/PolicyLossWithoutReg Max            375.517
trainer/PolicyLossWithoutReg Min              3.95589
exploration/num steps total              330000
exploration/num paths total                1068
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38085
exploration/Rewards Std                       0.907661
exploration/Rewards Max                       6.47325
exploration/Rewards Min                      -0.397429
exploration/Returns Mean                   4380.85
exploration/Returns Std                       0
exploration/Returns Max                    4380.85
exploration/Returns Min                    4380.85
exploration/Num Paths                         1
exploration/Average Returns                4380.85
evaluation_0/num steps total                  2.53405e+06
evaluation_0/num paths total               5908
evaluation_0/path length Mean               899.25
evaluation_0/path length Std                119.771
evaluation_0/path length Max               1000
evaluation_0/path length Min                677
evaluation_0/Rewards Mean                     4.46152
evaluation_0/Rewards Std                      1.13402
evaluation_0/Rewards Max                      8.71511
evaluation_0/Rewards Min                     -0.637462
evaluation_0/Returns Mean                  4012.02
evaluation_0/Returns Std                    615.469
evaluation_0/Returns Max                   4621.64
evaluation_0/Returns Min                   2836.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4012.02
time/epoch (s)                                0
time/total (s)                             5061.4
Epoch                                       325
---------------------------------------  ----------------
2022-11-16 17:39:19.075446 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 326 finished
---------------------------------------  ----------------
epoch                                       326
total_step                               331000
replay_pool/size                         331000
trainer/alpha                                 0.0639792
trainer/alpha_loss                            0.572286
trainer/entropy                              -6.20816
trainer/qf_loss                              20.4528
trainer/policy_loss                        -293.302
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.699
trainer/entropy_penalty                      -0.397193
trainer/entropy_percentage                   -0.00135238
trainer/Q1Pred Mean                         293.059
trainer/Q1Pred Std                           64.8252
trainer/Q1Pred Max                          387.563
trainer/Q1Pred Min                            4.54982
trainer/Q2Pred Mean                         292.66
trainer/Q2Pred Std                           64.7789
trainer/Q2Pred Max                          386.186
trainer/Q2Pred Min                            7.74402
trainer/QTargetWithReg Mean                 292.55
trainer/QTargetWithReg Std                   65.5549
trainer/QTargetWithReg Max                  386.568
trainer/QTargetWithReg Min                    4.49373
trainer/PolicyLossWithoutReg Mean           293.699
trainer/PolicyLossWithoutReg Std             63.7084
trainer/PolicyLossWithoutReg Max            385.7
trainer/PolicyLossWithoutReg Min              2.43776
exploration/num steps total              331000
exploration/num paths total                1069
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.88175
exploration/Rewards Std                       0.849635
exploration/Rewards Max                       5.97835
exploration/Rewards Min                      -0.251868
exploration/Returns Mean                   3881.75
exploration/Returns Std                       0
exploration/Returns Max                    3881.75
exploration/Returns Min                    3881.75
exploration/Num Paths                         1
exploration/Average Returns                3881.75
evaluation_0/num steps total                  2.54187e+06
evaluation_0/num paths total               5917
evaluation_0/path length Mean               868.444
evaluation_0/path length Std                187.462
evaluation_0/path length Max               1000
evaluation_0/path length Min                550
evaluation_0/Rewards Mean                     4.48127
evaluation_0/Rewards Std                      1.19052
evaluation_0/Rewards Max                      8.31948
evaluation_0/Rewards Min                     -0.655752
evaluation_0/Returns Mean                  3891.74
evaluation_0/Returns Std                    975.604
evaluation_0/Returns Max                   4690.49
evaluation_0/Returns Min                   2413.62
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3891.74
time/epoch (s)                                0
time/total (s)                             5076.15
Epoch                                       326
---------------------------------------  ----------------
2022-11-16 17:39:35.440773 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 327 finished
---------------------------------------  ----------------
epoch                                       327
total_step                               332000
replay_pool/size                         332000
trainer/alpha                                 0.0643491
trainer/alpha_loss                            1.71046
trainer/entropy                              -6.62347
trainer/qf_loss                              27.2065
trainer/policy_loss                        -284.81
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         285.237
trainer/entropy_penalty                      -0.426214
trainer/entropy_percentage                   -0.00149425
trainer/Q1Pred Mean                         284.727
trainer/Q1Pred Std                           77.3782
trainer/Q1Pred Max                          381.921
trainer/Q1Pred Min                          -23.4
trainer/Q2Pred Mean                         284.007
trainer/Q2Pred Std                           76.6289
trainer/Q2Pred Max                          378.617
trainer/Q2Pred Min                            5.85114
trainer/QTargetWithReg Mean                 284.684
trainer/QTargetWithReg Std                   76.778
trainer/QTargetWithReg Max                  382.474
trainer/QTargetWithReg Min                   -0.0520547
trainer/PolicyLossWithoutReg Mean           285.237
trainer/PolicyLossWithoutReg Std             74.2736
trainer/PolicyLossWithoutReg Max            379.556
trainer/PolicyLossWithoutReg Min              1.63681
exploration/num steps total              332000
exploration/num paths total                1070
exploration/path length this epoch Mean     455
exploration/path length this epoch Std        0
exploration/path length this epoch Max      455
exploration/path length this epoch Min      455
exploration/Rewards Mean                      4.28411
exploration/Rewards Std                       1.49402
exploration/Rewards Max                       6.85295
exploration/Rewards Min                      -0.467376
exploration/Returns Mean                   1949.27
exploration/Returns Std                       0
exploration/Returns Max                    1949.27
exploration/Returns Min                    1949.27
exploration/Num Paths                         1
exploration/Average Returns                1949.27
evaluation_0/num steps total                  2.54936e+06
evaluation_0/num paths total               5925
evaluation_0/path length Mean               937.25
evaluation_0/path length Std                141.795
evaluation_0/path length Max               1000
evaluation_0/path length Min                564
evaluation_0/Rewards Mean                     4.49522
evaluation_0/Rewards Std                      1.12783
evaluation_0/Rewards Max                      8.88746
evaluation_0/Rewards Min                     -0.609102
evaluation_0/Returns Mean                  4213.14
evaluation_0/Returns Std                    725.974
evaluation_0/Returns Max                   4672.19
evaluation_0/Returns Min                   2313.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4213.14
time/epoch (s)                                0
time/total (s)                             5092.51
Epoch                                       327
---------------------------------------  ----------------
2022-11-16 17:39:49.525052 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 328 finished
---------------------------------------  ----------------
epoch                                       328
total_step                               333000
replay_pool/size                         333000
trainer/alpha                                 0.0644635
trainer/alpha_loss                           -0.395016
trainer/entropy                              -5.85592
trainer/qf_loss                              16.9597
trainer/policy_loss                        -290.826
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         291.204
trainer/entropy_penalty                      -0.377493
trainer/entropy_percentage                   -0.00129632
trainer/Q1Pred Mean                         290.069
trainer/Q1Pred Std                           70.2529
trainer/Q1Pred Max                          380.967
trainer/Q1Pred Min                            5.65175
trainer/Q2Pred Mean                         290.178
trainer/Q2Pred Std                           70.1281
trainer/Q2Pred Max                          380.155
trainer/Q2Pred Min                            0.447952
trainer/QTargetWithReg Mean                 290.367
trainer/QTargetWithReg Std                   70.4388
trainer/QTargetWithReg Max                  380.852
trainer/QTargetWithReg Min                    2.03939
trainer/PolicyLossWithoutReg Mean           291.204
trainer/PolicyLossWithoutReg Std             69.435
trainer/PolicyLossWithoutReg Max            381.339
trainer/PolicyLossWithoutReg Min              4.25561
exploration/num steps total              333000
exploration/num paths total                1071
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38187
exploration/Rewards Std                       0.996464
exploration/Rewards Max                       6.80056
exploration/Rewards Min                      -0.703672
exploration/Returns Mean                   4381.87
exploration/Returns Std                       0
exploration/Returns Max                    4381.87
exploration/Returns Min                    4381.87
exploration/Num Paths                         1
exploration/Average Returns                4381.87
evaluation_0/num steps total                  2.55694e+06
evaluation_0/num paths total               5935
evaluation_0/path length Mean               758.1
evaluation_0/path length Std                207.85
evaluation_0/path length Max               1000
evaluation_0/path length Min                439
evaluation_0/Rewards Mean                     4.53926
evaluation_0/Rewards Std                      1.27056
evaluation_0/Rewards Max                      8.82321
evaluation_0/Rewards Min                     -0.695882
evaluation_0/Returns Mean                  3441.21
evaluation_0/Returns Std                   1004.76
evaluation_0/Returns Max                   4672.33
evaluation_0/Returns Min                   1869.35
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3441.21
time/epoch (s)                                0
time/total (s)                             5106.6
Epoch                                       328
---------------------------------------  ----------------
2022-11-16 17:40:06.349493 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 329 finished
---------------------------------------  ----------------
epoch                                       329
total_step                               334000
replay_pool/size                         334000
trainer/alpha                                 0.0633417
trainer/alpha_loss                           -0.495486
trainer/entropy                              -5.82042
trainer/qf_loss                              18.3534
trainer/policy_loss                        -289.118
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         289.487
trainer/entropy_penalty                      -0.368675
trainer/entropy_percentage                   -0.00127355
trainer/Q1Pred Mean                         289.551
trainer/Q1Pred Std                           74.9263
trainer/Q1Pred Max                          383.097
trainer/Q1Pred Min                            2.78802
trainer/Q2Pred Mean                         289.544
trainer/Q2Pred Std                           74.7808
trainer/Q2Pred Max                          379.739
trainer/Q2Pred Min                            6.79218
trainer/QTargetWithReg Mean                 289.503
trainer/QTargetWithReg Std                   75.0661
trainer/QTargetWithReg Max                  380.365
trainer/QTargetWithReg Min                    3.501
trainer/PolicyLossWithoutReg Mean           289.486
trainer/PolicyLossWithoutReg Std             73.7258
trainer/PolicyLossWithoutReg Max            379.132
trainer/PolicyLossWithoutReg Min             -1.30324
exploration/num steps total              334000
exploration/num paths total                1072
exploration/path length this epoch Mean     620
exploration/path length this epoch Std        0
exploration/path length this epoch Max      620
exploration/path length this epoch Min      620
exploration/Rewards Mean                      4.02479
exploration/Rewards Std                       1.27371
exploration/Rewards Max                       6.86939
exploration/Rewards Min                      -0.609564
exploration/Returns Mean                   2495.37
exploration/Returns Std                       0
exploration/Returns Max                    2495.37
exploration/Returns Min                    2495.37
exploration/Num Paths                         1
exploration/Average Returns                2495.37
evaluation_0/num steps total                  2.56439e+06
evaluation_0/num paths total               5943
evaluation_0/path length Mean               930.375
evaluation_0/path length Std                127.134
evaluation_0/path length Max               1000
evaluation_0/path length Min                641
evaluation_0/Rewards Mean                     4.74688
evaluation_0/Rewards Std                      1.25913
evaluation_0/Rewards Max                      9.03779
evaluation_0/Rewards Min                     -0.645889
evaluation_0/Returns Mean                  4416.38
evaluation_0/Returns Std                    688.641
evaluation_0/Returns Max                   5006.04
evaluation_0/Returns Min                   2836.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4416.38
time/epoch (s)                                0
time/total (s)                             5123.43
Epoch                                       329
---------------------------------------  ----------------
2022-11-16 17:40:22.875534 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 330 finished
---------------------------------------  ---------------
epoch                                       330
total_step                               335000
replay_pool/size                         335000
trainer/alpha                                 0.0648583
trainer/alpha_loss                            0.514491
trainer/entropy                              -6.18807
trainer/qf_loss                              26.7302
trainer/policy_loss                        -290.993
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         291.394
trainer/entropy_penalty                      -0.401348
trainer/entropy_percentage                   -0.00137734
trainer/Q1Pred Mean                         289.677
trainer/Q1Pred Std                           74.2435
trainer/Q1Pred Max                          382.201
trainer/Q1Pred Min                          -12.5089
trainer/Q2Pred Mean                         290.14
trainer/Q2Pred Std                           73.733
trainer/Q2Pred Max                          380.525
trainer/Q2Pred Min                           -5.63726
trainer/QTargetWithReg Mean                 289.519
trainer/QTargetWithReg Std                   74.0429
trainer/QTargetWithReg Max                  380.975
trainer/QTargetWithReg Min                   -0.895834
trainer/PolicyLossWithoutReg Mean           291.394
trainer/PolicyLossWithoutReg Std             71.4517
trainer/PolicyLossWithoutReg Max            380.101
trainer/PolicyLossWithoutReg Min             -5.02449
exploration/num steps total              335000
exploration/num paths total                1073
exploration/path length this epoch Mean     462
exploration/path length this epoch Std        0
exploration/path length this epoch Max      462
exploration/path length this epoch Min      462
exploration/Rewards Mean                      3.83666
exploration/Rewards Std                       1.45361
exploration/Rewards Max                       8.51168
exploration/Rewards Min                      -0.861056
exploration/Returns Mean                   1772.54
exploration/Returns Std                       0
exploration/Returns Max                    1772.54
exploration/Returns Min                    1772.54
exploration/Num Paths                         1
exploration/Average Returns                1772.54
evaluation_0/num steps total                  2.5718e+06
evaluation_0/num paths total               5951
evaluation_0/path length Mean               926.625
evaluation_0/path length Std                122.79
evaluation_0/path length Max               1000
evaluation_0/path length Min                633
evaluation_0/Rewards Mean                     4.52241
evaluation_0/Rewards Std                      1.16694
evaluation_0/Rewards Max                      8.08565
evaluation_0/Rewards Min                     -0.544591
evaluation_0/Returns Mean                  4190.58
evaluation_0/Returns Std                    643.308
evaluation_0/Returns Max                   4699.01
evaluation_0/Returns Min                   2699.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4190.58
time/epoch (s)                                0
time/total (s)                             5139.95
Epoch                                       330
---------------------------------------  ---------------
2022-11-16 17:40:39.655464 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 331 finished
---------------------------------------  ----------------
epoch                                       331
total_step                               336000
replay_pool/size                         336000
trainer/alpha                                 0.0654332
trainer/alpha_loss                           -0.825786
trainer/entropy                              -5.69715
trainer/qf_loss                              17.664
trainer/policy_loss                        -292.844
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.216
trainer/entropy_penalty                      -0.372783
trainer/entropy_percentage                   -0.00127136
trainer/Q1Pred Mean                         291.763
trainer/Q1Pred Std                           72.8685
trainer/Q1Pred Max                          372.172
trainer/Q1Pred Min                            3.76825
trainer/Q2Pred Mean                         291.674
trainer/Q2Pred Std                           73.2214
trainer/Q2Pred Max                          372.911
trainer/Q2Pred Min                            2.22268
trainer/QTargetWithReg Mean                 291.655
trainer/QTargetWithReg Std                   73.6803
trainer/QTargetWithReg Max                  372.825
trainer/QTargetWithReg Min                   -0.343416
trainer/PolicyLossWithoutReg Mean           293.216
trainer/PolicyLossWithoutReg Std             70.7685
trainer/PolicyLossWithoutReg Max            371.22
trainer/PolicyLossWithoutReg Min              8.27558
exploration/num steps total              336000
exploration/num paths total                1074
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.03149
exploration/Rewards Std                       0.926074
exploration/Rewards Max                       5.93204
exploration/Rewards Min                      -0.455313
exploration/Returns Mean                   4031.49
exploration/Returns Std                       0
exploration/Returns Max                    4031.49
exploration/Returns Min                    4031.49
exploration/Num Paths                         1
exploration/Average Returns                4031.49
evaluation_0/num steps total                  2.57955e+06
evaluation_0/num paths total               5963
evaluation_0/path length Mean               646
evaluation_0/path length Std                216.174
evaluation_0/path length Max               1000
evaluation_0/path length Min                243
evaluation_0/Rewards Mean                     4.42256
evaluation_0/Rewards Std                      1.3103
evaluation_0/Rewards Max                      9.11193
evaluation_0/Rewards Min                     -0.625932
evaluation_0/Returns Mean                  2856.98
evaluation_0/Returns Std                   1102.46
evaluation_0/Returns Max                   4618.12
evaluation_0/Returns Min                    828.228
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2856.98
time/epoch (s)                                0
time/total (s)                             5156.73
Epoch                                       331
---------------------------------------  ----------------
2022-11-16 17:40:56.096253 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 332 finished
---------------------------------------  ----------------
epoch                                       332
total_step                               337000
replay_pool/size                         337000
trainer/alpha                                 0.0646081
trainer/alpha_loss                            0.220868
trainer/entropy                              -6.08062
trainer/qf_loss                              38.7678
trainer/policy_loss                        -298.032
trainer/adversary_policy_loss                14.1711
trainer/policy_loss_without_entropy         298.425
trainer/entropy_penalty                      -0.392858
trainer/entropy_percentage                   -0.00131644
trainer/Q1Pred Mean                         295.391
trainer/Q1Pred Std                           64.0293
trainer/Q1Pred Max                          375.319
trainer/Q1Pred Min                           17.1188
trainer/Q2Pred Mean                         294.966
trainer/Q2Pred Std                           64.2858
trainer/Q2Pred Max                          376.602
trainer/Q2Pred Min                           12.3183
trainer/QTargetWithReg Mean                 294.614
trainer/QTargetWithReg Std                   66.1189
trainer/QTargetWithReg Max                  372.837
trainer/QTargetWithReg Min                    0.58619
trainer/PolicyLossWithoutReg Mean           298.425
trainer/PolicyLossWithoutReg Std             57.8551
trainer/PolicyLossWithoutReg Max            376.064
trainer/PolicyLossWithoutReg Min             21.4624
exploration/num steps total              337000
exploration/num paths total                1075
exploration/path length this epoch Mean     758
exploration/path length this epoch Std        0
exploration/path length this epoch Max      758
exploration/path length this epoch Min      758
exploration/Rewards Mean                      4.04429
exploration/Rewards Std                       1.5078
exploration/Rewards Max                       7.34884
exploration/Rewards Min                      -0.893535
exploration/Returns Mean                   3065.57
exploration/Returns Std                       0
exploration/Returns Max                    3065.57
exploration/Returns Min                    3065.57
exploration/Num Paths                         1
exploration/Average Returns                3065.57
evaluation_0/num steps total                  2.58732e+06
evaluation_0/num paths total               5972
evaluation_0/path length Mean               863
evaluation_0/path length Std                128.391
evaluation_0/path length Max               1000
evaluation_0/path length Min                614
evaluation_0/Rewards Mean                     4.80486
evaluation_0/Rewards Std                      1.28044
evaluation_0/Rewards Max                      9.20708
evaluation_0/Rewards Min                     -0.789968
evaluation_0/Returns Mean                  4146.59
evaluation_0/Returns Std                    627.2
evaluation_0/Returns Max                   5158.03
evaluation_0/Returns Min                   3015.97
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4146.59
time/epoch (s)                                0
time/total (s)                             5173.17
Epoch                                       332
---------------------------------------  ----------------
2022-11-16 17:41:12.962760 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 333 finished
---------------------------------------  ----------------
epoch                                       333
total_step                               338000
replay_pool/size                         338000
trainer/alpha                                 0.0637267
trainer/alpha_loss                           -0.795789
trainer/entropy                              -5.71096
trainer/qf_loss                              24.4746
trainer/policy_loss                        -289.069
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         289.433
trainer/entropy_penalty                      -0.363941
trainer/entropy_percentage                   -0.00125743
trainer/Q1Pred Mean                         287.715
trainer/Q1Pred Std                           75.5579
trainer/Q1Pred Max                          374.64
trainer/Q1Pred Min                           -2.52255
trainer/Q2Pred Mean                         287.841
trainer/Q2Pred Std                           76.078
trainer/Q2Pred Max                          372.154
trainer/Q2Pred Min                           -4.0664
trainer/QTargetWithReg Mean                 288.198
trainer/QTargetWithReg Std                   75.4151
trainer/QTargetWithReg Max                  373.542
trainer/QTargetWithReg Min                   -0.694556
trainer/PolicyLossWithoutReg Mean           289.433
trainer/PolicyLossWithoutReg Std             73.7327
trainer/PolicyLossWithoutReg Max            372.161
trainer/PolicyLossWithoutReg Min              0.408781
exploration/num steps total              338000
exploration/num paths total                1077
exploration/path length this epoch Mean     314.5
exploration/path length this epoch Std      306.5
exploration/path length this epoch Max      621
exploration/path length this epoch Min        8
exploration/Rewards Mean                      4.14828
exploration/Rewards Std                       1.26937
exploration/Rewards Max                       9.128
exploration/Rewards Min                      -0.731592
exploration/Returns Mean                   1304.63
exploration/Returns Std                    1304.95
exploration/Returns Max                    2609.59
exploration/Returns Min                      -0.318406
exploration/Num Paths                         2
exploration/Average Returns                1304.63
evaluation_0/num steps total                  2.59517e+06
evaluation_0/num paths total               5980
evaluation_0/path length Mean               981.625
evaluation_0/path length Std                 48.6157
evaluation_0/path length Max               1000
evaluation_0/path length Min                853
evaluation_0/Rewards Mean                     4.22133
evaluation_0/Rewards Std                      1.01928
evaluation_0/Rewards Max                      7.57463
evaluation_0/Rewards Min                     -0.662699
evaluation_0/Returns Mean                  4143.76
evaluation_0/Returns Std                    385.763
evaluation_0/Returns Max                   4763.51
evaluation_0/Returns Min                   3612.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4143.76
time/epoch (s)                                0
time/total (s)                             5190.03
Epoch                                       333
---------------------------------------  ----------------
2022-11-16 17:41:29.707760 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 334 finished
---------------------------------------  ----------------
epoch                                       334
total_step                               339000
replay_pool/size                         339000
trainer/alpha                                 0.0639343
trainer/alpha_loss                           -2.3546
trainer/entropy                              -5.14366
trainer/qf_loss                              20.9938
trainer/policy_loss                        -298.998
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.327
trainer/entropy_penalty                      -0.328856
trainer/entropy_percentage                   -0.00109865
trainer/Q1Pred Mean                         299.436
trainer/Q1Pred Std                           59.007
trainer/Q1Pred Max                          383.573
trainer/Q1Pred Min                           24.1315
trainer/Q2Pred Mean                         299.335
trainer/Q2Pred Std                           59.0029
trainer/Q2Pred Max                          377.644
trainer/Q2Pred Min                           24.8497
trainer/QTargetWithReg Mean                 299.453
trainer/QTargetWithReg Std                   59.0208
trainer/QTargetWithReg Max                  384.527
trainer/QTargetWithReg Min                   26.5405
trainer/PolicyLossWithoutReg Mean           299.327
trainer/PolicyLossWithoutReg Std             58.282
trainer/PolicyLossWithoutReg Max            379.503
trainer/PolicyLossWithoutReg Min             27.607
exploration/num steps total              339000
exploration/num paths total                1078
exploration/path length this epoch Mean     743
exploration/path length this epoch Std        0
exploration/path length this epoch Max      743
exploration/path length this epoch Min      743
exploration/Rewards Mean                      4.27609
exploration/Rewards Std                       1.35229
exploration/Rewards Max                       8.83969
exploration/Rewards Min                      -0.412146
exploration/Returns Mean                   3177.14
exploration/Returns Std                       0
exploration/Returns Max                    3177.14
exploration/Returns Min                    3177.14
exploration/Num Paths                         1
exploration/Average Returns                3177.14
evaluation_0/num steps total                  2.60286e+06
evaluation_0/num paths total               5991
evaluation_0/path length Mean               698.364
evaluation_0/path length Std                259.443
evaluation_0/path length Max               1000
evaluation_0/path length Min                247
evaluation_0/Rewards Mean                     4.49688
evaluation_0/Rewards Std                      1.34469
evaluation_0/Rewards Max                      8.85973
evaluation_0/Rewards Min                     -0.796583
evaluation_0/Returns Mean                  3140.46
evaluation_0/Returns Std                   1294.72
evaluation_0/Returns Max                   4679.69
evaluation_0/Returns Min                    867.252
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3140.46
time/epoch (s)                                0
time/total (s)                             5206.78
Epoch                                       334
---------------------------------------  ----------------
2022-11-16 17:41:46.571656 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 335 finished
---------------------------------------  ----------------
epoch                                       335
total_step                               340000
replay_pool/size                         340000
trainer/alpha                                 0.0630291
trainer/alpha_loss                            0.824636
trainer/entropy                              -6.29832
trainer/qf_loss                              35.7725
trainer/policy_loss                        -294.137
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.534
trainer/entropy_penalty                      -0.396978
trainer/entropy_percentage                   -0.00134782
trainer/Q1Pred Mean                         292.831
trainer/Q1Pred Std                           67.6909
trainer/Q1Pred Max                          377.828
trainer/Q1Pred Min                          -18.923
trainer/Q2Pred Mean                         292.263
trainer/Q2Pred Std                           68.2748
trainer/Q2Pred Max                          382.401
trainer/Q2Pred Min                           -3.04608
trainer/QTargetWithReg Mean                 291.685
trainer/QTargetWithReg Std                   68.1145
trainer/QTargetWithReg Max                  380.916
trainer/QTargetWithReg Min                   -0.0503799
trainer/PolicyLossWithoutReg Mean           294.534
trainer/PolicyLossWithoutReg Std             65.085
trainer/PolicyLossWithoutReg Max            382.059
trainer/PolicyLossWithoutReg Min             25.404
exploration/num steps total              340000
exploration/num paths total                1080
exploration/path length this epoch Mean     394.5
exploration/path length this epoch Std      323.5
exploration/path length this epoch Max      718
exploration/path length this epoch Min       71
exploration/Rewards Mean                      3.81326
exploration/Rewards Std                       1.22746
exploration/Rewards Max                       6.2311
exploration/Rewards Min                      -0.857658
exploration/Returns Mean                   1504.33
exploration/Returns Std                    1361.49
exploration/Returns Max                    2865.82
exploration/Returns Min                     142.84
exploration/Num Paths                         2
exploration/Average Returns                1504.33
evaluation_0/num steps total                  2.61048e+06
evaluation_0/num paths total               6003
evaluation_0/path length Mean               635.75
evaluation_0/path length Std                201.305
evaluation_0/path length Max               1000
evaluation_0/path length Min                340
evaluation_0/Rewards Mean                     4.43854
evaluation_0/Rewards Std                      1.4225
evaluation_0/Rewards Max                     11.3291
evaluation_0/Rewards Min                     -0.841275
evaluation_0/Returns Mean                  2821.8
evaluation_0/Returns Std                   1062.88
evaluation_0/Returns Max                   4911.91
evaluation_0/Returns Min                   1328.53
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2821.8
time/epoch (s)                                0
time/total (s)                             5223.64
Epoch                                       335
---------------------------------------  ----------------
2022-11-16 17:42:04.349063 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 336 finished
---------------------------------------  ----------------
epoch                                       336
total_step                               341000
replay_pool/size                         341000
trainer/alpha                                 0.0623458
trainer/alpha_loss                            1.05441
trainer/entropy                              -6.37995
trainer/qf_loss                              17.4934
trainer/policy_loss                        -287.9
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         288.298
trainer/entropy_penalty                      -0.397763
trainer/entropy_percentage                   -0.0013797
trainer/Q1Pred Mean                         287.46
trainer/Q1Pred Std                           69.4533
trainer/Q1Pred Max                          380.139
trainer/Q1Pred Min                            2.99163
trainer/Q2Pred Mean                         287.159
trainer/Q2Pred Std                           69.5737
trainer/Q2Pred Max                          376.513
trainer/Q2Pred Min                           -1.01886
trainer/QTargetWithReg Mean                 287.759
trainer/QTargetWithReg Std                   69.6131
trainer/QTargetWithReg Max                  378.348
trainer/QTargetWithReg Min                   -8.11663
trainer/PolicyLossWithoutReg Mean           288.298
trainer/PolicyLossWithoutReg Std             67.7175
trainer/PolicyLossWithoutReg Max            377.806
trainer/PolicyLossWithoutReg Min              3.16275
exploration/num steps total              341000
exploration/num paths total                1081
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41142
exploration/Rewards Std                       1.08577
exploration/Rewards Max                       6.75793
exploration/Rewards Min                      -0.793848
exploration/Returns Mean                   4411.42
exploration/Returns Std                       0
exploration/Returns Max                    4411.42
exploration/Returns Min                    4411.42
exploration/Num Paths                         1
exploration/Average Returns                4411.42
evaluation_0/num steps total                  2.61848e+06
evaluation_0/num paths total               6019
evaluation_0/path length Mean               499.5
evaluation_0/path length Std                193.818
evaluation_0/path length Max                810
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     4.42289
evaluation_0/Rewards Std                      1.44733
evaluation_0/Rewards Max                      8.76577
evaluation_0/Rewards Min                     -0.708603
evaluation_0/Returns Mean                  2209.23
evaluation_0/Returns Std                   1007.01
evaluation_0/Returns Max                   3632.82
evaluation_0/Returns Min                    299.978
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               2209.23
time/epoch (s)                                0
time/total (s)                             5241.42
Epoch                                       336
---------------------------------------  ----------------
2022-11-16 17:42:20.770079 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 337 finished
---------------------------------------  ---------------
epoch                                       337
total_step                               342000
replay_pool/size                         342000
trainer/alpha                                 0.0639817
trainer/alpha_loss                           -0.349648
trainer/entropy                              -5.87282
trainer/qf_loss                              26.8063
trainer/policy_loss                        -300.7
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.076
trainer/entropy_penalty                      -0.375753
trainer/entropy_percentage                   -0.00124803
trainer/Q1Pred Mean                         300.315
trainer/Q1Pred Std                           63.0706
trainer/Q1Pred Max                          380.875
trainer/Q1Pred Min                           44.3179
trainer/Q2Pred Mean                         299.725
trainer/Q2Pred Std                           62.1168
trainer/Q2Pred Max                          379.378
trainer/Q2Pred Min                           48.4405
trainer/QTargetWithReg Mean                 299.799
trainer/QTargetWithReg Std                   62.6372
trainer/QTargetWithReg Max                  382.529
trainer/QTargetWithReg Min                   40.5439
trainer/PolicyLossWithoutReg Mean           301.076
trainer/PolicyLossWithoutReg Std             60.5806
trainer/PolicyLossWithoutReg Max            379.459
trainer/PolicyLossWithoutReg Min             54.7011
exploration/num steps total              342000
exploration/num paths total                1082
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64842
exploration/Rewards Std                       1.10004
exploration/Rewards Max                       7.79309
exploration/Rewards Min                      -0.590478
exploration/Returns Mean                   4648.42
exploration/Returns Std                       0
exploration/Returns Max                    4648.42
exploration/Returns Min                    4648.42
exploration/Num Paths                         1
exploration/Average Returns                4648.42
evaluation_0/num steps total                  2.6263e+06
evaluation_0/num paths total               6027
evaluation_0/path length Mean               977.75
evaluation_0/path length Std                 58.868
evaluation_0/path length Max               1000
evaluation_0/path length Min                822
evaluation_0/Rewards Mean                     4.4269
evaluation_0/Rewards Std                      1.15189
evaluation_0/Rewards Max                      7.83855
evaluation_0/Rewards Min                     -0.579036
evaluation_0/Returns Mean                  4328.4
evaluation_0/Returns Std                    296.142
evaluation_0/Returns Max                   4535.13
evaluation_0/Returns Min                   3613.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4328.4
time/epoch (s)                                0
time/total (s)                             5257.84
Epoch                                       337
---------------------------------------  ---------------
2022-11-16 17:42:37.685022 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 338 finished
---------------------------------------  ----------------
epoch                                       338
total_step                               343000
replay_pool/size                         343000
trainer/alpha                                 0.0627901
trainer/alpha_loss                           -0.528365
trainer/entropy                              -5.80911
trainer/qf_loss                              32.8538
trainer/policy_loss                        -295.639
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.004
trainer/entropy_penalty                      -0.364754
trainer/entropy_percentage                   -0.00123226
trainer/Q1Pred Mean                         294.328
trainer/Q1Pred Std                           62.4052
trainer/Q1Pred Max                          380.091
trainer/Q1Pred Min                           11.8455
trainer/Q2Pred Mean                         294.187
trainer/Q2Pred Std                           61.6613
trainer/Q2Pred Max                          380.306
trainer/Q2Pred Min                            8.45866
trainer/QTargetWithReg Mean                 295.683
trainer/QTargetWithReg Std                   62.6125
trainer/QTargetWithReg Max                  377.96
trainer/QTargetWithReg Min                    4.93401
trainer/PolicyLossWithoutReg Mean           296.004
trainer/PolicyLossWithoutReg Std             60.2144
trainer/PolicyLossWithoutReg Max            379.947
trainer/PolicyLossWithoutReg Min             10.4957
exploration/num steps total              343000
exploration/num paths total                1083
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.2368
exploration/Rewards Std                       1.30603
exploration/Rewards Max                       6.1971
exploration/Rewards Min                      -2.82032
exploration/Returns Mean                   3236.8
exploration/Returns Std                       0
exploration/Returns Max                    3236.8
exploration/Returns Min                    3236.8
exploration/Num Paths                         1
exploration/Average Returns                3236.8
evaluation_0/num steps total                  2.63367e+06
evaluation_0/num paths total               6037
evaluation_0/path length Mean               736.8
evaluation_0/path length Std                188.757
evaluation_0/path length Max               1000
evaluation_0/path length Min                398
evaluation_0/Rewards Mean                     4.36065
evaluation_0/Rewards Std                      1.26985
evaluation_0/Rewards Max                      9.92421
evaluation_0/Rewards Min                     -0.649424
evaluation_0/Returns Mean                  3212.92
evaluation_0/Returns Std                    913.51
evaluation_0/Returns Max                   4442.4
evaluation_0/Returns Min                   1621.28
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3212.92
time/epoch (s)                                0
time/total (s)                             5274.75
Epoch                                       338
---------------------------------------  ----------------
2022-11-16 17:42:54.282814 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 339 finished
---------------------------------------  ---------------
epoch                                       339
total_step                               344000
replay_pool/size                         344000
trainer/alpha                                 0.0621497
trainer/alpha_loss                            0.121339
trainer/entropy                              -6.04368
trainer/qf_loss                              19.6796
trainer/policy_loss                        -292.197
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         292.573
trainer/entropy_penalty                      -0.375613
trainer/entropy_percentage                   -0.00128383
trainer/Q1Pred Mean                         292.003
trainer/Q1Pred Std                           70.35
trainer/Q1Pred Max                          380.447
trainer/Q1Pred Min                            4.09481
trainer/Q2Pred Mean                         291.381
trainer/Q2Pred Std                           69.4168
trainer/Q2Pred Max                          379.709
trainer/Q2Pred Min                            3.17053
trainer/QTargetWithReg Mean                 291.833
trainer/QTargetWithReg Std                   69.8155
trainer/QTargetWithReg Max                  380.675
trainer/QTargetWithReg Min                    9.35271
trainer/PolicyLossWithoutReg Mean           292.573
trainer/PolicyLossWithoutReg Std             67.7178
trainer/PolicyLossWithoutReg Max            378
trainer/PolicyLossWithoutReg Min              4.37623
exploration/num steps total              344000
exploration/num paths total                1086
exploration/path length this epoch Mean     286.667
exploration/path length this epoch Std      158.974
exploration/path length this epoch Max      460
exploration/path length this epoch Min       76
exploration/Rewards Mean                      3.58511
exploration/Rewards Std                       1.20557
exploration/Rewards Max                       6.11248
exploration/Rewards Min                      -0.737089
exploration/Returns Mean                   1027.73
exploration/Returns Std                     620.56
exploration/Returns Max                    1663.8
exploration/Returns Min                     186.052
exploration/Num Paths                         3
exploration/Average Returns                1027.73
evaluation_0/num steps total                  2.641e+06
evaluation_0/num paths total               6047
evaluation_0/path length Mean               733.8
evaluation_0/path length Std                194.521
evaluation_0/path length Max               1000
evaluation_0/path length Min                460
evaluation_0/Rewards Mean                     4.07396
evaluation_0/Rewards Std                      1.40759
evaluation_0/Rewards Max                     11.2438
evaluation_0/Rewards Min                     -0.689055
evaluation_0/Returns Mean                  2989.47
evaluation_0/Returns Std                    871.117
evaluation_0/Returns Max                   4347.4
evaluation_0/Returns Min                   1765.56
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2989.47
time/epoch (s)                                0
time/total (s)                             5291.35
Epoch                                       339
---------------------------------------  ---------------
2022-11-16 17:43:11.374199 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 340 finished
---------------------------------------  ----------------
epoch                                       340
total_step                               345000
replay_pool/size                         345000
trainer/alpha                                 0.0641157
trainer/alpha_loss                            1.21948
trainer/entropy                              -6.44393
trainer/qf_loss                              19.039
trainer/policy_loss                        -298.038
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.451
trainer/entropy_penalty                      -0.413157
trainer/entropy_percentage                   -0.00138434
trainer/Q1Pred Mean                         297.492
trainer/Q1Pred Std                           63.291
trainer/Q1Pred Max                          375.234
trainer/Q1Pred Min                            5.97363
trainer/Q2Pred Mean                         297.717
trainer/Q2Pred Std                           63.374
trainer/Q2Pred Max                          378.406
trainer/Q2Pred Min                           -4.75012
trainer/QTargetWithReg Mean                 297.047
trainer/QTargetWithReg Std                   64.0307
trainer/QTargetWithReg Max                  373.67
trainer/QTargetWithReg Min                   -5.20579
trainer/PolicyLossWithoutReg Mean           298.451
trainer/PolicyLossWithoutReg Std             62.4374
trainer/PolicyLossWithoutReg Max            375.034
trainer/PolicyLossWithoutReg Min             -6.71046
exploration/num steps total              345000
exploration/num paths total                1088
exploration/path length this epoch Mean      64
exploration/path length this epoch Std       18
exploration/path length this epoch Max       82
exploration/path length this epoch Min       46
exploration/Rewards Mean                      2.07539
exploration/Rewards Std                       1.43315
exploration/Rewards Max                       4.78683
exploration/Rewards Min                      -0.641999
exploration/Returns Mean                    132.825
exploration/Returns Std                      44.7046
exploration/Returns Max                     177.529
exploration/Returns Min                      88.1201
exploration/Num Paths                         2
exploration/Average Returns                 132.825
evaluation_0/num steps total                  2.64862e+06
evaluation_0/num paths total               6055
evaluation_0/path length Mean               952.125
evaluation_0/path length Std                126.665
evaluation_0/path length Max               1000
evaluation_0/path length Min                617
evaluation_0/Rewards Mean                     4.11944
evaluation_0/Rewards Std                      1.09408
evaluation_0/Rewards Max                      6.82631
evaluation_0/Rewards Min                     -0.58266
evaluation_0/Returns Mean                  3922.22
evaluation_0/Returns Std                    687.039
evaluation_0/Returns Max                   4452.42
evaluation_0/Returns Min                   2191.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3922.22
time/epoch (s)                                0
time/total (s)                             5308.44
Epoch                                       340
---------------------------------------  ----------------
2022-11-16 17:43:27.722145 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 341 finished
---------------------------------------  ----------------
epoch                                       341
total_step                               346000
replay_pool/size                         346000
trainer/alpha                                 0.0654774
trainer/alpha_loss                            0.120027
trainer/entropy                              -6.04403
trainer/qf_loss                              20.6936
trainer/policy_loss                        -290.511
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         290.906
trainer/entropy_penalty                      -0.395747
trainer/entropy_percentage                   -0.00136039
trainer/Q1Pred Mean                         289.959
trainer/Q1Pred Std                           81.4934
trainer/Q1Pred Max                          379.239
trainer/Q1Pred Min                          -19.3259
trainer/Q2Pred Mean                         289.394
trainer/Q2Pred Std                           81.0674
trainer/Q2Pred Max                          383.871
trainer/Q2Pred Min                          -24.4857
trainer/QTargetWithReg Mean                 289.807
trainer/QTargetWithReg Std                   80.844
trainer/QTargetWithReg Max                  384.934
trainer/QTargetWithReg Min                  -29.8653
trainer/PolicyLossWithoutReg Mean           290.906
trainer/PolicyLossWithoutReg Std             79.6229
trainer/PolicyLossWithoutReg Max            380.977
trainer/PolicyLossWithoutReg Min            -19.8324
exploration/num steps total              346000
exploration/num paths total                1089
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.10814
exploration/Rewards Std                       0.943037
exploration/Rewards Max                       6.43216
exploration/Rewards Min                      -0.565095
exploration/Returns Mean                   4108.14
exploration/Returns Std                       0
exploration/Returns Max                    4108.14
exploration/Returns Min                    4108.14
exploration/Num Paths                         1
exploration/Average Returns                4108.14
evaluation_0/num steps total                  2.65644e+06
evaluation_0/num paths total               6065
evaluation_0/path length Mean               781.5
evaluation_0/path length Std                193.182
evaluation_0/path length Max               1000
evaluation_0/path length Min                494
evaluation_0/Rewards Mean                     4.39009
evaluation_0/Rewards Std                      1.32312
evaluation_0/Rewards Max                      9.81245
evaluation_0/Rewards Min                     -0.532141
evaluation_0/Returns Mean                  3430.85
evaluation_0/Returns Std                    914.57
evaluation_0/Returns Max                   4512.37
evaluation_0/Returns Min                   2010.85
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3430.85
time/epoch (s)                                0
time/total (s)                             5324.79
Epoch                                       341
---------------------------------------  ----------------
2022-11-16 17:43:42.621297 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 342 finished
---------------------------------------  ----------------
epoch                                       342
total_step                               347000
replay_pool/size                         347000
trainer/alpha                                 0.0656913
trainer/alpha_loss                           -0.26557
trainer/entropy                              -5.90246
trainer/qf_loss                              22.8998
trainer/policy_loss                        -289.518
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         289.906
trainer/entropy_penalty                      -0.38774
trainer/entropy_percentage                   -0.00133747
trainer/Q1Pred Mean                         288.554
trainer/Q1Pred Std                           73.5024
trainer/Q1Pred Max                          382.835
trainer/Q1Pred Min                          -13.2121
trainer/Q2Pred Mean                         288.688
trainer/Q2Pred Std                           73.6456
trainer/Q2Pred Max                          384.44
trainer/Q2Pred Min                          -27.1898
trainer/QTargetWithReg Mean                 288.373
trainer/QTargetWithReg Std                   73.7811
trainer/QTargetWithReg Max                  384.26
trainer/QTargetWithReg Min                  -25.3081
trainer/PolicyLossWithoutReg Mean           289.906
trainer/PolicyLossWithoutReg Std             72.6894
trainer/PolicyLossWithoutReg Max            383.498
trainer/PolicyLossWithoutReg Min            -10.0509
exploration/num steps total              347000
exploration/num paths total                1090
exploration/path length this epoch Mean     374
exploration/path length this epoch Std        0
exploration/path length this epoch Max      374
exploration/path length this epoch Min      374
exploration/Rewards Mean                      3.88871
exploration/Rewards Std                       1.34669
exploration/Rewards Max                       7.28723
exploration/Rewards Min                      -0.526911
exploration/Returns Mean                   1454.38
exploration/Returns Std                       0
exploration/Returns Max                    1454.38
exploration/Returns Min                    1454.38
exploration/Num Paths                         1
exploration/Average Returns                1454.38
evaluation_0/num steps total                  2.66444e+06
evaluation_0/num paths total               6073
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.29399
evaluation_0/Rewards Std                      1.11433
evaluation_0/Rewards Max                      7.26676
evaluation_0/Rewards Min                     -0.701797
evaluation_0/Returns Mean                  4293.99
evaluation_0/Returns Std                    144.841
evaluation_0/Returns Max                   4592.96
evaluation_0/Returns Min                   4063.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4293.99
time/epoch (s)                                0
time/total (s)                             5339.69
Epoch                                       342
---------------------------------------  ----------------
2022-11-16 17:43:59.422206 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 343 finished
---------------------------------------  ----------------
epoch                                       343
total_step                               348000
replay_pool/size                         348000
trainer/alpha                                 0.0642003
trainer/alpha_loss                            0.0259198
trainer/entropy                              -6.00944
trainer/qf_loss                              17.2962
trainer/policy_loss                        -296.112
trainer/adversary_policy_loss                14.1966
trainer/policy_loss_without_entropy         296.498
trainer/entropy_penalty                      -0.385808
trainer/entropy_percentage                   -0.00130122
trainer/Q1Pred Mean                         295.976
trainer/Q1Pred Std                           68.173
trainer/Q1Pred Max                          380.368
trainer/Q1Pred Min                            9.15688
trainer/Q2Pred Mean                         295.824
trainer/Q2Pred Std                           68.4827
trainer/Q2Pred Max                          379.295
trainer/Q2Pred Min                            3.71128
trainer/QTargetWithReg Mean                 295.485
trainer/QTargetWithReg Std                   69.3093
trainer/QTargetWithReg Max                  379.046
trainer/QTargetWithReg Min                    5.06255
trainer/PolicyLossWithoutReg Mean           296.498
trainer/PolicyLossWithoutReg Std             66.9641
trainer/PolicyLossWithoutReg Max            377.791
trainer/PolicyLossWithoutReg Min              5.71564
exploration/num steps total              348000
exploration/num paths total                1091
exploration/path length this epoch Mean     601
exploration/path length this epoch Std        0
exploration/path length this epoch Max      601
exploration/path length this epoch Min      601
exploration/Rewards Mean                      4.4456
exploration/Rewards Std                       1.3723
exploration/Rewards Max                       7.46053
exploration/Rewards Min                      -0.769436
exploration/Returns Mean                   2671.81
exploration/Returns Std                       0
exploration/Returns Max                    2671.81
exploration/Returns Min                    2671.81
exploration/Num Paths                         1
exploration/Average Returns                2671.81
evaluation_0/num steps total                  2.67182e+06
evaluation_0/num paths total               6084
evaluation_0/path length Mean               671.545
evaluation_0/path length Std                214.437
evaluation_0/path length Max               1000
evaluation_0/path length Min                362
evaluation_0/Rewards Mean                     4.42683
evaluation_0/Rewards Std                      1.33478
evaluation_0/Rewards Max                      9.60169
evaluation_0/Rewards Min                     -0.44372
evaluation_0/Returns Mean                  2972.82
evaluation_0/Returns Std                   1112.56
evaluation_0/Returns Max                   4801.24
evaluation_0/Returns Min                   1309.24
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2972.82
time/epoch (s)                                0
time/total (s)                             5356.49
Epoch                                       343
---------------------------------------  ----------------
2022-11-16 17:44:15.813509 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 344 finished
---------------------------------------  ----------------
epoch                                       344
total_step                               349000
replay_pool/size                         349000
trainer/alpha                                 0.0647366
trainer/alpha_loss                           -0.316052
trainer/entropy                              -5.88455
trainer/qf_loss                              24.2123
trainer/policy_loss                        -297.933
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.314
trainer/entropy_penalty                      -0.380946
trainer/entropy_percentage                   -0.001277
trainer/Q1Pred Mean                         296.939
trainer/Q1Pred Std                           61.4906
trainer/Q1Pred Max                          378.811
trainer/Q1Pred Min                           27.319
trainer/Q2Pred Mean                         296.938
trainer/Q2Pred Std                           61.5263
trainer/Q2Pred Max                          380.823
trainer/Q2Pred Min                           23.7365
trainer/QTargetWithReg Mean                 297.732
trainer/QTargetWithReg Std                   61.9954
trainer/QTargetWithReg Max                  381.789
trainer/QTargetWithReg Min                   25.6973
trainer/PolicyLossWithoutReg Mean           298.314
trainer/PolicyLossWithoutReg Std             60.9186
trainer/PolicyLossWithoutReg Max            382.303
trainer/PolicyLossWithoutReg Min             24.2995
exploration/num steps total              349000
exploration/num paths total                1092
exploration/path length this epoch Mean     765
exploration/path length this epoch Std        0
exploration/path length this epoch Max      765
exploration/path length this epoch Min      765
exploration/Rewards Mean                      4.47926
exploration/Rewards Std                       1.41736
exploration/Rewards Max                       7.91573
exploration/Rewards Min                      -0.504837
exploration/Returns Mean                   3426.64
exploration/Returns Std                       0
exploration/Returns Max                    3426.64
exploration/Returns Min                    3426.64
exploration/Num Paths                         1
exploration/Average Returns                3426.64
evaluation_0/num steps total                  2.67907e+06
evaluation_0/num paths total               6093
evaluation_0/path length Mean               805
evaluation_0/path length Std                211.139
evaluation_0/path length Max               1000
evaluation_0/path length Min                466
evaluation_0/Rewards Mean                     4.56682
evaluation_0/Rewards Std                      1.15355
evaluation_0/Rewards Max                      9.59974
evaluation_0/Rewards Min                     -0.605566
evaluation_0/Returns Mean                  3676.29
evaluation_0/Returns Std                   1033.62
evaluation_0/Returns Max                   4799.7
evaluation_0/Returns Min                   2232.43
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3676.29
time/epoch (s)                                0
time/total (s)                             5372.88
Epoch                                       344
---------------------------------------  ----------------
2022-11-16 17:44:32.599496 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 345 finished
---------------------------------------  ----------------
epoch                                       345
total_step                               350000
replay_pool/size                         350000
trainer/alpha                                 0.0652032
trainer/alpha_loss                           -1.73263
trainer/entropy                              -5.36535
trainer/qf_loss                              18.6176
trainer/policy_loss                        -304.555
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.905
trainer/entropy_penalty                      -0.349838
trainer/entropy_percentage                   -0.00114737
trainer/Q1Pred Mean                         304.115
trainer/Q1Pred Std                           62.5869
trainer/Q1Pred Max                          384.5
trainer/Q1Pred Min                            1.26829
trainer/Q2Pred Mean                         304.378
trainer/Q2Pred Std                           62.5639
trainer/Q2Pred Max                          386.331
trainer/Q2Pred Min                           10.0771
trainer/QTargetWithReg Mean                 303.836
trainer/QTargetWithReg Std                   62.7457
trainer/QTargetWithReg Max                  384.923
trainer/QTargetWithReg Min                    1.50804
trainer/PolicyLossWithoutReg Mean           304.905
trainer/PolicyLossWithoutReg Std             61.3165
trainer/PolicyLossWithoutReg Max            385.679
trainer/PolicyLossWithoutReg Min             12.9358
exploration/num steps total              350000
exploration/num paths total                1093
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37394
exploration/Rewards Std                       1.23879
exploration/Rewards Max                       7.49934
exploration/Rewards Min                      -0.603333
exploration/Returns Mean                   4373.94
exploration/Returns Std                       0
exploration/Returns Max                    4373.94
exploration/Returns Min                    4373.94
exploration/Num Paths                         1
exploration/Average Returns                4373.94
evaluation_0/num steps total                  2.68691e+06
evaluation_0/num paths total               6107
evaluation_0/path length Mean               560.143
evaluation_0/path length Std                229.528
evaluation_0/path length Max               1000
evaluation_0/path length Min                290
evaluation_0/Rewards Mean                     4.32813
evaluation_0/Rewards Std                      1.29219
evaluation_0/Rewards Max                     10.4058
evaluation_0/Rewards Min                     -0.612194
evaluation_0/Returns Mean                  2424.37
evaluation_0/Returns Std                   1160.8
evaluation_0/Returns Max                   4573.37
evaluation_0/Returns Min                   1073.79
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2424.37
time/epoch (s)                                0
time/total (s)                             5389.67
Epoch                                       345
---------------------------------------  ----------------
2022-11-16 17:44:49.815085 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 346 finished
---------------------------------------  ----------------
epoch                                       346
total_step                               351000
replay_pool/size                         351000
trainer/alpha                                 0.063563
trainer/alpha_loss                           -0.511506
trainer/entropy                              -5.81438
trainer/qf_loss                              30.0932
trainer/policy_loss                        -295.951
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.321
trainer/entropy_penalty                      -0.36958
trainer/entropy_percentage                   -0.00124723
trainer/Q1Pred Mean                         295.126
trainer/Q1Pred Std                           64.4156
trainer/Q1Pred Max                          394.226
trainer/Q1Pred Min                            5.33577
trainer/Q2Pred Mean                         294.816
trainer/Q2Pred Std                           63.928
trainer/Q2Pred Max                          395.496
trainer/Q2Pred Min                           -3.25399
trainer/QTargetWithReg Mean                 295.276
trainer/QTargetWithReg Std                   63.6405
trainer/QTargetWithReg Max                  396.949
trainer/QTargetWithReg Min                    4.9247
trainer/PolicyLossWithoutReg Mean           296.321
trainer/PolicyLossWithoutReg Std             62.6807
trainer/PolicyLossWithoutReg Max            395.235
trainer/PolicyLossWithoutReg Min              3.35509
exploration/num steps total              351000
exploration/num paths total                1094
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51404
exploration/Rewards Std                       1.14355
exploration/Rewards Max                       7.47745
exploration/Rewards Min                      -0.550117
exploration/Returns Mean                   4514.04
exploration/Returns Std                       0
exploration/Returns Max                    4514.04
exploration/Returns Min                    4514.04
exploration/Num Paths                         1
exploration/Average Returns                4514.04
evaluation_0/num steps total                  2.69482e+06
evaluation_0/num paths total               6127
evaluation_0/path length Mean               395.65
evaluation_0/path length Std                204.272
evaluation_0/path length Max                866
evaluation_0/path length Min                 72
evaluation_0/Rewards Mean                     4.13328
evaluation_0/Rewards Std                      1.51426
evaluation_0/Rewards Max                     11.6898
evaluation_0/Rewards Min                     -0.629005
evaluation_0/Returns Mean                  1635.33
evaluation_0/Returns Std                    967.411
evaluation_0/Returns Max                   4028
evaluation_0/Returns Min                    179.837
evaluation_0/Num Paths                       20
evaluation_0/Average Returns               1635.33
time/epoch (s)                                0
time/total (s)                             5406.88
Epoch                                       346
---------------------------------------  ----------------
2022-11-16 17:45:06.476477 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 347 finished
---------------------------------------  ----------------
epoch                                       347
total_step                               352000
replay_pool/size                         352000
trainer/alpha                                 0.0648378
trainer/alpha_loss                            0.473821
trainer/entropy                              -6.17318
trainer/qf_loss                              16.6805
trainer/policy_loss                        -295.8
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.2
trainer/entropy_penalty                      -0.400255
trainer/entropy_percentage                   -0.0013513
trainer/Q1Pred Mean                         295.657
trainer/Q1Pred Std                           71.4855
trainer/Q1Pred Max                          376.141
trainer/Q1Pred Min                           -9.04522
trainer/Q2Pred Mean                         294.795
trainer/Q2Pred Std                           71.5983
trainer/Q2Pred Max                          375.976
trainer/Q2Pred Min                           -5.50671
trainer/QTargetWithReg Mean                 295.003
trainer/QTargetWithReg Std                   70.9475
trainer/QTargetWithReg Max                  378.019
trainer/QTargetWithReg Min                   -2.65049
trainer/PolicyLossWithoutReg Mean           296.2
trainer/PolicyLossWithoutReg Std             71.0066
trainer/PolicyLossWithoutReg Max            378.172
trainer/PolicyLossWithoutReg Min             -0.279198
exploration/num steps total              352000
exploration/num paths total                1095
exploration/path length this epoch Mean     337
exploration/path length this epoch Std        0
exploration/path length this epoch Max      337
exploration/path length this epoch Min      337
exploration/Rewards Mean                      3.40606
exploration/Rewards Std                       1.24885
exploration/Rewards Max                       7.53208
exploration/Rewards Min                      -0.577853
exploration/Returns Mean                   1147.84
exploration/Returns Std                       0
exploration/Returns Max                    1147.84
exploration/Returns Min                    1147.84
exploration/Num Paths                         1
exploration/Average Returns                1147.84
evaluation_0/num steps total                  2.70264e+06
evaluation_0/num paths total               6145
evaluation_0/path length Mean               434.111
evaluation_0/path length Std                178.142
evaluation_0/path length Max                805
evaluation_0/path length Min                198
evaluation_0/Rewards Mean                     4.397
evaluation_0/Rewards Std                      1.46102
evaluation_0/Rewards Max                     11.2719
evaluation_0/Rewards Min                     -0.759073
evaluation_0/Returns Mean                  1908.79
evaluation_0/Returns Std                    930.792
evaluation_0/Returns Max                   4024.65
evaluation_0/Returns Min                    722.57
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1908.79
time/epoch (s)                                0
time/total (s)                             5423.54
Epoch                                       347
---------------------------------------  ----------------
2022-11-16 17:45:21.397482 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 348 finished
---------------------------------------  ----------------
epoch                                       348
total_step                               353000
replay_pool/size                         353000
trainer/alpha                                 0.0647684
trainer/alpha_loss                            0.365542
trainer/entropy                              -6.13355
trainer/qf_loss                              21.4589
trainer/policy_loss                        -292.525
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         292.922
trainer/entropy_penalty                      -0.39726
trainer/entropy_percentage                   -0.0013562
trainer/Q1Pred Mean                         291.024
trainer/Q1Pred Std                           71.4751
trainer/Q1Pred Max                          377.683
trainer/Q1Pred Min                           -0.380038
trainer/Q2Pred Mean                         291.991
trainer/Q2Pred Std                           71.363
trainer/Q2Pred Max                          382.508
trainer/Q2Pred Min                           -1.15359
trainer/QTargetWithReg Mean                 291.099
trainer/QTargetWithReg Std                   71.2451
trainer/QTargetWithReg Max                  381.363
trainer/QTargetWithReg Min                   -1.01378
trainer/PolicyLossWithoutReg Mean           292.922
trainer/PolicyLossWithoutReg Std             70.5125
trainer/PolicyLossWithoutReg Max            379.101
trainer/PolicyLossWithoutReg Min             -5.90468
exploration/num steps total              353000
exploration/num paths total                1096
exploration/path length this epoch Mean     810
exploration/path length this epoch Std        0
exploration/path length this epoch Max      810
exploration/path length this epoch Min      810
exploration/Rewards Mean                      4.37761
exploration/Rewards Std                       1.37165
exploration/Rewards Max                       9.51458
exploration/Rewards Min                      -0.816951
exploration/Returns Mean                   3545.87
exploration/Returns Std                       0
exploration/Returns Max                    3545.87
exploration/Returns Min                    3545.87
exploration/Num Paths                         1
exploration/Average Returns                3545.87
evaluation_0/num steps total                  2.71064e+06
evaluation_0/num paths total               6153
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.14811
evaluation_0/Rewards Std                      0.919326
evaluation_0/Rewards Max                      7.77592
evaluation_0/Rewards Min                     -0.719954
evaluation_0/Returns Mean                  4148.11
evaluation_0/Returns Std                    122.027
evaluation_0/Returns Max                   4371.86
evaluation_0/Returns Min                   4019.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4148.11
time/epoch (s)                                0
time/total (s)                             5438.46
Epoch                                       348
---------------------------------------  ----------------
2022-11-16 17:45:38.383140 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 349 finished
---------------------------------------  ----------------
epoch                                       349
total_step                               354000
replay_pool/size                         354000
trainer/alpha                                 0.065015
trainer/alpha_loss                           -0.0723945
trainer/entropy                              -5.97351
trainer/qf_loss                              27.9988
trainer/policy_loss                        -296.359
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.747
trainer/entropy_penalty                      -0.388368
trainer/entropy_percentage                   -0.00130875
trainer/Q1Pred Mean                         295.865
trainer/Q1Pred Std                           64.9574
trainer/Q1Pred Max                          382.184
trainer/Q1Pred Min                            7.86616
trainer/Q2Pred Mean                         295.654
trainer/Q2Pred Std                           65.4502
trainer/Q2Pred Max                          379.483
trainer/Q2Pred Min                           -0.995992
trainer/QTargetWithReg Mean                 296.872
trainer/QTargetWithReg Std                   64.8518
trainer/QTargetWithReg Max                  380.602
trainer/QTargetWithReg Min                    4.3007
trainer/PolicyLossWithoutReg Mean           296.747
trainer/PolicyLossWithoutReg Std             63.7806
trainer/PolicyLossWithoutReg Max            380.632
trainer/PolicyLossWithoutReg Min              8.18816
exploration/num steps total              354000
exploration/num paths total                1097
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.13869
exploration/Rewards Std                       1.11754
exploration/Rewards Max                       7.0461
exploration/Rewards Min                      -0.751954
exploration/Returns Mean                   4138.69
exploration/Returns Std                       0
exploration/Returns Max                    4138.69
exploration/Returns Min                    4138.69
exploration/Num Paths                         1
exploration/Average Returns                4138.69
evaluation_0/num steps total                  2.71829e+06
evaluation_0/num paths total               6161
evaluation_0/path length Mean               956.75
evaluation_0/path length Std                114.429
evaluation_0/path length Max               1000
evaluation_0/path length Min                654
evaluation_0/Rewards Mean                     4.31477
evaluation_0/Rewards Std                      1.10282
evaluation_0/Rewards Max                      7.28411
evaluation_0/Rewards Min                     -0.718013
evaluation_0/Returns Mean                  4128.15
evaluation_0/Returns Std                    557.281
evaluation_0/Returns Max                   4619.95
evaluation_0/Returns Min                   2726.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4128.15
time/epoch (s)                                0
time/total (s)                             5455.45
Epoch                                       349
---------------------------------------  ----------------
2022-11-16 17:45:53.363746 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 350 finished
---------------------------------------  ----------------
epoch                                       350
total_step                               355000
replay_pool/size                         355000
trainer/alpha                                 0.06456
trainer/alpha_loss                           -0.0993008
trainer/entropy                              -5.96376
trainer/qf_loss                              29.4353
trainer/policy_loss                        -294.974
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.359
trainer/entropy_penalty                      -0.38502
trainer/entropy_percentage                   -0.00130357
trainer/Q1Pred Mean                         294.238
trainer/Q1Pred Std                           68.3456
trainer/Q1Pred Max                          379.283
trainer/Q1Pred Min                           -6.42153
trainer/Q2Pred Mean                         293.911
trainer/Q2Pred Std                           68.1085
trainer/Q2Pred Max                          378.384
trainer/Q2Pred Min                           -8.72133
trainer/QTargetWithReg Mean                 295.311
trainer/QTargetWithReg Std                   67.7559
trainer/QTargetWithReg Max                  379.754
trainer/QTargetWithReg Min                    6.49223
trainer/PolicyLossWithoutReg Mean           295.359
trainer/PolicyLossWithoutReg Std             67.6848
trainer/PolicyLossWithoutReg Max            378.017
trainer/PolicyLossWithoutReg Min              5.04398
exploration/num steps total              355000
exploration/num paths total                1098
exploration/path length this epoch Mean     749
exploration/path length this epoch Std        0
exploration/path length this epoch Max      749
exploration/path length this epoch Min      749
exploration/Rewards Mean                      4.26198
exploration/Rewards Std                       1.39899
exploration/Rewards Max                       7.33103
exploration/Rewards Min                      -0.60641
exploration/Returns Mean                   3192.22
exploration/Returns Std                       0
exploration/Returns Max                    3192.22
exploration/Returns Min                    3192.22
exploration/Num Paths                         1
exploration/Average Returns                3192.22
evaluation_0/num steps total                  2.72555e+06
evaluation_0/num paths total               6169
evaluation_0/path length Mean               907
evaluation_0/path length Std                139.956
evaluation_0/path length Max               1000
evaluation_0/path length Min                590
evaluation_0/Rewards Mean                     4.55289
evaluation_0/Rewards Std                      1.13157
evaluation_0/Rewards Max                     10.2999
evaluation_0/Rewards Min                     -0.582804
evaluation_0/Returns Mean                  4129.47
evaluation_0/Returns Std                    728.55
evaluation_0/Returns Max                   4707.44
evaluation_0/Returns Min                   2460.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4129.47
time/epoch (s)                                0
time/total (s)                             5470.43
Epoch                                       350
---------------------------------------  ----------------
2022-11-16 17:46:05.382528 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 351 finished
---------------------------------------  ----------------
epoch                                       351
total_step                               356000
replay_pool/size                         356000
trainer/alpha                                 0.0655712
trainer/alpha_loss                           -2.40873
trainer/entropy                              -5.11592
trainer/qf_loss                              19.6009
trainer/policy_loss                        -301.392
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.727
trainer/entropy_penalty                      -0.335457
trainer/entropy_percentage                   -0.00111179
trainer/Q1Pred Mean                         301.435
trainer/Q1Pred Std                           63.8036
trainer/Q1Pred Max                          382.161
trainer/Q1Pred Min                           18.4946
trainer/Q2Pred Mean                         300.995
trainer/Q2Pred Std                           64.26
trainer/Q2Pred Max                          380.595
trainer/Q2Pred Min                           11.4851
trainer/QTargetWithReg Mean                 301.197
trainer/QTargetWithReg Std                   64.3917
trainer/QTargetWithReg Max                  380.661
trainer/QTargetWithReg Min                    4.56788
trainer/PolicyLossWithoutReg Mean           301.727
trainer/PolicyLossWithoutReg Std             63.1677
trainer/PolicyLossWithoutReg Max            381.262
trainer/PolicyLossWithoutReg Min             22.3419
exploration/num steps total              356000
exploration/num paths total                1100
exploration/path length this epoch Mean     436.5
exploration/path length this epoch Std       43.5
exploration/path length this epoch Max      480
exploration/path length this epoch Min      393
exploration/Rewards Mean                      3.83152
exploration/Rewards Std                       1.18342
exploration/Rewards Max                       6.66068
exploration/Rewards Min                      -0.664249
exploration/Returns Mean                   1672.46
exploration/Returns Std                     263.917
exploration/Returns Max                    1936.38
exploration/Returns Min                    1408.54
exploration/Num Paths                         2
exploration/Average Returns                1672.46
evaluation_0/num steps total                  2.73349e+06
evaluation_0/num paths total               6180
evaluation_0/path length Mean               721.909
evaluation_0/path length Std                249.666
evaluation_0/path length Max               1000
evaluation_0/path length Min                271
evaluation_0/Rewards Mean                     4.48393
evaluation_0/Rewards Std                      1.28928
evaluation_0/Rewards Max                      9.15272
evaluation_0/Rewards Min                     -0.603667
evaluation_0/Returns Mean                  3236.99
evaluation_0/Returns Std                   1299.4
evaluation_0/Returns Max                   4807.39
evaluation_0/Returns Min                    976.669
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3236.99
time/epoch (s)                                0
time/total (s)                             5482.45
Epoch                                       351
---------------------------------------  ----------------
2022-11-16 17:46:18.697779 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 352 finished
---------------------------------------  ----------------
epoch                                       352
total_step                               357000
replay_pool/size                         357000
trainer/alpha                                 0.0649309
trainer/alpha_loss                           -0.0644607
trainer/entropy                              -5.97643
trainer/qf_loss                              17.9111
trainer/policy_loss                        -294.413
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.801
trainer/entropy_penalty                      -0.388055
trainer/entropy_percentage                   -0.00131633
trainer/Q1Pred Mean                         294.046
trainer/Q1Pred Std                           69.3204
trainer/Q1Pred Max                          384.327
trainer/Q1Pred Min                            9.66219
trainer/Q2Pred Mean                         293.635
trainer/Q2Pred Std                           69.1621
trainer/Q2Pred Max                          382.388
trainer/Q2Pred Min                            6.89247
trainer/QTargetWithReg Mean                 293.622
trainer/QTargetWithReg Std                   70.1533
trainer/QTargetWithReg Max                  384.828
trainer/QTargetWithReg Min                    3.71067
trainer/PolicyLossWithoutReg Mean           294.801
trainer/PolicyLossWithoutReg Std             68.6125
trainer/PolicyLossWithoutReg Max            382.64
trainer/PolicyLossWithoutReg Min              6.9071
exploration/num steps total              357000
exploration/num paths total                1101
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.07685
exploration/Rewards Std                       1.20856
exploration/Rewards Max                       6.85842
exploration/Rewards Min                      -0.668821
exploration/Returns Mean                   4076.85
exploration/Returns Std                       0
exploration/Returns Max                    4076.85
exploration/Returns Min                    4076.85
exploration/Num Paths                         1
exploration/Average Returns                4076.85
evaluation_0/num steps total                  2.74124e+06
evaluation_0/num paths total               6188
evaluation_0/path length Mean               968.5
evaluation_0/path length Std                 83.3412
evaluation_0/path length Max               1000
evaluation_0/path length Min                748
evaluation_0/Rewards Mean                     4.38099
evaluation_0/Rewards Std                      1.09483
evaluation_0/Rewards Max                      7.22075
evaluation_0/Rewards Min                     -0.668405
evaluation_0/Returns Mean                  4242.99
evaluation_0/Returns Std                    387.277
evaluation_0/Returns Max                   4515.76
evaluation_0/Returns Min                   3256.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4242.99
time/epoch (s)                                0
time/total (s)                             5495.77
Epoch                                       352
---------------------------------------  ----------------
2022-11-16 17:46:32.902010 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 353 finished
---------------------------------------  ---------------
epoch                                       353
total_step                               358000
replay_pool/size                         358000
trainer/alpha                                 0.066778
trainer/alpha_loss                           -0.16185
trainer/entropy                              -5.9402
trainer/qf_loss                              16.9234
trainer/policy_loss                        -295.212
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.609
trainer/entropy_penalty                      -0.396674
trainer/entropy_percentage                   -0.00134189
trainer/Q1Pred Mean                         294.557
trainer/Q1Pred Std                           65.5512
trainer/Q1Pred Max                          377.594
trainer/Q1Pred Min                           -9.68525
trainer/Q2Pred Mean                         294.278
trainer/Q2Pred Std                           65.4184
trainer/Q2Pred Max                          379.351
trainer/Q2Pred Min                           -9.24208
trainer/QTargetWithReg Mean                 294.442
trainer/QTargetWithReg Std                   65.4919
trainer/QTargetWithReg Max                  379.841
trainer/QTargetWithReg Min                  -14.8394
trainer/PolicyLossWithoutReg Mean           295.609
trainer/PolicyLossWithoutReg Std             64.3221
trainer/PolicyLossWithoutReg Max            379.994
trainer/PolicyLossWithoutReg Min             -5.83523
exploration/num steps total              358000
exploration/num paths total                1102
exploration/path length this epoch Mean     201
exploration/path length this epoch Std        0
exploration/path length this epoch Max      201
exploration/path length this epoch Min      201
exploration/Rewards Mean                      2.75636
exploration/Rewards Std                       1.14476
exploration/Rewards Max                       4.78934
exploration/Rewards Min                      -0.83375
exploration/Returns Mean                    554.029
exploration/Returns Std                       0
exploration/Returns Max                     554.029
exploration/Returns Min                     554.029
exploration/Num Paths                         1
exploration/Average Returns                 554.029
evaluation_0/num steps total                  2.7488e+06
evaluation_0/num paths total               6200
evaluation_0/path length Mean               629.917
evaluation_0/path length Std                224.289
evaluation_0/path length Max               1000
evaluation_0/path length Min                293
evaluation_0/Rewards Mean                     4.22299
evaluation_0/Rewards Std                      1.46733
evaluation_0/Rewards Max                     10.01
evaluation_0/Rewards Min                     -0.637379
evaluation_0/Returns Mean                  2660.13
evaluation_0/Returns Std                   1156.36
evaluation_0/Returns Max                   4647.86
evaluation_0/Returns Min                   1017.64
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2660.13
time/epoch (s)                                0
time/total (s)                             5509.97
Epoch                                       353
---------------------------------------  ---------------
2022-11-16 17:46:45.890175 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 354 finished
---------------------------------------  ----------------
epoch                                       354
total_step                               359000
replay_pool/size                         359000
trainer/alpha                                 0.065687
trainer/alpha_loss                           -0.0896657
trainer/entropy                              -5.96707
trainer/qf_loss                              20.2874
trainer/policy_loss                        -300.013
trainer/adversary_policy_loss                14.3318
trainer/policy_loss_without_entropy         300.405
trainer/entropy_penalty                      -0.391959
trainer/entropy_percentage                   -0.00130477
trainer/Q1Pred Mean                         299.469
trainer/Q1Pred Std                           60.259
trainer/Q1Pred Max                          383.392
trainer/Q1Pred Min                           13.6059
trainer/Q2Pred Mean                         298.891
trainer/Q2Pred Std                           59.9111
trainer/Q2Pred Max                          380.368
trainer/Q2Pred Min                           14.3671
trainer/QTargetWithReg Mean                 299.792
trainer/QTargetWithReg Std                   60.6095
trainer/QTargetWithReg Max                  383.102
trainer/QTargetWithReg Min                   15.3464
trainer/PolicyLossWithoutReg Mean           300.405
trainer/PolicyLossWithoutReg Std             58.1589
trainer/PolicyLossWithoutReg Max            381.629
trainer/PolicyLossWithoutReg Min             13.944
exploration/num steps total              359000
exploration/num paths total                1103
exploration/path length this epoch Mean     664
exploration/path length this epoch Std        0
exploration/path length this epoch Max      664
exploration/path length this epoch Min      664
exploration/Rewards Mean                      4.00621
exploration/Rewards Std                       1.20435
exploration/Rewards Max                       6.85623
exploration/Rewards Min                      -0.536104
exploration/Returns Mean                   2660.12
exploration/Returns Std                       0
exploration/Returns Max                    2660.12
exploration/Returns Min                    2660.12
exploration/Num Paths                         1
exploration/Average Returns                2660.12
evaluation_0/num steps total                  2.75671e+06
evaluation_0/num paths total               6209
evaluation_0/path length Mean               879.778
evaluation_0/path length Std                185.452
evaluation_0/path length Max               1000
evaluation_0/path length Min                465
evaluation_0/Rewards Mean                     4.26419
evaluation_0/Rewards Std                      1.07191
evaluation_0/Rewards Max                      9.20955
evaluation_0/Rewards Min                     -0.708549
evaluation_0/Returns Mean                  3751.54
evaluation_0/Returns Std                    856.159
evaluation_0/Returns Max                   4495.01
evaluation_0/Returns Min                   2028.98
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3751.54
time/epoch (s)                                0
time/total (s)                             5522.95
Epoch                                       354
---------------------------------------  ----------------
2022-11-16 17:47:00.373834 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 355 finished
---------------------------------------  ----------------
epoch                                       355
total_step                               360000
replay_pool/size                         360000
trainer/alpha                                 0.0657176
trainer/alpha_loss                            0.457802
trainer/entropy                              -6.16816
trainer/qf_loss                              18.994
trainer/policy_loss                        -297.003
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         297.409
trainer/entropy_penalty                      -0.405357
trainer/entropy_percentage                   -0.00136296
trainer/Q1Pred Mean                         296.11
trainer/Q1Pred Std                           76.1416
trainer/Q1Pred Max                          377.409
trainer/Q1Pred Min                           -8.39373
trainer/Q2Pred Mean                         295.878
trainer/Q2Pred Std                           77.1157
trainer/Q2Pred Max                          381.401
trainer/Q2Pred Min                          -34.291
trainer/QTargetWithReg Mean                 295.79
trainer/QTargetWithReg Std                   76.2046
trainer/QTargetWithReg Max                  377.317
trainer/QTargetWithReg Min                  -10.8078
trainer/PolicyLossWithoutReg Mean           297.409
trainer/PolicyLossWithoutReg Std             72.6437
trainer/PolicyLossWithoutReg Max            379.622
trainer/PolicyLossWithoutReg Min             -4.96033
exploration/num steps total              360000
exploration/num paths total                1104
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.36774
exploration/Rewards Std                       1.20932
exploration/Rewards Max                       7.03947
exploration/Rewards Min                      -0.61465
exploration/Returns Mean                   4367.74
exploration/Returns Std                       0
exploration/Returns Max                    4367.74
exploration/Returns Min                    4367.74
exploration/Num Paths                         1
exploration/Average Returns                4367.74
evaluation_0/num steps total                  2.76468e+06
evaluation_0/num paths total               6219
evaluation_0/path length Mean               796.6
evaluation_0/path length Std                171.799
evaluation_0/path length Max               1000
evaluation_0/path length Min                528
evaluation_0/Rewards Mean                     4.51647
evaluation_0/Rewards Std                      1.16287
evaluation_0/Rewards Max                      8.54277
evaluation_0/Rewards Min                     -0.614113
evaluation_0/Returns Mean                  3597.82
evaluation_0/Returns Std                    904.064
evaluation_0/Returns Max                   4666.07
evaluation_0/Returns Min                   2193.33
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3597.82
time/epoch (s)                                0
time/total (s)                             5537.44
Epoch                                       355
---------------------------------------  ----------------
2022-11-16 17:47:11.518352 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 356 finished
---------------------------------------  ----------------
epoch                                       356
total_step                               361000
replay_pool/size                         361000
trainer/alpha                                 0.0640302
trainer/alpha_loss                           -0.472779
trainer/entropy                              -5.82798
trainer/qf_loss                              19.8626
trainer/policy_loss                        -292.822
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.195
trainer/entropy_penalty                      -0.373167
trainer/entropy_percentage                   -0.00127276
trainer/Q1Pred Mean                         290.963
trainer/Q1Pred Std                           70.5894
trainer/Q1Pred Max                          377.699
trainer/Q1Pred Min                           16.8412
trainer/Q2Pred Mean                         291.592
trainer/Q2Pred Std                           70.6715
trainer/Q2Pred Max                          378.915
trainer/Q2Pred Min                           13.2857
trainer/QTargetWithReg Mean                 292.523
trainer/QTargetWithReg Std                   70.7253
trainer/QTargetWithReg Max                  382.444
trainer/QTargetWithReg Min                   17.1517
trainer/PolicyLossWithoutReg Mean           293.195
trainer/PolicyLossWithoutReg Std             69.8928
trainer/PolicyLossWithoutReg Max            380.595
trainer/PolicyLossWithoutReg Min             14.2662
exploration/num steps total              361000
exploration/num paths total                1105
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.85655
exploration/Rewards Std                       0.892672
exploration/Rewards Max                       6.58115
exploration/Rewards Min                      -0.570875
exploration/Returns Mean                   3856.55
exploration/Returns Std                       0
exploration/Returns Max                    3856.55
exploration/Returns Min                    3856.55
exploration/Num Paths                         1
exploration/Average Returns                3856.55
evaluation_0/num steps total                  2.77268e+06
evaluation_0/num paths total               6227
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.4812
evaluation_0/Rewards Std                      1.03337
evaluation_0/Rewards Max                      6.9508
evaluation_0/Rewards Min                     -0.545067
evaluation_0/Returns Mean                  4481.2
evaluation_0/Returns Std                     46.06
evaluation_0/Returns Max                   4559.17
evaluation_0/Returns Min                   4427.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4481.2
time/epoch (s)                                0
time/total (s)                             5548.58
Epoch                                       356
---------------------------------------  ----------------
2022-11-16 17:47:23.025426 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 357 finished
---------------------------------------  ----------------
epoch                                       357
total_step                               362000
replay_pool/size                         362000
trainer/alpha                                 0.0635437
trainer/alpha_loss                            0.91516
trainer/entropy                              -6.33204
trainer/qf_loss                              28.678
trainer/policy_loss                        -298.139
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.541
trainer/entropy_penalty                      -0.402361
trainer/entropy_percentage                   -0.00134776
trainer/Q1Pred Mean                         297.013
trainer/Q1Pred Std                           60.5755
trainer/Q1Pred Max                          384.465
trainer/Q1Pred Min                           20.3755
trainer/Q2Pred Mean                         297.588
trainer/Q2Pred Std                           60.7439
trainer/Q2Pred Max                          383.603
trainer/Q2Pred Min                           25.2808
trainer/QTargetWithReg Mean                 297.309
trainer/QTargetWithReg Std                   61.6877
trainer/QTargetWithReg Max                  382.97
trainer/QTargetWithReg Min                   21.9361
trainer/PolicyLossWithoutReg Mean           298.541
trainer/PolicyLossWithoutReg Std             59.6375
trainer/PolicyLossWithoutReg Max            383.565
trainer/PolicyLossWithoutReg Min             28.764
exploration/num steps total              362000
exploration/num paths total                1106
exploration/path length this epoch Mean     772
exploration/path length this epoch Std        0
exploration/path length this epoch Max      772
exploration/path length this epoch Min      772
exploration/Rewards Mean                      4.42383
exploration/Rewards Std                       1.24385
exploration/Rewards Max                       7.88451
exploration/Rewards Min                      -0.448951
exploration/Returns Mean                   3415.19
exploration/Returns Std                       0
exploration/Returns Max                    3415.19
exploration/Returns Min                    3415.19
exploration/Num Paths                         1
exploration/Average Returns                3415.19
evaluation_0/num steps total                  2.78068e+06
evaluation_0/num paths total               6235
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.352
evaluation_0/Rewards Std                      0.949445
evaluation_0/Rewards Max                      6.59424
evaluation_0/Rewards Min                     -0.533265
evaluation_0/Returns Mean                  4352
evaluation_0/Returns Std                    153.361
evaluation_0/Returns Max                   4582.9
evaluation_0/Returns Min                   4126.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4352
time/epoch (s)                                0
time/total (s)                             5560.09
Epoch                                       357
---------------------------------------  ----------------
2022-11-16 17:47:38.555488 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 358 finished
---------------------------------------  ----------------
epoch                                       358
total_step                               363000
replay_pool/size                         363000
trainer/alpha                                 0.064206
trainer/alpha_loss                           -1.15411
trainer/entropy                              -5.57966
trainer/qf_loss                              12.1842
trainer/policy_loss                        -298.127
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.485
trainer/entropy_penalty                      -0.358248
trainer/entropy_percentage                   -0.00120022
trainer/Q1Pred Mean                         297.562
trainer/Q1Pred Std                           70.0646
trainer/Q1Pred Max                          389.588
trainer/Q1Pred Min                            2.64618
trainer/Q2Pred Mean                         297.035
trainer/Q2Pred Std                           70.2977
trainer/Q2Pred Max                          383.503
trainer/Q2Pred Min                           -3.49798
trainer/QTargetWithReg Mean                 297.606
trainer/QTargetWithReg Std                   70.2771
trainer/QTargetWithReg Max                  381.786
trainer/QTargetWithReg Min                   -6.39673
trainer/PolicyLossWithoutReg Mean           298.485
trainer/PolicyLossWithoutReg Std             69.7906
trainer/PolicyLossWithoutReg Max            383.779
trainer/PolicyLossWithoutReg Min             -0.139716
exploration/num steps total              363000
exploration/num paths total                1107
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.13763
exploration/Rewards Std                       0.886188
exploration/Rewards Max                       6.32465
exploration/Rewards Min                      -0.530264
exploration/Returns Mean                   4137.63
exploration/Returns Std                       0
exploration/Returns Max                    4137.63
exploration/Returns Min                    4137.63
exploration/Num Paths                         1
exploration/Average Returns                4137.63
evaluation_0/num steps total                  2.78833e+06
evaluation_0/num paths total               6253
evaluation_0/path length Mean               425.222
evaluation_0/path length Std                329.849
evaluation_0/path length Max               1000
evaluation_0/path length Min                 68
evaluation_0/Rewards Mean                     4.45027
evaluation_0/Rewards Std                      1.56651
evaluation_0/Rewards Max                     12.848
evaluation_0/Rewards Min                     -0.624928
evaluation_0/Returns Mean                  1892.36
evaluation_0/Returns Std                   1705.06
evaluation_0/Returns Max                   4848.09
evaluation_0/Returns Min                    153.187
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1892.36
time/epoch (s)                                0
time/total (s)                             5575.62
Epoch                                       358
---------------------------------------  ----------------
2022-11-16 17:47:51.999045 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 359 finished
---------------------------------------  ----------------
epoch                                       359
total_step                               364000
replay_pool/size                         364000
trainer/alpha                                 0.0654866
trainer/alpha_loss                           -0.462779
trainer/entropy                              -5.83023
trainer/qf_loss                              32.646
trainer/policy_loss                        -292.671
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.053
trainer/entropy_penalty                      -0.381802
trainer/entropy_percentage                   -0.00130284
trainer/Q1Pred Mean                         292.338
trainer/Q1Pred Std                           71.348
trainer/Q1Pred Max                          381.609
trainer/Q1Pred Min                            6.89263
trainer/Q2Pred Mean                         292.296
trainer/Q2Pred Std                           70.8195
trainer/Q2Pred Max                          381.057
trainer/Q2Pred Min                            4.35138
trainer/QTargetWithReg Mean                 291.736
trainer/QTargetWithReg Std                   71.2721
trainer/QTargetWithReg Max                  381.045
trainer/QTargetWithReg Min                    6.54399
trainer/PolicyLossWithoutReg Mean           293.053
trainer/PolicyLossWithoutReg Std             70.1114
trainer/PolicyLossWithoutReg Max            380.285
trainer/PolicyLossWithoutReg Min              9.09493
exploration/num steps total              364000
exploration/num paths total                1108
exploration/path length this epoch Mean     275
exploration/path length this epoch Std        0
exploration/path length this epoch Max      275
exploration/path length this epoch Min      275
exploration/Rewards Mean                      3.53217
exploration/Rewards Std                       1.89636
exploration/Rewards Max                       8.65239
exploration/Rewards Min                      -0.57206
exploration/Returns Mean                    971.346
exploration/Returns Std                       0
exploration/Returns Max                     971.346
exploration/Returns Min                     971.346
exploration/Num Paths                         1
exploration/Average Returns                 971.346
evaluation_0/num steps total                  2.79559e+06
evaluation_0/num paths total               6263
evaluation_0/path length Mean               725.4
evaluation_0/path length Std                168.373
evaluation_0/path length Max               1000
evaluation_0/path length Min                557
evaluation_0/Rewards Mean                     4.46055
evaluation_0/Rewards Std                      1.33699
evaluation_0/Rewards Max                     10.0286
evaluation_0/Rewards Min                     -0.565033
evaluation_0/Returns Mean                  3235.68
evaluation_0/Returns Std                    864.081
evaluation_0/Returns Max                   4750.02
evaluation_0/Returns Min                   2321.5
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3235.68
time/epoch (s)                                0
time/total (s)                             5589.06
Epoch                                       359
---------------------------------------  ----------------
2022-11-16 17:48:04.910686 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 360 finished
---------------------------------------  ----------------
epoch                                       360
total_step                               365000
replay_pool/size                         365000
trainer/alpha                                 0.0647363
trainer/alpha_loss                           -1.104
trainer/entropy                              -5.5967
trainer/qf_loss                              16.7297
trainer/policy_loss                        -296.602
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.964
trainer/entropy_penalty                      -0.36231
trainer/entropy_percentage                   -0.00122004
trainer/Q1Pred Mean                         296.057
trainer/Q1Pred Std                           54.0373
trainer/Q1Pred Max                          387.448
trainer/Q1Pred Min                           15.5841
trainer/Q2Pred Mean                         296.083
trainer/Q2Pred Std                           53.6958
trainer/Q2Pred Max                          387.328
trainer/Q2Pred Min                           22.1956
trainer/QTargetWithReg Mean                 295.85
trainer/QTargetWithReg Std                   54.2002
trainer/QTargetWithReg Max                  389.229
trainer/QTargetWithReg Min                   18.5839
trainer/PolicyLossWithoutReg Mean           296.964
trainer/PolicyLossWithoutReg Std             53.3684
trainer/PolicyLossWithoutReg Max            388.162
trainer/PolicyLossWithoutReg Min             17.9491
exploration/num steps total              365000
exploration/num paths total                1111
exploration/path length this epoch Mean     219.333
exploration/path length this epoch Std       60.3011
exploration/path length this epoch Max      297
exploration/path length this epoch Min      150
exploration/Rewards Mean                      3.22268
exploration/Rewards Std                       1.79386
exploration/Rewards Max                       9.72015
exploration/Rewards Min                      -0.916982
exploration/Returns Mean                    706.842
exploration/Returns Std                     374.122
exploration/Returns Max                    1234.7
exploration/Returns Min                     411.742
exploration/Num Paths                         3
exploration/Average Returns                 706.842
evaluation_0/num steps total                  2.80261e+06
evaluation_0/num paths total               6271
evaluation_0/path length Mean               877.75
evaluation_0/path length Std                178.203
evaluation_0/path length Max               1000
evaluation_0/path length Min                485
evaluation_0/Rewards Mean                     4.38748
evaluation_0/Rewards Std                      1.20259
evaluation_0/Rewards Max                      9.1438
evaluation_0/Rewards Min                     -0.579638
evaluation_0/Returns Mean                  3851.11
evaluation_0/Returns Std                    897.258
evaluation_0/Returns Max                   4604.42
evaluation_0/Returns Min                   1801.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3851.11
time/epoch (s)                                0
time/total (s)                             5601.97
Epoch                                       360
---------------------------------------  ----------------
2022-11-16 17:48:20.111582 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 361 finished
---------------------------------------  ----------------
epoch                                       361
total_step                               366000
replay_pool/size                         366000
trainer/alpha                                 0.0641721
trainer/alpha_loss                            0.230173
trainer/entropy                              -6.08382
trainer/qf_loss                              18.7319
trainer/policy_loss                        -289.352
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         289.742
trainer/entropy_penalty                      -0.390411
trainer/entropy_percentage                   -0.00134744
trainer/Q1Pred Mean                         287.639
trainer/Q1Pred Std                           73.9514
trainer/Q1Pred Max                          378.739
trainer/Q1Pred Min                            2.51334
trainer/Q2Pred Mean                         288.309
trainer/Q2Pred Std                           74.101
trainer/Q2Pred Max                          376.434
trainer/Q2Pred Min                            5.33775
trainer/QTargetWithReg Mean                 287.993
trainer/QTargetWithReg Std                   75.0487
trainer/QTargetWithReg Max                  374.723
trainer/QTargetWithReg Min                    1.36543
trainer/PolicyLossWithoutReg Mean           289.743
trainer/PolicyLossWithoutReg Std             73.2649
trainer/PolicyLossWithoutReg Max            381.38
trainer/PolicyLossWithoutReg Min              5.37681
exploration/num steps total              366000
exploration/num paths total                1112
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44177
exploration/Rewards Std                       1.14035
exploration/Rewards Max                       7.03355
exploration/Rewards Min                      -0.592912
exploration/Returns Mean                   4441.77
exploration/Returns Std                       0
exploration/Returns Max                    4441.77
exploration/Returns Min                    4441.77
exploration/Num Paths                         1
exploration/Average Returns                4441.77
evaluation_0/num steps total                  2.81016e+06
evaluation_0/num paths total               6279
evaluation_0/path length Mean               944
evaluation_0/path length Std                148.162
evaluation_0/path length Max               1000
evaluation_0/path length Min                552
evaluation_0/Rewards Mean                     4.91182
evaluation_0/Rewards Std                      1.30507
evaluation_0/Rewards Max                     10.3536
evaluation_0/Rewards Min                     -0.579261
evaluation_0/Returns Mean                  4636.75
evaluation_0/Returns Std                    803.677
evaluation_0/Returns Max                   5091.62
evaluation_0/Returns Min                   2540.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4636.75
time/epoch (s)                                0
time/total (s)                             5617.17
Epoch                                       361
---------------------------------------  ----------------
2022-11-16 17:48:34.405776 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 362 finished
---------------------------------------  ----------------
epoch                                       362
total_step                               367000
replay_pool/size                         367000
trainer/alpha                                 0.0647013
trainer/alpha_loss                           -1.72356
trainer/entropy                              -5.3705
trainer/qf_loss                              20.5774
trainer/policy_loss                        -293.625
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.973
trainer/entropy_penalty                      -0.347478
trainer/entropy_percentage                   -0.00118201
trainer/Q1Pred Mean                         292.496
trainer/Q1Pred Std                           70.4605
trainer/Q1Pred Max                          385.793
trainer/Q1Pred Min                            7.23074
trainer/Q2Pred Mean                         292.944
trainer/Q2Pred Std                           71.0561
trainer/Q2Pred Max                          386.393
trainer/Q2Pred Min                          -41.3685
trainer/QTargetWithReg Mean                 292.789
trainer/QTargetWithReg Std                   70.0456
trainer/QTargetWithReg Max                  386.271
trainer/QTargetWithReg Min                    0.270645
trainer/PolicyLossWithoutReg Mean           293.973
trainer/PolicyLossWithoutReg Std             68.4861
trainer/PolicyLossWithoutReg Max            385.85
trainer/PolicyLossWithoutReg Min              3.28742
exploration/num steps total              367000
exploration/num paths total                1113
exploration/path length this epoch Mean     769
exploration/path length this epoch Std        0
exploration/path length this epoch Max      769
exploration/path length this epoch Min      769
exploration/Rewards Mean                      3.91551
exploration/Rewards Std                       1.42529
exploration/Rewards Max                       7.78621
exploration/Rewards Min                      -0.837834
exploration/Returns Mean                   3011.03
exploration/Returns Std                       0
exploration/Returns Max                    3011.03
exploration/Returns Min                    3011.03
exploration/Num Paths                         1
exploration/Average Returns                3011.03
evaluation_0/num steps total                  2.81784e+06
evaluation_0/num paths total               6288
evaluation_0/path length Mean               853.778
evaluation_0/path length Std                176.866
evaluation_0/path length Max               1000
evaluation_0/path length Min                505
evaluation_0/Rewards Mean                     4.10199
evaluation_0/Rewards Std                      1.17061
evaluation_0/Rewards Max                     10.1278
evaluation_0/Rewards Min                     -0.542168
evaluation_0/Returns Mean                  3502.18
evaluation_0/Returns Std                    921.216
evaluation_0/Returns Max                   4723.8
evaluation_0/Returns Min                   1862.48
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3502.18
time/epoch (s)                                0
time/total (s)                             5631.47
Epoch                                       362
---------------------------------------  ----------------
2022-11-16 17:48:48.054402 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 363 finished
---------------------------------------  ----------------
epoch                                       363
total_step                               368000
replay_pool/size                         368000
trainer/alpha                                 0.0658285
trainer/alpha_loss                           -0.548611
trainer/entropy                              -5.79836
trainer/qf_loss                              20.9334
trainer/policy_loss                        -301.325
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.707
trainer/entropy_penalty                      -0.381697
trainer/entropy_percentage                   -0.00126513
trainer/Q1Pred Mean                         301.063
trainer/Q1Pred Std                           59.9073
trainer/Q1Pred Max                          389.709
trainer/Q1Pred Min                           25.2912
trainer/Q2Pred Mean                         299.791
trainer/Q2Pred Std                           59.9599
trainer/Q2Pred Max                          385.301
trainer/Q2Pred Min                           16.8379
trainer/QTargetWithReg Mean                 301.37
trainer/QTargetWithReg Std                   60.4247
trainer/QTargetWithReg Max                  387.561
trainer/QTargetWithReg Min                   24.9221
trainer/PolicyLossWithoutReg Mean           301.707
trainer/PolicyLossWithoutReg Std             58.8111
trainer/PolicyLossWithoutReg Max            385.452
trainer/PolicyLossWithoutReg Min             27.2513
exploration/num steps total              368000
exploration/num paths total                1114
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56521
exploration/Rewards Std                       1.12066
exploration/Rewards Max                       7.07292
exploration/Rewards Min                      -0.614262
exploration/Returns Mean                   4565.21
exploration/Returns Std                       0
exploration/Returns Max                    4565.21
exploration/Returns Min                    4565.21
exploration/Num Paths                         1
exploration/Average Returns                4565.21
evaluation_0/num steps total                  2.82547e+06
evaluation_0/num paths total               6296
evaluation_0/path length Mean               953.125
evaluation_0/path length Std                124.02
evaluation_0/path length Max               1000
evaluation_0/path length Min                625
evaluation_0/Rewards Mean                     4.18922
evaluation_0/Rewards Std                      1.02508
evaluation_0/Rewards Max                      6.9697
evaluation_0/Rewards Min                     -0.583151
evaluation_0/Returns Mean                  3992.85
evaluation_0/Returns Std                    556.814
evaluation_0/Returns Max                   4286.31
evaluation_0/Returns Min                   2535.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3992.85
time/epoch (s)                                0
time/total (s)                             5645.12
Epoch                                       363
---------------------------------------  ----------------
2022-11-16 17:49:02.920726 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 364 finished
---------------------------------------  ----------------
epoch                                       364
total_step                               369000
replay_pool/size                         369000
trainer/alpha                                 0.0639099
trainer/alpha_loss                            0.493103
trainer/entropy                              -6.1793
trainer/qf_loss                              25.0603
trainer/policy_loss                        -292.886
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.281
trainer/entropy_penalty                      -0.394918
trainer/entropy_percentage                   -0.00134655
trainer/Q1Pred Mean                         292.543
trainer/Q1Pred Std                           69.6026
trainer/Q1Pred Max                          391.204
trainer/Q1Pred Min                            1.76169
trainer/Q2Pred Mean                         292.32
trainer/Q2Pred Std                           70.1745
trainer/Q2Pred Max                          390.978
trainer/Q2Pred Min                           -4.78995
trainer/QTargetWithReg Mean                 292.52
trainer/QTargetWithReg Std                   70.0011
trainer/QTargetWithReg Max                  391.707
trainer/QTargetWithReg Min                    3.35024
trainer/PolicyLossWithoutReg Mean           293.281
trainer/PolicyLossWithoutReg Std             68.9972
trainer/PolicyLossWithoutReg Max            390.237
trainer/PolicyLossWithoutReg Min             -0.659503
exploration/num steps total              369000
exploration/num paths total                1115
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.31221
exploration/Rewards Std                       0.998253
exploration/Rewards Max                       6.23034
exploration/Rewards Min                      -0.431244
exploration/Returns Mean                   4312.21
exploration/Returns Std                       0
exploration/Returns Max                    4312.21
exploration/Returns Min                    4312.21
exploration/Num Paths                         1
exploration/Average Returns                4312.21
evaluation_0/num steps total                  2.83344e+06
evaluation_0/num paths total               6305
evaluation_0/path length Mean               885.444
evaluation_0/path length Std                137.108
evaluation_0/path length Max               1000
evaluation_0/path length Min                670
evaluation_0/Rewards Mean                     4.57903
evaluation_0/Rewards Std                      1.11628
evaluation_0/Rewards Max                     12.0633
evaluation_0/Rewards Min                     -0.502639
evaluation_0/Returns Mean                  4054.47
evaluation_0/Returns Std                    681.67
evaluation_0/Returns Max                   4807.02
evaluation_0/Returns Min                   2999.45
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4054.47
time/epoch (s)                                0
time/total (s)                             5659.98
Epoch                                       364
---------------------------------------  ----------------
2022-11-16 17:49:16.469756 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 365 finished
---------------------------------------  ----------------
epoch                                       365
total_step                               370000
replay_pool/size                         370000
trainer/alpha                                 0.0650253
trainer/alpha_loss                           -0.0781477
trainer/entropy                              -5.97141
trainer/qf_loss                              17.9059
trainer/policy_loss                        -304.074
trainer/adversary_policy_loss                14.4841
trainer/policy_loss_without_entropy         304.463
trainer/entropy_penalty                      -0.388293
trainer/entropy_percentage                   -0.00127534
trainer/Q1Pred Mean                         303.193
trainer/Q1Pred Std                           53.9668
trainer/Q1Pred Max                          384.285
trainer/Q1Pred Min                            5.86784
trainer/Q2Pred Mean                         303.674
trainer/Q2Pred Std                           53.8352
trainer/Q2Pred Max                          382.28
trainer/Q2Pred Min                            1.0958
trainer/QTargetWithReg Mean                 303.622
trainer/QTargetWithReg Std                   54.4556
trainer/QTargetWithReg Max                  382.632
trainer/QTargetWithReg Min                   -6.06165
trainer/PolicyLossWithoutReg Mean           304.463
trainer/PolicyLossWithoutReg Std             52.762
trainer/PolicyLossWithoutReg Max            382.915
trainer/PolicyLossWithoutReg Min              5.6521
exploration/num steps total              370000
exploration/num paths total                1116
exploration/path length this epoch Mean     814
exploration/path length this epoch Std        0
exploration/path length this epoch Max      814
exploration/path length this epoch Min      814
exploration/Rewards Mean                      4.10333
exploration/Rewards Std                       1.09229
exploration/Rewards Max                       6.5931
exploration/Rewards Min                      -0.445779
exploration/Returns Mean                   3340.11
exploration/Returns Std                       0
exploration/Returns Max                    3340.11
exploration/Returns Min                    3340.11
exploration/Num Paths                         1
exploration/Average Returns                3340.11
evaluation_0/num steps total                  2.84094e+06
evaluation_0/num paths total               6315
evaluation_0/path length Mean               750.3
evaluation_0/path length Std                191.465
evaluation_0/path length Max               1000
evaluation_0/path length Min                483
evaluation_0/Rewards Mean                     4.48089
evaluation_0/Rewards Std                      1.2437
evaluation_0/Rewards Max                      9.53832
evaluation_0/Rewards Min                     -1.1155
evaluation_0/Returns Mean                  3362.01
evaluation_0/Returns Std                    888.343
evaluation_0/Returns Max                   4618.62
evaluation_0/Returns Min                   2096.8
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3362.01
time/epoch (s)                                0
time/total (s)                             5673.53
Epoch                                       365
---------------------------------------  ----------------
2022-11-16 17:49:31.268323 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 366 finished
---------------------------------------  ----------------
epoch                                       366
total_step                               371000
replay_pool/size                         371000
trainer/alpha                                 0.064301
trainer/alpha_loss                            1.54837
trainer/entropy                              -6.56421
trainer/qf_loss                              19.4507
trainer/policy_loss                        -294.172
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.594
trainer/entropy_penalty                      -0.422085
trainer/entropy_percentage                   -0.00143277
trainer/Q1Pred Mean                         291.254
trainer/Q1Pred Std                           68.1464
trainer/Q1Pred Max                          390.105
trainer/Q1Pred Min                          -62.1794
trainer/Q2Pred Mean                         291.289
trainer/Q2Pred Std                           66.9827
trainer/Q2Pred Max                          388.678
trainer/Q2Pred Min                          -31.3185
trainer/QTargetWithReg Mean                 291.729
trainer/QTargetWithReg Std                   67.8417
trainer/QTargetWithReg Max                  388.733
trainer/QTargetWithReg Min                  -37.5327
trainer/PolicyLossWithoutReg Mean           294.594
trainer/PolicyLossWithoutReg Std             61.1738
trainer/PolicyLossWithoutReg Max            387.628
trainer/PolicyLossWithoutReg Min             11.0122
exploration/num steps total              371000
exploration/num paths total                1117
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7092
exploration/Rewards Std                       1.17795
exploration/Rewards Max                       7.82619
exploration/Rewards Min                      -0.547261
exploration/Returns Mean                   4709.2
exploration/Returns Std                       0
exploration/Returns Max                    4709.2
exploration/Returns Min                    4709.2
exploration/Num Paths                         1
exploration/Average Returns                4709.2
evaluation_0/num steps total                  2.84894e+06
evaluation_0/num paths total               6324
evaluation_0/path length Mean               888.222
evaluation_0/path length Std                158.18
evaluation_0/path length Max               1000
evaluation_0/path length Min                500
evaluation_0/Rewards Mean                     4.4315
evaluation_0/Rewards Std                      1.12112
evaluation_0/Rewards Max                      8.21818
evaluation_0/Rewards Min                     -0.854382
evaluation_0/Returns Mean                  3936.16
evaluation_0/Returns Std                    795.353
evaluation_0/Returns Max                   4734.55
evaluation_0/Returns Min                   2055.28
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3936.16
time/epoch (s)                                0
time/total (s)                             5688.33
Epoch                                       366
---------------------------------------  ----------------
2022-11-16 17:49:44.468581 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 367 finished
---------------------------------------  ----------------
epoch                                       367
total_step                               372000
replay_pool/size                         372000
trainer/alpha                                 0.0647453
trainer/alpha_loss                           -0.0270802
trainer/entropy                              -5.99011
trainer/qf_loss                              23.2401
trainer/policy_loss                        -291.807
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         292.194
trainer/entropy_penalty                      -0.387831
trainer/entropy_percentage                   -0.00132731
trainer/Q1Pred Mean                         290.895
trainer/Q1Pred Std                           67.2912
trainer/Q1Pred Max                          386.391
trainer/Q1Pred Min                            2.97016
trainer/Q2Pred Mean                         290.128
trainer/Q2Pred Std                           67.2887
trainer/Q2Pred Max                          384.233
trainer/Q2Pred Min                            3.6403
trainer/QTargetWithReg Mean                 290.052
trainer/QTargetWithReg Std                   67.8645
trainer/QTargetWithReg Max                  384.821
trainer/QTargetWithReg Min                    0.163005
trainer/PolicyLossWithoutReg Mean           292.194
trainer/PolicyLossWithoutReg Std             65.502
trainer/PolicyLossWithoutReg Max            384.345
trainer/PolicyLossWithoutReg Min              4.53768
exploration/num steps total              372000
exploration/num paths total                1118
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15759
exploration/Rewards Std                       1.21502
exploration/Rewards Max                       7.10624
exploration/Rewards Min                      -1.00594
exploration/Returns Mean                   4157.59
exploration/Returns Std                       0
exploration/Returns Max                    4157.59
exploration/Returns Min                    4157.59
exploration/Num Paths                         1
exploration/Average Returns                4157.59
evaluation_0/num steps total                  2.85691e+06
evaluation_0/num paths total               6332
evaluation_0/path length Mean               996.625
evaluation_0/path length Std                  8.92941
evaluation_0/path length Max               1000
evaluation_0/path length Min                973
evaluation_0/Rewards Mean                     4.54432
evaluation_0/Rewards Std                      1.01677
evaluation_0/Rewards Max                      7.04763
evaluation_0/Rewards Min                     -0.523036
evaluation_0/Returns Mean                  4528.99
evaluation_0/Returns Std                    217.726
evaluation_0/Returns Max                   4821.58
evaluation_0/Returns Min                   4218.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4528.99
time/epoch (s)                                0
time/total (s)                             5701.53
Epoch                                       367
---------------------------------------  ----------------
2022-11-16 17:49:56.899608 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 368 finished
---------------------------------------  ---------------
epoch                                       368
total_step                               373000
replay_pool/size                         373000
trainer/alpha                                 0.0639327
trainer/alpha_loss                           -0.27195
trainer/entropy                              -5.90111
trainer/qf_loss                              22.4204
trainer/policy_loss                        -300.309
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.686
trainer/entropy_penalty                      -0.377274
trainer/entropy_percentage                   -0.00125471
trainer/Q1Pred Mean                         300.209
trainer/Q1Pred Std                           62.8986
trainer/Q1Pred Max                          378.793
trainer/Q1Pred Min                            9.08309
trainer/Q2Pred Mean                         299.256
trainer/Q2Pred Std                           63.8478
trainer/Q2Pred Max                          378.682
trainer/Q2Pred Min                          -14.7515
trainer/QTargetWithReg Mean                 298.739
trainer/QTargetWithReg Std                   63.34
trainer/QTargetWithReg Max                  378.87
trainer/QTargetWithReg Min                   -0.628542
trainer/PolicyLossWithoutReg Mean           300.686
trainer/PolicyLossWithoutReg Std             61.1963
trainer/PolicyLossWithoutReg Max            379.072
trainer/PolicyLossWithoutReg Min             17.7278
exploration/num steps total              373000
exploration/num paths total                1119
exploration/path length this epoch Mean     755
exploration/path length this epoch Std        0
exploration/path length this epoch Max      755
exploration/path length this epoch Min      755
exploration/Rewards Mean                      3.7998
exploration/Rewards Std                       0.995932
exploration/Rewards Max                       6.88837
exploration/Rewards Min                      -0.650411
exploration/Returns Mean                   2868.85
exploration/Returns Std                       0
exploration/Returns Max                    2868.85
exploration/Returns Min                    2868.85
exploration/Num Paths                         1
exploration/Average Returns                2868.85
evaluation_0/num steps total                  2.8645e+06
evaluation_0/num paths total               6340
evaluation_0/path length Mean               949.125
evaluation_0/path length Std                102.444
evaluation_0/path length Max               1000
evaluation_0/path length Min                692
evaluation_0/Rewards Mean                     4.58604
evaluation_0/Rewards Std                      1.10501
evaluation_0/Rewards Max                      9.96067
evaluation_0/Rewards Min                     -0.573152
evaluation_0/Returns Mean                  4352.73
evaluation_0/Returns Std                    464.422
evaluation_0/Returns Max                   4743.96
evaluation_0/Returns Min                   3198.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4352.73
time/epoch (s)                                0
time/total (s)                             5713.96
Epoch                                       368
---------------------------------------  ---------------
2022-11-16 17:50:12.257617 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 369 finished
---------------------------------------  ----------------
epoch                                       369
total_step                               374000
replay_pool/size                         374000
trainer/alpha                                 0.0628404
trainer/alpha_loss                            0.381603
trainer/entropy                              -6.1379
trainer/qf_loss                              15.7205
trainer/policy_loss                        -295.1
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.485
trainer/entropy_penalty                      -0.385708
trainer/entropy_percentage                   -0.00130534
trainer/Q1Pred Mean                         294.449
trainer/Q1Pred Std                           66.5382
trainer/Q1Pred Max                          378.915
trainer/Q1Pred Min                           11.9084
trainer/Q2Pred Mean                         294.77
trainer/Q2Pred Std                           66.5704
trainer/Q2Pred Max                          378.575
trainer/Q2Pred Min                           16.2558
trainer/QTargetWithReg Mean                 294.412
trainer/QTargetWithReg Std                   66.2615
trainer/QTargetWithReg Max                  378.064
trainer/QTargetWithReg Min                    7.75168
trainer/PolicyLossWithoutReg Mean           295.485
trainer/PolicyLossWithoutReg Std             65.198
trainer/PolicyLossWithoutReg Max            379.509
trainer/PolicyLossWithoutReg Min             15.3124
exploration/num steps total              374000
exploration/num paths total                1120
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53892
exploration/Rewards Std                       1.02522
exploration/Rewards Max                       7.50059
exploration/Rewards Min                      -0.616589
exploration/Returns Mean                   4538.92
exploration/Returns Std                       0
exploration/Returns Max                    4538.92
exploration/Returns Min                    4538.92
exploration/Num Paths                         1
exploration/Average Returns                4538.92
evaluation_0/num steps total                  2.87207e+06
evaluation_0/num paths total               6348
evaluation_0/path length Mean               946.5
evaluation_0/path length Std                100.929
evaluation_0/path length Max               1000
evaluation_0/path length Min                706
evaluation_0/Rewards Mean                     4.52951
evaluation_0/Rewards Std                      1.16798
evaluation_0/Rewards Max                      8.30776
evaluation_0/Rewards Min                     -0.56562
evaluation_0/Returns Mean                  4287.18
evaluation_0/Returns Std                    450.657
evaluation_0/Returns Max                   4699.17
evaluation_0/Returns Min                   3183.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4287.18
time/epoch (s)                                0
time/total (s)                             5729.32
Epoch                                       369
---------------------------------------  ----------------
2022-11-16 17:50:24.879232 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 370 finished
---------------------------------------  ----------------
epoch                                       370
total_step                               375000
replay_pool/size                         375000
trainer/alpha                                 0.0643418
trainer/alpha_loss                           -1.87213
trainer/entropy                              -5.31759
trainer/qf_loss                              32.115
trainer/policy_loss                        -298.057
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.399
trainer/entropy_penalty                      -0.342143
trainer/entropy_percentage                   -0.0011466
trainer/Q1Pred Mean                         295.797
trainer/Q1Pred Std                           72.8848
trainer/Q1Pred Max                          387.2
trainer/Q1Pred Min                          -40.1851
trainer/Q2Pred Mean                         296.275
trainer/Q2Pred Std                           71.9505
trainer/Q2Pred Max                          384.723
trainer/Q2Pred Min                          -40.5847
trainer/QTargetWithReg Mean                 296.176
trainer/QTargetWithReg Std                   71.6578
trainer/QTargetWithReg Max                  385.6
trainer/QTargetWithReg Min                    0.164019
trainer/PolicyLossWithoutReg Mean           298.399
trainer/PolicyLossWithoutReg Std             69.9662
trainer/PolicyLossWithoutReg Max            386.592
trainer/PolicyLossWithoutReg Min            -22.3306
exploration/num steps total              375000
exploration/num paths total                1121
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.22878
exploration/Rewards Std                       1.14127
exploration/Rewards Max                       6.2751
exploration/Rewards Min                      -0.474579
exploration/Returns Mean                   4228.78
exploration/Returns Std                       0
exploration/Returns Max                    4228.78
exploration/Returns Min                    4228.78
exploration/Num Paths                         1
exploration/Average Returns                4228.78
evaluation_0/num steps total                  2.87994e+06
evaluation_0/num paths total               6356
evaluation_0/path length Mean               983.5
evaluation_0/path length Std                 43.6549
evaluation_0/path length Max               1000
evaluation_0/path length Min                868
evaluation_0/Rewards Mean                     4.28478
evaluation_0/Rewards Std                      0.968249
evaluation_0/Rewards Max                      6.73591
evaluation_0/Rewards Min                     -0.606654
evaluation_0/Returns Mean                  4214.08
evaluation_0/Returns Std                    214.487
evaluation_0/Returns Max                   4552.56
evaluation_0/Returns Min                   3751.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4214.08
time/epoch (s)                                0
time/total (s)                             5741.94
Epoch                                       370
---------------------------------------  ----------------
2022-11-16 17:50:37.306694 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 371 finished
---------------------------------------  ----------------
epoch                                       371
total_step                               376000
replay_pool/size                         376000
trainer/alpha                                 0.062617
trainer/alpha_loss                            0.323912
trainer/entropy                              -6.11691
trainer/qf_loss                              21.7017
trainer/policy_loss                        -295.919
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         296.302
trainer/entropy_penalty                      -0.383022
trainer/entropy_percentage                   -0.00129267
trainer/Q1Pred Mean                         294.489
trainer/Q1Pred Std                           74.9473
trainer/Q1Pred Max                          379.641
trainer/Q1Pred Min                           13.8156
trainer/Q2Pred Mean                         294.483
trainer/Q2Pred Std                           75.2935
trainer/Q2Pred Max                          376.82
trainer/Q2Pred Min                           18.6363
trainer/QTargetWithReg Mean                 294.516
trainer/QTargetWithReg Std                   75.2353
trainer/QTargetWithReg Max                  375.834
trainer/QTargetWithReg Min                   21.9329
trainer/PolicyLossWithoutReg Mean           296.302
trainer/PolicyLossWithoutReg Std             73.3514
trainer/PolicyLossWithoutReg Max            377.155
trainer/PolicyLossWithoutReg Min             23.4067
exploration/num steps total              376000
exploration/num paths total                1122
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27127
exploration/Rewards Std                       1.01359
exploration/Rewards Max                       6.73901
exploration/Rewards Min                      -0.570263
exploration/Returns Mean                   4271.27
exploration/Returns Std                       0
exploration/Returns Max                    4271.27
exploration/Returns Min                    4271.27
exploration/Num Paths                         1
exploration/Average Returns                4271.27
evaluation_0/num steps total                  2.88744e+06
evaluation_0/num paths total               6364
evaluation_0/path length Mean               937.625
evaluation_0/path length Std                128.057
evaluation_0/path length Max               1000
evaluation_0/path length Min                613
evaluation_0/Rewards Mean                     4.53615
evaluation_0/Rewards Std                      1.03656
evaluation_0/Rewards Max                      7.51276
evaluation_0/Rewards Min                     -0.643094
evaluation_0/Returns Mean                  4253.21
evaluation_0/Returns Std                    593.18
evaluation_0/Returns Max                   4618.17
evaluation_0/Returns Min                   2751.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4253.21
time/epoch (s)                                0
time/total (s)                             5754.37
Epoch                                       371
---------------------------------------  ----------------
2022-11-16 17:50:51.907167 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 372 finished
---------------------------------------  ----------------
epoch                                       372
total_step                               377000
replay_pool/size                         377000
trainer/alpha                                 0.0644089
trainer/alpha_loss                           -0.481247
trainer/entropy                              -5.82453
trainer/qf_loss                              23.7184
trainer/policy_loss                        -294.434
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.809
trainer/entropy_penalty                      -0.375151
trainer/entropy_percentage                   -0.00127252
trainer/Q1Pred Mean                         293.854
trainer/Q1Pred Std                           70.2858
trainer/Q1Pred Max                          382.2
trainer/Q1Pred Min                           12.9027
trainer/Q2Pred Mean                         293.766
trainer/Q2Pred Std                           70.3374
trainer/Q2Pred Max                          380.637
trainer/Q2Pred Min                           14.864
trainer/QTargetWithReg Mean                 294.142
trainer/QTargetWithReg Std                   70.3696
trainer/QTargetWithReg Max                  377.942
trainer/QTargetWithReg Min                   17.3613
trainer/PolicyLossWithoutReg Mean           294.809
trainer/PolicyLossWithoutReg Std             69.7668
trainer/PolicyLossWithoutReg Max            379.502
trainer/PolicyLossWithoutReg Min             16.433
exploration/num steps total              377000
exploration/num paths total                1123
exploration/path length this epoch Mean     856
exploration/path length this epoch Std        0
exploration/path length this epoch Max      856
exploration/path length this epoch Min      856
exploration/Rewards Mean                      4.44695
exploration/Rewards Std                       1.27351
exploration/Rewards Max                       7.31609
exploration/Rewards Min                      -0.65416
exploration/Returns Mean                   3806.59
exploration/Returns Std                       0
exploration/Returns Max                    3806.59
exploration/Returns Min                    3806.59
exploration/Num Paths                         1
exploration/Average Returns                3806.59
evaluation_0/num steps total                  2.89485e+06
evaluation_0/num paths total               6373
evaluation_0/path length Mean               822.778
evaluation_0/path length Std                254.915
evaluation_0/path length Max               1000
evaluation_0/path length Min                282
evaluation_0/Rewards Mean                     4.01001
evaluation_0/Rewards Std                      1.2093
evaluation_0/Rewards Max                      9.21975
evaluation_0/Rewards Min                     -0.560155
evaluation_0/Returns Mean                  3299.35
evaluation_0/Returns Std                   1218.74
evaluation_0/Returns Max                   4191.93
evaluation_0/Returns Min                    554.253
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3299.35
time/epoch (s)                                0
time/total (s)                             5768.96
Epoch                                       372
---------------------------------------  ----------------
2022-11-16 17:51:04.461396 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 373 finished
---------------------------------------  ----------------
epoch                                       373
total_step                               378000
replay_pool/size                         378000
trainer/alpha                                 0.0631826
trainer/alpha_loss                            0.837791
trainer/entropy                              -6.30335
trainer/qf_loss                              29.8748
trainer/policy_loss                        -299.111
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.509
trainer/entropy_penalty                      -0.398262
trainer/entropy_percentage                   -0.00132971
trainer/Q1Pred Mean                         297.917
trainer/Q1Pred Std                           59.2639
trainer/Q1Pred Max                          372.589
trainer/Q1Pred Min                           16.9045
trainer/Q2Pred Mean                         297.39
trainer/Q2Pred Std                           59.0438
trainer/Q2Pred Max                          370.763
trainer/Q2Pred Min                           14.4249
trainer/QTargetWithReg Mean                 298.063
trainer/QTargetWithReg Std                   59.6879
trainer/QTargetWithReg Max                  372.649
trainer/QTargetWithReg Min                    6.89937
trainer/PolicyLossWithoutReg Mean           299.509
trainer/PolicyLossWithoutReg Std             58.5683
trainer/PolicyLossWithoutReg Max            370.911
trainer/PolicyLossWithoutReg Min             21.4216
exploration/num steps total              378000
exploration/num paths total                1124
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.35453
exploration/Rewards Std                       0.940278
exploration/Rewards Max                       6.60027
exploration/Rewards Min                      -0.634198
exploration/Returns Mean                   4354.53
exploration/Returns Std                       0
exploration/Returns Max                    4354.53
exploration/Returns Min                    4354.53
exploration/Num Paths                         1
exploration/Average Returns                4354.53
evaluation_0/num steps total                  2.90272e+06
evaluation_0/num paths total               6381
evaluation_0/path length Mean               983.875
evaluation_0/path length Std                 33.0924
evaluation_0/path length Max               1000
evaluation_0/path length Min                900
evaluation_0/Rewards Mean                     4.32543
evaluation_0/Rewards Std                      1.26738
evaluation_0/Rewards Max                      7.99422
evaluation_0/Rewards Min                     -0.629115
evaluation_0/Returns Mean                  4255.68
evaluation_0/Returns Std                    214.392
evaluation_0/Returns Max                   4496.5
evaluation_0/Returns Min                   3820.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4255.68
time/epoch (s)                                0
time/total (s)                             5781.52
Epoch                                       373
---------------------------------------  ----------------
2022-11-16 17:51:15.808444 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 374 finished
---------------------------------------  ----------------
epoch                                       374
total_step                               379000
replay_pool/size                         379000
trainer/alpha                                 0.0622846
trainer/alpha_loss                           -0.0891655
trainer/entropy                              -5.96788
trainer/qf_loss                              35.7967
trainer/policy_loss                        -302.918
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.29
trainer/entropy_penalty                      -0.371707
trainer/entropy_percentage                   -0.00122558
trainer/Q1Pred Mean                         302.437
trainer/Q1Pred Std                           59.4076
trainer/Q1Pred Max                          386.777
trainer/Q1Pred Min                           22.3805
trainer/Q2Pred Mean                         301.453
trainer/Q2Pred Std                           59.1303
trainer/Q2Pred Max                          385.313
trainer/Q2Pred Min                           24.0848
trainer/QTargetWithReg Mean                 300.869
trainer/QTargetWithReg Std                   60.7705
trainer/QTargetWithReg Max                  384.309
trainer/QTargetWithReg Min                   24.7322
trainer/PolicyLossWithoutReg Mean           303.29
trainer/PolicyLossWithoutReg Std             58.1208
trainer/PolicyLossWithoutReg Max            384.719
trainer/PolicyLossWithoutReg Min             22.4989
exploration/num steps total              379000
exploration/num paths total                1125
exploration/path length this epoch Mean     668
exploration/path length this epoch Std        0
exploration/path length this epoch Max      668
exploration/path length this epoch Min      668
exploration/Rewards Mean                      4.23813
exploration/Rewards Std                       1.32846
exploration/Rewards Max                       8.10669
exploration/Rewards Min                      -0.698768
exploration/Returns Mean                   2831.07
exploration/Returns Std                       0
exploration/Returns Max                    2831.07
exploration/Returns Min                    2831.07
exploration/Num Paths                         1
exploration/Average Returns                2831.07
evaluation_0/num steps total                  2.91072e+06
evaluation_0/num paths total               6389
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53889
evaluation_0/Rewards Std                      1.10101
evaluation_0/Rewards Max                      7.71079
evaluation_0/Rewards Min                     -0.637064
evaluation_0/Returns Mean                  4538.89
evaluation_0/Returns Std                    153.702
evaluation_0/Returns Max                   4710.4
evaluation_0/Returns Min                   4229.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4538.89
time/epoch (s)                                0
time/total (s)                             5792.87
Epoch                                       374
---------------------------------------  ----------------
2022-11-16 17:51:29.110829 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 375 finished
---------------------------------------  ----------------
epoch                                       375
total_step                               380000
replay_pool/size                         380000
trainer/alpha                                 0.0642168
trainer/alpha_loss                            0.151072
trainer/entropy                              -6.05503
trainer/qf_loss                              24.0273
trainer/policy_loss                        -298.003
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.392
trainer/entropy_penalty                      -0.388834
trainer/entropy_percentage                   -0.0013031
trainer/Q1Pred Mean                         298.823
trainer/Q1Pred Std                           65.0002
trainer/Q1Pred Max                          382.727
trainer/Q1Pred Min                           13.3908
trainer/Q2Pred Mean                         297.879
trainer/Q2Pred Std                           64.9171
trainer/Q2Pred Max                          379.422
trainer/Q2Pred Min                           15.8453
trainer/QTargetWithReg Mean                 298.655
trainer/QTargetWithReg Std                   64.5852
trainer/QTargetWithReg Max                  379.058
trainer/QTargetWithReg Min                   17.981
trainer/PolicyLossWithoutReg Mean           298.392
trainer/PolicyLossWithoutReg Std             64.0835
trainer/PolicyLossWithoutReg Max            379.445
trainer/PolicyLossWithoutReg Min             12.4006
exploration/num steps total              380000
exploration/num paths total                1127
exploration/path length this epoch Mean      33.5
exploration/path length this epoch Std       15.5
exploration/path length this epoch Max       49
exploration/path length this epoch Min       18
exploration/Rewards Mean                      1.4321
exploration/Rewards Std                       1.49732
exploration/Rewards Max                       3.99933
exploration/Rewards Min                      -0.631492
exploration/Returns Mean                     47.9754
exploration/Returns Std                      46.0462
exploration/Returns Max                      94.0216
exploration/Returns Min                       1.92917
exploration/Num Paths                         2
exploration/Average Returns                  47.9754
evaluation_0/num steps total                  2.91872e+06
evaluation_0/num paths total               6397
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59991
evaluation_0/Rewards Std                      1.06387
evaluation_0/Rewards Max                      6.9797
evaluation_0/Rewards Min                     -0.553391
evaluation_0/Returns Mean                  4599.91
evaluation_0/Returns Std                    131.558
evaluation_0/Returns Max                   4785.17
evaluation_0/Returns Min                   4368.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4599.91
time/epoch (s)                                0
time/total (s)                             5806.17
Epoch                                       375
---------------------------------------  ----------------
2022-11-16 17:51:41.620615 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 376 finished
---------------------------------------  ---------------
epoch                                       376
total_step                               381000
replay_pool/size                         381000
trainer/alpha                                 0.0652813
trainer/alpha_loss                           -0.28395
trainer/entropy                              -5.89595
trainer/qf_loss                              30.1375
trainer/policy_loss                        -301.139
trainer/adversary_policy_loss                14.4082
trainer/policy_loss_without_entropy         301.524
trainer/entropy_penalty                      -0.384896
trainer/entropy_percentage                   -0.0012765
trainer/Q1Pred Mean                         299.516
trainer/Q1Pred Std                           55.6794
trainer/Q1Pred Max                          381.107
trainer/Q1Pred Min                           50.2082
trainer/Q2Pred Mean                         299.887
trainer/Q2Pred Std                           55.8106
trainer/Q2Pred Max                          378.065
trainer/Q2Pred Min                           46.0132
trainer/QTargetWithReg Mean                 300.476
trainer/QTargetWithReg Std                   55.7568
trainer/QTargetWithReg Max                  380.303
trainer/QTargetWithReg Min                   39.5812
trainer/PolicyLossWithoutReg Mean           301.524
trainer/PolicyLossWithoutReg Std             54.5798
trainer/PolicyLossWithoutReg Max            378.671
trainer/PolicyLossWithoutReg Min             50.1995
exploration/num steps total              381000
exploration/num paths total                1128
exploration/path length this epoch Mean     280
exploration/path length this epoch Std        0
exploration/path length this epoch Max      280
exploration/path length this epoch Min      280
exploration/Rewards Mean                      3.56405
exploration/Rewards Std                       1.16479
exploration/Rewards Max                       5.38041
exploration/Rewards Min                      -0.481463
exploration/Returns Mean                    997.934
exploration/Returns Std                       0
exploration/Returns Max                     997.934
exploration/Returns Min                     997.934
exploration/Num Paths                         1
exploration/Average Returns                 997.934
evaluation_0/num steps total                  2.9265e+06
evaluation_0/num paths total               6405
evaluation_0/path length Mean               973.125
evaluation_0/path length Std                 71.1046
evaluation_0/path length Max               1000
evaluation_0/path length Min                785
evaluation_0/Rewards Mean                     4.37792
evaluation_0/Rewards Std                      1.0155
evaluation_0/Rewards Max                      8.18708
evaluation_0/Rewards Min                     -0.705702
evaluation_0/Returns Mean                  4260.26
evaluation_0/Returns Std                    279.539
evaluation_0/Returns Max                   4535.36
evaluation_0/Returns Min                   3562.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4260.26
time/epoch (s)                                0
time/total (s)                             5818.68
Epoch                                       376
---------------------------------------  ---------------
2022-11-16 17:51:53.856665 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 377 finished
---------------------------------------  ---------------
epoch                                       377
total_step                               382000
replay_pool/size                         382000
trainer/alpha                                 0.0634189
trainer/alpha_loss                           -1.32806
trainer/entropy                              -5.51847
trainer/qf_loss                              18.9375
trainer/policy_loss                        -300.249
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.599
trainer/entropy_penalty                      -0.349975
trainer/entropy_percentage                   -0.00116426
trainer/Q1Pred Mean                         299.997
trainer/Q1Pred Std                           61.4674
trainer/Q1Pred Max                          378.912
trainer/Q1Pred Min                            2.23626
trainer/Q2Pred Mean                         300.169
trainer/Q2Pred Std                           61.2677
trainer/Q2Pred Max                          379.434
trainer/Q2Pred Min                           13.1103
trainer/QTargetWithReg Mean                 299.506
trainer/QTargetWithReg Std                   62.167
trainer/QTargetWithReg Max                  381.075
trainer/QTargetWithReg Min                    2.93388
trainer/PolicyLossWithoutReg Mean           300.599
trainer/PolicyLossWithoutReg Std             60.4072
trainer/PolicyLossWithoutReg Max            379.087
trainer/PolicyLossWithoutReg Min              3.82974
exploration/num steps total              382000
exploration/num paths total                1129
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.89782
exploration/Rewards Std                       1.14952
exploration/Rewards Max                       6.3227
exploration/Rewards Min                      -0.572901
exploration/Returns Mean                   3897.82
exploration/Returns Std                       0
exploration/Returns Max                    3897.82
exploration/Returns Min                    3897.82
exploration/Num Paths                         1
exploration/Average Returns                3897.82
evaluation_0/num steps total                  2.9345e+06
evaluation_0/num paths total               6413
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69964
evaluation_0/Rewards Std                      1.01449
evaluation_0/Rewards Max                      7.65627
evaluation_0/Rewards Min                     -0.577446
evaluation_0/Returns Mean                  4699.64
evaluation_0/Returns Std                    195.146
evaluation_0/Returns Max                   4947.72
evaluation_0/Returns Min                   4282.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4699.64
time/epoch (s)                                0
time/total (s)                             5830.91
Epoch                                       377
---------------------------------------  ---------------
2022-11-16 17:52:07.717251 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 378 finished
---------------------------------------  ----------------
epoch                                       378
total_step                               383000
replay_pool/size                         383000
trainer/alpha                                 0.0610172
trainer/alpha_loss                           -0.0532431
trainer/entropy                              -5.98096
trainer/qf_loss                              18.2007
trainer/policy_loss                        -295.51
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.874
trainer/entropy_penalty                      -0.364942
trainer/entropy_percentage                   -0.00123343
trainer/Q1Pred Mean                         294.555
trainer/Q1Pred Std                           69.0012
trainer/Q1Pred Max                          381.69
trainer/Q1Pred Min                            8.5503
trainer/Q2Pred Mean                         293.985
trainer/Q2Pred Std                           69.6365
trainer/Q2Pred Max                          383.306
trainer/Q2Pred Min                            5.18301
trainer/QTargetWithReg Mean                 294.638
trainer/QTargetWithReg Std                   69.6166
trainer/QTargetWithReg Max                  383.188
trainer/QTargetWithReg Min                   12.1589
trainer/PolicyLossWithoutReg Mean           295.874
trainer/PolicyLossWithoutReg Std             67.886
trainer/PolicyLossWithoutReg Max            381.801
trainer/PolicyLossWithoutReg Min             12.4094
exploration/num steps total              383000
exploration/num paths total                1130
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.40259
exploration/Rewards Std                       1.10743
exploration/Rewards Max                       6.72513
exploration/Rewards Min                      -0.61427
exploration/Returns Mean                   4402.59
exploration/Returns Std                       0
exploration/Returns Max                    4402.59
exploration/Returns Min                    4402.59
exploration/Num Paths                         1
exploration/Average Returns                4402.59
evaluation_0/num steps total                  2.94207e+06
evaluation_0/num paths total               6421
evaluation_0/path length Mean               945.625
evaluation_0/path length Std                143.863
evaluation_0/path length Max               1000
evaluation_0/path length Min                565
evaluation_0/Rewards Mean                     4.54303
evaluation_0/Rewards Std                      1.20682
evaluation_0/Rewards Max                      8.14361
evaluation_0/Rewards Min                     -0.475258
evaluation_0/Returns Mean                  4296
evaluation_0/Returns Std                    766.423
evaluation_0/Returns Max                   4926.23
evaluation_0/Returns Min                   2351.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4296
time/epoch (s)                                0
time/total (s)                             5844.77
Epoch                                       378
---------------------------------------  ----------------
2022-11-16 17:52:20.800629 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 379 finished
---------------------------------------  ----------------
epoch                                       379
total_step                               384000
replay_pool/size                         384000
trainer/alpha                                 0.0631566
trainer/alpha_loss                           -0.883266
trainer/entropy                              -5.68024
trainer/qf_loss                              14.4354
trainer/policy_loss                        -306.937
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.296
trainer/entropy_penalty                      -0.358745
trainer/entropy_percentage                   -0.00116743
trainer/Q1Pred Mean                         306.492
trainer/Q1Pred Std                           53.7344
trainer/Q1Pred Max                          377.155
trainer/Q1Pred Min                            1.72116
trainer/Q2Pred Mean                         306.845
trainer/Q2Pred Std                           53.9328
trainer/Q2Pred Max                          377.349
trainer/Q2Pred Min                           -6.51354
trainer/QTargetWithReg Mean                 306.995
trainer/QTargetWithReg Std                   53.8559
trainer/QTargetWithReg Max                  376.555
trainer/QTargetWithReg Min                    3.05825
trainer/PolicyLossWithoutReg Mean           307.296
trainer/PolicyLossWithoutReg Std             52.3465
trainer/PolicyLossWithoutReg Max            377.292
trainer/PolicyLossWithoutReg Min             29.1298
exploration/num steps total              384000
exploration/num paths total                1131
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44854
exploration/Rewards Std                       1.09386
exploration/Rewards Max                       6.94624
exploration/Rewards Min                      -0.605158
exploration/Returns Mean                   4448.54
exploration/Returns Std                       0
exploration/Returns Max                    4448.54
exploration/Returns Min                    4448.54
exploration/Num Paths                         1
exploration/Average Returns                4448.54
evaluation_0/num steps total                  2.94944e+06
evaluation_0/num paths total               6429
evaluation_0/path length Mean               921
evaluation_0/path length Std                102.456
evaluation_0/path length Max               1000
evaluation_0/path length Min                773
evaluation_0/Rewards Mean                     4.33841
evaluation_0/Rewards Std                      1.07833
evaluation_0/Rewards Max                      7.48005
evaluation_0/Rewards Min                     -0.676082
evaluation_0/Returns Mean                  3995.68
evaluation_0/Returns Std                    620.012
evaluation_0/Returns Max                   4711.21
evaluation_0/Returns Min                   3061.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3995.68
time/epoch (s)                                0
time/total (s)                             5857.86
Epoch                                       379
---------------------------------------  ----------------
2022-11-16 17:52:32.107807 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 380 finished
---------------------------------------  ----------------
epoch                                       380
total_step                               385000
replay_pool/size                         385000
trainer/alpha                                 0.0635155
trainer/alpha_loss                           -0.106696
trainer/entropy                              -5.96129
trainer/qf_loss                              23.8349
trainer/policy_loss                        -294.917
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.295
trainer/entropy_penalty                      -0.378635
trainer/entropy_percentage                   -0.00128222
trainer/Q1Pred Mean                         293.967
trainer/Q1Pred Std                           72.2358
trainer/Q1Pred Max                          389.98
trainer/Q1Pred Min                            5.95104
trainer/Q2Pred Mean                         293.575
trainer/Q2Pred Std                           72.1453
trainer/Q2Pred Max                          385.317
trainer/Q2Pred Min                            4.95589
trainer/QTargetWithReg Mean                 294.759
trainer/QTargetWithReg Std                   72.2751
trainer/QTargetWithReg Max                  387.443
trainer/QTargetWithReg Min                    2.70665
trainer/PolicyLossWithoutReg Mean           295.295
trainer/PolicyLossWithoutReg Std             71.0724
trainer/PolicyLossWithoutReg Max            386.579
trainer/PolicyLossWithoutReg Min              7.4892
exploration/num steps total              385000
exploration/num paths total                1132
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.94851
exploration/Rewards Std                       0.916503
exploration/Rewards Max                       5.99126
exploration/Rewards Min                      -0.718631
exploration/Returns Mean                   3948.51
exploration/Returns Std                       0
exploration/Returns Max                    3948.51
exploration/Returns Min                    3948.51
exploration/Num Paths                         1
exploration/Average Returns                3948.51
evaluation_0/num steps total                  2.95744e+06
evaluation_0/num paths total               6437
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.33797
evaluation_0/Rewards Std                      1.00572
evaluation_0/Rewards Max                      9.81229
evaluation_0/Rewards Min                     -0.784369
evaluation_0/Returns Mean                  4337.97
evaluation_0/Returns Std                    163.969
evaluation_0/Returns Max                   4694.49
evaluation_0/Returns Min                   4201.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4337.97
time/epoch (s)                                0
time/total (s)                             5869.16
Epoch                                       380
---------------------------------------  ----------------
2022-11-16 17:52:46.642260 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 381 finished
---------------------------------------  ----------------
epoch                                       381
total_step                               386000
replay_pool/size                         386000
trainer/alpha                                 0.0629812
trainer/alpha_loss                            0.410523
trainer/entropy                              -6.14847
trainer/qf_loss                              21.005
trainer/policy_loss                        -294.844
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         295.232
trainer/entropy_penalty                      -0.387238
trainer/entropy_percentage                   -0.00131164
trainer/Q1Pred Mean                         293.805
trainer/Q1Pred Std                           68.4207
trainer/Q1Pred Max                          382.503
trainer/Q1Pred Min                            9.80962
trainer/Q2Pred Mean                         294.061
trainer/Q2Pred Std                           69.0147
trainer/Q2Pred Max                          380.185
trainer/Q2Pred Min                           -4.53991
trainer/QTargetWithReg Mean                 294.132
trainer/QTargetWithReg Std                   68.3356
trainer/QTargetWithReg Max                  379.75
trainer/QTargetWithReg Min                    8.5745
trainer/PolicyLossWithoutReg Mean           295.232
trainer/PolicyLossWithoutReg Std             67.3198
trainer/PolicyLossWithoutReg Max            379.546
trainer/PolicyLossWithoutReg Min             -1.75857
exploration/num steps total              386000
exploration/num paths total                1135
exploration/path length this epoch Mean     333.333
exploration/path length this epoch Std      194.998
exploration/path length this epoch Max      609
exploration/path length this epoch Min      189
exploration/Rewards Mean                      3.53684
exploration/Rewards Std                       1.14709
exploration/Rewards Max                       6.23105
exploration/Rewards Min                      -0.818906
exploration/Returns Mean                   1178.95
exploration/Returns Std                     845.421
exploration/Returns Max                    2374.55
exploration/Returns Min                     579.393
exploration/Num Paths                         3
exploration/Average Returns                1178.95
evaluation_0/num steps total                  2.96478e+06
evaluation_0/num paths total               6445
evaluation_0/path length Mean               917.625
evaluation_0/path length Std                144.326
evaluation_0/path length Max               1000
evaluation_0/path length Min                627
evaluation_0/Rewards Mean                     4.46811
evaluation_0/Rewards Std                      1.0439
evaluation_0/Rewards Max                      8.81358
evaluation_0/Rewards Min                     -0.812028
evaluation_0/Returns Mean                  4100.05
evaluation_0/Returns Std                    712.88
evaluation_0/Returns Max                   4599.25
evaluation_0/Returns Min                   2675.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4100.05
time/epoch (s)                                0
time/total (s)                             5883.7
Epoch                                       381
---------------------------------------  ----------------
2022-11-16 17:52:58.742154 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 382 finished
---------------------------------------  ----------------
epoch                                       382
total_step                               387000
replay_pool/size                         387000
trainer/alpha                                 0.0624517
trainer/alpha_loss                            0.730514
trainer/entropy                              -6.2634
trainer/qf_loss                              18.7634
trainer/policy_loss                        -292.908
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.299
trainer/entropy_penalty                      -0.39116
trainer/entropy_percentage                   -0.00133365
trainer/Q1Pred Mean                         292.01
trainer/Q1Pred Std                           70.3625
trainer/Q1Pred Max                          373.696
trainer/Q1Pred Min                           20.5615
trainer/Q2Pred Mean                         291.547
trainer/Q2Pred Std                           70.8959
trainer/Q2Pred Max                          374.727
trainer/Q2Pred Min                            3.83233
trainer/QTargetWithReg Mean                 292.096
trainer/QTargetWithReg Std                   70.8538
trainer/QTargetWithReg Max                  376.291
trainer/QTargetWithReg Min                   15.5723
trainer/PolicyLossWithoutReg Mean           293.299
trainer/PolicyLossWithoutReg Std             69.2418
trainer/PolicyLossWithoutReg Max            375.013
trainer/PolicyLossWithoutReg Min             18.556
exploration/num steps total              387000
exploration/num paths total                1136
exploration/path length this epoch Mean     821
exploration/path length this epoch Std        0
exploration/path length this epoch Max      821
exploration/path length this epoch Min      821
exploration/Rewards Mean                      4.65941
exploration/Rewards Std                       1.1856
exploration/Rewards Max                       8.66777
exploration/Rewards Min                      -0.674405
exploration/Returns Mean                   3825.37
exploration/Returns Std                       0
exploration/Returns Max                    3825.37
exploration/Returns Min                    3825.37
exploration/Num Paths                         1
exploration/Average Returns                3825.37
evaluation_0/num steps total                  2.97263e+06
evaluation_0/num paths total               6453
evaluation_0/path length Mean               981.75
evaluation_0/path length Std                 48.285
evaluation_0/path length Max               1000
evaluation_0/path length Min                854
evaluation_0/Rewards Mean                     4.66178
evaluation_0/Rewards Std                      1.11026
evaluation_0/Rewards Max                      7.71963
evaluation_0/Rewards Min                     -0.763545
evaluation_0/Returns Mean                  4576.7
evaluation_0/Returns Std                    271.47
evaluation_0/Returns Max                   4783.1
evaluation_0/Returns Min                   3876.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4576.7
time/epoch (s)                                0
time/total (s)                             5895.8
Epoch                                       382
---------------------------------------  ----------------
2022-11-16 17:53:11.118065 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 383 finished
---------------------------------------  ----------------
epoch                                       383
total_step                               388000
replay_pool/size                         388000
trainer/alpha                                 0.0629028
trainer/alpha_loss                           -0.10866
trainer/entropy                              -5.96072
trainer/qf_loss                              19.3743
trainer/policy_loss                        -297.433
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         297.808
trainer/entropy_penalty                      -0.374946
trainer/entropy_percentage                   -0.00125902
trainer/Q1Pred Mean                         296.915
trainer/Q1Pred Std                           61.3267
trainer/Q1Pred Max                          378.11
trainer/Q1Pred Min                            4.41987
trainer/Q2Pred Mean                         297.069
trainer/Q2Pred Std                           61.1957
trainer/Q2Pred Max                          377.147
trainer/Q2Pred Min                            9.28362
trainer/QTargetWithReg Mean                 297.042
trainer/QTargetWithReg Std                   61.871
trainer/QTargetWithReg Max                  375.964
trainer/QTargetWithReg Min                    5.65075
trainer/PolicyLossWithoutReg Mean           297.808
trainer/PolicyLossWithoutReg Std             59.7286
trainer/PolicyLossWithoutReg Max            376.145
trainer/PolicyLossWithoutReg Min             11.0798
exploration/num steps total              388000
exploration/num paths total                1138
exploration/path length this epoch Mean     493.5
exploration/path length this epoch Std      140.5
exploration/path length this epoch Max      634
exploration/path length this epoch Min      353
exploration/Rewards Mean                      4.13718
exploration/Rewards Std                       1.24221
exploration/Rewards Max                       6.60784
exploration/Rewards Min                      -0.77425
exploration/Returns Mean                   2041.7
exploration/Returns Std                     793.897
exploration/Returns Max                    2835.6
exploration/Returns Min                    1247.8
exploration/Num Paths                         2
exploration/Average Returns                2041.7
evaluation_0/num steps total                  2.98060e+06
evaluation_0/num paths total               6461
evaluation_0/path length Mean               996.625
evaluation_0/path length Std                  8.92941
evaluation_0/path length Max               1000
evaluation_0/path length Min                973
evaluation_0/Rewards Mean                     4.38054
evaluation_0/Rewards Std                      1.04914
evaluation_0/Rewards Max                      7.13905
evaluation_0/Rewards Min                     -0.776233
evaluation_0/Returns Mean                  4365.76
evaluation_0/Returns Std                    236.771
evaluation_0/Returns Max                   4709.21
evaluation_0/Returns Min                   3935.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4365.76
time/epoch (s)                                0
time/total (s)                             5908.17
Epoch                                       383
---------------------------------------  ----------------
2022-11-16 17:53:24.235746 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 384 finished
---------------------------------------  ----------------
epoch                                       384
total_step                               389000
replay_pool/size                         389000
trainer/alpha                                 0.062124
trainer/alpha_loss                           -1.32547
trainer/entropy                              -5.52297
trainer/qf_loss                              20.5148
trainer/policy_loss                        -302.806
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.149
trainer/entropy_penalty                      -0.343109
trainer/entropy_percentage                   -0.00113182
trainer/Q1Pred Mean                         302.508
trainer/Q1Pred Std                           60.1934
trainer/Q1Pred Max                          378.658
trainer/Q1Pred Min                           11.8287
trainer/Q2Pred Mean                         302.881
trainer/Q2Pred Std                           60.1386
trainer/Q2Pred Max                          379.089
trainer/Q2Pred Min                           17.7188
trainer/QTargetWithReg Mean                 302.891
trainer/QTargetWithReg Std                   60.1247
trainer/QTargetWithReg Max                  377.514
trainer/QTargetWithReg Min                   14.1066
trainer/PolicyLossWithoutReg Mean           303.149
trainer/PolicyLossWithoutReg Std             59.3092
trainer/PolicyLossWithoutReg Max            378.457
trainer/PolicyLossWithoutReg Min             11.8713
exploration/num steps total              389000
exploration/num paths total                1139
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2621
exploration/Rewards Std                       1.01555
exploration/Rewards Max                       6.76993
exploration/Rewards Min                      -0.719263
exploration/Returns Mean                   4262.1
exploration/Returns Std                       0
exploration/Returns Max                    4262.1
exploration/Returns Min                    4262.1
exploration/Num Paths                         1
exploration/Average Returns                4262.1
evaluation_0/num steps total                  2.98860e+06
evaluation_0/num paths total               6469
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75756
evaluation_0/Rewards Std                      1.26472
evaluation_0/Rewards Max                      8.79522
evaluation_0/Rewards Min                     -0.807078
evaluation_0/Returns Mean                  4757.56
evaluation_0/Returns Std                     68.4971
evaluation_0/Returns Max                   4873.94
evaluation_0/Returns Min                   4672.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4757.56
time/epoch (s)                                0
time/total (s)                             5921.29
Epoch                                       384
---------------------------------------  ----------------
2022-11-16 17:53:36.770945 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 385 finished
---------------------------------------  ---------------
epoch                                       385
total_step                               390000
replay_pool/size                         390000
trainer/alpha                                 0.0614139
trainer/alpha_loss                            0.325976
trainer/entropy                              -6.11683
trainer/qf_loss                              22.4791
trainer/policy_loss                        -303.451
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.827
trainer/entropy_penalty                      -0.375659
trainer/entropy_percentage                   -0.00123642
trainer/Q1Pred Mean                         302.656
trainer/Q1Pred Std                           64.1164
trainer/Q1Pred Max                          382.883
trainer/Q1Pred Min                            8.39257
trainer/Q2Pred Mean                         302.5
trainer/Q2Pred Std                           64.0667
trainer/Q2Pred Max                          381.338
trainer/Q2Pred Min                            6.41415
trainer/QTargetWithReg Mean                 302.389
trainer/QTargetWithReg Std                   64.8251
trainer/QTargetWithReg Max                  381.624
trainer/QTargetWithReg Min                    4.3377
trainer/PolicyLossWithoutReg Mean           303.827
trainer/PolicyLossWithoutReg Std             62.7459
trainer/PolicyLossWithoutReg Max            381.028
trainer/PolicyLossWithoutReg Min              8.36102
exploration/num steps total              390000
exploration/num paths total                1140
exploration/path length this epoch Mean     781
exploration/path length this epoch Std        0
exploration/path length this epoch Max      781
exploration/path length this epoch Min      781
exploration/Rewards Mean                      4.06793
exploration/Rewards Std                       0.90892
exploration/Rewards Max                       6.01938
exploration/Rewards Min                      -0.651421
exploration/Returns Mean                   3177.05
exploration/Returns Std                       0
exploration/Returns Max                    3177.05
exploration/Returns Min                    3177.05
exploration/Num Paths                         1
exploration/Average Returns                3177.05
evaluation_0/num steps total                  2.9961e+06
evaluation_0/num paths total               6477
evaluation_0/path length Mean               937.25
evaluation_0/path length Std                166.021
evaluation_0/path length Max               1000
evaluation_0/path length Min                498
evaluation_0/Rewards Mean                     4.80011
evaluation_0/Rewards Std                      1.12412
evaluation_0/Rewards Max                      8.91829
evaluation_0/Rewards Min                     -0.844134
evaluation_0/Returns Mean                  4498.9
evaluation_0/Returns Std                    838.07
evaluation_0/Returns Max                   5008.92
evaluation_0/Returns Min                   2315.05
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4498.9
time/epoch (s)                                0
time/total (s)                             5933.83
Epoch                                       385
---------------------------------------  ---------------
2022-11-16 17:53:49.587638 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 386 finished
---------------------------------------  ----------------
epoch                                       386
total_step                               391000
replay_pool/size                         391000
trainer/alpha                                 0.0645125
trainer/alpha_loss                            0.24012
trainer/entropy                              -6.08761
trainer/qf_loss                              22.021
trainer/policy_loss                        -300.944
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.336
trainer/entropy_penalty                      -0.392727
trainer/entropy_percentage                   -0.00130328
trainer/Q1Pred Mean                         299.369
trainer/Q1Pred Std                           64.3717
trainer/Q1Pred Max                          384.394
trainer/Q1Pred Min                            0.561079
trainer/Q2Pred Mean                         299.943
trainer/Q2Pred Std                           64.4921
trainer/Q2Pred Max                          385.192
trainer/Q2Pred Min                           -1.53832
trainer/QTargetWithReg Mean                 299.458
trainer/QTargetWithReg Std                   64.5801
trainer/QTargetWithReg Max                  384.443
trainer/QTargetWithReg Min                    0.893094
trainer/PolicyLossWithoutReg Mean           301.336
trainer/PolicyLossWithoutReg Std             60.9382
trainer/PolicyLossWithoutReg Max            382.031
trainer/PolicyLossWithoutReg Min              4.40249
exploration/num steps total              391000
exploration/num paths total                1141
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.90395
exploration/Rewards Std                       0.948492
exploration/Rewards Max                       6.50558
exploration/Rewards Min                      -0.772257
exploration/Returns Mean                   3903.95
exploration/Returns Std                       0
exploration/Returns Max                    3903.95
exploration/Returns Min                    3903.95
exploration/Num Paths                         1
exploration/Average Returns                3903.95
evaluation_0/num steps total                  3.00372e+06
evaluation_0/num paths total               6485
evaluation_0/path length Mean               952.625
evaluation_0/path length Std                 92.5242
evaluation_0/path length Max               1000
evaluation_0/path length Min                725
evaluation_0/Rewards Mean                     4.51057
evaluation_0/Rewards Std                      1.06834
evaluation_0/Rewards Max                      9.24436
evaluation_0/Rewards Min                     -0.843587
evaluation_0/Returns Mean                  4296.88
evaluation_0/Returns Std                    379.831
evaluation_0/Returns Max                   4676.81
evaluation_0/Returns Min                   3428.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4296.88
time/epoch (s)                                0
time/total (s)                             5946.64
Epoch                                       386
---------------------------------------  ----------------
2022-11-16 17:54:03.076833 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 387 finished
---------------------------------------  ----------------
epoch                                       387
total_step                               392000
replay_pool/size                         392000
trainer/alpha                                 0.0625064
trainer/alpha_loss                            0.0364257
trainer/entropy                              -6.01314
trainer/qf_loss                              17.6014
trainer/policy_loss                        -299.249
trainer/adversary_policy_loss                14.2865
trainer/policy_loss_without_entropy         299.625
trainer/entropy_penalty                      -0.37586
trainer/entropy_percentage                   -0.00125443
trainer/Q1Pred Mean                         298.229
trainer/Q1Pred Std                           64.276
trainer/Q1Pred Max                          377.141
trainer/Q1Pred Min                           11.7909
trainer/Q2Pred Mean                         297.955
trainer/Q2Pred Std                           64.5412
trainer/Q2Pred Max                          375.652
trainer/Q2Pred Min                           13.5337
trainer/QTargetWithReg Mean                 298.405
trainer/QTargetWithReg Std                   64.3237
trainer/QTargetWithReg Max                  376.406
trainer/QTargetWithReg Min                   14.9327
trainer/PolicyLossWithoutReg Mean           299.625
trainer/PolicyLossWithoutReg Std             63.045
trainer/PolicyLossWithoutReg Max            376.364
trainer/PolicyLossWithoutReg Min             14.9112
exploration/num steps total              392000
exploration/num paths total                1142
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49454
exploration/Rewards Std                       0.980326
exploration/Rewards Max                       6.67233
exploration/Rewards Min                      -0.929524
exploration/Returns Mean                   4494.54
exploration/Returns Std                       0
exploration/Returns Max                    4494.54
exploration/Returns Min                    4494.54
exploration/Num Paths                         1
exploration/Average Returns                4494.54
evaluation_0/num steps total                  3.01172e+06
evaluation_0/num paths total               6493
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.30493
evaluation_0/Rewards Std                      1.11628
evaluation_0/Rewards Max                      7.40519
evaluation_0/Rewards Min                     -0.916825
evaluation_0/Returns Mean                  4304.93
evaluation_0/Returns Std                    153.851
evaluation_0/Returns Max                   4582.69
evaluation_0/Returns Min                   4053.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4304.93
time/epoch (s)                                0
time/total (s)                             5960.13
Epoch                                       387
---------------------------------------  ----------------
2022-11-16 17:54:15.129520 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 388 finished
---------------------------------------  ----------------
epoch                                       388
total_step                               393000
replay_pool/size                         393000
trainer/alpha                                 0.0619271
trainer/alpha_loss                           -0.100018
trainer/entropy                              -5.96405
trainer/qf_loss                              24.0585
trainer/policy_loss                        -298.04
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.409
trainer/entropy_penalty                      -0.369336
trainer/entropy_percentage                   -0.00123768
trainer/Q1Pred Mean                         296.974
trainer/Q1Pred Std                           68.5204
trainer/Q1Pred Max                          383.118
trainer/Q1Pred Min                            7.24621
trainer/Q2Pred Mean                         297.585
trainer/Q2Pred Std                           68.5343
trainer/Q2Pred Max                          382.004
trainer/Q2Pred Min                            0.449636
trainer/QTargetWithReg Mean                 297.642
trainer/QTargetWithReg Std                   69.1982
trainer/QTargetWithReg Max                  382.88
trainer/QTargetWithReg Min                   -1.21211
trainer/PolicyLossWithoutReg Mean           298.409
trainer/PolicyLossWithoutReg Std             66.7281
trainer/PolicyLossWithoutReg Max            382.136
trainer/PolicyLossWithoutReg Min             10.2702
exploration/num steps total              393000
exploration/num paths total                1143
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47977
exploration/Rewards Std                       1.18828
exploration/Rewards Max                       7.00347
exploration/Rewards Min                      -0.511061
exploration/Returns Mean                   4479.77
exploration/Returns Std                       0
exploration/Returns Max                    4479.77
exploration/Returns Min                    4479.77
exploration/Num Paths                         1
exploration/Average Returns                4479.77
evaluation_0/num steps total                  3.01963e+06
evaluation_0/num paths total               6501
evaluation_0/path length Mean               988
evaluation_0/path length Std                 31.749
evaluation_0/path length Max               1000
evaluation_0/path length Min                904
evaluation_0/Rewards Mean                     4.8618
evaluation_0/Rewards Std                      1.15302
evaluation_0/Rewards Max                      9.82014
evaluation_0/Rewards Min                     -0.800963
evaluation_0/Returns Mean                  4803.46
evaluation_0/Returns Std                    151.452
evaluation_0/Returns Max                   4958.48
evaluation_0/Returns Min                   4452.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4803.46
time/epoch (s)                                0
time/total (s)                             5972.18
Epoch                                       388
---------------------------------------  ----------------
2022-11-16 17:54:27.391840 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 389 finished
---------------------------------------  ----------------
epoch                                       389
total_step                               394000
replay_pool/size                         394000
trainer/alpha                                 0.0623319
trainer/alpha_loss                           -0.00382204
trainer/entropy                              -5.99862
trainer/qf_loss                              16.3649
trainer/policy_loss                        -302.482
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.856
trainer/entropy_penalty                      -0.373906
trainer/entropy_percentage                   -0.0012346
trainer/Q1Pred Mean                         301.761
trainer/Q1Pred Std                           64.9414
trainer/Q1Pred Max                          386.733
trainer/Q1Pred Min                           -7.09291
trainer/Q2Pred Mean                         301.266
trainer/Q2Pred Std                           64.4558
trainer/Q2Pred Max                          384.895
trainer/Q2Pred Min                          -12.6109
trainer/QTargetWithReg Mean                 300.676
trainer/QTargetWithReg Std                   64.5784
trainer/QTargetWithReg Max                  383.491
trainer/QTargetWithReg Min                    0.654926
trainer/PolicyLossWithoutReg Mean           302.856
trainer/PolicyLossWithoutReg Std             63.5843
trainer/PolicyLossWithoutReg Max            386.747
trainer/PolicyLossWithoutReg Min              0.554013
exploration/num steps total              394000
exploration/num paths total                1145
exploration/path length this epoch Mean     264.5
exploration/path length this epoch Std      168.5
exploration/path length this epoch Max      433
exploration/path length this epoch Min       96
exploration/Rewards Mean                      3.16421
exploration/Rewards Std                       1.41834
exploration/Rewards Max                       6.45298
exploration/Rewards Min                      -0.874581
exploration/Returns Mean                    836.933
exploration/Returns Std                     616.487
exploration/Returns Max                    1453.42
exploration/Returns Min                     220.446
exploration/Num Paths                         2
exploration/Average Returns                 836.933
evaluation_0/num steps total                  3.02710e+06
evaluation_0/num paths total               6509
evaluation_0/path length Mean               934.625
evaluation_0/path length Std                172.966
evaluation_0/path length Max               1000
evaluation_0/path length Min                477
evaluation_0/Rewards Mean                     4.07268
evaluation_0/Rewards Std                      0.913575
evaluation_0/Rewards Max                      6.9725
evaluation_0/Rewards Min                     -0.461999
evaluation_0/Returns Mean                  3806.42
evaluation_0/Returns Std                    734.316
evaluation_0/Returns Max                   4414.86
evaluation_0/Returns Min                   1915.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3806.42
time/epoch (s)                                0
time/total (s)                             5984.44
Epoch                                       389
---------------------------------------  ----------------
2022-11-16 17:54:40.872144 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 390 finished
---------------------------------------  ----------------
epoch                                       390
total_step                               395000
replay_pool/size                         395000
trainer/alpha                                 0.062497
trainer/alpha_loss                            0.642746
trainer/entropy                              -6.23183
trainer/qf_loss                              26.9124
trainer/policy_loss                        -292.887
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         293.277
trainer/entropy_penalty                      -0.389471
trainer/entropy_percentage                   -0.001328
trainer/Q1Pred Mean                         292.535
trainer/Q1Pred Std                           74.3393
trainer/Q1Pred Max                          383.738
trainer/Q1Pred Min                            3.28723
trainer/Q2Pred Mean                         291.787
trainer/Q2Pred Std                           74.3856
trainer/Q2Pred Max                          380.843
trainer/Q2Pred Min                           -8.1729
trainer/QTargetWithReg Mean                 291.934
trainer/QTargetWithReg Std                   73.9181
trainer/QTargetWithReg Max                  380.123
trainer/QTargetWithReg Min                   -6.82036
trainer/PolicyLossWithoutReg Mean           293.277
trainer/PolicyLossWithoutReg Std             73.231
trainer/PolicyLossWithoutReg Max            380.169
trainer/PolicyLossWithoutReg Min              0.155128
exploration/num steps total              395000
exploration/num paths total                1146
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.29693
exploration/Rewards Std                       1.00868
exploration/Rewards Max                       7.15997
exploration/Rewards Min                      -0.300669
exploration/Returns Mean                   4296.93
exploration/Returns Std                       0
exploration/Returns Max                    4296.93
exploration/Returns Min                    4296.93
exploration/Num Paths                         1
exploration/Average Returns                4296.93
evaluation_0/num steps total                  3.03510e+06
evaluation_0/num paths total               6517
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.2358
evaluation_0/Rewards Std                      1.18499
evaluation_0/Rewards Max                      7.70245
evaluation_0/Rewards Min                     -0.87874
evaluation_0/Returns Mean                  4235.8
evaluation_0/Returns Std                    189.878
evaluation_0/Returns Max                   4558.57
evaluation_0/Returns Min                   3859.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4235.8
time/epoch (s)                                0
time/total (s)                             5997.92
Epoch                                       390
---------------------------------------  ----------------
2022-11-16 17:54:53.428388 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 391 finished
---------------------------------------  ---------------
epoch                                       391
total_step                               396000
replay_pool/size                         396000
trainer/alpha                                 0.0628668
trainer/alpha_loss                           -0.239435
trainer/entropy                              -5.91346
trainer/qf_loss                              24.667
trainer/policy_loss                        -296.78
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         297.152
trainer/entropy_penalty                      -0.37176
trainer/entropy_percentage                   -0.00125108
trainer/Q1Pred Mean                         296.31
trainer/Q1Pred Std                           67.5838
trainer/Q1Pred Max                          384.221
trainer/Q1Pred Min                           22.2222
trainer/Q2Pred Mean                         295.521
trainer/Q2Pred Std                           67.6387
trainer/Q2Pred Max                          383.021
trainer/Q2Pred Min                           20.3891
trainer/QTargetWithReg Mean                 294.568
trainer/QTargetWithReg Std                   68.2323
trainer/QTargetWithReg Max                  382.797
trainer/QTargetWithReg Min                   17.667
trainer/PolicyLossWithoutReg Mean           297.152
trainer/PolicyLossWithoutReg Std             66.2645
trainer/PolicyLossWithoutReg Max            383.907
trainer/PolicyLossWithoutReg Min             21.2051
exploration/num steps total              396000
exploration/num paths total                1147
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.28898
exploration/Rewards Std                       1.15325
exploration/Rewards Max                       6.83989
exploration/Rewards Min                      -0.846909
exploration/Returns Mean                   4288.98
exploration/Returns Std                       0
exploration/Returns Max                    4288.98
exploration/Returns Min                    4288.98
exploration/Num Paths                         1
exploration/Average Returns                4288.98
evaluation_0/num steps total                  3.0427e+06
evaluation_0/num paths total               6525
evaluation_0/path length Mean               949.625
evaluation_0/path length Std                100.192
evaluation_0/path length Max               1000
evaluation_0/path length Min                700
evaluation_0/Rewards Mean                     4.62368
evaluation_0/Rewards Std                      1.33078
evaluation_0/Rewards Max                      9.45063
evaluation_0/Rewards Min                     -0.984279
evaluation_0/Returns Mean                  4390.76
evaluation_0/Returns Std                    506.999
evaluation_0/Returns Max                   4804.87
evaluation_0/Returns Min                   3169.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4390.76
time/epoch (s)                                0
time/total (s)                             6010.48
Epoch                                       391
---------------------------------------  ---------------
2022-11-16 17:55:06.207261 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 392 finished
---------------------------------------  ----------------
epoch                                       392
total_step                               397000
replay_pool/size                         397000
trainer/alpha                                 0.0637067
trainer/alpha_loss                            1.03643
trainer/entropy                              -6.3764
trainer/qf_loss                              27.7342
trainer/policy_loss                        -296.938
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         297.344
trainer/entropy_penalty                      -0.406219
trainer/entropy_percentage                   -0.00136616
trainer/Q1Pred Mean                         295.492
trainer/Q1Pred Std                           70.4673
trainer/Q1Pred Max                          378.857
trainer/Q1Pred Min                            3.01398
trainer/Q2Pred Mean                         296.142
trainer/Q2Pred Std                           70.0505
trainer/Q2Pred Max                          377.929
trainer/Q2Pred Min                            3.27273
trainer/QTargetWithReg Mean                 295.55
trainer/QTargetWithReg Std                   71.3357
trainer/QTargetWithReg Max                  376.78
trainer/QTargetWithReg Min                    1.00637
trainer/PolicyLossWithoutReg Mean           297.344
trainer/PolicyLossWithoutReg Std             67.739
trainer/PolicyLossWithoutReg Max            377.82
trainer/PolicyLossWithoutReg Min              6.24764
exploration/num steps total              397000
exploration/num paths total                1148
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.19997
exploration/Rewards Std                       1.19231
exploration/Rewards Max                       6.92842
exploration/Rewards Min                      -1.0143
exploration/Returns Mean                   4199.97
exploration/Returns Std                       0
exploration/Returns Max                    4199.97
exploration/Returns Min                    4199.97
exploration/Num Paths                         1
exploration/Average Returns                4199.97
evaluation_0/num steps total                  3.05044e+06
evaluation_0/num paths total               6533
evaluation_0/path length Mean               966.75
evaluation_0/path length Std                 58.8276
evaluation_0/path length Max               1000
evaluation_0/path length Min                843
evaluation_0/Rewards Mean                     4.62395
evaluation_0/Rewards Std                      1.16777
evaluation_0/Rewards Max                     10.108
evaluation_0/Rewards Min                     -0.759961
evaluation_0/Returns Mean                  4470.21
evaluation_0/Returns Std                    273.437
evaluation_0/Returns Max                   4738.35
evaluation_0/Returns Min                   3909.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4470.21
time/epoch (s)                                0
time/total (s)                             6023.26
Epoch                                       392
---------------------------------------  ----------------
2022-11-16 17:55:20.002612 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 393 finished
---------------------------------------  ----------------
epoch                                       393
total_step                               398000
replay_pool/size                         398000
trainer/alpha                                 0.0634757
trainer/alpha_loss                            0.0426559
trainer/entropy                              -6.01547
trainer/qf_loss                              15.365
trainer/policy_loss                        -300.414
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.796
trainer/entropy_penalty                      -0.381836
trainer/entropy_percentage                   -0.00126942
trainer/Q1Pred Mean                         299.95
trainer/Q1Pred Std                           70.0428
trainer/Q1Pred Max                          394.658
trainer/Q1Pred Min                           12.2549
trainer/Q2Pred Mean                         300.288
trainer/Q2Pred Std                           70.486
trainer/Q2Pred Max                          391.556
trainer/Q2Pred Min                           13.6567
trainer/QTargetWithReg Mean                 299.897
trainer/QTargetWithReg Std                   70.1156
trainer/QTargetWithReg Max                  394.743
trainer/QTargetWithReg Min                   14.052
trainer/PolicyLossWithoutReg Mean           300.796
trainer/PolicyLossWithoutReg Std             68.9908
trainer/PolicyLossWithoutReg Max            392.272
trainer/PolicyLossWithoutReg Min             13.9098
exploration/num steps total              398000
exploration/num paths total                1149
exploration/path length this epoch Mean     770
exploration/path length this epoch Std        0
exploration/path length this epoch Max      770
exploration/path length this epoch Min      770
exploration/Rewards Mean                      4.40539
exploration/Rewards Std                       1.05661
exploration/Rewards Max                       6.75648
exploration/Rewards Min                      -0.649234
exploration/Returns Mean                   3392.15
exploration/Returns Std                       0
exploration/Returns Max                    3392.15
exploration/Returns Min                    3392.15
exploration/Num Paths                         1
exploration/Average Returns                3392.15
evaluation_0/num steps total                  3.05844e+06
evaluation_0/num paths total               6541
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.42922
evaluation_0/Rewards Std                      1.0839
evaluation_0/Rewards Max                      7.711
evaluation_0/Rewards Min                     -0.854808
evaluation_0/Returns Mean                  4429.22
evaluation_0/Returns Std                    281.183
evaluation_0/Returns Max                   4847.43
evaluation_0/Returns Min                   3892.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4429.22
time/epoch (s)                                0
time/total (s)                             6037.05
Epoch                                       393
---------------------------------------  ----------------
2022-11-16 17:55:32.775923 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 394 finished
---------------------------------------  ----------------
epoch                                       394
total_step                               399000
replay_pool/size                         399000
trainer/alpha                                 0.061224
trainer/alpha_loss                            0.377431
trainer/entropy                              -6.13512
trainer/qf_loss                              25.4454
trainer/policy_loss                        -299.629
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.005
trainer/entropy_penalty                      -0.375616
trainer/entropy_percentage                   -0.00125203
trainer/Q1Pred Mean                         299.166
trainer/Q1Pred Std                           68.4905
trainer/Q1Pred Max                          394.175
trainer/Q1Pred Min                           15.5429
trainer/Q2Pred Mean                         299.059
trainer/Q2Pred Std                           69.0771
trainer/Q2Pred Max                          392.976
trainer/Q2Pred Min                           15.6019
trainer/QTargetWithReg Mean                 299.18
trainer/QTargetWithReg Std                   69.0921
trainer/QTargetWithReg Max                  392.89
trainer/QTargetWithReg Min                    3.16534
trainer/PolicyLossWithoutReg Mean           300.005
trainer/PolicyLossWithoutReg Std             67.203
trainer/PolicyLossWithoutReg Max            393.087
trainer/PolicyLossWithoutReg Min             15.3828
exploration/num steps total              399000
exploration/num paths total                1153
exploration/path length this epoch Mean     209
exploration/path length this epoch Std      222.97
exploration/path length this epoch Max      595
exploration/path length this epoch Min       70
exploration/Rewards Mean                      3.28974
exploration/Rewards Std                       1.59663
exploration/Rewards Max                       8.08933
exploration/Rewards Min                      -0.960516
exploration/Returns Mean                    687.555
exploration/Returns Std                     897.98
exploration/Returns Max                    2242.79
exploration/Returns Min                     152.275
exploration/Num Paths                         4
exploration/Average Returns                 687.555
evaluation_0/num steps total                  3.06606e+06
evaluation_0/num paths total               6549
evaluation_0/path length Mean               952.75
evaluation_0/path length Std                 82.7145
evaluation_0/path length Max               1000
evaluation_0/path length Min                787
evaluation_0/Rewards Mean                     4.78536
evaluation_0/Rewards Std                      1.28627
evaluation_0/Rewards Max                      9.42444
evaluation_0/Rewards Min                     -0.958869
evaluation_0/Returns Mean                  4559.25
evaluation_0/Returns Std                    476.257
evaluation_0/Returns Max                   5091.85
evaluation_0/Returns Min                   3661.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4559.25
time/epoch (s)                                0
time/total (s)                             6049.83
Epoch                                       394
---------------------------------------  ----------------
2022-11-16 17:55:46.089794 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 395 finished
---------------------------------------  ----------------
epoch                                       395
total_step                               400000
replay_pool/size                         400000
trainer/alpha                                 0.0631762
trainer/alpha_loss                            2.05595
trainer/entropy                              -6.74437
trainer/qf_loss                              22.7825
trainer/policy_loss                        -292.427
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         292.853
trainer/entropy_penalty                      -0.426084
trainer/entropy_percentage                   -0.00145494
trainer/Q1Pred Mean                         292.171
trainer/Q1Pred Std                           70.5369
trainer/Q1Pred Max                          386.833
trainer/Q1Pred Min                           15.3723
trainer/Q2Pred Mean                         291.697
trainer/Q2Pred Std                           70.388
trainer/Q2Pred Max                          386.821
trainer/Q2Pred Min                           16.5055
trainer/QTargetWithReg Mean                 291.189
trainer/QTargetWithReg Std                   71.3163
trainer/QTargetWithReg Max                  386.921
trainer/QTargetWithReg Min                   12.7519
trainer/PolicyLossWithoutReg Mean           292.853
trainer/PolicyLossWithoutReg Std             69.3865
trainer/PolicyLossWithoutReg Max            386.749
trainer/PolicyLossWithoutReg Min             15.714
exploration/num steps total              400000
exploration/num paths total                1154
exploration/path length this epoch Mean     680
exploration/path length this epoch Std        0
exploration/path length this epoch Max      680
exploration/path length this epoch Min      680
exploration/Rewards Mean                      4.23455
exploration/Rewards Std                       1.0117
exploration/Rewards Max                       6.20835
exploration/Rewards Min                      -0.842247
exploration/Returns Mean                   2879.5
exploration/Returns Std                       0
exploration/Returns Max                    2879.5
exploration/Returns Min                    2879.5
exploration/Num Paths                         1
exploration/Average Returns                2879.5
evaluation_0/num steps total                  3.07406e+06
evaluation_0/num paths total               6557
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.36007
evaluation_0/Rewards Std                      1.18797
evaluation_0/Rewards Max                      7.15804
evaluation_0/Rewards Min                     -0.673046
evaluation_0/Returns Mean                  4360.07
evaluation_0/Returns Std                    157.243
evaluation_0/Returns Max                   4591.42
evaluation_0/Returns Min                   4135.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4360.07
time/epoch (s)                                0
time/total (s)                             6063.14
Epoch                                       395
---------------------------------------  ----------------
2022-11-16 17:55:57.453041 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 396 finished
---------------------------------------  ----------------
epoch                                       396
total_step                               401000
replay_pool/size                         401000
trainer/alpha                                 0.0613476
trainer/alpha_loss                            0.738711
trainer/entropy                              -6.26466
trainer/qf_loss                              18.9715
trainer/policy_loss                        -300.189
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.573
trainer/entropy_penalty                      -0.384322
trainer/entropy_percentage                   -0.00127863
trainer/Q1Pred Mean                         298.76
trainer/Q1Pred Std                           59.6855
trainer/Q1Pred Max                          380.098
trainer/Q1Pred Min                           23.2672
trainer/Q2Pred Mean                         298.574
trainer/Q2Pred Std                           59.4726
trainer/Q2Pred Max                          376.459
trainer/Q2Pred Min                           34.7805
trainer/QTargetWithReg Mean                 299.127
trainer/QTargetWithReg Std                   59.3784
trainer/QTargetWithReg Max                  378.876
trainer/QTargetWithReg Min                   29.1457
trainer/PolicyLossWithoutReg Mean           300.573
trainer/PolicyLossWithoutReg Std             57.8486
trainer/PolicyLossWithoutReg Max            376.845
trainer/PolicyLossWithoutReg Min             24.3551
exploration/num steps total              401000
exploration/num paths total                1155
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15142
exploration/Rewards Std                       1.05241
exploration/Rewards Max                       6.45311
exploration/Rewards Min                      -0.552662
exploration/Returns Mean                   4151.42
exploration/Returns Std                       0
exploration/Returns Max                    4151.42
exploration/Returns Min                    4151.42
exploration/Num Paths                         1
exploration/Average Returns                4151.42
evaluation_0/num steps total                  3.08206e+06
evaluation_0/num paths total               6565
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57428
evaluation_0/Rewards Std                      1.12521
evaluation_0/Rewards Max                      7.34126
evaluation_0/Rewards Min                     -0.749464
evaluation_0/Returns Mean                  4574.28
evaluation_0/Returns Std                    143.114
evaluation_0/Returns Max                   4788.29
evaluation_0/Returns Min                   4350.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4574.28
time/epoch (s)                                0
time/total (s)                             6074.5
Epoch                                       396
---------------------------------------  ----------------
2022-11-16 17:56:09.785497 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 397 finished
---------------------------------------  ----------------
epoch                                       397
total_step                               402000
replay_pool/size                         402000
trainer/alpha                                 0.0616531
trainer/alpha_loss                            0.53483
trainer/entropy                              -6.19196
trainer/qf_loss                              18.1779
trainer/policy_loss                        -300.063
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.445
trainer/entropy_penalty                      -0.381753
trainer/entropy_percentage                   -0.00127063
trainer/Q1Pred Mean                         298.496
trainer/Q1Pred Std                           67.9044
trainer/Q1Pred Max                          386.29
trainer/Q1Pred Min                            0.225876
trainer/Q2Pred Mean                         298.536
trainer/Q2Pred Std                           67.9082
trainer/Q2Pred Max                          383.999
trainer/Q2Pred Min                            2.77805
trainer/QTargetWithReg Mean                 299.608
trainer/QTargetWithReg Std                   67.0529
trainer/QTargetWithReg Max                  386.696
trainer/QTargetWithReg Min                    5.96791
trainer/PolicyLossWithoutReg Mean           300.445
trainer/PolicyLossWithoutReg Std             66.3915
trainer/PolicyLossWithoutReg Max            387.336
trainer/PolicyLossWithoutReg Min              1.12337
exploration/num steps total              402000
exploration/num paths total                1156
exploration/path length this epoch Mean     166
exploration/path length this epoch Std        0
exploration/path length this epoch Max      166
exploration/path length this epoch Min      166
exploration/Rewards Mean                      3.14711
exploration/Rewards Std                       1.35067
exploration/Rewards Max                       5.41427
exploration/Rewards Min                      -0.852896
exploration/Returns Mean                    522.42
exploration/Returns Std                       0
exploration/Returns Max                     522.42
exploration/Returns Min                     522.42
exploration/Num Paths                         1
exploration/Average Returns                 522.42
evaluation_0/num steps total                  3.08974e+06
evaluation_0/num paths total               6573
evaluation_0/path length Mean               960.75
evaluation_0/path length Std                 56.0508
evaluation_0/path length Max               1000
evaluation_0/path length Min                840
evaluation_0/Rewards Mean                     4.86373
evaluation_0/Rewards Std                      1.29432
evaluation_0/Rewards Max                      9.60674
evaluation_0/Rewards Min                     -0.701237
evaluation_0/Returns Mean                  4672.83
evaluation_0/Returns Std                    431.457
evaluation_0/Returns Max                   5374.13
evaluation_0/Returns Min                   3844.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4672.83
time/epoch (s)                                0
time/total (s)                             6086.83
Epoch                                       397
---------------------------------------  ----------------
2022-11-16 17:56:25.821022 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 398 finished
---------------------------------------  ----------------
epoch                                       398
total_step                               403000
replay_pool/size                         403000
trainer/alpha                                 0.0629679
trainer/alpha_loss                            1.17113
trainer/entropy                              -6.42352
trainer/qf_loss                              23.2673
trainer/policy_loss                        -300.304
trainer/adversary_policy_loss                14.3029
trainer/policy_loss_without_entropy         300.709
trainer/entropy_penalty                      -0.404476
trainer/entropy_percentage                   -0.00134508
trainer/Q1Pred Mean                         300.069
trainer/Q1Pred Std                           64.3688
trainer/Q1Pred Max                          377.211
trainer/Q1Pred Min                            6.69195
trainer/Q2Pred Mean                         299.242
trainer/Q2Pred Std                           65.7326
trainer/Q2Pred Max                          376.568
trainer/Q2Pred Min                           -9.70649
trainer/QTargetWithReg Mean                 300.026
trainer/QTargetWithReg Std                   65.5517
trainer/QTargetWithReg Max                  375.356
trainer/QTargetWithReg Min                   -0.377987
trainer/PolicyLossWithoutReg Mean           300.709
trainer/PolicyLossWithoutReg Std             61.9244
trainer/PolicyLossWithoutReg Max            374.877
trainer/PolicyLossWithoutReg Min              6.67811
exploration/num steps total              403000
exploration/num paths total                1157
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44157
exploration/Rewards Std                       1.3775
exploration/Rewards Max                       6.93342
exploration/Rewards Min                      -0.730287
exploration/Returns Mean                   4441.57
exploration/Returns Std                       0
exploration/Returns Max                    4441.57
exploration/Returns Min                    4441.57
exploration/Num Paths                         1
exploration/Average Returns                4441.57
evaluation_0/num steps total                  3.09749e+06
evaluation_0/num paths total               6581
evaluation_0/path length Mean               968.125
evaluation_0/path length Std                 55.3725
evaluation_0/path length Max               1000
evaluation_0/path length Min                864
evaluation_0/Rewards Mean                     4.86126
evaluation_0/Rewards Std                      1.16511
evaluation_0/Rewards Max                      9.13984
evaluation_0/Rewards Min                     -0.796146
evaluation_0/Returns Mean                  4706.31
evaluation_0/Returns Std                    265.043
evaluation_0/Returns Max                   4986.87
evaluation_0/Returns Min                   4240.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4706.31
time/epoch (s)                                0
time/total (s)                             6102.87
Epoch                                       398
---------------------------------------  ----------------
2022-11-16 17:56:37.155318 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 399 finished
---------------------------------------  ----------------
epoch                                       399
total_step                               404000
replay_pool/size                         404000
trainer/alpha                                 0.0597928
trainer/alpha_loss                            1.16826
trainer/entropy                              -6.41474
trainer/qf_loss                              17.245
trainer/policy_loss                        -298.75
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.133
trainer/entropy_penalty                      -0.383555
trainer/entropy_percentage                   -0.00128222
trainer/Q1Pred Mean                         297.528
trainer/Q1Pred Std                           73.4094
trainer/Q1Pred Max                          390.124
trainer/Q1Pred Min                           -3.68631
trainer/Q2Pred Mean                         298.669
trainer/Q2Pred Std                           73.5721
trainer/Q2Pred Max                          388.097
trainer/Q2Pred Min                           -9.60605
trainer/QTargetWithReg Mean                 297.795
trainer/QTargetWithReg Std                   73.0016
trainer/QTargetWithReg Max                  389.261
trainer/QTargetWithReg Min                   -4.9266
trainer/PolicyLossWithoutReg Mean           299.133
trainer/PolicyLossWithoutReg Std             72.5307
trainer/PolicyLossWithoutReg Max            389
trainer/PolicyLossWithoutReg Min              0.78146
exploration/num steps total              404000
exploration/num paths total                1158
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.39194
exploration/Rewards Std                       1.05437
exploration/Rewards Max                       7.13112
exploration/Rewards Min                      -0.712679
exploration/Returns Mean                   4391.94
exploration/Returns Std                       0
exploration/Returns Max                    4391.94
exploration/Returns Min                    4391.94
exploration/Num Paths                         1
exploration/Average Returns                4391.94
evaluation_0/num steps total                  3.10549e+06
evaluation_0/num paths total               6589
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.46778
evaluation_0/Rewards Std                      0.97107
evaluation_0/Rewards Max                      7.20827
evaluation_0/Rewards Min                     -0.746312
evaluation_0/Returns Mean                  4467.78
evaluation_0/Returns Std                    145.681
evaluation_0/Returns Max                   4636.7
evaluation_0/Returns Min                   4210.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4467.78
time/epoch (s)                                0
time/total (s)                             6114.2
Epoch                                       399
---------------------------------------  ----------------
2022-11-16 17:56:50.826703 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 400 finished
---------------------------------------  ----------------
epoch                                       400
total_step                               405000
replay_pool/size                         405000
trainer/alpha                                 0.0624663
trainer/alpha_loss                           -0.356047
trainer/entropy                              -5.8716
trainer/qf_loss                              19.547
trainer/policy_loss                        -300.074
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.44
trainer/entropy_penalty                      -0.366777
trainer/entropy_percentage                   -0.0012208
trainer/Q1Pred Mean                         299.093
trainer/Q1Pred Std                           65.7008
trainer/Q1Pred Max                          384.75
trainer/Q1Pred Min                            0.889303
trainer/Q2Pred Mean                         299.396
trainer/Q2Pred Std                           66.0053
trainer/Q2Pred Max                          386.566
trainer/Q2Pred Min                           -1.43948
trainer/QTargetWithReg Mean                 300.157
trainer/QTargetWithReg Std                   66.2186
trainer/QTargetWithReg Max                  385.969
trainer/QTargetWithReg Min                    3.13729
trainer/PolicyLossWithoutReg Mean           300.44
trainer/PolicyLossWithoutReg Std             65.0608
trainer/PolicyLossWithoutReg Max            384.805
trainer/PolicyLossWithoutReg Min             -1.30383
exploration/num steps total              405000
exploration/num paths total                1159
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.86515
exploration/Rewards Std                       1.06231
exploration/Rewards Max                       6.30041
exploration/Rewards Min                      -0.403354
exploration/Returns Mean                   3865.15
exploration/Returns Std                       0
exploration/Returns Max                    3865.15
exploration/Returns Min                    3865.15
exploration/Num Paths                         1
exploration/Average Returns                3865.15
evaluation_0/num steps total                  3.11298e+06
evaluation_0/num paths total               6597
evaluation_0/path length Mean               936.125
evaluation_0/path length Std                111.806
evaluation_0/path length Max               1000
evaluation_0/path length Min                656
evaluation_0/Rewards Mean                     4.79415
evaluation_0/Rewards Std                      1.23857
evaluation_0/Rewards Max                      9.42793
evaluation_0/Rewards Min                     -0.785371
evaluation_0/Returns Mean                  4487.93
evaluation_0/Returns Std                    658.444
evaluation_0/Returns Max                   5063.87
evaluation_0/Returns Min                   2934.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4487.93
time/epoch (s)                                0
time/total (s)                             6127.87
Epoch                                       400
---------------------------------------  ----------------
2022-11-16 17:57:04.214582 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 401 finished
---------------------------------------  ----------------
epoch                                       401
total_step                               406000
replay_pool/size                         406000
trainer/alpha                                 0.0618493
trainer/alpha_loss                            0.5499
trainer/entropy                              -6.1976
trainer/qf_loss                              35.0408
trainer/policy_loss                        -299.422
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.806
trainer/entropy_penalty                      -0.383317
trainer/entropy_percentage                   -0.00127855
trainer/Q1Pred Mean                         300.167
trainer/Q1Pred Std                           61.3227
trainer/Q1Pred Max                          378.778
trainer/Q1Pred Min                           29.586
trainer/Q2Pred Mean                         299.78
trainer/Q2Pred Std                           61.6558
trainer/Q2Pred Max                          382.535
trainer/Q2Pred Min                           28.3289
trainer/QTargetWithReg Mean                 298.49
trainer/QTargetWithReg Std                   61.1121
trainer/QTargetWithReg Max                  383.806
trainer/QTargetWithReg Min                   30.7195
trainer/PolicyLossWithoutReg Mean           299.806
trainer/PolicyLossWithoutReg Std             60.217
trainer/PolicyLossWithoutReg Max            383.074
trainer/PolicyLossWithoutReg Min             29.1034
exploration/num steps total              406000
exploration/num paths total                1160
exploration/path length this epoch Mean     826
exploration/path length this epoch Std        0
exploration/path length this epoch Max      826
exploration/path length this epoch Min      826
exploration/Rewards Mean                      4.33835
exploration/Rewards Std                       1.07363
exploration/Rewards Max                       6.73973
exploration/Rewards Min                      -0.61552
exploration/Returns Mean                   3583.47
exploration/Returns Std                       0
exploration/Returns Max                    3583.47
exploration/Returns Min                    3583.47
exploration/Num Paths                         1
exploration/Average Returns                3583.47
evaluation_0/num steps total                  3.12098e+06
evaluation_0/num paths total               6605
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.60818
evaluation_0/Rewards Std                      1.20584
evaluation_0/Rewards Max                      7.59909
evaluation_0/Rewards Min                     -0.978793
evaluation_0/Returns Mean                  4608.18
evaluation_0/Returns Std                    134.742
evaluation_0/Returns Max                   4815.29
evaluation_0/Returns Min                   4434.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4608.18
time/epoch (s)                                0
time/total (s)                             6141.26
Epoch                                       401
---------------------------------------  ----------------
2022-11-16 17:57:15.917374 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 402 finished
---------------------------------------  ----------------
epoch                                       402
total_step                               407000
replay_pool/size                         407000
trainer/alpha                                 0.062183
trainer/alpha_loss                           -0.916044
trainer/entropy                              -5.67021
trainer/qf_loss                              31.1164
trainer/policy_loss                        -301.569
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.921
trainer/entropy_penalty                      -0.35259
trainer/entropy_percentage                   -0.00116782
trainer/Q1Pred Mean                         300.916
trainer/Q1Pred Std                           64.0066
trainer/Q1Pred Max                          383.721
trainer/Q1Pred Min                            9.23788
trainer/Q2Pred Mean                         301.895
trainer/Q2Pred Std                           63.7329
trainer/Q2Pred Max                          387.589
trainer/Q2Pred Min                            6.98476
trainer/QTargetWithReg Mean                 300.785
trainer/QTargetWithReg Std                   63.886
trainer/QTargetWithReg Max                  384.618
trainer/QTargetWithReg Min                   -1.53194
trainer/PolicyLossWithoutReg Mean           301.921
trainer/PolicyLossWithoutReg Std             62.6097
trainer/PolicyLossWithoutReg Max            385.137
trainer/PolicyLossWithoutReg Min              9.19768
exploration/num steps total              407000
exploration/num paths total                1161
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51332
exploration/Rewards Std                       1.16185
exploration/Rewards Max                       7.02019
exploration/Rewards Min                      -0.752246
exploration/Returns Mean                   4513.32
exploration/Returns Std                       0
exploration/Returns Max                    4513.32
exploration/Returns Min                    4513.32
exploration/Num Paths                         1
exploration/Average Returns                4513.32
evaluation_0/num steps total                  3.12898e+06
evaluation_0/num paths total               6613
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.4418
evaluation_0/Rewards Std                      1.08212
evaluation_0/Rewards Max                      7.16724
evaluation_0/Rewards Min                     -0.959275
evaluation_0/Returns Mean                  4441.8
evaluation_0/Returns Std                    154.05
evaluation_0/Returns Max                   4637.36
evaluation_0/Returns Min                   4149.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4441.8
time/epoch (s)                                0
time/total (s)                             6152.97
Epoch                                       402
---------------------------------------  ----------------
2022-11-16 17:57:28.474520 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 403 finished
---------------------------------------  ----------------
epoch                                       403
total_step                               408000
replay_pool/size                         408000
trainer/alpha                                 0.0622594
trainer/alpha_loss                           -0.112453
trainer/entropy                              -5.9595
trainer/qf_loss                              29.6721
trainer/policy_loss                        -298.884
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.255
trainer/entropy_penalty                      -0.371035
trainer/entropy_percentage                   -0.00123986
trainer/Q1Pred Mean                         297.348
trainer/Q1Pred Std                           64.3154
trainer/Q1Pred Max                          383.585
trainer/Q1Pred Min                           -7.69448
trainer/Q2Pred Mean                         297.812
trainer/Q2Pred Std                           64.5561
trainer/Q2Pred Max                          385.444
trainer/Q2Pred Min                            9.3739
trainer/QTargetWithReg Mean                 298.114
trainer/QTargetWithReg Std                   64.1121
trainer/QTargetWithReg Max                  384.272
trainer/QTargetWithReg Min                    0.297645
trainer/PolicyLossWithoutReg Mean           299.255
trainer/PolicyLossWithoutReg Std             60.4198
trainer/PolicyLossWithoutReg Max            384.975
trainer/PolicyLossWithoutReg Min             35.0303
exploration/num steps total              408000
exploration/num paths total                1163
exploration/path length this epoch Mean     348
exploration/path length this epoch Std      293
exploration/path length this epoch Max      641
exploration/path length this epoch Min       55
exploration/Rewards Mean                      3.88631
exploration/Rewards Std                       1.27488
exploration/Rewards Max                       6.168
exploration/Rewards Min                      -0.943385
exploration/Returns Mean                   1352.44
exploration/Returns Std                    1234.3
exploration/Returns Max                    2586.74
exploration/Returns Min                     118.135
exploration/Num Paths                         2
exploration/Average Returns                1352.44
evaluation_0/num steps total                  3.13668e+06
evaluation_0/num paths total               6621
evaluation_0/path length Mean               962.5
evaluation_0/path length Std                 99.2157
evaluation_0/path length Max               1000
evaluation_0/path length Min                700
evaluation_0/Rewards Mean                     4.46406
evaluation_0/Rewards Std                      1.25674
evaluation_0/Rewards Max                      8.8761
evaluation_0/Rewards Min                     -0.860612
evaluation_0/Returns Mean                  4296.66
evaluation_0/Returns Std                    484.196
evaluation_0/Returns Max                   4587.26
evaluation_0/Returns Min                   3041.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4296.66
time/epoch (s)                                0
time/total (s)                             6165.52
Epoch                                       403
---------------------------------------  ----------------
2022-11-16 17:57:41.983500 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 404 finished
---------------------------------------  ----------------
epoch                                       404
total_step                               409000
replay_pool/size                         409000
trainer/alpha                                 0.0620874
trainer/alpha_loss                            1.13057
trainer/entropy                              -6.40679
trainer/qf_loss                              22.0218
trainer/policy_loss                        -294.471
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         294.869
trainer/entropy_penalty                      -0.397781
trainer/entropy_percentage                   -0.00134901
trainer/Q1Pred Mean                         293.404
trainer/Q1Pred Std                           71.9577
trainer/Q1Pred Max                          386.29
trainer/Q1Pred Min                            0.175108
trainer/Q2Pred Mean                         294.721
trainer/Q2Pred Std                           71.1362
trainer/Q2Pred Max                          385.969
trainer/Q2Pred Min                            1.13757
trainer/QTargetWithReg Mean                 294.562
trainer/QTargetWithReg Std                   71.0263
trainer/QTargetWithReg Max                  384.891
trainer/QTargetWithReg Min                    3.25778
trainer/PolicyLossWithoutReg Mean           294.869
trainer/PolicyLossWithoutReg Std             71.0888
trainer/PolicyLossWithoutReg Max            384.732
trainer/PolicyLossWithoutReg Min            -10.7937
exploration/num steps total              409000
exploration/num paths total                1164
exploration/path length this epoch Mean     660
exploration/path length this epoch Std        0
exploration/path length this epoch Max      660
exploration/path length this epoch Min      660
exploration/Rewards Mean                      3.90184
exploration/Rewards Std                       1.32598
exploration/Rewards Max                       6.49467
exploration/Rewards Min                      -0.855854
exploration/Returns Mean                   2575.22
exploration/Returns Std                       0
exploration/Returns Max                    2575.22
exploration/Returns Min                    2575.22
exploration/Num Paths                         1
exploration/Average Returns                2575.22
evaluation_0/num steps total                  3.14468e+06
evaluation_0/num paths total               6629
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66283
evaluation_0/Rewards Std                      1.18679
evaluation_0/Rewards Max                      7.76018
evaluation_0/Rewards Min                     -0.880334
evaluation_0/Returns Mean                  4662.83
evaluation_0/Returns Std                    117.195
evaluation_0/Returns Max                   4848.09
evaluation_0/Returns Min                   4513.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4662.83
time/epoch (s)                                0
time/total (s)                             6179.03
Epoch                                       404
---------------------------------------  ----------------
2022-11-16 17:57:54.455033 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 405 finished
---------------------------------------  ----------------
epoch                                       405
total_step                               410000
replay_pool/size                         410000
trainer/alpha                                 0.0623446
trainer/alpha_loss                           -0.171485
trainer/entropy                              -5.9382
trainer/qf_loss                              16.0244
trainer/policy_loss                        -303.969
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.339
trainer/entropy_penalty                      -0.370215
trainer/entropy_percentage                   -0.00121646
trainer/Q1Pred Mean                         303.709
trainer/Q1Pred Std                           62.7193
trainer/Q1Pred Max                          386.001
trainer/Q1Pred Min                           58.6902
trainer/Q2Pred Mean                         303.28
trainer/Q2Pred Std                           63.2695
trainer/Q2Pred Max                          387.61
trainer/Q2Pred Min                           58.2548
trainer/QTargetWithReg Mean                 304.009
trainer/QTargetWithReg Std                   62.5398
trainer/QTargetWithReg Max                  386.171
trainer/QTargetWithReg Min                   54.3666
trainer/PolicyLossWithoutReg Mean           304.339
trainer/PolicyLossWithoutReg Std             61.679
trainer/PolicyLossWithoutReg Max            384.467
trainer/PolicyLossWithoutReg Min             63.6831
exploration/num steps total              410000
exploration/num paths total                1165
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.39453
exploration/Rewards Std                       1.1518
exploration/Rewards Max                       6.45369
exploration/Rewards Min                      -0.812413
exploration/Returns Mean                   4394.53
exploration/Returns Std                       0
exploration/Returns Max                    4394.53
exploration/Returns Min                    4394.53
exploration/Num Paths                         1
exploration/Average Returns                4394.53
evaluation_0/num steps total                  3.15249e+06
evaluation_0/num paths total               6637
evaluation_0/path length Mean               976.375
evaluation_0/path length Std                 62.5059
evaluation_0/path length Max               1000
evaluation_0/path length Min                811
evaluation_0/Rewards Mean                     4.44818
evaluation_0/Rewards Std                      1.17372
evaluation_0/Rewards Max                      7.95759
evaluation_0/Rewards Min                     -0.831188
evaluation_0/Returns Mean                  4343.09
evaluation_0/Returns Std                    321.74
evaluation_0/Returns Max                   4586.99
evaluation_0/Returns Min                   3525.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4343.09
time/epoch (s)                                0
time/total (s)                             6191.5
Epoch                                       405
---------------------------------------  ----------------
2022-11-16 17:58:07.106148 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 406 finished
---------------------------------------  ---------------
epoch                                       406
total_step                               411000
replay_pool/size                         411000
trainer/alpha                                 0.0606836
trainer/alpha_loss                           -0.845312
trainer/entropy                              -5.69832
trainer/qf_loss                              24.8137
trainer/policy_loss                        -304.301
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.647
trainer/entropy_penalty                      -0.345794
trainer/entropy_percentage                   -0.00113507
trainer/Q1Pred Mean                         303.911
trainer/Q1Pred Std                           52.7052
trainer/Q1Pred Max                          386.767
trainer/Q1Pred Min                           12.4695
trainer/Q2Pred Mean                         304.011
trainer/Q2Pred Std                           52.6662
trainer/Q2Pred Max                          386.827
trainer/Q2Pred Min                           10.2642
trainer/QTargetWithReg Mean                 303.883
trainer/QTargetWithReg Std                   52.9751
trainer/QTargetWithReg Max                  384.666
trainer/QTargetWithReg Min                   15.8454
trainer/PolicyLossWithoutReg Mean           304.647
trainer/PolicyLossWithoutReg Std             52.1071
trainer/PolicyLossWithoutReg Max            384.821
trainer/PolicyLossWithoutReg Min             13.5137
exploration/num steps total              411000
exploration/num paths total                1166
exploration/path length this epoch Mean      77
exploration/path length this epoch Std        0
exploration/path length this epoch Max       77
exploration/path length this epoch Min       77
exploration/Rewards Mean                      2.28149
exploration/Rewards Std                       1.51726
exploration/Rewards Max                       4.7749
exploration/Rewards Min                      -0.922037
exploration/Returns Mean                    175.675
exploration/Returns Std                       0
exploration/Returns Max                     175.675
exploration/Returns Min                     175.675
exploration/Num Paths                         1
exploration/Average Returns                 175.675
evaluation_0/num steps total                  3.16e+06
evaluation_0/num paths total               6645
evaluation_0/path length Mean               939.125
evaluation_0/path length Std                161.06
evaluation_0/path length Max               1000
evaluation_0/path length Min                513
evaluation_0/Rewards Mean                     4.11417
evaluation_0/Rewards Std                      1.10642
evaluation_0/Rewards Max                     10.045
evaluation_0/Rewards Min                     -0.86391
evaluation_0/Returns Mean                  3863.72
evaluation_0/Returns Std                    740.488
evaluation_0/Returns Max                   4869.78
evaluation_0/Returns Min                   2164.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3863.72
time/epoch (s)                                0
time/total (s)                             6204.15
Epoch                                       406
---------------------------------------  ---------------
2022-11-16 17:58:21.999988 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 407 finished
---------------------------------------  ----------------
epoch                                       407
total_step                               412000
replay_pool/size                         412000
trainer/alpha                                 0.0621808
trainer/alpha_loss                            0.29039
trainer/entropy                              -6.10454
trainer/qf_loss                              28.0566
trainer/policy_loss                        -303.385
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.764
trainer/entropy_penalty                      -0.379585
trainer/entropy_percentage                   -0.00124961
trainer/Q1Pred Mean                         302.744
trainer/Q1Pred Std                           61.1787
trainer/Q1Pred Max                          384.193
trainer/Q1Pred Min                           36.0635
trainer/Q2Pred Mean                         303.016
trainer/Q2Pred Std                           61.2396
trainer/Q2Pred Max                          384.186
trainer/Q2Pred Min                           32.0645
trainer/QTargetWithReg Mean                 302.843
trainer/QTargetWithReg Std                   60.2079
trainer/QTargetWithReg Max                  382.8
trainer/QTargetWithReg Min                   33.0617
trainer/PolicyLossWithoutReg Mean           303.764
trainer/PolicyLossWithoutReg Std             60.4846
trainer/PolicyLossWithoutReg Max            383.513
trainer/PolicyLossWithoutReg Min             31.9779
exploration/num steps total              412000
exploration/num paths total                1167
exploration/path length this epoch Mean     575
exploration/path length this epoch Std        0
exploration/path length this epoch Max      575
exploration/path length this epoch Min      575
exploration/Rewards Mean                      3.93476
exploration/Rewards Std                       1.37043
exploration/Rewards Max                       8.34643
exploration/Rewards Min                      -0.680412
exploration/Returns Mean                   2262.49
exploration/Returns Std                       0
exploration/Returns Max                    2262.49
exploration/Returns Min                    2262.49
exploration/Num Paths                         1
exploration/Average Returns                2262.49
evaluation_0/num steps total                  3.16718e+06
evaluation_0/num paths total               6653
evaluation_0/path length Mean               897
evaluation_0/path length Std                272.512
evaluation_0/path length Max               1000
evaluation_0/path length Min                176
evaluation_0/Rewards Mean                     4.15515
evaluation_0/Rewards Std                      1.14673
evaluation_0/Rewards Max                      7.03297
evaluation_0/Rewards Min                     -0.969901
evaluation_0/Returns Mean                  3727.17
evaluation_0/Returns Std                   1274.31
evaluation_0/Returns Max                   4418.14
evaluation_0/Returns Min                    364.371
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3727.17
time/epoch (s)                                0
time/total (s)                             6219.05
Epoch                                       407
---------------------------------------  ----------------
2022-11-16 17:58:33.352629 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 408 finished
---------------------------------------  ----------------
epoch                                       408
total_step                               413000
replay_pool/size                         413000
trainer/alpha                                 0.0621416
trainer/alpha_loss                            2.82767
trainer/entropy                              -7.01772
trainer/qf_loss                              20.6935
trainer/policy_loss                        -298.378
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.814
trainer/entropy_penalty                      -0.436093
trainer/entropy_percentage                   -0.00145941
trainer/Q1Pred Mean                         297.831
trainer/Q1Pred Std                           70.2189
trainer/Q1Pred Max                          379.348
trainer/Q1Pred Min                            6.57489
trainer/Q2Pred Mean                         297.786
trainer/Q2Pred Std                           70.0325
trainer/Q2Pred Max                          380.45
trainer/Q2Pred Min                            7.154
trainer/QTargetWithReg Mean                 297.766
trainer/QTargetWithReg Std                   70.5486
trainer/QTargetWithReg Max                  380.473
trainer/QTargetWithReg Min                    5.60015
trainer/PolicyLossWithoutReg Mean           298.814
trainer/PolicyLossWithoutReg Std             68.7233
trainer/PolicyLossWithoutReg Max            379.924
trainer/PolicyLossWithoutReg Min              2.2339
exploration/num steps total              413000
exploration/num paths total                1168
exploration/path length this epoch Mean     378
exploration/path length this epoch Std        0
exploration/path length this epoch Max      378
exploration/path length this epoch Min      378
exploration/Rewards Mean                      3.17947
exploration/Rewards Std                       1.18894
exploration/Rewards Max                       6.02925
exploration/Rewards Min                      -0.842415
exploration/Returns Mean                   1201.84
exploration/Returns Std                       0
exploration/Returns Max                    1201.84
exploration/Returns Min                    1201.84
exploration/Num Paths                         1
exploration/Average Returns                1201.84
evaluation_0/num steps total                  3.17518e+06
evaluation_0/num paths total               6661
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.18784
evaluation_0/Rewards Std                      1.19852
evaluation_0/Rewards Max                      7.53408
evaluation_0/Rewards Min                     -0.783543
evaluation_0/Returns Mean                  4187.84
evaluation_0/Returns Std                    162.671
evaluation_0/Returns Max                   4495.43
evaluation_0/Returns Min                   3978.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4187.84
time/epoch (s)                                0
time/total (s)                             6230.4
Epoch                                       408
---------------------------------------  ----------------
2022-11-16 17:58:46.780812 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 409 finished
---------------------------------------  ----------------
epoch                                       409
total_step                               414000
replay_pool/size                         414000
trainer/alpha                                 0.0620255
trainer/alpha_loss                           -1.10787
trainer/entropy                              -5.60151
trainer/qf_loss                              21.6404
trainer/policy_loss                        -302.833
trainer/adversary_policy_loss                14.5141
trainer/policy_loss_without_entropy         303.18
trainer/entropy_penalty                      -0.347436
trainer/entropy_percentage                   -0.00114597
trainer/Q1Pred Mean                         300.798
trainer/Q1Pred Std                           64.3255
trainer/Q1Pred Max                          388.457
trainer/Q1Pred Min                           -1.06027
trainer/Q2Pred Mean                         300.309
trainer/Q2Pred Std                           64.4367
trainer/Q2Pred Max                          385.683
trainer/Q2Pred Min                            5.4525
trainer/QTargetWithReg Mean                 300.612
trainer/QTargetWithReg Std                   64.8112
trainer/QTargetWithReg Max                  389.614
trainer/QTargetWithReg Min                    0.982388
trainer/PolicyLossWithoutReg Mean           303.18
trainer/PolicyLossWithoutReg Std             59.8749
trainer/PolicyLossWithoutReg Max            387.83
trainer/PolicyLossWithoutReg Min             13.1516
exploration/num steps total              414000
exploration/num paths total                1169
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2838
exploration/Rewards Std                       1.01245
exploration/Rewards Max                       6.9465
exploration/Rewards Min                      -0.744529
exploration/Returns Mean                   4283.8
exploration/Returns Std                       0
exploration/Returns Max                    4283.8
exploration/Returns Min                    4283.8
exploration/Num Paths                         1
exploration/Average Returns                4283.8
evaluation_0/num steps total                  3.18289e+06
evaluation_0/num paths total               6669
evaluation_0/path length Mean               964
evaluation_0/path length Std                 55.3444
evaluation_0/path length Max               1000
evaluation_0/path length Min                836
evaluation_0/Rewards Mean                     4.67611
evaluation_0/Rewards Std                      1.31277
evaluation_0/Rewards Max                      9.14405
evaluation_0/Rewards Min                     -1.10432
evaluation_0/Returns Mean                  4507.77
evaluation_0/Returns Std                    267.736
evaluation_0/Returns Max                   4832.67
evaluation_0/Returns Min                   3947.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4507.77
time/epoch (s)                                0
time/total (s)                             6243.83
Epoch                                       409
---------------------------------------  ----------------
2022-11-16 17:59:00.578209 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 410 finished
---------------------------------------  ----------------
epoch                                       410
total_step                               415000
replay_pool/size                         415000
trainer/alpha                                 0.0606908
trainer/alpha_loss                            0.391357
trainer/entropy                              -6.13967
trainer/qf_loss                              18.7344
trainer/policy_loss                        -302.851
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.223
trainer/entropy_penalty                      -0.372621
trainer/entropy_percentage                   -0.00122887
trainer/Q1Pred Mean                         301.853
trainer/Q1Pred Std                           61.8022
trainer/Q1Pred Max                          391.758
trainer/Q1Pred Min                           -2.56475
trainer/Q2Pred Mean                         301.697
trainer/Q2Pred Std                           61.8836
trainer/Q2Pred Max                          390.115
trainer/Q2Pred Min                           14.6749
trainer/QTargetWithReg Mean                 301.784
trainer/QTargetWithReg Std                   62.2032
trainer/QTargetWithReg Max                  391.099
trainer/QTargetWithReg Min                    0.154679
trainer/PolicyLossWithoutReg Mean           303.223
trainer/PolicyLossWithoutReg Std             60.2084
trainer/PolicyLossWithoutReg Max            390.425
trainer/PolicyLossWithoutReg Min             18.5465
exploration/num steps total              415000
exploration/num paths total                1170
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52583
exploration/Rewards Std                       1.42037
exploration/Rewards Max                       8.75157
exploration/Rewards Min                      -1.04972
exploration/Returns Mean                   4525.83
exploration/Returns Std                       0
exploration/Returns Max                    4525.83
exploration/Returns Min                    4525.83
exploration/Num Paths                         1
exploration/Average Returns                4525.83
evaluation_0/num steps total                  3.19089e+06
evaluation_0/num paths total               6677
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82497
evaluation_0/Rewards Std                      1.06251
evaluation_0/Rewards Max                      7.4125
evaluation_0/Rewards Min                     -0.806258
evaluation_0/Returns Mean                  4824.97
evaluation_0/Returns Std                    102.043
evaluation_0/Returns Max                   5038.42
evaluation_0/Returns Min                   4678.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4824.97
time/epoch (s)                                0
time/total (s)                             6257.62
Epoch                                       410
---------------------------------------  ----------------
2022-11-16 17:59:11.961043 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 411 finished
---------------------------------------  ----------------
epoch                                       411
total_step                               416000
replay_pool/size                         416000
trainer/alpha                                 0.0611369
trainer/alpha_loss                            1.35904
trainer/entropy                              -6.48629
trainer/qf_loss                              36.603
trainer/policy_loss                        -301.697
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.094
trainer/entropy_penalty                      -0.396551
trainer/entropy_percentage                   -0.00131268
trainer/Q1Pred Mean                         301.095
trainer/Q1Pred Std                           68.56
trainer/Q1Pred Max                          385.383
trainer/Q1Pred Min                           -8.03177
trainer/Q2Pred Mean                         301.112
trainer/Q2Pred Std                           69.0245
trainer/Q2Pred Max                          385.856
trainer/Q2Pred Min                            8.06286
trainer/QTargetWithReg Mean                 300.232
trainer/QTargetWithReg Std                   69.7612
trainer/QTargetWithReg Max                  386.24
trainer/QTargetWithReg Min                   -5.13249
trainer/PolicyLossWithoutReg Mean           302.094
trainer/PolicyLossWithoutReg Std             67.0339
trainer/PolicyLossWithoutReg Max            385.339
trainer/PolicyLossWithoutReg Min              4.71279
exploration/num steps total              416000
exploration/num paths total                1171
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51215
exploration/Rewards Std                       1.07394
exploration/Rewards Max                       7.31799
exploration/Rewards Min                      -0.887817
exploration/Returns Mean                   4512.15
exploration/Returns Std                       0
exploration/Returns Max                    4512.15
exploration/Returns Min                    4512.15
exploration/Num Paths                         1
exploration/Average Returns                4512.15
evaluation_0/num steps total                  3.19889e+06
evaluation_0/num paths total               6685
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.3851
evaluation_0/Rewards Std                      1.03577
evaluation_0/Rewards Max                      8.49595
evaluation_0/Rewards Min                     -0.711988
evaluation_0/Returns Mean                  4385.1
evaluation_0/Returns Std                    271.885
evaluation_0/Returns Max                   4791.47
evaluation_0/Returns Min                   3847.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4385.1
time/epoch (s)                                0
time/total (s)                             6269.01
Epoch                                       411
---------------------------------------  ----------------
2022-11-16 17:59:24.540767 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 412 finished
---------------------------------------  ----------------
epoch                                       412
total_step                               417000
replay_pool/size                         417000
trainer/alpha                                 0.060949
trainer/alpha_loss                           -2.35477
trainer/entropy                              -5.15828
trainer/qf_loss                              17.9348
trainer/policy_loss                        -303.593
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.907
trainer/entropy_penalty                      -0.314392
trainer/entropy_percentage                   -0.0010345
trainer/Q1Pred Mean                         302.846
trainer/Q1Pred Std                           69.5744
trainer/Q1Pred Max                          387.829
trainer/Q1Pred Min                           11.4695
trainer/Q2Pred Mean                         303.545
trainer/Q2Pred Std                           69.3881
trainer/Q2Pred Max                          387.29
trainer/Q2Pred Min                           15.4629
trainer/QTargetWithReg Mean                 303.557
trainer/QTargetWithReg Std                   70.4273
trainer/QTargetWithReg Max                  388.988
trainer/QTargetWithReg Min                    8.38973
trainer/PolicyLossWithoutReg Mean           303.907
trainer/PolicyLossWithoutReg Std             68.4569
trainer/PolicyLossWithoutReg Max            388.262
trainer/PolicyLossWithoutReg Min             11.1696
exploration/num steps total              417000
exploration/num paths total                1172
exploration/path length this epoch Mean     833
exploration/path length this epoch Std        0
exploration/path length this epoch Max      833
exploration/path length this epoch Min      833
exploration/Rewards Mean                      4.24376
exploration/Rewards Std                       1.24438
exploration/Rewards Max                       8.9906
exploration/Rewards Min                      -0.613684
exploration/Returns Mean                   3535.06
exploration/Returns Std                       0
exploration/Returns Max                    3535.06
exploration/Returns Min                    3535.06
exploration/Num Paths                         1
exploration/Average Returns                3535.06
evaluation_0/num steps total                  3.20669e+06
evaluation_0/num paths total               6693
evaluation_0/path length Mean               975
evaluation_0/path length Std                 66.1438
evaluation_0/path length Max               1000
evaluation_0/path length Min                800
evaluation_0/Rewards Mean                     4.67841
evaluation_0/Rewards Std                      1.21852
evaluation_0/Rewards Max                      8.48833
evaluation_0/Rewards Min                     -0.889852
evaluation_0/Returns Mean                  4561.45
evaluation_0/Returns Std                    303.293
evaluation_0/Returns Max                   4901.84
evaluation_0/Returns Min                   3824.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4561.45
time/epoch (s)                                0
time/total (s)                             6281.58
Epoch                                       412
---------------------------------------  ----------------
2022-11-16 17:59:37.493231 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 413 finished
---------------------------------------  ----------------
epoch                                       413
total_step                               418000
replay_pool/size                         418000
trainer/alpha                                 0.0617341
trainer/alpha_loss                            0.464085
trainer/entropy                              -6.16664
trainer/qf_loss                              27.4488
trainer/policy_loss                        -297.82
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         298.201
trainer/entropy_penalty                      -0.380692
trainer/entropy_percentage                   -0.00127663
trainer/Q1Pred Mean                         297.018
trainer/Q1Pred Std                           70.9294
trainer/Q1Pred Max                          403.47
trainer/Q1Pred Min                            4.10644
trainer/Q2Pred Mean                         296.029
trainer/Q2Pred Std                           71.4456
trainer/Q2Pred Max                          399.523
trainer/Q2Pred Min                          -10.2159
trainer/QTargetWithReg Mean                 297.215
trainer/QTargetWithReg Std                   71.7606
trainer/QTargetWithReg Max                  401.275
trainer/QTargetWithReg Min                    0.58619
trainer/PolicyLossWithoutReg Mean           298.201
trainer/PolicyLossWithoutReg Std             68.867
trainer/PolicyLossWithoutReg Max            401.548
trainer/PolicyLossWithoutReg Min              9.34826
exploration/num steps total              418000
exploration/num paths total                1173
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.23888
exploration/Rewards Std                       1.18244
exploration/Rewards Max                       6.67379
exploration/Rewards Min                      -0.916207
exploration/Returns Mean                   4238.88
exploration/Returns Std                       0
exploration/Returns Max                    4238.88
exploration/Returns Min                    4238.88
exploration/Num Paths                         1
exploration/Average Returns                4238.88
evaluation_0/num steps total                  3.21469e+06
evaluation_0/num paths total               6701
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.2115
evaluation_0/Rewards Std                      0.984488
evaluation_0/Rewards Max                      6.85807
evaluation_0/Rewards Min                     -0.801483
evaluation_0/Returns Mean                  4211.5
evaluation_0/Returns Std                    214.196
evaluation_0/Returns Max                   4564.45
evaluation_0/Returns Min                   3918.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4211.5
time/epoch (s)                                0
time/total (s)                             6294.54
Epoch                                       413
---------------------------------------  ----------------
2022-11-16 17:59:50.337910 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 414 finished
---------------------------------------  ---------------
epoch                                       414
total_step                               419000
replay_pool/size                         419000
trainer/alpha                                 0.0610503
trainer/alpha_loss                           -0.792473
trainer/entropy                              -5.71656
trainer/qf_loss                              26.5872
trainer/policy_loss                        -305.608
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.957
trainer/entropy_penalty                      -0.348998
trainer/entropy_percentage                   -0.00114068
trainer/Q1Pred Mean                         304.867
trainer/Q1Pred Std                           61.2091
trainer/Q1Pred Max                          388.142
trainer/Q1Pred Min                            7.29916
trainer/Q2Pred Mean                         304.893
trainer/Q2Pred Std                           60.9447
trainer/Q2Pred Max                          387.788
trainer/Q2Pred Min                            7.69483
trainer/QTargetWithReg Mean                 303.385
trainer/QTargetWithReg Std                   61.4883
trainer/QTargetWithReg Max                  384.957
trainer/QTargetWithReg Min                    5.99899
trainer/PolicyLossWithoutReg Mean           305.957
trainer/PolicyLossWithoutReg Std             59.9201
trainer/PolicyLossWithoutReg Max            388.112
trainer/PolicyLossWithoutReg Min              4.87048
exploration/num steps total              419000
exploration/num paths total                1174
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.26545
exploration/Rewards Std                       1.04651
exploration/Rewards Max                       6.888
exploration/Rewards Min                      -0.737202
exploration/Returns Mean                   4265.45
exploration/Returns Std                       0
exploration/Returns Max                    4265.45
exploration/Returns Min                    4265.45
exploration/Num Paths                         1
exploration/Average Returns                4265.45
evaluation_0/num steps total                  3.2223e+06
evaluation_0/num paths total               6711
evaluation_0/path length Mean               761.4
evaluation_0/path length Std                237.663
evaluation_0/path length Max               1000
evaluation_0/path length Min                419
evaluation_0/Rewards Mean                     4.27999
evaluation_0/Rewards Std                      1.27466
evaluation_0/Rewards Max                     10.3796
evaluation_0/Rewards Min                     -0.849993
evaluation_0/Returns Mean                  3258.78
evaluation_0/Returns Std                   1148.88
evaluation_0/Returns Max                   4492.74
evaluation_0/Returns Min                   1677.59
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3258.78
time/epoch (s)                                0
time/total (s)                             6307.38
Epoch                                       414
---------------------------------------  ---------------
2022-11-16 18:00:02.702553 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 415 finished
---------------------------------------  ----------------
epoch                                       415
total_step                               420000
replay_pool/size                         420000
trainer/alpha                                 0.0631299
trainer/alpha_loss                            0.900422
trainer/entropy                              -6.32592
trainer/qf_loss                              20.7604
trainer/policy_loss                        -292.138
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         292.537
trainer/entropy_penalty                      -0.399354
trainer/entropy_percentage                   -0.00136514
trainer/Q1Pred Mean                         291.586
trainer/Q1Pred Std                           78.8235
trainer/Q1Pred Max                          384.403
trainer/Q1Pred Min                           -2.50108
trainer/Q2Pred Mean                         291.841
trainer/Q2Pred Std                           78.4582
trainer/Q2Pred Max                          383.553
trainer/Q2Pred Min                          -13.8658
trainer/QTargetWithReg Mean                 292.03
trainer/QTargetWithReg Std                   78.1373
trainer/QTargetWithReg Max                  383.274
trainer/QTargetWithReg Min                   -1.57425
trainer/PolicyLossWithoutReg Mean           292.537
trainer/PolicyLossWithoutReg Std             77.0602
trainer/PolicyLossWithoutReg Max            383.35
trainer/PolicyLossWithoutReg Min             -6.27216
exploration/num steps total              420000
exploration/num paths total                1175
exploration/path length this epoch Mean     771
exploration/path length this epoch Std        0
exploration/path length this epoch Max      771
exploration/path length this epoch Min      771
exploration/Rewards Mean                      4.47086
exploration/Rewards Std                       1.21226
exploration/Rewards Max                       7.21863
exploration/Rewards Min                      -0.936288
exploration/Returns Mean                   3447.04
exploration/Returns Std                       0
exploration/Returns Max                    3447.04
exploration/Returns Min                    3447.04
exploration/Num Paths                         1
exploration/Average Returns                3447.04
evaluation_0/num steps total                  3.22992e+06
evaluation_0/num paths total               6719
evaluation_0/path length Mean               951.625
evaluation_0/path length Std                127.988
evaluation_0/path length Max               1000
evaluation_0/path length Min                613
evaluation_0/Rewards Mean                     4.63812
evaluation_0/Rewards Std                      1.10484
evaluation_0/Rewards Max                      7.65177
evaluation_0/Rewards Min                     -1.03779
evaluation_0/Returns Mean                  4413.75
evaluation_0/Returns Std                    660.476
evaluation_0/Returns Max                   4920.88
evaluation_0/Returns Min                   2733.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4413.75
time/epoch (s)                                0
time/total (s)                             6319.75
Epoch                                       415
---------------------------------------  ----------------
2022-11-16 18:00:17.688072 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 416 finished
---------------------------------------  ----------------
epoch                                       416
total_step                               421000
replay_pool/size                         421000
trainer/alpha                                 0.0620266
trainer/alpha_loss                           -1.00187
trainer/entropy                              -5.63964
trainer/qf_loss                              23.8681
trainer/policy_loss                        -309.087
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.436
trainer/entropy_penalty                      -0.349808
trainer/entropy_percentage                   -0.00113047
trainer/Q1Pred Mean                         308.484
trainer/Q1Pred Std                           57.7354
trainer/Q1Pred Max                          386.186
trainer/Q1Pred Min                          -19.7681
trainer/Q2Pred Mean                         308.644
trainer/Q2Pred Std                           57.589
trainer/Q2Pred Max                          387.544
trainer/Q2Pred Min                          -11.3697
trainer/QTargetWithReg Mean                 308.136
trainer/QTargetWithReg Std                   57.541
trainer/QTargetWithReg Max                  385.699
trainer/QTargetWithReg Min                    0.141534
trainer/PolicyLossWithoutReg Mean           309.436
trainer/PolicyLossWithoutReg Std             55.9042
trainer/PolicyLossWithoutReg Max            386.221
trainer/PolicyLossWithoutReg Min             13.6539
exploration/num steps total              421000
exploration/num paths total                1176
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72945
exploration/Rewards Std                       1.03255
exploration/Rewards Max                       6.88793
exploration/Rewards Min                      -0.896718
exploration/Returns Mean                   4729.45
exploration/Returns Std                       0
exploration/Returns Max                    4729.45
exploration/Returns Min                    4729.45
exploration/Num Paths                         1
exploration/Average Returns                4729.45
evaluation_0/num steps total                  3.23719e+06
evaluation_0/num paths total               6727
evaluation_0/path length Mean               909.625
evaluation_0/path length Std                 83.0827
evaluation_0/path length Max               1000
evaluation_0/path length Min                781
evaluation_0/Rewards Mean                     4.44378
evaluation_0/Rewards Std                      1.40718
evaluation_0/Rewards Max                     10.152
evaluation_0/Rewards Min                     -0.930643
evaluation_0/Returns Mean                  4042.17
evaluation_0/Returns Std                    367.476
evaluation_0/Returns Max                   4430.1
evaluation_0/Returns Min                   3420.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4042.17
time/epoch (s)                                0
time/total (s)                             6334.73
Epoch                                       416
---------------------------------------  ----------------
2022-11-16 18:00:30.457817 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 417 finished
---------------------------------------  ----------------
epoch                                       417
total_step                               422000
replay_pool/size                         422000
trainer/alpha                                 0.0617134
trainer/alpha_loss                            1.65002
trainer/entropy                              -6.59239
trainer/qf_loss                              26.4262
trainer/policy_loss                        -306.624
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.031
trainer/entropy_penalty                      -0.406839
trainer/entropy_percentage                   -0.00132507
trainer/Q1Pred Mean                         305.882
trainer/Q1Pred Std                           72.034
trainer/Q1Pred Max                          388.293
trainer/Q1Pred Min                          -29.2434
trainer/Q2Pred Mean                         306.065
trainer/Q2Pred Std                           72.2875
trainer/Q2Pred Max                          386.494
trainer/Q2Pred Min                          -40.6913
trainer/QTargetWithReg Mean                 305.613
trainer/QTargetWithReg Std                   72.6349
trainer/QTargetWithReg Max                  386.75
trainer/QTargetWithReg Min                  -38.3492
trainer/PolicyLossWithoutReg Mean           307.031
trainer/PolicyLossWithoutReg Std             71.1357
trainer/PolicyLossWithoutReg Max            386.782
trainer/PolicyLossWithoutReg Min            -15.3689
exploration/num steps total              422000
exploration/num paths total                1177
exploration/path length this epoch Mean     413
exploration/path length this epoch Std        0
exploration/path length this epoch Max      413
exploration/path length this epoch Min      413
exploration/Rewards Mean                      3.74741
exploration/Rewards Std                       1.28241
exploration/Rewards Max                       6.6286
exploration/Rewards Min                      -0.786759
exploration/Returns Mean                   1547.68
exploration/Returns Std                       0
exploration/Returns Max                    1547.68
exploration/Returns Min                    1547.68
exploration/Num Paths                         1
exploration/Average Returns                1547.68
evaluation_0/num steps total                  3.24491e+06
evaluation_0/num paths total               6736
evaluation_0/path length Mean               857.556
evaluation_0/path length Std                205.595
evaluation_0/path length Max               1000
evaluation_0/path length Min                382
evaluation_0/Rewards Mean                     4.4297
evaluation_0/Rewards Std                      1.26694
evaluation_0/Rewards Max                      9.62378
evaluation_0/Rewards Min                     -0.851316
evaluation_0/Returns Mean                  3798.72
evaluation_0/Returns Std                    995.173
evaluation_0/Returns Max                   4567.41
evaluation_0/Returns Min                   1628.32
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3798.72
time/epoch (s)                                0
time/total (s)                             6347.5
Epoch                                       417
---------------------------------------  ----------------
2022-11-16 18:00:42.759607 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 418 finished
---------------------------------------  ----------------
epoch                                       418
total_step                               423000
replay_pool/size                         423000
trainer/alpha                                 0.0615649
trainer/alpha_loss                           -1.40623
trainer/entropy                              -5.49552
trainer/qf_loss                              22.518
trainer/policy_loss                        -302.325
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.663
trainer/entropy_penalty                      -0.338331
trainer/entropy_percentage                   -0.00111785
trainer/Q1Pred Mean                         301.994
trainer/Q1Pred Std                           71.8714
trainer/Q1Pred Max                          394.274
trainer/Q1Pred Min                          -10.2249
trainer/Q2Pred Mean                         302.219
trainer/Q2Pred Std                           71.9549
trainer/Q2Pred Max                          392.689
trainer/Q2Pred Min                           -6.02676
trainer/QTargetWithReg Mean                 302.043
trainer/QTargetWithReg Std                   71.4524
trainer/QTargetWithReg Max                  392.713
trainer/QTargetWithReg Min                   -7.3701
trainer/PolicyLossWithoutReg Mean           302.663
trainer/PolicyLossWithoutReg Std             70.9652
trainer/PolicyLossWithoutReg Max            392.342
trainer/PolicyLossWithoutReg Min            -11.3917
exploration/num steps total              423000
exploration/num paths total                1178
exploration/path length this epoch Mean     384
exploration/path length this epoch Std        0
exploration/path length this epoch Max      384
exploration/path length this epoch Min      384
exploration/Rewards Mean                      3.54272
exploration/Rewards Std                       1.18872
exploration/Rewards Max                       6.43597
exploration/Rewards Min                      -0.808189
exploration/Returns Mean                   1360.4
exploration/Returns Std                       0
exploration/Returns Max                    1360.4
exploration/Returns Min                    1360.4
exploration/Num Paths                         1
exploration/Average Returns                1360.4
evaluation_0/num steps total                  3.25281e+06
evaluation_0/num paths total               6747
evaluation_0/path length Mean               718.273
evaluation_0/path length Std                249.493
evaluation_0/path length Max               1000
evaluation_0/path length Min                145
evaluation_0/Rewards Mean                     4.57527
evaluation_0/Rewards Std                      1.29279
evaluation_0/Rewards Max                      8.9273
evaluation_0/Rewards Min                     -0.877391
evaluation_0/Returns Mean                  3286.29
evaluation_0/Returns Std                   1292.87
evaluation_0/Returns Max                   4818.93
evaluation_0/Returns Min                    359.542
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3286.29
time/epoch (s)                                0
time/total (s)                             6359.8
Epoch                                       418
---------------------------------------  ----------------
2022-11-16 18:00:56.673399 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 419 finished
---------------------------------------  ----------------
epoch                                       419
total_step                               424000
replay_pool/size                         424000
trainer/alpha                                 0.0606383
trainer/alpha_loss                            0.170282
trainer/entropy                              -6.06076
trainer/qf_loss                              20.7058
trainer/policy_loss                        -298.763
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         299.131
trainer/entropy_penalty                      -0.367514
trainer/entropy_percentage                   -0.00122861
trainer/Q1Pred Mean                         298.225
trainer/Q1Pred Std                           73.3578
trainer/Q1Pred Max                          384.401
trainer/Q1Pred Min                          -26.3394
trainer/Q2Pred Mean                         297.206
trainer/Q2Pred Std                           73.6673
trainer/Q2Pred Max                          383.063
trainer/Q2Pred Min                          -23.6559
trainer/QTargetWithReg Mean                 298.158
trainer/QTargetWithReg Std                   72.7991
trainer/QTargetWithReg Max                  383.004
trainer/QTargetWithReg Min                   -9.89645
trainer/PolicyLossWithoutReg Mean           299.131
trainer/PolicyLossWithoutReg Std             69.1242
trainer/PolicyLossWithoutReg Max            382.62
trainer/PolicyLossWithoutReg Min             -5.80023
exploration/num steps total              424000
exploration/num paths total                1179
exploration/path length this epoch Mean     847
exploration/path length this epoch Std        0
exploration/path length this epoch Max      847
exploration/path length this epoch Min      847
exploration/Rewards Mean                      4.36961
exploration/Rewards Std                       1.33775
exploration/Rewards Max                       7.3139
exploration/Rewards Min                      -0.818512
exploration/Returns Mean                   3701.06
exploration/Returns Std                       0
exploration/Returns Max                    3701.06
exploration/Returns Min                    3701.06
exploration/Num Paths                         1
exploration/Average Returns                3701.06
evaluation_0/num steps total                  3.26020e+06
evaluation_0/num paths total               6757
evaluation_0/path length Mean               739.2
evaluation_0/path length Std                207.366
evaluation_0/path length Max               1000
evaluation_0/path length Min                438
evaluation_0/Rewards Mean                     4.71221
evaluation_0/Rewards Std                      1.29364
evaluation_0/Rewards Max                      9.53844
evaluation_0/Rewards Min                     -0.77434
evaluation_0/Returns Mean                  3483.26
evaluation_0/Returns Std                   1112.22
evaluation_0/Returns Max                   4997.3
evaluation_0/Returns Min                   1893.15
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3483.26
time/epoch (s)                                0
time/total (s)                             6373.71
Epoch                                       419
---------------------------------------  ----------------
2022-11-16 18:01:08.847952 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 420 finished
---------------------------------------  ----------------
epoch                                       420
total_step                               425000
replay_pool/size                         425000
trainer/alpha                                 0.0630939
trainer/alpha_loss                           -0.253678
trainer/entropy                              -5.90819
trainer/qf_loss                              28.9003
trainer/policy_loss                        -302.913
trainer/adversary_policy_loss                14.365
trainer/policy_loss_without_entropy         303.286
trainer/entropy_penalty                      -0.37277
trainer/entropy_percentage                   -0.00122911
trainer/Q1Pred Mean                         302.384
trainer/Q1Pred Std                           66.0648
trainer/Q1Pred Max                          385.374
trainer/Q1Pred Min                           12.0528
trainer/Q2Pred Mean                         301.697
trainer/Q2Pred Std                           66.3426
trainer/Q2Pred Max                          388.695
trainer/Q2Pred Min                            5.88127
trainer/QTargetWithReg Mean                 302.171
trainer/QTargetWithReg Std                   67.1748
trainer/QTargetWithReg Max                  384.329
trainer/QTargetWithReg Min                    2.30633
trainer/PolicyLossWithoutReg Mean           303.286
trainer/PolicyLossWithoutReg Std             65.8165
trainer/PolicyLossWithoutReg Max            384.67
trainer/PolicyLossWithoutReg Min              7.79663
exploration/num steps total              425000
exploration/num paths total                1180
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70958
exploration/Rewards Std                       1.1133
exploration/Rewards Max                       6.60301
exploration/Rewards Min                      -0.668641
exploration/Returns Mean                   4709.58
exploration/Returns Std                       0
exploration/Returns Max                    4709.58
exploration/Returns Min                    4709.58
exploration/Num Paths                         1
exploration/Average Returns                4709.58
evaluation_0/num steps total                  3.26807e+06
evaluation_0/num paths total               6767
evaluation_0/path length Mean               786.2
evaluation_0/path length Std                182.559
evaluation_0/path length Max               1000
evaluation_0/path length Min                466
evaluation_0/Rewards Mean                     4.75212
evaluation_0/Rewards Std                      1.24587
evaluation_0/Rewards Max                      9.76568
evaluation_0/Rewards Min                     -0.79528
evaluation_0/Returns Mean                  3736.12
evaluation_0/Returns Std                    970.399
evaluation_0/Returns Max                   4972.42
evaluation_0/Returns Min                   2033.14
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3736.12
time/epoch (s)                                0
time/total (s)                             6385.89
Epoch                                       420
---------------------------------------  ----------------
2022-11-16 18:01:21.859109 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 421 finished
---------------------------------------  ---------------
epoch                                       421
total_step                               426000
replay_pool/size                         426000
trainer/alpha                                 0.0634073
trainer/alpha_loss                           -0.844062
trainer/entropy                              -5.69397
trainer/qf_loss                              27.0009
trainer/policy_loss                        -303.116
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.477
trainer/entropy_penalty                      -0.361039
trainer/entropy_percentage                   -0.00118967
trainer/Q1Pred Mean                         303.581
trainer/Q1Pred Std                           65.0824
trainer/Q1Pred Max                          385.432
trainer/Q1Pred Min                           10.3933
trainer/Q2Pred Mean                         302.485
trainer/Q2Pred Std                           65.8897
trainer/Q2Pred Max                          383.901
trainer/Q2Pred Min                          -16.8964
trainer/QTargetWithReg Mean                 301.854
trainer/QTargetWithReg Std                   65.9913
trainer/QTargetWithReg Max                  383.482
trainer/QTargetWithReg Min                   -0.84942
trainer/PolicyLossWithoutReg Mean           303.477
trainer/PolicyLossWithoutReg Std             65.2762
trainer/PolicyLossWithoutReg Max            384.139
trainer/PolicyLossWithoutReg Min            -28.2325
exploration/num steps total              426000
exploration/num paths total                1181
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55832
exploration/Rewards Std                       1.04626
exploration/Rewards Max                       7.02657
exploration/Rewards Min                      -0.813805
exploration/Returns Mean                   4558.32
exploration/Returns Std                       0
exploration/Returns Max                    4558.32
exploration/Returns Min                    4558.32
exploration/Num Paths                         1
exploration/Average Returns                4558.32
evaluation_0/num steps total                  3.276e+06
evaluation_0/num paths total               6776
evaluation_0/path length Mean               881
evaluation_0/path length Std                108.059
evaluation_0/path length Max               1000
evaluation_0/path length Min                702
evaluation_0/Rewards Mean                     4.39364
evaluation_0/Rewards Std                      1.19597
evaluation_0/Rewards Max                      9.296
evaluation_0/Rewards Min                     -0.948803
evaluation_0/Returns Mean                  3870.8
evaluation_0/Returns Std                    526.038
evaluation_0/Returns Max                   4653.49
evaluation_0/Returns Min                   2968.31
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3870.8
time/epoch (s)                                0
time/total (s)                             6398.9
Epoch                                       421
---------------------------------------  ---------------
2022-11-16 18:01:34.582213 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 422 finished
---------------------------------------  ---------------
epoch                                       422
total_step                               427000
replay_pool/size                         427000
trainer/alpha                                 0.0627534
trainer/alpha_loss                           -0.347089
trainer/entropy                              -5.87462
trainer/qf_loss                              16.3176
trainer/policy_loss                        -305.667
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         306.035
trainer/entropy_penalty                      -0.368653
trainer/entropy_percentage                   -0.00120461
trainer/Q1Pred Mean                         304.89
trainer/Q1Pred Std                           64.0764
trainer/Q1Pred Max                          383.087
trainer/Q1Pred Min                           19.5074
trainer/Q2Pred Mean                         304.902
trainer/Q2Pred Std                           63.3586
trainer/Q2Pred Max                          381.718
trainer/Q2Pred Min                           23.0218
trainer/QTargetWithReg Mean                 305.342
trainer/QTargetWithReg Std                   63.4056
trainer/QTargetWithReg Max                  385.182
trainer/QTargetWithReg Min                   24.309
trainer/PolicyLossWithoutReg Mean           306.035
trainer/PolicyLossWithoutReg Std             62.7038
trainer/PolicyLossWithoutReg Max            381.565
trainer/PolicyLossWithoutReg Min             22.5855
exploration/num steps total              427000
exploration/num paths total                1182
exploration/path length this epoch Mean     849
exploration/path length this epoch Std        0
exploration/path length this epoch Max      849
exploration/path length this epoch Min      849
exploration/Rewards Mean                      4.56812
exploration/Rewards Std                       1.37183
exploration/Rewards Max                       8.34851
exploration/Rewards Min                      -0.687693
exploration/Returns Mean                   3878.33
exploration/Returns Std                       0
exploration/Returns Max                    3878.33
exploration/Returns Min                    3878.33
exploration/Num Paths                         1
exploration/Average Returns                3878.33
evaluation_0/num steps total                  3.284e+06
evaluation_0/num paths total               6784
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58493
evaluation_0/Rewards Std                      1.00698
evaluation_0/Rewards Max                      7.10394
evaluation_0/Rewards Min                     -0.87326
evaluation_0/Returns Mean                  4584.93
evaluation_0/Returns Std                    125.008
evaluation_0/Returns Max                   4704.46
evaluation_0/Returns Min                   4399.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4584.93
time/epoch (s)                                0
time/total (s)                             6411.62
Epoch                                       422
---------------------------------------  ---------------
2022-11-16 18:01:46.912250 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 423 finished
---------------------------------------  ---------------
epoch                                       423
total_step                               428000
replay_pool/size                         428000
trainer/alpha                                 0.0628773
trainer/alpha_loss                            0.708631
trainer/entropy                              -6.25613
trainer/qf_loss                              32.2569
trainer/policy_loss                        -306.879
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.272
trainer/entropy_penalty                      -0.393368
trainer/entropy_percentage                   -0.00128019
trainer/Q1Pred Mean                         304.694
trainer/Q1Pred Std                           64.801
trainer/Q1Pred Max                          389.547
trainer/Q1Pred Min                           -2.71541
trainer/Q2Pred Mean                         305.135
trainer/Q2Pred Std                           64.5106
trainer/Q2Pred Max                          384.372
trainer/Q2Pred Min                            4.32921
trainer/QTargetWithReg Mean                 305.68
trainer/QTargetWithReg Std                   64.7007
trainer/QTargetWithReg Max                  384.867
trainer/QTargetWithReg Min                    0.212966
trainer/PolicyLossWithoutReg Mean           307.273
trainer/PolicyLossWithoutReg Std             59.7961
trainer/PolicyLossWithoutReg Max            383.599
trainer/PolicyLossWithoutReg Min              8.56244
exploration/num steps total              428000
exploration/num paths total                1183
exploration/path length this epoch Mean     913
exploration/path length this epoch Std        0
exploration/path length this epoch Max      913
exploration/path length this epoch Min      913
exploration/Rewards Mean                      4.21833
exploration/Rewards Std                       1.33878
exploration/Rewards Max                       8.82256
exploration/Rewards Min                      -0.804834
exploration/Returns Mean                   3851.33
exploration/Returns Std                       0
exploration/Returns Max                    3851.33
exploration/Returns Min                    3851.33
exploration/Num Paths                         1
exploration/Average Returns                3851.33
evaluation_0/num steps total                  3.2919e+06
evaluation_0/num paths total               6792
evaluation_0/path length Mean               987.875
evaluation_0/path length Std                 32.0797
evaluation_0/path length Max               1000
evaluation_0/path length Min                903
evaluation_0/Rewards Mean                     4.8576
evaluation_0/Rewards Std                      1.11808
evaluation_0/Rewards Max                      8.08632
evaluation_0/Rewards Min                     -0.831788
evaluation_0/Returns Mean                  4798.7
evaluation_0/Returns Std                    151.345
evaluation_0/Returns Max                   4983.41
evaluation_0/Returns Min                   4437.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4798.7
time/epoch (s)                                0
time/total (s)                             6423.95
Epoch                                       423
---------------------------------------  ---------------
2022-11-16 18:02:00.214145 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 424 finished
---------------------------------------  ----------------
epoch                                       424
total_step                               429000
replay_pool/size                         429000
trainer/alpha                                 0.0617714
trainer/alpha_loss                           -0.39921
trainer/entropy                              -5.85662
trainer/qf_loss                              18.2244
trainer/policy_loss                        -301.43
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.792
trainer/entropy_penalty                      -0.361772
trainer/entropy_percentage                   -0.00119875
trainer/Q1Pred Mean                         300.687
trainer/Q1Pred Std                           62.8817
trainer/Q1Pred Max                          383.797
trainer/Q1Pred Min                           10.4531
trainer/Q2Pred Mean                         301.159
trainer/Q2Pred Std                           62.7248
trainer/Q2Pred Max                          384.257
trainer/Q2Pred Min                            8.32019
trainer/QTargetWithReg Mean                 300.78
trainer/QTargetWithReg Std                   62.5107
trainer/QTargetWithReg Max                  383.245
trainer/QTargetWithReg Min                   22.5604
trainer/PolicyLossWithoutReg Mean           301.792
trainer/PolicyLossWithoutReg Std             60.9514
trainer/PolicyLossWithoutReg Max            382.974
trainer/PolicyLossWithoutReg Min             12.7935
exploration/num steps total              429000
exploration/num paths total                1184
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.23142
exploration/Rewards Std                       1.24121
exploration/Rewards Max                       6.70243
exploration/Rewards Min                      -0.868099
exploration/Returns Mean                   4231.42
exploration/Returns Std                       0
exploration/Returns Max                    4231.42
exploration/Returns Min                    4231.42
exploration/Num Paths                         1
exploration/Average Returns                4231.42
evaluation_0/num steps total                  3.29987e+06
evaluation_0/num paths total               6801
evaluation_0/path length Mean               885.333
evaluation_0/path length Std                148.236
evaluation_0/path length Max               1000
evaluation_0/path length Min                629
evaluation_0/Rewards Mean                     4.73857
evaluation_0/Rewards Std                      1.18027
evaluation_0/Rewards Max                      8.79693
evaluation_0/Rewards Min                     -0.876682
evaluation_0/Returns Mean                  4195.21
evaluation_0/Returns Std                    741.607
evaluation_0/Returns Max                   4910.89
evaluation_0/Returns Min                   2845.15
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4195.21
time/epoch (s)                                0
time/total (s)                             6437.26
Epoch                                       424
---------------------------------------  ----------------
2022-11-16 18:02:13.914616 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 425 finished
---------------------------------------  ----------------
epoch                                       425
total_step                               430000
replay_pool/size                         430000
trainer/alpha                                 0.0644491
trainer/alpha_loss                           -0.289132
trainer/entropy                              -5.89455
trainer/qf_loss                              28.3321
trainer/policy_loss                        -309.636
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.016
trainer/entropy_penalty                      -0.379899
trainer/entropy_percentage                   -0.00122542
trainer/Q1Pred Mean                         309.304
trainer/Q1Pred Std                           60.23
trainer/Q1Pred Max                          385.649
trainer/Q1Pred Min                           10.4356
trainer/Q2Pred Mean                         308.77
trainer/Q2Pred Std                           60.3418
trainer/Q2Pred Max                          387.724
trainer/Q2Pred Min                           14.839
trainer/QTargetWithReg Mean                 308.435
trainer/QTargetWithReg Std                   60.3915
trainer/QTargetWithReg Max                  385.829
trainer/QTargetWithReg Min                    5.0818
trainer/PolicyLossWithoutReg Mean           310.016
trainer/PolicyLossWithoutReg Std             59.2987
trainer/PolicyLossWithoutReg Max            387.459
trainer/PolicyLossWithoutReg Min             16.8035
exploration/num steps total              430000
exploration/num paths total                1185
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47717
exploration/Rewards Std                       1.05401
exploration/Rewards Max                       6.54473
exploration/Rewards Min                      -0.745544
exploration/Returns Mean                   4477.17
exploration/Returns Std                       0
exploration/Returns Max                    4477.17
exploration/Returns Min                    4477.17
exploration/Num Paths                         1
exploration/Average Returns                4477.17
evaluation_0/num steps total                  3.30787e+06
evaluation_0/num paths total               6811
evaluation_0/path length Mean               799.9
evaluation_0/path length Std                196.781
evaluation_0/path length Max               1000
evaluation_0/path length Min                483
evaluation_0/Rewards Mean                     4.67002
evaluation_0/Rewards Std                      1.20268
evaluation_0/Rewards Max                      9.92015
evaluation_0/Rewards Min                     -0.886114
evaluation_0/Returns Mean                  3735.55
evaluation_0/Returns Std                   1020.97
evaluation_0/Returns Max                   4845.34
evaluation_0/Returns Min                   1974.08
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3735.55
time/epoch (s)                                0
time/total (s)                             6450.96
Epoch                                       425
---------------------------------------  ----------------
2022-11-16 18:02:25.860902 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 426 finished
---------------------------------------  ----------------
epoch                                       426
total_step                               431000
replay_pool/size                         431000
trainer/alpha                                 0.0618852
trainer/alpha_loss                           -0.723987
trainer/entropy                              -5.73979
trainer/qf_loss                              22.5353
trainer/policy_loss                        -308.208
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.563
trainer/entropy_penalty                      -0.355208
trainer/entropy_percentage                   -0.00115117
trainer/Q1Pred Mean                         307.165
trainer/Q1Pred Std                           67.7973
trainer/Q1Pred Max                          393.872
trainer/Q1Pred Min                          -41.3494
trainer/Q2Pred Mean                         307.685
trainer/Q2Pred Std                           66.8687
trainer/Q2Pred Max                          389.669
trainer/Q2Pred Min                           -2.98242
trainer/QTargetWithReg Mean                 307.308
trainer/QTargetWithReg Std                   67.0856
trainer/QTargetWithReg Max                  390.33
trainer/QTargetWithReg Min                    0.412732
trainer/PolicyLossWithoutReg Mean           308.563
trainer/PolicyLossWithoutReg Std             64.1586
trainer/PolicyLossWithoutReg Max            389.576
trainer/PolicyLossWithoutReg Min              1.81374
exploration/num steps total              431000
exploration/num paths total                1186
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81526
exploration/Rewards Std                       1.2125
exploration/Rewards Max                       7.96635
exploration/Rewards Min                      -0.769298
exploration/Returns Mean                   4815.26
exploration/Returns Std                       0
exploration/Returns Max                    4815.26
exploration/Returns Min                    4815.26
exploration/Num Paths                         1
exploration/Average Returns                4815.26
evaluation_0/num steps total                  3.31556e+06
evaluation_0/num paths total               6824
evaluation_0/path length Mean               591.923
evaluation_0/path length Std                266.332
evaluation_0/path length Max               1000
evaluation_0/path length Min                156
evaluation_0/Rewards Mean                     4.15427
evaluation_0/Rewards Std                      1.56154
evaluation_0/Rewards Max                     11.5692
evaluation_0/Rewards Min                     -0.913803
evaluation_0/Returns Mean                  2459.01
evaluation_0/Returns Std                   1410.87
evaluation_0/Returns Max                   4740.9
evaluation_0/Returns Min                    325.714
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2459.01
time/epoch (s)                                0
time/total (s)                             6462.9
Epoch                                       426
---------------------------------------  ----------------
2022-11-16 18:02:38.310580 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 427 finished
---------------------------------------  ----------------
epoch                                       427
total_step                               432000
replay_pool/size                         432000
trainer/alpha                                 0.0625012
trainer/alpha_loss                            0.584368
trainer/entropy                              -6.21076
trainer/qf_loss                              28.9457
trainer/policy_loss                        -304.427
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.816
trainer/entropy_penalty                      -0.38818
trainer/entropy_percentage                   -0.00127349
trainer/Q1Pred Mean                         303.329
trainer/Q1Pred Std                           66.1426
trainer/Q1Pred Max                          386.526
trainer/Q1Pred Min                           12.3434
trainer/Q2Pred Mean                         303.274
trainer/Q2Pred Std                           66.1905
trainer/Q2Pred Max                          384.992
trainer/Q2Pred Min                            9.50963
trainer/QTargetWithReg Mean                 303.902
trainer/QTargetWithReg Std                   65.9501
trainer/QTargetWithReg Max                  387.649
trainer/QTargetWithReg Min                   19.0494
trainer/PolicyLossWithoutReg Mean           304.816
trainer/PolicyLossWithoutReg Std             65.1125
trainer/PolicyLossWithoutReg Max            385.139
trainer/PolicyLossWithoutReg Min             12.2658
exploration/num steps total              432000
exploration/num paths total                1187
exploration/path length this epoch Mean     614
exploration/path length this epoch Std        0
exploration/path length this epoch Max      614
exploration/path length this epoch Min      614
exploration/Rewards Mean                      4.20259
exploration/Rewards Std                       1.2511
exploration/Rewards Max                       6.46633
exploration/Rewards Min                      -0.592209
exploration/Returns Mean                   2580.39
exploration/Returns Std                       0
exploration/Returns Max                    2580.39
exploration/Returns Min                    2580.39
exploration/Num Paths                         1
exploration/Average Returns                2580.39
evaluation_0/num steps total                  3.32301e+06
evaluation_0/num paths total               6834
evaluation_0/path length Mean               744.9
evaluation_0/path length Std                253.795
evaluation_0/path length Max               1000
evaluation_0/path length Min                389
evaluation_0/Rewards Mean                     4.53587
evaluation_0/Rewards Std                      1.31687
evaluation_0/Rewards Max                     10.3623
evaluation_0/Rewards Min                     -0.915924
evaluation_0/Returns Mean                  3378.77
evaluation_0/Returns Std                   1310.67
evaluation_0/Returns Max                   4727.87
evaluation_0/Returns Min                   1575.34
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3378.77
time/epoch (s)                                0
time/total (s)                             6475.35
Epoch                                       427
---------------------------------------  ----------------
2022-11-16 18:02:52.598824 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 428 finished
---------------------------------------  ----------------
epoch                                       428
total_step                               433000
replay_pool/size                         433000
trainer/alpha                                 0.0630487
trainer/alpha_loss                            0.42962
trainer/entropy                              -6.15543
trainer/qf_loss                              24.4861
trainer/policy_loss                        -303.701
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.089
trainer/entropy_penalty                      -0.388092
trainer/entropy_percentage                   -0.00127624
trainer/Q1Pred Mean                         302.617
trainer/Q1Pred Std                           65.9055
trainer/Q1Pred Max                          388.238
trainer/Q1Pred Min                            5.93833
trainer/Q2Pred Mean                         303.376
trainer/Q2Pred Std                           66.1549
trainer/Q2Pred Max                          389.6
trainer/Q2Pred Min                            6.7928
trainer/QTargetWithReg Mean                 303.445
trainer/QTargetWithReg Std                   66.0318
trainer/QTargetWithReg Max                  388.176
trainer/QTargetWithReg Min                   11.8314
trainer/PolicyLossWithoutReg Mean           304.089
trainer/PolicyLossWithoutReg Std             64.9394
trainer/PolicyLossWithoutReg Max            388.101
trainer/PolicyLossWithoutReg Min             13.1386
exploration/num steps total              433000
exploration/num paths total                1189
exploration/path length this epoch Mean     369
exploration/path length this epoch Std      294
exploration/path length this epoch Max      663
exploration/path length this epoch Min       75
exploration/Rewards Mean                      3.82274
exploration/Rewards Std                       1.44987
exploration/Rewards Max                       6.3959
exploration/Rewards Min                      -0.956491
exploration/Returns Mean                   1410.59
exploration/Returns Std                    1246.93
exploration/Returns Max                    2657.52
exploration/Returns Min                     163.665
exploration/Num Paths                         2
exploration/Average Returns                1410.59
evaluation_0/num steps total                  3.33034e+06
evaluation_0/num paths total               6843
evaluation_0/path length Mean               814.111
evaluation_0/path length Std                176.057
evaluation_0/path length Max               1000
evaluation_0/path length Min                491
evaluation_0/Rewards Mean                     4.49819
evaluation_0/Rewards Std                      1.35472
evaluation_0/Rewards Max                      8.71305
evaluation_0/Rewards Min                     -0.76411
evaluation_0/Returns Mean                  3662.03
evaluation_0/Returns Std                    886.831
evaluation_0/Returns Max                   4656.18
evaluation_0/Returns Min                   2073.64
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3662.03
time/epoch (s)                                0
time/total (s)                             6489.64
Epoch                                       428
---------------------------------------  ----------------
2022-11-16 18:03:05.054462 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 429 finished
---------------------------------------  ----------------
epoch                                       429
total_step                               434000
replay_pool/size                         434000
trainer/alpha                                 0.0624887
trainer/alpha_loss                            0.206303
trainer/entropy                              -6.0744
trainer/qf_loss                              20.7305
trainer/policy_loss                        -306.781
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.161
trainer/entropy_penalty                      -0.379582
trainer/entropy_percentage                   -0.00123578
trainer/Q1Pred Mean                         305.691
trainer/Q1Pred Std                           66.5259
trainer/Q1Pred Max                          390.889
trainer/Q1Pred Min                          -13.853
trainer/Q2Pred Mean                         305.62
trainer/Q2Pred Std                           65.9214
trainer/Q2Pred Max                          388.386
trainer/Q2Pred Min                          -12.8669
trainer/QTargetWithReg Mean                 305.823
trainer/QTargetWithReg Std                   66.9438
trainer/QTargetWithReg Max                  392.544
trainer/QTargetWithReg Min                   -9.7153
trainer/PolicyLossWithoutReg Mean           307.161
trainer/PolicyLossWithoutReg Std             62.9758
trainer/PolicyLossWithoutReg Max            388.76
trainer/PolicyLossWithoutReg Min             -8.60952
exploration/num steps total              434000
exploration/num paths total                1191
exploration/path length this epoch Mean     375
exploration/path length this epoch Std      181
exploration/path length this epoch Max      556
exploration/path length this epoch Min      194
exploration/Rewards Mean                      3.59051
exploration/Rewards Std                       1.6361
exploration/Rewards Max                       7.08058
exploration/Rewards Min                      -1.14285
exploration/Returns Mean                   1346.44
exploration/Returns Std                     983.554
exploration/Returns Max                    2330
exploration/Returns Min                     362.888
exploration/Num Paths                         2
exploration/Average Returns                1346.44
evaluation_0/num steps total                  3.33833e+06
evaluation_0/num paths total               6853
evaluation_0/path length Mean               799.1
evaluation_0/path length Std                197.192
evaluation_0/path length Max               1000
evaluation_0/path length Min                476
evaluation_0/Rewards Mean                     4.38954
evaluation_0/Rewards Std                      1.34944
evaluation_0/Rewards Max                      9.45033
evaluation_0/Rewards Min                     -0.777752
evaluation_0/Returns Mean                  3507.68
evaluation_0/Returns Std                   1044.28
evaluation_0/Returns Max                   4629.24
evaluation_0/Returns Min                   1856.89
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3507.68
time/epoch (s)                                0
time/total (s)                             6502.09
Epoch                                       429
---------------------------------------  ----------------
2022-11-16 18:03:19.017747 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 430 finished
---------------------------------------  ----------------
epoch                                       430
total_step                               435000
replay_pool/size                         435000
trainer/alpha                                 0.060565
trainer/alpha_loss                            1.33063
trainer/entropy                              -6.47456
trainer/qf_loss                              30.1602
trainer/policy_loss                        -303.373
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.765
trainer/entropy_penalty                      -0.392131
trainer/entropy_percentage                   -0.0012909
trainer/Q1Pred Mean                         302.598
trainer/Q1Pred Std                           66.8201
trainer/Q1Pred Max                          383.813
trainer/Q1Pred Min                            7.65216
trainer/Q2Pred Mean                         302.521
trainer/Q2Pred Std                           66.3591
trainer/Q2Pred Max                          383.568
trainer/Q2Pred Min                            9.91775
trainer/QTargetWithReg Mean                 302.618
trainer/QTargetWithReg Std                   66.6287
trainer/QTargetWithReg Max                  385.139
trainer/QTargetWithReg Min                    6.82669
trainer/PolicyLossWithoutReg Mean           303.765
trainer/PolicyLossWithoutReg Std             64.7481
trainer/PolicyLossWithoutReg Max            384.439
trainer/PolicyLossWithoutReg Min              9.74767
exploration/num steps total              435000
exploration/num paths total                1192
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.13939
exploration/Rewards Std                       1.08629
exploration/Rewards Max                       6.58269
exploration/Rewards Min                      -0.673773
exploration/Returns Mean                   4139.39
exploration/Returns Std                       0
exploration/Returns Max                    4139.39
exploration/Returns Min                    4139.39
exploration/Num Paths                         1
exploration/Average Returns                4139.39
evaluation_0/num steps total                  3.34577e+06
evaluation_0/num paths total               6863
evaluation_0/path length Mean               744.5
evaluation_0/path length Std                171.033
evaluation_0/path length Max               1000
evaluation_0/path length Min                490
evaluation_0/Rewards Mean                     4.47928
evaluation_0/Rewards Std                      1.41117
evaluation_0/Rewards Max                      9.00699
evaluation_0/Rewards Min                     -0.806134
evaluation_0/Returns Mean                  3334.82
evaluation_0/Returns Std                    985.204
evaluation_0/Returns Max                   4920.45
evaluation_0/Returns Min                   1938.81
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3334.82
time/epoch (s)                                0
time/total (s)                             6516.06
Epoch                                       430
---------------------------------------  ----------------
2022-11-16 18:03:32.216211 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 431 finished
---------------------------------------  ----------------
epoch                                       431
total_step                               436000
replay_pool/size                         436000
trainer/alpha                                 0.0628415
trainer/alpha_loss                           -1.43894
trainer/entropy                              -5.47998
trainer/qf_loss                              29.7905
trainer/policy_loss                        -316.185
trainer/adversary_policy_loss                15.1537
trainer/policy_loss_without_entropy         316.529
trainer/entropy_penalty                      -0.34437
trainer/entropy_percentage                   -0.00108796
trainer/Q1Pred Mean                         315.672
trainer/Q1Pred Std                           55.5987
trainer/Q1Pred Max                          390.393
trainer/Q1Pred Min                           21.5959
trainer/Q2Pred Mean                         314.735
trainer/Q2Pred Std                           55.402
trainer/Q2Pred Max                          394.094
trainer/Q2Pred Min                           21.3667
trainer/QTargetWithReg Mean                 314.066
trainer/QTargetWithReg Std                   55.013
trainer/QTargetWithReg Max                  396.129
trainer/QTargetWithReg Min                   20.0195
trainer/PolicyLossWithoutReg Mean           316.529
trainer/PolicyLossWithoutReg Std             53.5128
trainer/PolicyLossWithoutReg Max            390.828
trainer/PolicyLossWithoutReg Min             20.7196
exploration/num steps total              436000
exploration/num paths total                1193
exploration/path length this epoch Mean     661
exploration/path length this epoch Std        0
exploration/path length this epoch Max      661
exploration/path length this epoch Min      661
exploration/Rewards Mean                      3.99392
exploration/Rewards Std                       1.24641
exploration/Rewards Max                       6.86828
exploration/Rewards Min                      -0.835628
exploration/Returns Mean                   2639.98
exploration/Returns Std                       0
exploration/Returns Max                    2639.98
exploration/Returns Min                    2639.98
exploration/Num Paths                         1
exploration/Average Returns                2639.98
evaluation_0/num steps total                  3.35309e+06
evaluation_0/num paths total               6871
evaluation_0/path length Mean               915.125
evaluation_0/path length Std                224.558
evaluation_0/path length Max               1000
evaluation_0/path length Min                321
evaluation_0/Rewards Mean                     4.61562
evaluation_0/Rewards Std                      1.1256
evaluation_0/Rewards Max                      7.18481
evaluation_0/Rewards Min                     -0.88576
evaluation_0/Returns Mean                  4223.87
evaluation_0/Returns Std                   1131.82
evaluation_0/Returns Max                   4795.82
evaluation_0/Returns Min                   1249.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4223.87
time/epoch (s)                                0
time/total (s)                             6529.25
Epoch                                       431
---------------------------------------  ----------------
2022-11-16 18:03:44.748203 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 432 finished
---------------------------------------  ---------------
epoch                                       432
total_step                               437000
replay_pool/size                         437000
trainer/alpha                                 0.061656
trainer/alpha_loss                            0.857907
trainer/entropy                              -6.30792
trainer/qf_loss                              25.1607
trainer/policy_loss                        -303.287
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.676
trainer/entropy_penalty                      -0.388921
trainer/entropy_percentage                   -0.00128071
trainer/Q1Pred Mean                         302.937
trainer/Q1Pred Std                           61.7147
trainer/Q1Pred Max                          387.801
trainer/Q1Pred Min                          -11.3688
trainer/Q2Pred Mean                         303.32
trainer/Q2Pred Std                           61.0125
trainer/Q2Pred Max                          387.273
trainer/Q2Pred Min                            1.8488
trainer/QTargetWithReg Mean                 302.997
trainer/QTargetWithReg Std                   61.2748
trainer/QTargetWithReg Max                  387.339
trainer/QTargetWithReg Min                    2.82801
trainer/PolicyLossWithoutReg Mean           303.676
trainer/PolicyLossWithoutReg Std             60.2533
trainer/PolicyLossWithoutReg Max            385.565
trainer/PolicyLossWithoutReg Min             -9.07945
exploration/num steps total              437000
exploration/num paths total                1194
exploration/path length this epoch Mean     945
exploration/path length this epoch Std        0
exploration/path length this epoch Max      945
exploration/path length this epoch Min      945
exploration/Rewards Mean                      4.82683
exploration/Rewards Std                       1.3354
exploration/Rewards Max                       8.74993
exploration/Rewards Min                      -0.847673
exploration/Returns Mean                   4561.36
exploration/Returns Std                       0
exploration/Returns Max                    4561.36
exploration/Returns Min                    4561.36
exploration/Num Paths                         1
exploration/Average Returns                4561.36
evaluation_0/num steps total                  3.3607e+06
evaluation_0/num paths total               6881
evaluation_0/path length Mean               760.6
evaluation_0/path length Std                246.394
evaluation_0/path length Max               1000
evaluation_0/path length Min                422
evaluation_0/Rewards Mean                     4.58975
evaluation_0/Rewards Std                      1.22186
evaluation_0/Rewards Max                      8.48788
evaluation_0/Rewards Min                     -0.846313
evaluation_0/Returns Mean                  3490.96
evaluation_0/Returns Std                   1242.25
evaluation_0/Returns Max                   4844.19
evaluation_0/Returns Min                   1730.71
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3490.96
time/epoch (s)                                0
time/total (s)                             6541.79
Epoch                                       432
---------------------------------------  ---------------
2022-11-16 18:03:59.392152 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 433 finished
---------------------------------------  ---------------
epoch                                       433
total_step                               438000
replay_pool/size                         438000
trainer/alpha                                 0.0613863
trainer/alpha_loss                           -0.54847
trainer/entropy                              -5.80344
trainer/qf_loss                              23.714
trainer/policy_loss                        -303.052
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.408
trainer/entropy_penalty                      -0.356252
trainer/entropy_percentage                   -0.00117417
trainer/Q1Pred Mean                         302.212
trainer/Q1Pred Std                           76.0034
trainer/Q1Pred Max                          397.087
trainer/Q1Pred Min                          -24.772
trainer/Q2Pred Mean                         302.045
trainer/Q2Pred Std                           75.7311
trainer/Q2Pred Max                          397.619
trainer/Q2Pred Min                          -16.9046
trainer/QTargetWithReg Mean                 302.295
trainer/QTargetWithReg Std                   74.9291
trainer/QTargetWithReg Max                  397.78
trainer/QTargetWithReg Min                  -42.8773
trainer/PolicyLossWithoutReg Mean           303.408
trainer/PolicyLossWithoutReg Std             75.0049
trainer/PolicyLossWithoutReg Max            397.599
trainer/PolicyLossWithoutReg Min            -26.0684
exploration/num steps total              438000
exploration/num paths total                1197
exploration/path length this epoch Mean     311.667
exploration/path length this epoch Std      194.889
exploration/path length this epoch Max      582
exploration/path length this epoch Min      130
exploration/Rewards Mean                      3.41926
exploration/Rewards Std                       1.77348
exploration/Rewards Max                       7.84906
exploration/Rewards Min                      -0.911023
exploration/Returns Mean                   1065.67
exploration/Returns Std                    1069.34
exploration/Returns Max                    2568.49
exploration/Returns Min                     168.078
exploration/Num Paths                         3
exploration/Average Returns                1065.67
evaluation_0/num steps total                  3.3678e+06
evaluation_0/num paths total               6893
evaluation_0/path length Mean               591.667
evaluation_0/path length Std                175.09
evaluation_0/path length Max                993
evaluation_0/path length Min                415
evaluation_0/Rewards Mean                     4.08133
evaluation_0/Rewards Std                      1.47619
evaluation_0/Rewards Max                      9.8775
evaluation_0/Rewards Min                     -0.631674
evaluation_0/Returns Mean                  2414.79
evaluation_0/Returns Std                    828.464
evaluation_0/Returns Max                   4193.69
evaluation_0/Returns Min                   1601.18
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2414.79
time/epoch (s)                                0
time/total (s)                             6556.43
Epoch                                       433
---------------------------------------  ---------------
2022-11-16 18:04:12.316457 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 434 finished
---------------------------------------  ----------------
epoch                                       434
total_step                               439000
replay_pool/size                         439000
trainer/alpha                                 0.0624592
trainer/alpha_loss                           -1.19507
trainer/entropy                              -5.56912
trainer/qf_loss                              22.4124
trainer/policy_loss                        -314.357
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.705
trainer/entropy_penalty                      -0.347843
trainer/entropy_percentage                   -0.0011053
trainer/Q1Pred Mean                         314.31
trainer/Q1Pred Std                           59.8889
trainer/Q1Pred Max                          391.716
trainer/Q1Pred Min                           11.6479
trainer/Q2Pred Mean                         314.379
trainer/Q2Pred Std                           59.5182
trainer/Q2Pred Max                          389.505
trainer/Q2Pred Min                           11.0582
trainer/QTargetWithReg Mean                 314.376
trainer/QTargetWithReg Std                   59.5176
trainer/QTargetWithReg Max                  392.158
trainer/QTargetWithReg Min                   13.4444
trainer/PolicyLossWithoutReg Mean           314.705
trainer/PolicyLossWithoutReg Std             59.2068
trainer/PolicyLossWithoutReg Max            391.191
trainer/PolicyLossWithoutReg Min              9.41954
exploration/num steps total              439000
exploration/num paths total                1198
exploration/path length this epoch Mean     555
exploration/path length this epoch Std        0
exploration/path length this epoch Max      555
exploration/path length this epoch Min      555
exploration/Rewards Mean                      3.9778
exploration/Rewards Std                       1.20147
exploration/Rewards Max                       6.12136
exploration/Rewards Min                      -0.638239
exploration/Returns Mean                   2207.68
exploration/Returns Std                       0
exploration/Returns Max                    2207.68
exploration/Returns Min                    2207.68
exploration/Num Paths                         1
exploration/Average Returns                2207.68
evaluation_0/num steps total                  3.37513e+06
evaluation_0/num paths total               6904
evaluation_0/path length Mean               666.545
evaluation_0/path length Std                203.174
evaluation_0/path length Max               1000
evaluation_0/path length Min                368
evaluation_0/Rewards Mean                     4.49871
evaluation_0/Rewards Std                      1.2855
evaluation_0/Rewards Max                      8.30109
evaluation_0/Rewards Min                     -0.649899
evaluation_0/Returns Mean                  2998.6
evaluation_0/Returns Std                   1065.25
evaluation_0/Returns Max                   4772.56
evaluation_0/Returns Min                   1508.39
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2998.6
time/epoch (s)                                0
time/total (s)                             6569.35
Epoch                                       434
---------------------------------------  ----------------
2022-11-16 18:04:25.163510 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 435 finished
---------------------------------------  ----------------
epoch                                       435
total_step                               440000
replay_pool/size                         440000
trainer/alpha                                 0.061048
trainer/alpha_loss                            1.48166
trainer/entropy                              -6.5299
trainer/qf_loss                              49.0698
trainer/policy_loss                        -300.157
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         300.556
trainer/entropy_penalty                      -0.398637
trainer/entropy_percentage                   -0.00132633
trainer/Q1Pred Mean                         300.232
trainer/Q1Pred Std                           72.1116
trainer/Q1Pred Max                          392.602
trainer/Q1Pred Min                          -16.1941
trainer/Q2Pred Mean                         299.952
trainer/Q2Pred Std                           72.4348
trainer/Q2Pred Max                          390.369
trainer/Q2Pred Min                            7.86613
trainer/QTargetWithReg Mean                 299.554
trainer/QTargetWithReg Std                   73.6128
trainer/QTargetWithReg Max                  391.241
trainer/QTargetWithReg Min                   -7.70021
trainer/PolicyLossWithoutReg Mean           300.556
trainer/PolicyLossWithoutReg Std             70.5284
trainer/PolicyLossWithoutReg Max            389.827
trainer/PolicyLossWithoutReg Min             14.7638
exploration/num steps total              440000
exploration/num paths total                1200
exploration/path length this epoch Mean     478.5
exploration/path length this epoch Std      156.5
exploration/path length this epoch Max      635
exploration/path length this epoch Min      322
exploration/Rewards Mean                      3.80676
exploration/Rewards Std                       1.48683
exploration/Rewards Max                       7.57421
exploration/Rewards Min                      -0.696134
exploration/Returns Mean                   1821.53
exploration/Returns Std                     867.496
exploration/Returns Max                    2689.03
exploration/Returns Min                     954.038
exploration/Num Paths                         2
exploration/Average Returns                1821.53
evaluation_0/num steps total                  3.38284e+06
evaluation_0/num paths total               6914
evaluation_0/path length Mean               770.4
evaluation_0/path length Std                217.756
evaluation_0/path length Max               1000
evaluation_0/path length Min                439
evaluation_0/Rewards Mean                     4.6669
evaluation_0/Rewards Std                      1.22358
evaluation_0/Rewards Max                      8.74428
evaluation_0/Rewards Min                     -0.85271
evaluation_0/Returns Mean                  3595.38
evaluation_0/Returns Std                   1132.46
evaluation_0/Returns Max                   4892.65
evaluation_0/Returns Min                   1877.04
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3595.38
time/epoch (s)                                0
time/total (s)                             6582.2
Epoch                                       435
---------------------------------------  ----------------
2022-11-16 18:04:39.727513 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 436 finished
---------------------------------------  ----------------
epoch                                       436
total_step                               441000
replay_pool/size                         441000
trainer/alpha                                 0.0621121
trainer/alpha_loss                            0.396494
trainer/entropy                              -6.14269
trainer/qf_loss                              18.1786
trainer/policy_loss                        -302.993
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.375
trainer/entropy_penalty                      -0.381536
trainer/entropy_percentage                   -0.00125764
trainer/Q1Pred Mean                         301.77
trainer/Q1Pred Std                           76.7196
trainer/Q1Pred Max                          393.792
trainer/Q1Pred Min                          -10.5641
trainer/Q2Pred Mean                         302.206
trainer/Q2Pred Std                           77.0285
trainer/Q2Pred Max                          388.302
trainer/Q2Pred Min                          -10.4625
trainer/QTargetWithReg Mean                 302.189
trainer/QTargetWithReg Std                   76.5563
trainer/QTargetWithReg Max                  387.098
trainer/QTargetWithReg Min                   -0.599456
trainer/PolicyLossWithoutReg Mean           303.375
trainer/PolicyLossWithoutReg Std             74.1881
trainer/PolicyLossWithoutReg Max            388.346
trainer/PolicyLossWithoutReg Min              2.98566
exploration/num steps total              441000
exploration/num paths total                1201
exploration/path length this epoch Mean     365
exploration/path length this epoch Std        0
exploration/path length this epoch Max      365
exploration/path length this epoch Min      365
exploration/Rewards Mean                      3.7493
exploration/Rewards Std                       1.24398
exploration/Rewards Max                       6.74173
exploration/Rewards Min                      -0.77518
exploration/Returns Mean                   1368.5
exploration/Returns Std                       0
exploration/Returns Max                    1368.5
exploration/Returns Min                    1368.5
exploration/Num Paths                         1
exploration/Average Returns                1368.5
evaluation_0/num steps total                  3.39061e+06
evaluation_0/num paths total               6922
evaluation_0/path length Mean               971.75
evaluation_0/path length Std                 74.7425
evaluation_0/path length Max               1000
evaluation_0/path length Min                774
evaluation_0/Rewards Mean                     4.66164
evaluation_0/Rewards Std                      1.09056
evaluation_0/Rewards Max                     10.8031
evaluation_0/Rewards Min                     -0.824925
evaluation_0/Returns Mean                  4529.95
evaluation_0/Returns Std                    370.148
evaluation_0/Returns Max                   4805.19
evaluation_0/Returns Min                   3568.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4529.95
time/epoch (s)                                0
time/total (s)                             6596.76
Epoch                                       436
---------------------------------------  ----------------
2022-11-16 18:04:53.730978 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 437 finished
---------------------------------------  ---------------
epoch                                       437
total_step                               442000
replay_pool/size                         442000
trainer/alpha                                 0.0620169
trainer/alpha_loss                            0.223204
trainer/entropy                              -6.08028
trainer/qf_loss                              18.2067
trainer/policy_loss                        -301.338
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.715
trainer/entropy_penalty                      -0.37708
trainer/entropy_percentage                   -0.00124979
trainer/Q1Pred Mean                         300.164
trainer/Q1Pred Std                           64.1841
trainer/Q1Pred Max                          400.359
trainer/Q1Pred Min                          -10.2397
trainer/Q2Pred Mean                         300.156
trainer/Q2Pred Std                           63.9137
trainer/Q2Pred Max                          398.69
trainer/Q2Pred Min                           -3.95546
trainer/QTargetWithReg Mean                 300.756
trainer/QTargetWithReg Std                   64.2847
trainer/QTargetWithReg Max                  401.449
trainer/QTargetWithReg Min                   -6.87913
trainer/PolicyLossWithoutReg Mean           301.715
trainer/PolicyLossWithoutReg Std             63.0242
trainer/PolicyLossWithoutReg Max            400.976
trainer/PolicyLossWithoutReg Min             -4.67792
exploration/num steps total              442000
exploration/num paths total                1202
exploration/path length this epoch Mean     606
exploration/path length this epoch Std        0
exploration/path length this epoch Max      606
exploration/path length this epoch Min      606
exploration/Rewards Mean                      4.31433
exploration/Rewards Std                       1.09942
exploration/Rewards Max                       6.65795
exploration/Rewards Min                      -0.888648
exploration/Returns Mean                   2614.49
exploration/Returns Std                       0
exploration/Returns Max                    2614.49
exploration/Returns Min                    2614.49
exploration/Num Paths                         1
exploration/Average Returns                2614.49
evaluation_0/num steps total                  3.3984e+06
evaluation_0/num paths total               6936
evaluation_0/path length Mean               556.571
evaluation_0/path length Std                241.967
evaluation_0/path length Max               1000
evaluation_0/path length Min                313
evaluation_0/Rewards Mean                     4.12586
evaluation_0/Rewards Std                      1.45067
evaluation_0/Rewards Max                      9.04195
evaluation_0/Rewards Min                     -0.701854
evaluation_0/Returns Mean                  2296.33
evaluation_0/Returns Std                   1238.29
evaluation_0/Returns Max                   4612.82
evaluation_0/Returns Min                   1091.85
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2296.33
time/epoch (s)                                0
time/total (s)                             6610.77
Epoch                                       437
---------------------------------------  ---------------
2022-11-16 18:05:07.581399 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 438 finished
---------------------------------------  ----------------
epoch                                       438
total_step                               443000
replay_pool/size                         443000
trainer/alpha                                 0.0632321
trainer/alpha_loss                            0.141176
trainer/entropy                              -6.05113
trainer/qf_loss                              23.4999
trainer/policy_loss                        -307.026
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.408
trainer/entropy_penalty                      -0.382626
trainer/entropy_percentage                   -0.00124468
trainer/Q1Pred Mean                         305.789
trainer/Q1Pred Std                           61.724
trainer/Q1Pred Max                          397.689
trainer/Q1Pred Min                           27.3813
trainer/Q2Pred Mean                         305.707
trainer/Q2Pred Std                           62.1878
trainer/Q2Pred Max                          396.396
trainer/Q2Pred Min                           29.5077
trainer/QTargetWithReg Mean                 305.663
trainer/QTargetWithReg Std                   62.4967
trainer/QTargetWithReg Max                  393.838
trainer/QTargetWithReg Min                   31.5226
trainer/PolicyLossWithoutReg Mean           307.408
trainer/PolicyLossWithoutReg Std             60.2712
trainer/PolicyLossWithoutReg Max            396.245
trainer/PolicyLossWithoutReg Min             34.8512
exploration/num steps total              443000
exploration/num paths total                1203
exploration/path length this epoch Mean     743
exploration/path length this epoch Std        0
exploration/path length this epoch Max      743
exploration/path length this epoch Min      743
exploration/Rewards Mean                      4.24026
exploration/Rewards Std                       1.37557
exploration/Rewards Max                       8.25222
exploration/Rewards Min                      -0.645226
exploration/Returns Mean                   3150.51
exploration/Returns Std                       0
exploration/Returns Max                    3150.51
exploration/Returns Min                    3150.51
exploration/Num Paths                         1
exploration/Average Returns                3150.51
evaluation_0/num steps total                  3.40555e+06
evaluation_0/num paths total               6946
evaluation_0/path length Mean               714.9
evaluation_0/path length Std                210.387
evaluation_0/path length Max               1000
evaluation_0/path length Min                429
evaluation_0/Rewards Mean                     4.58595
evaluation_0/Rewards Std                      1.32506
evaluation_0/Rewards Max                      9.50113
evaluation_0/Rewards Min                     -0.747273
evaluation_0/Returns Mean                  3278.49
evaluation_0/Returns Std                   1158.07
evaluation_0/Returns Max                   4866.2
evaluation_0/Returns Min                   1654.09
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3278.49
time/epoch (s)                                0
time/total (s)                             6624.62
Epoch                                       438
---------------------------------------  ----------------
2022-11-16 18:05:22.977760 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 439 finished
---------------------------------------  ----------------
epoch                                       439
total_step                               444000
replay_pool/size                         444000
trainer/alpha                                 0.0620571
trainer/alpha_loss                            0.0948238
trainer/entropy                              -6.03411
trainer/qf_loss                              22.4164
trainer/policy_loss                        -302.364
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.738
trainer/entropy_penalty                      -0.374459
trainer/entropy_percentage                   -0.00123691
trainer/Q1Pred Mean                         301.55
trainer/Q1Pred Std                           66.4506
trainer/Q1Pred Max                          383.706
trainer/Q1Pred Min                            2.16117
trainer/Q2Pred Mean                         301.549
trainer/Q2Pred Std                           66.4492
trainer/Q2Pred Max                          381.723
trainer/Q2Pred Min                            8.53571
trainer/QTargetWithReg Mean                 302.409
trainer/QTargetWithReg Std                   66.3966
trainer/QTargetWithReg Max                  384.286
trainer/QTargetWithReg Min                    4.12678
trainer/PolicyLossWithoutReg Mean           302.738
trainer/PolicyLossWithoutReg Std             65.7848
trainer/PolicyLossWithoutReg Max            382.705
trainer/PolicyLossWithoutReg Min              5.22938
exploration/num steps total              444000
exploration/num paths total                1204
exploration/path length this epoch Mean     604
exploration/path length this epoch Std        0
exploration/path length this epoch Max      604
exploration/path length this epoch Min      604
exploration/Rewards Mean                      4.31918
exploration/Rewards Std                       1.23759
exploration/Rewards Max                      10.2307
exploration/Rewards Min                      -0.828584
exploration/Returns Mean                   2608.78
exploration/Returns Std                       0
exploration/Returns Max                    2608.78
exploration/Returns Min                    2608.78
exploration/Num Paths                         1
exploration/Average Returns                2608.78
evaluation_0/num steps total                  3.41285e+06
evaluation_0/num paths total               6958
evaluation_0/path length Mean               608.25
evaluation_0/path length Std                129.903
evaluation_0/path length Max               1000
evaluation_0/path length Min                499
evaluation_0/Rewards Mean                     4.40871
evaluation_0/Rewards Std                      1.34725
evaluation_0/Rewards Max                     10.6416
evaluation_0/Rewards Min                     -0.660871
evaluation_0/Returns Mean                  2681.6
evaluation_0/Returns Std                    663.31
evaluation_0/Returns Max                   4671.26
evaluation_0/Returns Min                   2085.42
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2681.6
time/epoch (s)                                0
time/total (s)                             6640.01
Epoch                                       439
---------------------------------------  ----------------
2022-11-16 18:05:35.739295 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 440 finished
---------------------------------------  ----------------
epoch                                       440
total_step                               445000
replay_pool/size                         445000
trainer/alpha                                 0.0644408
trainer/alpha_loss                           -1.07541
trainer/entropy                              -5.6078
trainer/qf_loss                              21.4218
trainer/policy_loss                        -305.312
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.674
trainer/entropy_penalty                      -0.361371
trainer/entropy_percentage                   -0.00118221
trainer/Q1Pred Mean                         305.381
trainer/Q1Pred Std                           68.3569
trainer/Q1Pred Max                          391.789
trainer/Q1Pred Min                          -30.3502
trainer/Q2Pred Mean                         305.178
trainer/Q2Pred Std                           68.0459
trainer/Q2Pred Max                          388.895
trainer/Q2Pred Min                           -9.20473
trainer/QTargetWithReg Mean                 305.118
trainer/QTargetWithReg Std                   67.8673
trainer/QTargetWithReg Max                  391.742
trainer/QTargetWithReg Min                  -29.1467
trainer/PolicyLossWithoutReg Mean           305.674
trainer/PolicyLossWithoutReg Std             67.7483
trainer/PolicyLossWithoutReg Max            387.267
trainer/PolicyLossWithoutReg Min            -38.412
exploration/num steps total              445000
exploration/num paths total                1205
exploration/path length this epoch Mean     518
exploration/path length this epoch Std        0
exploration/path length this epoch Max      518
exploration/path length this epoch Min      518
exploration/Rewards Mean                      4.19895
exploration/Rewards Std                       1.4081
exploration/Rewards Max                       8.95078
exploration/Rewards Min                      -0.62848
exploration/Returns Mean                   2175.06
exploration/Returns Std                       0
exploration/Returns Max                    2175.06
exploration/Returns Min                    2175.06
exploration/Num Paths                         1
exploration/Average Returns                2175.06
evaluation_0/num steps total                  3.42044e+06
evaluation_0/num paths total               6969
evaluation_0/path length Mean               690.182
evaluation_0/path length Std                242.423
evaluation_0/path length Max               1000
evaluation_0/path length Min                339
evaluation_0/Rewards Mean                     4.67248
evaluation_0/Rewards Std                      1.34116
evaluation_0/Rewards Max                     10.2784
evaluation_0/Rewards Min                     -0.778056
evaluation_0/Returns Mean                  3224.86
evaluation_0/Returns Std                   1314.29
evaluation_0/Returns Max                   4933.09
evaluation_0/Returns Min                   1369.31
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3224.86
time/epoch (s)                                0
time/total (s)                             6652.77
Epoch                                       440
---------------------------------------  ----------------
2022-11-16 18:05:48.351579 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 441 finished
---------------------------------------  ----------------
epoch                                       441
total_step                               446000
replay_pool/size                         446000
trainer/alpha                                 0.0631686
trainer/alpha_loss                            0.869435
trainer/entropy                              -6.31478
trainer/qf_loss                              22.5524
trainer/policy_loss                        -303.93
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.329
trainer/entropy_penalty                      -0.398896
trainer/entropy_percentage                   -0.00131074
trainer/Q1Pred Mean                         303.399
trainer/Q1Pred Std                           67.5168
trainer/Q1Pred Max                          399.542
trainer/Q1Pred Min                           15.6848
trainer/Q2Pred Mean                         303.925
trainer/Q2Pred Std                           66.7291
trainer/Q2Pred Max                          397.48
trainer/Q2Pred Min                           20.4105
trainer/QTargetWithReg Mean                 302.75
trainer/QTargetWithReg Std                   66.8053
trainer/QTargetWithReg Max                  396.486
trainer/QTargetWithReg Min                   18.9432
trainer/PolicyLossWithoutReg Mean           304.329
trainer/PolicyLossWithoutReg Std             66.3953
trainer/PolicyLossWithoutReg Max            398.781
trainer/PolicyLossWithoutReg Min             17.7992
exploration/num steps total              446000
exploration/num paths total                1206
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.35341
exploration/Rewards Std                       0.99487
exploration/Rewards Max                       6.76734
exploration/Rewards Min                      -0.655739
exploration/Returns Mean                   4353.41
exploration/Returns Std                       0
exploration/Returns Max                    4353.41
exploration/Returns Min                    4353.41
exploration/Num Paths                         1
exploration/Average Returns                4353.41
evaluation_0/num steps total                  3.42826e+06
evaluation_0/num paths total               6979
evaluation_0/path length Mean               781.4
evaluation_0/path length Std                193.62
evaluation_0/path length Max               1000
evaluation_0/path length Min                511
evaluation_0/Rewards Mean                     4.63576
evaluation_0/Rewards Std                      1.32193
evaluation_0/Rewards Max                      9.9034
evaluation_0/Rewards Min                     -0.530529
evaluation_0/Returns Mean                  3622.39
evaluation_0/Returns Std                   1074.79
evaluation_0/Returns Max                   4902.37
evaluation_0/Returns Min                   2097.98
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3622.39
time/epoch (s)                                0
time/total (s)                             6665.39
Epoch                                       441
---------------------------------------  ----------------
2022-11-16 18:06:03.005477 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 442 finished
---------------------------------------  ----------------
epoch                                       442
total_step                               447000
replay_pool/size                         447000
trainer/alpha                                 0.0614502
trainer/alpha_loss                            0.854043
trainer/entropy                              -6.30615
trainer/qf_loss                              23.8536
trainer/policy_loss                        -304.894
trainer/adversary_policy_loss                14.4239
trainer/policy_loss_without_entropy         305.282
trainer/entropy_penalty                      -0.387514
trainer/entropy_percentage                   -0.00126937
trainer/Q1Pred Mean                         303.941
trainer/Q1Pred Std                           70.2461
trainer/Q1Pred Max                          391.489
trainer/Q1Pred Min                          -23.9673
trainer/Q2Pred Mean                         303.459
trainer/Q2Pred Std                           70.6121
trainer/Q2Pred Max                          392.635
trainer/Q2Pred Min                          -17.7606
trainer/QTargetWithReg Mean                 303.679
trainer/QTargetWithReg Std                   70.3237
trainer/QTargetWithReg Max                  393.853
trainer/QTargetWithReg Min                   -5.8126
trainer/PolicyLossWithoutReg Mean           305.282
trainer/PolicyLossWithoutReg Std             64.0602
trainer/PolicyLossWithoutReg Max            389.578
trainer/PolicyLossWithoutReg Min             -3.59844
exploration/num steps total              447000
exploration/num paths total                1208
exploration/path length this epoch Mean     359
exploration/path length this epoch Std      349
exploration/path length this epoch Max      708
exploration/path length this epoch Min       10
exploration/Rewards Mean                      4.10971
exploration/Rewards Std                       1.30899
exploration/Rewards Max                       6.60929
exploration/Rewards Min                      -0.704752
exploration/Returns Mean                   1475.39
exploration/Returns Std                    1478.23
exploration/Returns Max                    2953.62
exploration/Returns Min                      -2.84672
exploration/Num Paths                         2
exploration/Average Returns                1475.39
evaluation_0/num steps total                  3.43549e+06
evaluation_0/num paths total               6990
evaluation_0/path length Mean               658
evaluation_0/path length Std                268.185
evaluation_0/path length Max               1000
evaluation_0/path length Min                332
evaluation_0/Rewards Mean                     4.33097
evaluation_0/Rewards Std                      1.32996
evaluation_0/Rewards Max                      8.41505
evaluation_0/Rewards Min                     -0.856851
evaluation_0/Returns Mean                  2849.78
evaluation_0/Returns Std                   1412.44
evaluation_0/Returns Max                   4697.1
evaluation_0/Returns Min                   1247.89
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2849.78
time/epoch (s)                                0
time/total (s)                             6680.04
Epoch                                       442
---------------------------------------  ----------------
2022-11-16 18:06:15.788419 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 443 finished
---------------------------------------  ----------------
epoch                                       443
total_step                               448000
replay_pool/size                         448000
trainer/alpha                                 0.0626487
trainer/alpha_loss                           -0.552263
trainer/entropy                              -5.80064
trainer/qf_loss                              16.6617
trainer/policy_loss                        -305.198
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.561
trainer/entropy_penalty                      -0.363403
trainer/entropy_percentage                   -0.0011893
trainer/Q1Pred Mean                         304.564
trainer/Q1Pred Std                           72.0497
trainer/Q1Pred Max                          384.719
trainer/Q1Pred Min                           -0.301555
trainer/Q2Pred Mean                         304.921
trainer/Q2Pred Std                           71.891
trainer/Q2Pred Max                          391.249
trainer/Q2Pred Min                            3.43501
trainer/QTargetWithReg Mean                 305.076
trainer/QTargetWithReg Std                   71.8973
trainer/QTargetWithReg Max                  388.756
trainer/QTargetWithReg Min                   -2.34435
trainer/PolicyLossWithoutReg Mean           305.561
trainer/PolicyLossWithoutReg Std             70.6976
trainer/PolicyLossWithoutReg Max            387.831
trainer/PolicyLossWithoutReg Min              8.58548
exploration/num steps total              448000
exploration/num paths total                1209
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.29145
exploration/Rewards Std                       1.27245
exploration/Rewards Max                       6.88113
exploration/Rewards Min                      -0.76201
exploration/Returns Mean                   4291.45
exploration/Returns Std                       0
exploration/Returns Max                    4291.45
exploration/Returns Min                    4291.45
exploration/Num Paths                         1
exploration/Average Returns                4291.45
evaluation_0/num steps total                  3.44316e+06
evaluation_0/num paths total               6999
evaluation_0/path length Mean               851.556
evaluation_0/path length Std                288.401
evaluation_0/path length Max               1000
evaluation_0/path length Min                167
evaluation_0/Rewards Mean                     4.29348
evaluation_0/Rewards Std                      1.29524
evaluation_0/Rewards Max                      6.85554
evaluation_0/Rewards Min                     -0.684193
evaluation_0/Returns Mean                  3656.14
evaluation_0/Returns Std                   1453.73
evaluation_0/Returns Max                   4552.75
evaluation_0/Returns Min                    279.913
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3656.14
time/epoch (s)                                0
time/total (s)                             6692.82
Epoch                                       443
---------------------------------------  ----------------
2022-11-16 18:06:28.248234 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 444 finished
---------------------------------------  ----------------
epoch                                       444
total_step                               449000
replay_pool/size                         449000
trainer/alpha                                 0.0629093
trainer/alpha_loss                            0.443916
trainer/entropy                              -6.16047
trainer/qf_loss                              26.8696
trainer/policy_loss                        -308.736
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.124
trainer/entropy_penalty                      -0.387551
trainer/entropy_percentage                   -0.00125371
trainer/Q1Pred Mean                         308.331
trainer/Q1Pred Std                           62.3937
trainer/Q1Pred Max                          395.576
trainer/Q1Pred Min                           14.6992
trainer/Q2Pred Mean                         307.403
trainer/Q2Pred Std                           62.4327
trainer/Q2Pred Max                          393.841
trainer/Q2Pred Min                           25.8369
trainer/QTargetWithReg Mean                 308.764
trainer/QTargetWithReg Std                   62.8012
trainer/QTargetWithReg Max                  396.011
trainer/QTargetWithReg Min                    6.56174
trainer/PolicyLossWithoutReg Mean           309.124
trainer/PolicyLossWithoutReg Std             62.0546
trainer/PolicyLossWithoutReg Max            394.389
trainer/PolicyLossWithoutReg Min             16.0191
exploration/num steps total              449000
exploration/num paths total                1210
exploration/path length this epoch Mean     579
exploration/path length this epoch Std        0
exploration/path length this epoch Max      579
exploration/path length this epoch Min      579
exploration/Rewards Mean                      4.12698
exploration/Rewards Std                       1.18199
exploration/Rewards Max                       6.4625
exploration/Rewards Min                      -0.786651
exploration/Returns Mean                   2389.52
exploration/Returns Std                       0
exploration/Returns Max                    2389.52
exploration/Returns Min                    2389.52
exploration/Num Paths                         1
exploration/Average Returns                2389.52
evaluation_0/num steps total                  3.45095e+06
evaluation_0/num paths total               7011
evaluation_0/path length Mean               649.417
evaluation_0/path length Std                195.745
evaluation_0/path length Max               1000
evaluation_0/path length Min                466
evaluation_0/Rewards Mean                     4.28238
evaluation_0/Rewards Std                      1.48147
evaluation_0/Rewards Max                     10.4657
evaluation_0/Rewards Min                     -0.573984
evaluation_0/Returns Mean                  2781.05
evaluation_0/Returns Std                   1074.09
evaluation_0/Returns Max                   4941.7
evaluation_0/Returns Min                   1772.58
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2781.05
time/epoch (s)                                0
time/total (s)                             6705.28
Epoch                                       444
---------------------------------------  ----------------
2022-11-16 18:06:42.115313 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 445 finished
---------------------------------------  ----------------
epoch                                       445
total_step                               450000
replay_pool/size                         450000
trainer/alpha                                 0.0646362
trainer/alpha_loss                           -1.25126
trainer/entropy                              -5.54315
trainer/qf_loss                              25.3041
trainer/policy_loss                        -303.39
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.748
trainer/entropy_penalty                      -0.358288
trainer/entropy_percentage                   -0.00117956
trainer/Q1Pred Mean                         302.778
trainer/Q1Pred Std                           74.0209
trainer/Q1Pred Max                          392.912
trainer/Q1Pred Min                            2.97229
trainer/Q2Pred Mean                         301.992
trainer/Q2Pred Std                           74.3485
trainer/Q2Pred Max                          390.187
trainer/Q2Pred Min                            4.45531
trainer/QTargetWithReg Mean                 301.897
trainer/QTargetWithReg Std                   73.1994
trainer/QTargetWithReg Max                  392.3
trainer/QTargetWithReg Min                    6.28788
trainer/PolicyLossWithoutReg Mean           303.748
trainer/PolicyLossWithoutReg Std             72.9475
trainer/PolicyLossWithoutReg Max            392.374
trainer/PolicyLossWithoutReg Min              1.96201
exploration/num steps total              450000
exploration/num paths total                1211
exploration/path length this epoch Mean     771
exploration/path length this epoch Std        0
exploration/path length this epoch Max      771
exploration/path length this epoch Min      771
exploration/Rewards Mean                      4.07332
exploration/Rewards Std                       1.35161
exploration/Rewards Max                       6.6087
exploration/Rewards Min                      -0.514708
exploration/Returns Mean                   3140.53
exploration/Returns Std                       0
exploration/Returns Max                    3140.53
exploration/Returns Min                    3140.53
exploration/Num Paths                         1
exploration/Average Returns                3140.53
evaluation_0/num steps total                  3.45891e+06
evaluation_0/num paths total               7019
evaluation_0/path length Mean               994.875
evaluation_0/path length Std                 11.1517
evaluation_0/path length Max               1000
evaluation_0/path length Min                966
evaluation_0/Rewards Mean                     4.47325
evaluation_0/Rewards Std                      1.18719
evaluation_0/Rewards Max                      7.20264
evaluation_0/Rewards Min                     -0.650394
evaluation_0/Returns Mean                  4450.33
evaluation_0/Returns Std                     99.3364
evaluation_0/Returns Max                   4632.23
evaluation_0/Returns Min                   4290.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4450.33
time/epoch (s)                                0
time/total (s)                             6719.15
Epoch                                       445
---------------------------------------  ----------------
2022-11-16 18:06:54.416193 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 446 finished
---------------------------------------  ----------------
epoch                                       446
total_step                               451000
replay_pool/size                         451000
trainer/alpha                                 0.0632914
trainer/alpha_loss                           -0.041466
trainer/entropy                              -5.98498
trainer/qf_loss                              22.9917
trainer/policy_loss                        -306.722
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.101
trainer/entropy_penalty                      -0.378798
trainer/entropy_percentage                   -0.00123346
trainer/Q1Pred Mean                         307.096
trainer/Q1Pred Std                           67.0818
trainer/Q1Pred Max                          393.424
trainer/Q1Pred Min                            9.45211
trainer/Q2Pred Mean                         306.465
trainer/Q2Pred Std                           66.6832
trainer/Q2Pred Max                          389.57
trainer/Q2Pred Min                            8.95473
trainer/QTargetWithReg Mean                 305.428
trainer/QTargetWithReg Std                   67.0477
trainer/QTargetWithReg Max                  392.73
trainer/QTargetWithReg Min                    5.82556
trainer/PolicyLossWithoutReg Mean           307.101
trainer/PolicyLossWithoutReg Std             66.0977
trainer/PolicyLossWithoutReg Max            392.241
trainer/PolicyLossWithoutReg Min              8.25407
exploration/num steps total              451000
exploration/num paths total                1212
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5395
exploration/Rewards Std                       1.06532
exploration/Rewards Max                       6.96485
exploration/Rewards Min                      -0.581514
exploration/Returns Mean                   4539.5
exploration/Returns Std                       0
exploration/Returns Max                    4539.5
exploration/Returns Min                    4539.5
exploration/Num Paths                         1
exploration/Average Returns                4539.5
evaluation_0/num steps total                  3.46667e+06
evaluation_0/num paths total               7028
evaluation_0/path length Mean               862.222
evaluation_0/path length Std                171.307
evaluation_0/path length Max               1000
evaluation_0/path length Min                476
evaluation_0/Rewards Mean                     4.75013
evaluation_0/Rewards Std                      1.27013
evaluation_0/Rewards Max                      9.55758
evaluation_0/Rewards Min                     -0.683227
evaluation_0/Returns Mean                  4095.67
evaluation_0/Returns Std                    946.755
evaluation_0/Returns Max                   5096.07
evaluation_0/Returns Min                   2097.48
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4095.67
time/epoch (s)                                0
time/total (s)                             6731.45
Epoch                                       446
---------------------------------------  ----------------
2022-11-16 18:07:06.811214 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 447 finished
---------------------------------------  ----------------
epoch                                       447
total_step                               452000
replay_pool/size                         452000
trainer/alpha                                 0.0612163
trainer/alpha_loss                           -0.0952909
trainer/entropy                              -5.96589
trainer/qf_loss                              19.0798
trainer/policy_loss                        -307.496
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.861
trainer/entropy_penalty                      -0.365209
trainer/entropy_percentage                   -0.00118628
trainer/Q1Pred Mean                         307.039
trainer/Q1Pred Std                           73.6135
trainer/Q1Pred Max                          394.764
trainer/Q1Pred Min                           -3.80024
trainer/Q2Pred Mean                         307.344
trainer/Q2Pred Std                           73.8512
trainer/Q2Pred Max                          388.266
trainer/Q2Pred Min                           -2.86335
trainer/QTargetWithReg Mean                 306.142
trainer/QTargetWithReg Std                   74.4238
trainer/QTargetWithReg Max                  392.202
trainer/QTargetWithReg Min                    2.73209
trainer/PolicyLossWithoutReg Mean           307.861
trainer/PolicyLossWithoutReg Std             72.0285
trainer/PolicyLossWithoutReg Max            386.946
trainer/PolicyLossWithoutReg Min             -6.14221
exploration/num steps total              452000
exploration/num paths total                1213
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2621
exploration/Rewards Std                       1.03737
exploration/Rewards Max                       6.96259
exploration/Rewards Min                      -0.868721
exploration/Returns Mean                   4262.1
exploration/Returns Std                       0
exploration/Returns Max                    4262.1
exploration/Returns Min                    4262.1
exploration/Num Paths                         1
exploration/Average Returns                4262.1
evaluation_0/num steps total                  3.47447e+06
evaluation_0/num paths total               7038
evaluation_0/path length Mean               780.2
evaluation_0/path length Std                220.951
evaluation_0/path length Max               1000
evaluation_0/path length Min                349
evaluation_0/Rewards Mean                     4.42876
evaluation_0/Rewards Std                      1.41158
evaluation_0/Rewards Max                     10.1898
evaluation_0/Rewards Min                     -0.616804
evaluation_0/Returns Mean                  3455.32
evaluation_0/Returns Std                   1172.79
evaluation_0/Returns Max                   4660.08
evaluation_0/Returns Min                   1211.82
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3455.32
time/epoch (s)                                0
time/total (s)                             6743.84
Epoch                                       447
---------------------------------------  ----------------
2022-11-16 18:07:36.816478 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 448 finished
---------------------------------------  ----------------
epoch                                       448
total_step                               453000
replay_pool/size                         453000
trainer/alpha                                 0.0629012
trainer/alpha_loss                            0.489774
trainer/entropy                              -6.17706
trainer/qf_loss                              24.2042
trainer/policy_loss                        -309.36
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.748
trainer/entropy_penalty                      -0.388545
trainer/entropy_percentage                   -0.00125439
trainer/Q1Pred Mean                         308.206
trainer/Q1Pred Std                           65.8332
trainer/Q1Pred Max                          397.23
trainer/Q1Pred Min                            0.206617
trainer/Q2Pred Mean                         308.339
trainer/Q2Pred Std                           66.2659
trainer/Q2Pred Max                          391.368
trainer/Q2Pred Min                          -28.5263
trainer/QTargetWithReg Mean                 308.906
trainer/QTargetWithReg Std                   65.5547
trainer/QTargetWithReg Max                  392.592
trainer/QTargetWithReg Min                    0.30175
trainer/PolicyLossWithoutReg Mean           309.748
trainer/PolicyLossWithoutReg Std             63.2708
trainer/PolicyLossWithoutReg Max            392.213
trainer/PolicyLossWithoutReg Min              6.95923
exploration/num steps total              453000
exploration/num paths total                1214
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61823
exploration/Rewards Std                       1.081
exploration/Rewards Max                       7.35422
exploration/Rewards Min                      -0.687051
exploration/Returns Mean                   4618.23
exploration/Returns Std                       0
exploration/Returns Max                    4618.23
exploration/Returns Min                    4618.23
exploration/Num Paths                         1
exploration/Average Returns                4618.23
evaluation_0/num steps total                  3.48184e+06
evaluation_0/num paths total               7046
evaluation_0/path length Mean               921.25
evaluation_0/path length Std                208.353
evaluation_0/path length Max               1000
evaluation_0/path length Min                370
evaluation_0/Rewards Mean                     4.54379
evaluation_0/Rewards Std                      1.02293
evaluation_0/Rewards Max                      7.23957
evaluation_0/Rewards Min                     -0.609849
evaluation_0/Returns Mean                  4185.97
evaluation_0/Returns Std                   1034.59
evaluation_0/Returns Max                   4654.81
evaluation_0/Returns Min                   1454.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4185.97
time/epoch (s)                                0
time/total (s)                             6773.85
Epoch                                       448
---------------------------------------  ----------------
2022-11-16 18:09:09.147464 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 449 finished
---------------------------------------  ----------------
epoch                                       449
total_step                               454000
replay_pool/size                         454000
trainer/alpha                                 0.0622914
trainer/alpha_loss                            0.382264
trainer/entropy                              -6.1377
trainer/qf_loss                              19.617
trainer/policy_loss                        -308.542
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.924
trainer/entropy_penalty                      -0.382326
trainer/entropy_percentage                   -0.0012376
trainer/Q1Pred Mean                         307.995
trainer/Q1Pred Std                           68.7883
trainer/Q1Pred Max                          390.098
trainer/Q1Pred Min                            3.72843
trainer/Q2Pred Mean                         307.963
trainer/Q2Pred Std                           69.0165
trainer/Q2Pred Max                          387.354
trainer/Q2Pred Min                           -0.772312
trainer/QTargetWithReg Mean                 307.975
trainer/QTargetWithReg Std                   68.649
trainer/QTargetWithReg Max                  388.265
trainer/QTargetWithReg Min                   11.0808
trainer/PolicyLossWithoutReg Mean           308.925
trainer/PolicyLossWithoutReg Std             68.4927
trainer/PolicyLossWithoutReg Max            387.209
trainer/PolicyLossWithoutReg Min              5.21145
exploration/num steps total              454000
exploration/num paths total                1215
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.03825
exploration/Rewards Std                       0.993929
exploration/Rewards Max                       6.23134
exploration/Rewards Min                      -0.708102
exploration/Returns Mean                   4038.25
exploration/Returns Std                       0
exploration/Returns Max                    4038.25
exploration/Returns Min                    4038.25
exploration/Num Paths                         1
exploration/Average Returns                4038.25
evaluation_0/num steps total                  3.48944e+06
evaluation_0/num paths total               7055
evaluation_0/path length Mean               843.667
evaluation_0/path length Std                215.53
evaluation_0/path length Max               1000
evaluation_0/path length Min                321
evaluation_0/Rewards Mean                     4.59384
evaluation_0/Rewards Std                      1.29242
evaluation_0/Rewards Max                      9.70601
evaluation_0/Rewards Min                     -0.747278
evaluation_0/Returns Mean                  3875.67
evaluation_0/Returns Std                   1125.68
evaluation_0/Returns Max                   4782.45
evaluation_0/Returns Min                   1187.51
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3875.67
time/epoch (s)                                0
time/total (s)                             6866.19
Epoch                                       449
---------------------------------------  ----------------
2022-11-16 18:10:39.035106 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 450 finished
---------------------------------------  ----------------
epoch                                       450
total_step                               455000
replay_pool/size                         455000
trainer/alpha                                 0.0630347
trainer/alpha_loss                            0.787843
trainer/entropy                              -6.28503
trainer/qf_loss                              24.0798
trainer/policy_loss                        -308.049
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.445
trainer/entropy_penalty                      -0.396175
trainer/entropy_percentage                   -0.00128443
trainer/Q1Pred Mean                         307.109
trainer/Q1Pred Std                           62.2598
trainer/Q1Pred Max                          395.347
trainer/Q1Pred Min                           17.3039
trainer/Q2Pred Mean                         307.595
trainer/Q2Pred Std                           61.7755
trainer/Q2Pred Max                          393.613
trainer/Q2Pred Min                           16.1122
trainer/QTargetWithReg Mean                 307.444
trainer/QTargetWithReg Std                   62.3572
trainer/QTargetWithReg Max                  395.646
trainer/QTargetWithReg Min                   17.6332
trainer/PolicyLossWithoutReg Mean           308.445
trainer/PolicyLossWithoutReg Std             60.907
trainer/PolicyLossWithoutReg Max            394.422
trainer/PolicyLossWithoutReg Min             16.4841
exploration/num steps total              455000
exploration/num paths total                1216
exploration/path length this epoch Mean     480
exploration/path length this epoch Std        0
exploration/path length this epoch Max      480
exploration/path length this epoch Min      480
exploration/Rewards Mean                      3.86366
exploration/Rewards Std                       1.27356
exploration/Rewards Max                       7.47367
exploration/Rewards Min                      -0.619088
exploration/Returns Mean                   1854.56
exploration/Returns Std                       0
exploration/Returns Max                    1854.56
exploration/Returns Min                    1854.56
exploration/Num Paths                         1
exploration/Average Returns                1854.56
evaluation_0/num steps total                  3.49692e+06
evaluation_0/num paths total               7063
evaluation_0/path length Mean               935
evaluation_0/path length Std                119.989
evaluation_0/path length Max               1000
evaluation_0/path length Min                657
evaluation_0/Rewards Mean                     4.5238
evaluation_0/Rewards Std                      1.24478
evaluation_0/Rewards Max                      6.96733
evaluation_0/Rewards Min                     -0.594859
evaluation_0/Returns Mean                  4229.75
evaluation_0/Returns Std                    634.053
evaluation_0/Returns Max                   4679.88
evaluation_0/Returns Min                   2752.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4229.75
time/epoch (s)                                0
time/total (s)                             6956.07
Epoch                                       450
---------------------------------------  ----------------
2022-11-16 18:11:49.623678 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 451 finished
---------------------------------------  ----------------
epoch                                       451
total_step                               456000
replay_pool/size                         456000
trainer/alpha                                 0.0625386
trainer/alpha_loss                           -0.277486
trainer/entropy                              -5.89989
trainer/qf_loss                              25.68
trainer/policy_loss                        -304.122
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.491
trainer/entropy_penalty                      -0.368971
trainer/entropy_percentage                   -0.00121176
trainer/Q1Pred Mean                         304.216
trainer/Q1Pred Std                           75.5948
trainer/Q1Pred Max                          388.911
trainer/Q1Pred Min                          -11.2104
trainer/Q2Pred Mean                         304.112
trainer/Q2Pred Std                           75.4934
trainer/Q2Pred Max                          387.977
trainer/Q2Pred Min                          -16.7204
trainer/QTargetWithReg Mean                 304.647
trainer/QTargetWithReg Std                   75.1057
trainer/QTargetWithReg Max                  389.374
trainer/QTargetWithReg Min                  -10.9328
trainer/PolicyLossWithoutReg Mean           304.491
trainer/PolicyLossWithoutReg Std             74.9139
trainer/PolicyLossWithoutReg Max            388.858
trainer/PolicyLossWithoutReg Min             -9.55721
exploration/num steps total              456000
exploration/num paths total                1217
exploration/path length this epoch Mean     634
exploration/path length this epoch Std        0
exploration/path length this epoch Max      634
exploration/path length this epoch Min      634
exploration/Rewards Mean                      3.38487
exploration/Rewards Std                       1.47267
exploration/Rewards Max                       6.91475
exploration/Rewards Min                      -0.648196
exploration/Returns Mean                   2146.01
exploration/Returns Std                       0
exploration/Returns Max                    2146.01
exploration/Returns Min                    2146.01
exploration/Num Paths                         1
exploration/Average Returns                2146.01
evaluation_0/num steps total                  3.50492e+06
evaluation_0/num paths total               7071
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.54231
evaluation_0/Rewards Std                      1.05201
evaluation_0/Rewards Max                      7.39236
evaluation_0/Rewards Min                     -0.484546
evaluation_0/Returns Mean                  4542.31
evaluation_0/Returns Std                     95.3199
evaluation_0/Returns Max                   4685.03
evaluation_0/Returns Min                   4369.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4542.31
time/epoch (s)                                0
time/total (s)                             7026.66
Epoch                                       451
---------------------------------------  ----------------
2022-11-16 18:13:05.709038 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 452 finished
---------------------------------------  ----------------
epoch                                       452
total_step                               457000
replay_pool/size                         457000
trainer/alpha                                 0.0624137
trainer/alpha_loss                           -0.590047
trainer/entropy                              -5.78728
trainer/qf_loss                              27.6877
trainer/policy_loss                        -301.907
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.269
trainer/entropy_penalty                      -0.361206
trainer/entropy_percentage                   -0.00119498
trainer/Q1Pred Mean                         300.655
trainer/Q1Pred Std                           69.3232
trainer/Q1Pred Max                          388.058
trainer/Q1Pred Min                           -8.14879
trainer/Q2Pred Mean                         300.527
trainer/Q2Pred Std                           69.1347
trainer/Q2Pred Max                          387.142
trainer/Q2Pred Min                           25.6606
trainer/QTargetWithReg Mean                 300.28
trainer/QTargetWithReg Std                   68.9535
trainer/QTargetWithReg Max                  388.408
trainer/QTargetWithReg Min                   -0.737634
trainer/PolicyLossWithoutReg Mean           302.269
trainer/PolicyLossWithoutReg Std             65.7254
trainer/PolicyLossWithoutReg Max            386.968
trainer/PolicyLossWithoutReg Min             27.5355
exploration/num steps total              457000
exploration/num paths total                1218
exploration/path length this epoch Mean     336
exploration/path length this epoch Std        0
exploration/path length this epoch Max      336
exploration/path length this epoch Min      336
exploration/Rewards Mean                      3.62311
exploration/Rewards Std                       1.16087
exploration/Rewards Max                       5.48295
exploration/Rewards Min                      -0.644097
exploration/Returns Mean                   1217.36
exploration/Returns Std                       0
exploration/Returns Max                    1217.36
exploration/Returns Min                    1217.36
exploration/Num Paths                         1
exploration/Average Returns                1217.36
evaluation_0/num steps total                  3.51264e+06
evaluation_0/num paths total               7079
evaluation_0/path length Mean               965.25
evaluation_0/path length Std                 91.9399
evaluation_0/path length Max               1000
evaluation_0/path length Min                722
evaluation_0/Rewards Mean                     4.55923
evaluation_0/Rewards Std                      1.29389
evaluation_0/Rewards Max                      7.45953
evaluation_0/Rewards Min                     -0.522542
evaluation_0/Returns Mean                  4400.79
evaluation_0/Returns Std                    485.151
evaluation_0/Returns Max                   4830.38
evaluation_0/Returns Min                   3164.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4400.79
time/epoch (s)                                0
time/total (s)                             7102.74
Epoch                                       452
---------------------------------------  ----------------
2022-11-16 18:13:20.127384 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 453 finished
---------------------------------------  ----------------
epoch                                       453
total_step                               458000
replay_pool/size                         458000
trainer/alpha                                 0.0647653
trainer/alpha_loss                           -0.525823
trainer/entropy                              -5.80788
trainer/qf_loss                              27.0693
trainer/policy_loss                        -314.719
trainer/adversary_policy_loss                14.9598
trainer/policy_loss_without_entropy         315.095
trainer/entropy_penalty                      -0.376149
trainer/entropy_percentage                   -0.00119376
trainer/Q1Pred Mean                         313.172
trainer/Q1Pred Std                           56.3248
trainer/Q1Pred Max                          385.204
trainer/Q1Pred Min                           22.1578
trainer/Q2Pred Mean                         313.723
trainer/Q2Pred Std                           55.3395
trainer/Q2Pred Max                          385.616
trainer/Q2Pred Min                           40.9585
trainer/QTargetWithReg Mean                 314.43
trainer/QTargetWithReg Std                   55.5316
trainer/QTargetWithReg Max                  386.44
trainer/QTargetWithReg Min                   25.0362
trainer/PolicyLossWithoutReg Mean           315.095
trainer/PolicyLossWithoutReg Std             54.4528
trainer/PolicyLossWithoutReg Max            388.783
trainer/PolicyLossWithoutReg Min             36.9269
exploration/num steps total              458000
exploration/num paths total                1219
exploration/path length this epoch Mean     959
exploration/path length this epoch Std        0
exploration/path length this epoch Max      959
exploration/path length this epoch Min      959
exploration/Rewards Mean                      4.32586
exploration/Rewards Std                       1.08124
exploration/Rewards Max                       6.87537
exploration/Rewards Min                      -0.565641
exploration/Returns Mean                   4148.5
exploration/Returns Std                       0
exploration/Returns Max                    4148.5
exploration/Returns Min                    4148.5
exploration/Num Paths                         1
exploration/Average Returns                4148.5
evaluation_0/num steps total                  3.52041e+06
evaluation_0/num paths total               7092
evaluation_0/path length Mean               598
evaluation_0/path length Std                170.672
evaluation_0/path length Max               1000
evaluation_0/path length Min                352
evaluation_0/Rewards Mean                     4.45883
evaluation_0/Rewards Std                      1.50611
evaluation_0/Rewards Max                     11.0216
evaluation_0/Rewards Min                     -0.734352
evaluation_0/Returns Mean                  2666.38
evaluation_0/Returns Std                    857.158
evaluation_0/Returns Max                   4487.44
evaluation_0/Returns Min                   1398.69
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2666.38
time/epoch (s)                                0
time/total (s)                             7117.15
Epoch                                       453
---------------------------------------  ----------------
2022-11-16 18:13:50.787674 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 454 finished
---------------------------------------  ----------------
epoch                                       454
total_step                               459000
replay_pool/size                         459000
trainer/alpha                                 0.0646671
trainer/alpha_loss                            0.361643
trainer/entropy                              -6.13205
trainer/qf_loss                              28.0592
trainer/policy_loss                        -307.724
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.12
trainer/entropy_penalty                      -0.396542
trainer/entropy_percentage                   -0.00128697
trainer/Q1Pred Mean                         306.342
trainer/Q1Pred Std                           71.1835
trainer/Q1Pred Max                          390.28
trainer/Q1Pred Min                           17.5274
trainer/Q2Pred Mean                         306.621
trainer/Q2Pred Std                           71.2053
trainer/Q2Pred Max                          392.576
trainer/Q2Pred Min                           16.1666
trainer/QTargetWithReg Mean                 305.682
trainer/QTargetWithReg Std                   70.8639
trainer/QTargetWithReg Max                  390.117
trainer/QTargetWithReg Min                   13.3195
trainer/PolicyLossWithoutReg Mean           308.12
trainer/PolicyLossWithoutReg Std             67.6324
trainer/PolicyLossWithoutReg Max            389.711
trainer/PolicyLossWithoutReg Min             18.5999
exploration/num steps total              459000
exploration/num paths total                1220
exploration/path length this epoch Mean     458
exploration/path length this epoch Std        0
exploration/path length this epoch Max      458
exploration/path length this epoch Min      458
exploration/Rewards Mean                      3.47239
exploration/Rewards Std                       1.48244
exploration/Rewards Max                      10.0148
exploration/Rewards Min                      -0.840023
exploration/Returns Mean                   1590.35
exploration/Returns Std                       0
exploration/Returns Max                    1590.35
exploration/Returns Min                    1590.35
exploration/Num Paths                         1
exploration/Average Returns                1590.35
evaluation_0/num steps total                  3.52819e+06
evaluation_0/num paths total               7102
evaluation_0/path length Mean               778
evaluation_0/path length Std                170.792
evaluation_0/path length Max               1000
evaluation_0/path length Min                548
evaluation_0/Rewards Mean                     4.75052
evaluation_0/Rewards Std                      1.33203
evaluation_0/Rewards Max                      8.32511
evaluation_0/Rewards Min                     -0.553886
evaluation_0/Returns Mean                  3695.91
evaluation_0/Returns Std                    908.491
evaluation_0/Returns Max                   4930.41
evaluation_0/Returns Min                   2419.74
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3695.91
time/epoch (s)                                0
time/total (s)                             7147.82
Epoch                                       454
---------------------------------------  ----------------
2022-11-16 18:15:06.550031 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 455 finished
---------------------------------------  ----------------
epoch                                       455
total_step                               460000
replay_pool/size                         460000
trainer/alpha                                 0.0625993
trainer/alpha_loss                           -0.244524
trainer/entropy                              -5.91175
trainer/qf_loss                              27.7624
trainer/policy_loss                        -307.113
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.483
trainer/entropy_penalty                      -0.370072
trainer/entropy_percentage                   -0.00120355
trainer/Q1Pred Mean                         307.241
trainer/Q1Pred Std                           69.8999
trainer/Q1Pred Max                          392.202
trainer/Q1Pred Min                            8.87783
trainer/Q2Pred Mean                         306.871
trainer/Q2Pred Std                           70.0514
trainer/Q2Pred Max                          391.431
trainer/Q2Pred Min                           10.4897
trainer/QTargetWithReg Mean                 306.369
trainer/QTargetWithReg Std                   70.1702
trainer/QTargetWithReg Max                  387.481
trainer/QTargetWithReg Min                    5.5207
trainer/PolicyLossWithoutReg Mean           307.483
trainer/PolicyLossWithoutReg Std             69.0521
trainer/PolicyLossWithoutReg Max            389.333
trainer/PolicyLossWithoutReg Min              9.55585
exploration/num steps total              460000
exploration/num paths total                1221
exploration/path length this epoch Mean     479
exploration/path length this epoch Std        0
exploration/path length this epoch Max      479
exploration/path length this epoch Min      479
exploration/Rewards Mean                      3.66884
exploration/Rewards Std                       1.15598
exploration/Rewards Max                       6.21446
exploration/Rewards Min                      -0.751529
exploration/Returns Mean                   1757.37
exploration/Returns Std                       0
exploration/Returns Max                    1757.37
exploration/Returns Min                    1757.37
exploration/Num Paths                         1
exploration/Average Returns                1757.37
evaluation_0/num steps total                  3.53552e+06
evaluation_0/num paths total               7112
evaluation_0/path length Mean               733.2
evaluation_0/path length Std                186.847
evaluation_0/path length Max               1000
evaluation_0/path length Min                540
evaluation_0/Rewards Mean                     4.41447
evaluation_0/Rewards Std                      1.48109
evaluation_0/Rewards Max                      9.51758
evaluation_0/Rewards Min                     -0.495221
evaluation_0/Returns Mean                  3236.69
evaluation_0/Returns Std                   1019.86
evaluation_0/Returns Max                   4791
evaluation_0/Returns Min                   2198.73
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3236.69
time/epoch (s)                                0
time/total (s)                             7223.58
Epoch                                       455
---------------------------------------  ----------------
2022-11-16 18:16:24.122651 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 456 finished
---------------------------------------  ----------------
epoch                                       456
total_step                               461000
replay_pool/size                         461000
trainer/alpha                                 0.0630587
trainer/alpha_loss                           -0.896081
trainer/entropy                              -5.67578
trainer/qf_loss                              18.9104
trainer/policy_loss                        -313.982
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.34
trainer/entropy_penalty                      -0.357907
trainer/entropy_percentage                   -0.0011386
trainer/Q1Pred Mean                         313.301
trainer/Q1Pred Std                           60.0747
trainer/Q1Pred Max                          393.836
trainer/Q1Pred Min                           15.4783
trainer/Q2Pred Mean                         313.508
trainer/Q2Pred Std                           60.6349
trainer/Q2Pred Max                          396.285
trainer/Q2Pred Min                            9.64216
trainer/QTargetWithReg Mean                 313.932
trainer/QTargetWithReg Std                   60.0882
trainer/QTargetWithReg Max                  395.245
trainer/QTargetWithReg Min                   10.0057
trainer/PolicyLossWithoutReg Mean           314.34
trainer/PolicyLossWithoutReg Std             59.4175
trainer/PolicyLossWithoutReg Max            394.442
trainer/PolicyLossWithoutReg Min             14.0886
exploration/num steps total              461000
exploration/num paths total                1222
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44313
exploration/Rewards Std                       1.32842
exploration/Rewards Max                       7.25579
exploration/Rewards Min                      -0.451263
exploration/Returns Mean                   4443.13
exploration/Returns Std                       0
exploration/Returns Max                    4443.13
exploration/Returns Min                    4443.13
exploration/Num Paths                         1
exploration/Average Returns                4443.13
evaluation_0/num steps total                  3.54321e+06
evaluation_0/num paths total               7121
evaluation_0/path length Mean               854.444
evaluation_0/path length Std                168.844
evaluation_0/path length Max               1000
evaluation_0/path length Min                605
evaluation_0/Rewards Mean                     4.49839
evaluation_0/Rewards Std                      1.35358
evaluation_0/Rewards Max                     10.1259
evaluation_0/Rewards Min                     -0.639719
evaluation_0/Returns Mean                  3843.63
evaluation_0/Returns Std                    875.977
evaluation_0/Returns Max                   4704.17
evaluation_0/Returns Min                   2498.08
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3843.63
time/epoch (s)                                0
time/total (s)                             7301.15
Epoch                                       456
---------------------------------------  ----------------
2022-11-16 18:17:24.177306 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 457 finished
---------------------------------------  ----------------
epoch                                       457
total_step                               462000
replay_pool/size                         462000
trainer/alpha                                 0.06288
trainer/alpha_loss                           -0.0726429
trainer/entropy                              -5.97374
trainer/qf_loss                              14.6003
trainer/policy_loss                        -313.707
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.083
trainer/entropy_penalty                      -0.375629
trainer/entropy_percentage                   -0.00119596
trainer/Q1Pred Mean                         313.357
trainer/Q1Pred Std                           63.7353
trainer/Q1Pred Max                          394.278
trainer/Q1Pred Min                           13.2512
trainer/Q2Pred Mean                         313.255
trainer/Q2Pred Std                           63.6526
trainer/Q2Pred Max                          394.198
trainer/Q2Pred Min                           12.8527
trainer/QTargetWithReg Mean                 312.996
trainer/QTargetWithReg Std                   63.9946
trainer/QTargetWithReg Max                  400.39
trainer/QTargetWithReg Min                    8.88948
trainer/PolicyLossWithoutReg Mean           314.083
trainer/PolicyLossWithoutReg Std             62.9289
trainer/PolicyLossWithoutReg Max            395.25
trainer/PolicyLossWithoutReg Min              9.33396
exploration/num steps total              462000
exploration/num paths total                1223
exploration/path length this epoch Mean     616
exploration/path length this epoch Std        0
exploration/path length this epoch Max      616
exploration/path length this epoch Min      616
exploration/Rewards Mean                      4.07336
exploration/Rewards Std                       1.12906
exploration/Rewards Max                       6.39906
exploration/Rewards Min                      -0.727703
exploration/Returns Mean                   2509.19
exploration/Returns Std                       0
exploration/Returns Max                    2509.19
exploration/Returns Min                    2509.19
exploration/Num Paths                         1
exploration/Average Returns                2509.19
evaluation_0/num steps total                  3.55121e+06
evaluation_0/num paths total               7129
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53657
evaluation_0/Rewards Std                      1.33079
evaluation_0/Rewards Max                      7.30627
evaluation_0/Rewards Min                     -0.801793
evaluation_0/Returns Mean                  4536.57
evaluation_0/Returns Std                    147.285
evaluation_0/Returns Max                   4761.25
evaluation_0/Returns Min                   4345.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4536.57
time/epoch (s)                                0
time/total (s)                             7361.21
Epoch                                       457
---------------------------------------  ----------------
2022-11-16 18:18:40.419060 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 458 finished
---------------------------------------  ----------------
epoch                                       458
total_step                               463000
replay_pool/size                         463000
trainer/alpha                                 0.064233
trainer/alpha_loss                            0.179
trainer/entropy                              -6.0652
trainer/qf_loss                              20.3646
trainer/policy_loss                        -301.745
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.135
trainer/entropy_penalty                      -0.389586
trainer/entropy_percentage                   -0.00128944
trainer/Q1Pred Mean                         300.964
trainer/Q1Pred Std                           68.0675
trainer/Q1Pred Max                          400.28
trainer/Q1Pred Min                           19.1629
trainer/Q2Pred Mean                         301.12
trainer/Q2Pred Std                           67.831
trainer/Q2Pred Max                          393.431
trainer/Q2Pred Min                           15.8607
trainer/QTargetWithReg Mean                 300.754
trainer/QTargetWithReg Std                   68.4721
trainer/QTargetWithReg Max                  395.134
trainer/QTargetWithReg Min                   14.0798
trainer/PolicyLossWithoutReg Mean           302.135
trainer/PolicyLossWithoutReg Std             67.2971
trainer/PolicyLossWithoutReg Max            396.58
trainer/PolicyLossWithoutReg Min             14.2477
exploration/num steps total              463000
exploration/num paths total                1224
exploration/path length this epoch Mean     486
exploration/path length this epoch Std        0
exploration/path length this epoch Max      486
exploration/path length this epoch Min      486
exploration/Rewards Mean                      4.33492
exploration/Rewards Std                       1.27748
exploration/Rewards Max                       7.22818
exploration/Rewards Min                      -0.882699
exploration/Returns Mean                   2106.77
exploration/Returns Std                       0
exploration/Returns Max                    2106.77
exploration/Returns Min                    2106.77
exploration/Num Paths                         1
exploration/Average Returns                2106.77
evaluation_0/num steps total                  3.55916e+06
evaluation_0/num paths total               7138
evaluation_0/path length Mean               882.667
evaluation_0/path length Std                137.407
evaluation_0/path length Max               1000
evaluation_0/path length Min                633
evaluation_0/Rewards Mean                     4.56711
evaluation_0/Rewards Std                      1.57353
evaluation_0/Rewards Max                      9.88331
evaluation_0/Rewards Min                     -0.61679
evaluation_0/Returns Mean                  4031.23
evaluation_0/Returns Std                    722.303
evaluation_0/Returns Max                   4816.05
evaluation_0/Returns Min                   2779.15
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4031.23
time/epoch (s)                                0
time/total (s)                             7437.45
Epoch                                       458
---------------------------------------  ----------------
2022-11-16 18:19:28.795242 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 459 finished
---------------------------------------  ----------------
epoch                                       459
total_step                               464000
replay_pool/size                         464000
trainer/alpha                                 0.0645521
trainer/alpha_loss                           -0.234215
trainer/entropy                              -5.91453
trainer/qf_loss                              16.1482
trainer/policy_loss                        -311.642
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.023
trainer/entropy_penalty                      -0.381795
trainer/entropy_percentage                   -0.00122361
trainer/Q1Pred Mean                         311.649
trainer/Q1Pred Std                           73.2205
trainer/Q1Pred Max                          400.912
trainer/Q1Pred Min                            6.36695
trainer/Q2Pred Mean                         310.853
trainer/Q2Pred Std                           73.3981
trainer/Q2Pred Max                          401.217
trainer/Q2Pred Min                           -3.40757
trainer/QTargetWithReg Mean                 310.661
trainer/QTargetWithReg Std                   72.9805
trainer/QTargetWithReg Max                  399.666
trainer/QTargetWithReg Min                    5.86626
trainer/PolicyLossWithoutReg Mean           312.023
trainer/PolicyLossWithoutReg Std             71.744
trainer/PolicyLossWithoutReg Max            401.228
trainer/PolicyLossWithoutReg Min              3.35291
exploration/num steps total              464000
exploration/num paths total                1225
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74828
exploration/Rewards Std                       1.37241
exploration/Rewards Max                       7.13461
exploration/Rewards Min                      -0.383594
exploration/Returns Mean                   4748.28
exploration/Returns Std                       0
exploration/Returns Max                    4748.28
exploration/Returns Min                    4748.28
exploration/Num Paths                         1
exploration/Average Returns                4748.28
evaluation_0/num steps total                  3.56637e+06
evaluation_0/num paths total               7146
evaluation_0/path length Mean               901.25
evaluation_0/path length Std                110.053
evaluation_0/path length Max               1000
evaluation_0/path length Min                684
evaluation_0/Rewards Mean                     4.5975
evaluation_0/Rewards Std                      1.35962
evaluation_0/Rewards Max                     10.19
evaluation_0/Rewards Min                     -0.68749
evaluation_0/Returns Mean                  4143.5
evaluation_0/Returns Std                    659.833
evaluation_0/Returns Max                   4911.15
evaluation_0/Returns Min                   2918.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4143.5
time/epoch (s)                                0
time/total (s)                             7485.82
Epoch                                       459
---------------------------------------  ----------------
2022-11-16 18:19:40.822616 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 460 finished
---------------------------------------  ----------------
epoch                                       460
total_step                               465000
replay_pool/size                         465000
trainer/alpha                                 0.0638666
trainer/alpha_loss                           -0.440909
trainer/entropy                              -5.83972
trainer/qf_loss                              27.8285
trainer/policy_loss                        -307.477
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.85
trainer/entropy_penalty                      -0.372963
trainer/entropy_percentage                   -0.00121151
trainer/Q1Pred Mean                         306.741
trainer/Q1Pred Std                           62.8237
trainer/Q1Pred Max                          405.034
trainer/Q1Pred Min                            8.75501
trainer/Q2Pred Mean                         307.425
trainer/Q2Pred Std                           62.4257
trainer/Q2Pred Max                          403.899
trainer/Q2Pred Min                            8.42375
trainer/QTargetWithReg Mean                 307.53
trainer/QTargetWithReg Std                   63.4691
trainer/QTargetWithReg Max                  402.703
trainer/QTargetWithReg Min                    0.739419
trainer/PolicyLossWithoutReg Mean           307.85
trainer/PolicyLossWithoutReg Std             61.6057
trainer/PolicyLossWithoutReg Max            403.574
trainer/PolicyLossWithoutReg Min             14.0175
exploration/num steps total              465000
exploration/num paths total                1226
exploration/path length this epoch Mean     239
exploration/path length this epoch Std        0
exploration/path length this epoch Max      239
exploration/path length this epoch Min      239
exploration/Rewards Mean                      3.43275
exploration/Rewards Std                       1.09282
exploration/Rewards Max                       4.84886
exploration/Rewards Min                      -0.706878
exploration/Returns Mean                    820.427
exploration/Returns Std                       0
exploration/Returns Max                     820.427
exploration/Returns Min                     820.427
exploration/Num Paths                         1
exploration/Average Returns                 820.427
evaluation_0/num steps total                  3.57437e+06
evaluation_0/num paths total               7154
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71522
evaluation_0/Rewards Std                      1.35431
evaluation_0/Rewards Max                      7.70668
evaluation_0/Rewards Min                     -0.528
evaluation_0/Returns Mean                  4715.22
evaluation_0/Returns Std                    135.193
evaluation_0/Returns Max                   4843.32
evaluation_0/Returns Min                   4452.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4715.22
time/epoch (s)                                0
time/total (s)                             7497.84
Epoch                                       460
---------------------------------------  ----------------
2022-11-16 18:19:53.649113 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 461 finished
---------------------------------------  ----------------
epoch                                       461
total_step                               466000
replay_pool/size                         466000
trainer/alpha                                 0.0641503
trainer/alpha_loss                            0.408536
trainer/entropy                              -6.14875
trainer/qf_loss                              23.9778
trainer/policy_loss                        -313.177
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.572
trainer/entropy_penalty                      -0.394444
trainer/entropy_percentage                   -0.00125791
trainer/Q1Pred Mean                         312.719
trainer/Q1Pred Std                           61.0121
trainer/Q1Pred Max                          397.875
trainer/Q1Pred Min                           21.9884
trainer/Q2Pred Mean                         313.246
trainer/Q2Pred Std                           60.8973
trainer/Q2Pred Max                          394.649
trainer/Q2Pred Min                           37.0354
trainer/QTargetWithReg Mean                 313.202
trainer/QTargetWithReg Std                   60.2901
trainer/QTargetWithReg Max                  396.769
trainer/QTargetWithReg Min                   17.2735
trainer/PolicyLossWithoutReg Mean           313.572
trainer/PolicyLossWithoutReg Std             59.8532
trainer/PolicyLossWithoutReg Max            396.131
trainer/PolicyLossWithoutReg Min             21.0983
exploration/num steps total              466000
exploration/num paths total                1227
exploration/path length this epoch Mean     121
exploration/path length this epoch Std        0
exploration/path length this epoch Max      121
exploration/path length this epoch Min      121
exploration/Rewards Mean                      1.92917
exploration/Rewards Std                       1.18567
exploration/Rewards Max                       4.65165
exploration/Rewards Min                      -0.432854
exploration/Returns Mean                    233.43
exploration/Returns Std                       0
exploration/Returns Max                     233.43
exploration/Returns Min                     233.43
exploration/Num Paths                         1
exploration/Average Returns                 233.43
evaluation_0/num steps total                  3.58237e+06
evaluation_0/num paths total               7162
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69244
evaluation_0/Rewards Std                      1.27004
evaluation_0/Rewards Max                      7.09777
evaluation_0/Rewards Min                     -0.563087
evaluation_0/Returns Mean                  4692.44
evaluation_0/Returns Std                     95.5334
evaluation_0/Returns Max                   4908.98
evaluation_0/Returns Min                   4576.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4692.44
time/epoch (s)                                0
time/total (s)                             7510.67
Epoch                                       461
---------------------------------------  ----------------
2022-11-16 18:20:08.963966 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 462 finished
---------------------------------------  ----------------
epoch                                       462
total_step                               467000
replay_pool/size                         467000
trainer/alpha                                 0.0642775
trainer/alpha_loss                            0.287529
trainer/entropy                              -6.10476
trainer/qf_loss                              27.8472
trainer/policy_loss                        -310.105
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.497
trainer/entropy_penalty                      -0.392399
trainer/entropy_percentage                   -0.00126378
trainer/Q1Pred Mean                         308.469
trainer/Q1Pred Std                           61.5981
trainer/Q1Pred Max                          389.532
trainer/Q1Pred Min                           17.9741
trainer/Q2Pred Mean                         308.462
trainer/Q2Pred Std                           62.2204
trainer/Q2Pred Max                          391.544
trainer/Q2Pred Min                           27.9531
trainer/QTargetWithReg Mean                 309.912
trainer/QTargetWithReg Std                   61.8631
trainer/QTargetWithReg Max                  390.484
trainer/QTargetWithReg Min                   28.0004
trainer/PolicyLossWithoutReg Mean           310.497
trainer/PolicyLossWithoutReg Std             60.0288
trainer/PolicyLossWithoutReg Max            389.945
trainer/PolicyLossWithoutReg Min             44.5702
exploration/num steps total              467000
exploration/num paths total                1228
exploration/path length this epoch Mean     704
exploration/path length this epoch Std        0
exploration/path length this epoch Max      704
exploration/path length this epoch Min      704
exploration/Rewards Mean                      4.19243
exploration/Rewards Std                       1.07774
exploration/Rewards Max                       6.88422
exploration/Rewards Min                      -0.501935
exploration/Returns Mean                   2951.47
exploration/Returns Std                       0
exploration/Returns Max                    2951.47
exploration/Returns Min                    2951.47
exploration/Num Paths                         1
exploration/Average Returns                2951.47
evaluation_0/num steps total                  3.58954e+06
evaluation_0/num paths total               7171
evaluation_0/path length Mean               796.889
evaluation_0/path length Std                287.463
evaluation_0/path length Max               1000
evaluation_0/path length Min                374
evaluation_0/Rewards Mean                     4.52224
evaluation_0/Rewards Std                      1.33841
evaluation_0/Rewards Max                      7.97758
evaluation_0/Rewards Min                     -0.646983
evaluation_0/Returns Mean                  3603.73
evaluation_0/Returns Std                   1580.64
evaluation_0/Returns Max                   4873.13
evaluation_0/Returns Min                   1282.72
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3603.73
time/epoch (s)                                0
time/total (s)                             7525.98
Epoch                                       462
---------------------------------------  ----------------
2022-11-16 18:20:21.385868 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 463 finished
---------------------------------------  ----------------
epoch                                       463
total_step                               468000
replay_pool/size                         468000
trainer/alpha                                 0.0641583
trainer/alpha_loss                            2.20612
trainer/entropy                              -6.80316
trainer/qf_loss                              38.1169
trainer/policy_loss                        -303.174
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.61
trainer/entropy_penalty                      -0.43648
trainer/entropy_percentage                   -0.00143763
trainer/Q1Pred Mean                         302.537
trainer/Q1Pred Std                           69.4987
trainer/Q1Pred Max                          390.371
trainer/Q1Pred Min                            5.41391
trainer/Q2Pred Mean                         301.899
trainer/Q2Pred Std                           70.2799
trainer/Q2Pred Max                          388.099
trainer/Q2Pred Min                           -0.632367
trainer/QTargetWithReg Mean                 302.315
trainer/QTargetWithReg Std                   70.6152
trainer/QTargetWithReg Max                  389.519
trainer/QTargetWithReg Min                    5.80856
trainer/PolicyLossWithoutReg Mean           303.61
trainer/PolicyLossWithoutReg Std             68.458
trainer/PolicyLossWithoutReg Max            387.228
trainer/PolicyLossWithoutReg Min              1.07251
exploration/num steps total              468000
exploration/num paths total                1230
exploration/path length this epoch Mean     291.5
exploration/path length this epoch Std       33.5
exploration/path length this epoch Max      325
exploration/path length this epoch Min      258
exploration/Rewards Mean                      3.57363
exploration/Rewards Std                       1.43576
exploration/Rewards Max                       6.40065
exploration/Rewards Min                      -0.696667
exploration/Returns Mean                   1041.71
exploration/Returns Std                      85.4646
exploration/Returns Max                    1127.18
exploration/Returns Min                     956.25
exploration/Num Paths                         2
exploration/Average Returns                1041.71
evaluation_0/num steps total                  3.59701e+06
evaluation_0/num paths total               7179
evaluation_0/path length Mean               934.125
evaluation_0/path length Std                118.569
evaluation_0/path length Max               1000
evaluation_0/path length Min                672
evaluation_0/Rewards Mean                     4.6998
evaluation_0/Rewards Std                      1.30778
evaluation_0/Rewards Max                      9.16171
evaluation_0/Rewards Min                     -0.525327
evaluation_0/Returns Mean                  4390.2
evaluation_0/Returns Std                    623.56
evaluation_0/Returns Max                   4924.43
evaluation_0/Returns Min                   2995.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4390.2
time/epoch (s)                                0
time/total (s)                             7538.4
Epoch                                       463
---------------------------------------  ----------------
2022-11-16 18:20:33.775938 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 464 finished
---------------------------------------  ----------------
epoch                                       464
total_step                               469000
replay_pool/size                         469000
trainer/alpha                                 0.0639369
trainer/alpha_loss                           -0.307804
trainer/entropy                              -5.88806
trainer/qf_loss                              17.6121
trainer/policy_loss                        -309.831
trainer/adversary_policy_loss                14.7941
trainer/policy_loss_without_entropy         310.208
trainer/entropy_penalty                      -0.376464
trainer/entropy_percentage                   -0.00121359
trainer/Q1Pred Mean                         309.071
trainer/Q1Pred Std                           62.3458
trainer/Q1Pred Max                          387.027
trainer/Q1Pred Min                           11.2026
trainer/Q2Pred Mean                         309.623
trainer/Q2Pred Std                           61.7139
trainer/Q2Pred Max                          387.873
trainer/Q2Pred Min                           10.0754
trainer/QTargetWithReg Mean                 309.906
trainer/QTargetWithReg Std                   62.2923
trainer/QTargetWithReg Max                  387.383
trainer/QTargetWithReg Min                   12.1502
trainer/PolicyLossWithoutReg Mean           310.208
trainer/PolicyLossWithoutReg Std             61.3095
trainer/PolicyLossWithoutReg Max            390.796
trainer/PolicyLossWithoutReg Min             10.3751
exploration/num steps total              469000
exploration/num paths total                1231
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75622
exploration/Rewards Std                       1.02573
exploration/Rewards Max                       6.3249
exploration/Rewards Min                      -0.558707
exploration/Returns Mean                   4756.22
exploration/Returns Std                       0
exploration/Returns Max                    4756.22
exploration/Returns Min                    4756.22
exploration/Num Paths                         1
exploration/Average Returns                4756.22
evaluation_0/num steps total                  3.60417e+06
evaluation_0/num paths total               7187
evaluation_0/path length Mean               894.625
evaluation_0/path length Std                136.844
evaluation_0/path length Max               1000
evaluation_0/path length Min                652
evaluation_0/Rewards Mean                     4.76285
evaluation_0/Rewards Std                      1.33975
evaluation_0/Rewards Max                     11.4161
evaluation_0/Rewards Min                     -0.629619
evaluation_0/Returns Mean                  4260.96
evaluation_0/Returns Std                    706.752
evaluation_0/Returns Max                   4983.41
evaluation_0/Returns Min                   2999.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4260.96
time/epoch (s)                                0
time/total (s)                             7550.79
Epoch                                       464
---------------------------------------  ----------------
2022-11-16 18:20:49.254012 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 465 finished
---------------------------------------  ----------------
epoch                                       465
total_step                               470000
replay_pool/size                         470000
trainer/alpha                                 0.0634207
trainer/alpha_loss                            1.72075
trainer/entropy                              -6.62391
trainer/qf_loss                              16.1762
trainer/policy_loss                        -302.254
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.674
trainer/entropy_penalty                      -0.420093
trainer/entropy_percentage                   -0.00138794
trainer/Q1Pred Mean                         302.538
trainer/Q1Pred Std                           74.7199
trainer/Q1Pred Max                          396.88
trainer/Q1Pred Min                           -0.346441
trainer/Q2Pred Mean                         302.519
trainer/Q2Pred Std                           75.5641
trainer/Q2Pred Max                          401.7
trainer/Q2Pred Min                           -4.11966
trainer/QTargetWithReg Mean                 301.99
trainer/QTargetWithReg Std                   75.2388
trainer/QTargetWithReg Max                  394.145
trainer/QTargetWithReg Min                    3.84566
trainer/PolicyLossWithoutReg Mean           302.674
trainer/PolicyLossWithoutReg Std             73.6042
trainer/PolicyLossWithoutReg Max            395.99
trainer/PolicyLossWithoutReg Min              4.49019
exploration/num steps total              470000
exploration/num paths total                1232
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8784
exploration/Rewards Std                       1.22962
exploration/Rewards Max                       6.83037
exploration/Rewards Min                      -0.577151
exploration/Returns Mean                   4878.4
exploration/Returns Std                       0
exploration/Returns Max                    4878.4
exploration/Returns Min                    4878.4
exploration/Num Paths                         1
exploration/Average Returns                4878.4
evaluation_0/num steps total                  3.61195e+06
evaluation_0/num paths total               7196
evaluation_0/path length Mean               864.778
evaluation_0/path length Std                119.2
evaluation_0/path length Max               1000
evaluation_0/path length Min                683
evaluation_0/Rewards Mean                     4.67745
evaluation_0/Rewards Std                      1.26799
evaluation_0/Rewards Max                      9.50432
evaluation_0/Rewards Min                     -0.544072
evaluation_0/Returns Mean                  4044.96
evaluation_0/Returns Std                    613.09
evaluation_0/Returns Max                   4881.19
evaluation_0/Returns Min                   3197.44
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4044.96
time/epoch (s)                                0
time/total (s)                             7566.27
Epoch                                       465
---------------------------------------  ----------------
2022-11-16 18:21:00.470874 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 466 finished
---------------------------------------  ----------------
epoch                                       466
total_step                               471000
replay_pool/size                         471000
trainer/alpha                                 0.0628433
trainer/alpha_loss                           -1.07295
trainer/entropy                              -5.61222
trainer/qf_loss                              24.0694
trainer/policy_loss                        -309.709
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.062
trainer/entropy_penalty                      -0.352691
trainer/entropy_percentage                   -0.00113749
trainer/Q1Pred Mean                         309.383
trainer/Q1Pred Std                           62.9068
trainer/Q1Pred Max                          394.171
trainer/Q1Pred Min                            8.86995
trainer/Q2Pred Mean                         308.973
trainer/Q2Pred Std                           62.3974
trainer/Q2Pred Max                          391.574
trainer/Q2Pred Min                           17.7943
trainer/QTargetWithReg Mean                 308.145
trainer/QTargetWithReg Std                   63.6014
trainer/QTargetWithReg Max                  390.997
trainer/QTargetWithReg Min                   14.3993
trainer/PolicyLossWithoutReg Mean           310.062
trainer/PolicyLossWithoutReg Std             61.5413
trainer/PolicyLossWithoutReg Max            391.574
trainer/PolicyLossWithoutReg Min             15.0925
exploration/num steps total              471000
exploration/num paths total                1233
exploration/path length this epoch Mean     808
exploration/path length this epoch Std        0
exploration/path length this epoch Max      808
exploration/path length this epoch Min      808
exploration/Rewards Mean                      4.61845
exploration/Rewards Std                       1.28404
exploration/Rewards Max                       6.84819
exploration/Rewards Min                      -0.773853
exploration/Returns Mean                   3731.71
exploration/Returns Std                       0
exploration/Returns Max                    3731.71
exploration/Returns Min                    3731.71
exploration/Num Paths                         1
exploration/Average Returns                3731.71
evaluation_0/num steps total                  3.61995e+06
evaluation_0/num paths total               7204
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83617
evaluation_0/Rewards Std                      1.20326
evaluation_0/Rewards Max                      8.13998
evaluation_0/Rewards Min                     -0.526018
evaluation_0/Returns Mean                  4836.17
evaluation_0/Returns Std                     76.3998
evaluation_0/Returns Max                   4911.65
evaluation_0/Returns Min                   4714.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.17
time/epoch (s)                                0
time/total (s)                             7577.49
Epoch                                       466
---------------------------------------  ----------------
2022-11-16 18:21:12.680215 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 467 finished
---------------------------------------  ----------------
epoch                                       467
total_step                               472000
replay_pool/size                         472000
trainer/alpha                                 0.0623747
trainer/alpha_loss                           -0.0963401
trainer/entropy                              -5.96528
trainer/qf_loss                              28.3709
trainer/policy_loss                        -303.742
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.114
trainer/entropy_penalty                      -0.372083
trainer/entropy_percentage                   -0.0012235
trainer/Q1Pred Mean                         303.933
trainer/Q1Pred Std                           58.6444
trainer/Q1Pred Max                          393.77
trainer/Q1Pred Min                           18.1756
trainer/Q2Pred Mean                         302.835
trainer/Q2Pred Std                           59.0958
trainer/Q2Pred Max                          395.711
trainer/Q2Pred Min                           17.3222
trainer/QTargetWithReg Mean                 303.731
trainer/QTargetWithReg Std                   59.7465
trainer/QTargetWithReg Max                  394.166
trainer/QTargetWithReg Min                   20.3972
trainer/PolicyLossWithoutReg Mean           304.114
trainer/PolicyLossWithoutReg Std             57.1861
trainer/PolicyLossWithoutReg Max            393.865
trainer/PolicyLossWithoutReg Min             18.3003
exploration/num steps total              472000
exploration/num paths total                1234
exploration/path length this epoch Mean     703
exploration/path length this epoch Std        0
exploration/path length this epoch Max      703
exploration/path length this epoch Min      703
exploration/Rewards Mean                      4.31663
exploration/Rewards Std                       1.38675
exploration/Rewards Max                       6.46304
exploration/Rewards Min                      -0.594583
exploration/Returns Mean                   3034.59
exploration/Returns Std                       0
exploration/Returns Max                    3034.59
exploration/Returns Min                    3034.59
exploration/Num Paths                         1
exploration/Average Returns                3034.59
evaluation_0/num steps total                  3.62791e+06
evaluation_0/num paths total               7213
evaluation_0/path length Mean               884
evaluation_0/path length Std                213.342
evaluation_0/path length Max               1000
evaluation_0/path length Min                380
evaluation_0/Rewards Mean                     4.65115
evaluation_0/Rewards Std                      1.35328
evaluation_0/Rewards Max                     10.0294
evaluation_0/Rewards Min                     -0.756051
evaluation_0/Returns Mean                  4111.62
evaluation_0/Returns Std                   1121.79
evaluation_0/Returns Max                   4840.2
evaluation_0/Returns Min                   1495.06
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4111.62
time/epoch (s)                                0
time/total (s)                             7589.7
Epoch                                       467
---------------------------------------  ----------------
2022-11-16 18:21:27.641336 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 468 finished
---------------------------------------  ----------------
epoch                                       468
total_step                               473000
replay_pool/size                         473000
trainer/alpha                                 0.0624538
trainer/alpha_loss                            1.20709
trainer/entropy                              -6.43521
trainer/qf_loss                              31.0426
trainer/policy_loss                        -304.361
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.763
trainer/entropy_penalty                      -0.401903
trainer/entropy_percentage                   -0.00131874
trainer/Q1Pred Mean                         303.504
trainer/Q1Pred Std                           65.9699
trainer/Q1Pred Max                          388.888
trainer/Q1Pred Min                            1.86181
trainer/Q2Pred Mean                         303.388
trainer/Q2Pred Std                           65.7388
trainer/Q2Pred Max                          390.346
trainer/Q2Pred Min                            0.788038
trainer/QTargetWithReg Mean                 303.067
trainer/QTargetWithReg Std                   65.8409
trainer/QTargetWithReg Max                  390.237
trainer/QTargetWithReg Min                    5.77565
trainer/PolicyLossWithoutReg Mean           304.762
trainer/PolicyLossWithoutReg Std             64.3587
trainer/PolicyLossWithoutReg Max            389.776
trainer/PolicyLossWithoutReg Min              5.50349
exploration/num steps total              473000
exploration/num paths total                1235
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58121
exploration/Rewards Std                       1.03552
exploration/Rewards Max                       6.78825
exploration/Rewards Min                      -0.844821
exploration/Returns Mean                   4581.21
exploration/Returns Std                       0
exploration/Returns Max                    4581.21
exploration/Returns Min                    4581.21
exploration/Num Paths                         1
exploration/Average Returns                4581.21
evaluation_0/num steps total                  3.63534e+06
evaluation_0/num paths total               7221
evaluation_0/path length Mean               929.25
evaluation_0/path length Std                 96.4621
evaluation_0/path length Max               1000
evaluation_0/path length Min                748
evaluation_0/Rewards Mean                     4.81402
evaluation_0/Rewards Std                      1.17787
evaluation_0/Rewards Max                      9.38832
evaluation_0/Rewards Min                     -0.640743
evaluation_0/Returns Mean                  4473.43
evaluation_0/Returns Std                    494.596
evaluation_0/Returns Max                   4945.01
evaluation_0/Returns Min                   3528.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4473.43
time/epoch (s)                                0
time/total (s)                             7604.66
Epoch                                       468
---------------------------------------  ----------------
2022-11-16 18:21:39.882178 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 469 finished
---------------------------------------  ----------------
epoch                                       469
total_step                               474000
replay_pool/size                         474000
trainer/alpha                                 0.0648546
trainer/alpha_loss                            0.261988
trainer/entropy                              -6.09577
trainer/qf_loss                              32.2873
trainer/policy_loss                        -303.205
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         303.6
trainer/entropy_penalty                      -0.395339
trainer/entropy_percentage                   -0.00130217
trainer/Q1Pred Mean                         302.442
trainer/Q1Pred Std                           69.0535
trainer/Q1Pred Max                          392.937
trainer/Q1Pred Min                           -9.13733
trainer/Q2Pred Mean                         302.368
trainer/Q2Pred Std                           69.5737
trainer/Q2Pred Max                          391.408
trainer/Q2Pred Min                          -11.7324
trainer/QTargetWithReg Mean                 302.769
trainer/QTargetWithReg Std                   70.1357
trainer/QTargetWithReg Max                  391.888
trainer/QTargetWithReg Min                  -10.3425
trainer/PolicyLossWithoutReg Mean           303.6
trainer/PolicyLossWithoutReg Std             66.5572
trainer/PolicyLossWithoutReg Max            390.874
trainer/PolicyLossWithoutReg Min              1.2481
exploration/num steps total              474000
exploration/num paths total                1236
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4967
exploration/Rewards Std                       1.08975
exploration/Rewards Max                       6.76206
exploration/Rewards Min                      -0.570721
exploration/Returns Mean                   4496.7
exploration/Returns Std                       0
exploration/Returns Max                    4496.7
exploration/Returns Min                    4496.7
exploration/Num Paths                         1
exploration/Average Returns                4496.7
evaluation_0/num steps total                  3.64319e+06
evaluation_0/num paths total               7229
evaluation_0/path length Mean               981.5
evaluation_0/path length Std                 34.2162
evaluation_0/path length Max               1000
evaluation_0/path length Min                902
evaluation_0/Rewards Mean                     4.62648
evaluation_0/Rewards Std                      1.21642
evaluation_0/Rewards Max                      9.41367
evaluation_0/Rewards Min                     -0.417861
evaluation_0/Returns Mean                  4540.89
evaluation_0/Returns Std                    239.071
evaluation_0/Returns Max                   4792.1
evaluation_0/Returns Min                   3985.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4540.89
time/epoch (s)                                0
time/total (s)                             7616.9
Epoch                                       469
---------------------------------------  ----------------
2022-11-16 18:21:52.613307 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 470 finished
---------------------------------------  ---------------
epoch                                       470
total_step                               475000
replay_pool/size                         475000
trainer/alpha                                 0.0646717
trainer/alpha_loss                            0.0691968
trainer/entropy                              -6.02527
trainer/qf_loss                             169
trainer/policy_loss                        -305.816
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         306.206
trainer/entropy_penalty                      -0.389664
trainer/entropy_percentage                   -0.00127256
trainer/Q1Pred Mean                         305.525
trainer/Q1Pred Std                           66.9375
trainer/Q1Pred Max                          391.944
trainer/Q1Pred Min                          -24.1486
trainer/Q2Pred Mean                         305.911
trainer/Q2Pred Std                           67.1138
trainer/Q2Pred Max                          394.014
trainer/Q2Pred Min                          -13.3232
trainer/QTargetWithReg Mean                 305.004
trainer/QTargetWithReg Std                   69.6433
trainer/QTargetWithReg Max                  397.896
trainer/QTargetWithReg Min                   -0.573629
trainer/PolicyLossWithoutReg Mean           306.206
trainer/PolicyLossWithoutReg Std             63.7762
trainer/PolicyLossWithoutReg Max            391.632
trainer/PolicyLossWithoutReg Min             18.8128
exploration/num steps total              475000
exploration/num paths total                1237
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54632
exploration/Rewards Std                       1.44414
exploration/Rewards Max                       7.29545
exploration/Rewards Min                      -0.4507
exploration/Returns Mean                   4546.32
exploration/Returns Std                       0
exploration/Returns Max                    4546.32
exploration/Returns Min                    4546.32
exploration/Num Paths                         1
exploration/Average Returns                4546.32
evaluation_0/num steps total                  3.6506e+06
evaluation_0/num paths total               7237
evaluation_0/path length Mean               926
evaluation_0/path length Std                101.847
evaluation_0/path length Max               1000
evaluation_0/path length Min                730
evaluation_0/Rewards Mean                     4.66384
evaluation_0/Rewards Std                      1.24597
evaluation_0/Rewards Max                      9.53991
evaluation_0/Rewards Min                     -0.686202
evaluation_0/Returns Mean                  4318.72
evaluation_0/Returns Std                    582.24
evaluation_0/Returns Max                   4806.15
evaluation_0/Returns Min                   3221.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4318.72
time/epoch (s)                                0
time/total (s)                             7629.63
Epoch                                       470
---------------------------------------  ---------------
2022-11-16 18:22:05.793052 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 471 finished
---------------------------------------  ---------------
epoch                                       471
total_step                               476000
replay_pool/size                         476000
trainer/alpha                                 0.0636938
trainer/alpha_loss                            1.33431
trainer/entropy                              -6.48452
trainer/qf_loss                              17.1351
trainer/policy_loss                        -312.674
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.087
trainer/entropy_penalty                      -0.413023
trainer/entropy_percentage                   -0.0013192
trainer/Q1Pred Mean                         312.141
trainer/Q1Pred Std                           66.3756
trainer/Q1Pred Max                          402.605
trainer/Q1Pred Min                           -1.47578
trainer/Q2Pred Mean                         312.08
trainer/Q2Pred Std                           67.7006
trainer/Q2Pred Max                          395.871
trainer/Q2Pred Min                          -14.5206
trainer/QTargetWithReg Mean                 312.156
trainer/QTargetWithReg Std                   67.3776
trainer/QTargetWithReg Max                  389.219
trainer/QTargetWithReg Min                  -20.716
trainer/PolicyLossWithoutReg Mean           313.087
trainer/PolicyLossWithoutReg Std             66.4662
trainer/PolicyLossWithoutReg Max            396.095
trainer/PolicyLossWithoutReg Min            -21.6257
exploration/num steps total              476000
exploration/num paths total                1238
exploration/path length this epoch Mean     613
exploration/path length this epoch Std        0
exploration/path length this epoch Max      613
exploration/path length this epoch Min      613
exploration/Rewards Mean                      4.13537
exploration/Rewards Std                       1.49311
exploration/Rewards Max                       8.53486
exploration/Rewards Min                      -0.904599
exploration/Returns Mean                   2534.98
exploration/Returns Std                       0
exploration/Returns Max                    2534.98
exploration/Returns Min                    2534.98
exploration/Num Paths                         1
exploration/Average Returns                2534.98
evaluation_0/num steps total                  3.6586e+06
evaluation_0/num paths total               7245
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63995
evaluation_0/Rewards Std                      1.14574
evaluation_0/Rewards Max                      7.78225
evaluation_0/Rewards Min                     -0.658886
evaluation_0/Returns Mean                  4639.95
evaluation_0/Returns Std                    114.445
evaluation_0/Returns Max                   4755.21
evaluation_0/Returns Min                   4426.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4639.95
time/epoch (s)                                0
time/total (s)                             7642.81
Epoch                                       471
---------------------------------------  ---------------
2022-11-16 18:22:19.880734 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 472 finished
---------------------------------------  ----------------
epoch                                       472
total_step                               477000
replay_pool/size                         477000
trainer/alpha                                 0.0621767
trainer/alpha_loss                           -0.227613
trainer/entropy                              -5.91806
trainer/qf_loss                              28.5976
trainer/policy_loss                        -304.596
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.964
trainer/entropy_penalty                      -0.367965
trainer/entropy_percentage                   -0.00120658
trainer/Q1Pred Mean                         303.505
trainer/Q1Pred Std                           66.7519
trainer/Q1Pred Max                          392.61
trainer/Q1Pred Min                            3.02876
trainer/Q2Pred Mean                         304.993
trainer/Q2Pred Std                           67.3522
trainer/Q2Pred Max                          392.695
trainer/Q2Pred Min                            5.93537
trainer/QTargetWithReg Mean                 304.191
trainer/QTargetWithReg Std                   66.7208
trainer/QTargetWithReg Max                  392.146
trainer/QTargetWithReg Min                    2.87773
trainer/PolicyLossWithoutReg Mean           304.964
trainer/PolicyLossWithoutReg Std             65.6631
trainer/PolicyLossWithoutReg Max            390.511
trainer/PolicyLossWithoutReg Min              8.23134
exploration/num steps total              477000
exploration/num paths total                1239
exploration/path length this epoch Mean     515
exploration/path length this epoch Std        0
exploration/path length this epoch Max      515
exploration/path length this epoch Min      515
exploration/Rewards Mean                      4.06868
exploration/Rewards Std                       1.31783
exploration/Rewards Max                       9.53574
exploration/Rewards Min                      -0.442066
exploration/Returns Mean                   2095.37
exploration/Returns Std                       0
exploration/Returns Max                    2095.37
exploration/Returns Min                    2095.37
exploration/Num Paths                         1
exploration/Average Returns                2095.37
evaluation_0/num steps total                  3.66598e+06
evaluation_0/num paths total               7253
evaluation_0/path length Mean               921.75
evaluation_0/path length Std                142.651
evaluation_0/path length Max               1000
evaluation_0/path length Min                598
evaluation_0/Rewards Mean                     4.68434
evaluation_0/Rewards Std                      1.16415
evaluation_0/Rewards Max                      8.88939
evaluation_0/Rewards Min                     -0.599132
evaluation_0/Returns Mean                  4317.79
evaluation_0/Returns Std                    714.079
evaluation_0/Returns Max                   4900.96
evaluation_0/Returns Min                   2736.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4317.79
time/epoch (s)                                0
time/total (s)                             7656.9
Epoch                                       472
---------------------------------------  ----------------
2022-11-16 18:22:33.331892 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 473 finished
---------------------------------------  ----------------
epoch                                       473
total_step                               478000
replay_pool/size                         478000
trainer/alpha                                 0.0645613
trainer/alpha_loss                            0.921673
trainer/entropy                              -6.33635
trainer/qf_loss                              61.4478
trainer/policy_loss                        -312.024
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.433
trainer/entropy_penalty                      -0.409083
trainer/entropy_percentage                   -0.00130934
trainer/Q1Pred Mean                         310.94
trainer/Q1Pred Std                           56.7846
trainer/Q1Pred Max                          383.833
trainer/Q1Pred Min                           64.9728
trainer/Q2Pred Mean                         312.099
trainer/Q2Pred Std                           56.7723
trainer/Q2Pred Max                          386.995
trainer/Q2Pred Min                           62.1613
trainer/QTargetWithReg Mean                 311.195
trainer/QTargetWithReg Std                   57.0668
trainer/QTargetWithReg Max                  385.093
trainer/QTargetWithReg Min                   66.4945
trainer/PolicyLossWithoutReg Mean           312.433
trainer/PolicyLossWithoutReg Std             55.385
trainer/PolicyLossWithoutReg Max            383.822
trainer/PolicyLossWithoutReg Min             64.906
exploration/num steps total              478000
exploration/num paths total                1240
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43376
exploration/Rewards Std                       1.01996
exploration/Rewards Max                       6.65604
exploration/Rewards Min                      -0.701065
exploration/Returns Mean                   4433.76
exploration/Returns Std                       0
exploration/Returns Max                    4433.76
exploration/Returns Min                    4433.76
exploration/Num Paths                         1
exploration/Average Returns                4433.76
evaluation_0/num steps total                  3.67394e+06
evaluation_0/num paths total               7261
evaluation_0/path length Mean               996.125
evaluation_0/path length Std                 10.2523
evaluation_0/path length Max               1000
evaluation_0/path length Min                969
evaluation_0/Rewards Mean                     4.62183
evaluation_0/Rewards Std                      1.09258
evaluation_0/Rewards Max                      8.91868
evaluation_0/Rewards Min                     -0.487163
evaluation_0/Returns Mean                  4603.92
evaluation_0/Returns Std                    188.926
evaluation_0/Returns Max                   4905.97
evaluation_0/Returns Min                   4349.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4603.92
time/epoch (s)                                0
time/total (s)                             7670.35
Epoch                                       473
---------------------------------------  ----------------
2022-11-16 18:22:44.948454 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 474 finished
---------------------------------------  ----------------
epoch                                       474
total_step                               479000
replay_pool/size                         479000
trainer/alpha                                 0.0645908
trainer/alpha_loss                            0.234227
trainer/entropy                              -6.08549
trainer/qf_loss                              23.6035
trainer/policy_loss                        -307.542
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.935
trainer/entropy_penalty                      -0.393067
trainer/entropy_percentage                   -0.00127646
trainer/Q1Pred Mean                         307.574
trainer/Q1Pred Std                           68.5598
trainer/Q1Pred Max                          390.462
trainer/Q1Pred Min                          -22.0111
trainer/Q2Pred Mean                         306.658
trainer/Q2Pred Std                           68.4513
trainer/Q2Pred Max                          389.23
trainer/Q2Pred Min                          -32.5322
trainer/QTargetWithReg Mean                 306.989
trainer/QTargetWithReg Std                   68.1223
trainer/QTargetWithReg Max                  391.149
trainer/QTargetWithReg Min                  -18.0015
trainer/PolicyLossWithoutReg Mean           307.935
trainer/PolicyLossWithoutReg Std             67.1845
trainer/PolicyLossWithoutReg Max            391.335
trainer/PolicyLossWithoutReg Min            -24.0788
exploration/num steps total              479000
exploration/num paths total                1241
exploration/path length this epoch Mean     318
exploration/path length this epoch Std        0
exploration/path length this epoch Max      318
exploration/path length this epoch Min      318
exploration/Rewards Mean                      3.79515
exploration/Rewards Std                       1.25801
exploration/Rewards Max                       6.93758
exploration/Rewards Min                      -0.458073
exploration/Returns Mean                   1206.86
exploration/Returns Std                       0
exploration/Returns Max                    1206.86
exploration/Returns Min                    1206.86
exploration/Num Paths                         1
exploration/Average Returns                1206.86
evaluation_0/num steps total                  3.68194e+06
evaluation_0/num paths total               7269
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80227
evaluation_0/Rewards Std                      1.09559
evaluation_0/Rewards Max                      8.349
evaluation_0/Rewards Min                     -0.667645
evaluation_0/Returns Mean                  4802.27
evaluation_0/Returns Std                     45.8786
evaluation_0/Returns Max                   4854.74
evaluation_0/Returns Min                   4716.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4802.27
time/epoch (s)                                0
time/total (s)                             7681.96
Epoch                                       474
---------------------------------------  ----------------
2022-11-16 18:22:58.176308 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 475 finished
---------------------------------------  ----------------
epoch                                       475
total_step                               480000
replay_pool/size                         480000
trainer/alpha                                 0.0635106
trainer/alpha_loss                           -0.157068
trainer/entropy                              -5.94302
trainer/qf_loss                              27.2378
trainer/policy_loss                        -308.358
trainer/adversary_policy_loss                14.7312
trainer/policy_loss_without_entropy         308.736
trainer/entropy_penalty                      -0.377445
trainer/entropy_percentage                   -0.00122255
trainer/Q1Pred Mean                         308.154
trainer/Q1Pred Std                           67.5912
trainer/Q1Pred Max                          400.13
trainer/Q1Pred Min                           15.3971
trainer/Q2Pred Mean                         308.352
trainer/Q2Pred Std                           67.0694
trainer/Q2Pred Max                          399.395
trainer/Q2Pred Min                           11.1119
trainer/QTargetWithReg Mean                 308.428
trainer/QTargetWithReg Std                   67.269
trainer/QTargetWithReg Max                  400.003
trainer/QTargetWithReg Min                    3.36714
trainer/PolicyLossWithoutReg Mean           308.736
trainer/PolicyLossWithoutReg Std             66.1081
trainer/PolicyLossWithoutReg Max            398.447
trainer/PolicyLossWithoutReg Min             14.7951
exploration/num steps total              480000
exploration/num paths total                1242
exploration/path length this epoch Mean     474
exploration/path length this epoch Std        0
exploration/path length this epoch Max      474
exploration/path length this epoch Min      474
exploration/Rewards Mean                      3.61699
exploration/Rewards Std                       1.18271
exploration/Rewards Max                       5.93724
exploration/Rewards Min                      -0.670782
exploration/Returns Mean                   1714.45
exploration/Returns Std                       0
exploration/Returns Max                    1714.45
exploration/Returns Min                    1714.45
exploration/Num Paths                         1
exploration/Average Returns                1714.45
evaluation_0/num steps total                  3.68941e+06
evaluation_0/num paths total               7277
evaluation_0/path length Mean               933.125
evaluation_0/path length Std                176.935
evaluation_0/path length Max               1000
evaluation_0/path length Min                465
evaluation_0/Rewards Mean                     4.51567
evaluation_0/Rewards Std                      1.16468
evaluation_0/Rewards Max                      8.09645
evaluation_0/Rewards Min                     -0.482053
evaluation_0/Returns Mean                  4213.69
evaluation_0/Returns Std                    869.972
evaluation_0/Returns Max                   4827.29
evaluation_0/Returns Min                   1943.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4213.69
time/epoch (s)                                0
time/total (s)                             7695.19
Epoch                                       475
---------------------------------------  ----------------
2022-11-16 18:23:14.190994 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 476 finished
---------------------------------------  ----------------
epoch                                       476
total_step                               481000
replay_pool/size                         481000
trainer/alpha                                 0.0634015
trainer/alpha_loss                            0.301099
trainer/entropy                              -6.10916
trainer/qf_loss                              18.7763
trainer/policy_loss                        -301.597
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         301.984
trainer/entropy_penalty                      -0.38733
trainer/entropy_percentage                   -0.00128262
trainer/Q1Pred Mean                         301.044
trainer/Q1Pred Std                           71.0402
trainer/Q1Pred Max                          387.949
trainer/Q1Pred Min                           -7.37355
trainer/Q2Pred Mean                         300.089
trainer/Q2Pred Std                           70.5593
trainer/Q2Pred Max                          385.515
trainer/Q2Pred Min                           -2.90383
trainer/QTargetWithReg Mean                 300.655
trainer/QTargetWithReg Std                   71.6096
trainer/QTargetWithReg Max                  390.525
trainer/QTargetWithReg Min                   -5.87395
trainer/PolicyLossWithoutReg Mean           301.985
trainer/PolicyLossWithoutReg Std             69.9914
trainer/PolicyLossWithoutReg Max            390.977
trainer/PolicyLossWithoutReg Min              8.64701
exploration/num steps total              481000
exploration/num paths total                1243
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.39045
exploration/Rewards Std                       1.10188
exploration/Rewards Max                       6.87089
exploration/Rewards Min                      -0.465242
exploration/Returns Mean                   4390.45
exploration/Returns Std                       0
exploration/Returns Max                    4390.45
exploration/Returns Min                    4390.45
exploration/Num Paths                         1
exploration/Average Returns                4390.45
evaluation_0/num steps total                  3.69685e+06
evaluation_0/num paths total               7285
evaluation_0/path length Mean               929.75
evaluation_0/path length Std                185.864
evaluation_0/path length Max               1000
evaluation_0/path length Min                438
evaluation_0/Rewards Mean                     4.51043
evaluation_0/Rewards Std                      1.16417
evaluation_0/Rewards Max                      9.42026
evaluation_0/Rewards Min                     -0.510695
evaluation_0/Returns Mean                  4193.58
evaluation_0/Returns Std                    946.937
evaluation_0/Returns Max                   4921.26
evaluation_0/Returns Min                   1764.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4193.58
time/epoch (s)                                0
time/total (s)                             7711.21
Epoch                                       476
---------------------------------------  ----------------
2022-11-16 18:23:28.093080 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 477 finished
---------------------------------------  ----------------
epoch                                       477
total_step                               482000
replay_pool/size                         482000
trainer/alpha                                 0.0646079
trainer/alpha_loss                           -1.10569
trainer/entropy                              -5.59639
trainer/qf_loss                              21.8943
trainer/policy_loss                        -301.659
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         302.02
trainer/entropy_penalty                      -0.361571
trainer/entropy_percentage                   -0.00119717
trainer/Q1Pred Mean                         301.46
trainer/Q1Pred Std                           67.4363
trainer/Q1Pred Max                          394.975
trainer/Q1Pred Min                           10.397
trainer/Q2Pred Mean                         301.612
trainer/Q2Pred Std                           67.739
trainer/Q2Pred Max                          390.919
trainer/Q2Pred Min                            1.37377
trainer/QTargetWithReg Mean                 301.831
trainer/QTargetWithReg Std                   67.3974
trainer/QTargetWithReg Max                  394.635
trainer/QTargetWithReg Min                   13.963
trainer/PolicyLossWithoutReg Mean           302.02
trainer/PolicyLossWithoutReg Std             66.8517
trainer/PolicyLossWithoutReg Max            392.13
trainer/PolicyLossWithoutReg Min              9.14028
exploration/num steps total              482000
exploration/num paths total                1244
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60835
exploration/Rewards Std                       0.987087
exploration/Rewards Max                       7.0708
exploration/Rewards Min                      -0.6101
exploration/Returns Mean                   4608.35
exploration/Returns Std                       0
exploration/Returns Max                    4608.35
exploration/Returns Min                    4608.35
exploration/Num Paths                         1
exploration/Average Returns                4608.35
evaluation_0/num steps total                  3.70452e+06
evaluation_0/num paths total               7293
evaluation_0/path length Mean               958.625
evaluation_0/path length Std                109.468
evaluation_0/path length Max               1000
evaluation_0/path length Min                669
evaluation_0/Rewards Mean                     4.76726
evaluation_0/Rewards Std                      1.07243
evaluation_0/Rewards Max                      8.14156
evaluation_0/Rewards Min                     -0.868783
evaluation_0/Returns Mean                  4570.01
evaluation_0/Returns Std                    575.025
evaluation_0/Returns Max                   4956.02
evaluation_0/Returns Min                   3081.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4570.01
time/epoch (s)                                0
time/total (s)                             7725.11
Epoch                                       477
---------------------------------------  ----------------
2022-11-16 18:23:42.036604 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 478 finished
---------------------------------------  ----------------
epoch                                       478
total_step                               483000
replay_pool/size                         483000
trainer/alpha                                 0.0652667
trainer/alpha_loss                           -1.21461
trainer/entropy                              -5.55497
trainer/qf_loss                              16.4404
trainer/policy_loss                        -314.671
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.034
trainer/entropy_penalty                      -0.362555
trainer/entropy_percentage                   -0.00115084
trainer/Q1Pred Mean                         314.433
trainer/Q1Pred Std                           64.0913
trainer/Q1Pred Max                          393.799
trainer/Q1Pred Min                          -19.6317
trainer/Q2Pred Mean                         314.383
trainer/Q2Pred Std                           64.4528
trainer/Q2Pred Max                          395.426
trainer/Q2Pred Min                          -21.9039
trainer/QTargetWithReg Mean                 314.929
trainer/QTargetWithReg Std                   64.3006
trainer/QTargetWithReg Max                  395.404
trainer/QTargetWithReg Min                  -17.8137
trainer/PolicyLossWithoutReg Mean           315.034
trainer/PolicyLossWithoutReg Std             63.3266
trainer/PolicyLossWithoutReg Max            396.666
trainer/PolicyLossWithoutReg Min            -13.6275
exploration/num steps total              483000
exploration/num paths total                1245
exploration/path length this epoch Mean     491
exploration/path length this epoch Std        0
exploration/path length this epoch Max      491
exploration/path length this epoch Min      491
exploration/Rewards Mean                      4.09022
exploration/Rewards Std                       1.11959
exploration/Rewards Max                       6.657
exploration/Rewards Min                      -0.690599
exploration/Returns Mean                   2008.3
exploration/Returns Std                       0
exploration/Returns Max                    2008.3
exploration/Returns Min                    2008.3
exploration/Num Paths                         1
exploration/Average Returns                2008.3
evaluation_0/num steps total                  3.71225e+06
evaluation_0/num paths total               7301
evaluation_0/path length Mean               966.25
evaluation_0/path length Std                 69.996
evaluation_0/path length Max               1000
evaluation_0/path length Min                788
evaluation_0/Rewards Mean                     4.7487
evaluation_0/Rewards Std                      1.12169
evaluation_0/Rewards Max                      9.32899
evaluation_0/Rewards Min                     -0.852281
evaluation_0/Returns Mean                  4588.43
evaluation_0/Returns Std                    398.332
evaluation_0/Returns Max                   4863.7
evaluation_0/Returns Min                   3570.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4588.43
time/epoch (s)                                0
time/total (s)                             7739.05
Epoch                                       478
---------------------------------------  ----------------
2022-11-16 18:23:56.591385 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 479 finished
---------------------------------------  ----------------
epoch                                       479
total_step                               484000
replay_pool/size                         484000
trainer/alpha                                 0.0650248
trainer/alpha_loss                           -2.04158
trainer/entropy                              -5.25296
trainer/qf_loss                              28.3818
trainer/policy_loss                        -309.365
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.706
trainer/entropy_penalty                      -0.341573
trainer/entropy_percentage                   -0.00110289
trainer/Q1Pred Mean                         309.056
trainer/Q1Pred Std                           64.0566
trainer/Q1Pred Max                          398.538
trainer/Q1Pred Min                           11.5023
trainer/Q2Pred Mean                         309.827
trainer/Q2Pred Std                           64.108
trainer/Q2Pred Max                          397.352
trainer/Q2Pred Min                           15.5736
trainer/QTargetWithReg Mean                 309.742
trainer/QTargetWithReg Std                   64.0332
trainer/QTargetWithReg Max                  400.527
trainer/QTargetWithReg Min                   14.3706
trainer/PolicyLossWithoutReg Mean           309.706
trainer/PolicyLossWithoutReg Std             62.9793
trainer/PolicyLossWithoutReg Max            400.762
trainer/PolicyLossWithoutReg Min             11.8161
exploration/num steps total              484000
exploration/num paths total                1246
exploration/path length this epoch Mean     985
exploration/path length this epoch Std        0
exploration/path length this epoch Max      985
exploration/path length this epoch Min      985
exploration/Rewards Mean                      4.33371
exploration/Rewards Std                       1.22696
exploration/Rewards Max                       7.00862
exploration/Rewards Min                      -0.720939
exploration/Returns Mean                   4268.71
exploration/Returns Std                       0
exploration/Returns Max                    4268.71
exploration/Returns Min                    4268.71
exploration/Num Paths                         1
exploration/Average Returns                4268.71
evaluation_0/num steps total                  3.72016e+06
evaluation_0/num paths total               7309
evaluation_0/path length Mean               988.875
evaluation_0/path length Std                 29.434
evaluation_0/path length Max               1000
evaluation_0/path length Min                911
evaluation_0/Rewards Mean                     4.68979
evaluation_0/Rewards Std                      1.10554
evaluation_0/Rewards Max                      8.17286
evaluation_0/Rewards Min                     -0.86953
evaluation_0/Returns Mean                  4637.62
evaluation_0/Returns Std                    178.882
evaluation_0/Returns Max                   4796.47
evaluation_0/Returns Min                   4215.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4637.62
time/epoch (s)                                0
time/total (s)                             7753.61
Epoch                                       479
---------------------------------------  ----------------
2022-11-16 18:24:08.485199 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 480 finished
---------------------------------------  ----------------
epoch                                       480
total_step                               485000
replay_pool/size                         485000
trainer/alpha                                 0.0647794
trainer/alpha_loss                           -0.376613
trainer/entropy                              -5.86239
trainer/qf_loss                              19.1704
trainer/policy_loss                        -310.756
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         311.136
trainer/entropy_penalty                      -0.379762
trainer/entropy_percentage                   -0.00122056
trainer/Q1Pred Mean                         309.877
trainer/Q1Pred Std                           58.6194
trainer/Q1Pred Max                          387.526
trainer/Q1Pred Min                           40.1549
trainer/Q2Pred Mean                         309.667
trainer/Q2Pred Std                           58.6392
trainer/Q2Pred Max                          387.811
trainer/Q2Pred Min                           45.0462
trainer/QTargetWithReg Mean                 310.403
trainer/QTargetWithReg Std                   59.4383
trainer/QTargetWithReg Max                  389.256
trainer/QTargetWithReg Min                   47.7536
trainer/PolicyLossWithoutReg Mean           311.136
trainer/PolicyLossWithoutReg Std             58.0243
trainer/PolicyLossWithoutReg Max            387.752
trainer/PolicyLossWithoutReg Min             38.6525
exploration/num steps total              485000
exploration/num paths total                1247
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53155
exploration/Rewards Std                       1.15395
exploration/Rewards Max                       6.83069
exploration/Rewards Min                      -0.793035
exploration/Returns Mean                   4531.55
exploration/Returns Std                       0
exploration/Returns Max                    4531.55
exploration/Returns Min                    4531.55
exploration/Num Paths                         1
exploration/Average Returns                4531.55
evaluation_0/num steps total                  3.72816e+06
evaluation_0/num paths total               7317
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65824
evaluation_0/Rewards Std                      1.04112
evaluation_0/Rewards Max                      6.91205
evaluation_0/Rewards Min                     -0.55623
evaluation_0/Returns Mean                  4658.24
evaluation_0/Returns Std                     46.0358
evaluation_0/Returns Max                   4720.92
evaluation_0/Returns Min                   4564.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4658.24
time/epoch (s)                                0
time/total (s)                             7765.5
Epoch                                       480
---------------------------------------  ----------------
2022-11-16 18:24:19.433086 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 481 finished
---------------------------------------  ----------------
epoch                                       481
total_step                               486000
replay_pool/size                         486000
trainer/alpha                                 0.0633515
trainer/alpha_loss                           -1.67826
trainer/entropy                              -5.39168
trainer/qf_loss                              16.1687
trainer/policy_loss                        -312.498
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.84
trainer/entropy_penalty                      -0.341571
trainer/entropy_percentage                   -0.00109184
trainer/Q1Pred Mean                         312.834
trainer/Q1Pred Std                           66.2889
trainer/Q1Pred Max                          395.641
trainer/Q1Pred Min                            7.64507
trainer/Q2Pred Mean                         312.384
trainer/Q2Pred Std                           66.6707
trainer/Q2Pred Max                          394.498
trainer/Q2Pred Min                            4.04303
trainer/QTargetWithReg Mean                 312.464
trainer/QTargetWithReg Std                   66.1933
trainer/QTargetWithReg Max                  394.308
trainer/QTargetWithReg Min                    5.47843
trainer/PolicyLossWithoutReg Mean           312.84
trainer/PolicyLossWithoutReg Std             65.9468
trainer/PolicyLossWithoutReg Max            399.731
trainer/PolicyLossWithoutReg Min              3.42435
exploration/num steps total              486000
exploration/num paths total                1248
exploration/path length this epoch Mean     952
exploration/path length this epoch Std        0
exploration/path length this epoch Max      952
exploration/path length this epoch Min      952
exploration/Rewards Mean                      4.40872
exploration/Rewards Std                       0.963878
exploration/Rewards Max                       7.28368
exploration/Rewards Min                      -0.863475
exploration/Returns Mean                   4197.1
exploration/Returns Std                       0
exploration/Returns Max                    4197.1
exploration/Returns Min                    4197.1
exploration/Num Paths                         1
exploration/Average Returns                4197.1
evaluation_0/num steps total                  3.73616e+06
evaluation_0/num paths total               7325
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93264
evaluation_0/Rewards Std                      1.12854
evaluation_0/Rewards Max                      7.82521
evaluation_0/Rewards Min                     -0.560261
evaluation_0/Returns Mean                  4932.64
evaluation_0/Returns Std                     50.9493
evaluation_0/Returns Max                   4995.14
evaluation_0/Returns Min                   4821.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4932.64
time/epoch (s)                                0
time/total (s)                             7776.45
Epoch                                       481
---------------------------------------  ----------------
2022-11-16 18:24:33.822955 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 482 finished
---------------------------------------  ----------------
epoch                                       482
total_step                               487000
replay_pool/size                         487000
trainer/alpha                                 0.064676
trainer/alpha_loss                            0.391994
trainer/entropy                              -6.14314
trainer/qf_loss                              28.9046
trainer/policy_loss                        -304.945
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.342
trainer/entropy_penalty                      -0.397313
trainer/entropy_percentage                   -0.00130121
trainer/Q1Pred Mean                         304.513
trainer/Q1Pred Std                           69.8278
trainer/Q1Pred Max                          400.932
trainer/Q1Pred Min                           34.9842
trainer/Q2Pred Mean                         303.837
trainer/Q2Pred Std                           70.1569
trainer/Q2Pred Max                          401.277
trainer/Q2Pred Min                           28.9244
trainer/QTargetWithReg Mean                 303.49
trainer/QTargetWithReg Std                   69.6355
trainer/QTargetWithReg Max                  400.641
trainer/QTargetWithReg Min                   26.5553
trainer/PolicyLossWithoutReg Mean           305.342
trainer/PolicyLossWithoutReg Std             68.3436
trainer/PolicyLossWithoutReg Max            400.087
trainer/PolicyLossWithoutReg Min             34.3531
exploration/num steps total              487000
exploration/num paths total                1249
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61033
exploration/Rewards Std                       1.06291
exploration/Rewards Max                       6.98391
exploration/Rewards Min                      -0.550603
exploration/Returns Mean                   4610.33
exploration/Returns Std                       0
exploration/Returns Max                    4610.33
exploration/Returns Min                    4610.33
exploration/Num Paths                         1
exploration/Average Returns                4610.33
evaluation_0/num steps total                  3.74353e+06
evaluation_0/num paths total               7333
evaluation_0/path length Mean               921.125
evaluation_0/path length Std                116.868
evaluation_0/path length Max               1000
evaluation_0/path length Min                683
evaluation_0/Rewards Mean                     4.68294
evaluation_0/Rewards Std                      1.24863
evaluation_0/Rewards Max                      9.31811
evaluation_0/Rewards Min                     -0.460186
evaluation_0/Returns Mean                  4313.57
evaluation_0/Returns Std                    549.857
evaluation_0/Returns Max                   4900.62
evaluation_0/Returns Min                   3201.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4313.57
time/epoch (s)                                0
time/total (s)                             7790.83
Epoch                                       482
---------------------------------------  ----------------
2022-11-16 18:24:46.175380 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 483 finished
---------------------------------------  ----------------
epoch                                       483
total_step                               488000
replay_pool/size                         488000
trainer/alpha                                 0.0646847
trainer/alpha_loss                            0.326942
trainer/entropy                              -6.1194
trainer/qf_loss                              16.9683
trainer/policy_loss                        -309.989
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.385
trainer/entropy_penalty                      -0.395831
trainer/entropy_percentage                   -0.00127529
trainer/Q1Pred Mean                         309.056
trainer/Q1Pred Std                           58.6568
trainer/Q1Pred Max                          396.482
trainer/Q1Pred Min                           -9.3513
trainer/Q2Pred Mean                         309.787
trainer/Q2Pred Std                           58.7353
trainer/Q2Pred Max                          399.374
trainer/Q2Pred Min                            9.38121
trainer/QTargetWithReg Mean                 309.351
trainer/QTargetWithReg Std                   58.7644
trainer/QTargetWithReg Max                  397.655
trainer/QTargetWithReg Min                   -3.578
trainer/PolicyLossWithoutReg Mean           310.385
trainer/PolicyLossWithoutReg Std             57.2227
trainer/PolicyLossWithoutReg Max            397.366
trainer/PolicyLossWithoutReg Min              2.85679
exploration/num steps total              488000
exploration/num paths total                1250
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60095
exploration/Rewards Std                       1.05543
exploration/Rewards Max                       7.13682
exploration/Rewards Min                      -0.717333
exploration/Returns Mean                   4600.95
exploration/Returns Std                       0
exploration/Returns Max                    4600.95
exploration/Returns Min                    4600.95
exploration/Num Paths                         1
exploration/Average Returns                4600.95
evaluation_0/num steps total                  3.75117e+06
evaluation_0/num paths total               7341
evaluation_0/path length Mean               954.875
evaluation_0/path length Std                 85.581
evaluation_0/path length Max               1000
evaluation_0/path length Min                749
evaluation_0/Rewards Mean                     4.47886
evaluation_0/Rewards Std                      1.25798
evaluation_0/Rewards Max                     10.8827
evaluation_0/Rewards Min                     -0.831702
evaluation_0/Returns Mean                  4276.75
evaluation_0/Returns Std                    411.13
evaluation_0/Returns Max                   4629.23
evaluation_0/Returns Min                   3282.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4276.75
time/epoch (s)                                0
time/total (s)                             7803.19
Epoch                                       483
---------------------------------------  ----------------
2022-11-16 18:24:59.203429 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 484 finished
---------------------------------------  ----------------
epoch                                       484
total_step                               489000
replay_pool/size                         489000
trainer/alpha                                 0.0634756
trainer/alpha_loss                           -0.0902079
trainer/entropy                              -5.96728
trainer/qf_loss                              24.7095
trainer/policy_loss                        -315.853
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.231
trainer/entropy_penalty                      -0.378777
trainer/entropy_percentage                   -0.00119778
trainer/Q1Pred Mean                         314.733
trainer/Q1Pred Std                           66.7621
trainer/Q1Pred Max                          395.392
trainer/Q1Pred Min                           16.7587
trainer/Q2Pred Mean                         314.584
trainer/Q2Pred Std                           66.3448
trainer/Q2Pred Max                          394.776
trainer/Q2Pred Min                           24.155
trainer/QTargetWithReg Mean                 313.925
trainer/QTargetWithReg Std                   66.7318
trainer/QTargetWithReg Max                  395.146
trainer/QTargetWithReg Min                   19.9784
trainer/PolicyLossWithoutReg Mean           316.231
trainer/PolicyLossWithoutReg Std             65.9258
trainer/PolicyLossWithoutReg Max            397.774
trainer/PolicyLossWithoutReg Min             21.3786
exploration/num steps total              489000
exploration/num paths total                1252
exploration/path length this epoch Mean     441.5
exploration/path length this epoch Std      143.5
exploration/path length this epoch Max      585
exploration/path length this epoch Min      298
exploration/Rewards Mean                      3.80105
exploration/Rewards Std                       1.34998
exploration/Rewards Max                       6.38882
exploration/Rewards Min                      -0.869237
exploration/Returns Mean                   1678.16
exploration/Returns Std                     648.941
exploration/Returns Max                    2327.1
exploration/Returns Min                    1029.22
exploration/Num Paths                         2
exploration/Average Returns                1678.16
evaluation_0/num steps total                  3.75884e+06
evaluation_0/num paths total               7349
evaluation_0/path length Mean               959.25
evaluation_0/path length Std                 76.1179
evaluation_0/path length Max               1000
evaluation_0/path length Min                780
evaluation_0/Rewards Mean                     4.60982
evaluation_0/Rewards Std                      1.14606
evaluation_0/Rewards Max                      8.62067
evaluation_0/Rewards Min                     -0.761345
evaluation_0/Returns Mean                  4421.97
evaluation_0/Returns Std                    336.274
evaluation_0/Returns Max                   4766.56
evaluation_0/Returns Min                   3643.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4421.97
time/epoch (s)                                0
time/total (s)                             7816.22
Epoch                                       484
---------------------------------------  ----------------
2022-11-16 18:25:13.369729 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 485 finished
---------------------------------------  ----------------
epoch                                       485
total_step                               490000
replay_pool/size                         490000
trainer/alpha                                 0.0643671
trainer/alpha_loss                           -1.06025
trainer/entropy                              -5.61348
trainer/qf_loss                              23.2411
trainer/policy_loss                        -309.996
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.357
trainer/entropy_penalty                      -0.361323
trainer/entropy_percentage                   -0.00116422
trainer/Q1Pred Mean                         309.805
trainer/Q1Pred Std                           71.8484
trainer/Q1Pred Max                          389.835
trainer/Q1Pred Min                           15.1539
trainer/Q2Pred Mean                         309.523
trainer/Q2Pred Std                           72.2767
trainer/Q2Pred Max                          391.809
trainer/Q2Pred Min                            3.22237
trainer/QTargetWithReg Mean                 309.191
trainer/QTargetWithReg Std                   72.1727
trainer/QTargetWithReg Max                  389.317
trainer/QTargetWithReg Min                    5.70748
trainer/PolicyLossWithoutReg Mean           310.357
trainer/PolicyLossWithoutReg Std             71.1924
trainer/PolicyLossWithoutReg Max            392.57
trainer/PolicyLossWithoutReg Min              6.17227
exploration/num steps total              490000
exploration/num paths total                1253
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.32043
exploration/Rewards Std                       1.38292
exploration/Rewards Max                       6.97772
exploration/Rewards Min                      -0.744867
exploration/Returns Mean                   4320.43
exploration/Returns Std                       0
exploration/Returns Max                    4320.43
exploration/Returns Min                    4320.43
exploration/Num Paths                         1
exploration/Average Returns                4320.43
evaluation_0/num steps total                  3.76622e+06
evaluation_0/num paths total               7357
evaluation_0/path length Mean               922.875
evaluation_0/path length Std                204.054
evaluation_0/path length Max               1000
evaluation_0/path length Min                383
evaluation_0/Rewards Mean                     4.72367
evaluation_0/Rewards Std                      1.11191
evaluation_0/Rewards Max                      7.11931
evaluation_0/Rewards Min                     -0.881263
evaluation_0/Returns Mean                  4359.35
evaluation_0/Returns Std                   1046.92
evaluation_0/Returns Max                   4870.57
evaluation_0/Returns Min                   1594.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4359.35
time/epoch (s)                                0
time/total (s)                             7830.38
Epoch                                       485
---------------------------------------  ----------------
2022-11-16 18:25:24.695183 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 486 finished
---------------------------------------  ----------------
epoch                                       486
total_step                               491000
replay_pool/size                         491000
trainer/alpha                                 0.0664887
trainer/alpha_loss                           -0.131749
trainer/entropy                              -5.95139
trainer/qf_loss                              21.8783
trainer/policy_loss                        -313.825
trainer/adversary_policy_loss                14.9548
trainer/policy_loss_without_entropy         314.221
trainer/entropy_penalty                      -0.3957
trainer/entropy_percentage                   -0.00125931
trainer/Q1Pred Mean                         313.838
trainer/Q1Pred Std                           68.3991
trainer/Q1Pred Max                          402.073
trainer/Q1Pred Min                           19.0692
trainer/Q2Pred Mean                         313.178
trainer/Q2Pred Std                           68.5367
trainer/Q2Pred Max                          401.82
trainer/Q2Pred Min                           18.896
trainer/QTargetWithReg Mean                 312.667
trainer/QTargetWithReg Std                   67.8451
trainer/QTargetWithReg Max                  399.632
trainer/QTargetWithReg Min                   18.4147
trainer/PolicyLossWithoutReg Mean           314.221
trainer/PolicyLossWithoutReg Std             66.7888
trainer/PolicyLossWithoutReg Max            401.882
trainer/PolicyLossWithoutReg Min             20.7876
exploration/num steps total              491000
exploration/num paths total                1254
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44553
exploration/Rewards Std                       1.21772
exploration/Rewards Max                       6.63946
exploration/Rewards Min                      -0.769682
exploration/Returns Mean                   4445.53
exploration/Returns Std                       0
exploration/Returns Max                    4445.53
exploration/Returns Min                    4445.53
exploration/Num Paths                         1
exploration/Average Returns                4445.53
evaluation_0/num steps total                  3.77422e+06
evaluation_0/num paths total               7365
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58813
evaluation_0/Rewards Std                      1.24664
evaluation_0/Rewards Max                      7.1638
evaluation_0/Rewards Min                     -0.640352
evaluation_0/Returns Mean                  4588.13
evaluation_0/Returns Std                     98.4622
evaluation_0/Returns Max                   4760.67
evaluation_0/Returns Min                   4426.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4588.13
time/epoch (s)                                0
time/total (s)                             7841.71
Epoch                                       486
---------------------------------------  ----------------
2022-11-16 18:25:35.991645 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 487 finished
---------------------------------------  ----------------
epoch                                       487
total_step                               492000
replay_pool/size                         492000
trainer/alpha                                 0.0672256
trainer/alpha_loss                           -0.451154
trainer/entropy                              -5.83288
trainer/qf_loss                              37.22
trainer/policy_loss                        -309.226
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.619
trainer/entropy_penalty                      -0.392119
trainer/entropy_percentage                   -0.00126646
trainer/Q1Pred Mean                         307.853
trainer/Q1Pred Std                           70.6684
trainer/Q1Pred Max                          391.125
trainer/Q1Pred Min                            7.71292
trainer/Q2Pred Mean                         307.758
trainer/Q2Pred Std                           70.681
trainer/Q2Pred Max                          392.984
trainer/Q2Pred Min                            5.4849
trainer/QTargetWithReg Mean                 308.372
trainer/QTargetWithReg Std                   71.6897
trainer/QTargetWithReg Max                  391.526
trainer/QTargetWithReg Min                    0.672736
trainer/PolicyLossWithoutReg Mean           309.619
trainer/PolicyLossWithoutReg Std             68.4357
trainer/PolicyLossWithoutReg Max            391.962
trainer/PolicyLossWithoutReg Min             10.9514
exploration/num steps total              492000
exploration/num paths total                1255
exploration/path length this epoch Mean     943
exploration/path length this epoch Std        0
exploration/path length this epoch Max      943
exploration/path length this epoch Min      943
exploration/Rewards Mean                      4.09439
exploration/Rewards Std                       1.13413
exploration/Rewards Max                       6.61293
exploration/Rewards Min                      -0.611025
exploration/Returns Mean                   3861.01
exploration/Returns Std                       0
exploration/Returns Max                    3861.01
exploration/Returns Min                    3861.01
exploration/Num Paths                         1
exploration/Average Returns                3861.01
evaluation_0/num steps total                  3.78222e+06
evaluation_0/num paths total               7373
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63599
evaluation_0/Rewards Std                      1.05861
evaluation_0/Rewards Max                      7.26604
evaluation_0/Rewards Min                     -0.83842
evaluation_0/Returns Mean                  4635.99
evaluation_0/Returns Std                    117.21
evaluation_0/Returns Max                   4785.57
evaluation_0/Returns Min                   4424.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4635.99
time/epoch (s)                                0
time/total (s)                             7853
Epoch                                       487
---------------------------------------  ----------------
2022-11-16 18:25:48.824637 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 488 finished
---------------------------------------  ----------------
epoch                                       488
total_step                               493000
replay_pool/size                         493000
trainer/alpha                                 0.0639105
trainer/alpha_loss                           -1.44089
trainer/entropy                              -5.47607
trainer/qf_loss                              17.0101
trainer/policy_loss                        -304.779
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.129
trainer/entropy_penalty                      -0.349979
trainer/entropy_percentage                   -0.00114699
trainer/Q1Pred Mean                         304.259
trainer/Q1Pred Std                           72.8109
trainer/Q1Pred Max                          390.499
trainer/Q1Pred Min                           -7.20129
trainer/Q2Pred Mean                         304.135
trainer/Q2Pred Std                           72.6888
trainer/Q2Pred Max                          392.295
trainer/Q2Pred Min                          -10.1419
trainer/QTargetWithReg Mean                 305.042
trainer/QTargetWithReg Std                   73.4646
trainer/QTargetWithReg Max                  391.43
trainer/QTargetWithReg Min                   -6.22551
trainer/PolicyLossWithoutReg Mean           305.129
trainer/PolicyLossWithoutReg Std             72.163
trainer/PolicyLossWithoutReg Max            391.216
trainer/PolicyLossWithoutReg Min             -5.47382
exploration/num steps total              493000
exploration/num paths total                1256
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.30058
exploration/Rewards Std                       1.22829
exploration/Rewards Max                       6.83542
exploration/Rewards Min                      -0.814487
exploration/Returns Mean                   4300.58
exploration/Returns Std                       0
exploration/Returns Max                    4300.58
exploration/Returns Min                    4300.58
exploration/Num Paths                         1
exploration/Average Returns                4300.58
evaluation_0/num steps total                  3.79022e+06
evaluation_0/num paths total               7381
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.55368
evaluation_0/Rewards Std                      1.34553
evaluation_0/Rewards Max                      8.63654
evaluation_0/Rewards Min                     -0.608969
evaluation_0/Returns Mean                  4553.68
evaluation_0/Returns Std                    166.349
evaluation_0/Returns Max                   4756.05
evaluation_0/Returns Min                   4254
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4553.68
time/epoch (s)                                0
time/total (s)                             7865.84
Epoch                                       488
---------------------------------------  ----------------
2022-11-16 18:26:01.079680 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 489 finished
---------------------------------------  ----------------
epoch                                       489
total_step                               494000
replay_pool/size                         494000
trainer/alpha                                 0.0638063
trainer/alpha_loss                            0.796826
trainer/entropy                              -6.28955
trainer/qf_loss                              18.736
trainer/policy_loss                        -307.709
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.11
trainer/entropy_penalty                      -0.401313
trainer/entropy_percentage                   -0.0013025
trainer/Q1Pred Mean                         308.021
trainer/Q1Pred Std                           68.8395
trainer/Q1Pred Max                          399.965
trainer/Q1Pred Min                           13.1647
trainer/Q2Pred Mean                         307.948
trainer/Q2Pred Std                           69.3981
trainer/Q2Pred Max                          403.213
trainer/Q2Pred Min                            6.48691
trainer/QTargetWithReg Mean                 307.454
trainer/QTargetWithReg Std                   69.4527
trainer/QTargetWithReg Max                  400.175
trainer/QTargetWithReg Min                    9.88833
trainer/PolicyLossWithoutReg Mean           308.11
trainer/PolicyLossWithoutReg Std             68.3989
trainer/PolicyLossWithoutReg Max            401.151
trainer/PolicyLossWithoutReg Min             11.7757
exploration/num steps total              494000
exploration/num paths total                1257
exploration/path length this epoch Mean      12
exploration/path length this epoch Std        0
exploration/path length this epoch Max       12
exploration/path length this epoch Min       12
exploration/Rewards Mean                     -0.248995
exploration/Rewards Std                       0.389424
exploration/Rewards Max                       0.675791
exploration/Rewards Min                      -0.646579
exploration/Returns Mean                     -2.98794
exploration/Returns Std                       0
exploration/Returns Max                      -2.98794
exploration/Returns Min                      -2.98794
exploration/Num Paths                         1
exploration/Average Returns                  -2.98794
evaluation_0/num steps total                  3.79778e+06
evaluation_0/num paths total               7391
evaluation_0/path length Mean               756.2
evaluation_0/path length Std                309.455
evaluation_0/path length Max               1000
evaluation_0/path length Min                286
evaluation_0/Rewards Mean                     4.34887
evaluation_0/Rewards Std                      1.32841
evaluation_0/Rewards Max                      7.26366
evaluation_0/Rewards Min                     -0.766497
evaluation_0/Returns Mean                  3288.62
evaluation_0/Returns Std                   1610.93
evaluation_0/Returns Max                   4698.93
evaluation_0/Returns Min                    898.941
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3288.62
time/epoch (s)                                0
time/total (s)                             7878.09
Epoch                                       489
---------------------------------------  ----------------
2022-11-16 18:26:11.967365 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 490 finished
---------------------------------------  ----------------
epoch                                       490
total_step                               495000
replay_pool/size                         495000
trainer/alpha                                 0.0642743
trainer/alpha_loss                           -0.623874
trainer/entropy                              -5.77268
trainer/qf_loss                              27.5664
trainer/policy_loss                        -315.679
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.05
trainer/entropy_penalty                      -0.371035
trainer/entropy_percentage                   -0.00117398
trainer/Q1Pred Mean                         314.829
trainer/Q1Pred Std                           58.4874
trainer/Q1Pred Max                          408.768
trainer/Q1Pred Min                          -41.6809
trainer/Q2Pred Mean                         315.227
trainer/Q2Pred Std                           59.5924
trainer/Q2Pred Max                          411.828
trainer/Q2Pred Min                          -61.7465
trainer/QTargetWithReg Mean                 315.851
trainer/QTargetWithReg Std                   57.6444
trainer/QTargetWithReg Max                  411.316
trainer/QTargetWithReg Min                  -41.76
trainer/PolicyLossWithoutReg Mean           316.05
trainer/PolicyLossWithoutReg Std             57.933
trainer/PolicyLossWithoutReg Max            409.776
trainer/PolicyLossWithoutReg Min            -60.9815
exploration/num steps total              495000
exploration/num paths total                1258
exploration/path length this epoch Mean     942
exploration/path length this epoch Std        0
exploration/path length this epoch Max      942
exploration/path length this epoch Min      942
exploration/Rewards Mean                      4.6089
exploration/Rewards Std                       1.12457
exploration/Rewards Max                       6.94546
exploration/Rewards Min                      -0.83686
exploration/Returns Mean                   4341.59
exploration/Returns Std                       0
exploration/Returns Max                    4341.59
exploration/Returns Min                    4341.59
exploration/Num Paths                         1
exploration/Average Returns                4341.59
evaluation_0/num steps total                  3.80578e+06
evaluation_0/num paths total               7399
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76334
evaluation_0/Rewards Std                      1.18084
evaluation_0/Rewards Max                      7.06023
evaluation_0/Rewards Min                     -0.877087
evaluation_0/Returns Mean                  4763.34
evaluation_0/Returns Std                    146.611
evaluation_0/Returns Max                   4936.15
evaluation_0/Returns Min                   4423.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4763.34
time/epoch (s)                                0
time/total (s)                             7888.98
Epoch                                       490
---------------------------------------  ----------------
2022-11-16 18:26:25.061362 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 491 finished
---------------------------------------  ----------------
epoch                                       491
total_step                               496000
replay_pool/size                         496000
trainer/alpha                                 0.0646235
trainer/alpha_loss                           -0.239861
trainer/entropy                              -5.91243
trainer/qf_loss                              19.5329
trainer/policy_loss                        -313.81
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.192
trainer/entropy_penalty                      -0.382082
trainer/entropy_percentage                   -0.00121608
trainer/Q1Pred Mean                         313.533
trainer/Q1Pred Std                           64.5254
trainer/Q1Pred Max                          411.917
trainer/Q1Pred Min                           -9.9961
trainer/Q2Pred Mean                         313.504
trainer/Q2Pred Std                           63.4825
trainer/Q2Pred Max                          411.96
trainer/Q2Pred Min                          -14.6169
trainer/QTargetWithReg Mean                 313.266
trainer/QTargetWithReg Std                   63.545
trainer/QTargetWithReg Max                  411.16
trainer/QTargetWithReg Min                  -14.3068
trainer/PolicyLossWithoutReg Mean           314.192
trainer/PolicyLossWithoutReg Std             63.2717
trainer/PolicyLossWithoutReg Max            410.983
trainer/PolicyLossWithoutReg Min             -5.47224
exploration/num steps total              496000
exploration/num paths total                1259
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.30183
exploration/Rewards Std                       1.04986
exploration/Rewards Max                       6.9537
exploration/Rewards Min                      -1.02312
exploration/Returns Mean                   4301.83
exploration/Returns Std                       0
exploration/Returns Max                    4301.83
exploration/Returns Min                    4301.83
exploration/Num Paths                         1
exploration/Average Returns                4301.83
evaluation_0/num steps total                  3.81324e+06
evaluation_0/num paths total               7407
evaluation_0/path length Mean               931.25
evaluation_0/path length Std                181.895
evaluation_0/path length Max               1000
evaluation_0/path length Min                450
evaluation_0/Rewards Mean                     4.55435
evaluation_0/Rewards Std                      1.07042
evaluation_0/Rewards Max                      7.20801
evaluation_0/Rewards Min                     -0.634951
evaluation_0/Returns Mean                  4241.24
evaluation_0/Returns Std                    941.548
evaluation_0/Returns Max                   4673.47
evaluation_0/Returns Min                   1757.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4241.24
time/epoch (s)                                0
time/total (s)                             7902.07
Epoch                                       491
---------------------------------------  ----------------
2022-11-16 18:26:38.248757 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 492 finished
---------------------------------------  ----------------
epoch                                       492
total_step                               497000
replay_pool/size                         497000
trainer/alpha                                 0.0658521
trainer/alpha_loss                           -0.0575854
trainer/entropy                              -5.97883
trainer/qf_loss                              40.4592
trainer/policy_loss                        -305.33
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.724
trainer/entropy_penalty                      -0.393718
trainer/entropy_percentage                   -0.00128783
trainer/Q1Pred Mean                         303.422
trainer/Q1Pred Std                           67.2548
trainer/Q1Pred Max                          390.702
trainer/Q1Pred Min                           10.7644
trainer/Q2Pred Mean                         303.288
trainer/Q2Pred Std                           68.2727
trainer/Q2Pred Max                          396.626
trainer/Q2Pred Min                           -2.59651
trainer/QTargetWithReg Mean                 303.613
trainer/QTargetWithReg Std                   69.3725
trainer/QTargetWithReg Max                  392.07
trainer/QTargetWithReg Min                    4.2896
trainer/PolicyLossWithoutReg Mean           305.724
trainer/PolicyLossWithoutReg Std             62.9876
trainer/PolicyLossWithoutReg Max            391.804
trainer/PolicyLossWithoutReg Min             24.8274
exploration/num steps total              497000
exploration/num paths total                1260
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5221
exploration/Rewards Std                       1.12885
exploration/Rewards Max                       6.76259
exploration/Rewards Min                      -0.255001
exploration/Returns Mean                   4522.1
exploration/Returns Std                       0
exploration/Returns Max                    4522.1
exploration/Returns Min                    4522.1
exploration/Num Paths                         1
exploration/Average Returns                4522.1
evaluation_0/num steps total                  3.82061e+06
evaluation_0/num paths total               7415
evaluation_0/path length Mean               922.25
evaluation_0/path length Std                205.707
evaluation_0/path length Max               1000
evaluation_0/path length Min                378
evaluation_0/Rewards Mean                     4.7008
evaluation_0/Rewards Std                      1.0435
evaluation_0/Rewards Max                      7.30307
evaluation_0/Rewards Min                     -0.693809
evaluation_0/Returns Mean                  4335.31
evaluation_0/Returns Std                   1065.09
evaluation_0/Returns Max                   4869.9
evaluation_0/Returns Min                   1524.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4335.31
time/epoch (s)                                0
time/total (s)                             7915.26
Epoch                                       492
---------------------------------------  ----------------
2022-11-16 18:26:50.368816 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 493 finished
---------------------------------------  ----------------
epoch                                       493
total_step                               498000
replay_pool/size                         498000
trainer/alpha                                 0.0644552
trainer/alpha_loss                           -0.0385174
trainer/entropy                              -5.98595
trainer/qf_loss                              16.9396
trainer/policy_loss                        -308.696
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.082
trainer/entropy_penalty                      -0.385826
trainer/entropy_percentage                   -0.0012483
trainer/Q1Pred Mean                         308.773
trainer/Q1Pred Std                           68.7471
trainer/Q1Pred Max                          397.656
trainer/Q1Pred Min                            6.76709
trainer/Q2Pred Mean                         309.435
trainer/Q2Pred Std                           68.6447
trainer/Q2Pred Max                          396.132
trainer/Q2Pred Min                            9.91138
trainer/QTargetWithReg Mean                 309.081
trainer/QTargetWithReg Std                   68.9902
trainer/QTargetWithReg Max                  395.636
trainer/QTargetWithReg Min                    4.47079
trainer/PolicyLossWithoutReg Mean           309.082
trainer/PolicyLossWithoutReg Std             67.5223
trainer/PolicyLossWithoutReg Max            395.635
trainer/PolicyLossWithoutReg Min              6.96519
exploration/num steps total              498000
exploration/num paths total                1261
exploration/path length this epoch Mean     972
exploration/path length this epoch Std        0
exploration/path length this epoch Max      972
exploration/path length this epoch Min      972
exploration/Rewards Mean                      4.35881
exploration/Rewards Std                       0.948624
exploration/Rewards Max                       7.17426
exploration/Rewards Min                      -0.925008
exploration/Returns Mean                   4236.77
exploration/Returns Std                       0
exploration/Returns Max                    4236.77
exploration/Returns Min                    4236.77
exploration/Num Paths                         1
exploration/Average Returns                4236.77
evaluation_0/num steps total                  3.82854e+06
evaluation_0/num paths total               7426
evaluation_0/path length Mean               720.182
evaluation_0/path length Std                176.088
evaluation_0/path length Max               1000
evaluation_0/path length Min                495
evaluation_0/Rewards Mean                     4.55482
evaluation_0/Rewards Std                      1.2552
evaluation_0/Rewards Max                     10.0213
evaluation_0/Rewards Min                     -0.696012
evaluation_0/Returns Mean                  3280.3
evaluation_0/Returns Std                    859.038
evaluation_0/Returns Max                   4684.13
evaluation_0/Returns Min                   2240.18
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3280.3
time/epoch (s)                                0
time/total (s)                             7927.38
Epoch                                       493
---------------------------------------  ----------------
2022-11-16 18:27:02.461202 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 494 finished
---------------------------------------  ----------------
epoch                                       494
total_step                               499000
replay_pool/size                         499000
trainer/alpha                                 0.0645813
trainer/alpha_loss                            1.46626
trainer/entropy                              -6.53514
trainer/qf_loss                              33.5443
trainer/policy_loss                        -304.292
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         304.714
trainer/entropy_penalty                      -0.422048
trainer/entropy_percentage                   -0.00138506
trainer/Q1Pred Mean                         303.43
trainer/Q1Pred Std                           73.2806
trainer/Q1Pred Max                          394.434
trainer/Q1Pred Min                            9.78415
trainer/Q2Pred Mean                         304.372
trainer/Q2Pred Std                           73.3534
trainer/Q2Pred Max                          395.979
trainer/Q2Pred Min                           12.4977
trainer/QTargetWithReg Mean                 304.587
trainer/QTargetWithReg Std                   73.8944
trainer/QTargetWithReg Max                  396.551
trainer/QTargetWithReg Min                   10.4641
trainer/PolicyLossWithoutReg Mean           304.714
trainer/PolicyLossWithoutReg Std             73.1668
trainer/PolicyLossWithoutReg Max            395.965
trainer/PolicyLossWithoutReg Min             15.1493
exploration/num steps total              499000
exploration/num paths total                1262
exploration/path length this epoch Mean     475
exploration/path length this epoch Std        0
exploration/path length this epoch Max      475
exploration/path length this epoch Min      475
exploration/Rewards Mean                      3.86086
exploration/Rewards Std                       1.28634
exploration/Rewards Max                       6.25067
exploration/Rewards Min                      -0.877436
exploration/Returns Mean                   1833.91
exploration/Returns Std                       0
exploration/Returns Max                    1833.91
exploration/Returns Min                    1833.91
exploration/Num Paths                         1
exploration/Average Returns                1833.91
evaluation_0/num steps total                  3.83654e+06
evaluation_0/num paths total               7434
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71172
evaluation_0/Rewards Std                      1.02774
evaluation_0/Rewards Max                      7.0298
evaluation_0/Rewards Min                     -0.877953
evaluation_0/Returns Mean                  4711.72
evaluation_0/Returns Std                     76.5274
evaluation_0/Returns Max                   4796.77
evaluation_0/Returns Min                   4567.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4711.72
time/epoch (s)                                0
time/total (s)                             7939.47
Epoch                                       494
---------------------------------------  ----------------
2022-11-16 18:27:13.973212 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 495 finished
---------------------------------------  ----------------
epoch                                       495
total_step                               500000
replay_pool/size                         500000
trainer/alpha                                 0.0648549
trainer/alpha_loss                            0.170443
trainer/entropy                              -6.0623
trainer/qf_loss                              27.5112
trainer/policy_loss                        -308.853
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.246
trainer/entropy_penalty                      -0.39317
trainer/entropy_percentage                   -0.00127138
trainer/Q1Pred Mean                         307.267
trainer/Q1Pred Std                           64.3845
trainer/Q1Pred Max                          403.198
trainer/Q1Pred Min                          -15.0902
trainer/Q2Pred Mean                         308.045
trainer/Q2Pred Std                           63.7146
trainer/Q2Pred Max                          403.952
trainer/Q2Pred Min                          -11.0539
trainer/QTargetWithReg Mean                 308.475
trainer/QTargetWithReg Std                   63.4523
trainer/QTargetWithReg Max                  403.933
trainer/QTargetWithReg Min                    0.739419
trainer/PolicyLossWithoutReg Mean           309.246
trainer/PolicyLossWithoutReg Std             63.4798
trainer/PolicyLossWithoutReg Max            404.238
trainer/PolicyLossWithoutReg Min            -26.6752
exploration/num steps total              500000
exploration/num paths total                1263
exploration/path length this epoch Mean     316
exploration/path length this epoch Std        0
exploration/path length this epoch Max      316
exploration/path length this epoch Min      316
exploration/Rewards Mean                      3.05755
exploration/Rewards Std                       1.27403
exploration/Rewards Max                       5.86989
exploration/Rewards Min                      -0.908583
exploration/Returns Mean                    966.186
exploration/Returns Std                       0
exploration/Returns Max                     966.186
exploration/Returns Min                     966.186
exploration/Num Paths                         1
exploration/Average Returns                 966.186
evaluation_0/num steps total                  3.84454e+06
evaluation_0/num paths total               7442
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.26603
evaluation_0/Rewards Std                      1.20124
evaluation_0/Rewards Max                      6.9613
evaluation_0/Rewards Min                     -0.734658
evaluation_0/Returns Mean                  4266.03
evaluation_0/Returns Std                    107.574
evaluation_0/Returns Max                   4465.79
evaluation_0/Returns Min                   4126.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4266.03
time/epoch (s)                                0
time/total (s)                             7950.98
Epoch                                       495
---------------------------------------  ----------------
2022-11-16 18:27:25.034251 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 496 finished
---------------------------------------  ----------------
epoch                                       496
total_step                               501000
replay_pool/size                         501000
trainer/alpha                                 0.0650166
trainer/alpha_loss                            1.20521
trainer/entropy                              -6.44094
trainer/qf_loss                              24.8277
trainer/policy_loss                        -305.825
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         306.244
trainer/entropy_penalty                      -0.418768
trainer/entropy_percentage                   -0.00136743
trainer/Q1Pred Mean                         303.878
trainer/Q1Pred Std                           69.1783
trainer/Q1Pred Max                          403.862
trainer/Q1Pred Min                          -11.2819
trainer/Q2Pred Mean                         304.405
trainer/Q2Pred Std                           69.1044
trainer/Q2Pred Max                          403.173
trainer/Q2Pred Min                           -0.36575
trainer/QTargetWithReg Mean                 304.785
trainer/QTargetWithReg Std                   69.7574
trainer/QTargetWithReg Max                  401.706
trainer/QTargetWithReg Min                  -17.1228
trainer/PolicyLossWithoutReg Mean           306.244
trainer/PolicyLossWithoutReg Std             68.7719
trainer/PolicyLossWithoutReg Max            404.266
trainer/PolicyLossWithoutReg Min            -14.7
exploration/num steps total              501000
exploration/num paths total                1264
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58058
exploration/Rewards Std                       1.02229
exploration/Rewards Max                       7.01472
exploration/Rewards Min                      -0.704141
exploration/Returns Mean                   4580.58
exploration/Returns Std                       0
exploration/Returns Max                    4580.58
exploration/Returns Min                    4580.58
exploration/Num Paths                         1
exploration/Average Returns                4580.58
evaluation_0/num steps total                  3.85254e+06
evaluation_0/num paths total               7450
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63134
evaluation_0/Rewards Std                      0.930942
evaluation_0/Rewards Max                      7.32336
evaluation_0/Rewards Min                     -0.649915
evaluation_0/Returns Mean                  4631.34
evaluation_0/Returns Std                     82.408
evaluation_0/Returns Max                   4765.98
evaluation_0/Returns Min                   4541.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4631.34
time/epoch (s)                                0
time/total (s)                             7962.04
Epoch                                       496
---------------------------------------  ----------------
2022-11-16 18:27:36.478348 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 497 finished
---------------------------------------  ----------------
epoch                                       497
total_step                               502000
replay_pool/size                         502000
trainer/alpha                                 0.064063
trainer/alpha_loss                           -0.441488
trainer/entropy                              -5.83932
trainer/qf_loss                              34.1979
trainer/policy_loss                        -308.941
trainer/adversary_policy_loss                14.6402
trainer/policy_loss_without_entropy         309.315
trainer/entropy_penalty                      -0.374085
trainer/entropy_percentage                   -0.0012094
trainer/Q1Pred Mean                         307.681
trainer/Q1Pred Std                           74.559
trainer/Q1Pred Max                          392.134
trainer/Q1Pred Min                            9.69431
trainer/Q2Pred Mean                         307.996
trainer/Q2Pred Std                           74.2892
trainer/Q2Pred Max                          394.081
trainer/Q2Pred Min                            9.27433
trainer/QTargetWithReg Mean                 306.773
trainer/QTargetWithReg Std                   74.5436
trainer/QTargetWithReg Max                  390.945
trainer/QTargetWithReg Min                    3.35982
trainer/PolicyLossWithoutReg Mean           309.315
trainer/PolicyLossWithoutReg Std             70.756
trainer/PolicyLossWithoutReg Max            392.255
trainer/PolicyLossWithoutReg Min             11.7868
exploration/num steps total              502000
exploration/num paths total                1265
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.42509
exploration/Rewards Std                       1.15828
exploration/Rewards Max                       6.53632
exploration/Rewards Min                      -0.644082
exploration/Returns Mean                   4425.09
exploration/Returns Std                       0
exploration/Returns Max                    4425.09
exploration/Returns Min                    4425.09
exploration/Num Paths                         1
exploration/Average Returns                4425.09
evaluation_0/num steps total                  3.86054e+06
evaluation_0/num paths total               7458
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.40934
evaluation_0/Rewards Std                      1.07181
evaluation_0/Rewards Max                      6.91345
evaluation_0/Rewards Min                     -0.701608
evaluation_0/Returns Mean                  4409.34
evaluation_0/Returns Std                    107.438
evaluation_0/Returns Max                   4528.49
evaluation_0/Returns Min                   4208.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4409.34
time/epoch (s)                                0
time/total (s)                             7973.49
Epoch                                       497
---------------------------------------  ----------------
2022-11-16 18:27:48.312269 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 498 finished
---------------------------------------  ----------------
epoch                                       498
total_step                               503000
replay_pool/size                         503000
trainer/alpha                                 0.0625175
trainer/alpha_loss                           -1.09439
trainer/entropy                              -5.60525
trainer/qf_loss                              25.0579
trainer/policy_loss                        -316.284
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.634
trainer/entropy_penalty                      -0.350427
trainer/entropy_percentage                   -0.00110672
trainer/Q1Pred Mean                         314.118
trainer/Q1Pred Std                           63.4886
trainer/Q1Pred Max                          392.986
trainer/Q1Pred Min                           13.32
trainer/Q2Pred Mean                         314.667
trainer/Q2Pred Std                           63.3821
trainer/Q2Pred Max                          391.731
trainer/Q2Pred Min                            9.10481
trainer/QTargetWithReg Mean                 314.731
trainer/QTargetWithReg Std                   63.438
trainer/QTargetWithReg Max                  394.51
trainer/QTargetWithReg Min                    0.126535
trainer/PolicyLossWithoutReg Mean           316.634
trainer/PolicyLossWithoutReg Std             60.657
trainer/PolicyLossWithoutReg Max            394.286
trainer/PolicyLossWithoutReg Min             11.595
exploration/num steps total              503000
exploration/num paths total                1266
exploration/path length this epoch Mean     968
exploration/path length this epoch Std        0
exploration/path length this epoch Max      968
exploration/path length this epoch Min      968
exploration/Rewards Mean                      4.51166
exploration/Rewards Std                       1.14399
exploration/Rewards Max                       6.91083
exploration/Rewards Min                      -0.458519
exploration/Returns Mean                   4367.29
exploration/Returns Std                       0
exploration/Returns Max                    4367.29
exploration/Returns Min                    4367.29
exploration/Num Paths                         1
exploration/Average Returns                4367.29
evaluation_0/num steps total                  3.86854e+06
evaluation_0/num paths total               7466
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.49251
evaluation_0/Rewards Std                      1.09843
evaluation_0/Rewards Max                      6.93913
evaluation_0/Rewards Min                     -0.880345
evaluation_0/Returns Mean                  4492.51
evaluation_0/Returns Std                     79.4249
evaluation_0/Returns Max                   4593.49
evaluation_0/Returns Min                   4325.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4492.51
time/epoch (s)                                0
time/total (s)                             7985.32
Epoch                                       498
---------------------------------------  ----------------
2022-11-16 18:27:59.657393 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 499 finished
---------------------------------------  ----------------
epoch                                       499
total_step                               504000
replay_pool/size                         504000
trainer/alpha                                 0.0640372
trainer/alpha_loss                            0.602608
trainer/entropy                              -6.21927
trainer/qf_loss                              26.1972
trainer/policy_loss                        -315.664
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.062
trainer/entropy_penalty                      -0.398264
trainer/entropy_percentage                   -0.00126008
trainer/Q1Pred Mean                         312.896
trainer/Q1Pred Std                           73.0937
trainer/Q1Pred Max                          392.424
trainer/Q1Pred Min                          -25.7474
trainer/Q2Pred Mean                         312.85
trainer/Q2Pred Std                           72.5286
trainer/Q2Pred Max                          392.025
trainer/Q2Pred Min                          -24.3758
trainer/QTargetWithReg Mean                 312.982
trainer/QTargetWithReg Std                   72.7547
trainer/QTargetWithReg Max                  389.373
trainer/QTargetWithReg Min                  -32.0386
trainer/PolicyLossWithoutReg Mean           316.062
trainer/PolicyLossWithoutReg Std             67.5266
trainer/PolicyLossWithoutReg Max            390.59
trainer/PolicyLossWithoutReg Min            -19.5428
exploration/num steps total              504000
exploration/num paths total                1267
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4035
exploration/Rewards Std                       1.23074
exploration/Rewards Max                       7.76677
exploration/Rewards Min                      -0.805459
exploration/Returns Mean                   4403.5
exploration/Returns Std                       0
exploration/Returns Max                    4403.5
exploration/Returns Min                    4403.5
exploration/Num Paths                         1
exploration/Average Returns                4403.5
evaluation_0/num steps total                  3.87654e+06
evaluation_0/num paths total               7474
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69593
evaluation_0/Rewards Std                      1.19239
evaluation_0/Rewards Max                      7.59947
evaluation_0/Rewards Min                     -0.605043
evaluation_0/Returns Mean                  4695.93
evaluation_0/Returns Std                     86.396
evaluation_0/Returns Max                   4814.2
evaluation_0/Returns Min                   4571.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4695.93
time/epoch (s)                                0
time/total (s)                             7996.67
Epoch                                       499
---------------------------------------  ----------------
2022-11-16 18:28:12.052298 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 500 finished
---------------------------------------  ----------------
epoch                                       500
total_step                               505000
replay_pool/size                         505000
trainer/alpha                                 0.0629608
trainer/alpha_loss                            0.159852
trainer/entropy                              -6.05781
trainer/qf_loss                              17.4919
trainer/policy_loss                        -307.533
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.914
trainer/entropy_penalty                      -0.381404
trainer/entropy_percentage                   -0.00123867
trainer/Q1Pred Mean                         306.871
trainer/Q1Pred Std                           67.4473
trainer/Q1Pred Max                          397.291
trainer/Q1Pred Min                           11.0452
trainer/Q2Pred Mean                         306.805
trainer/Q2Pred Std                           67.6206
trainer/Q2Pred Max                          398.528
trainer/Q2Pred Min                           10.8182
trainer/QTargetWithReg Mean                 307.298
trainer/QTargetWithReg Std                   67.3901
trainer/QTargetWithReg Max                  398.857
trainer/QTargetWithReg Min                    9.02191
trainer/PolicyLossWithoutReg Mean           307.914
trainer/PolicyLossWithoutReg Std             66.2498
trainer/PolicyLossWithoutReg Max            398.288
trainer/PolicyLossWithoutReg Min              4.20948
exploration/num steps total              505000
exploration/num paths total                1268
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41334
exploration/Rewards Std                       1.011
exploration/Rewards Max                       6.82903
exploration/Rewards Min                      -0.45163
exploration/Returns Mean                   4413.34
exploration/Returns Std                       0
exploration/Returns Max                    4413.34
exploration/Returns Min                    4413.34
exploration/Num Paths                         1
exploration/Average Returns                4413.34
evaluation_0/num steps total                  3.88396e+06
evaluation_0/num paths total               7482
evaluation_0/path length Mean               927.5
evaluation_0/path length Std                191.817
evaluation_0/path length Max               1000
evaluation_0/path length Min                420
evaluation_0/Rewards Mean                     4.55047
evaluation_0/Rewards Std                      1.17513
evaluation_0/Rewards Max                      8.6593
evaluation_0/Rewards Min                     -0.585781
evaluation_0/Returns Mean                  4220.56
evaluation_0/Returns Std                    982.95
evaluation_0/Returns Max                   4797.26
evaluation_0/Returns Min                   1660.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4220.56
time/epoch (s)                                0
time/total (s)                             8009.06
Epoch                                       500
---------------------------------------  ----------------
2022-11-16 18:28:25.322027 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 501 finished
---------------------------------------  ----------------
epoch                                       501
total_step                               506000
replay_pool/size                         506000
trainer/alpha                                 0.0645033
trainer/alpha_loss                           -0.518748
trainer/entropy                              -5.81073
trainer/qf_loss                              21.6579
trainer/policy_loss                        -312.261
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.636
trainer/entropy_penalty                      -0.374811
trainer/entropy_percentage                   -0.00119888
trainer/Q1Pred Mean                         311.977
trainer/Q1Pred Std                           65.5422
trainer/Q1Pred Max                          402.155
trainer/Q1Pred Min                          -11.0247
trainer/Q2Pred Mean                         311.899
trainer/Q2Pred Std                           66.0565
trainer/Q2Pred Max                          404.339
trainer/Q2Pred Min                           -7.86532
trainer/QTargetWithReg Mean                 312.04
trainer/QTargetWithReg Std                   65.9565
trainer/QTargetWithReg Max                  403.196
trainer/QTargetWithReg Min                    2.87288
trainer/PolicyLossWithoutReg Mean           312.636
trainer/PolicyLossWithoutReg Std             65.0309
trainer/PolicyLossWithoutReg Max            403.227
trainer/PolicyLossWithoutReg Min             -5.32958
exploration/num steps total              506000
exploration/num paths total                1269
exploration/path length this epoch Mean     515
exploration/path length this epoch Std        0
exploration/path length this epoch Max      515
exploration/path length this epoch Min      515
exploration/Rewards Mean                      4.11926
exploration/Rewards Std                       1.32602
exploration/Rewards Max                       6.18395
exploration/Rewards Min                      -0.772299
exploration/Returns Mean                   2121.42
exploration/Returns Std                       0
exploration/Returns Max                    2121.42
exploration/Returns Min                    2121.42
exploration/Num Paths                         1
exploration/Average Returns                2121.42
evaluation_0/num steps total                  3.89185e+06
evaluation_0/num paths total               7490
evaluation_0/path length Mean               986.875
evaluation_0/path length Std                 34.7255
evaluation_0/path length Max               1000
evaluation_0/path length Min                895
evaluation_0/Rewards Mean                     4.71989
evaluation_0/Rewards Std                      1.01284
evaluation_0/Rewards Max                      8.19655
evaluation_0/Rewards Min                     -0.59544
evaluation_0/Returns Mean                  4657.95
evaluation_0/Returns Std                    181.928
evaluation_0/Returns Max                   4807.24
evaluation_0/Returns Min                   4216.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4657.95
time/epoch (s)                                0
time/total (s)                             8022.33
Epoch                                       501
---------------------------------------  ----------------
2022-11-16 18:28:38.141221 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 502 finished
---------------------------------------  ----------------
epoch                                       502
total_step                               507000
replay_pool/size                         507000
trainer/alpha                                 0.0640068
trainer/alpha_loss                            0.898546
trainer/entropy                              -6.32689
trainer/qf_loss                              42.8095
trainer/policy_loss                        -309.683
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         310.088
trainer/entropy_penalty                      -0.404964
trainer/entropy_percentage                   -0.00130597
trainer/Q1Pred Mean                         309.366
trainer/Q1Pred Std                           72.2316
trainer/Q1Pred Max                          397.895
trainer/Q1Pred Min                            9.72575
trainer/Q2Pred Mean                         310.268
trainer/Q2Pred Std                           72.3857
trainer/Q2Pred Max                          400.401
trainer/Q2Pred Min                            7.657
trainer/QTargetWithReg Mean                 308.846
trainer/QTargetWithReg Std                   73.6125
trainer/QTargetWithReg Max                  398.16
trainer/QTargetWithReg Min                    3.67574
trainer/PolicyLossWithoutReg Mean           310.088
trainer/PolicyLossWithoutReg Std             71.0913
trainer/PolicyLossWithoutReg Max            397.515
trainer/PolicyLossWithoutReg Min              7.85801
exploration/num steps total              507000
exploration/num paths total                1270
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.34046
exploration/Rewards Std                       1.11584
exploration/Rewards Max                       6.79889
exploration/Rewards Min                      -0.611032
exploration/Returns Mean                   4340.46
exploration/Returns Std                       0
exploration/Returns Max                    4340.46
exploration/Returns Min                    4340.46
exploration/Num Paths                         1
exploration/Average Returns                4340.46
evaluation_0/num steps total                  3.89984e+06
evaluation_0/num paths total               7498
evaluation_0/path length Mean               998.125
evaluation_0/path length Std                  4.96078
evaluation_0/path length Max               1000
evaluation_0/path length Min                985
evaluation_0/Rewards Mean                     4.5023
evaluation_0/Rewards Std                      1.05964
evaluation_0/Rewards Max                      7.20058
evaluation_0/Rewards Min                     -0.744878
evaluation_0/Returns Mean                  4493.86
evaluation_0/Returns Std                     94.8597
evaluation_0/Returns Max                   4657.02
evaluation_0/Returns Min                   4341.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4493.86
time/epoch (s)                                0
time/total (s)                             8035.15
Epoch                                       502
---------------------------------------  ----------------
2022-11-16 18:28:49.292169 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 503 finished
---------------------------------------  ----------------
epoch                                       503
total_step                               508000
replay_pool/size                         508000
trainer/alpha                                 0.0624975
trainer/alpha_loss                            0.483904
trainer/entropy                              -6.17453
trainer/qf_loss                              25.2619
trainer/policy_loss                        -311.74
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.126
trainer/entropy_penalty                      -0.385893
trainer/entropy_percentage                   -0.00123634
trainer/Q1Pred Mean                         310.206
trainer/Q1Pred Std                           63.4254
trainer/Q1Pred Max                          407.197
trainer/Q1Pred Min                          -14.9431
trainer/Q2Pred Mean                         310.885
trainer/Q2Pred Std                           63.7989
trainer/Q2Pred Max                          406.832
trainer/Q2Pred Min                          -12.8641
trainer/QTargetWithReg Mean                 310.861
trainer/QTargetWithReg Std                   63.9645
trainer/QTargetWithReg Max                  410.154
trainer/QTargetWithReg Min                  -13.9523
trainer/PolicyLossWithoutReg Mean           312.126
trainer/PolicyLossWithoutReg Std             62.1586
trainer/PolicyLossWithoutReg Max            406.96
trainer/PolicyLossWithoutReg Min            -11.9972
exploration/num steps total              508000
exploration/num paths total                1271
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48963
exploration/Rewards Std                       1.10621
exploration/Rewards Max                       6.82773
exploration/Rewards Min                      -0.58367
exploration/Returns Mean                   4489.63
exploration/Returns Std                       0
exploration/Returns Max                    4489.63
exploration/Returns Min                    4489.63
exploration/Num Paths                         1
exploration/Average Returns                4489.63
evaluation_0/num steps total                  3.90784e+06
evaluation_0/num paths total               7506
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.45905
evaluation_0/Rewards Std                      0.97461
evaluation_0/Rewards Max                      6.75938
evaluation_0/Rewards Min                     -0.740178
evaluation_0/Returns Mean                  4459.05
evaluation_0/Returns Std                     93.2672
evaluation_0/Returns Max                   4587.72
evaluation_0/Returns Min                   4316.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4459.05
time/epoch (s)                                0
time/total (s)                             8046.3
Epoch                                       503
---------------------------------------  ----------------
2022-11-16 18:29:02.466938 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 504 finished
---------------------------------------  ----------------
epoch                                       504
total_step                               509000
replay_pool/size                         509000
trainer/alpha                                 0.0618368
trainer/alpha_loss                            0.473728
trainer/entropy                              -6.17021
trainer/qf_loss                              21.427
trainer/policy_loss                        -304.708
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.09
trainer/entropy_penalty                      -0.381546
trainer/entropy_percentage                   -0.0012506
trainer/Q1Pred Mean                         303.327
trainer/Q1Pred Std                           69.9125
trainer/Q1Pred Max                          397.618
trainer/Q1Pred Min                            0.58346
trainer/Q2Pred Mean                         303.73
trainer/Q2Pred Std                           69.7257
trainer/Q2Pred Max                          399.906
trainer/Q2Pred Min                           -3.62811
trainer/QTargetWithReg Mean                 303.638
trainer/QTargetWithReg Std                   69.6127
trainer/QTargetWithReg Max                  400.22
trainer/QTargetWithReg Min                    0.981722
trainer/PolicyLossWithoutReg Mean           305.09
trainer/PolicyLossWithoutReg Std             68.405
trainer/PolicyLossWithoutReg Max            399.613
trainer/PolicyLossWithoutReg Min             -0.853857
exploration/num steps total              509000
exploration/num paths total                1272
exploration/path length this epoch Mean     889
exploration/path length this epoch Std        0
exploration/path length this epoch Max      889
exploration/path length this epoch Min      889
exploration/Rewards Mean                      4.11165
exploration/Rewards Std                       1.18413
exploration/Rewards Max                       6.42934
exploration/Rewards Min                      -0.790425
exploration/Returns Mean                   3655.25
exploration/Returns Std                       0
exploration/Returns Max                    3655.25
exploration/Returns Min                    3655.25
exploration/Num Paths                         1
exploration/Average Returns                3655.25
evaluation_0/num steps total                  3.91584e+06
evaluation_0/num paths total               7514
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.55938
evaluation_0/Rewards Std                      1.09994
evaluation_0/Rewards Max                      7.26045
evaluation_0/Rewards Min                     -0.589044
evaluation_0/Returns Mean                  4559.38
evaluation_0/Returns Std                     77.8159
evaluation_0/Returns Max                   4668.91
evaluation_0/Returns Min                   4415.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4559.38
time/epoch (s)                                0
time/total (s)                             8059.47
Epoch                                       504
---------------------------------------  ----------------
2022-11-16 18:29:14.118082 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 505 finished
---------------------------------------  ----------------
epoch                                       505
total_step                               510000
replay_pool/size                         510000
trainer/alpha                                 0.0637796
trainer/alpha_loss                            1.33521
trainer/entropy                              -6.4851
trainer/qf_loss                              35.7171
trainer/policy_loss                        -308.599
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.013
trainer/entropy_penalty                      -0.413617
trainer/entropy_percentage                   -0.00133851
trainer/Q1Pred Mean                         307.771
trainer/Q1Pred Std                           73.7987
trainer/Q1Pred Max                          397.407
trainer/Q1Pred Min                            8.12417
trainer/Q2Pred Mean                         308.593
trainer/Q2Pred Std                           73.0767
trainer/Q2Pred Max                          398.949
trainer/Q2Pred Min                           13.4146
trainer/QTargetWithReg Mean                 308.445
trainer/QTargetWithReg Std                   73.1635
trainer/QTargetWithReg Max                  394.876
trainer/QTargetWithReg Min                   10.4964
trainer/PolicyLossWithoutReg Mean           309.013
trainer/PolicyLossWithoutReg Std             71.4515
trainer/PolicyLossWithoutReg Max            397.91
trainer/PolicyLossWithoutReg Min              8.81984
exploration/num steps total              510000
exploration/num paths total                1273
exploration/path length this epoch Mean     606
exploration/path length this epoch Std        0
exploration/path length this epoch Max      606
exploration/path length this epoch Min      606
exploration/Rewards Mean                      3.60112
exploration/Rewards Std                       1.3126
exploration/Rewards Max                       6.22222
exploration/Rewards Min                      -0.582217
exploration/Returns Mean                   2182.28
exploration/Returns Std                       0
exploration/Returns Max                    2182.28
exploration/Returns Min                    2182.28
exploration/Num Paths                         1
exploration/Average Returns                2182.28
evaluation_0/num steps total                  3.92384e+06
evaluation_0/num paths total               7522
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62768
evaluation_0/Rewards Std                      1.0716
evaluation_0/Rewards Max                      7.06745
evaluation_0/Rewards Min                     -0.840031
evaluation_0/Returns Mean                  4627.68
evaluation_0/Returns Std                     48.1219
evaluation_0/Returns Max                   4681.27
evaluation_0/Returns Min                   4538.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4627.68
time/epoch (s)                                0
time/total (s)                             8071.12
Epoch                                       505
---------------------------------------  ----------------
2022-11-16 18:29:25.189582 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 506 finished
---------------------------------------  ----------------
epoch                                       506
total_step                               511000
replay_pool/size                         511000
trainer/alpha                                 0.0638409
trainer/alpha_loss                           -0.924098
trainer/entropy                              -5.66411
trainer/qf_loss                              23.79
trainer/policy_loss                        -304.884
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.246
trainer/entropy_penalty                      -0.361602
trainer/entropy_percentage                   -0.00118463
trainer/Q1Pred Mean                         304.055
trainer/Q1Pred Std                           77.8604
trainer/Q1Pred Max                          399.347
trainer/Q1Pred Min                            5.0615
trainer/Q2Pred Mean                         304.145
trainer/Q2Pred Std                           78.0871
trainer/Q2Pred Max                          396.117
trainer/Q2Pred Min                            4.64708
trainer/QTargetWithReg Mean                 304.278
trainer/QTargetWithReg Std                   79.1131
trainer/QTargetWithReg Max                  396.288
trainer/QTargetWithReg Min                    0.245354
trainer/PolicyLossWithoutReg Mean           305.245
trainer/PolicyLossWithoutReg Std             76.2229
trainer/PolicyLossWithoutReg Max            396.063
trainer/PolicyLossWithoutReg Min              6.80288
exploration/num steps total              511000
exploration/num paths total                1274
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41293
exploration/Rewards Std                       0.995628
exploration/Rewards Max                       6.44937
exploration/Rewards Min                      -0.733618
exploration/Returns Mean                   4412.93
exploration/Returns Std                       0
exploration/Returns Max                    4412.93
exploration/Returns Min                    4412.93
exploration/Num Paths                         1
exploration/Average Returns                4412.93
evaluation_0/num steps total                  3.93184e+06
evaluation_0/num paths total               7530
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03335
evaluation_0/Rewards Std                      1.16313
evaluation_0/Rewards Max                      7.40982
evaluation_0/Rewards Min                     -0.565479
evaluation_0/Returns Mean                  5033.35
evaluation_0/Returns Std                     85.2808
evaluation_0/Returns Max                   5141.54
evaluation_0/Returns Min                   4913.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5033.35
time/epoch (s)                                0
time/total (s)                             8082.19
Epoch                                       506
---------------------------------------  ----------------
2022-11-16 18:29:38.312675 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 507 finished
---------------------------------------  ----------------
epoch                                       507
total_step                               512000
replay_pool/size                         512000
trainer/alpha                                 0.0629507
trainer/alpha_loss                            0.320881
trainer/entropy                              -6.11604
trainer/qf_loss                              23.4125
trainer/policy_loss                        -304.781
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.167
trainer/entropy_penalty                      -0.385009
trainer/entropy_percentage                   -0.00126164
trainer/Q1Pred Mean                         305.59
trainer/Q1Pred Std                           69.0345
trainer/Q1Pred Max                          398.87
trainer/Q1Pred Min                           15.9399
trainer/Q2Pred Mean                         304.428
trainer/Q2Pred Std                           69.7755
trainer/Q2Pred Max                          400.077
trainer/Q2Pred Min                           18.1589
trainer/QTargetWithReg Mean                 305.951
trainer/QTargetWithReg Std                   69.639
trainer/QTargetWithReg Max                  401.343
trainer/QTargetWithReg Min                   16.7766
trainer/PolicyLossWithoutReg Mean           305.166
trainer/PolicyLossWithoutReg Std             68.453
trainer/PolicyLossWithoutReg Max            397.551
trainer/PolicyLossWithoutReg Min             14.5821
exploration/num steps total              512000
exploration/num paths total                1275
exploration/path length this epoch Mean     927
exploration/path length this epoch Std        0
exploration/path length this epoch Max      927
exploration/path length this epoch Min      927
exploration/Rewards Mean                      4.53632
exploration/Rewards Std                       1.00325
exploration/Rewards Max                       7.01767
exploration/Rewards Min                      -0.513793
exploration/Returns Mean                   4205.17
exploration/Returns Std                       0
exploration/Returns Max                    4205.17
exploration/Returns Min                    4205.17
exploration/Num Paths                         1
exploration/Average Returns                4205.17
evaluation_0/num steps total                  3.93984e+06
evaluation_0/num paths total               7538
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62787
evaluation_0/Rewards Std                      0.964111
evaluation_0/Rewards Max                      7.17497
evaluation_0/Rewards Min                     -0.619657
evaluation_0/Returns Mean                  4627.87
evaluation_0/Returns Std                    124.46
evaluation_0/Returns Max                   4788.93
evaluation_0/Returns Min                   4438.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4627.87
time/epoch (s)                                0
time/total (s)                             8095.32
Epoch                                       507
---------------------------------------  ----------------
2022-11-16 18:29:50.252996 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 508 finished
---------------------------------------  ----------------
epoch                                       508
total_step                               513000
replay_pool/size                         513000
trainer/alpha                                 0.0645123
trainer/alpha_loss                           -1.62278
trainer/entropy                              -5.40788
trainer/qf_loss                              17.7677
trainer/policy_loss                        -317.846
trainer/adversary_policy_loss                15.1946
trainer/policy_loss_without_entropy         318.195
trainer/entropy_penalty                      -0.348875
trainer/entropy_percentage                   -0.00109642
trainer/Q1Pred Mean                         316.828
trainer/Q1Pred Std                           63.2187
trainer/Q1Pred Max                          400.317
trainer/Q1Pred Min                          -10.5416
trainer/Q2Pred Mean                         317.178
trainer/Q2Pred Std                           62.5852
trainer/Q2Pred Max                          400.514
trainer/Q2Pred Min                            0.00739843
trainer/QTargetWithReg Mean                 316.562
trainer/QTargetWithReg Std                   62.1715
trainer/QTargetWithReg Max                  398.856
trainer/QTargetWithReg Min                   -0.773239
trainer/PolicyLossWithoutReg Mean           318.195
trainer/PolicyLossWithoutReg Std             62.2138
trainer/PolicyLossWithoutReg Max            399.32
trainer/PolicyLossWithoutReg Min             -7.36814
exploration/num steps total              513000
exploration/num paths total                1276
exploration/path length this epoch Mean     962
exploration/path length this epoch Std        0
exploration/path length this epoch Max      962
exploration/path length this epoch Min      962
exploration/Rewards Mean                      4.21674
exploration/Rewards Std                       1.07176
exploration/Rewards Max                       6.78109
exploration/Rewards Min                      -0.528763
exploration/Returns Mean                   4056.5
exploration/Returns Std                       0
exploration/Returns Max                    4056.5
exploration/Returns Min                    4056.5
exploration/Num Paths                         1
exploration/Average Returns                4056.5
evaluation_0/num steps total                  3.94784e+06
evaluation_0/num paths total               7546
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.51904
evaluation_0/Rewards Std                      1.06525
evaluation_0/Rewards Max                      7.07519
evaluation_0/Rewards Min                     -0.812654
evaluation_0/Returns Mean                  4519.04
evaluation_0/Returns Std                    168.439
evaluation_0/Returns Max                   4729.71
evaluation_0/Returns Min                   4196.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4519.04
time/epoch (s)                                0
time/total (s)                             8107.26
Epoch                                       508
---------------------------------------  ----------------
2022-11-16 18:30:01.612039 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 509 finished
---------------------------------------  ----------------
epoch                                       509
total_step                               514000
replay_pool/size                         514000
trainer/alpha                                 0.0644289
trainer/alpha_loss                           -0.0657941
trainer/entropy                              -5.97601
trainer/qf_loss                              25.6835
trainer/policy_loss                        -304.849
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         305.235
trainer/entropy_penalty                      -0.385028
trainer/entropy_percentage                   -0.00126142
trainer/Q1Pred Mean                         304.13
trainer/Q1Pred Std                           73.6911
trainer/Q1Pred Max                          403.334
trainer/Q1Pred Min                          -22.2699
trainer/Q2Pred Mean                         304.23
trainer/Q2Pred Std                           73.1878
trainer/Q2Pred Max                          402.468
trainer/Q2Pred Min                           -8.59242
trainer/QTargetWithReg Mean                 304.464
trainer/QTargetWithReg Std                   73.7855
trainer/QTargetWithReg Max                  403.026
trainer/QTargetWithReg Min                  -16.0915
trainer/PolicyLossWithoutReg Mean           305.235
trainer/PolicyLossWithoutReg Std             72.8312
trainer/PolicyLossWithoutReg Max            403.495
trainer/PolicyLossWithoutReg Min            -13.7567
exploration/num steps total              514000
exploration/num paths total                1277
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55043
exploration/Rewards Std                       1.25894
exploration/Rewards Max                       7.78843
exploration/Rewards Min                      -0.684521
exploration/Returns Mean                   4550.43
exploration/Returns Std                       0
exploration/Returns Max                    4550.43
exploration/Returns Min                    4550.43
exploration/Num Paths                         1
exploration/Average Returns                4550.43
evaluation_0/num steps total                  3.95584e+06
evaluation_0/num paths total               7554
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.54983
evaluation_0/Rewards Std                      1.17562
evaluation_0/Rewards Max                      7.35547
evaluation_0/Rewards Min                     -0.770783
evaluation_0/Returns Mean                  4549.83
evaluation_0/Returns Std                     88.0972
evaluation_0/Returns Max                   4665.32
evaluation_0/Returns Min                   4380.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4549.83
time/epoch (s)                                0
time/total (s)                             8118.62
Epoch                                       509
---------------------------------------  ----------------
2022-11-16 18:30:14.393601 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 510 finished
---------------------------------------  ----------------
epoch                                       510
total_step                               515000
replay_pool/size                         515000
trainer/alpha                                 0.063295
trainer/alpha_loss                            1.02793
trainer/entropy                              -6.37245
trainer/qf_loss                              28.3605
trainer/policy_loss                        -309.376
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         309.78
trainer/entropy_penalty                      -0.403344
trainer/entropy_percentage                   -0.00130204
trainer/Q1Pred Mean                         308.765
trainer/Q1Pred Std                           60.3374
trainer/Q1Pred Max                          401.111
trainer/Q1Pred Min                           42.2678
trainer/Q2Pred Mean                         309.078
trainer/Q2Pred Std                           60.3024
trainer/Q2Pred Max                          400.745
trainer/Q2Pred Min                           41.1054
trainer/QTargetWithReg Mean                 308.545
trainer/QTargetWithReg Std                   60.9394
trainer/QTargetWithReg Max                  400.71
trainer/QTargetWithReg Min                   39.4542
trainer/PolicyLossWithoutReg Mean           309.78
trainer/PolicyLossWithoutReg Std             59.0487
trainer/PolicyLossWithoutReg Max            399.158
trainer/PolicyLossWithoutReg Min             39.7303
exploration/num steps total              515000
exploration/num paths total                1278
exploration/path length this epoch Mean     347
exploration/path length this epoch Std        0
exploration/path length this epoch Max      347
exploration/path length this epoch Min      347
exploration/Rewards Mean                      3.21222
exploration/Rewards Std                       1.31792
exploration/Rewards Max                       5.91462
exploration/Rewards Min                      -0.68518
exploration/Returns Mean                   1114.64
exploration/Returns Std                       0
exploration/Returns Max                    1114.64
exploration/Returns Min                    1114.64
exploration/Num Paths                         1
exploration/Average Returns                1114.64
evaluation_0/num steps total                  3.96384e+06
evaluation_0/num paths total               7562
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83732
evaluation_0/Rewards Std                      1.11648
evaluation_0/Rewards Max                      7.957
evaluation_0/Rewards Min                     -0.740211
evaluation_0/Returns Mean                  4837.32
evaluation_0/Returns Std                     70.9551
evaluation_0/Returns Max                   4927.02
evaluation_0/Returns Min                   4690.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4837.32
time/epoch (s)                                0
time/total (s)                             8131.4
Epoch                                       510
---------------------------------------  ----------------
2022-11-16 18:30:26.014226 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 511 finished
---------------------------------------  ----------------
epoch                                       511
total_step                               516000
replay_pool/size                         516000
trainer/alpha                                 0.0628546
trainer/alpha_loss                            0.833295
trainer/entropy                              -6.30113
trainer/qf_loss                              26.094
trainer/policy_loss                        -312.346
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.742
trainer/entropy_penalty                      -0.396056
trainer/entropy_percentage                   -0.0012664
trainer/Q1Pred Mean                         311.58
trainer/Q1Pred Std                           69.0125
trainer/Q1Pred Max                          396.21
trainer/Q1Pred Min                           -4.02228
trainer/Q2Pred Mean                         311.593
trainer/Q2Pred Std                           69.0049
trainer/Q2Pred Max                          391.718
trainer/Q2Pred Min                            2.05808
trainer/QTargetWithReg Mean                 310.78
trainer/QTargetWithReg Std                   69.6937
trainer/QTargetWithReg Max                  389.691
trainer/QTargetWithReg Min                  -12.5623
trainer/PolicyLossWithoutReg Mean           312.742
trainer/PolicyLossWithoutReg Std             68.0638
trainer/PolicyLossWithoutReg Max            395.363
trainer/PolicyLossWithoutReg Min             -1.16228
exploration/num steps total              516000
exploration/num paths total                1279
exploration/path length this epoch Mean     723
exploration/path length this epoch Std        0
exploration/path length this epoch Max      723
exploration/path length this epoch Min      723
exploration/Rewards Mean                      4.46608
exploration/Rewards Std                       1.1866
exploration/Rewards Max                       6.80242
exploration/Rewards Min                      -0.343308
exploration/Returns Mean                   3228.98
exploration/Returns Std                       0
exploration/Returns Max                    3228.98
exploration/Returns Min                    3228.98
exploration/Num Paths                         1
exploration/Average Returns                3228.98
evaluation_0/num steps total                  3.97184e+06
evaluation_0/num paths total               7570
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76823
evaluation_0/Rewards Std                      1.02228
evaluation_0/Rewards Max                      7.16334
evaluation_0/Rewards Min                     -0.605343
evaluation_0/Returns Mean                  4768.23
evaluation_0/Returns Std                     85.175
evaluation_0/Returns Max                   4926.08
evaluation_0/Returns Min                   4656.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4768.23
time/epoch (s)                                0
time/total (s)                             8143.02
Epoch                                       511
---------------------------------------  ----------------
2022-11-16 18:30:37.171522 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 512 finished
---------------------------------------  ----------------
epoch                                       512
total_step                               517000
replay_pool/size                         517000
trainer/alpha                                 0.0626679
trainer/alpha_loss                            0.0325215
trainer/entropy                              -6.01174
trainer/qf_loss                              17.458
trainer/policy_loss                        -313.276
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.653
trainer/entropy_penalty                      -0.376743
trainer/entropy_percentage                   -0.00120115
trainer/Q1Pred Mean                         312.274
trainer/Q1Pred Std                           69.9051
trainer/Q1Pred Max                          405.108
trainer/Q1Pred Min                            2.92713
trainer/Q2Pred Mean                         312.055
trainer/Q2Pred Std                           70.1687
trainer/Q2Pred Max                          405.994
trainer/Q2Pred Min                           -6.98172
trainer/QTargetWithReg Mean                 311.085
trainer/QTargetWithReg Std                   69.9979
trainer/QTargetWithReg Max                  404.794
trainer/QTargetWithReg Min                   -0.304086
trainer/PolicyLossWithoutReg Mean           313.653
trainer/PolicyLossWithoutReg Std             66.6889
trainer/PolicyLossWithoutReg Max            404.712
trainer/PolicyLossWithoutReg Min             15.7355
exploration/num steps total              517000
exploration/num paths total                1281
exploration/path length this epoch Mean     361
exploration/path length this epoch Std      333
exploration/path length this epoch Max      694
exploration/path length this epoch Min       28
exploration/Rewards Mean                      4.02615
exploration/Rewards Std                       1.36816
exploration/Rewards Max                       6.656
exploration/Rewards Min                      -0.747563
exploration/Returns Mean                   1453.44
exploration/Returns Std                    1433.52
exploration/Returns Max                    2886.96
exploration/Returns Min                      19.9185
exploration/Num Paths                         2
exploration/Average Returns                1453.44
evaluation_0/num steps total                  3.97984e+06
evaluation_0/num paths total               7578
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.51901
evaluation_0/Rewards Std                      1.02757
evaluation_0/Rewards Max                      7.02223
evaluation_0/Rewards Min                     -0.848689
evaluation_0/Returns Mean                  4519.01
evaluation_0/Returns Std                     90.9176
evaluation_0/Returns Max                   4683.89
evaluation_0/Returns Min                   4419.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4519.01
time/epoch (s)                                0
time/total (s)                             8154.17
Epoch                                       512
---------------------------------------  ----------------
2022-11-16 18:30:50.172276 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 513 finished
---------------------------------------  ----------------
epoch                                       513
total_step                               518000
replay_pool/size                         518000
trainer/alpha                                 0.0609916
trainer/alpha_loss                           -0.356589
trainer/entropy                              -5.87251
trainer/qf_loss                              25.8593
trainer/policy_loss                        -312.569
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         312.927
trainer/entropy_penalty                      -0.358174
trainer/entropy_percentage                   -0.00114459
trainer/Q1Pred Mean                         312.009
trainer/Q1Pred Std                           58.3293
trainer/Q1Pred Max                          401.134
trainer/Q1Pred Min                           48.9043
trainer/Q2Pred Mean                         311.739
trainer/Q2Pred Std                           58.0028
trainer/Q2Pred Max                          398.924
trainer/Q2Pred Min                           45.8667
trainer/QTargetWithReg Mean                 312.371
trainer/QTargetWithReg Std                   58.3975
trainer/QTargetWithReg Max                  401.693
trainer/QTargetWithReg Min                   49.3766
trainer/PolicyLossWithoutReg Mean           312.927
trainer/PolicyLossWithoutReg Std             57.0298
trainer/PolicyLossWithoutReg Max            399.498
trainer/PolicyLossWithoutReg Min             51.7007
exploration/num steps total              518000
exploration/num paths total                1282
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.89487
exploration/Rewards Std                       1.13804
exploration/Rewards Max                       7.01655
exploration/Rewards Min                      -0.809553
exploration/Returns Mean                   3894.87
exploration/Returns Std                       0
exploration/Returns Max                    3894.87
exploration/Returns Min                    3894.87
exploration/Num Paths                         1
exploration/Average Returns                3894.87
evaluation_0/num steps total                  3.98784e+06
evaluation_0/num paths total               7586
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74701
evaluation_0/Rewards Std                      0.964266
evaluation_0/Rewards Max                      7.13974
evaluation_0/Rewards Min                     -0.559971
evaluation_0/Returns Mean                  4747.01
evaluation_0/Returns Std                     87.7138
evaluation_0/Returns Max                   4905.99
evaluation_0/Returns Min                   4588.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4747.01
time/epoch (s)                                0
time/total (s)                             8167.18
Epoch                                       513
---------------------------------------  ----------------
2022-11-16 18:31:02.071025 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 514 finished
---------------------------------------  ----------------
epoch                                       514
total_step                               519000
replay_pool/size                         519000
trainer/alpha                                 0.0638122
trainer/alpha_loss                            0.0225409
trainer/entropy                              -6.00819
trainer/qf_loss                              24.1545
trainer/policy_loss                        -310.703
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         311.087
trainer/entropy_penalty                      -0.383396
trainer/entropy_percentage                   -0.00123244
trainer/Q1Pred Mean                         310.262
trainer/Q1Pred Std                           61.4858
trainer/Q1Pred Max                          402.645
trainer/Q1Pred Min                            9.45474
trainer/Q2Pred Mean                         310.31
trainer/Q2Pred Std                           61.7422
trainer/Q2Pred Max                          402.011
trainer/Q2Pred Min                            8.97465
trainer/QTargetWithReg Mean                 310.374
trainer/QTargetWithReg Std                   62.2537
trainer/QTargetWithReg Max                  403.33
trainer/QTargetWithReg Min                    5.69717
trainer/PolicyLossWithoutReg Mean           311.087
trainer/PolicyLossWithoutReg Std             61.0699
trainer/PolicyLossWithoutReg Max            402.735
trainer/PolicyLossWithoutReg Min              8.78782
exploration/num steps total              519000
exploration/num paths total                1283
exploration/path length this epoch Mean     898
exploration/path length this epoch Std        0
exploration/path length this epoch Max      898
exploration/path length this epoch Min      898
exploration/Rewards Mean                      4.3097
exploration/Rewards Std                       0.997391
exploration/Rewards Max                       6.85421
exploration/Rewards Min                      -0.377785
exploration/Returns Mean                   3870.11
exploration/Returns Std                       0
exploration/Returns Max                    3870.11
exploration/Returns Min                    3870.11
exploration/Num Paths                         1
exploration/Average Returns                3870.11
evaluation_0/num steps total                  3.99584e+06
evaluation_0/num paths total               7594
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57569
evaluation_0/Rewards Std                      1.01143
evaluation_0/Rewards Max                      7.42325
evaluation_0/Rewards Min                     -0.390758
evaluation_0/Returns Mean                  4575.69
evaluation_0/Returns Std                     59.7957
evaluation_0/Returns Max                   4693.08
evaluation_0/Returns Min                   4524.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4575.69
time/epoch (s)                                0
time/total (s)                             8179.07
Epoch                                       514
---------------------------------------  ----------------
2022-11-16 18:31:14.724671 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 515 finished
---------------------------------------  ----------------
epoch                                       515
total_step                               520000
replay_pool/size                         520000
trainer/alpha                                 0.0622897
trainer/alpha_loss                           -0.0319074
trainer/entropy                              -5.98851
trainer/qf_loss                              24.7828
trainer/policy_loss                        -314.729
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.102
trainer/entropy_penalty                      -0.373022
trainer/entropy_percentage                   -0.00118381
trainer/Q1Pred Mean                         313.516
trainer/Q1Pred Std                           59.157
trainer/Q1Pred Max                          399.658
trainer/Q1Pred Min                           29.2893
trainer/Q2Pred Mean                         314.036
trainer/Q2Pred Std                           58.4941
trainer/Q2Pred Max                          400.004
trainer/Q2Pred Min                           34.3248
trainer/QTargetWithReg Mean                 314.228
trainer/QTargetWithReg Std                   59.273
trainer/QTargetWithReg Max                  400.534
trainer/QTargetWithReg Min                   38.1136
trainer/PolicyLossWithoutReg Mean           315.102
trainer/PolicyLossWithoutReg Std             56.9911
trainer/PolicyLossWithoutReg Max            400.514
trainer/PolicyLossWithoutReg Min             38.081
exploration/num steps total              520000
exploration/num paths total                1285
exploration/path length this epoch Mean     360.5
exploration/path length this epoch Std       42.5
exploration/path length this epoch Max      403
exploration/path length this epoch Min      318
exploration/Rewards Mean                      3.88464
exploration/Rewards Std                       1.25901
exploration/Rewards Max                       6.22471
exploration/Rewards Min                      -0.525651
exploration/Returns Mean                   1400.41
exploration/Returns Std                     159.249
exploration/Returns Max                    1559.66
exploration/Returns Min                    1241.16
exploration/Num Paths                         2
exploration/Average Returns                1400.41
evaluation_0/num steps total                  4.00384e+06
evaluation_0/num paths total               7602
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75059
evaluation_0/Rewards Std                      0.999862
evaluation_0/Rewards Max                      7.11695
evaluation_0/Rewards Min                     -0.537161
evaluation_0/Returns Mean                  4750.59
evaluation_0/Returns Std                     82.5266
evaluation_0/Returns Max                   4872.99
evaluation_0/Returns Min                   4615.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4750.59
time/epoch (s)                                0
time/total (s)                             8191.73
Epoch                                       515
---------------------------------------  ----------------
2022-11-16 18:31:27.429714 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 516 finished
---------------------------------------  ----------------
epoch                                       516
total_step                               521000
replay_pool/size                         521000
trainer/alpha                                 0.0630837
trainer/alpha_loss                            0.902705
trainer/entropy                              -6.32666
trainer/qf_loss                              30.4192
trainer/policy_loss                        -313.981
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.381
trainer/entropy_penalty                      -0.399109
trainer/entropy_percentage                   -0.00126951
trainer/Q1Pred Mean                         312.261
trainer/Q1Pred Std                           64.802
trainer/Q1Pred Max                          400.102
trainer/Q1Pred Min                           16.1049
trainer/Q2Pred Mean                         312.652
trainer/Q2Pred Std                           64.9036
trainer/Q2Pred Max                          400.765
trainer/Q2Pred Min                           14.7571
trainer/QTargetWithReg Mean                 312.605
trainer/QTargetWithReg Std                   65.5141
trainer/QTargetWithReg Max                  402.455
trainer/QTargetWithReg Min                  -14.7746
trainer/PolicyLossWithoutReg Mean           314.381
trainer/PolicyLossWithoutReg Std             61.5478
trainer/PolicyLossWithoutReg Max            398.857
trainer/PolicyLossWithoutReg Min             15.7572
exploration/num steps total              521000
exploration/num paths total                1286
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69566
exploration/Rewards Std                       1.08647
exploration/Rewards Max                       7.07761
exploration/Rewards Min                      -0.44681
exploration/Returns Mean                   4695.66
exploration/Returns Std                       0
exploration/Returns Max                    4695.66
exploration/Returns Min                    4695.66
exploration/Num Paths                         1
exploration/Average Returns                4695.66
evaluation_0/num steps total                  4.01184e+06
evaluation_0/num paths total               7610
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64953
evaluation_0/Rewards Std                      1.09144
evaluation_0/Rewards Max                      7.09497
evaluation_0/Rewards Min                     -0.62534
evaluation_0/Returns Mean                  4649.53
evaluation_0/Returns Std                     82.0132
evaluation_0/Returns Max                   4815.97
evaluation_0/Returns Min                   4531.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4649.53
time/epoch (s)                                0
time/total (s)                             8204.43
Epoch                                       516
---------------------------------------  ----------------
2022-11-16 18:31:39.426476 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 517 finished
---------------------------------------  ----------------
epoch                                       517
total_step                               522000
replay_pool/size                         522000
trainer/alpha                                 0.0628517
trainer/alpha_loss                           -0.270576
trainer/entropy                              -5.90221
trainer/qf_loss                              20.1068
trainer/policy_loss                        -308.007
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         308.378
trainer/entropy_penalty                      -0.370964
trainer/entropy_percentage                   -0.00120295
trainer/Q1Pred Mean                         307.629
trainer/Q1Pred Std                           67.2409
trainer/Q1Pred Max                          391.532
trainer/Q1Pred Min                          -18.9561
trainer/Q2Pred Mean                         307.261
trainer/Q2Pred Std                           66.8492
trainer/Q2Pred Max                          391.286
trainer/Q2Pred Min                          -20.8049
trainer/QTargetWithReg Mean                 306.982
trainer/QTargetWithReg Std                   66.0472
trainer/QTargetWithReg Max                  393.846
trainer/QTargetWithReg Min                   -1.74884
trainer/PolicyLossWithoutReg Mean           308.378
trainer/PolicyLossWithoutReg Std             64.3898
trainer/PolicyLossWithoutReg Max            394.109
trainer/PolicyLossWithoutReg Min            -19.8855
exploration/num steps total              522000
exploration/num paths total                1287
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5267
exploration/Rewards Std                       1.05054
exploration/Rewards Max                       6.82159
exploration/Rewards Min                      -0.580958
exploration/Returns Mean                   4526.7
exploration/Returns Std                       0
exploration/Returns Max                    4526.7
exploration/Returns Min                    4526.7
exploration/Num Paths                         1
exploration/Average Returns                4526.7
evaluation_0/num steps total                  4.01984e+06
evaluation_0/num paths total               7618
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7532
evaluation_0/Rewards Std                      1.04048
evaluation_0/Rewards Max                      7.23713
evaluation_0/Rewards Min                     -0.900195
evaluation_0/Returns Mean                  4753.2
evaluation_0/Returns Std                    101.302
evaluation_0/Returns Max                   4895.54
evaluation_0/Returns Min                   4621.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4753.2
time/epoch (s)                                0
time/total (s)                             8216.43
Epoch                                       517
---------------------------------------  ----------------
2022-11-16 18:31:51.089714 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 518 finished
---------------------------------------  ----------------
epoch                                       518
total_step                               523000
replay_pool/size                         523000
trainer/alpha                                 0.0624549
trainer/alpha_loss                            0.82265
trainer/entropy                              -6.29664
trainer/qf_loss                              18.4219
trainer/policy_loss                        -315.257
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.651
trainer/entropy_penalty                      -0.393256
trainer/entropy_percentage                   -0.00124586
trainer/Q1Pred Mean                         314.402
trainer/Q1Pred Std                           59.5977
trainer/Q1Pred Max                          403.551
trainer/Q1Pred Min                           34.2018
trainer/Q2Pred Mean                         314.711
trainer/Q2Pred Std                           59.4985
trainer/Q2Pred Max                          404.088
trainer/Q2Pred Min                           33.9132
trainer/QTargetWithReg Mean                 314.308
trainer/QTargetWithReg Std                   59.1174
trainer/QTargetWithReg Max                  403.337
trainer/QTargetWithReg Min                   36.7842
trainer/PolicyLossWithoutReg Mean           315.651
trainer/PolicyLossWithoutReg Std             58.189
trainer/PolicyLossWithoutReg Max            404.37
trainer/PolicyLossWithoutReg Min             40.1019
exploration/num steps total              523000
exploration/num paths total                1288
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60583
exploration/Rewards Std                       1.07184
exploration/Rewards Max                       6.78466
exploration/Rewards Min                      -0.75384
exploration/Returns Mean                   4605.83
exploration/Returns Std                       0
exploration/Returns Max                    4605.83
exploration/Returns Min                    4605.83
exploration/Num Paths                         1
exploration/Average Returns                4605.83
evaluation_0/num steps total                  4.02784e+06
evaluation_0/num paths total               7626
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76864
evaluation_0/Rewards Std                      0.987684
evaluation_0/Rewards Max                      7.14699
evaluation_0/Rewards Min                     -0.749389
evaluation_0/Returns Mean                  4768.64
evaluation_0/Returns Std                    138.879
evaluation_0/Returns Max                   4968.67
evaluation_0/Returns Min                   4590.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4768.64
time/epoch (s)                                0
time/total (s)                             8228.09
Epoch                                       518
---------------------------------------  ----------------
2022-11-16 18:32:05.491626 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 519 finished
---------------------------------------  ----------------
epoch                                       519
total_step                               524000
replay_pool/size                         524000
trainer/alpha                                 0.0649141
trainer/alpha_loss                            0.887783
trainer/entropy                              -6.32463
trainer/qf_loss                              22.7408
trainer/policy_loss                        -310.498
trainer/adversary_policy_loss                14.7249
trainer/policy_loss_without_entropy         310.909
trainer/entropy_penalty                      -0.410557
trainer/entropy_percentage                   -0.00132051
trainer/Q1Pred Mean                         310.5
trainer/Q1Pred Std                           76.6119
trainer/Q1Pred Max                          398.193
trainer/Q1Pred Min                          -13.0676
trainer/Q2Pred Mean                         310.103
trainer/Q2Pred Std                           76.4668
trainer/Q2Pred Max                          398.476
trainer/Q2Pred Min                           -4.1932
trainer/QTargetWithReg Mean                 310.472
trainer/QTargetWithReg Std                   76.8564
trainer/QTargetWithReg Max                  398.507
trainer/QTargetWithReg Min                   -8.82924
trainer/PolicyLossWithoutReg Mean           310.909
trainer/PolicyLossWithoutReg Std             75.7117
trainer/PolicyLossWithoutReg Max            397.311
trainer/PolicyLossWithoutReg Min            -11.1645
exploration/num steps total              524000
exploration/num paths total                1289
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78222
exploration/Rewards Std                       1.14505
exploration/Rewards Max                       6.98637
exploration/Rewards Min                      -0.854255
exploration/Returns Mean                   4782.22
exploration/Returns Std                       0
exploration/Returns Max                    4782.22
exploration/Returns Min                    4782.22
exploration/Num Paths                         1
exploration/Average Returns                4782.22
evaluation_0/num steps total                  4.03584e+06
evaluation_0/num paths total               7634
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.54393
evaluation_0/Rewards Std                      0.948221
evaluation_0/Rewards Max                      6.88927
evaluation_0/Rewards Min                     -0.594305
evaluation_0/Returns Mean                  4543.93
evaluation_0/Returns Std                     74.8051
evaluation_0/Returns Max                   4700.17
evaluation_0/Returns Min                   4470.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4543.93
time/epoch (s)                                0
time/total (s)                             8242.49
Epoch                                       519
---------------------------------------  ----------------
2022-11-16 18:32:18.484574 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 520 finished
---------------------------------------  ----------------
epoch                                       520
total_step                               525000
replay_pool/size                         525000
trainer/alpha                                 0.0642349
trainer/alpha_loss                            0.543362
trainer/entropy                              -6.19792
trainer/qf_loss                              25.9693
trainer/policy_loss                        -317.886
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         318.284
trainer/entropy_penalty                      -0.398123
trainer/entropy_percentage                   -0.00125084
trainer/Q1Pred Mean                         317.577
trainer/Q1Pred Std                           56.4685
trainer/Q1Pred Max                          400.482
trainer/Q1Pred Min                           57.1058
trainer/Q2Pred Mean                         318.274
trainer/Q2Pred Std                           55.7398
trainer/Q2Pred Max                          400.298
trainer/Q2Pred Min                           62.893
trainer/QTargetWithReg Mean                 318.696
trainer/QTargetWithReg Std                   56.1121
trainer/QTargetWithReg Max                  401.239
trainer/QTargetWithReg Min                   63.355
trainer/PolicyLossWithoutReg Mean           318.284
trainer/PolicyLossWithoutReg Std             55.4843
trainer/PolicyLossWithoutReg Max            399.486
trainer/PolicyLossWithoutReg Min             60.349
exploration/num steps total              525000
exploration/num paths total                1290
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66105
exploration/Rewards Std                       1.03434
exploration/Rewards Max                       6.4464
exploration/Rewards Min                      -0.723854
exploration/Returns Mean                   4661.05
exploration/Returns Std                       0
exploration/Returns Max                    4661.05
exploration/Returns Min                    4661.05
exploration/Num Paths                         1
exploration/Average Returns                4661.05
evaluation_0/num steps total                  4.04384e+06
evaluation_0/num paths total               7642
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.4131
evaluation_0/Rewards Std                      0.881387
evaluation_0/Rewards Max                      7.06789
evaluation_0/Rewards Min                     -0.911103
evaluation_0/Returns Mean                  4413.1
evaluation_0/Returns Std                    200.592
evaluation_0/Returns Max                   4823.25
evaluation_0/Returns Min                   4214.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4413.1
time/epoch (s)                                0
time/total (s)                             8255.49
Epoch                                       520
---------------------------------------  ----------------
2022-11-16 18:32:31.616461 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 521 finished
---------------------------------------  ----------------
epoch                                       521
total_step                               526000
replay_pool/size                         526000
trainer/alpha                                 0.0626287
trainer/alpha_loss                           -0.18113
trainer/entropy                              -5.93462
trainer/qf_loss                              21.4388
trainer/policy_loss                        -311.229
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         311.6
trainer/entropy_penalty                      -0.371678
trainer/entropy_percentage                   -0.0011928
trainer/Q1Pred Mean                         309.454
trainer/Q1Pred Std                           68.007
trainer/Q1Pred Max                          398.671
trainer/Q1Pred Min                           -3.35202
trainer/Q2Pred Mean                         309.474
trainer/Q2Pred Std                           68.0181
trainer/Q2Pred Max                          397.713
trainer/Q2Pred Min                            5.4876
trainer/QTargetWithReg Mean                 310.389
trainer/QTargetWithReg Std                   67.5941
trainer/QTargetWithReg Max                  400.383
trainer/QTargetWithReg Min                    0.267489
trainer/PolicyLossWithoutReg Mean           311.6
trainer/PolicyLossWithoutReg Std             64.6112
trainer/PolicyLossWithoutReg Max            398.382
trainer/PolicyLossWithoutReg Min             17.8676
exploration/num steps total              526000
exploration/num paths total                1291
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.23114
exploration/Rewards Std                       1.06311
exploration/Rewards Max                       7.18611
exploration/Rewards Min                      -0.660975
exploration/Returns Mean                   4231.14
exploration/Returns Std                       0
exploration/Returns Max                    4231.14
exploration/Returns Min                    4231.14
exploration/Num Paths                         1
exploration/Average Returns                4231.14
evaluation_0/num steps total                  4.05184e+06
evaluation_0/num paths total               7650
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83263
evaluation_0/Rewards Std                      1.03841
evaluation_0/Rewards Max                      7.15315
evaluation_0/Rewards Min                     -0.769466
evaluation_0/Returns Mean                  4832.63
evaluation_0/Returns Std                     52.3199
evaluation_0/Returns Max                   4893.4
evaluation_0/Returns Min                   4762.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4832.63
time/epoch (s)                                0
time/total (s)                             8268.62
Epoch                                       521
---------------------------------------  ----------------
2022-11-16 18:32:45.825927 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 522 finished
---------------------------------------  ----------------
epoch                                       522
total_step                               527000
replay_pool/size                         527000
trainer/alpha                                 0.0649259
trainer/alpha_loss                            0.352516
trainer/entropy                              -6.12891
trainer/qf_loss                              22.6541
trainer/policy_loss                        -314.128
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.526
trainer/entropy_penalty                      -0.397925
trainer/entropy_percentage                   -0.00126516
trainer/Q1Pred Mean                         314.214
trainer/Q1Pred Std                           56.1095
trainer/Q1Pred Max                          397.753
trainer/Q1Pred Min                           19.4935
trainer/Q2Pred Mean                         314.113
trainer/Q2Pred Std                           56.0426
trainer/Q2Pred Max                          397.706
trainer/Q2Pred Min                           14.5373
trainer/QTargetWithReg Mean                 312.89
trainer/QTargetWithReg Std                   55.9243
trainer/QTargetWithReg Max                  395.733
trainer/QTargetWithReg Min                   13.5153
trainer/PolicyLossWithoutReg Mean           314.526
trainer/PolicyLossWithoutReg Std             55.6306
trainer/PolicyLossWithoutReg Max            396.982
trainer/PolicyLossWithoutReg Min             13.0716
exploration/num steps total              527000
exploration/num paths total                1292
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48382
exploration/Rewards Std                       1.25537
exploration/Rewards Max                       6.72024
exploration/Rewards Min                      -0.820275
exploration/Returns Mean                   4483.82
exploration/Returns Std                       0
exploration/Returns Max                    4483.82
exploration/Returns Min                    4483.82
exploration/Num Paths                         1
exploration/Average Returns                4483.82
evaluation_0/num steps total                  4.05984e+06
evaluation_0/num paths total               7658
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73291
evaluation_0/Rewards Std                      1.07221
evaluation_0/Rewards Max                      7.01743
evaluation_0/Rewards Min                     -0.82896
evaluation_0/Returns Mean                  4732.91
evaluation_0/Returns Std                     84.2479
evaluation_0/Returns Max                   4916.5
evaluation_0/Returns Min                   4612.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4732.91
time/epoch (s)                                0
time/total (s)                             8282.82
Epoch                                       522
---------------------------------------  ----------------
2022-11-16 18:32:58.627740 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 523 finished
---------------------------------------  ----------------
epoch                                       523
total_step                               528000
replay_pool/size                         528000
trainer/alpha                                 0.0632714
trainer/alpha_loss                            0.316767
trainer/entropy                              -6.11475
trainer/qf_loss                              19.5111
trainer/policy_loss                        -316.293
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.679
trainer/entropy_penalty                      -0.386888
trainer/entropy_percentage                   -0.0012217
trainer/Q1Pred Mean                         315.985
trainer/Q1Pred Std                           60.2609
trainer/Q1Pred Max                          398.455
trainer/Q1Pred Min                           35.0868
trainer/Q2Pred Mean                         315.508
trainer/Q2Pred Std                           60.5374
trainer/Q2Pred Max                          395.771
trainer/Q2Pred Min                           40.9366
trainer/QTargetWithReg Mean                 315.688
trainer/QTargetWithReg Std                   61.1839
trainer/QTargetWithReg Max                  398.302
trainer/QTargetWithReg Min                   35.6309
trainer/PolicyLossWithoutReg Mean           316.679
trainer/PolicyLossWithoutReg Std             59.421
trainer/PolicyLossWithoutReg Max            397.843
trainer/PolicyLossWithoutReg Min             41.7771
exploration/num steps total              528000
exploration/num paths total                1293
exploration/path length this epoch Mean     979
exploration/path length this epoch Std        0
exploration/path length this epoch Max      979
exploration/path length this epoch Min      979
exploration/Rewards Mean                      4.76375
exploration/Rewards Std                       1.00921
exploration/Rewards Max                       6.79778
exploration/Rewards Min                      -0.837161
exploration/Returns Mean                   4663.72
exploration/Returns Std                       0
exploration/Returns Max                    4663.72
exploration/Returns Min                    4663.72
exploration/Num Paths                         1
exploration/Average Returns                4663.72
evaluation_0/num steps total                  4.06784e+06
evaluation_0/num paths total               7666
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11417
evaluation_0/Rewards Std                      1.08219
evaluation_0/Rewards Max                      7.55643
evaluation_0/Rewards Min                     -0.548388
evaluation_0/Returns Mean                  5114.17
evaluation_0/Returns Std                    126.941
evaluation_0/Returns Max                   5273.78
evaluation_0/Returns Min                   4915.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5114.17
time/epoch (s)                                0
time/total (s)                             8295.63
Epoch                                       523
---------------------------------------  ----------------
2022-11-16 18:33:10.970105 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 524 finished
---------------------------------------  ----------------
epoch                                       524
total_step                               529000
replay_pool/size                         529000
trainer/alpha                                 0.0633909
trainer/alpha_loss                            0.783456
trainer/entropy                              -6.28403
trainer/qf_loss                              30.0382
trainer/policy_loss                        -306.858
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         307.257
trainer/entropy_penalty                      -0.398351
trainer/entropy_percentage                   -0.00129648
trainer/Q1Pred Mean                         306.253
trainer/Q1Pred Std                           74.2864
trainer/Q1Pred Max                          399.664
trainer/Q1Pred Min                           13.7028
trainer/Q2Pred Mean                         305.825
trainer/Q2Pred Std                           74.2856
trainer/Q2Pred Max                          398.79
trainer/Q2Pred Min                           11.2883
trainer/QTargetWithReg Mean                 306.92
trainer/QTargetWithReg Std                   73.2879
trainer/QTargetWithReg Max                  405.135
trainer/QTargetWithReg Min                    5.02069
trainer/PolicyLossWithoutReg Mean           307.257
trainer/PolicyLossWithoutReg Std             73.2755
trainer/PolicyLossWithoutReg Max            399.859
trainer/PolicyLossWithoutReg Min             11.6595
exploration/num steps total              529000
exploration/num paths total                1294
exploration/path length this epoch Mean     969
exploration/path length this epoch Std        0
exploration/path length this epoch Max      969
exploration/path length this epoch Min      969
exploration/Rewards Mean                      4.52641
exploration/Rewards Std                       1.32654
exploration/Rewards Max                       6.81938
exploration/Rewards Min                      -0.496191
exploration/Returns Mean                   4386.09
exploration/Returns Std                       0
exploration/Returns Max                    4386.09
exploration/Returns Min                    4386.09
exploration/Num Paths                         1
exploration/Average Returns                4386.09
evaluation_0/num steps total                  4.07584e+06
evaluation_0/num paths total               7674
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.46607
evaluation_0/Rewards Std                      1.27263
evaluation_0/Rewards Max                      7.22156
evaluation_0/Rewards Min                     -0.754216
evaluation_0/Returns Mean                  4466.07
evaluation_0/Returns Std                     46.8478
evaluation_0/Returns Max                   4541.42
evaluation_0/Returns Min                   4403.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4466.07
time/epoch (s)                                0
time/total (s)                             8307.97
Epoch                                       524
---------------------------------------  ----------------
2022-11-16 18:33:24.534470 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 525 finished
---------------------------------------  ----------------
epoch                                       525
total_step                               530000
replay_pool/size                         530000
trainer/alpha                                 0.0628918
trainer/alpha_loss                           -0.611706
trainer/entropy                              -5.77887
trainer/qf_loss                              25.2364
trainer/policy_loss                        -317.955
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         318.319
trainer/entropy_penalty                      -0.363443
trainer/entropy_percentage                   -0.00114176
trainer/Q1Pred Mean                         316.936
trainer/Q1Pred Std                           62.4674
trainer/Q1Pred Max                          400.048
trainer/Q1Pred Min                            6.71025
trainer/Q2Pred Mean                         317.83
trainer/Q2Pred Std                           62.9296
trainer/Q2Pred Max                          399.624
trainer/Q2Pred Min                            1.89316
trainer/QTargetWithReg Mean                 318.643
trainer/QTargetWithReg Std                   62.5799
trainer/QTargetWithReg Max                  400.382
trainer/QTargetWithReg Min                    3.68286
trainer/PolicyLossWithoutReg Mean           318.319
trainer/PolicyLossWithoutReg Std             61.5803
trainer/PolicyLossWithoutReg Max            400.446
trainer/PolicyLossWithoutReg Min              3.82856
exploration/num steps total              530000
exploration/num paths total                1295
exploration/path length this epoch Mean     498
exploration/path length this epoch Std        0
exploration/path length this epoch Max      498
exploration/path length this epoch Min      498
exploration/Rewards Mean                      3.61398
exploration/Rewards Std                       1.38502
exploration/Rewards Max                       6.53618
exploration/Rewards Min                      -0.680427
exploration/Returns Mean                   1799.76
exploration/Returns Std                       0
exploration/Returns Max                    1799.76
exploration/Returns Min                    1799.76
exploration/Num Paths                         1
exploration/Average Returns                1799.76
evaluation_0/num steps total                  4.08384e+06
evaluation_0/num paths total               7682
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.56164
evaluation_0/Rewards Std                      1.12945
evaluation_0/Rewards Max                      6.96851
evaluation_0/Rewards Min                     -1.08456
evaluation_0/Returns Mean                  4561.64
evaluation_0/Returns Std                    150.137
evaluation_0/Returns Max                   4749.2
evaluation_0/Returns Min                   4325.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4561.64
time/epoch (s)                                0
time/total (s)                             8321.53
Epoch                                       525
---------------------------------------  ----------------
2022-11-16 18:33:37.446036 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 526 finished
---------------------------------------  ----------------
epoch                                       526
total_step                               531000
replay_pool/size                         531000
trainer/alpha                                 0.0616499
trainer/alpha_loss                           -1.79087
trainer/entropy                              -5.35722
trainer/qf_loss                              19.1115
trainer/policy_loss                        -316.345
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.675
trainer/entropy_penalty                      -0.330272
trainer/entropy_percentage                   -0.00104294
trainer/Q1Pred Mean                         316.062
trainer/Q1Pred Std                           65.8348
trainer/Q1Pred Max                          404.617
trainer/Q1Pred Min                            2.12747
trainer/Q2Pred Mean                         316.309
trainer/Q2Pred Std                           65.9308
trainer/Q2Pred Max                          407.972
trainer/Q2Pred Min                            3.26866
trainer/QTargetWithReg Mean                 315.721
trainer/QTargetWithReg Std                   66.1459
trainer/QTargetWithReg Max                  407.457
trainer/QTargetWithReg Min                    2.80846
trainer/PolicyLossWithoutReg Mean           316.675
trainer/PolicyLossWithoutReg Std             64.6236
trainer/PolicyLossWithoutReg Max            403.339
trainer/PolicyLossWithoutReg Min              6.1484
exploration/num steps total              531000
exploration/num paths total                1297
exploration/path length this epoch Mean     447.5
exploration/path length this epoch Std      237.5
exploration/path length this epoch Max      685
exploration/path length this epoch Min      210
exploration/Rewards Mean                      4.0991
exploration/Rewards Std                       1.21919
exploration/Rewards Max                       6.83221
exploration/Rewards Min                      -1.19384
exploration/Returns Mean                   1834.35
exploration/Returns Std                    1178.14
exploration/Returns Max                    3012.49
exploration/Returns Min                     656.205
exploration/Num Paths                         2
exploration/Average Returns                1834.35
evaluation_0/num steps total                  4.09184e+06
evaluation_0/num paths total               7690
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64778
evaluation_0/Rewards Std                      1.10791
evaluation_0/Rewards Max                      7.19363
evaluation_0/Rewards Min                     -0.669322
evaluation_0/Returns Mean                  4647.78
evaluation_0/Returns Std                    151.863
evaluation_0/Returns Max                   4799.53
evaluation_0/Returns Min                   4341.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4647.78
time/epoch (s)                                0
time/total (s)                             8334.44
Epoch                                       526
---------------------------------------  ----------------
2022-11-16 18:33:50.322227 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 527 finished
---------------------------------------  ----------------
epoch                                       527
total_step                               532000
replay_pool/size                         532000
trainer/alpha                                 0.0627646
trainer/alpha_loss                            0.55086
trainer/entropy                              -6.19899
trainer/qf_loss                              24.3382
trainer/policy_loss                        -314.556
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.945
trainer/entropy_penalty                      -0.389077
trainer/entropy_percentage                   -0.00123538
trainer/Q1Pred Mean                         313.69
trainer/Q1Pred Std                           64.9758
trainer/Q1Pred Max                          395.124
trainer/Q1Pred Min                          -37.1714
trainer/Q2Pred Mean                         314.243
trainer/Q2Pred Std                           65.4876
trainer/Q2Pred Max                          396.546
trainer/Q2Pred Min                          -16.4611
trainer/QTargetWithReg Mean                 314.197
trainer/QTargetWithReg Std                   64.9795
trainer/QTargetWithReg Max                  394.842
trainer/QTargetWithReg Min                    1.08282
trainer/PolicyLossWithoutReg Mean           314.945
trainer/PolicyLossWithoutReg Std             63.9071
trainer/PolicyLossWithoutReg Max            395.035
trainer/PolicyLossWithoutReg Min            -24.6943
exploration/num steps total              532000
exploration/num paths total                1298
exploration/path length this epoch Mean      16
exploration/path length this epoch Std        0
exploration/path length this epoch Max       16
exploration/path length this epoch Min       16
exploration/Rewards Mean                     -0.320352
exploration/Rewards Std                       0.365545
exploration/Rewards Max                       0.78522
exploration/Rewards Min                      -0.772894
exploration/Returns Mean                     -5.12563
exploration/Returns Std                       0
exploration/Returns Max                      -5.12563
exploration/Returns Min                      -5.12563
exploration/Num Paths                         1
exploration/Average Returns                  -5.12563
evaluation_0/num steps total                  4.09984e+06
evaluation_0/num paths total               7698
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81701
evaluation_0/Rewards Std                      1.00935
evaluation_0/Rewards Max                      6.86581
evaluation_0/Rewards Min                     -0.62175
evaluation_0/Returns Mean                  4817.01
evaluation_0/Returns Std                     75.8222
evaluation_0/Returns Max                   4912.51
evaluation_0/Returns Min                   4639.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4817.01
time/epoch (s)                                0
time/total (s)                             8347.32
Epoch                                       527
---------------------------------------  ----------------
2022-11-16 18:34:03.599280 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 528 finished
---------------------------------------  ----------------
epoch                                       528
total_step                               533000
replay_pool/size                         533000
trainer/alpha                                 0.0619279
trainer/alpha_loss                            0.643895
trainer/entropy                              -6.23147
trainer/qf_loss                              18.5716
trainer/policy_loss                        -321.379
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         321.765
trainer/entropy_penalty                      -0.385902
trainer/entropy_percentage                   -0.00119933
trainer/Q1Pred Mean                         320.714
trainer/Q1Pred Std                           62.3401
trainer/Q1Pred Max                          407.525
trainer/Q1Pred Min                           15.4439
trainer/Q2Pred Mean                         319.781
trainer/Q2Pred Std                           62.6625
trainer/Q2Pred Max                          406.844
trainer/Q2Pred Min                           18.6925
trainer/QTargetWithReg Mean                 320.389
trainer/QTargetWithReg Std                   63.0248
trainer/QTargetWithReg Max                  407.803
trainer/QTargetWithReg Min                   11.9922
trainer/PolicyLossWithoutReg Mean           321.765
trainer/PolicyLossWithoutReg Std             59.1644
trainer/PolicyLossWithoutReg Max            407.012
trainer/PolicyLossWithoutReg Min             20.7694
exploration/num steps total              533000
exploration/num paths total                1299
exploration/path length this epoch Mean     556
exploration/path length this epoch Std        0
exploration/path length this epoch Max      556
exploration/path length this epoch Min      556
exploration/Rewards Mean                      4.41644
exploration/Rewards Std                       1.20927
exploration/Rewards Max                       6.8579
exploration/Rewards Min                      -0.411861
exploration/Returns Mean                   2455.54
exploration/Returns Std                       0
exploration/Returns Max                    2455.54
exploration/Returns Min                    2455.54
exploration/Num Paths                         1
exploration/Average Returns                2455.54
evaluation_0/num steps total                  4.10784e+06
evaluation_0/num paths total               7706
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92471
evaluation_0/Rewards Std                      1.03044
evaluation_0/Rewards Max                      7.25061
evaluation_0/Rewards Min                     -0.844254
evaluation_0/Returns Mean                  4924.71
evaluation_0/Returns Std                    100.209
evaluation_0/Returns Max                   5065.08
evaluation_0/Returns Min                   4780.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4924.71
time/epoch (s)                                0
time/total (s)                             8360.6
Epoch                                       528
---------------------------------------  ----------------
2022-11-16 18:34:15.953248 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 529 finished
---------------------------------------  ----------------
epoch                                       529
total_step                               534000
replay_pool/size                         534000
trainer/alpha                                 0.0616445
trainer/alpha_loss                           -0.847576
trainer/entropy                              -5.69581
trainer/qf_loss                              27.3734
trainer/policy_loss                        -313.483
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.834
trainer/entropy_penalty                      -0.351115
trainer/entropy_percentage                   -0.00111879
trainer/Q1Pred Mean                         312.272
trainer/Q1Pred Std                           69.0328
trainer/Q1Pred Max                          407.307
trainer/Q1Pred Min                          -30.6286
trainer/Q2Pred Mean                         312.968
trainer/Q2Pred Std                           69.2723
trainer/Q2Pred Max                          405.131
trainer/Q2Pred Min                          -59.6867
trainer/QTargetWithReg Mean                 313.204
trainer/QTargetWithReg Std                   67.937
trainer/QTargetWithReg Max                  404.806
trainer/QTargetWithReg Min                   -0.122444
trainer/PolicyLossWithoutReg Mean           313.834
trainer/PolicyLossWithoutReg Std             66.0809
trainer/PolicyLossWithoutReg Max            405.711
trainer/PolicyLossWithoutReg Min            -37.896
exploration/num steps total              534000
exploration/num paths total                1300
exploration/path length this epoch Mean     841
exploration/path length this epoch Std        0
exploration/path length this epoch Max      841
exploration/path length this epoch Min      841
exploration/Rewards Mean                      4.81923
exploration/Rewards Std                       1.05638
exploration/Rewards Max                       6.96349
exploration/Rewards Min                      -0.706199
exploration/Returns Mean                   4052.97
exploration/Returns Std                       0
exploration/Returns Max                    4052.97
exploration/Returns Min                    4052.97
exploration/Num Paths                         1
exploration/Average Returns                4052.97
evaluation_0/num steps total                  4.11584e+06
evaluation_0/num paths total               7714
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77996
evaluation_0/Rewards Std                      1.01939
evaluation_0/Rewards Max                      7.18693
evaluation_0/Rewards Min                     -0.788542
evaluation_0/Returns Mean                  4779.96
evaluation_0/Returns Std                     64.8253
evaluation_0/Returns Max                   4884.58
evaluation_0/Returns Min                   4642.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4779.96
time/epoch (s)                                0
time/total (s)                             8372.95
Epoch                                       529
---------------------------------------  ----------------
2022-11-16 18:34:27.081164 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 530 finished
---------------------------------------  ----------------
epoch                                       530
total_step                               535000
replay_pool/size                         535000
trainer/alpha                                 0.0618769
trainer/alpha_loss                            0.2252
trainer/entropy                              -6.08093
trainer/qf_loss                              25.6842
trainer/policy_loss                        -315.704
trainer/adversary_policy_loss                14.9947
trainer/policy_loss_without_entropy         316.08
trainer/entropy_penalty                      -0.376269
trainer/entropy_percentage                   -0.00119042
trainer/Q1Pred Mean                         315.266
trainer/Q1Pred Std                           68.0459
trainer/Q1Pred Max                          407.449
trainer/Q1Pred Min                           -2.11091
trainer/Q2Pred Mean                         315.514
trainer/Q2Pred Std                           67.7739
trainer/Q2Pred Max                          404.467
trainer/Q2Pred Min                          -17.5073
trainer/QTargetWithReg Mean                 314.955
trainer/QTargetWithReg Std                   68.1601
trainer/QTargetWithReg Max                  405.23
trainer/QTargetWithReg Min                   -7.90804
trainer/PolicyLossWithoutReg Mean           316.08
trainer/PolicyLossWithoutReg Std             66.7318
trainer/PolicyLossWithoutReg Max            404.458
trainer/PolicyLossWithoutReg Min             -7.91595
exploration/num steps total              535000
exploration/num paths total                1301
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60898
exploration/Rewards Std                       1.007
exploration/Rewards Max                       6.91169
exploration/Rewards Min                      -0.670854
exploration/Returns Mean                   4608.98
exploration/Returns Std                       0
exploration/Returns Max                    4608.98
exploration/Returns Min                    4608.98
exploration/Num Paths                         1
exploration/Average Returns                4608.98
evaluation_0/num steps total                  4.12384e+06
evaluation_0/num paths total               7722
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74382
evaluation_0/Rewards Std                      1.07563
evaluation_0/Rewards Max                      7.04082
evaluation_0/Rewards Min                     -0.790389
evaluation_0/Returns Mean                  4743.82
evaluation_0/Returns Std                    154.065
evaluation_0/Returns Max                   4940.77
evaluation_0/Returns Min                   4518.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4743.82
time/epoch (s)                                0
time/total (s)                             8384.08
Epoch                                       530
---------------------------------------  ----------------
2022-11-16 18:34:40.722072 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 531 finished
---------------------------------------  ----------------
epoch                                       531
total_step                               536000
replay_pool/size                         536000
trainer/alpha                                 0.0624671
trainer/alpha_loss                            1.0889
trainer/entropy                              -6.39267
trainer/qf_loss                              47.5441
trainer/policy_loss                        -318.988
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         319.388
trainer/entropy_penalty                      -0.399332
trainer/entropy_percentage                   -0.0012503
trainer/Q1Pred Mean                         316.527
trainer/Q1Pred Std                           66.6457
trainer/Q1Pred Max                          404.909
trainer/Q1Pred Min                          -55.0116
trainer/Q2Pred Mean                         316.523
trainer/Q2Pred Std                           66.9111
trainer/Q2Pred Max                          403.626
trainer/Q2Pred Min                          -97.0514
trainer/QTargetWithReg Mean                 317.399
trainer/QTargetWithReg Std                   65.2867
trainer/QTargetWithReg Max                  406.215
trainer/QTargetWithReg Min                   -1.37478
trainer/PolicyLossWithoutReg Mean           319.388
trainer/PolicyLossWithoutReg Std             60.563
trainer/PolicyLossWithoutReg Max            404.392
trainer/PolicyLossWithoutReg Min             12.3487
exploration/num steps total              536000
exploration/num paths total                1302
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.34324
exploration/Rewards Std                       1.20111
exploration/Rewards Max                       6.72905
exploration/Rewards Min                      -0.651742
exploration/Returns Mean                   4343.24
exploration/Returns Std                       0
exploration/Returns Max                    4343.24
exploration/Returns Min                    4343.24
exploration/Num Paths                         1
exploration/Average Returns                4343.24
evaluation_0/num steps total                  4.13184e+06
evaluation_0/num paths total               7730
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.54368
evaluation_0/Rewards Std                      0.995168
evaluation_0/Rewards Max                      6.99947
evaluation_0/Rewards Min                     -0.531282
evaluation_0/Returns Mean                  4543.68
evaluation_0/Returns Std                    176.46
evaluation_0/Returns Max                   4859.72
evaluation_0/Returns Min                   4372.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4543.68
time/epoch (s)                                0
time/total (s)                             8397.72
Epoch                                       531
---------------------------------------  ----------------
2022-11-16 18:34:52.153942 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 532 finished
---------------------------------------  ----------------
epoch                                       532
total_step                               537000
replay_pool/size                         537000
trainer/alpha                                 0.0616521
trainer/alpha_loss                            1.743
trainer/entropy                              -6.62558
trainer/qf_loss                              19.4241
trainer/policy_loss                        -314.794
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.203
trainer/entropy_penalty                      -0.408481
trainer/entropy_percentage                   -0.00129593
trainer/Q1Pred Mean                         313.859
trainer/Q1Pred Std                           61.6663
trainer/Q1Pred Max                          407.145
trainer/Q1Pred Min                           12.8005
trainer/Q2Pred Mean                         313.969
trainer/Q2Pred Std                           61.2776
trainer/Q2Pred Max                          408.275
trainer/Q2Pred Min                           16.5309
trainer/QTargetWithReg Mean                 313.698
trainer/QTargetWithReg Std                   61.7913
trainer/QTargetWithReg Max                  405.809
trainer/QTargetWithReg Min                   19.3472
trainer/PolicyLossWithoutReg Mean           315.203
trainer/PolicyLossWithoutReg Std             60.7691
trainer/PolicyLossWithoutReg Max            406.881
trainer/PolicyLossWithoutReg Min             14.0094
exploration/num steps total              537000
exploration/num paths total                1303
exploration/path length this epoch Mean     312
exploration/path length this epoch Std        0
exploration/path length this epoch Max      312
exploration/path length this epoch Min      312
exploration/Rewards Mean                      3.65145
exploration/Rewards Std                       1.40453
exploration/Rewards Max                       6.82446
exploration/Rewards Min                      -0.58351
exploration/Returns Mean                   1139.25
exploration/Returns Std                       0
exploration/Returns Max                    1139.25
exploration/Returns Min                    1139.25
exploration/Num Paths                         1
exploration/Average Returns                1139.25
evaluation_0/num steps total                  4.13984e+06
evaluation_0/num paths total               7738
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.60926
evaluation_0/Rewards Std                      0.930891
evaluation_0/Rewards Max                      6.92445
evaluation_0/Rewards Min                     -0.64788
evaluation_0/Returns Mean                  4609.26
evaluation_0/Returns Std                    117.796
evaluation_0/Returns Max                   4753.24
evaluation_0/Returns Min                   4371.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4609.26
time/epoch (s)                                0
time/total (s)                             8409.15
Epoch                                       532
---------------------------------------  ----------------
2022-11-16 18:35:03.340350 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 533 finished
---------------------------------------  ----------------
epoch                                       533
total_step                               538000
replay_pool/size                         538000
trainer/alpha                                 0.0630383
trainer/alpha_loss                           -0.559463
trainer/entropy                              -5.79758
trainer/qf_loss                              19.9044
trainer/policy_loss                        -312.809
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.175
trainer/entropy_penalty                      -0.36547
trainer/entropy_percentage                   -0.00116698
trainer/Q1Pred Mean                         312.022
trainer/Q1Pred Std                           75.0339
trainer/Q1Pred Max                          403.991
trainer/Q1Pred Min                           -2.13587
trainer/Q2Pred Mean                         312.081
trainer/Q2Pred Std                           74.9669
trainer/Q2Pred Max                          404.516
trainer/Q2Pred Min                          -15.2788
trainer/QTargetWithReg Mean                 312.41
trainer/QTargetWithReg Std                   74.41
trainer/QTargetWithReg Max                  403.932
trainer/QTargetWithReg Min                    3.49896
trainer/PolicyLossWithoutReg Mean           313.175
trainer/PolicyLossWithoutReg Std             74.0332
trainer/PolicyLossWithoutReg Max            404.324
trainer/PolicyLossWithoutReg Min              6.0483
exploration/num steps total              538000
exploration/num paths total                1304
exploration/path length this epoch Mean     684
exploration/path length this epoch Std        0
exploration/path length this epoch Max      684
exploration/path length this epoch Min      684
exploration/Rewards Mean                      4.43584
exploration/Rewards Std                       1.14574
exploration/Rewards Max                       6.96071
exploration/Rewards Min                      -1.09603
exploration/Returns Mean                   3034.12
exploration/Returns Std                       0
exploration/Returns Max                    3034.12
exploration/Returns Min                    3034.12
exploration/Num Paths                         1
exploration/Average Returns                3034.12
evaluation_0/num steps total                  4.14784e+06
evaluation_0/num paths total               7746
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70798
evaluation_0/Rewards Std                      1.08742
evaluation_0/Rewards Max                      7.06133
evaluation_0/Rewards Min                     -0.660333
evaluation_0/Returns Mean                  4707.98
evaluation_0/Returns Std                     99.9449
evaluation_0/Returns Max                   4827.35
evaluation_0/Returns Min                   4543.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4707.98
time/epoch (s)                                0
time/total (s)                             8420.33
Epoch                                       533
---------------------------------------  ----------------
2022-11-16 18:35:16.716855 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 534 finished
---------------------------------------  ----------------
epoch                                       534
total_step                               539000
replay_pool/size                         539000
trainer/alpha                                 0.0618231
trainer/alpha_loss                            0.944686
trainer/entropy                              -6.33936
trainer/qf_loss                              19.7211
trainer/policy_loss                        -313.233
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         313.625
trainer/entropy_penalty                      -0.391919
trainer/entropy_percentage                   -0.00124964
trainer/Q1Pred Mean                         311.796
trainer/Q1Pred Std                           75.185
trainer/Q1Pred Max                          408.5
trainer/Q1Pred Min                           25.4369
trainer/Q2Pred Mean                         311.251
trainer/Q2Pred Std                           74.0057
trainer/Q2Pred Max                          406.458
trainer/Q2Pred Min                           27.0939
trainer/QTargetWithReg Mean                 312.307
trainer/QTargetWithReg Std                   74.5607
trainer/QTargetWithReg Max                  406.483
trainer/QTargetWithReg Min                   25.3999
trainer/PolicyLossWithoutReg Mean           313.625
trainer/PolicyLossWithoutReg Std             72.0189
trainer/PolicyLossWithoutReg Max            408.517
trainer/PolicyLossWithoutReg Min             30.4298
exploration/num steps total              539000
exploration/num paths total                1305
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49339
exploration/Rewards Std                       1.12134
exploration/Rewards Max                       6.74936
exploration/Rewards Min                      -0.60931
exploration/Returns Mean                   4493.39
exploration/Returns Std                       0
exploration/Returns Max                    4493.39
exploration/Returns Min                    4493.39
exploration/Num Paths                         1
exploration/Average Returns                4493.39
evaluation_0/num steps total                  4.15584e+06
evaluation_0/num paths total               7754
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63145
evaluation_0/Rewards Std                      0.991459
evaluation_0/Rewards Max                      6.88157
evaluation_0/Rewards Min                     -0.731493
evaluation_0/Returns Mean                  4631.45
evaluation_0/Returns Std                    159.171
evaluation_0/Returns Max                   4931.71
evaluation_0/Returns Min                   4341.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4631.45
time/epoch (s)                                0
time/total (s)                             8433.71
Epoch                                       534
---------------------------------------  ----------------
2022-11-16 18:35:27.651382 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 535 finished
---------------------------------------  ----------------
epoch                                       535
total_step                               540000
replay_pool/size                         540000
trainer/alpha                                 0.0625135
trainer/alpha_loss                           -0.487987
trainer/entropy                              -5.82397
trainer/qf_loss                              21.6079
trainer/policy_loss                        -320.725
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         321.089
trainer/entropy_penalty                      -0.364076
trainer/entropy_percentage                   -0.00113388
trainer/Q1Pred Mean                         320.061
trainer/Q1Pred Std                           65.1852
trainer/Q1Pred Max                          404.185
trainer/Q1Pred Min                          -19.8921
trainer/Q2Pred Mean                         319.031
trainer/Q2Pred Std                           65.4611
trainer/Q2Pred Max                          403.71
trainer/Q2Pred Min                          -13.6929
trainer/QTargetWithReg Mean                 318.904
trainer/QTargetWithReg Std                   65.1189
trainer/QTargetWithReg Max                  403.195
trainer/QTargetWithReg Min                    0.526385
trainer/PolicyLossWithoutReg Mean           321.089
trainer/PolicyLossWithoutReg Std             61.2815
trainer/PolicyLossWithoutReg Max            403.832
trainer/PolicyLossWithoutReg Min              9.53821
exploration/num steps total              540000
exploration/num paths total                1306
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62916
exploration/Rewards Std                       0.956266
exploration/Rewards Max                       7.30776
exploration/Rewards Min                      -0.750073
exploration/Returns Mean                   4629.16
exploration/Returns Std                       0
exploration/Returns Max                    4629.16
exploration/Returns Min                    4629.16
exploration/Num Paths                         1
exploration/Average Returns                4629.16
evaluation_0/num steps total                  4.16384e+06
evaluation_0/num paths total               7762
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.47947
evaluation_0/Rewards Std                      0.988439
evaluation_0/Rewards Max                      7.00758
evaluation_0/Rewards Min                     -0.512065
evaluation_0/Returns Mean                  4479.47
evaluation_0/Returns Std                    101.299
evaluation_0/Returns Max                   4643.36
evaluation_0/Returns Min                   4365.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4479.47
time/epoch (s)                                0
time/total (s)                             8444.65
Epoch                                       535
---------------------------------------  ----------------
2022-11-16 18:35:39.264221 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 536 finished
---------------------------------------  ----------------
epoch                                       536
total_step                               541000
replay_pool/size                         541000
trainer/alpha                                 0.0650579
trainer/alpha_loss                           -1.41215
trainer/entropy                              -5.48317
trainer/qf_loss                              21.8216
trainer/policy_loss                        -321.963
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         322.319
trainer/entropy_penalty                      -0.356724
trainer/entropy_percentage                   -0.00110674
trainer/Q1Pred Mean                         321.998
trainer/Q1Pred Std                           60.4568
trainer/Q1Pred Max                          410.583
trainer/Q1Pred Min                           21.0287
trainer/Q2Pred Mean                         321.323
trainer/Q2Pred Std                           60.8986
trainer/Q2Pred Max                          409.298
trainer/Q2Pred Min                           23.1506
trainer/QTargetWithReg Mean                 320.719
trainer/QTargetWithReg Std                   60.1431
trainer/QTargetWithReg Max                  408.763
trainer/QTargetWithReg Min                   26.4239
trainer/PolicyLossWithoutReg Mean           322.319
trainer/PolicyLossWithoutReg Std             60.1322
trainer/PolicyLossWithoutReg Max            410.211
trainer/PolicyLossWithoutReg Min             22.9081
exploration/num steps total              541000
exploration/num paths total                1307
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54457
exploration/Rewards Std                       1.11669
exploration/Rewards Max                       7.01063
exploration/Rewards Min                      -0.518108
exploration/Returns Mean                   4544.57
exploration/Returns Std                       0
exploration/Returns Max                    4544.57
exploration/Returns Min                    4544.57
exploration/Num Paths                         1
exploration/Average Returns                4544.57
evaluation_0/num steps total                  4.17184e+06
evaluation_0/num paths total               7770
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95717
evaluation_0/Rewards Std                      1.07316
evaluation_0/Rewards Max                      8.26816
evaluation_0/Rewards Min                     -0.571487
evaluation_0/Returns Mean                  4957.17
evaluation_0/Returns Std                     73.5906
evaluation_0/Returns Max                   5102.75
evaluation_0/Returns Min                   4854.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4957.17
time/epoch (s)                                0
time/total (s)                             8456.26
Epoch                                       536
---------------------------------------  ----------------
2022-11-16 18:35:51.711088 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 537 finished
---------------------------------------  ----------------
epoch                                       537
total_step                               542000
replay_pool/size                         542000
trainer/alpha                                 0.0624483
trainer/alpha_loss                            0.362474
trainer/entropy                              -6.13068
trainer/qf_loss                              22.5471
trainer/policy_loss                        -319.888
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.271
trainer/entropy_penalty                      -0.382851
trainer/entropy_percentage                   -0.0011954
trainer/Q1Pred Mean                         318.616
trainer/Q1Pred Std                           62.9872
trainer/Q1Pred Max                          401.23
trainer/Q1Pred Min                           16.342
trainer/Q2Pred Mean                         319.131
trainer/Q2Pred Std                           63.0925
trainer/Q2Pred Max                          402.515
trainer/Q2Pred Min                           12.9087
trainer/QTargetWithReg Mean                 319.227
trainer/QTargetWithReg Std                   63.0436
trainer/QTargetWithReg Max                  401.405
trainer/QTargetWithReg Min                   16.2937
trainer/PolicyLossWithoutReg Mean           320.271
trainer/PolicyLossWithoutReg Std             61.3838
trainer/PolicyLossWithoutReg Max            400.939
trainer/PolicyLossWithoutReg Min             37.065
exploration/num steps total              542000
exploration/num paths total                1308
exploration/path length this epoch Mean     235
exploration/path length this epoch Std        0
exploration/path length this epoch Max      235
exploration/path length this epoch Min      235
exploration/Rewards Mean                      3.6705
exploration/Rewards Std                       1.22036
exploration/Rewards Max                       6.28155
exploration/Rewards Min                      -0.416634
exploration/Returns Mean                    862.569
exploration/Returns Std                       0
exploration/Returns Max                     862.569
exploration/Returns Min                     862.569
exploration/Num Paths                         1
exploration/Average Returns                 862.569
evaluation_0/num steps total                  4.17984e+06
evaluation_0/num paths total               7778
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78148
evaluation_0/Rewards Std                      0.975388
evaluation_0/Rewards Max                      6.83475
evaluation_0/Rewards Min                     -0.644593
evaluation_0/Returns Mean                  4781.48
evaluation_0/Returns Std                    128.738
evaluation_0/Returns Max                   4940.72
evaluation_0/Returns Min                   4550.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4781.48
time/epoch (s)                                0
time/total (s)                             8468.7
Epoch                                       537
---------------------------------------  ----------------
2022-11-16 18:36:02.776762 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 538 finished
---------------------------------------  ----------------
epoch                                       538
total_step                               543000
replay_pool/size                         543000
trainer/alpha                                 0.0601881
trainer/alpha_loss                            1.31587
trainer/entropy                              -6.46823
trainer/qf_loss                              27.9247
trainer/policy_loss                        -316.595
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.985
trainer/entropy_penalty                      -0.389311
trainer/entropy_percentage                   -0.00122817
trainer/Q1Pred Mean                         316.856
trainer/Q1Pred Std                           66.3767
trainer/Q1Pred Max                          404.239
trainer/Q1Pred Min                           -0.215205
trainer/Q2Pred Mean                         316.118
trainer/Q2Pred Std                           67.7517
trainer/Q2Pred Max                          404.487
trainer/Q2Pred Min                           -7.90953
trainer/QTargetWithReg Mean                 316.429
trainer/QTargetWithReg Std                   67.5049
trainer/QTargetWithReg Max                  404.693
trainer/QTargetWithReg Min                  -24.6477
trainer/PolicyLossWithoutReg Mean           316.985
trainer/PolicyLossWithoutReg Std             66.2813
trainer/PolicyLossWithoutReg Max            404.166
trainer/PolicyLossWithoutReg Min             -2.42446
exploration/num steps total              543000
exploration/num paths total                1309
exploration/path length this epoch Mean     853
exploration/path length this epoch Std        0
exploration/path length this epoch Max      853
exploration/path length this epoch Min      853
exploration/Rewards Mean                      4.69386
exploration/Rewards Std                       1.0538
exploration/Rewards Max                       6.94582
exploration/Rewards Min                      -0.594149
exploration/Returns Mean                   4003.86
exploration/Returns Std                       0
exploration/Returns Max                    4003.86
exploration/Returns Min                    4003.86
exploration/Num Paths                         1
exploration/Average Returns                4003.86
evaluation_0/num steps total                  4.18784e+06
evaluation_0/num paths total               7786
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02112
evaluation_0/Rewards Std                      1.07742
evaluation_0/Rewards Max                      7.16048
evaluation_0/Rewards Min                     -0.768356
evaluation_0/Returns Mean                  5021.12
evaluation_0/Returns Std                    103.652
evaluation_0/Returns Max                   5227.2
evaluation_0/Returns Min                   4847.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5021.12
time/epoch (s)                                0
time/total (s)                             8479.77
Epoch                                       538
---------------------------------------  ----------------
2022-11-16 18:36:13.811907 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 539 finished
---------------------------------------  ----------------
epoch                                       539
total_step                               544000
replay_pool/size                         544000
trainer/alpha                                 0.0600879
trainer/alpha_loss                           -0.661125
trainer/entropy                              -5.76488
trainer/qf_loss                              12.6162
trainer/policy_loss                        -319.273
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         319.619
trainer/entropy_penalty                      -0.3464
trainer/entropy_percentage                   -0.00108379
trainer/Q1Pred Mean                         319.483
trainer/Q1Pred Std                           65.5524
trainer/Q1Pred Max                          400.142
trainer/Q1Pred Min                           16.6217
trainer/Q2Pred Mean                         319.307
trainer/Q2Pred Std                           65.5262
trainer/Q2Pred Max                          400.623
trainer/Q2Pred Min                           13.3578
trainer/QTargetWithReg Mean                 319.755
trainer/QTargetWithReg Std                   65.3666
trainer/QTargetWithReg Max                  404.016
trainer/QTargetWithReg Min                    9.97057
trainer/PolicyLossWithoutReg Mean           319.619
trainer/PolicyLossWithoutReg Std             64.8969
trainer/PolicyLossWithoutReg Max            399.56
trainer/PolicyLossWithoutReg Min             14.5221
exploration/num steps total              544000
exploration/num paths total                1310
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50771
exploration/Rewards Std                       1.11296
exploration/Rewards Max                       6.85402
exploration/Rewards Min                      -1.021
exploration/Returns Mean                   4507.71
exploration/Returns Std                       0
exploration/Returns Max                    4507.71
exploration/Returns Min                    4507.71
exploration/Num Paths                         1
exploration/Average Returns                4507.71
evaluation_0/num steps total                  4.19584e+06
evaluation_0/num paths total               7794
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78659
evaluation_0/Rewards Std                      1.01053
evaluation_0/Rewards Max                      7.12581
evaluation_0/Rewards Min                     -0.501525
evaluation_0/Returns Mean                  4786.59
evaluation_0/Returns Std                     84.3937
evaluation_0/Returns Max                   4942.76
evaluation_0/Returns Min                   4652.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4786.59
time/epoch (s)                                0
time/total (s)                             8490.8
Epoch                                       539
---------------------------------------  ----------------
2022-11-16 18:36:27.283800 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 540 finished
---------------------------------------  ----------------
epoch                                       540
total_step                               545000
replay_pool/size                         545000
trainer/alpha                                 0.0623535
trainer/alpha_loss                            0.126363
trainer/entropy                              -6.04554
trainer/qf_loss                              21.7492
trainer/policy_loss                        -315.167
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.544
trainer/entropy_penalty                      -0.37696
trainer/entropy_percentage                   -0.00119464
trainer/Q1Pred Mean                         314.528
trainer/Q1Pred Std                           73.2965
trainer/Q1Pred Max                          409.461
trainer/Q1Pred Min                          -10.2448
trainer/Q2Pred Mean                         315.33
trainer/Q2Pred Std                           73.4292
trainer/Q2Pred Max                          407.96
trainer/Q2Pred Min                          -13.9719
trainer/QTargetWithReg Mean                 314.946
trainer/QTargetWithReg Std                   74.8252
trainer/QTargetWithReg Max                  408.4
trainer/QTargetWithReg Min                  -15.2067
trainer/PolicyLossWithoutReg Mean           315.544
trainer/PolicyLossWithoutReg Std             71.5607
trainer/PolicyLossWithoutReg Max            407.339
trainer/PolicyLossWithoutReg Min             -6.18922
exploration/num steps total              545000
exploration/num paths total                1311
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41516
exploration/Rewards Std                       1.07013
exploration/Rewards Max                       6.87241
exploration/Rewards Min                      -0.691225
exploration/Returns Mean                   4415.16
exploration/Returns Std                       0
exploration/Returns Max                    4415.16
exploration/Returns Min                    4415.16
exploration/Num Paths                         1
exploration/Average Returns                4415.16
evaluation_0/num steps total                  4.20384e+06
evaluation_0/num paths total               7802
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62362
evaluation_0/Rewards Std                      0.985645
evaluation_0/Rewards Max                      7.07538
evaluation_0/Rewards Min                     -0.523926
evaluation_0/Returns Mean                  4623.62
evaluation_0/Returns Std                     57.618
evaluation_0/Returns Max                   4679
evaluation_0/Returns Min                   4508.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4623.62
time/epoch (s)                                0
time/total (s)                             8504.28
Epoch                                       540
---------------------------------------  ----------------
2022-11-16 18:36:39.233842 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 541 finished
---------------------------------------  ----------------
epoch                                       541
total_step                               546000
replay_pool/size                         546000
trainer/alpha                                 0.0608893
trainer/alpha_loss                            0.655719
trainer/entropy                              -6.2343
trainer/qf_loss                              29.6644
trainer/policy_loss                        -317.067
trainer/adversary_policy_loss                15.1132
trainer/policy_loss_without_entropy         317.447
trainer/entropy_penalty                      -0.379602
trainer/entropy_percentage                   -0.0011958
trainer/Q1Pred Mean                         315.03
trainer/Q1Pred Std                           69.6614
trainer/Q1Pred Max                          392.998
trainer/Q1Pred Min                          -27.5448
trainer/Q2Pred Mean                         315.639
trainer/Q2Pred Std                           70.5143
trainer/Q2Pred Max                          394.584
trainer/Q2Pred Min                          -87.5975
trainer/QTargetWithReg Mean                 315.395
trainer/QTargetWithReg Std                   70.9757
trainer/QTargetWithReg Max                  394.647
trainer/QTargetWithReg Min                  -86.8846
trainer/PolicyLossWithoutReg Mean           317.447
trainer/PolicyLossWithoutReg Std             66.1588
trainer/PolicyLossWithoutReg Max            393.628
trainer/PolicyLossWithoutReg Min              1.4877
exploration/num steps total              546000
exploration/num paths total                1312
exploration/path length this epoch Mean     808
exploration/path length this epoch Std        0
exploration/path length this epoch Max      808
exploration/path length this epoch Min      808
exploration/Rewards Mean                      4.27504
exploration/Rewards Std                       0.987936
exploration/Rewards Max                       6.41368
exploration/Rewards Min                      -0.494971
exploration/Returns Mean                   3454.23
exploration/Returns Std                       0
exploration/Returns Max                    3454.23
exploration/Returns Min                    3454.23
exploration/Num Paths                         1
exploration/Average Returns                3454.23
evaluation_0/num steps total                  4.21184e+06
evaluation_0/num paths total               7810
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00376
evaluation_0/Rewards Std                      1.06507
evaluation_0/Rewards Max                      7.29561
evaluation_0/Rewards Min                     -0.902088
evaluation_0/Returns Mean                  5003.76
evaluation_0/Returns Std                    129.441
evaluation_0/Returns Max                   5114.12
evaluation_0/Returns Min                   4712.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5003.76
time/epoch (s)                                0
time/total (s)                             8516.23
Epoch                                       541
---------------------------------------  ----------------
2022-11-16 18:36:52.354282 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 542 finished
---------------------------------------  ----------------
epoch                                       542
total_step                               547000
replay_pool/size                         547000
trainer/alpha                                 0.0624213
trainer/alpha_loss                           -0.245719
trainer/entropy                              -5.91142
trainer/qf_loss                              19.176
trainer/policy_loss                        -320.092
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.461
trainer/entropy_penalty                      -0.368998
trainer/entropy_percentage                   -0.00115146
trainer/Q1Pred Mean                         320.579
trainer/Q1Pred Std                           66.7153
trainer/Q1Pred Max                          405.673
trainer/Q1Pred Min                           11.9502
trainer/Q2Pred Mean                         320.062
trainer/Q2Pred Std                           66.3425
trainer/Q2Pred Max                          407.828
trainer/Q2Pred Min                           16.452
trainer/QTargetWithReg Mean                 320.05
trainer/QTargetWithReg Std                   67.3112
trainer/QTargetWithReg Max                  409.649
trainer/QTargetWithReg Min                   12.3982
trainer/PolicyLossWithoutReg Mean           320.461
trainer/PolicyLossWithoutReg Std             66.0404
trainer/PolicyLossWithoutReg Max            405.679
trainer/PolicyLossWithoutReg Min             13.8726
exploration/num steps total              547000
exploration/num paths total                1313
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72866
exploration/Rewards Std                       0.987469
exploration/Rewards Max                       6.99078
exploration/Rewards Min                      -0.633117
exploration/Returns Mean                   4728.66
exploration/Returns Std                       0
exploration/Returns Max                    4728.66
exploration/Returns Min                    4728.66
exploration/Num Paths                         1
exploration/Average Returns                4728.66
evaluation_0/num steps total                  4.21984e+06
evaluation_0/num paths total               7818
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81002
evaluation_0/Rewards Std                      0.97884
evaluation_0/Rewards Max                      7.10867
evaluation_0/Rewards Min                     -0.947019
evaluation_0/Returns Mean                  4810.02
evaluation_0/Returns Std                     45.391
evaluation_0/Returns Max                   4881
evaluation_0/Returns Min                   4722.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4810.02
time/epoch (s)                                0
time/total (s)                             8529.35
Epoch                                       542
---------------------------------------  ----------------
2022-11-16 18:37:05.670107 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 543 finished
---------------------------------------  ----------------
epoch                                       543
total_step                               548000
replay_pool/size                         548000
trainer/alpha                                 0.0619546
trainer/alpha_loss                           -1.48637
trainer/entropy                              -5.46558
trainer/qf_loss                              23.6425
trainer/policy_loss                        -317.4
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         317.738
trainer/entropy_penalty                      -0.338618
trainer/entropy_percentage                   -0.00106571
trainer/Q1Pred Mean                         316.302
trainer/Q1Pred Std                           70.6365
trainer/Q1Pred Max                          403.344
trainer/Q1Pred Min                            0.866069
trainer/Q2Pred Mean                         317.009
trainer/Q2Pred Std                           70.7909
trainer/Q2Pred Max                          404.169
trainer/Q2Pred Min                           -2.60425
trainer/QTargetWithReg Mean                 317.128
trainer/QTargetWithReg Std                   70.4322
trainer/QTargetWithReg Max                  403.416
trainer/QTargetWithReg Min                   -1.28204
trainer/PolicyLossWithoutReg Mean           317.738
trainer/PolicyLossWithoutReg Std             69.562
trainer/PolicyLossWithoutReg Max            404.599
trainer/PolicyLossWithoutReg Min             -4.01683
exploration/num steps total              548000
exploration/num paths total                1314
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54654
exploration/Rewards Std                       1.19685
exploration/Rewards Max                       6.74837
exploration/Rewards Min                      -0.852767
exploration/Returns Mean                   4546.54
exploration/Returns Std                       0
exploration/Returns Max                    4546.54
exploration/Returns Min                    4546.54
exploration/Num Paths                         1
exploration/Average Returns                4546.54
evaluation_0/num steps total                  4.22784e+06
evaluation_0/num paths total               7826
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93198
evaluation_0/Rewards Std                      0.948848
evaluation_0/Rewards Max                      7.35888
evaluation_0/Rewards Min                     -0.845118
evaluation_0/Returns Mean                  4931.98
evaluation_0/Returns Std                     49.4406
evaluation_0/Returns Max                   4998.71
evaluation_0/Returns Min                   4854.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4931.98
time/epoch (s)                                0
time/total (s)                             8542.66
Epoch                                       543
---------------------------------------  ----------------
2022-11-16 18:37:18.715831 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 544 finished
---------------------------------------  ----------------
epoch                                       544
total_step                               549000
replay_pool/size                         549000
trainer/alpha                                 0.0607625
trainer/alpha_loss                           -0.20929
trainer/entropy                              -5.92527
trainer/qf_loss                              16.5319
trainer/policy_loss                        -326.947
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         327.307
trainer/entropy_penalty                      -0.360034
trainer/entropy_percentage                   -0.00109999
trainer/Q1Pred Mean                         326.724
trainer/Q1Pred Std                           55.0899
trainer/Q1Pred Max                          408.208
trainer/Q1Pred Min                           20.4266
trainer/Q2Pred Mean                         327.021
trainer/Q2Pred Std                           55.8465
trainer/Q2Pred Max                          408.834
trainer/Q2Pred Min                            4.46084
trainer/QTargetWithReg Mean                 326.893
trainer/QTargetWithReg Std                   55.3648
trainer/QTargetWithReg Max                  407.987
trainer/QTargetWithReg Min                   10.2704
trainer/PolicyLossWithoutReg Mean           327.307
trainer/PolicyLossWithoutReg Std             55.0435
trainer/PolicyLossWithoutReg Max            407.516
trainer/PolicyLossWithoutReg Min              9.73579
exploration/num steps total              549000
exploration/num paths total                1315
exploration/path length this epoch Mean     809
exploration/path length this epoch Std        0
exploration/path length this epoch Max      809
exploration/path length this epoch Min      809
exploration/Rewards Mean                      4.14674
exploration/Rewards Std                       1.06542
exploration/Rewards Max                       6.37167
exploration/Rewards Min                      -0.695627
exploration/Returns Mean                   3354.72
exploration/Returns Std                       0
exploration/Returns Max                    3354.72
exploration/Returns Min                    3354.72
exploration/Num Paths                         1
exploration/Average Returns                3354.72
evaluation_0/num steps total                  4.23584e+06
evaluation_0/num paths total               7834
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66761
evaluation_0/Rewards Std                      1.06383
evaluation_0/Rewards Max                      7.14398
evaluation_0/Rewards Min                     -0.824307
evaluation_0/Returns Mean                  4667.61
evaluation_0/Returns Std                    106.715
evaluation_0/Returns Max                   4786.89
evaluation_0/Returns Min                   4472.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4667.61
time/epoch (s)                                0
time/total (s)                             8555.71
Epoch                                       544
---------------------------------------  ----------------
2022-11-16 18:37:30.994246 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 545 finished
---------------------------------------  ----------------
epoch                                       545
total_step                               550000
replay_pool/size                         550000
trainer/alpha                                 0.0608837
trainer/alpha_loss                            0.42505
trainer/entropy                              -6.15186
trainer/qf_loss                              18.3413
trainer/policy_loss                        -324.374
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.749
trainer/entropy_penalty                      -0.374548
trainer/entropy_percentage                   -0.00115335
trainer/Q1Pred Mean                         323.619
trainer/Q1Pred Std                           56.1078
trainer/Q1Pred Max                          407.387
trainer/Q1Pred Min                           62.0175
trainer/Q2Pred Mean                         323.886
trainer/Q2Pred Std                           55.9112
trainer/Q2Pred Max                          406.348
trainer/Q2Pred Min                           66.0164
trainer/QTargetWithReg Mean                 323.513
trainer/QTargetWithReg Std                   56.2824
trainer/QTargetWithReg Max                  407.482
trainer/QTargetWithReg Min                   51.6367
trainer/PolicyLossWithoutReg Mean           324.749
trainer/PolicyLossWithoutReg Std             54.72
trainer/PolicyLossWithoutReg Max            407.303
trainer/PolicyLossWithoutReg Min             70.8462
exploration/num steps total              550000
exploration/num paths total                1316
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45904
exploration/Rewards Std                       1.23242
exploration/Rewards Max                       7.68737
exploration/Rewards Min                      -0.784474
exploration/Returns Mean                   4459.04
exploration/Returns Std                       0
exploration/Returns Max                    4459.04
exploration/Returns Min                    4459.04
exploration/Num Paths                         1
exploration/Average Returns                4459.04
evaluation_0/num steps total                  4.24384e+06
evaluation_0/num paths total               7842
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83543
evaluation_0/Rewards Std                      0.987696
evaluation_0/Rewards Max                      7.06605
evaluation_0/Rewards Min                     -1.01926
evaluation_0/Returns Mean                  4835.43
evaluation_0/Returns Std                    138.81
evaluation_0/Returns Max                   4976.85
evaluation_0/Returns Min                   4598.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4835.43
time/epoch (s)                                0
time/total (s)                             8567.99
Epoch                                       545
---------------------------------------  ----------------
2022-11-16 18:37:44.660850 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 546 finished
---------------------------------------  ----------------
epoch                                       546
total_step                               551000
replay_pool/size                         551000
trainer/alpha                                 0.065215
trainer/alpha_loss                            0.487774
trainer/entropy                              -6.17866
trainer/qf_loss                              26.1321
trainer/policy_loss                        -316.193
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.596
trainer/entropy_penalty                      -0.402942
trainer/entropy_percentage                   -0.00127273
trainer/Q1Pred Mean                         315.122
trainer/Q1Pred Std                           71.299
trainer/Q1Pred Max                          394.232
trainer/Q1Pred Min                          -39.3659
trainer/Q2Pred Mean                         315.026
trainer/Q2Pred Std                           71.182
trainer/Q2Pred Max                          396.182
trainer/Q2Pred Min                          -33.4957
trainer/QTargetWithReg Mean                 314.703
trainer/QTargetWithReg Std                   71.1586
trainer/QTargetWithReg Max                  396.497
trainer/QTargetWithReg Min                   -2.17885
trainer/PolicyLossWithoutReg Mean           316.596
trainer/PolicyLossWithoutReg Std             66.8291
trainer/PolicyLossWithoutReg Max            393.291
trainer/PolicyLossWithoutReg Min             -0.0167248
exploration/num steps total              551000
exploration/num paths total                1319
exploration/path length this epoch Mean     177
exploration/path length this epoch Std       67.1764
exploration/path length this epoch Max      265
exploration/path length this epoch Min      102
exploration/Rewards Mean                      2.90183
exploration/Rewards Std                       1.33601
exploration/Rewards Max                       6.28146
exploration/Rewards Min                      -0.913822
exploration/Returns Mean                    513.624
exploration/Returns Std                     284.795
exploration/Returns Max                     892.572
exploration/Returns Min                     205.992
exploration/Num Paths                         3
exploration/Average Returns                 513.624
evaluation_0/num steps total                  4.25184e+06
evaluation_0/num paths total               7850
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80658
evaluation_0/Rewards Std                      0.96364
evaluation_0/Rewards Max                      7.41764
evaluation_0/Rewards Min                     -0.986811
evaluation_0/Returns Mean                  4806.58
evaluation_0/Returns Std                     61.5137
evaluation_0/Returns Max                   4885.73
evaluation_0/Returns Min                   4705.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4806.58
time/epoch (s)                                0
time/total (s)                             8581.65
Epoch                                       546
---------------------------------------  ----------------
2022-11-16 18:37:56.025777 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 547 finished
---------------------------------------  ----------------
epoch                                       547
total_step                               552000
replay_pool/size                         552000
trainer/alpha                                 0.0615832
trainer/alpha_loss                            1.24521
trainer/entropy                              -6.44673
trainer/qf_loss                              30.0427
trainer/policy_loss                        -315.482
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         315.879
trainer/entropy_penalty                      -0.39701
trainer/entropy_percentage                   -0.00125684
trainer/Q1Pred Mean                         315.305
trainer/Q1Pred Std                           73.2974
trainer/Q1Pred Max                          407.738
trainer/Q1Pred Min                            3.62456
trainer/Q2Pred Mean                         314.776
trainer/Q2Pred Std                           73.6621
trainer/Q2Pred Max                          411.405
trainer/Q2Pred Min                           -7.65531
trainer/QTargetWithReg Mean                 313.984
trainer/QTargetWithReg Std                   73.9925
trainer/QTargetWithReg Max                  408.952
trainer/QTargetWithReg Min                   -0.164953
trainer/PolicyLossWithoutReg Mean           315.879
trainer/PolicyLossWithoutReg Std             70.1547
trainer/PolicyLossWithoutReg Max            407.455
trainer/PolicyLossWithoutReg Min             -4.4749
exploration/num steps total              552000
exploration/num paths total                1320
exploration/path length this epoch Mean     752
exploration/path length this epoch Std        0
exploration/path length this epoch Max      752
exploration/path length this epoch Min      752
exploration/Rewards Mean                      4.54043
exploration/Rewards Std                       1.33085
exploration/Rewards Max                       6.97429
exploration/Rewards Min                      -0.935283
exploration/Returns Mean                   3414.4
exploration/Returns Std                       0
exploration/Returns Max                    3414.4
exploration/Returns Min                    3414.4
exploration/Num Paths                         1
exploration/Average Returns                3414.4
evaluation_0/num steps total                  4.25984e+06
evaluation_0/num paths total               7858
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62211
evaluation_0/Rewards Std                      1.06043
evaluation_0/Rewards Max                      7.02398
evaluation_0/Rewards Min                     -0.980481
evaluation_0/Returns Mean                  4622.11
evaluation_0/Returns Std                     78.6836
evaluation_0/Returns Max                   4760.57
evaluation_0/Returns Min                   4520.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4622.11
time/epoch (s)                                0
time/total (s)                             8593.02
Epoch                                       547
---------------------------------------  ----------------
2022-11-16 18:38:07.308649 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 548 finished
---------------------------------------  ----------------
epoch                                       548
total_step                               553000
replay_pool/size                         553000
trainer/alpha                                 0.0614781
trainer/alpha_loss                            2.87385
trainer/entropy                              -7.03032
trainer/qf_loss                              31.6558
trainer/policy_loss                        -316.922
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         317.354
trainer/entropy_penalty                      -0.43221
trainer/entropy_percentage                   -0.00136192
trainer/Q1Pred Mean                         316.448
trainer/Q1Pred Std                           70.1466
trainer/Q1Pred Max                          411.715
trainer/Q1Pred Min                          -11.5214
trainer/Q2Pred Mean                         316.477
trainer/Q2Pred Std                           70.4164
trainer/Q2Pred Max                          408.469
trainer/Q2Pred Min                          -15.1459
trainer/QTargetWithReg Mean                 316.965
trainer/QTargetWithReg Std                   70.4391
trainer/QTargetWithReg Max                  409.269
trainer/QTargetWithReg Min                  -12.6227
trainer/PolicyLossWithoutReg Mean           317.354
trainer/PolicyLossWithoutReg Std             69.4305
trainer/PolicyLossWithoutReg Max            408.65
trainer/PolicyLossWithoutReg Min            -12.7475
exploration/num steps total              553000
exploration/num paths total                1321
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38824
exploration/Rewards Std                       1.06919
exploration/Rewards Max                       6.91165
exploration/Rewards Min                      -0.764805
exploration/Returns Mean                   4388.24
exploration/Returns Std                       0
exploration/Returns Max                    4388.24
exploration/Returns Min                    4388.24
exploration/Num Paths                         1
exploration/Average Returns                4388.24
evaluation_0/num steps total                  4.26784e+06
evaluation_0/num paths total               7866
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79086
evaluation_0/Rewards Std                      0.975923
evaluation_0/Rewards Max                      7.16218
evaluation_0/Rewards Min                     -0.643937
evaluation_0/Returns Mean                  4790.86
evaluation_0/Returns Std                     80.9452
evaluation_0/Returns Max                   4903.41
evaluation_0/Returns Min                   4675.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4790.86
time/epoch (s)                                0
time/total (s)                             8604.3
Epoch                                       548
---------------------------------------  ----------------
2022-11-16 18:38:20.530753 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 549 finished
---------------------------------------  ----------------
epoch                                       549
total_step                               554000
replay_pool/size                         554000
trainer/alpha                                 0.0616286
trainer/alpha_loss                            0.0530887
trainer/entropy                              -6.01905
trainer/qf_loss                              27.6305
trainer/policy_loss                        -318.633
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         319.004
trainer/entropy_penalty                      -0.370946
trainer/entropy_percentage                   -0.00116282
trainer/Q1Pred Mean                         319.117
trainer/Q1Pred Std                           57.9582
trainer/Q1Pred Max                          408.488
trainer/Q1Pred Min                            9.76979
trainer/Q2Pred Mean                         318.776
trainer/Q2Pred Std                           57.7234
trainer/Q2Pred Max                          405.59
trainer/Q2Pred Min                           29.8596
trainer/QTargetWithReg Mean                 317.305
trainer/QTargetWithReg Std                   57.666
trainer/QTargetWithReg Max                  405.588
trainer/QTargetWithReg Min                    0.719168
trainer/PolicyLossWithoutReg Mean           319.004
trainer/PolicyLossWithoutReg Std             56.9482
trainer/PolicyLossWithoutReg Max            405.275
trainer/PolicyLossWithoutReg Min             18.2444
exploration/num steps total              554000
exploration/num paths total                1322
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70661
exploration/Rewards Std                       1.10303
exploration/Rewards Max                       6.76737
exploration/Rewards Min                      -0.701955
exploration/Returns Mean                   4706.61
exploration/Returns Std                       0
exploration/Returns Max                    4706.61
exploration/Returns Min                    4706.61
exploration/Num Paths                         1
exploration/Average Returns                4706.61
evaluation_0/num steps total                  4.27584e+06
evaluation_0/num paths total               7874
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57367
evaluation_0/Rewards Std                      0.965657
evaluation_0/Rewards Max                      7.10698
evaluation_0/Rewards Min                     -0.523012
evaluation_0/Returns Mean                  4573.67
evaluation_0/Returns Std                     94.3879
evaluation_0/Returns Max                   4697.48
evaluation_0/Returns Min                   4386.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4573.67
time/epoch (s)                                0
time/total (s)                             8617.52
Epoch                                       549
---------------------------------------  ----------------
2022-11-16 18:38:32.235291 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 550 finished
---------------------------------------  ----------------
epoch                                       550
total_step                               555000
replay_pool/size                         555000
trainer/alpha                                 0.0598233
trainer/alpha_loss                            0.22681
trainer/entropy                              -6.08053
trainer/qf_loss                              20.0467
trainer/policy_loss                        -319.849
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.212
trainer/entropy_penalty                      -0.363758
trainer/entropy_percentage                   -0.00113599
trainer/Q1Pred Mean                         319.161
trainer/Q1Pred Std                           66.467
trainer/Q1Pred Max                          406.944
trainer/Q1Pred Min                          -10.7275
trainer/Q2Pred Mean                         319.323
trainer/Q2Pred Std                           65.7769
trainer/Q2Pred Max                          405.986
trainer/Q2Pred Min                          -11.5562
trainer/QTargetWithReg Mean                 319.372
trainer/QTargetWithReg Std                   65.8927
trainer/QTargetWithReg Max                  407.373
trainer/QTargetWithReg Min                   -0.285756
trainer/PolicyLossWithoutReg Mean           320.213
trainer/PolicyLossWithoutReg Std             64.1056
trainer/PolicyLossWithoutReg Max            405.614
trainer/PolicyLossWithoutReg Min              6.01578
exploration/num steps total              555000
exploration/num paths total                1324
exploration/path length this epoch Mean     311
exploration/path length this epoch Std      161
exploration/path length this epoch Max      472
exploration/path length this epoch Min      150
exploration/Rewards Mean                      3.69958
exploration/Rewards Std                       1.19913
exploration/Rewards Max                       6.36651
exploration/Rewards Min                      -0.712359
exploration/Returns Mean                   1150.57
exploration/Returns Std                     733.707
exploration/Returns Max                    1884.28
exploration/Returns Min                     416.864
exploration/Num Paths                         2
exploration/Average Returns                1150.57
evaluation_0/num steps total                  4.28384e+06
evaluation_0/num paths total               7882
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59938
evaluation_0/Rewards Std                      1.0361
evaluation_0/Rewards Max                      7.16667
evaluation_0/Rewards Min                     -0.703495
evaluation_0/Returns Mean                  4599.38
evaluation_0/Returns Std                     49.2733
evaluation_0/Returns Max                   4656.97
evaluation_0/Returns Min                   4482.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4599.38
time/epoch (s)                                0
time/total (s)                             8629.22
Epoch                                       550
---------------------------------------  ----------------
2022-11-16 18:38:44.872229 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 551 finished
---------------------------------------  ----------------
epoch                                       551
total_step                               556000
replay_pool/size                         556000
trainer/alpha                                 0.0613634
trainer/alpha_loss                            0.0347125
trainer/entropy                              -6.01244
trainer/qf_loss                              15.6373
trainer/policy_loss                        -323.374
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.743
trainer/entropy_penalty                      -0.368944
trainer/entropy_percentage                   -0.00113962
trainer/Q1Pred Mean                         323.174
trainer/Q1Pred Std                           60.6352
trainer/Q1Pred Max                          406.057
trainer/Q1Pred Min                            9.83033
trainer/Q2Pred Mean                         323.576
trainer/Q2Pred Std                           60.8395
trainer/Q2Pred Max                          408.318
trainer/Q2Pred Min                           12.3387
trainer/QTargetWithReg Mean                 322.669
trainer/QTargetWithReg Std                   61.2094
trainer/QTargetWithReg Max                  408.399
trainer/QTargetWithReg Min                    7.30317
trainer/PolicyLossWithoutReg Mean           323.743
trainer/PolicyLossWithoutReg Std             60.1318
trainer/PolicyLossWithoutReg Max            407.182
trainer/PolicyLossWithoutReg Min              9.71912
exploration/num steps total              556000
exploration/num paths total                1325
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15059
exploration/Rewards Std                       1.14887
exploration/Rewards Max                       6.66738
exploration/Rewards Min                      -0.536765
exploration/Returns Mean                   4150.59
exploration/Returns Std                       0
exploration/Returns Max                    4150.59
exploration/Returns Min                    4150.59
exploration/Num Paths                         1
exploration/Average Returns                4150.59
evaluation_0/num steps total                  4.29184e+06
evaluation_0/num paths total               7890
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61442
evaluation_0/Rewards Std                      1.07428
evaluation_0/Rewards Max                      7.00695
evaluation_0/Rewards Min                     -0.55529
evaluation_0/Returns Mean                  4614.42
evaluation_0/Returns Std                     69.3991
evaluation_0/Returns Max                   4734.88
evaluation_0/Returns Min                   4506.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4614.42
time/epoch (s)                                0
time/total (s)                             8641.86
Epoch                                       551
---------------------------------------  ----------------
2022-11-16 18:38:58.096413 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 552 finished
---------------------------------------  ----------------
epoch                                       552
total_step                               557000
replay_pool/size                         557000
trainer/alpha                                 0.0607373
trainer/alpha_loss                            0.0545944
trainer/entropy                              -6.01949
trainer/qf_loss                              21.4849
trainer/policy_loss                        -315.803
trainer/adversary_policy_loss                14.9902
trainer/policy_loss_without_entropy         316.168
trainer/entropy_penalty                      -0.365608
trainer/entropy_percentage                   -0.00115637
trainer/Q1Pred Mean                         314.495
trainer/Q1Pred Std                           69.7827
trainer/Q1Pred Max                          398.045
trainer/Q1Pred Min                           -7.5189
trainer/Q2Pred Mean                         315.068
trainer/Q2Pred Std                           69.6765
trainer/Q2Pred Max                          400.031
trainer/Q2Pred Min                          -11.3223
trainer/QTargetWithReg Mean                 314.687
trainer/QTargetWithReg Std                   69.9623
trainer/QTargetWithReg Max                  398.872
trainer/QTargetWithReg Min                   -6.30717
trainer/PolicyLossWithoutReg Mean           316.168
trainer/PolicyLossWithoutReg Std             68.7289
trainer/PolicyLossWithoutReg Max            399.045
trainer/PolicyLossWithoutReg Min              6.99704
exploration/num steps total              557000
exploration/num paths total                1326
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37355
exploration/Rewards Std                       1.04962
exploration/Rewards Max                       6.69834
exploration/Rewards Min                      -0.469915
exploration/Returns Mean                   4373.55
exploration/Returns Std                       0
exploration/Returns Max                    4373.55
exploration/Returns Min                    4373.55
exploration/Num Paths                         1
exploration/Average Returns                4373.55
evaluation_0/num steps total                  4.29984e+06
evaluation_0/num paths total               7898
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71705
evaluation_0/Rewards Std                      0.967345
evaluation_0/Rewards Max                      6.99004
evaluation_0/Rewards Min                     -0.505731
evaluation_0/Returns Mean                  4717.05
evaluation_0/Returns Std                     66.938
evaluation_0/Returns Max                   4812.06
evaluation_0/Returns Min                   4632.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4717.05
time/epoch (s)                                0
time/total (s)                             8655.08
Epoch                                       552
---------------------------------------  ----------------
2022-11-16 18:39:09.488117 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 553 finished
---------------------------------------  ----------------
epoch                                       553
total_step                               558000
replay_pool/size                         558000
trainer/alpha                                 0.0610799
trainer/alpha_loss                            0.284003
trainer/entropy                              -6.10159
trainer/qf_loss                              19.9552
trainer/policy_loss                        -324.263
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.635
trainer/entropy_penalty                      -0.372684
trainer/entropy_percentage                   -0.00114801
trainer/Q1Pred Mean                         323.151
trainer/Q1Pred Std                           64.841
trainer/Q1Pred Max                          406.015
trainer/Q1Pred Min                           14.6401
trainer/Q2Pred Mean                         322.862
trainer/Q2Pred Std                           64.6282
trainer/Q2Pred Max                          404.496
trainer/Q2Pred Min                           14.5867
trainer/QTargetWithReg Mean                 323.673
trainer/QTargetWithReg Std                   64.6805
trainer/QTargetWithReg Max                  404.277
trainer/QTargetWithReg Min                   14.5963
trainer/PolicyLossWithoutReg Mean           324.635
trainer/PolicyLossWithoutReg Std             61.5462
trainer/PolicyLossWithoutReg Max            404.589
trainer/PolicyLossWithoutReg Min             15.9748
exploration/num steps total              558000
exploration/num paths total                1327
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.00904
exploration/Rewards Std                       1.35554
exploration/Rewards Max                       6.71052
exploration/Rewards Min                      -0.344686
exploration/Returns Mean                   4009.04
exploration/Returns Std                       0
exploration/Returns Max                    4009.04
exploration/Returns Min                    4009.04
exploration/Num Paths                         1
exploration/Average Returns                4009.04
evaluation_0/num steps total                  4.30784e+06
evaluation_0/num paths total               7906
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64378
evaluation_0/Rewards Std                      0.956688
evaluation_0/Rewards Max                      6.85875
evaluation_0/Rewards Min                     -0.612212
evaluation_0/Returns Mean                  4643.78
evaluation_0/Returns Std                     84.3251
evaluation_0/Returns Max                   4764.73
evaluation_0/Returns Min                   4503.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4643.78
time/epoch (s)                                0
time/total (s)                             8666.48
Epoch                                       553
---------------------------------------  ----------------
2022-11-16 18:39:20.631543 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 554 finished
---------------------------------------  ----------------
epoch                                       554
total_step                               559000
replay_pool/size                         559000
trainer/alpha                                 0.0601244
trainer/alpha_loss                           -0.294394
trainer/entropy                              -5.89529
trainer/qf_loss                              16.3838
trainer/policy_loss                        -320.118
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.472
trainer/entropy_penalty                      -0.35445
trainer/entropy_percentage                   -0.00110602
trainer/Q1Pred Mean                         320.404
trainer/Q1Pred Std                           61.0229
trainer/Q1Pred Max                          414.332
trainer/Q1Pred Min                           19.9561
trainer/Q2Pred Mean                         320.119
trainer/Q2Pred Std                           60.5402
trainer/Q2Pred Max                          413.894
trainer/Q2Pred Min                           25.6462
trainer/QTargetWithReg Mean                 319.533
trainer/QTargetWithReg Std                   61.4673
trainer/QTargetWithReg Max                  414.347
trainer/QTargetWithReg Min                   16.4616
trainer/PolicyLossWithoutReg Mean           320.472
trainer/PolicyLossWithoutReg Std             60.0621
trainer/PolicyLossWithoutReg Max            414.294
trainer/PolicyLossWithoutReg Min             22.9634
exploration/num steps total              559000
exploration/num paths total                1328
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70698
exploration/Rewards Std                       1.01252
exploration/Rewards Max                       6.60859
exploration/Rewards Min                      -0.76125
exploration/Returns Mean                   4706.98
exploration/Returns Std                       0
exploration/Returns Max                    4706.98
exploration/Returns Min                    4706.98
exploration/Num Paths                         1
exploration/Average Returns                4706.98
evaluation_0/num steps total                  4.31584e+06
evaluation_0/num paths total               7914
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66615
evaluation_0/Rewards Std                      0.961654
evaluation_0/Rewards Max                      6.92938
evaluation_0/Rewards Min                     -0.525086
evaluation_0/Returns Mean                  4666.15
evaluation_0/Returns Std                     50.4353
evaluation_0/Returns Max                   4769.58
evaluation_0/Returns Min                   4602.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4666.15
time/epoch (s)                                0
time/total (s)                             8677.62
Epoch                                       554
---------------------------------------  ----------------
2022-11-16 18:39:35.183935 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 555 finished
---------------------------------------  ----------------
epoch                                       555
total_step                               560000
replay_pool/size                         560000
trainer/alpha                                 0.0602734
trainer/alpha_loss                            0.188236
trainer/entropy                              -6.06702
trainer/qf_loss                              29.26
trainer/policy_loss                        -313.969
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.334
trainer/entropy_penalty                      -0.36568
trainer/entropy_percentage                   -0.00116335
trainer/Q1Pred Mean                         314.755
trainer/Q1Pred Std                           65.3826
trainer/Q1Pred Max                          408.837
trainer/Q1Pred Min                            0.368852
trainer/Q2Pred Mean                         314.155
trainer/Q2Pred Std                           65.7814
trainer/Q2Pred Max                          408.961
trainer/Q2Pred Min                           -6.51171
trainer/QTargetWithReg Mean                 314.855
trainer/QTargetWithReg Std                   65.0435
trainer/QTargetWithReg Max                  408.882
trainer/QTargetWithReg Min                   -2.37215
trainer/PolicyLossWithoutReg Mean           314.334
trainer/PolicyLossWithoutReg Std             64.9267
trainer/PolicyLossWithoutReg Max            407.979
trainer/PolicyLossWithoutReg Min              3.47326
exploration/num steps total              560000
exploration/num paths total                1329
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78653
exploration/Rewards Std                       0.989188
exploration/Rewards Max                       6.85248
exploration/Rewards Min                      -0.606459
exploration/Returns Mean                   4786.53
exploration/Returns Std                       0
exploration/Returns Max                    4786.53
exploration/Returns Min                    4786.53
exploration/Num Paths                         1
exploration/Average Returns                4786.53
evaluation_0/num steps total                  4.32315e+06
evaluation_0/num paths total               7923
evaluation_0/path length Mean               812.556
evaluation_0/path length Std                260.207
evaluation_0/path length Max               1000
evaluation_0/path length Min                336
evaluation_0/Rewards Mean                     4.65499
evaluation_0/Rewards Std                      1.0112
evaluation_0/Rewards Max                      7.69243
evaluation_0/Rewards Min                     -0.432712
evaluation_0/Returns Mean                  3782.44
evaluation_0/Returns Std                   1281.5
evaluation_0/Returns Max                   4783.77
evaluation_0/Returns Min                   1476.46
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3782.44
time/epoch (s)                                0
time/total (s)                             8692.17
Epoch                                       555
---------------------------------------  ----------------
2022-11-16 18:39:46.885868 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 556 finished
---------------------------------------  ----------------
epoch                                       556
total_step                               561000
replay_pool/size                         561000
trainer/alpha                                 0.0603819
trainer/alpha_loss                            0.557007
trainer/entropy                              -6.19842
trainer/qf_loss                              25.7596
trainer/policy_loss                        -321.304
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         321.678
trainer/entropy_penalty                      -0.374272
trainer/entropy_percentage                   -0.0011635
trainer/Q1Pred Mean                         320.352
trainer/Q1Pred Std                           67.2816
trainer/Q1Pred Max                          415.377
trainer/Q1Pred Min                            4.80802
trainer/Q2Pred Mean                         320.423
trainer/Q2Pred Std                           66.8309
trainer/Q2Pred Max                          413.125
trainer/Q2Pred Min                            7.79164
trainer/QTargetWithReg Mean                 319.774
trainer/QTargetWithReg Std                   66.6509
trainer/QTargetWithReg Max                  413.022
trainer/QTargetWithReg Min                    3.96744
trainer/PolicyLossWithoutReg Mean           321.678
trainer/PolicyLossWithoutReg Std             64.1216
trainer/PolicyLossWithoutReg Max            412.461
trainer/PolicyLossWithoutReg Min             15.2818
exploration/num steps total              561000
exploration/num paths total                1330
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8567
exploration/Rewards Std                       1.00731
exploration/Rewards Max                       6.98327
exploration/Rewards Min                      -0.259856
exploration/Returns Mean                   4856.7
exploration/Returns Std                       0
exploration/Returns Max                    4856.7
exploration/Returns Min                    4856.7
exploration/Num Paths                         1
exploration/Average Returns                4856.7
evaluation_0/num steps total                  4.33115e+06
evaluation_0/num paths total               7931
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83329
evaluation_0/Rewards Std                      0.97863
evaluation_0/Rewards Max                      6.89454
evaluation_0/Rewards Min                     -0.508988
evaluation_0/Returns Mean                  4833.29
evaluation_0/Returns Std                     80.1223
evaluation_0/Returns Max                   4983.3
evaluation_0/Returns Min                   4752.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4833.29
time/epoch (s)                                0
time/total (s)                             8703.87
Epoch                                       556
---------------------------------------  ----------------
2022-11-16 18:39:58.082992 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 557 finished
---------------------------------------  ----------------
epoch                                       557
total_step                               562000
replay_pool/size                         562000
trainer/alpha                                 0.0605512
trainer/alpha_loss                            1.1549
trainer/entropy                              -6.41182
trainer/qf_loss                              22.3412
trainer/policy_loss                        -314.425
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         314.814
trainer/entropy_penalty                      -0.388243
trainer/entropy_percentage                   -0.00123325
trainer/Q1Pred Mean                         314.09
trainer/Q1Pred Std                           69.8772
trainer/Q1Pred Max                          407.459
trainer/Q1Pred Min                            4.25641
trainer/Q2Pred Mean                         313.709
trainer/Q2Pred Std                           69.9878
trainer/Q2Pred Max                          406.292
trainer/Q2Pred Min                           -2.50605
trainer/QTargetWithReg Mean                 314.48
trainer/QTargetWithReg Std                   69.7543
trainer/QTargetWithReg Max                  406.415
trainer/QTargetWithReg Min                    3.96999
trainer/PolicyLossWithoutReg Mean           314.814
trainer/PolicyLossWithoutReg Std             68.5213
trainer/PolicyLossWithoutReg Max            405.865
trainer/PolicyLossWithoutReg Min             -3.11339
exploration/num steps total              562000
exploration/num paths total                1331
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81723
exploration/Rewards Std                       0.941845
exploration/Rewards Max                       6.87235
exploration/Rewards Min                      -0.504103
exploration/Returns Mean                   4817.23
exploration/Returns Std                       0
exploration/Returns Max                    4817.23
exploration/Returns Min                    4817.23
exploration/Num Paths                         1
exploration/Average Returns                4817.23
evaluation_0/num steps total                  4.33915e+06
evaluation_0/num paths total               7939
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75233
evaluation_0/Rewards Std                      1.02284
evaluation_0/Rewards Max                      7.36283
evaluation_0/Rewards Min                     -1.0149
evaluation_0/Returns Mean                  4752.33
evaluation_0/Returns Std                    127.351
evaluation_0/Returns Max                   4937.16
evaluation_0/Returns Min                   4567.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4752.33
time/epoch (s)                                0
time/total (s)                             8715.07
Epoch                                       557
---------------------------------------  ----------------
2022-11-16 18:40:11.526878 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 558 finished
---------------------------------------  ----------------
epoch                                       558
total_step                               563000
replay_pool/size                         563000
trainer/alpha                                 0.0621537
trainer/alpha_loss                            0.967609
trainer/entropy                              -6.34827
trainer/qf_loss                              18.9396
trainer/policy_loss                        -323.678
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.072
trainer/entropy_penalty                      -0.394569
trainer/entropy_percentage                   -0.00121753
trainer/Q1Pred Mean                         322.692
trainer/Q1Pred Std                           65.6352
trainer/Q1Pred Max                          403.472
trainer/Q1Pred Min                           18.0681
trainer/Q2Pred Mean                         322.715
trainer/Q2Pred Std                           65.7634
trainer/Q2Pred Max                          402.771
trainer/Q2Pred Min                           19.1383
trainer/QTargetWithReg Mean                 322.772
trainer/QTargetWithReg Std                   65.1663
trainer/QTargetWithReg Max                  404.81
trainer/QTargetWithReg Min                   23.4562
trainer/PolicyLossWithoutReg Mean           324.072
trainer/PolicyLossWithoutReg Std             63.5681
trainer/PolicyLossWithoutReg Max            404.174
trainer/PolicyLossWithoutReg Min             20.8259
exploration/num steps total              563000
exploration/num paths total                1332
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88252
exploration/Rewards Std                       1.08137
exploration/Rewards Max                       7.08767
exploration/Rewards Min                      -0.951639
exploration/Returns Mean                   4882.52
exploration/Returns Std                       0
exploration/Returns Max                    4882.52
exploration/Returns Min                    4882.52
exploration/Num Paths                         1
exploration/Average Returns                4882.52
evaluation_0/num steps total                  4.34715e+06
evaluation_0/num paths total               7947
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6342
evaluation_0/Rewards Std                      0.949999
evaluation_0/Rewards Max                      7.02657
evaluation_0/Rewards Min                     -0.695347
evaluation_0/Returns Mean                  4634.2
evaluation_0/Returns Std                    143.918
evaluation_0/Returns Max                   4884.76
evaluation_0/Returns Min                   4410.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4634.2
time/epoch (s)                                0
time/total (s)                             8728.51
Epoch                                       558
---------------------------------------  ----------------
2022-11-16 18:40:23.160719 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 559 finished
---------------------------------------  ----------------
epoch                                       559
total_step                               564000
replay_pool/size                         564000
trainer/alpha                                 0.0632173
trainer/alpha_loss                           -1.66534
trainer/entropy                              -5.39686
trainer/qf_loss                              15.4204
trainer/policy_loss                        -322.099
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         322.441
trainer/entropy_penalty                      -0.341174
trainer/entropy_percentage                   -0.0010581
trainer/Q1Pred Mean                         321.384
trainer/Q1Pred Std                           70.3231
trainer/Q1Pred Max                          401.666
trainer/Q1Pred Min                            4.12897
trainer/Q2Pred Mean                         321.482
trainer/Q2Pred Std                           69.8503
trainer/Q2Pred Max                          403.167
trainer/Q2Pred Min                           -1.31063
trainer/QTargetWithReg Mean                 321.702
trainer/QTargetWithReg Std                   69.8311
trainer/QTargetWithReg Max                  402.364
trainer/QTargetWithReg Min                   -1.53839
trainer/PolicyLossWithoutReg Mean           322.441
trainer/PolicyLossWithoutReg Std             69.2318
trainer/PolicyLossWithoutReg Max            401.315
trainer/PolicyLossWithoutReg Min              2.03715
exploration/num steps total              564000
exploration/num paths total                1333
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76466
exploration/Rewards Std                       1.07455
exploration/Rewards Max                       6.81021
exploration/Rewards Min                      -0.661859
exploration/Returns Mean                   4764.66
exploration/Returns Std                       0
exploration/Returns Max                    4764.66
exploration/Returns Min                    4764.66
exploration/Num Paths                         1
exploration/Average Returns                4764.66
evaluation_0/num steps total                  4.35515e+06
evaluation_0/num paths total               7955
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62333
evaluation_0/Rewards Std                      0.976009
evaluation_0/Rewards Max                      7.19092
evaluation_0/Rewards Min                     -0.85516
evaluation_0/Returns Mean                  4623.33
evaluation_0/Returns Std                    107.403
evaluation_0/Returns Max                   4788.14
evaluation_0/Returns Min                   4476.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4623.33
time/epoch (s)                                0
time/total (s)                             8740.15
Epoch                                       559
---------------------------------------  ----------------
2022-11-16 18:40:34.273642 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 560 finished
---------------------------------------  ----------------
epoch                                       560
total_step                               565000
replay_pool/size                         565000
trainer/alpha                                 0.0605246
trainer/alpha_loss                            0.370876
trainer/entropy                              -6.13223
trainer/qf_loss                              31.658
trainer/policy_loss                        -317.592
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         317.964
trainer/entropy_penalty                      -0.371151
trainer/entropy_percentage                   -0.00116728
trainer/Q1Pred Mean                         316.792
trainer/Q1Pred Std                           70.901
trainer/Q1Pred Max                          411.85
trainer/Q1Pred Min                          -47.4869
trainer/Q2Pred Mean                         316.668
trainer/Q2Pred Std                           70.5246
trainer/Q2Pred Max                          412.923
trainer/Q2Pred Min                          -33.2409
trainer/QTargetWithReg Mean                 315.754
trainer/QTargetWithReg Std                   71.2634
trainer/QTargetWithReg Max                  411.963
trainer/QTargetWithReg Min                  -74.2138
trainer/PolicyLossWithoutReg Mean           317.964
trainer/PolicyLossWithoutReg Std             69.609
trainer/PolicyLossWithoutReg Max            412.703
trainer/PolicyLossWithoutReg Min            -40.7324
exploration/num steps total              565000
exploration/num paths total                1334
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.33413
exploration/Rewards Std                       1.08081
exploration/Rewards Max                       6.99408
exploration/Rewards Min                      -0.959367
exploration/Returns Mean                   4334.13
exploration/Returns Std                       0
exploration/Returns Max                    4334.13
exploration/Returns Min                    4334.13
exploration/Num Paths                         1
exploration/Average Returns                4334.13
evaluation_0/num steps total                  4.36315e+06
evaluation_0/num paths total               7963
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92606
evaluation_0/Rewards Std                      1.0807
evaluation_0/Rewards Max                      7.99638
evaluation_0/Rewards Min                     -0.385453
evaluation_0/Returns Mean                  4926.06
evaluation_0/Returns Std                     45.6822
evaluation_0/Returns Max                   4991.63
evaluation_0/Returns Min                   4858.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4926.06
time/epoch (s)                                0
time/total (s)                             8751.26
Epoch                                       560
---------------------------------------  ----------------
2022-11-16 18:40:47.643830 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 561 finished
---------------------------------------  ----------------
epoch                                       561
total_step                               566000
replay_pool/size                         566000
trainer/alpha                                 0.0603454
trainer/alpha_loss                            2.10986
trainer/entropy                              -6.75139
trainer/qf_loss                              22.7712
trainer/policy_loss                        -319.652
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.06
trainer/entropy_penalty                      -0.407416
trainer/entropy_percentage                   -0.00127294
trainer/Q1Pred Mean                         319.345
trainer/Q1Pred Std                           66.558
trainer/Q1Pred Max                          409.846
trainer/Q1Pred Min                           43.3087
trainer/Q2Pred Mean                         319.123
trainer/Q2Pred Std                           66.0141
trainer/Q2Pred Max                          407.504
trainer/Q2Pred Min                           43.9931
trainer/QTargetWithReg Mean                 318.647
trainer/QTargetWithReg Std                   66.0953
trainer/QTargetWithReg Max                  407.72
trainer/QTargetWithReg Min                   44.3965
trainer/PolicyLossWithoutReg Mean           320.06
trainer/PolicyLossWithoutReg Std             64.923
trainer/PolicyLossWithoutReg Max            408.595
trainer/PolicyLossWithoutReg Min             45.9264
exploration/num steps total              566000
exploration/num paths total                1335
exploration/path length this epoch Mean     951
exploration/path length this epoch Std        0
exploration/path length this epoch Max      951
exploration/path length this epoch Min      951
exploration/Rewards Mean                      4.77087
exploration/Rewards Std                       1.05729
exploration/Rewards Max                       7.77901
exploration/Rewards Min                      -0.446509
exploration/Returns Mean                   4537.1
exploration/Returns Std                       0
exploration/Returns Max                    4537.1
exploration/Returns Min                    4537.1
exploration/Num Paths                         1
exploration/Average Returns                4537.1
evaluation_0/num steps total                  4.37115e+06
evaluation_0/num paths total               7971
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65458
evaluation_0/Rewards Std                      1.03833
evaluation_0/Rewards Max                      7.21376
evaluation_0/Rewards Min                     -0.652932
evaluation_0/Returns Mean                  4654.58
evaluation_0/Returns Std                    105.112
evaluation_0/Returns Max                   4860.2
evaluation_0/Returns Min                   4495.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4654.58
time/epoch (s)                                0
time/total (s)                             8764.63
Epoch                                       561
---------------------------------------  ----------------
2022-11-16 18:40:58.645819 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 562 finished
---------------------------------------  ----------------
epoch                                       562
total_step                               567000
replay_pool/size                         567000
trainer/alpha                                 0.0615154
trainer/alpha_loss                           -0.626621
trainer/entropy                              -5.77526
trainer/qf_loss                              17.5128
trainer/policy_loss                        -320.358
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         320.713
trainer/entropy_penalty                      -0.355268
trainer/entropy_percentage                   -0.00110774
trainer/Q1Pred Mean                         319.692
trainer/Q1Pred Std                           60.4675
trainer/Q1Pred Max                          409.842
trainer/Q1Pred Min                           33.5281
trainer/Q2Pred Mean                         319.87
trainer/Q2Pred Std                           60.5146
trainer/Q2Pred Max                          409.965
trainer/Q2Pred Min                           31.238
trainer/QTargetWithReg Mean                 319.509
trainer/QTargetWithReg Std                   60.4254
trainer/QTargetWithReg Max                  409.367
trainer/QTargetWithReg Min                   36.2888
trainer/PolicyLossWithoutReg Mean           320.713
trainer/PolicyLossWithoutReg Std             59.7472
trainer/PolicyLossWithoutReg Max            410.501
trainer/PolicyLossWithoutReg Min             33.8591
exploration/num steps total              567000
exploration/num paths total                1336
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49436
exploration/Rewards Std                       1.24673
exploration/Rewards Max                       6.76157
exploration/Rewards Min                      -0.772228
exploration/Returns Mean                   4494.36
exploration/Returns Std                       0
exploration/Returns Max                    4494.36
exploration/Returns Min                    4494.36
exploration/Num Paths                         1
exploration/Average Returns                4494.36
evaluation_0/num steps total                  4.37915e+06
evaluation_0/num paths total               7979
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83328
evaluation_0/Rewards Std                      1.05336
evaluation_0/Rewards Max                      7.41988
evaluation_0/Rewards Min                     -0.683117
evaluation_0/Returns Mean                  4833.28
evaluation_0/Returns Std                     91.4877
evaluation_0/Returns Max                   4951.57
evaluation_0/Returns Min                   4666.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4833.28
time/epoch (s)                                0
time/total (s)                             8775.63
Epoch                                       562
---------------------------------------  ----------------
2022-11-16 18:41:09.834075 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 563 finished
---------------------------------------  ----------------
epoch                                       563
total_step                               568000
replay_pool/size                         568000
trainer/alpha                                 0.0602209
trainer/alpha_loss                           -0.626103
trainer/entropy                              -5.77716
trainer/qf_loss                              19.0837
trainer/policy_loss                        -321.63
trainer/adversary_policy_loss                15.3038
trainer/policy_loss_without_entropy         321.978
trainer/entropy_penalty                      -0.347906
trainer/entropy_percentage                   -0.00108053
trainer/Q1Pred Mean                         320.572
trainer/Q1Pred Std                           70.6706
trainer/Q1Pred Max                          414.514
trainer/Q1Pred Min                            4.00242
trainer/Q2Pred Mean                         320.972
trainer/Q2Pred Std                           70.3635
trainer/Q2Pred Max                          419.077
trainer/Q2Pred Min                           10.855
trainer/QTargetWithReg Mean                 319.845
trainer/QTargetWithReg Std                   71.1951
trainer/QTargetWithReg Max                  420.845
trainer/QTargetWithReg Min                    0.371254
trainer/PolicyLossWithoutReg Mean           321.978
trainer/PolicyLossWithoutReg Std             67.3689
trainer/PolicyLossWithoutReg Max            415.297
trainer/PolicyLossWithoutReg Min              7.04234
exploration/num steps total              568000
exploration/num paths total                1337
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90801
exploration/Rewards Std                       1.13511
exploration/Rewards Max                       7.02302
exploration/Rewards Min                      -0.732841
exploration/Returns Mean                   4908.01
exploration/Returns Std                       0
exploration/Returns Max                    4908.01
exploration/Returns Min                    4908.01
exploration/Num Paths                         1
exploration/Average Returns                4908.01
evaluation_0/num steps total                  4.38715e+06
evaluation_0/num paths total               7987
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73238
evaluation_0/Rewards Std                      0.95304
evaluation_0/Rewards Max                      7.09691
evaluation_0/Rewards Min                     -0.599714
evaluation_0/Returns Mean                  4732.38
evaluation_0/Returns Std                     75.1102
evaluation_0/Returns Max                   4863.88
evaluation_0/Returns Min                   4603.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4732.38
time/epoch (s)                                0
time/total (s)                             8786.82
Epoch                                       563
---------------------------------------  ----------------
2022-11-16 18:41:23.514621 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 564 finished
---------------------------------------  ----------------
epoch                                       564
total_step                               569000
replay_pool/size                         569000
trainer/alpha                                 0.0617004
trainer/alpha_loss                            0.218244
trainer/entropy                              -6.07835
trainer/qf_loss                              19.7166
trainer/policy_loss                        -322.745
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.12
trainer/entropy_penalty                      -0.375037
trainer/entropy_percentage                   -0.00116067
trainer/Q1Pred Mean                         322.039
trainer/Q1Pred Std                           66.9831
trainer/Q1Pred Max                          407.218
trainer/Q1Pred Min                           14.1555
trainer/Q2Pred Mean                         321.308
trainer/Q2Pred Std                           67.7769
trainer/Q2Pred Max                          406.895
trainer/Q2Pred Min                            3.50117
trainer/QTargetWithReg Mean                 322.275
trainer/QTargetWithReg Std                   67.3559
trainer/QTargetWithReg Max                  408.029
trainer/QTargetWithReg Min                    5.07891
trainer/PolicyLossWithoutReg Mean           323.12
trainer/PolicyLossWithoutReg Std             66.3352
trainer/PolicyLossWithoutReg Max            409.014
trainer/PolicyLossWithoutReg Min              7.38427
exploration/num steps total              569000
exploration/num paths total                1338
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7417
exploration/Rewards Std                       1.05454
exploration/Rewards Max                       6.5928
exploration/Rewards Min                      -0.659508
exploration/Returns Mean                   4741.7
exploration/Returns Std                       0
exploration/Returns Max                    4741.7
exploration/Returns Min                    4741.7
exploration/Num Paths                         1
exploration/Average Returns                4741.7
evaluation_0/num steps total                  4.39515e+06
evaluation_0/num paths total               7995
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.41538
evaluation_0/Rewards Std                      1.0323
evaluation_0/Rewards Max                      6.80413
evaluation_0/Rewards Min                     -0.744497
evaluation_0/Returns Mean                  4415.38
evaluation_0/Returns Std                    143.83
evaluation_0/Returns Max                   4609.26
evaluation_0/Returns Min                   4159.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4415.38
time/epoch (s)                                0
time/total (s)                             8800.5
Epoch                                       564
---------------------------------------  ----------------
2022-11-16 18:41:34.802009 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 565 finished
---------------------------------------  ----------------
epoch                                       565
total_step                               570000
replay_pool/size                         570000
trainer/alpha                                 0.0608525
trainer/alpha_loss                            1.98653
trainer/entropy                              -6.70959
trainer/qf_loss                              32.3007
trainer/policy_loss                        -320.996
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         321.404
trainer/entropy_penalty                      -0.408295
trainer/entropy_percentage                   -0.00127035
trainer/Q1Pred Mean                         320.196
trainer/Q1Pred Std                           68.7504
trainer/Q1Pred Max                          396.563
trainer/Q1Pred Min                            3.95869
trainer/Q2Pred Mean                         320.894
trainer/Q2Pred Std                           68.5208
trainer/Q2Pred Max                          395.357
trainer/Q2Pred Min                           14.8858
trainer/QTargetWithReg Mean                 321.252
trainer/QTargetWithReg Std                   68.8265
trainer/QTargetWithReg Max                  396.658
trainer/QTargetWithReg Min                    4.49223
trainer/PolicyLossWithoutReg Mean           321.404
trainer/PolicyLossWithoutReg Std             66.7516
trainer/PolicyLossWithoutReg Max            394.626
trainer/PolicyLossWithoutReg Min             13.4824
exploration/num steps total              570000
exploration/num paths total                1339
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49326
exploration/Rewards Std                       1.10983
exploration/Rewards Max                       7.15484
exploration/Rewards Min                      -0.794655
exploration/Returns Mean                   4493.26
exploration/Returns Std                       0
exploration/Returns Max                    4493.26
exploration/Returns Min                    4493.26
exploration/Num Paths                         1
exploration/Average Returns                4493.26
evaluation_0/num steps total                  4.40315e+06
evaluation_0/num paths total               8003
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81424
evaluation_0/Rewards Std                      1.21772
evaluation_0/Rewards Max                      6.97534
evaluation_0/Rewards Min                     -1.09718
evaluation_0/Returns Mean                  4814.24
evaluation_0/Returns Std                     70.2948
evaluation_0/Returns Max                   4925.31
evaluation_0/Returns Min                   4738.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4814.24
time/epoch (s)                                0
time/total (s)                             8811.79
Epoch                                       565
---------------------------------------  ----------------
2022-11-16 18:41:47.901743 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 566 finished
---------------------------------------  ----------------
epoch                                       566
total_step                               571000
replay_pool/size                         571000
trainer/alpha                                 0.0599647
trainer/alpha_loss                            0.379368
trainer/entropy                              -6.13482
trainer/qf_loss                              22.37
trainer/policy_loss                        -315.936
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         316.304
trainer/entropy_penalty                      -0.367873
trainer/entropy_percentage                   -0.00116304
trainer/Q1Pred Mean                         315.256
trainer/Q1Pred Std                           68.0148
trainer/Q1Pred Max                          406.98
trainer/Q1Pred Min                           -5.31346
trainer/Q2Pred Mean                         315.28
trainer/Q2Pred Std                           67.6194
trainer/Q2Pred Max                          409.955
trainer/Q2Pred Min                           12.667
trainer/QTargetWithReg Mean                 314.801
trainer/QTargetWithReg Std                   68.5771
trainer/QTargetWithReg Max                  405.093
trainer/QTargetWithReg Min                    0.331671
trainer/PolicyLossWithoutReg Mean           316.304
trainer/PolicyLossWithoutReg Std             64.4575
trainer/PolicyLossWithoutReg Max            405.968
trainer/PolicyLossWithoutReg Min             14.428
exploration/num steps total              571000
exploration/num paths total                1340
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76823
exploration/Rewards Std                       1.05544
exploration/Rewards Max                       7.08053
exploration/Rewards Min                      -1.02458
exploration/Returns Mean                   4768.23
exploration/Returns Std                       0
exploration/Returns Max                    4768.23
exploration/Returns Min                    4768.23
exploration/Num Paths                         1
exploration/Average Returns                4768.23
evaluation_0/num steps total                  4.41115e+06
evaluation_0/num paths total               8011
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94001
evaluation_0/Rewards Std                      1.14211
evaluation_0/Rewards Max                      7.42162
evaluation_0/Rewards Min                     -0.978536
evaluation_0/Returns Mean                  4940.01
evaluation_0/Returns Std                     34.0856
evaluation_0/Returns Max                   4996.16
evaluation_0/Returns Min                   4895.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4940.01
time/epoch (s)                                0
time/total (s)                             8824.89
Epoch                                       566
---------------------------------------  ----------------
2022-11-16 18:42:00.892042 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 567 finished
---------------------------------------  ----------------
epoch                                       567
total_step                               572000
replay_pool/size                         572000
trainer/alpha                                 0.0624207
trainer/alpha_loss                           -0.318098
trainer/entropy                              -5.88533
trainer/qf_loss                              20.9107
trainer/policy_loss                        -321.122
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         321.489
trainer/entropy_penalty                      -0.367366
trainer/entropy_percentage                   -0.0011427
trainer/Q1Pred Mean                         320
trainer/Q1Pred Std                           74.9305
trainer/Q1Pred Max                          406.991
trainer/Q1Pred Min                            4.00987
trainer/Q2Pred Mean                         320.651
trainer/Q2Pred Std                           74.7896
trainer/Q2Pred Max                          410.529
trainer/Q2Pred Min                           12.498
trainer/QTargetWithReg Mean                 320.801
trainer/QTargetWithReg Std                   74.8863
trainer/QTargetWithReg Max                  408.645
trainer/QTargetWithReg Min                    7.76569
trainer/PolicyLossWithoutReg Mean           321.489
trainer/PolicyLossWithoutReg Std             73.4333
trainer/PolicyLossWithoutReg Max            407.963
trainer/PolicyLossWithoutReg Min             13.8836
exploration/num steps total              572000
exploration/num paths total                1341
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65966
exploration/Rewards Std                       1.08294
exploration/Rewards Max                       7.02576
exploration/Rewards Min                      -0.831177
exploration/Returns Mean                   4659.66
exploration/Returns Std                       0
exploration/Returns Max                    4659.66
exploration/Returns Min                    4659.66
exploration/Num Paths                         1
exploration/Average Returns                4659.66
evaluation_0/num steps total                  4.41915e+06
evaluation_0/num paths total               8019
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65973
evaluation_0/Rewards Std                      1.00669
evaluation_0/Rewards Max                      7.17109
evaluation_0/Rewards Min                     -0.830188
evaluation_0/Returns Mean                  4659.73
evaluation_0/Returns Std                    147.153
evaluation_0/Returns Max                   4814.49
evaluation_0/Returns Min                   4321.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4659.73
time/epoch (s)                                0
time/total (s)                             8837.88
Epoch                                       567
---------------------------------------  ----------------
2022-11-16 18:42:13.393506 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 568 finished
---------------------------------------  ----------------
epoch                                       568
total_step                               573000
replay_pool/size                         573000
trainer/alpha                                 0.0594465
trainer/alpha_loss                            0.740095
trainer/entropy                              -6.2622
trainer/qf_loss                              28.4828
trainer/policy_loss                        -323.177
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.549
trainer/entropy_penalty                      -0.372266
trainer/entropy_percentage                   -0.00115057
trainer/Q1Pred Mean                         322.948
trainer/Q1Pred Std                           58.8812
trainer/Q1Pred Max                          404.857
trainer/Q1Pred Min                          -25.8066
trainer/Q2Pred Mean                         322.751
trainer/Q2Pred Std                           58.6467
trainer/Q2Pred Max                          407.251
trainer/Q2Pred Min                           -8.14084
trainer/QTargetWithReg Mean                 323.277
trainer/QTargetWithReg Std                   59.6947
trainer/QTargetWithReg Max                  409.525
trainer/QTargetWithReg Min                  -21.183
trainer/PolicyLossWithoutReg Mean           323.549
trainer/PolicyLossWithoutReg Std             58.5205
trainer/PolicyLossWithoutReg Max            407.715
trainer/PolicyLossWithoutReg Min            -12.9511
exploration/num steps total              573000
exploration/num paths total                1342
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52541
exploration/Rewards Std                       0.968051
exploration/Rewards Max                       6.81275
exploration/Rewards Min                      -0.706156
exploration/Returns Mean                   4525.41
exploration/Returns Std                       0
exploration/Returns Max                    4525.41
exploration/Returns Min                    4525.41
exploration/Num Paths                         1
exploration/Average Returns                4525.41
evaluation_0/num steps total                  4.42715e+06
evaluation_0/num paths total               8027
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83262
evaluation_0/Rewards Std                      1.04702
evaluation_0/Rewards Max                      7.45574
evaluation_0/Rewards Min                     -0.782622
evaluation_0/Returns Mean                  4832.62
evaluation_0/Returns Std                    105.312
evaluation_0/Returns Max                   4996.8
evaluation_0/Returns Min                   4660.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4832.62
time/epoch (s)                                0
time/total (s)                             8850.38
Epoch                                       568
---------------------------------------  ----------------
2022-11-16 18:42:26.836527 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 569 finished
---------------------------------------  ----------------
epoch                                       569
total_step                               574000
replay_pool/size                         574000
trainer/alpha                                 0.060149
trainer/alpha_loss                           -0.584272
trainer/entropy                              -5.79214
trainer/qf_loss                              22.7435
trainer/policy_loss                        -322.863
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.211
trainer/entropy_penalty                      -0.348391
trainer/entropy_percentage                   -0.00107791
trainer/Q1Pred Mean                         321.414
trainer/Q1Pred Std                           72.4388
trainer/Q1Pred Max                          408.556
trainer/Q1Pred Min                           16.2312
trainer/Q2Pred Mean                         321.367
trainer/Q2Pred Std                           72.5186
trainer/Q2Pred Max                          403.762
trainer/Q2Pred Min                            7.87676
trainer/QTargetWithReg Mean                 322.248
trainer/QTargetWithReg Std                   72.8464
trainer/QTargetWithReg Max                  405.435
trainer/QTargetWithReg Min                   16.3697
trainer/PolicyLossWithoutReg Mean           323.211
trainer/PolicyLossWithoutReg Std             71.5211
trainer/PolicyLossWithoutReg Max            407.257
trainer/PolicyLossWithoutReg Min             15.7726
exploration/num steps total              574000
exploration/num paths total                1343
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61628
exploration/Rewards Std                       1.18099
exploration/Rewards Max                       6.9012
exploration/Rewards Min                      -0.811224
exploration/Returns Mean                   4616.28
exploration/Returns Std                       0
exploration/Returns Max                    4616.28
exploration/Returns Min                    4616.28
exploration/Num Paths                         1
exploration/Average Returns                4616.28
evaluation_0/num steps total                  4.43515e+06
evaluation_0/num paths total               8035
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78432
evaluation_0/Rewards Std                      1.02549
evaluation_0/Rewards Max                      7.30424
evaluation_0/Rewards Min                     -0.757072
evaluation_0/Returns Mean                  4784.32
evaluation_0/Returns Std                     86.7572
evaluation_0/Returns Max                   4917.7
evaluation_0/Returns Min                   4608.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4784.32
time/epoch (s)                                0
time/total (s)                             8863.82
Epoch                                       569
---------------------------------------  ----------------
2022-11-16 18:42:40.594971 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 570 finished
---------------------------------------  ----------------
epoch                                       570
total_step                               575000
replay_pool/size                         575000
trainer/alpha                                 0.059795
trainer/alpha_loss                            2.32997
trainer/entropy                              -6.82718
trainer/qf_loss                              28.3917
trainer/policy_loss                        -319.114
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         319.522
trainer/entropy_penalty                      -0.408231
trainer/entropy_percentage                   -0.00127763
trainer/Q1Pred Mean                         318.269
trainer/Q1Pred Std                           71.4414
trainer/Q1Pred Max                          401.413
trainer/Q1Pred Min                          -10.0584
trainer/Q2Pred Mean                         318.346
trainer/Q2Pred Std                           71.765
trainer/Q2Pred Max                          402.399
trainer/Q2Pred Min                           -4.18837
trainer/QTargetWithReg Mean                 318.371
trainer/QTargetWithReg Std                   72.1844
trainer/QTargetWithReg Max                  402.619
trainer/QTargetWithReg Min                  -25.2421
trainer/PolicyLossWithoutReg Mean           319.522
trainer/PolicyLossWithoutReg Std             70.8144
trainer/PolicyLossWithoutReg Max            402.331
trainer/PolicyLossWithoutReg Min            -15.4037
exploration/num steps total              575000
exploration/num paths total                1344
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.33266
exploration/Rewards Std                       1.0025
exploration/Rewards Max                       7.00501
exploration/Rewards Min                      -0.674231
exploration/Returns Mean                   4332.66
exploration/Returns Std                       0
exploration/Returns Max                    4332.66
exploration/Returns Min                    4332.66
exploration/Num Paths                         1
exploration/Average Returns                4332.66
evaluation_0/num steps total                  4.44315e+06
evaluation_0/num paths total               8043
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93178
evaluation_0/Rewards Std                      1.02047
evaluation_0/Rewards Max                      7.21374
evaluation_0/Rewards Min                     -0.624681
evaluation_0/Returns Mean                  4931.78
evaluation_0/Returns Std                     89.0245
evaluation_0/Returns Max                   5076.96
evaluation_0/Returns Min                   4783.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4931.78
time/epoch (s)                                0
time/total (s)                             8877.58
Epoch                                       570
---------------------------------------  ----------------
2022-11-16 18:42:54.471031 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 571 finished
---------------------------------------  ----------------
epoch                                       571
total_step                               576000
replay_pool/size                         576000
trainer/alpha                                 0.0599601
trainer/alpha_loss                           -0.799654
trainer/entropy                              -5.71583
trainer/qf_loss                              18.9442
trainer/policy_loss                        -318.162
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         318.505
trainer/entropy_penalty                      -0.342722
trainer/entropy_percentage                   -0.00107603
trainer/Q1Pred Mean                         318.128
trainer/Q1Pred Std                           70.9945
trainer/Q1Pred Max                          405.841
trainer/Q1Pred Min                           20.3957
trainer/Q2Pred Mean                         317.61
trainer/Q2Pred Std                           71.3658
trainer/Q2Pred Max                          406.115
trainer/Q2Pred Min                           -3.26793
trainer/QTargetWithReg Mean                 316.631
trainer/QTargetWithReg Std                   71.855
trainer/QTargetWithReg Max                  404.899
trainer/QTargetWithReg Min                    3.31459
trainer/PolicyLossWithoutReg Mean           318.505
trainer/PolicyLossWithoutReg Std             70.0993
trainer/PolicyLossWithoutReg Max            405.351
trainer/PolicyLossWithoutReg Min             17.0447
exploration/num steps total              576000
exploration/num paths total                1345
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60803
exploration/Rewards Std                       1.11949
exploration/Rewards Max                       7.23311
exploration/Rewards Min                      -0.45939
exploration/Returns Mean                   4608.03
exploration/Returns Std                       0
exploration/Returns Max                    4608.03
exploration/Returns Min                    4608.03
exploration/Num Paths                         1
exploration/Average Returns                4608.03
evaluation_0/num steps total                  4.45041e+06
evaluation_0/num paths total               8052
evaluation_0/path length Mean               806.889
evaluation_0/path length Std                361.82
evaluation_0/path length Max               1000
evaluation_0/path length Min                 89
evaluation_0/Rewards Mean                     4.73623
evaluation_0/Rewards Std                      1.04202
evaluation_0/Rewards Max                      7.10708
evaluation_0/Rewards Min                     -0.572193
evaluation_0/Returns Mean                  3821.61
evaluation_0/Returns Std                   1822.74
evaluation_0/Returns Max                   4900.77
evaluation_0/Returns Min                    238.108
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3821.61
time/epoch (s)                                0
time/total (s)                             8891.45
Epoch                                       571
---------------------------------------  ----------------
2022-11-16 18:43:07.416190 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 572 finished
---------------------------------------  ----------------
epoch                                       572
total_step                               577000
replay_pool/size                         577000
trainer/alpha                                 0.0586996
trainer/alpha_loss                            2.26915
trainer/entropy                              -6.80028
trainer/qf_loss                              25.4351
trainer/policy_loss                        -323.372
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.771
trainer/entropy_penalty                      -0.399174
trainer/entropy_percentage                   -0.00123289
trainer/Q1Pred Mean                         323.219
trainer/Q1Pred Std                           71.4405
trainer/Q1Pred Max                          413.202
trainer/Q1Pred Min                           -3.6402
trainer/Q2Pred Mean                         322.287
trainer/Q2Pred Std                           71.2376
trainer/Q2Pred Max                          413.565
trainer/Q2Pred Min                           -0.463071
trainer/QTargetWithReg Mean                 323.097
trainer/QTargetWithReg Std                   71.8013
trainer/QTargetWithReg Max                  412.275
trainer/QTargetWithReg Min                  -26.5106
trainer/PolicyLossWithoutReg Mean           323.771
trainer/PolicyLossWithoutReg Std             69.7242
trainer/PolicyLossWithoutReg Max            413.237
trainer/PolicyLossWithoutReg Min             -3.27248
exploration/num steps total              577000
exploration/num paths total                1346
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44746
exploration/Rewards Std                       0.937505
exploration/Rewards Max                       6.9932
exploration/Rewards Min                      -0.464309
exploration/Returns Mean                   4447.46
exploration/Returns Std                       0
exploration/Returns Max                    4447.46
exploration/Returns Min                    4447.46
exploration/Num Paths                         1
exploration/Average Returns                4447.46
evaluation_0/num steps total                  4.45841e+06
evaluation_0/num paths total               8060
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89564
evaluation_0/Rewards Std                      0.992217
evaluation_0/Rewards Max                      7.07426
evaluation_0/Rewards Min                     -0.836052
evaluation_0/Returns Mean                  4895.64
evaluation_0/Returns Std                     19.5782
evaluation_0/Returns Max                   4919.67
evaluation_0/Returns Min                   4857.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4895.64
time/epoch (s)                                0
time/total (s)                             8904.4
Epoch                                       572
---------------------------------------  ----------------
2022-11-16 18:43:21.506409 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 573 finished
---------------------------------------  ----------------
epoch                                       573
total_step                               578000
replay_pool/size                         578000
trainer/alpha                                 0.0610062
trainer/alpha_loss                            1.59166
trainer/entropy                              -6.56908
trainer/qf_loss                              19.972
trainer/policy_loss                        -323.597
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.998
trainer/entropy_penalty                      -0.400755
trainer/entropy_percentage                   -0.00123691
trainer/Q1Pred Mean                         322.987
trainer/Q1Pred Std                           65.5958
trainer/Q1Pred Max                          399.946
trainer/Q1Pred Min                           25.952
trainer/Q2Pred Mean                         322.603
trainer/Q2Pred Std                           66.1328
trainer/Q2Pred Max                          399.434
trainer/Q2Pred Min                           20.3256
trainer/QTargetWithReg Mean                 323.33
trainer/QTargetWithReg Std                   65.9967
trainer/QTargetWithReg Max                  399.816
trainer/QTargetWithReg Min                   24.4582
trainer/PolicyLossWithoutReg Mean           323.998
trainer/PolicyLossWithoutReg Std             65.1202
trainer/PolicyLossWithoutReg Max            410.007
trainer/PolicyLossWithoutReg Min             23.1681
exploration/num steps total              578000
exploration/num paths total                1347
exploration/path length this epoch Mean     722
exploration/path length this epoch Std        0
exploration/path length this epoch Max      722
exploration/path length this epoch Min      722
exploration/Rewards Mean                      4.38621
exploration/Rewards Std                       1.25064
exploration/Rewards Max                       6.91577
exploration/Rewards Min                      -0.682649
exploration/Returns Mean                   3166.85
exploration/Returns Std                       0
exploration/Returns Max                    3166.85
exploration/Returns Min                    3166.85
exploration/Num Paths                         1
exploration/Average Returns                3166.85
evaluation_0/num steps total                  4.46641e+06
evaluation_0/num paths total               8068
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73128
evaluation_0/Rewards Std                      1.0196
evaluation_0/Rewards Max                      7.12812
evaluation_0/Rewards Min                     -0.842765
evaluation_0/Returns Mean                  4731.28
evaluation_0/Returns Std                     79.0315
evaluation_0/Returns Max                   4851
evaluation_0/Returns Min                   4624.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4731.28
time/epoch (s)                                0
time/total (s)                             8918.49
Epoch                                       573
---------------------------------------  ----------------
2022-11-16 18:43:32.809236 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 574 finished
---------------------------------------  ----------------
epoch                                       574
total_step                               579000
replay_pool/size                         579000
trainer/alpha                                 0.059364
trainer/alpha_loss                            2.11632
trainer/entropy                              -6.74936
trainer/qf_loss                              22.6686
trainer/policy_loss                        -321.452
trainer/adversary_policy_loss                15.2479
trainer/policy_loss_without_entropy         321.853
trainer/entropy_penalty                      -0.400669
trainer/entropy_percentage                   -0.00124488
trainer/Q1Pred Mean                         320.481
trainer/Q1Pred Std                           62.4415
trainer/Q1Pred Max                          420.166
trainer/Q1Pred Min                           38.3705
trainer/Q2Pred Mean                         320.362
trainer/Q2Pred Std                           62.4862
trainer/Q2Pred Max                          416.894
trainer/Q2Pred Min                           21.5103
trainer/QTargetWithReg Mean                 321.212
trainer/QTargetWithReg Std                   62.2907
trainer/QTargetWithReg Max                  416.68
trainer/QTargetWithReg Min                   28.9195
trainer/PolicyLossWithoutReg Mean           321.853
trainer/PolicyLossWithoutReg Std             61.7278
trainer/PolicyLossWithoutReg Max            417.494
trainer/PolicyLossWithoutReg Min             29.9302
exploration/num steps total              579000
exploration/num paths total                1348
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59894
exploration/Rewards Std                       0.951308
exploration/Rewards Max                       6.5085
exploration/Rewards Min                      -0.942948
exploration/Returns Mean                   4598.94
exploration/Returns Std                       0
exploration/Returns Max                    4598.94
exploration/Returns Min                    4598.94
exploration/Num Paths                         1
exploration/Average Returns                4598.94
evaluation_0/num steps total                  4.47441e+06
evaluation_0/num paths total               8076
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.56602
evaluation_0/Rewards Std                      1.04356
evaluation_0/Rewards Max                      7.6788
evaluation_0/Rewards Min                     -0.46108
evaluation_0/Returns Mean                  4566.02
evaluation_0/Returns Std                    164.951
evaluation_0/Returns Max                   4765.92
evaluation_0/Returns Min                   4200.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4566.02
time/epoch (s)                                0
time/total (s)                             8929.79
Epoch                                       574
---------------------------------------  ----------------
2022-11-16 18:43:43.830385 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 575 finished
---------------------------------------  ----------------
epoch                                       575
total_step                               580000
replay_pool/size                         580000
trainer/alpha                                 0.0616911
trainer/alpha_loss                           -0.801876
trainer/entropy                              -5.71214
trainer/qf_loss                              22.2482
trainer/policy_loss                        -325.527
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.879
trainer/entropy_penalty                      -0.352388
trainer/entropy_percentage                   -0.00108135
trainer/Q1Pred Mean                         324.965
trainer/Q1Pred Std                           63.655
trainer/Q1Pred Max                          407.719
trainer/Q1Pred Min                           21.106
trainer/Q2Pred Mean                         324.663
trainer/Q2Pred Std                           64.0216
trainer/Q2Pred Max                          405.282
trainer/Q2Pred Min                           27.3574
trainer/QTargetWithReg Mean                 324.996
trainer/QTargetWithReg Std                   63.7444
trainer/QTargetWithReg Max                  407.107
trainer/QTargetWithReg Min                   20.2588
trainer/PolicyLossWithoutReg Mean           325.879
trainer/PolicyLossWithoutReg Std             62.8898
trainer/PolicyLossWithoutReg Max            406.773
trainer/PolicyLossWithoutReg Min             23.8765
exploration/num steps total              580000
exploration/num paths total                1349
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.33587
exploration/Rewards Std                       1.08606
exploration/Rewards Max                       6.68961
exploration/Rewards Min                      -0.803228
exploration/Returns Mean                   4335.87
exploration/Returns Std                       0
exploration/Returns Max                    4335.87
exploration/Returns Min                    4335.87
exploration/Num Paths                         1
exploration/Average Returns                4335.87
evaluation_0/num steps total                  4.48241e+06
evaluation_0/num paths total               8084
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73073
evaluation_0/Rewards Std                      1.00438
evaluation_0/Rewards Max                      7.06522
evaluation_0/Rewards Min                     -0.722027
evaluation_0/Returns Mean                  4730.73
evaluation_0/Returns Std                    112.435
evaluation_0/Returns Max                   4950.05
evaluation_0/Returns Min                   4536.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4730.73
time/epoch (s)                                0
time/total (s)                             8940.81
Epoch                                       575
---------------------------------------  ----------------
2022-11-16 18:43:57.019158 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 576 finished
---------------------------------------  ----------------
epoch                                       576
total_step                               581000
replay_pool/size                         581000
trainer/alpha                                 0.0594448
trainer/alpha_loss                            0.124643
trainer/entropy                              -6.04416
trainer/qf_loss                              20.5579
trainer/policy_loss                        -323.879
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.239
trainer/entropy_penalty                      -0.359294
trainer/entropy_percentage                   -0.00110811
trainer/Q1Pred Mean                         323.092
trainer/Q1Pred Std                           69.3677
trainer/Q1Pred Max                          403.054
trainer/Q1Pred Min                            4.37402
trainer/Q2Pred Mean                         323.57
trainer/Q2Pred Std                           69.1812
trainer/Q2Pred Max                          403.893
trainer/Q2Pred Min                           -2.11678
trainer/QTargetWithReg Mean                 323.12
trainer/QTargetWithReg Std                   70.1411
trainer/QTargetWithReg Max                  402.747
trainer/QTargetWithReg Min                    0.239723
trainer/PolicyLossWithoutReg Mean           324.239
trainer/PolicyLossWithoutReg Std             66.9993
trainer/PolicyLossWithoutReg Max            402.941
trainer/PolicyLossWithoutReg Min              2.46103
exploration/num steps total              581000
exploration/num paths total                1351
exploration/path length this epoch Mean     476
exploration/path length this epoch Std      427
exploration/path length this epoch Max      903
exploration/path length this epoch Min       49
exploration/Rewards Mean                      4.5227
exploration/Rewards Std                       1.27699
exploration/Rewards Max                       6.81796
exploration/Rewards Min                      -0.969785
exploration/Returns Mean                   2152.8
exploration/Returns Std                    2084.23
exploration/Returns Max                    4237.03
exploration/Returns Min                      68.5756
exploration/Num Paths                         2
exploration/Average Returns                2152.8
evaluation_0/num steps total                  4.49041e+06
evaluation_0/num paths total               8092
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85204
evaluation_0/Rewards Std                      1.10064
evaluation_0/Rewards Max                      7.36139
evaluation_0/Rewards Min                     -0.445612
evaluation_0/Returns Mean                  4852.04
evaluation_0/Returns Std                     58.4382
evaluation_0/Returns Max                   4919.54
evaluation_0/Returns Min                   4731.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4852.04
time/epoch (s)                                0
time/total (s)                             8954
Epoch                                       576
---------------------------------------  ----------------
2022-11-16 18:44:09.163097 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 577 finished
---------------------------------------  ----------------
epoch                                       577
total_step                               582000
replay_pool/size                         582000
trainer/alpha                                 0.0595304
trainer/alpha_loss                           -0.733251
trainer/entropy                              -5.7401
trainer/qf_loss                              18.2319
trainer/policy_loss                        -329.347
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.688
trainer/entropy_penalty                      -0.34171
trainer/entropy_percentage                   -0.00103646
trainer/Q1Pred Mean                         330.049
trainer/Q1Pred Std                           57.9897
trainer/Q1Pred Max                          412.612
trainer/Q1Pred Min                           35.4721
trainer/Q2Pred Mean                         329.627
trainer/Q2Pred Std                           58.3779
trainer/Q2Pred Max                          410.952
trainer/Q2Pred Min                           39.0802
trainer/QTargetWithReg Mean                 329.738
trainer/QTargetWithReg Std                   57.9784
trainer/QTargetWithReg Max                  412.514
trainer/QTargetWithReg Min                   41.1332
trainer/PolicyLossWithoutReg Mean           329.688
trainer/PolicyLossWithoutReg Std             56.8668
trainer/PolicyLossWithoutReg Max            410.658
trainer/PolicyLossWithoutReg Min             40.952
exploration/num steps total              582000
exploration/num paths total                1352
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65313
exploration/Rewards Std                       1.11112
exploration/Rewards Max                       6.99271
exploration/Rewards Min                      -0.708919
exploration/Returns Mean                   4653.13
exploration/Returns Std                       0
exploration/Returns Max                    4653.13
exploration/Returns Min                    4653.13
exploration/Num Paths                         1
exploration/Average Returns                4653.13
evaluation_0/num steps total                  4.49841e+06
evaluation_0/num paths total               8100
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74843
evaluation_0/Rewards Std                      0.954509
evaluation_0/Rewards Max                      7.12492
evaluation_0/Rewards Min                     -0.662884
evaluation_0/Returns Mean                  4748.43
evaluation_0/Returns Std                    120.797
evaluation_0/Returns Max                   4854.47
evaluation_0/Returns Min                   4458.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4748.43
time/epoch (s)                                0
time/total (s)                             8966.14
Epoch                                       577
---------------------------------------  ----------------
2022-11-16 18:44:21.526894 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 578 finished
---------------------------------------  ----------------
epoch                                       578
total_step                               583000
replay_pool/size                         583000
trainer/alpha                                 0.0587944
trainer/alpha_loss                           -0.517663
trainer/entropy                              -5.81732
trainer/qf_loss                              15.4345
trainer/policy_loss                        -325.459
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.801
trainer/entropy_penalty                      -0.342026
trainer/entropy_percentage                   -0.0010498
trainer/Q1Pred Mean                         324.393
trainer/Q1Pred Std                           57.9087
trainer/Q1Pred Max                          421.016
trainer/Q1Pred Min                           18.7347
trainer/Q2Pred Mean                         324.803
trainer/Q2Pred Std                           57.7387
trainer/Q2Pred Max                          423.704
trainer/Q2Pred Min                           16.0847
trainer/QTargetWithReg Mean                 325.589
trainer/QTargetWithReg Std                   58.0591
trainer/QTargetWithReg Max                  420.636
trainer/QTargetWithReg Min                   18.9106
trainer/PolicyLossWithoutReg Mean           325.801
trainer/PolicyLossWithoutReg Std             56.4868
trainer/PolicyLossWithoutReg Max            422.018
trainer/PolicyLossWithoutReg Min             17.897
exploration/num steps total              583000
exploration/num paths total                1353
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77514
exploration/Rewards Std                       1.00911
exploration/Rewards Max                       7.12513
exploration/Rewards Min                      -1.01993
exploration/Returns Mean                   4775.14
exploration/Returns Std                       0
exploration/Returns Max                    4775.14
exploration/Returns Min                    4775.14
exploration/Num Paths                         1
exploration/Average Returns                4775.14
evaluation_0/num steps total                  4.50604e+06
evaluation_0/num paths total               8108
evaluation_0/path length Mean               954.125
evaluation_0/path length Std                 81.6401
evaluation_0/path length Max               1000
evaluation_0/path length Min                779
evaluation_0/Rewards Mean                     4.74443
evaluation_0/Rewards Std                      1.02377
evaluation_0/Rewards Max                      7.81757
evaluation_0/Rewards Min                     -0.872262
evaluation_0/Returns Mean                  4526.78
evaluation_0/Returns Std                    438.547
evaluation_0/Returns Max                   4831.99
evaluation_0/Returns Min                   3577.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4526.78
time/epoch (s)                                0
time/total (s)                             8978.51
Epoch                                       578
---------------------------------------  ----------------
2022-11-16 18:44:35.279677 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 579 finished
---------------------------------------  ----------------
epoch                                       579
total_step                               584000
replay_pool/size                         584000
trainer/alpha                                 0.0593966
trainer/alpha_loss                            0.242146
trainer/entropy                              -6.08576
trainer/qf_loss                              18.9913
trainer/policy_loss                        -332.668
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.03
trainer/entropy_penalty                      -0.361473
trainer/entropy_percentage                   -0.00108541
trainer/Q1Pred Mean                         331.999
trainer/Q1Pred Std                           61.7681
trainer/Q1Pred Max                          413.894
trainer/Q1Pred Min                           25.4485
trainer/Q2Pred Mean                         332.229
trainer/Q2Pred Std                           61.6967
trainer/Q2Pred Max                          415.304
trainer/Q2Pred Min                           17.7667
trainer/QTargetWithReg Mean                 332.284
trainer/QTargetWithReg Std                   62.5021
trainer/QTargetWithReg Max                  415.995
trainer/QTargetWithReg Min                    5.30239
trainer/PolicyLossWithoutReg Mean           333.03
trainer/PolicyLossWithoutReg Std             59.5669
trainer/PolicyLossWithoutReg Max            413.334
trainer/PolicyLossWithoutReg Min             45.3971
exploration/num steps total              584000
exploration/num paths total                1354
exploration/path length this epoch Mean     955
exploration/path length this epoch Std        0
exploration/path length this epoch Max      955
exploration/path length this epoch Min      955
exploration/Rewards Mean                      4.73672
exploration/Rewards Std                       1.02574
exploration/Rewards Max                       6.91074
exploration/Rewards Min                      -0.740613
exploration/Returns Mean                   4523.57
exploration/Returns Std                       0
exploration/Returns Max                    4523.57
exploration/Returns Min                    4523.57
exploration/Num Paths                         1
exploration/Average Returns                4523.57
evaluation_0/num steps total                  4.51404e+06
evaluation_0/num paths total               8116
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79153
evaluation_0/Rewards Std                      0.992136
evaluation_0/Rewards Max                      7.24189
evaluation_0/Rewards Min                     -0.746711
evaluation_0/Returns Mean                  4791.53
evaluation_0/Returns Std                     56.2066
evaluation_0/Returns Max                   4862.44
evaluation_0/Returns Min                   4667.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4791.53
time/epoch (s)                                0
time/total (s)                             8992.26
Epoch                                       579
---------------------------------------  ----------------
2022-11-16 18:44:46.658107 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 580 finished
---------------------------------------  ----------------
epoch                                       580
total_step                               585000
replay_pool/size                         585000
trainer/alpha                                 0.059988
trainer/alpha_loss                           -0.324773
trainer/entropy                              -5.88457
trainer/qf_loss                              17.9098
trainer/policy_loss                        -331.472
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.825
trainer/entropy_penalty                      -0.353003
trainer/entropy_percentage                   -0.00106382
trainer/Q1Pred Mean                         329.53
trainer/Q1Pred Std                           54.2523
trainer/Q1Pred Max                          419.537
trainer/Q1Pred Min                           23.9235
trainer/Q2Pred Mean                         329.28
trainer/Q2Pred Std                           54.7692
trainer/Q2Pred Max                          419.071
trainer/Q2Pred Min                           15.5204
trainer/QTargetWithReg Mean                 330.72
trainer/QTargetWithReg Std                   55.3272
trainer/QTargetWithReg Max                  422.02
trainer/QTargetWithReg Min                   23.1962
trainer/PolicyLossWithoutReg Mean           331.825
trainer/PolicyLossWithoutReg Std             53.9972
trainer/PolicyLossWithoutReg Max            422.336
trainer/PolicyLossWithoutReg Min             25.0666
exploration/num steps total              585000
exploration/num paths total                1355
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61236
exploration/Rewards Std                       0.983545
exploration/Rewards Max                       6.684
exploration/Rewards Min                      -0.69251
exploration/Returns Mean                   4612.36
exploration/Returns Std                       0
exploration/Returns Max                    4612.36
exploration/Returns Min                    4612.36
exploration/Num Paths                         1
exploration/Average Returns                4612.36
evaluation_0/num steps total                  4.52204e+06
evaluation_0/num paths total               8124
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68915
evaluation_0/Rewards Std                      1.06327
evaluation_0/Rewards Max                      7.3414
evaluation_0/Rewards Min                     -0.723581
evaluation_0/Returns Mean                  4689.15
evaluation_0/Returns Std                    105.224
evaluation_0/Returns Max                   4820.91
evaluation_0/Returns Min                   4442.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4689.15
time/epoch (s)                                0
time/total (s)                             9003.64
Epoch                                       580
---------------------------------------  ----------------
2022-11-16 18:44:59.123132 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 581 finished
---------------------------------------  ----------------
epoch                                       581
total_step                               586000
replay_pool/size                         586000
trainer/alpha                                 0.0592774
trainer/alpha_loss                            0.292963
trainer/entropy                              -6.10369
trainer/qf_loss                              19.6894
trainer/policy_loss                        -326.086
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         326.448
trainer/entropy_penalty                      -0.36181
trainer/entropy_percentage                   -0.00110833
trainer/Q1Pred Mean                         325.962
trainer/Q1Pred Std                           72.4981
trainer/Q1Pred Max                          415.209
trainer/Q1Pred Min                          -13.7581
trainer/Q2Pred Mean                         325.996
trainer/Q2Pred Std                           72.3328
trainer/Q2Pred Max                          417.16
trainer/Q2Pred Min                          -29.4972
trainer/QTargetWithReg Mean                 325.206
trainer/QTargetWithReg Std                   71.6725
trainer/QTargetWithReg Max                  412.652
trainer/QTargetWithReg Min                    3.95576
trainer/PolicyLossWithoutReg Mean           326.448
trainer/PolicyLossWithoutReg Std             71.2792
trainer/PolicyLossWithoutReg Max            415.331
trainer/PolicyLossWithoutReg Min            -24.1953
exploration/num steps total              586000
exploration/num paths total                1356
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84404
exploration/Rewards Std                       1.11274
exploration/Rewards Max                       7.36936
exploration/Rewards Min                      -0.873723
exploration/Returns Mean                   4844.04
exploration/Returns Std                       0
exploration/Returns Max                    4844.04
exploration/Returns Min                    4844.04
exploration/Num Paths                         1
exploration/Average Returns                4844.04
evaluation_0/num steps total                  4.52999e+06
evaluation_0/num paths total               8132
evaluation_0/path length Mean               993.75
evaluation_0/path length Std                 16.5359
evaluation_0/path length Max               1000
evaluation_0/path length Min                950
evaluation_0/Rewards Mean                     4.78626
evaluation_0/Rewards Std                      1.03727
evaluation_0/Rewards Max                      8.50207
evaluation_0/Rewards Min                     -0.734978
evaluation_0/Returns Mean                  4756.34
evaluation_0/Returns Std                     66.2778
evaluation_0/Returns Max                   4852.5
evaluation_0/Returns Min                   4630.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4756.34
time/epoch (s)                                0
time/total (s)                             9016.1
Epoch                                       581
---------------------------------------  ----------------
2022-11-16 18:45:13.492707 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 582 finished
---------------------------------------  ----------------
epoch                                       582
total_step                               587000
replay_pool/size                         587000
trainer/alpha                                 0.05988
trainer/alpha_loss                            0.294085
trainer/entropy                              -6.10446
trainer/qf_loss                              18.9062
trainer/policy_loss                        -329.382
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.748
trainer/entropy_penalty                      -0.365535
trainer/entropy_percentage                   -0.00110853
trainer/Q1Pred Mean                         328.541
trainer/Q1Pred Std                           70.7841
trainer/Q1Pred Max                          416.827
trainer/Q1Pred Min                          -15.9311
trainer/Q2Pred Mean                         329.076
trainer/Q2Pred Std                           71.1234
trainer/Q2Pred Max                          415.398
trainer/Q2Pred Min                          -26.4608
trainer/QTargetWithReg Mean                 329.365
trainer/QTargetWithReg Std                   70.6224
trainer/QTargetWithReg Max                  417.063
trainer/QTargetWithReg Min                   -1.74884
trainer/PolicyLossWithoutReg Mean           329.748
trainer/PolicyLossWithoutReg Std             69.958
trainer/PolicyLossWithoutReg Max            415.731
trainer/PolicyLossWithoutReg Min            -23.8206
exploration/num steps total              587000
exploration/num paths total                1357
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50314
exploration/Rewards Std                       1.19251
exploration/Rewards Max                       6.88165
exploration/Rewards Min                      -1.04558
exploration/Returns Mean                   4503.14
exploration/Returns Std                       0
exploration/Returns Max                    4503.14
exploration/Returns Min                    4503.14
exploration/Num Paths                         1
exploration/Average Returns                4503.14
evaluation_0/num steps total                  4.53799e+06
evaluation_0/num paths total               8140
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67111
evaluation_0/Rewards Std                      1.06384
evaluation_0/Rewards Max                      7.33606
evaluation_0/Rewards Min                     -0.613383
evaluation_0/Returns Mean                  4671.11
evaluation_0/Returns Std                     69.9296
evaluation_0/Returns Max                   4758.29
evaluation_0/Returns Min                   4533.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4671.11
time/epoch (s)                                0
time/total (s)                             9030.47
Epoch                                       582
---------------------------------------  ----------------
2022-11-16 18:45:24.935112 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 583 finished
---------------------------------------  ----------------
epoch                                       583
total_step                               588000
replay_pool/size                         588000
trainer/alpha                                 0.0598431
trainer/alpha_loss                            0.388976
trainer/entropy                              -6.13813
trainer/qf_loss                              19.261
trainer/policy_loss                        -322.407
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         322.774
trainer/entropy_penalty                      -0.367325
trainer/entropy_percentage                   -0.00113802
trainer/Q1Pred Mean                         322.025
trainer/Q1Pred Std                           67.2326
trainer/Q1Pred Max                          415.577
trainer/Q1Pred Min                           16.4208
trainer/Q2Pred Mean                         322.062
trainer/Q2Pred Std                           67.4928
trainer/Q2Pred Max                          414.652
trainer/Q2Pred Min                           12.1151
trainer/QTargetWithReg Mean                 321.841
trainer/QTargetWithReg Std                   66.9733
trainer/QTargetWithReg Max                  415.893
trainer/QTargetWithReg Min                    1.87032
trainer/PolicyLossWithoutReg Mean           322.774
trainer/PolicyLossWithoutReg Std             64.4308
trainer/PolicyLossWithoutReg Max            415.077
trainer/PolicyLossWithoutReg Min             44.5761
exploration/num steps total              588000
exploration/num paths total                1358
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5689
exploration/Rewards Std                       1.08218
exploration/Rewards Max                       7.21827
exploration/Rewards Min                      -0.545796
exploration/Returns Mean                   4568.9
exploration/Returns Std                       0
exploration/Returns Max                    4568.9
exploration/Returns Min                    4568.9
exploration/Num Paths                         1
exploration/Average Returns                4568.9
evaluation_0/num steps total                  4.54599e+06
evaluation_0/num paths total               8148
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68567
evaluation_0/Rewards Std                      0.960185
evaluation_0/Rewards Max                      7.53122
evaluation_0/Rewards Min                     -0.661981
evaluation_0/Returns Mean                  4685.67
evaluation_0/Returns Std                    105.997
evaluation_0/Returns Max                   4808.62
evaluation_0/Returns Min                   4459.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4685.67
time/epoch (s)                                0
time/total (s)                             9041.91
Epoch                                       583
---------------------------------------  ----------------
2022-11-16 18:45:36.320016 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 584 finished
---------------------------------------  ----------------
epoch                                       584
total_step                               589000
replay_pool/size                         589000
trainer/alpha                                 0.0610117
trainer/alpha_loss                           -0.352043
trainer/entropy                              -5.87413
trainer/qf_loss                              14.126
trainer/policy_loss                        -329.151
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.51
trainer/entropy_penalty                      -0.358391
trainer/entropy_percentage                   -0.00108765
trainer/Q1Pred Mean                         329.031
trainer/Q1Pred Std                           54.5671
trainer/Q1Pred Max                          415.858
trainer/Q1Pred Min                          120.294
trainer/Q2Pred Mean                         329.744
trainer/Q2Pred Std                           54.3001
trainer/Q2Pred Max                          417.425
trainer/Q2Pred Min                          109.933
trainer/QTargetWithReg Mean                 329.112
trainer/QTargetWithReg Std                   54.5084
trainer/QTargetWithReg Max                  417.157
trainer/QTargetWithReg Min                  126.317
trainer/PolicyLossWithoutReg Mean           329.51
trainer/PolicyLossWithoutReg Std             53.3151
trainer/PolicyLossWithoutReg Max            416.316
trainer/PolicyLossWithoutReg Min            132.526
exploration/num steps total              589000
exploration/num paths total                1359
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54225
exploration/Rewards Std                       0.984566
exploration/Rewards Max                       6.88996
exploration/Rewards Min                      -0.579656
exploration/Returns Mean                   4542.25
exploration/Returns Std                       0
exploration/Returns Max                    4542.25
exploration/Returns Min                    4542.25
exploration/Num Paths                         1
exploration/Average Returns                4542.25
evaluation_0/num steps total                  4.55399e+06
evaluation_0/num paths total               8156
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71449
evaluation_0/Rewards Std                      0.968651
evaluation_0/Rewards Max                      7.0882
evaluation_0/Rewards Min                     -0.623107
evaluation_0/Returns Mean                  4714.49
evaluation_0/Returns Std                     41.5527
evaluation_0/Returns Max                   4780.32
evaluation_0/Returns Min                   4650.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4714.49
time/epoch (s)                                0
time/total (s)                             9053.3
Epoch                                       584
---------------------------------------  ----------------
2022-11-16 18:45:49.551418 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 585 finished
---------------------------------------  ----------------
epoch                                       585
total_step                               590000
replay_pool/size                         590000
trainer/alpha                                 0.0600187
trainer/alpha_loss                            0.00270281
trainer/entropy                              -6.00096
trainer/qf_loss                              22.421
trainer/policy_loss                        -325.669
trainer/adversary_policy_loss                15.5844
trainer/policy_loss_without_entropy         326.03
trainer/entropy_penalty                      -0.36017
trainer/entropy_percentage                   -0.00110472
trainer/Q1Pred Mean                         327.001
trainer/Q1Pred Std                           65.5274
trainer/Q1Pred Max                          418.875
trainer/Q1Pred Min                          -38.8901
trainer/Q2Pred Mean                         325.875
trainer/Q2Pred Std                           65.0926
trainer/Q2Pred Max                          415.56
trainer/Q2Pred Min                          -17.7547
trainer/QTargetWithReg Mean                 325.635
trainer/QTargetWithReg Std                   65.2784
trainer/QTargetWithReg Max                  418.104
trainer/QTargetWithReg Min                  -15.4241
trainer/PolicyLossWithoutReg Mean           326.03
trainer/PolicyLossWithoutReg Std             64.6604
trainer/PolicyLossWithoutReg Max            415.396
trainer/PolicyLossWithoutReg Min            -23.9426
exploration/num steps total              590000
exploration/num paths total                1360
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47925
exploration/Rewards Std                       1.00856
exploration/Rewards Max                       6.72307
exploration/Rewards Min                      -0.653428
exploration/Returns Mean                   4479.25
exploration/Returns Std                       0
exploration/Returns Max                    4479.25
exploration/Returns Min                    4479.25
exploration/Num Paths                         1
exploration/Average Returns                4479.25
evaluation_0/num steps total                  4.56199e+06
evaluation_0/num paths total               8164
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63702
evaluation_0/Rewards Std                      1.16193
evaluation_0/Rewards Max                      7.17373
evaluation_0/Rewards Min                     -0.646671
evaluation_0/Returns Mean                  4637.02
evaluation_0/Returns Std                    115.694
evaluation_0/Returns Max                   4803.11
evaluation_0/Returns Min                   4426.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4637.02
time/epoch (s)                                0
time/total (s)                             9066.53
Epoch                                       585
---------------------------------------  ----------------
2022-11-16 18:46:01.276871 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 586 finished
---------------------------------------  ----------------
epoch                                       586
total_step                               591000
replay_pool/size                         591000
trainer/alpha                                 0.060585
trainer/alpha_loss                            1.31007
trainer/entropy                              -6.46723
trainer/qf_loss                              35.1934
trainer/policy_loss                        -328.094
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         328.486
trainer/entropy_penalty                      -0.391817
trainer/entropy_percentage                   -0.0011928
trainer/Q1Pred Mean                         326.674
trainer/Q1Pred Std                           64.4387
trainer/Q1Pred Max                          410.249
trainer/Q1Pred Min                           16.7824
trainer/Q2Pred Mean                         326.755
trainer/Q2Pred Std                           64.3296
trainer/Q2Pred Max                          413.069
trainer/Q2Pred Min                           20.9113
trainer/QTargetWithReg Mean                 325.408
trainer/QTargetWithReg Std                   64.6614
trainer/QTargetWithReg Max                  408.091
trainer/QTargetWithReg Min                   15.1977
trainer/PolicyLossWithoutReg Mean           328.486
trainer/PolicyLossWithoutReg Std             62.1126
trainer/PolicyLossWithoutReg Max            412.436
trainer/PolicyLossWithoutReg Min             13.1015
exploration/num steps total              591000
exploration/num paths total                1361
exploration/path length this epoch Mean     676
exploration/path length this epoch Std        0
exploration/path length this epoch Max      676
exploration/path length this epoch Min      676
exploration/Rewards Mean                      4.25781
exploration/Rewards Std                       1.13971
exploration/Rewards Max                       6.7426
exploration/Rewards Min                      -0.653178
exploration/Returns Mean                   2878.28
exploration/Returns Std                       0
exploration/Returns Max                    2878.28
exploration/Returns Min                    2878.28
exploration/Num Paths                         1
exploration/Average Returns                2878.28
evaluation_0/num steps total                  4.56999e+06
evaluation_0/num paths total               8172
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74673
evaluation_0/Rewards Std                      0.965904
evaluation_0/Rewards Max                      6.95809
evaluation_0/Rewards Min                     -0.759658
evaluation_0/Returns Mean                  4746.73
evaluation_0/Returns Std                     69.8681
evaluation_0/Returns Max                   4828.23
evaluation_0/Returns Min                   4589.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4746.73
time/epoch (s)                                0
time/total (s)                             9078.25
Epoch                                       586
---------------------------------------  ----------------
2022-11-16 18:46:12.497017 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 587 finished
---------------------------------------  ----------------
epoch                                       587
total_step                               592000
replay_pool/size                         592000
trainer/alpha                                 0.060872
trainer/alpha_loss                           -2.45154
trainer/entropy                              -5.12406
trainer/qf_loss                              19.4787
trainer/policy_loss                        -330.042
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.354
trainer/entropy_penalty                      -0.311911
trainer/entropy_percentage                   -0.000944172
trainer/Q1Pred Mean                         329.496
trainer/Q1Pred Std                           61.3393
trainer/Q1Pred Max                          403.253
trainer/Q1Pred Min                           -1.55435
trainer/Q2Pred Mean                         329.814
trainer/Q2Pred Std                           60.8602
trainer/Q2Pred Max                          405.011
trainer/Q2Pred Min                           18.9909
trainer/QTargetWithReg Mean                 329.388
trainer/QTargetWithReg Std                   61.3286
trainer/QTargetWithReg Max                  405.384
trainer/QTargetWithReg Min                    7.02718
trainer/PolicyLossWithoutReg Mean           330.354
trainer/PolicyLossWithoutReg Std             60.7876
trainer/PolicyLossWithoutReg Max            403.44
trainer/PolicyLossWithoutReg Min              7.04781
exploration/num steps total              592000
exploration/num paths total                1362
exploration/path length this epoch Mean     335
exploration/path length this epoch Std        0
exploration/path length this epoch Max      335
exploration/path length this epoch Min      335
exploration/Rewards Mean                      3.85887
exploration/Rewards Std                       1.29505
exploration/Rewards Max                       6.75929
exploration/Rewards Min                      -0.0766332
exploration/Returns Mean                   1292.72
exploration/Returns Std                       0
exploration/Returns Max                    1292.72
exploration/Returns Min                    1292.72
exploration/Num Paths                         1
exploration/Average Returns                1292.72
evaluation_0/num steps total                  4.57799e+06
evaluation_0/num paths total               8180
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64415
evaluation_0/Rewards Std                      0.992409
evaluation_0/Rewards Max                      7.2597
evaluation_0/Rewards Min                     -0.780354
evaluation_0/Returns Mean                  4644.15
evaluation_0/Returns Std                    121.077
evaluation_0/Returns Max                   4810.94
evaluation_0/Returns Min                   4362.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4644.15
time/epoch (s)                                0
time/total (s)                             9089.47
Epoch                                       587
---------------------------------------  ----------------
2022-11-16 18:46:26.109881 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 588 finished
---------------------------------------  ----------------
epoch                                       588
total_step                               593000
replay_pool/size                         593000
trainer/alpha                                 0.0590854
trainer/alpha_loss                           -0.206264
trainer/entropy                              -5.92708
trainer/qf_loss                              33.1565
trainer/policy_loss                        -329.684
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.034
trainer/entropy_penalty                      -0.350204
trainer/entropy_percentage                   -0.00106112
trainer/Q1Pred Mean                         328.914
trainer/Q1Pred Std                           58.6489
trainer/Q1Pred Max                          409.995
trainer/Q1Pred Min                           24.7762
trainer/Q2Pred Mean                         328.98
trainer/Q2Pred Std                           58.147
trainer/Q2Pred Max                          410.502
trainer/Q2Pred Min                           31.287
trainer/QTargetWithReg Mean                 330.282
trainer/QTargetWithReg Std                   58.6933
trainer/QTargetWithReg Max                  412.388
trainer/QTargetWithReg Min                   27.873
trainer/PolicyLossWithoutReg Mean           330.034
trainer/PolicyLossWithoutReg Std             57.9136
trainer/PolicyLossWithoutReg Max            411.704
trainer/PolicyLossWithoutReg Min             22.1335
exploration/num steps total              593000
exploration/num paths total                1363
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49605
exploration/Rewards Std                       1.01723
exploration/Rewards Max                       6.63391
exploration/Rewards Min                      -0.801382
exploration/Returns Mean                   4496.05
exploration/Returns Std                       0
exploration/Returns Max                    4496.05
exploration/Returns Min                    4496.05
exploration/Num Paths                         1
exploration/Average Returns                4496.05
evaluation_0/num steps total                  4.58599e+06
evaluation_0/num paths total               8188
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70749
evaluation_0/Rewards Std                      0.992349
evaluation_0/Rewards Max                      7.09785
evaluation_0/Rewards Min                     -0.624007
evaluation_0/Returns Mean                  4707.49
evaluation_0/Returns Std                     92.0088
evaluation_0/Returns Max                   4886.15
evaluation_0/Returns Min                   4568.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4707.49
time/epoch (s)                                0
time/total (s)                             9103.09
Epoch                                       588
---------------------------------------  ----------------
2022-11-16 18:46:39.125104 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 589 finished
---------------------------------------  ----------------
epoch                                       589
total_step                               594000
replay_pool/size                         594000
trainer/alpha                                 0.0595354
trainer/alpha_loss                            0.283661
trainer/entropy                              -6.10055
trainer/qf_loss                              16.99
trainer/policy_loss                        -326.007
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         326.371
trainer/entropy_penalty                      -0.363198
trainer/entropy_percentage                   -0.00111284
trainer/Q1Pred Mean                         324.681
trainer/Q1Pred Std                           64.0597
trainer/Q1Pred Max                          414.616
trainer/Q1Pred Min                           10.5555
trainer/Q2Pred Mean                         325.246
trainer/Q2Pred Std                           63.7093
trainer/Q2Pred Max                          413.205
trainer/Q2Pred Min                           24.7862
trainer/QTargetWithReg Mean                 325.392
trainer/QTargetWithReg Std                   64.2593
trainer/QTargetWithReg Max                  414.758
trainer/QTargetWithReg Min                   17.5061
trainer/PolicyLossWithoutReg Mean           326.37
trainer/PolicyLossWithoutReg Std             62.4821
trainer/PolicyLossWithoutReg Max            414.803
trainer/PolicyLossWithoutReg Min             29.6425
exploration/num steps total              594000
exploration/num paths total                1364
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51039
exploration/Rewards Std                       1.0437
exploration/Rewards Max                       6.90306
exploration/Rewards Min                      -0.759798
exploration/Returns Mean                   4510.39
exploration/Returns Std                       0
exploration/Returns Max                    4510.39
exploration/Returns Min                    4510.39
exploration/Num Paths                         1
exploration/Average Returns                4510.39
evaluation_0/num steps total                  4.59399e+06
evaluation_0/num paths total               8196
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.39627
evaluation_0/Rewards Std                      1.18722
evaluation_0/Rewards Max                      7.22615
evaluation_0/Rewards Min                     -0.652212
evaluation_0/Returns Mean                  4396.27
evaluation_0/Returns Std                    136.254
evaluation_0/Returns Max                   4550.23
evaluation_0/Returns Min                   4087.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4396.27
time/epoch (s)                                0
time/total (s)                             9116.1
Epoch                                       589
---------------------------------------  ----------------
2022-11-16 18:46:51.238836 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 590 finished
---------------------------------------  ----------------
epoch                                       590
total_step                               595000
replay_pool/size                         595000
trainer/alpha                                 0.060332
trainer/alpha_loss                           -0.549639
trainer/entropy                              -5.80425
trainer/qf_loss                              22.5471
trainer/policy_loss                        -327.999
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         328.349
trainer/entropy_penalty                      -0.350182
trainer/entropy_percentage                   -0.00106649
trainer/Q1Pred Mean                         327.441
trainer/Q1Pred Std                           69.285
trainer/Q1Pred Max                          404.932
trainer/Q1Pred Min                           14.2627
trainer/Q2Pred Mean                         327.244
trainer/Q2Pred Std                           68.7087
trainer/Q2Pred Max                          406.777
trainer/Q2Pred Min                           12.0959
trainer/QTargetWithReg Mean                 327.289
trainer/QTargetWithReg Std                   68.576
trainer/QTargetWithReg Max                  404.714
trainer/QTargetWithReg Min                    8.86042
trainer/PolicyLossWithoutReg Mean           328.349
trainer/PolicyLossWithoutReg Std             66.8076
trainer/PolicyLossWithoutReg Max            405.605
trainer/PolicyLossWithoutReg Min             14.0179
exploration/num steps total              595000
exploration/num paths total                1365
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48188
exploration/Rewards Std                       0.980531
exploration/Rewards Max                       6.96727
exploration/Rewards Min                      -0.977582
exploration/Returns Mean                   4481.88
exploration/Returns Std                       0
exploration/Returns Max                    4481.88
exploration/Returns Min                    4481.88
exploration/Num Paths                         1
exploration/Average Returns                4481.88
evaluation_0/num steps total                  4.60199e+06
evaluation_0/num paths total               8204
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6083
evaluation_0/Rewards Std                      0.983408
evaluation_0/Rewards Max                      6.99773
evaluation_0/Rewards Min                     -0.54859
evaluation_0/Returns Mean                  4608.3
evaluation_0/Returns Std                    110.739
evaluation_0/Returns Max                   4721.34
evaluation_0/Returns Min                   4419.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4608.3
time/epoch (s)                                0
time/total (s)                             9128.21
Epoch                                       590
---------------------------------------  ----------------
2022-11-16 18:47:05.767856 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 591 finished
---------------------------------------  ----------------
epoch                                       591
total_step                               596000
replay_pool/size                         596000
trainer/alpha                                 0.058302
trainer/alpha_loss                            1.55547
trainer/entropy                              -6.54725
trainer/qf_loss                              23.6108
trainer/policy_loss                        -324.676
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.058
trainer/entropy_penalty                      -0.381718
trainer/entropy_percentage                   -0.00117431
trainer/Q1Pred Mean                         325.295
trainer/Q1Pred Std                           70.6664
trainer/Q1Pred Max                          421.045
trainer/Q1Pred Min                           42.0916
trainer/Q2Pred Mean                         325.568
trainer/Q2Pred Std                           70.8529
trainer/Q2Pred Max                          417.531
trainer/Q2Pred Min                           33.9465
trainer/QTargetWithReg Mean                 324.159
trainer/QTargetWithReg Std                   71.3854
trainer/QTargetWithReg Max                  415.747
trainer/QTargetWithReg Min                   30.8002
trainer/PolicyLossWithoutReg Mean           325.058
trainer/PolicyLossWithoutReg Std             69.5438
trainer/PolicyLossWithoutReg Max            416.743
trainer/PolicyLossWithoutReg Min             38.115
exploration/num steps total              596000
exploration/num paths total                1366
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50086
exploration/Rewards Std                       1.01513
exploration/Rewards Max                       6.73729
exploration/Rewards Min                      -0.597941
exploration/Returns Mean                   4500.86
exploration/Returns Std                       0
exploration/Returns Max                    4500.86
exploration/Returns Min                    4500.86
exploration/Num Paths                         1
exploration/Average Returns                4500.86
evaluation_0/num steps total                  4.60984e+06
evaluation_0/num paths total               8213
evaluation_0/path length Mean               871.444
evaluation_0/path length Std                176.763
evaluation_0/path length Max               1000
evaluation_0/path length Min                448
evaluation_0/Rewards Mean                     4.68201
evaluation_0/Rewards Std                      1.14903
evaluation_0/Rewards Max                      8.72944
evaluation_0/Rewards Min                     -0.700182
evaluation_0/Returns Mean                  4080.11
evaluation_0/Returns Std                    847.894
evaluation_0/Returns Max                   4774.94
evaluation_0/Returns Min                   1985.72
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4080.11
time/epoch (s)                                0
time/total (s)                             9142.74
Epoch                                       591
---------------------------------------  ----------------
2022-11-16 18:47:17.915984 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 592 finished
---------------------------------------  ----------------
epoch                                       592
total_step                               597000
replay_pool/size                         597000
trainer/alpha                                 0.0581178
trainer/alpha_loss                           -0.00920976
trainer/entropy                              -5.99676
trainer/qf_loss                              20.5581
trainer/policy_loss                        -324.685
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.033
trainer/entropy_penalty                      -0.348519
trainer/entropy_percentage                   -0.00107226
trainer/Q1Pred Mean                         324.971
trainer/Q1Pred Std                           71.1021
trainer/Q1Pred Max                          414.087
trainer/Q1Pred Min                          -11.9043
trainer/Q2Pred Mean                         323.751
trainer/Q2Pred Std                           70.7051
trainer/Q2Pred Max                          411.654
trainer/Q2Pred Min                           -3.92874
trainer/QTargetWithReg Mean                 324.328
trainer/QTargetWithReg Std                   70.6623
trainer/QTargetWithReg Max                  412.32
trainer/QTargetWithReg Min                    5.59606
trainer/PolicyLossWithoutReg Mean           325.033
trainer/PolicyLossWithoutReg Std             69.391
trainer/PolicyLossWithoutReg Max            413.435
trainer/PolicyLossWithoutReg Min              5.85058
exploration/num steps total              597000
exploration/num paths total                1368
exploration/path length this epoch Mean     408.5
exploration/path length this epoch Std      342.5
exploration/path length this epoch Max      751
exploration/path length this epoch Min       66
exploration/Rewards Mean                      4.15435
exploration/Rewards Std                       1.28451
exploration/Rewards Max                       7.39353
exploration/Rewards Min                      -0.731379
exploration/Returns Mean                   1697.05
exploration/Returns Std                    1558.05
exploration/Returns Max                    3255.1
exploration/Returns Min                     139.006
exploration/Num Paths                         2
exploration/Average Returns                1697.05
evaluation_0/num steps total                  4.61784e+06
evaluation_0/num paths total               8221
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76538
evaluation_0/Rewards Std                      1.08279
evaluation_0/Rewards Max                      7.68832
evaluation_0/Rewards Min                     -0.839396
evaluation_0/Returns Mean                  4765.38
evaluation_0/Returns Std                     75.4734
evaluation_0/Returns Max                   4852
evaluation_0/Returns Min                   4588.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4765.38
time/epoch (s)                                0
time/total (s)                             9154.89
Epoch                                       592
---------------------------------------  ----------------
2022-11-16 18:47:31.119638 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 593 finished
---------------------------------------  ----------------
epoch                                       593
total_step                               598000
replay_pool/size                         598000
trainer/alpha                                 0.0579876
trainer/alpha_loss                            0.367829
trainer/entropy                              -6.12918
trainer/qf_loss                              24.8601
trainer/policy_loss                        -328.927
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.283
trainer/entropy_penalty                      -0.355416
trainer/entropy_percentage                   -0.00107937
trainer/Q1Pred Mean                         327.965
trainer/Q1Pred Std                           61.6619
trainer/Q1Pred Max                          415.867
trainer/Q1Pred Min                           14.9876
trainer/Q2Pred Mean                         327.651
trainer/Q2Pred Std                           62.0043
trainer/Q2Pred Max                          413.047
trainer/Q2Pred Min                            7.64993
trainer/QTargetWithReg Mean                 327.799
trainer/QTargetWithReg Std                   62.4307
trainer/QTargetWithReg Max                  413.894
trainer/QTargetWithReg Min                   11.2349
trainer/PolicyLossWithoutReg Mean           329.283
trainer/PolicyLossWithoutReg Std             60.6953
trainer/PolicyLossWithoutReg Max            412.75
trainer/PolicyLossWithoutReg Min             20.6098
exploration/num steps total              598000
exploration/num paths total                1369
exploration/path length this epoch Mean     798
exploration/path length this epoch Std        0
exploration/path length this epoch Max      798
exploration/path length this epoch Min      798
exploration/Rewards Mean                      4.12022
exploration/Rewards Std                       1.05336
exploration/Rewards Max                       6.71634
exploration/Rewards Min                      -0.722877
exploration/Returns Mean                   3287.94
exploration/Returns Std                       0
exploration/Returns Max                    3287.94
exploration/Returns Min                    3287.94
exploration/Num Paths                         1
exploration/Average Returns                3287.94
evaluation_0/num steps total                  4.62584e+06
evaluation_0/num paths total               8229
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63865
evaluation_0/Rewards Std                      1.22134
evaluation_0/Rewards Max                      7.23639
evaluation_0/Rewards Min                     -0.774319
evaluation_0/Returns Mean                  4638.65
evaluation_0/Returns Std                    163.924
evaluation_0/Returns Max                   4803.39
evaluation_0/Returns Min                   4233.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4638.65
time/epoch (s)                                0
time/total (s)                             9168.09
Epoch                                       593
---------------------------------------  ----------------
2022-11-16 18:47:44.324388 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 594 finished
---------------------------------------  ----------------
epoch                                       594
total_step                               599000
replay_pool/size                         599000
trainer/alpha                                 0.0586725
trainer/alpha_loss                           -0.186476
trainer/entropy                              -5.93424
trainer/qf_loss                              19.2346
trainer/policy_loss                        -324.482
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.83
trainer/entropy_penalty                      -0.348177
trainer/entropy_percentage                   -0.00107187
trainer/Q1Pred Mean                         323.564
trainer/Q1Pred Std                           71.8166
trainer/Q1Pred Max                          420.374
trainer/Q1Pred Min                          -19.783
trainer/Q2Pred Mean                         324.104
trainer/Q2Pred Std                           72.122
trainer/Q2Pred Max                          417.479
trainer/Q2Pred Min                          -15.3006
trainer/QTargetWithReg Mean                 323.692
trainer/QTargetWithReg Std                   72.0046
trainer/QTargetWithReg Max                  421.59
trainer/QTargetWithReg Min                  -23.6635
trainer/PolicyLossWithoutReg Mean           324.83
trainer/PolicyLossWithoutReg Std             70.7836
trainer/PolicyLossWithoutReg Max            418.088
trainer/PolicyLossWithoutReg Min            -11.3574
exploration/num steps total              599000
exploration/num paths total                1370
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55628
exploration/Rewards Std                       1.11888
exploration/Rewards Max                       6.89854
exploration/Rewards Min                      -0.983274
exploration/Returns Mean                   4556.28
exploration/Returns Std                       0
exploration/Returns Max                    4556.28
exploration/Returns Min                    4556.28
exploration/Num Paths                         1
exploration/Average Returns                4556.28
evaluation_0/num steps total                  4.63384e+06
evaluation_0/num paths total               8237
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75082
evaluation_0/Rewards Std                      1.01829
evaluation_0/Rewards Max                      7.0339
evaluation_0/Rewards Min                     -0.876782
evaluation_0/Returns Mean                  4750.82
evaluation_0/Returns Std                     53.6216
evaluation_0/Returns Max                   4833.14
evaluation_0/Returns Min                   4668.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4750.82
time/epoch (s)                                0
time/total (s)                             9181.3
Epoch                                       594
---------------------------------------  ----------------
2022-11-16 18:47:56.934051 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 595 finished
---------------------------------------  ----------------
epoch                                       595
total_step                               600000
replay_pool/size                         600000
trainer/alpha                                 0.058717
trainer/alpha_loss                           -0.731708
trainer/entropy                              -5.7419
trainer/qf_loss                              21.982
trainer/policy_loss                        -324.907
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.245
trainer/entropy_penalty                      -0.337147
trainer/entropy_percentage                   -0.0010366
trainer/Q1Pred Mean                         324.242
trainer/Q1Pred Std                           66.0616
trainer/Q1Pred Max                          408.758
trainer/Q1Pred Min                            5.09312
trainer/Q2Pred Mean                         324.643
trainer/Q2Pred Std                           65.8863
trainer/Q2Pred Max                          408.359
trainer/Q2Pred Min                            1.09976
trainer/QTargetWithReg Mean                 325.142
trainer/QTargetWithReg Std                   66.504
trainer/QTargetWithReg Max                  407.033
trainer/QTargetWithReg Min                    4.07828
trainer/PolicyLossWithoutReg Mean           325.245
trainer/PolicyLossWithoutReg Std             65.1004
trainer/PolicyLossWithoutReg Max            408.972
trainer/PolicyLossWithoutReg Min              7.18153
exploration/num steps total              600000
exploration/num paths total                1371
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57439
exploration/Rewards Std                       0.944456
exploration/Rewards Max                       6.79135
exploration/Rewards Min                      -0.851959
exploration/Returns Mean                   4574.39
exploration/Returns Std                       0
exploration/Returns Max                    4574.39
exploration/Returns Min                    4574.39
exploration/Num Paths                         1
exploration/Average Returns                4574.39
evaluation_0/num steps total                  4.64184e+06
evaluation_0/num paths total               8245
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81478
evaluation_0/Rewards Std                      1.05074
evaluation_0/Rewards Max                      6.99931
evaluation_0/Rewards Min                     -0.833768
evaluation_0/Returns Mean                  4814.78
evaluation_0/Returns Std                     79.8824
evaluation_0/Returns Max                   4905.73
evaluation_0/Returns Min                   4635.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4814.78
time/epoch (s)                                0
time/total (s)                             9193.91
Epoch                                       595
---------------------------------------  ----------------
2022-11-16 18:48:08.860683 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 596 finished
---------------------------------------  ----------------
epoch                                       596
total_step                               601000
replay_pool/size                         601000
trainer/alpha                                 0.0605072
trainer/alpha_loss                           -1.42184
trainer/entropy                              -5.49307
trainer/qf_loss                              20.135
trainer/policy_loss                        -332.489
trainer/adversary_policy_loss                15.9494
trainer/policy_loss_without_entropy         332.821
trainer/entropy_penalty                      -0.332371
trainer/entropy_percentage                   -0.000998645
trainer/Q1Pred Mean                         332.469
trainer/Q1Pred Std                           53.9333
trainer/Q1Pred Max                          410.807
trainer/Q1Pred Min                           11.285
trainer/Q2Pred Mean                         331.427
trainer/Q2Pred Std                           54.4346
trainer/Q2Pred Max                          411.817
trainer/Q2Pred Min                            9.03538
trainer/QTargetWithReg Mean                 332.631
trainer/QTargetWithReg Std                   54.2345
trainer/QTargetWithReg Max                  410.378
trainer/QTargetWithReg Min                    6.81295
trainer/PolicyLossWithoutReg Mean           332.821
trainer/PolicyLossWithoutReg Std             53.5901
trainer/PolicyLossWithoutReg Max            411.065
trainer/PolicyLossWithoutReg Min              5.77815
exploration/num steps total              601000
exploration/num paths total                1372
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62424
exploration/Rewards Std                       1.02449
exploration/Rewards Max                       7.0714
exploration/Rewards Min                      -0.618908
exploration/Returns Mean                   4624.24
exploration/Returns Std                       0
exploration/Returns Max                    4624.24
exploration/Returns Min                    4624.24
exploration/Num Paths                         1
exploration/Average Returns                4624.24
evaluation_0/num steps total                  4.64984e+06
evaluation_0/num paths total               8253
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84174
evaluation_0/Rewards Std                      1.01143
evaluation_0/Rewards Max                      7.03539
evaluation_0/Rewards Min                     -0.867035
evaluation_0/Returns Mean                  4841.74
evaluation_0/Returns Std                     65.8504
evaluation_0/Returns Max                   4921.49
evaluation_0/Returns Min                   4734.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4841.74
time/epoch (s)                                0
time/total (s)                             9205.83
Epoch                                       596
---------------------------------------  ----------------
2022-11-16 18:48:22.418383 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 597 finished
---------------------------------------  ----------------
epoch                                       597
total_step                               602000
replay_pool/size                         602000
trainer/alpha                                 0.0600192
trainer/alpha_loss                            0.318577
trainer/entropy                              -6.11324
trainer/qf_loss                              25.4693
trainer/policy_loss                        -333.491
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.858
trainer/entropy_penalty                      -0.366912
trainer/entropy_percentage                   -0.00109901
trainer/Q1Pred Mean                         332.466
trainer/Q1Pred Std                           58.0296
trainer/Q1Pred Max                          410.686
trainer/Q1Pred Min                           -4.95482
trainer/Q2Pred Mean                         332.708
trainer/Q2Pred Std                           58.3626
trainer/Q2Pred Max                          411.187
trainer/Q2Pred Min                           -1.49528
trainer/QTargetWithReg Mean                 332.389
trainer/QTargetWithReg Std                   57.7703
trainer/QTargetWithReg Max                  410.678
trainer/QTargetWithReg Min                   -0.256758
trainer/PolicyLossWithoutReg Mean           333.858
trainer/PolicyLossWithoutReg Std             56.9738
trainer/PolicyLossWithoutReg Max            411.334
trainer/PolicyLossWithoutReg Min             -3.29042
exploration/num steps total              602000
exploration/num paths total                1373
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69615
exploration/Rewards Std                       0.968938
exploration/Rewards Max                       6.80493
exploration/Rewards Min                      -0.684459
exploration/Returns Mean                   4696.15
exploration/Returns Std                       0
exploration/Returns Max                    4696.15
exploration/Returns Min                    4696.15
exploration/Num Paths                         1
exploration/Average Returns                4696.15
evaluation_0/num steps total                  4.65784e+06
evaluation_0/num paths total               8261
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86062
evaluation_0/Rewards Std                      1.00558
evaluation_0/Rewards Max                      7.0791
evaluation_0/Rewards Min                     -0.630349
evaluation_0/Returns Mean                  4860.62
evaluation_0/Returns Std                     68.3837
evaluation_0/Returns Max                   4949.28
evaluation_0/Returns Min                   4731.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4860.62
time/epoch (s)                                0
time/total (s)                             9219.39
Epoch                                       597
---------------------------------------  ----------------
2022-11-16 18:48:34.055188 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 598 finished
---------------------------------------  ----------------
epoch                                       598
total_step                               603000
replay_pool/size                         603000
trainer/alpha                                 0.0613444
trainer/alpha_loss                           -1.20227
trainer/entropy                              -5.56925
trainer/qf_loss                              24.2564
trainer/policy_loss                        -333.701
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.043
trainer/entropy_penalty                      -0.341642
trainer/entropy_percentage                   -0.00102275
trainer/Q1Pred Mean                         333.189
trainer/Q1Pred Std                           63.5573
trainer/Q1Pred Max                          407.924
trainer/Q1Pred Min                            9.05981
trainer/Q2Pred Mean                         333.473
trainer/Q2Pred Std                           63.5101
trainer/Q2Pred Max                          408.452
trainer/Q2Pred Min                           15.8392
trainer/QTargetWithReg Mean                 332.414
trainer/QTargetWithReg Std                   64.1257
trainer/QTargetWithReg Max                  407.248
trainer/QTargetWithReg Min                   12.0361
trainer/PolicyLossWithoutReg Mean           334.043
trainer/PolicyLossWithoutReg Std             62.1506
trainer/PolicyLossWithoutReg Max            408.666
trainer/PolicyLossWithoutReg Min             13.3579
exploration/num steps total              603000
exploration/num paths total                1374
exploration/path length this epoch Mean     399
exploration/path length this epoch Std        0
exploration/path length this epoch Max      399
exploration/path length this epoch Min      399
exploration/Rewards Mean                      4.05849
exploration/Rewards Std                       1.22812
exploration/Rewards Max                       6.43909
exploration/Rewards Min                      -0.844566
exploration/Returns Mean                   1619.34
exploration/Returns Std                       0
exploration/Returns Max                    1619.34
exploration/Returns Min                    1619.34
exploration/Num Paths                         1
exploration/Average Returns                1619.34
evaluation_0/num steps total                  4.66584e+06
evaluation_0/num paths total               8269
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76201
evaluation_0/Rewards Std                      1.01058
evaluation_0/Rewards Max                      7.32996
evaluation_0/Rewards Min                     -0.627747
evaluation_0/Returns Mean                  4762.01
evaluation_0/Returns Std                     91.9931
evaluation_0/Returns Max                   4955.87
evaluation_0/Returns Min                   4659.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4762.01
time/epoch (s)                                0
time/total (s)                             9231.03
Epoch                                       598
---------------------------------------  ----------------
2022-11-16 18:48:45.212415 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 599 finished
---------------------------------------  ----------------
epoch                                       599
total_step                               604000
replay_pool/size                         604000
trainer/alpha                                 0.0605424
trainer/alpha_loss                           -0.799092
trainer/entropy                              -5.71505
trainer/qf_loss                              21.3502
trainer/policy_loss                        -333.235
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.581
trainer/entropy_penalty                      -0.346003
trainer/entropy_percentage                   -0.00103724
trainer/Q1Pred Mean                         332.314
trainer/Q1Pred Std                           67.7651
trainer/Q1Pred Max                          420.012
trainer/Q1Pred Min                           45.0286
trainer/Q2Pred Mean                         332.172
trainer/Q2Pred Std                           67.1905
trainer/Q2Pred Max                          418.125
trainer/Q2Pred Min                           46.0068
trainer/QTargetWithReg Mean                 332.539
trainer/QTargetWithReg Std                   67.5431
trainer/QTargetWithReg Max                  419.328
trainer/QTargetWithReg Min                   49.8022
trainer/PolicyLossWithoutReg Mean           333.581
trainer/PolicyLossWithoutReg Std             65.7596
trainer/PolicyLossWithoutReg Max            418.436
trainer/PolicyLossWithoutReg Min             44.2177
exploration/num steps total              604000
exploration/num paths total                1375
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60745
exploration/Rewards Std                       1.02578
exploration/Rewards Max                       7.08437
exploration/Rewards Min                      -0.79469
exploration/Returns Mean                   4607.45
exploration/Returns Std                       0
exploration/Returns Max                    4607.45
exploration/Returns Min                    4607.45
exploration/Num Paths                         1
exploration/Average Returns                4607.45
evaluation_0/num steps total                  4.67384e+06
evaluation_0/num paths total               8277
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57456
evaluation_0/Rewards Std                      1.03006
evaluation_0/Rewards Max                      7.13333
evaluation_0/Rewards Min                     -0.609682
evaluation_0/Returns Mean                  4574.56
evaluation_0/Returns Std                     63.3582
evaluation_0/Returns Max                   4662.57
evaluation_0/Returns Min                   4494.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4574.56
time/epoch (s)                                0
time/total (s)                             9242.18
Epoch                                       599
---------------------------------------  ----------------
2022-11-16 18:48:59.095322 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 600 finished
---------------------------------------  ----------------
epoch                                       600
total_step                               605000
replay_pool/size                         605000
trainer/alpha                                 0.0585571
trainer/alpha_loss                            1.08226
trainer/entropy                              -6.38138
trainer/qf_loss                              25.7316
trainer/policy_loss                        -327.865
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         328.238
trainer/entropy_penalty                      -0.373675
trainer/entropy_percentage                   -0.00113843
trainer/Q1Pred Mean                         326.075
trainer/Q1Pred Std                           69.7545
trainer/Q1Pred Max                          414.639
trainer/Q1Pred Min                           10.6316
trainer/Q2Pred Mean                         326.651
trainer/Q2Pred Std                           69.9752
trainer/Q2Pred Max                          414.581
trainer/Q2Pred Min                           -3.48212
trainer/QTargetWithReg Mean                 326.182
trainer/QTargetWithReg Std                   70.3895
trainer/QTargetWithReg Max                  414.348
trainer/QTargetWithReg Min                   -0.285756
trainer/PolicyLossWithoutReg Mean           328.238
trainer/PolicyLossWithoutReg Std             67.4276
trainer/PolicyLossWithoutReg Max            414.302
trainer/PolicyLossWithoutReg Min             16.8794
exploration/num steps total              605000
exploration/num paths total                1376
exploration/path length this epoch Mean     607
exploration/path length this epoch Std        0
exploration/path length this epoch Max      607
exploration/path length this epoch Min      607
exploration/Rewards Mean                      4.3369
exploration/Rewards Std                       1.0843
exploration/Rewards Max                       6.29458
exploration/Rewards Min                      -0.731668
exploration/Returns Mean                   2632.5
exploration/Returns Std                       0
exploration/Returns Max                    2632.5
exploration/Returns Min                    2632.5
exploration/Num Paths                         1
exploration/Average Returns                2632.5
evaluation_0/num steps total                  4.68184e+06
evaluation_0/num paths total               8285
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59676
evaluation_0/Rewards Std                      1.10276
evaluation_0/Rewards Max                      7.38627
evaluation_0/Rewards Min                     -0.656063
evaluation_0/Returns Mean                  4596.76
evaluation_0/Returns Std                     56.9843
evaluation_0/Returns Max                   4638.55
evaluation_0/Returns Min                   4451.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4596.76
time/epoch (s)                                0
time/total (s)                             9256.07
Epoch                                       600
---------------------------------------  ----------------
2022-11-16 18:49:11.707379 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 601 finished
---------------------------------------  ----------------
epoch                                       601
total_step                               606000
replay_pool/size                         606000
trainer/alpha                                 0.0609099
trainer/alpha_loss                            0.046377
trainer/entropy                              -6.01657
trainer/qf_loss                              25.2955
trainer/policy_loss                        -333.656
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.023
trainer/entropy_penalty                      -0.366469
trainer/entropy_percentage                   -0.00109714
trainer/Q1Pred Mean                         333.585
trainer/Q1Pred Std                           62.049
trainer/Q1Pred Max                          413.195
trainer/Q1Pred Min                          -10.7443
trainer/Q2Pred Mean                         333.389
trainer/Q2Pred Std                           61.2345
trainer/Q2Pred Max                          410.225
trainer/Q2Pred Min                           -7.61591
trainer/QTargetWithReg Mean                 333.859
trainer/QTargetWithReg Std                   60.6803
trainer/QTargetWithReg Max                  409.728
trainer/QTargetWithReg Min                    4.53596
trainer/PolicyLossWithoutReg Mean           334.023
trainer/PolicyLossWithoutReg Std             60.4198
trainer/PolicyLossWithoutReg Max            409.547
trainer/PolicyLossWithoutReg Min             -4.77075
exploration/num steps total              606000
exploration/num paths total                1377
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59381
exploration/Rewards Std                       1.11445
exploration/Rewards Max                       6.91482
exploration/Rewards Min                      -0.654882
exploration/Returns Mean                   4593.81
exploration/Returns Std                       0
exploration/Returns Max                    4593.81
exploration/Returns Min                    4593.81
exploration/Num Paths                         1
exploration/Average Returns                4593.81
evaluation_0/num steps total                  4.68984e+06
evaluation_0/num paths total               8293
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76983
evaluation_0/Rewards Std                      1.05385
evaluation_0/Rewards Max                      7.36313
evaluation_0/Rewards Min                     -0.809913
evaluation_0/Returns Mean                  4769.83
evaluation_0/Returns Std                     88.7655
evaluation_0/Returns Max                   4866.2
evaluation_0/Returns Min                   4568.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4769.83
time/epoch (s)                                0
time/total (s)                             9268.68
Epoch                                       601
---------------------------------------  ----------------
2022-11-16 18:49:25.062645 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 602 finished
---------------------------------------  ----------------
epoch                                       602
total_step                               607000
replay_pool/size                         607000
trainer/alpha                                 0.0595824
trainer/alpha_loss                           -0.222426
trainer/entropy                              -5.92114
trainer/qf_loss                              28.0158
trainer/policy_loss                        -325.178
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.53
trainer/entropy_penalty                      -0.352796
trainer/entropy_percentage                   -0.00108376
trainer/Q1Pred Mean                         324.823
trainer/Q1Pred Std                           67.6568
trainer/Q1Pred Max                          419.655
trainer/Q1Pred Min                           12.3198
trainer/Q2Pred Mean                         325.293
trainer/Q2Pred Std                           67.6678
trainer/Q2Pred Max                          417.617
trainer/Q2Pred Min                           18.5682
trainer/QTargetWithReg Mean                 324.916
trainer/QTargetWithReg Std                   67.3591
trainer/QTargetWithReg Max                  417.068
trainer/QTargetWithReg Min                   17.1615
trainer/PolicyLossWithoutReg Mean           325.53
trainer/PolicyLossWithoutReg Std             66.6708
trainer/PolicyLossWithoutReg Max            416.629
trainer/PolicyLossWithoutReg Min             19.2083
exploration/num steps total              607000
exploration/num paths total                1378
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.30621
exploration/Rewards Std                       1.01139
exploration/Rewards Max                       6.79524
exploration/Rewards Min                      -0.640749
exploration/Returns Mean                   4306.21
exploration/Returns Std                       0
exploration/Returns Max                    4306.21
exploration/Returns Min                    4306.21
exploration/Num Paths                         1
exploration/Average Returns                4306.21
evaluation_0/num steps total                  4.69784e+06
evaluation_0/num paths total               8301
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70222
evaluation_0/Rewards Std                      1.09127
evaluation_0/Rewards Max                      7.12338
evaluation_0/Rewards Min                     -0.636751
evaluation_0/Returns Mean                  4702.22
evaluation_0/Returns Std                     56.3249
evaluation_0/Returns Max                   4785.05
evaluation_0/Returns Min                   4613.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4702.22
time/epoch (s)                                0
time/total (s)                             9282.04
Epoch                                       602
---------------------------------------  ----------------
2022-11-16 18:49:38.510983 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 603 finished
---------------------------------------  ----------------
epoch                                       603
total_step                               608000
replay_pool/size                         608000
trainer/alpha                                 0.0596841
trainer/alpha_loss                            1.22303
trainer/entropy                              -6.43389
trainer/qf_loss                              57.1064
trainer/policy_loss                        -331.307
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.691
trainer/entropy_penalty                      -0.384001
trainer/entropy_percentage                   -0.00115771
trainer/Q1Pred Mean                         330.29
trainer/Q1Pred Std                           70.4969
trainer/Q1Pred Max                          419.49
trainer/Q1Pred Min                           16.7619
trainer/Q2Pred Mean                         330.547
trainer/Q2Pred Std                           71.261
trainer/Q2Pred Max                          420.945
trainer/Q2Pred Min                           17.4828
trainer/QTargetWithReg Mean                 329.978
trainer/QTargetWithReg Std                   73.0322
trainer/QTargetWithReg Max                  418.592
trainer/QTargetWithReg Min                  -16.3028
trainer/PolicyLossWithoutReg Mean           331.691
trainer/PolicyLossWithoutReg Std             68.3045
trainer/PolicyLossWithoutReg Max            420.482
trainer/PolicyLossWithoutReg Min             19.8049
exploration/num steps total              608000
exploration/num paths total                1379
exploration/path length this epoch Mean      23
exploration/path length this epoch Std        0
exploration/path length this epoch Max       23
exploration/path length this epoch Min       23
exploration/Rewards Mean                      0.269323
exploration/Rewards Std                       0.553689
exploration/Rewards Max                       1.21499
exploration/Rewards Min                      -0.681264
exploration/Returns Mean                      6.19442
exploration/Returns Std                       0
exploration/Returns Max                       6.19442
exploration/Returns Min                       6.19442
exploration/Num Paths                         1
exploration/Average Returns                   6.19442
evaluation_0/num steps total                  4.70584e+06
evaluation_0/num paths total               8309
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83454
evaluation_0/Rewards Std                      1.05557
evaluation_0/Rewards Max                      7.12373
evaluation_0/Rewards Min                     -0.614303
evaluation_0/Returns Mean                  4834.54
evaluation_0/Returns Std                     53.8849
evaluation_0/Returns Max                   4929.9
evaluation_0/Returns Min                   4754.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4834.54
time/epoch (s)                                0
time/total (s)                             9295.48
Epoch                                       603
---------------------------------------  ----------------
2022-11-16 18:49:49.555925 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 604 finished
---------------------------------------  ----------------
epoch                                       604
total_step                               609000
replay_pool/size                         609000
trainer/alpha                                 0.0598488
trainer/alpha_loss                           -0.180263
trainer/entropy                              -5.93598
trainer/qf_loss                              25.0109
trainer/policy_loss                        -329.061
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.416
trainer/entropy_penalty                      -0.355261
trainer/entropy_percentage                   -0.00107846
trainer/Q1Pred Mean                         328.902
trainer/Q1Pred Std                           63.142
trainer/Q1Pred Max                          414.456
trainer/Q1Pred Min                           22.7442
trainer/Q2Pred Mean                         328.314
trainer/Q2Pred Std                           64.2214
trainer/Q2Pred Max                          415.503
trainer/Q2Pred Min                           -2.8533
trainer/QTargetWithReg Mean                 327.778
trainer/QTargetWithReg Std                   63.8721
trainer/QTargetWithReg Max                  413.657
trainer/QTargetWithReg Min                  -24.0488
trainer/PolicyLossWithoutReg Mean           329.416
trainer/PolicyLossWithoutReg Std             62.1148
trainer/PolicyLossWithoutReg Max            415.085
trainer/PolicyLossWithoutReg Min             35.7235
exploration/num steps total              609000
exploration/num paths total                1380
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49907
exploration/Rewards Std                       1.12229
exploration/Rewards Max                       6.92685
exploration/Rewards Min                      -0.326115
exploration/Returns Mean                   4499.07
exploration/Returns Std                       0
exploration/Returns Max                    4499.07
exploration/Returns Min                    4499.07
exploration/Num Paths                         1
exploration/Average Returns                4499.07
evaluation_0/num steps total                  4.71384e+06
evaluation_0/num paths total               8317
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94628
evaluation_0/Rewards Std                      0.957735
evaluation_0/Rewards Max                      7.15589
evaluation_0/Rewards Min                     -0.936088
evaluation_0/Returns Mean                  4946.28
evaluation_0/Returns Std                     58.16
evaluation_0/Returns Max                   5046.7
evaluation_0/Returns Min                   4849.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4946.28
time/epoch (s)                                0
time/total (s)                             9306.53
Epoch                                       604
---------------------------------------  ----------------
2022-11-16 18:50:00.700382 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 605 finished
---------------------------------------  ----------------
epoch                                       605
total_step                               610000
replay_pool/size                         610000
trainer/alpha                                 0.0598467
trainer/alpha_loss                            0.273244
trainer/entropy                              -6.09704
trainer/qf_loss                              26.8368
trainer/policy_loss                        -333.833
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.198
trainer/entropy_penalty                      -0.364887
trainer/entropy_percentage                   -0.00109183
trainer/Q1Pred Mean                         333.262
trainer/Q1Pred Std                           60.7198
trainer/Q1Pred Max                          419.175
trainer/Q1Pred Min                           46.5432
trainer/Q2Pred Mean                         333.604
trainer/Q2Pred Std                           61.264
trainer/Q2Pred Max                          419.543
trainer/Q2Pred Min                           47.886
trainer/QTargetWithReg Mean                 332.414
trainer/QTargetWithReg Std                   60.5149
trainer/QTargetWithReg Max                  419.911
trainer/QTargetWithReg Min                   43.6359
trainer/PolicyLossWithoutReg Mean           334.197
trainer/PolicyLossWithoutReg Std             60.0982
trainer/PolicyLossWithoutReg Max            421.099
trainer/PolicyLossWithoutReg Min             50.4278
exploration/num steps total              610000
exploration/num paths total                1381
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6621
exploration/Rewards Std                       1.11394
exploration/Rewards Max                       7.28629
exploration/Rewards Min                      -1.0159
exploration/Returns Mean                   4662.1
exploration/Returns Std                       0
exploration/Returns Max                    4662.1
exploration/Returns Min                    4662.1
exploration/Num Paths                         1
exploration/Average Returns                4662.1
evaluation_0/num steps total                  4.72184e+06
evaluation_0/num paths total               8325
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77886
evaluation_0/Rewards Std                      1.01484
evaluation_0/Rewards Max                      7.24038
evaluation_0/Rewards Min                     -1.0861
evaluation_0/Returns Mean                  4778.86
evaluation_0/Returns Std                     55.7691
evaluation_0/Returns Max                   4864.86
evaluation_0/Returns Min                   4662.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4778.86
time/epoch (s)                                0
time/total (s)                             9317.67
Epoch                                       605
---------------------------------------  ----------------
2022-11-16 18:50:14.477549 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 606 finished
---------------------------------------  ----------------
epoch                                       606
total_step                               611000
replay_pool/size                         611000
trainer/alpha                                 0.0602875
trainer/alpha_loss                           -1.36503
trainer/entropy                              -5.51398
trainer/qf_loss                              19.9009
trainer/policy_loss                        -331.568
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.9
trainer/entropy_penalty                      -0.332424
trainer/entropy_percentage                   -0.00100158
trainer/Q1Pred Mean                         330.438
trainer/Q1Pred Std                           66.2495
trainer/Q1Pred Max                          419.84
trainer/Q1Pred Min                           26.1384
trainer/Q2Pred Mean                         330.626
trainer/Q2Pred Std                           66.4274
trainer/Q2Pred Max                          419.493
trainer/Q2Pred Min                           23.5187
trainer/QTargetWithReg Mean                 330.477
trainer/QTargetWithReg Std                   66.8375
trainer/QTargetWithReg Max                  420.707
trainer/QTargetWithReg Min                   27.3056
trainer/PolicyLossWithoutReg Mean           331.9
trainer/PolicyLossWithoutReg Std             65.2363
trainer/PolicyLossWithoutReg Max            419.652
trainer/PolicyLossWithoutReg Min             25.7784
exploration/num steps total              611000
exploration/num paths total                1383
exploration/path length this epoch Mean     156
exploration/path length this epoch Std      143
exploration/path length this epoch Max      299
exploration/path length this epoch Min       13
exploration/Rewards Mean                      3.57014
exploration/Rewards Std                       1.57727
exploration/Rewards Max                       6.10339
exploration/Rewards Min                      -0.998324
exploration/Returns Mean                    556.941
exploration/Returns Std                     559.953
exploration/Returns Max                    1116.89
exploration/Returns Min                      -3.01177
exploration/Num Paths                         2
exploration/Average Returns                 556.941
evaluation_0/num steps total                  4.72984e+06
evaluation_0/num paths total               8333
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69912
evaluation_0/Rewards Std                      0.979593
evaluation_0/Rewards Max                      6.93917
evaluation_0/Rewards Min                     -0.67031
evaluation_0/Returns Mean                  4699.12
evaluation_0/Returns Std                     78.0337
evaluation_0/Returns Max                   4867.36
evaluation_0/Returns Min                   4561.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4699.12
time/epoch (s)                                0
time/total (s)                             9331.45
Epoch                                       606
---------------------------------------  ----------------
2022-11-16 18:50:25.533522 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 607 finished
---------------------------------------  ----------------
epoch                                       607
total_step                               612000
replay_pool/size                         612000
trainer/alpha                                 0.0615431
trainer/alpha_loss                           -0.748373
trainer/entropy                              -5.73157
trainer/qf_loss                              26.0643
trainer/policy_loss                        -325.535
trainer/adversary_policy_loss                15.635
trainer/policy_loss_without_entropy         325.888
trainer/entropy_penalty                      -0.352738
trainer/entropy_percentage                   -0.00108239
trainer/Q1Pred Mean                         324.726
trainer/Q1Pred Std                           74.6388
trainer/Q1Pred Max                          413.924
trainer/Q1Pred Min                           28.5796
trainer/Q2Pred Mean                         325.492
trainer/Q2Pred Std                           74.4733
trainer/Q2Pred Max                          416.434
trainer/Q2Pred Min                           31.2722
trainer/QTargetWithReg Mean                 324.66
trainer/QTargetWithReg Std                   75.5449
trainer/QTargetWithReg Max                  415.87
trainer/QTargetWithReg Min                   28.6755
trainer/PolicyLossWithoutReg Mean           325.887
trainer/PolicyLossWithoutReg Std             72.9044
trainer/PolicyLossWithoutReg Max            413.151
trainer/PolicyLossWithoutReg Min             34.6997
exploration/num steps total              612000
exploration/num paths total                1384
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.10317
exploration/Rewards Std                       1.07017
exploration/Rewards Max                       6.72065
exploration/Rewards Min                      -0.836276
exploration/Returns Mean                   4103.17
exploration/Returns Std                       0
exploration/Returns Max                    4103.17
exploration/Returns Min                    4103.17
exploration/Num Paths                         1
exploration/Average Returns                4103.17
evaluation_0/num steps total                  4.73784e+06
evaluation_0/num paths total               8341
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62471
evaluation_0/Rewards Std                      0.958151
evaluation_0/Rewards Max                      7.04705
evaluation_0/Rewards Min                     -0.422702
evaluation_0/Returns Mean                  4624.71
evaluation_0/Returns Std                     59.6393
evaluation_0/Returns Max                   4700.49
evaluation_0/Returns Min                   4537.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4624.71
time/epoch (s)                                0
time/total (s)                             9342.5
Epoch                                       607
---------------------------------------  ----------------
2022-11-16 18:50:36.551769 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 608 finished
---------------------------------------  ----------------
epoch                                       608
total_step                               613000
replay_pool/size                         613000
trainer/alpha                                 0.0591819
trainer/alpha_loss                            1.18449
trainer/entropy                              -6.41896
trainer/qf_loss                              28.9272
trainer/policy_loss                        -326.174
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         326.553
trainer/entropy_penalty                      -0.379886
trainer/entropy_percentage                   -0.00116332
trainer/Q1Pred Mean                         324.929
trainer/Q1Pred Std                           68.3494
trainer/Q1Pred Max                          417.629
trainer/Q1Pred Min                           -5.27559
trainer/Q2Pred Mean                         325.317
trainer/Q2Pred Std                           68.2714
trainer/Q2Pred Max                          416.553
trainer/Q2Pred Min                          -16.3202
trainer/QTargetWithReg Mean                 325.922
trainer/QTargetWithReg Std                   68.9077
trainer/QTargetWithReg Max                  417.879
trainer/QTargetWithReg Min                    6.27897
trainer/PolicyLossWithoutReg Mean           326.553
trainer/PolicyLossWithoutReg Std             66.9636
trainer/PolicyLossWithoutReg Max            416.624
trainer/PolicyLossWithoutReg Min             20.5068
exploration/num steps total              613000
exploration/num paths total                1385
exploration/path length this epoch Mean     644
exploration/path length this epoch Std        0
exploration/path length this epoch Max      644
exploration/path length this epoch Min      644
exploration/Rewards Mean                      4.34921
exploration/Rewards Std                       1.2396
exploration/Rewards Max                       6.64308
exploration/Rewards Min                      -0.718446
exploration/Returns Mean                   2800.89
exploration/Returns Std                       0
exploration/Returns Max                    2800.89
exploration/Returns Min                    2800.89
exploration/Num Paths                         1
exploration/Average Returns                2800.89
evaluation_0/num steps total                  4.74584e+06
evaluation_0/num paths total               8349
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67047
evaluation_0/Rewards Std                      0.902361
evaluation_0/Rewards Max                      7.267
evaluation_0/Rewards Min                     -0.701418
evaluation_0/Returns Mean                  4670.47
evaluation_0/Returns Std                     42.0563
evaluation_0/Returns Max                   4726.67
evaluation_0/Returns Min                   4595.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4670.47
time/epoch (s)                                0
time/total (s)                             9353.52
Epoch                                       608
---------------------------------------  ----------------
2022-11-16 18:50:50.297195 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 609 finished
---------------------------------------  ----------------
epoch                                       609
total_step                               614000
replay_pool/size                         614000
trainer/alpha                                 0.061355
trainer/alpha_loss                            0.252589
trainer/entropy                              -6.0905
trainer/qf_loss                              23.4163
trainer/policy_loss                        -329.416
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.79
trainer/entropy_penalty                      -0.373683
trainer/entropy_percentage                   -0.00113309
trainer/Q1Pred Mean                         328.71
trainer/Q1Pred Std                           54.7524
trainer/Q1Pred Max                          413.756
trainer/Q1Pred Min                           89.1023
trainer/Q2Pred Mean                         329.14
trainer/Q2Pred Std                           55.1952
trainer/Q2Pred Max                          411.733
trainer/Q2Pred Min                           85.5402
trainer/QTargetWithReg Mean                 327.689
trainer/QTargetWithReg Std                   55.3256
trainer/QTargetWithReg Max                  414.35
trainer/QTargetWithReg Min                   86.8047
trainer/PolicyLossWithoutReg Mean           329.79
trainer/PolicyLossWithoutReg Std             53.6819
trainer/PolicyLossWithoutReg Max            412.408
trainer/PolicyLossWithoutReg Min             89.0054
exploration/num steps total              614000
exploration/num paths total                1386
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57489
exploration/Rewards Std                       1.02137
exploration/Rewards Max                       6.66539
exploration/Rewards Min                      -0.449166
exploration/Returns Mean                   4574.89
exploration/Returns Std                       0
exploration/Returns Max                    4574.89
exploration/Returns Min                    4574.89
exploration/Num Paths                         1
exploration/Average Returns                4574.89
evaluation_0/num steps total                  4.75384e+06
evaluation_0/num paths total               8357
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70569
evaluation_0/Rewards Std                      0.934828
evaluation_0/Rewards Max                      6.93028
evaluation_0/Rewards Min                     -0.449712
evaluation_0/Returns Mean                  4705.69
evaluation_0/Returns Std                     59.6528
evaluation_0/Returns Max                   4792.84
evaluation_0/Returns Min                   4620.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4705.69
time/epoch (s)                                0
time/total (s)                             9367.27
Epoch                                       609
---------------------------------------  ----------------
2022-11-16 18:51:01.924194 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 610 finished
---------------------------------------  ----------------
epoch                                       610
total_step                               615000
replay_pool/size                         615000
trainer/alpha                                 0.0590533
trainer/alpha_loss                           -0.612122
trainer/entropy                              -5.78364
trainer/qf_loss                              32.4374
trainer/policy_loss                        -327.596
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         327.937
trainer/entropy_penalty                      -0.341544
trainer/entropy_percentage                   -0.00104149
trainer/Q1Pred Mean                         326.583
trainer/Q1Pred Std                           67.2431
trainer/Q1Pred Max                          426.427
trainer/Q1Pred Min                           22.0416
trainer/Q2Pred Mean                         325.762
trainer/Q2Pred Std                           67.4106
trainer/Q2Pred Max                          425.731
trainer/Q2Pred Min                           20.2051
trainer/QTargetWithReg Mean                 325.878
trainer/QTargetWithReg Std                   68.5396
trainer/QTargetWithReg Max                  427.042
trainer/QTargetWithReg Min                   -0.0306203
trainer/PolicyLossWithoutReg Mean           327.937
trainer/PolicyLossWithoutReg Std             64.2093
trainer/PolicyLossWithoutReg Max            426.588
trainer/PolicyLossWithoutReg Min             21.0699
exploration/num steps total              615000
exploration/num paths total                1388
exploration/path length this epoch Mean     460
exploration/path length this epoch Std      373
exploration/path length this epoch Max      833
exploration/path length this epoch Min       87
exploration/Rewards Mean                      3.99783
exploration/Rewards Std                       1.29352
exploration/Rewards Max                       7.20571
exploration/Rewards Min                      -0.606979
exploration/Returns Mean                   1839
exploration/Returns Std                    1651.59
exploration/Returns Max                    3490.59
exploration/Returns Min                     187.418
exploration/Num Paths                         2
exploration/Average Returns                1839
evaluation_0/num steps total                  4.76184e+06
evaluation_0/num paths total               8365
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89203
evaluation_0/Rewards Std                      0.990497
evaluation_0/Rewards Max                      7.53383
evaluation_0/Rewards Min                     -0.770062
evaluation_0/Returns Mean                  4892.03
evaluation_0/Returns Std                     66.0925
evaluation_0/Returns Max                   4943.44
evaluation_0/Returns Min                   4726.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4892.03
time/epoch (s)                                0
time/total (s)                             9378.89
Epoch                                       610
---------------------------------------  ----------------
2022-11-16 18:51:14.879525 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 611 finished
---------------------------------------  ----------------
epoch                                       611
total_step                               616000
replay_pool/size                         616000
trainer/alpha                                 0.058727
trainer/alpha_loss                            0.785264
trainer/entropy                              -6.27702
trainer/qf_loss                              22.7924
trainer/policy_loss                        -331.509
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.877
trainer/entropy_penalty                      -0.368631
trainer/entropy_percentage                   -0.00111075
trainer/Q1Pred Mean                         330.413
trainer/Q1Pred Std                           70.74
trainer/Q1Pred Max                          414.453
trainer/Q1Pred Min                           -0.29606
trainer/Q2Pred Mean                         330.822
trainer/Q2Pred Std                           71.2572
trainer/Q2Pred Max                          412.234
trainer/Q2Pred Min                            7.11753
trainer/QTargetWithReg Mean                 331.492
trainer/QTargetWithReg Std                   71.1549
trainer/QTargetWithReg Max                  414.848
trainer/QTargetWithReg Min                    4.07602
trainer/PolicyLossWithoutReg Mean           331.877
trainer/PolicyLossWithoutReg Std             69.2432
trainer/PolicyLossWithoutReg Max            413.052
trainer/PolicyLossWithoutReg Min             12.8898
exploration/num steps total              616000
exploration/num paths total                1389
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60698
exploration/Rewards Std                       1.00308
exploration/Rewards Max                       7.24232
exploration/Rewards Min                      -0.582459
exploration/Returns Mean                   4606.98
exploration/Returns Std                       0
exploration/Returns Max                    4606.98
exploration/Returns Min                    4606.98
exploration/Num Paths                         1
exploration/Average Returns                4606.98
evaluation_0/num steps total                  4.76919e+06
evaluation_0/num paths total               8375
evaluation_0/path length Mean               735.5
evaluation_0/path length Std                404.087
evaluation_0/path length Max               1000
evaluation_0/path length Min                102
evaluation_0/Rewards Mean                     4.46654
evaluation_0/Rewards Std                      1.48408
evaluation_0/Rewards Max                      7.17892
evaluation_0/Rewards Min                     -0.856617
evaluation_0/Returns Mean                  3285.14
evaluation_0/Returns Std                   2037.04
evaluation_0/Returns Max                   4800.15
evaluation_0/Returns Min                    139.965
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3285.14
time/epoch (s)                                0
time/total (s)                             9391.85
Epoch                                       611
---------------------------------------  ----------------
2022-11-16 18:51:29.631673 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 612 finished
---------------------------------------  ----------------
epoch                                       612
total_step                               617000
replay_pool/size                         617000
trainer/alpha                                 0.0596045
trainer/alpha_loss                           -0.125634
trainer/entropy                              -5.95545
trainer/qf_loss                              22.1355
trainer/policy_loss                        -323.933
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         324.288
trainer/entropy_penalty                      -0.354972
trainer/entropy_percentage                   -0.00109462
trainer/Q1Pred Mean                         322.258
trainer/Q1Pred Std                           76.9167
trainer/Q1Pred Max                          421.924
trainer/Q1Pred Min                           13.9242
trainer/Q2Pred Mean                         322.322
trainer/Q2Pred Std                           77.3305
trainer/Q2Pred Max                          420.963
trainer/Q2Pred Min                           15.3576
trainer/QTargetWithReg Mean                 322.556
trainer/QTargetWithReg Std                   76.4037
trainer/QTargetWithReg Max                  420.288
trainer/QTargetWithReg Min                   11.7692
trainer/PolicyLossWithoutReg Mean           324.288
trainer/PolicyLossWithoutReg Std             76.136
trainer/PolicyLossWithoutReg Max            420.822
trainer/PolicyLossWithoutReg Min             14.4558
exploration/num steps total              617000
exploration/num paths total                1390
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7711
exploration/Rewards Std                       1.12583
exploration/Rewards Max                       7.05963
exploration/Rewards Min                      -0.780025
exploration/Returns Mean                   4771.1
exploration/Returns Std                       0
exploration/Returns Max                    4771.1
exploration/Returns Min                    4771.1
exploration/Num Paths                         1
exploration/Average Returns                4771.1
evaluation_0/num steps total                  4.77627e+06
evaluation_0/num paths total               8383
evaluation_0/path length Mean               885.125
evaluation_0/path length Std                303.931
evaluation_0/path length Max               1000
evaluation_0/path length Min                 81
evaluation_0/Rewards Mean                     4.67411
evaluation_0/Rewards Std                      1.01156
evaluation_0/Rewards Max                      7.17064
evaluation_0/Rewards Min                     -0.675219
evaluation_0/Returns Mean                  4137.17
evaluation_0/Returns Std                   1483.33
evaluation_0/Returns Max                   4795.85
evaluation_0/Returns Min                    220.435
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4137.17
time/epoch (s)                                0
time/total (s)                             9406.6
Epoch                                       612
---------------------------------------  ----------------
2022-11-16 18:51:41.340880 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 613 finished
---------------------------------------  ----------------
epoch                                       613
total_step                               618000
replay_pool/size                         618000
trainer/alpha                                 0.0612045
trainer/alpha_loss                           -0.616055
trainer/entropy                              -5.77947
trainer/qf_loss                              15.6768
trainer/policy_loss                        -327.201
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         327.555
trainer/entropy_penalty                      -0.35373
trainer/entropy_percentage                   -0.00107991
trainer/Q1Pred Mean                         326.219
trainer/Q1Pred Std                           71.2458
trainer/Q1Pred Max                          430.403
trainer/Q1Pred Min                           -3.24583
trainer/Q2Pred Mean                         326.543
trainer/Q2Pred Std                           71.422
trainer/Q2Pred Max                          427.15
trainer/Q2Pred Min                            1.11859
trainer/QTargetWithReg Mean                 326.878
trainer/QTargetWithReg Std                   70.6757
trainer/QTargetWithReg Max                  424.704
trainer/QTargetWithReg Min                    3.28334
trainer/PolicyLossWithoutReg Mean           327.555
trainer/PolicyLossWithoutReg Std             69.7856
trainer/PolicyLossWithoutReg Max            425.897
trainer/PolicyLossWithoutReg Min             -1.1766
exploration/num steps total              618000
exploration/num paths total                1391
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72444
exploration/Rewards Std                       1.10673
exploration/Rewards Max                       7.28206
exploration/Rewards Min                      -0.78367
exploration/Returns Mean                   4724.44
exploration/Returns Std                       0
exploration/Returns Max                    4724.44
exploration/Returns Min                    4724.44
exploration/Num Paths                         1
exploration/Average Returns                4724.44
evaluation_0/num steps total                  4.78427e+06
evaluation_0/num paths total               8391
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66861
evaluation_0/Rewards Std                      0.977687
evaluation_0/Rewards Max                      7.18828
evaluation_0/Rewards Min                     -0.50623
evaluation_0/Returns Mean                  4668.61
evaluation_0/Returns Std                     83.4529
evaluation_0/Returns Max                   4820.34
evaluation_0/Returns Min                   4498.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4668.61
time/epoch (s)                                0
time/total (s)                             9418.31
Epoch                                       613
---------------------------------------  ----------------
2022-11-16 18:51:52.484373 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 614 finished
---------------------------------------  ----------------
epoch                                       614
total_step                               619000
replay_pool/size                         619000
trainer/alpha                                 0.0581725
trainer/alpha_loss                            0.000235981
trainer/entropy                              -6.00008
trainer/qf_loss                              25.3844
trainer/policy_loss                        -330.123
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.472
trainer/entropy_penalty                      -0.34904
trainer/entropy_percentage                   -0.00105619
trainer/Q1Pred Mean                         329.764
trainer/Q1Pred Std                           69.2182
trainer/Q1Pred Max                          420.929
trainer/Q1Pred Min                            0.848491
trainer/Q2Pred Mean                         329.155
trainer/Q2Pred Std                           69.3024
trainer/Q2Pred Max                          417.238
trainer/Q2Pred Min                           -6.48409
trainer/QTargetWithReg Mean                 330.117
trainer/QTargetWithReg Std                   69.881
trainer/QTargetWithReg Max                  420.493
trainer/QTargetWithReg Min                   -9.62418
trainer/PolicyLossWithoutReg Mean           330.472
trainer/PolicyLossWithoutReg Std             67.4331
trainer/PolicyLossWithoutReg Max            417.762
trainer/PolicyLossWithoutReg Min             -0.0318203
exploration/num steps total              619000
exploration/num paths total                1392
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5641
exploration/Rewards Std                       1.07244
exploration/Rewards Max                       6.93088
exploration/Rewards Min                      -0.889883
exploration/Returns Mean                   4564.1
exploration/Returns Std                       0
exploration/Returns Max                    4564.1
exploration/Returns Min                    4564.1
exploration/Num Paths                         1
exploration/Average Returns                4564.1
evaluation_0/num steps total                  4.79227e+06
evaluation_0/num paths total               8399
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73724
evaluation_0/Rewards Std                      0.926216
evaluation_0/Rewards Max                      7.18339
evaluation_0/Rewards Min                     -0.492354
evaluation_0/Returns Mean                  4737.24
evaluation_0/Returns Std                     91.3037
evaluation_0/Returns Max                   4860.76
evaluation_0/Returns Min                   4540.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4737.24
time/epoch (s)                                0
time/total (s)                             9429.45
Epoch                                       614
---------------------------------------  ----------------
2022-11-16 18:52:03.919096 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 615 finished
---------------------------------------  ----------------
epoch                                       615
total_step                               620000
replay_pool/size                         620000
trainer/alpha                                 0.0587544
trainer/alpha_loss                            0.973293
trainer/entropy                              -6.34339
trainer/qf_loss                              23.6678
trainer/policy_loss                        -330.104
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.477
trainer/entropy_penalty                      -0.372702
trainer/entropy_percentage                   -0.00112777
trainer/Q1Pred Mean                         329.786
trainer/Q1Pred Std                           70.1476
trainer/Q1Pred Max                          415.306
trainer/Q1Pred Min                           34.1653
trainer/Q2Pred Mean                         329.933
trainer/Q2Pred Std                           70.7596
trainer/Q2Pred Max                          420.161
trainer/Q2Pred Min                           40.8907
trainer/QTargetWithReg Mean                 330.231
trainer/QTargetWithReg Std                   71.2959
trainer/QTargetWithReg Max                  423.072
trainer/QTargetWithReg Min                   34.8678
trainer/PolicyLossWithoutReg Mean           330.477
trainer/PolicyLossWithoutReg Std             69.5488
trainer/PolicyLossWithoutReg Max            414.926
trainer/PolicyLossWithoutReg Min             37.0523
exploration/num steps total              620000
exploration/num paths total                1393
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.35158
exploration/Rewards Std                       1.06747
exploration/Rewards Max                       6.47223
exploration/Rewards Min                      -0.886955
exploration/Returns Mean                   4351.58
exploration/Returns Std                       0
exploration/Returns Max                    4351.58
exploration/Returns Min                    4351.58
exploration/Num Paths                         1
exploration/Average Returns                4351.58
evaluation_0/num steps total                  4.80027e+06
evaluation_0/num paths total               8407
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62859
evaluation_0/Rewards Std                      1.09503
evaluation_0/Rewards Max                      7.181
evaluation_0/Rewards Min                     -0.835202
evaluation_0/Returns Mean                  4628.59
evaluation_0/Returns Std                     49.3675
evaluation_0/Returns Max                   4718.69
evaluation_0/Returns Min                   4574.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4628.59
time/epoch (s)                                0
time/total (s)                             9440.89
Epoch                                       615
---------------------------------------  ----------------
2022-11-16 18:52:18.366989 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 616 finished
---------------------------------------  ----------------
epoch                                       616
total_step                               621000
replay_pool/size                         621000
trainer/alpha                                 0.0602654
trainer/alpha_loss                            1.08692
trainer/entropy                              -6.38694
trainer/qf_loss                              30.2651
trainer/policy_loss                        -330.017
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.402
trainer/entropy_penalty                      -0.384911
trainer/entropy_percentage                   -0.00116498
trainer/Q1Pred Mean                         329.474
trainer/Q1Pred Std                           64.5614
trainer/Q1Pred Max                          411.643
trainer/Q1Pred Min                            9.28845
trainer/Q2Pred Mean                         329.998
trainer/Q2Pred Std                           64.3473
trainer/Q2Pred Max                          412.922
trainer/Q2Pred Min                            0.319926
trainer/QTargetWithReg Mean                 330.539
trainer/QTargetWithReg Std                   64.5533
trainer/QTargetWithReg Max                  413.531
trainer/QTargetWithReg Min                    3.67342
trainer/PolicyLossWithoutReg Mean           330.402
trainer/PolicyLossWithoutReg Std             63.733
trainer/PolicyLossWithoutReg Max            412.015
trainer/PolicyLossWithoutReg Min              3.09866
exploration/num steps total              621000
exploration/num paths total                1394
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50468
exploration/Rewards Std                       1.09676
exploration/Rewards Max                       6.7722
exploration/Rewards Min                      -0.718453
exploration/Returns Mean                   4504.68
exploration/Returns Std                       0
exploration/Returns Max                    4504.68
exploration/Returns Min                    4504.68
exploration/Num Paths                         1
exploration/Average Returns                4504.68
evaluation_0/num steps total                  4.80803e+06
evaluation_0/num paths total               8415
evaluation_0/path length Mean               969.25
evaluation_0/path length Std                 81.3569
evaluation_0/path length Max               1000
evaluation_0/path length Min                754
evaluation_0/Rewards Mean                     4.55336
evaluation_0/Rewards Std                      1.15908
evaluation_0/Rewards Max                      7.01593
evaluation_0/Rewards Min                     -0.89729
evaluation_0/Returns Mean                  4413.34
evaluation_0/Returns Std                    459.129
evaluation_0/Returns Max                   4643.5
evaluation_0/Returns Min                   3203
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4413.34
time/epoch (s)                                0
time/total (s)                             9455.33
Epoch                                       616
---------------------------------------  ----------------
2022-11-16 18:52:30.371413 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 617 finished
---------------------------------------  ----------------
epoch                                       617
total_step                               622000
replay_pool/size                         622000
trainer/alpha                                 0.061427
trainer/alpha_loss                           -0.257022
trainer/entropy                              -5.90787
trainer/qf_loss                              18.1862
trainer/policy_loss                        -327.916
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         328.279
trainer/entropy_penalty                      -0.362903
trainer/entropy_percentage                   -0.00110547
trainer/Q1Pred Mean                         327.669
trainer/Q1Pred Std                           72.3409
trainer/Q1Pred Max                          413.974
trainer/Q1Pred Min                          -18.7067
trainer/Q2Pred Mean                         327.728
trainer/Q2Pred Std                           73.1261
trainer/Q2Pred Max                          417.049
trainer/Q2Pred Min                          -28.9129
trainer/QTargetWithReg Mean                 327.596
trainer/QTargetWithReg Std                   72.9425
trainer/QTargetWithReg Max                  414.348
trainer/QTargetWithReg Min                  -25.8558
trainer/PolicyLossWithoutReg Mean           328.279
trainer/PolicyLossWithoutReg Std             71.5098
trainer/PolicyLossWithoutReg Max            413.041
trainer/PolicyLossWithoutReg Min            -28.6701
exploration/num steps total              622000
exploration/num paths total                1396
exploration/path length this epoch Mean     356.5
exploration/path length this epoch Std       34.5
exploration/path length this epoch Max      391
exploration/path length this epoch Min      322
exploration/Rewards Mean                      3.80902
exploration/Rewards Std                       1.23903
exploration/Rewards Max                       6.42328
exploration/Rewards Min                      -0.783345
exploration/Returns Mean                   1357.91
exploration/Returns Std                     164.803
exploration/Returns Max                    1522.72
exploration/Returns Min                    1193.11
exploration/Num Paths                         2
exploration/Average Returns                1357.91
evaluation_0/num steps total                  4.81603e+06
evaluation_0/num paths total               8423
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7432
evaluation_0/Rewards Std                      1.00983
evaluation_0/Rewards Max                      7.22518
evaluation_0/Rewards Min                     -0.663992
evaluation_0/Returns Mean                  4743.2
evaluation_0/Returns Std                     89.2792
evaluation_0/Returns Max                   4916.05
evaluation_0/Returns Min                   4611.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4743.2
time/epoch (s)                                0
time/total (s)                             9467.34
Epoch                                       617
---------------------------------------  ----------------
2022-11-16 18:52:44.307508 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 618 finished
---------------------------------------  ----------------
epoch                                       618
total_step                               623000
replay_pool/size                         623000
trainer/alpha                                 0.0602337
trainer/alpha_loss                            0.972093
trainer/entropy                              -6.34599
trainer/qf_loss                              51.7656
trainer/policy_loss                        -332.579
trainer/adversary_policy_loss                15.5485
trainer/policy_loss_without_entropy         332.962
trainer/entropy_penalty                      -0.382242
trainer/entropy_percentage                   -0.00114801
trainer/Q1Pred Mean                         331.23
trainer/Q1Pred Std                           62.3783
trainer/Q1Pred Max                          412.815
trainer/Q1Pred Min                            4.76777
trainer/Q2Pred Mean                         331.899
trainer/Q2Pred Std                           62.9923
trainer/Q2Pred Max                          413.977
trainer/Q2Pred Min                            2.55228
trainer/QTargetWithReg Mean                 331.769
trainer/QTargetWithReg Std                   62.5927
trainer/QTargetWithReg Max                  408.826
trainer/QTargetWithReg Min                   -1.76213
trainer/PolicyLossWithoutReg Mean           332.962
trainer/PolicyLossWithoutReg Std             57.9169
trainer/PolicyLossWithoutReg Max            411.617
trainer/PolicyLossWithoutReg Min              2.49669
exploration/num steps total              623000
exploration/num paths total                1397
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76931
exploration/Rewards Std                       0.994218
exploration/Rewards Max                       7.24034
exploration/Rewards Min                      -0.412127
exploration/Returns Mean                   4769.31
exploration/Returns Std                       0
exploration/Returns Max                    4769.31
exploration/Returns Min                    4769.31
exploration/Num Paths                         1
exploration/Average Returns                4769.31
evaluation_0/num steps total                  4.82403e+06
evaluation_0/num paths total               8431
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74255
evaluation_0/Rewards Std                      1.03896
evaluation_0/Rewards Max                      7.40089
evaluation_0/Rewards Min                     -0.81883
evaluation_0/Returns Mean                  4742.55
evaluation_0/Returns Std                     51.3837
evaluation_0/Returns Max                   4842.92
evaluation_0/Returns Min                   4680.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4742.55
time/epoch (s)                                0
time/total (s)                             9481.27
Epoch                                       618
---------------------------------------  ----------------
2022-11-16 18:52:56.059251 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 619 finished
---------------------------------------  ----------------
epoch                                       619
total_step                               624000
replay_pool/size                         624000
trainer/alpha                                 0.0589181
trainer/alpha_loss                            0.00342136
trainer/entropy                              -6.00121
trainer/qf_loss                              15.1322
trainer/policy_loss                        -331.628
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.982
trainer/entropy_penalty                      -0.35358
trainer/entropy_percentage                   -0.00106506
trainer/Q1Pred Mean                         331.466
trainer/Q1Pred Std                           61.1647
trainer/Q1Pred Max                          413.122
trainer/Q1Pred Min                           10.1115
trainer/Q2Pred Mean                         330.407
trainer/Q2Pred Std                           61.3045
trainer/Q2Pred Max                          410.091
trainer/Q2Pred Min                           10.1828
trainer/QTargetWithReg Mean                 330.742
trainer/QTargetWithReg Std                   60.9443
trainer/QTargetWithReg Max                  411.883
trainer/QTargetWithReg Min                    1.54543
trainer/PolicyLossWithoutReg Mean           331.982
trainer/PolicyLossWithoutReg Std             60.0449
trainer/PolicyLossWithoutReg Max            410.387
trainer/PolicyLossWithoutReg Min             10.7831
exploration/num steps total              624000
exploration/num paths total                1398
exploration/path length this epoch Mean     776
exploration/path length this epoch Std        0
exploration/path length this epoch Max      776
exploration/path length this epoch Min      776
exploration/Rewards Mean                      4.45283
exploration/Rewards Std                       1.14561
exploration/Rewards Max                       6.3431
exploration/Rewards Min                      -0.864211
exploration/Returns Mean                   3455.4
exploration/Returns Std                       0
exploration/Returns Max                    3455.4
exploration/Returns Min                    3455.4
exploration/Num Paths                         1
exploration/Average Returns                3455.4
evaluation_0/num steps total                  4.83203e+06
evaluation_0/num paths total               8439
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65652
evaluation_0/Rewards Std                      0.987218
evaluation_0/Rewards Max                      7.17667
evaluation_0/Rewards Min                     -0.865994
evaluation_0/Returns Mean                  4656.52
evaluation_0/Returns Std                     43.5212
evaluation_0/Returns Max                   4722.88
evaluation_0/Returns Min                   4594.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4656.52
time/epoch (s)                                0
time/total (s)                             9493.02
Epoch                                       619
---------------------------------------  ----------------
2022-11-16 18:53:07.301413 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 620 finished
---------------------------------------  ----------------
epoch                                       620
total_step                               625000
replay_pool/size                         625000
trainer/alpha                                 0.0597889
trainer/alpha_loss                            1.09907
trainer/entropy                              -6.39017
trainer/qf_loss                              18.2522
trainer/policy_loss                        -329.498
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.88
trainer/entropy_penalty                      -0.382061
trainer/entropy_percentage                   -0.00115818
trainer/Q1Pred Mean                         329.586
trainer/Q1Pred Std                           70.4791
trainer/Q1Pred Max                          416.571
trainer/Q1Pred Min                           18.5319
trainer/Q2Pred Mean                         329.731
trainer/Q2Pred Std                           70.7764
trainer/Q2Pred Max                          421.662
trainer/Q2Pred Min                           22.4018
trainer/QTargetWithReg Mean                 329.416
trainer/QTargetWithReg Std                   70.661
trainer/QTargetWithReg Max                  416.507
trainer/QTargetWithReg Min                   20.5028
trainer/PolicyLossWithoutReg Mean           329.88
trainer/PolicyLossWithoutReg Std             69.4878
trainer/PolicyLossWithoutReg Max            415.819
trainer/PolicyLossWithoutReg Min             16.5397
exploration/num steps total              625000
exploration/num paths total                1399
exploration/path length this epoch Mean     587
exploration/path length this epoch Std        0
exploration/path length this epoch Max      587
exploration/path length this epoch Min      587
exploration/Rewards Mean                      4.38637
exploration/Rewards Std                       1.09079
exploration/Rewards Max                       6.58294
exploration/Rewards Min                      -0.973062
exploration/Returns Mean                   2574.8
exploration/Returns Std                       0
exploration/Returns Max                    2574.8
exploration/Returns Min                    2574.8
exploration/Num Paths                         1
exploration/Average Returns                2574.8
evaluation_0/num steps total                  4.84003e+06
evaluation_0/num paths total               8447
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77843
evaluation_0/Rewards Std                      1.06345
evaluation_0/Rewards Max                      7.05242
evaluation_0/Rewards Min                     -0.896583
evaluation_0/Returns Mean                  4778.43
evaluation_0/Returns Std                     64.6448
evaluation_0/Returns Max                   4851.41
evaluation_0/Returns Min                   4638.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4778.43
time/epoch (s)                                0
time/total (s)                             9504.27
Epoch                                       620
---------------------------------------  ----------------
2022-11-16 18:53:21.036132 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 621 finished
---------------------------------------  ----------------
epoch                                       621
total_step                               626000
replay_pool/size                         626000
trainer/alpha                                 0.0588554
trainer/alpha_loss                            0.0244484
trainer/entropy                              -6.00863
trainer/qf_loss                              25.4235
trainer/policy_loss                        -329
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.353
trainer/entropy_penalty                      -0.35364
trainer/entropy_percentage                   -0.00107374
trainer/Q1Pred Mean                         329.288
trainer/Q1Pred Std                           75.754
trainer/Q1Pred Max                          419.131
trainer/Q1Pred Min                          -15.1966
trainer/Q2Pred Mean                         329.695
trainer/Q2Pred Std                           74.7737
trainer/Q2Pred Max                          417.159
trainer/Q2Pred Min                            2.98456
trainer/QTargetWithReg Mean                 329.39
trainer/QTargetWithReg Std                   75.4079
trainer/QTargetWithReg Max                  416.935
trainer/QTargetWithReg Min                    3.50391
trainer/PolicyLossWithoutReg Mean           329.353
trainer/PolicyLossWithoutReg Std             74.1002
trainer/PolicyLossWithoutReg Max            416.637
trainer/PolicyLossWithoutReg Min            -15.3279
exploration/num steps total              626000
exploration/num paths total                1400
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5923
exploration/Rewards Std                       1.00879
exploration/Rewards Max                       6.88349
exploration/Rewards Min                      -0.996959
exploration/Returns Mean                   4592.3
exploration/Returns Std                       0
exploration/Returns Max                    4592.3
exploration/Returns Min                    4592.3
exploration/Num Paths                         1
exploration/Average Returns                4592.3
evaluation_0/num steps total                  4.84803e+06
evaluation_0/num paths total               8455
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74043
evaluation_0/Rewards Std                      0.937546
evaluation_0/Rewards Max                      7.04028
evaluation_0/Rewards Min                     -0.661617
evaluation_0/Returns Mean                  4740.43
evaluation_0/Returns Std                     47.2383
evaluation_0/Returns Max                   4810.95
evaluation_0/Returns Min                   4651.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4740.43
time/epoch (s)                                0
time/total (s)                             9518
Epoch                                       621
---------------------------------------  ----------------
2022-11-16 18:53:33.274328 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 622 finished
---------------------------------------  ----------------
epoch                                       622
total_step                               627000
replay_pool/size                         627000
trainer/alpha                                 0.059495
trainer/alpha_loss                           -0.634731
trainer/entropy                              -5.77506
trainer/qf_loss                              18.1261
trainer/policy_loss                        -332.397
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         332.741
trainer/entropy_penalty                      -0.343588
trainer/entropy_percentage                   -0.0010326
trainer/Q1Pred Mean                         331.707
trainer/Q1Pred Std                           65.7042
trainer/Q1Pred Max                          416.99
trainer/Q1Pred Min                            4.98013
trainer/Q2Pred Mean                         332.004
trainer/Q2Pred Std                           66.2428
trainer/Q2Pred Max                          419.746
trainer/Q2Pred Min                            8.18673
trainer/QTargetWithReg Mean                 332.161
trainer/QTargetWithReg Std                   65.8969
trainer/QTargetWithReg Max                  417.001
trainer/QTargetWithReg Min                   10.9774
trainer/PolicyLossWithoutReg Mean           332.74
trainer/PolicyLossWithoutReg Std             65.2168
trainer/PolicyLossWithoutReg Max            418.291
trainer/PolicyLossWithoutReg Min              6.45694
exploration/num steps total              627000
exploration/num paths total                1401
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53635
exploration/Rewards Std                       1.16395
exploration/Rewards Max                       6.35405
exploration/Rewards Min                      -0.697485
exploration/Returns Mean                   4536.35
exploration/Returns Std                       0
exploration/Returns Max                    4536.35
exploration/Returns Min                    4536.35
exploration/Num Paths                         1
exploration/Average Returns                4536.35
evaluation_0/num steps total                  4.85603e+06
evaluation_0/num paths total               8463
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68634
evaluation_0/Rewards Std                      1.1244
evaluation_0/Rewards Max                      7.53
evaluation_0/Rewards Min                     -0.884848
evaluation_0/Returns Mean                  4686.34
evaluation_0/Returns Std                     96.1954
evaluation_0/Returns Max                   4838.82
evaluation_0/Returns Min                   4549.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4686.34
time/epoch (s)                                0
time/total (s)                             9530.24
Epoch                                       622
---------------------------------------  ----------------
2022-11-16 18:53:44.788113 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 623 finished
---------------------------------------  ----------------
epoch                                       623
total_step                               628000
replay_pool/size                         628000
trainer/alpha                                 0.0596901
trainer/alpha_loss                           -0.419896
trainer/entropy                              -5.85103
trainer/qf_loss                              28.8757
trainer/policy_loss                        -337.168
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         337.517
trainer/entropy_penalty                      -0.349248
trainer/entropy_percentage                   -0.00103476
trainer/Q1Pred Mean                         336.838
trainer/Q1Pred Std                           58.5168
trainer/Q1Pred Max                          418.686
trainer/Q1Pred Min                           44.2443
trainer/Q2Pred Mean                         336.908
trainer/Q2Pred Std                           59.2472
trainer/Q2Pred Max                          421.995
trainer/Q2Pred Min                           37.947
trainer/QTargetWithReg Mean                 338.156
trainer/QTargetWithReg Std                   59.1666
trainer/QTargetWithReg Max                  421.084
trainer/QTargetWithReg Min                   33.1448
trainer/PolicyLossWithoutReg Mean           337.517
trainer/PolicyLossWithoutReg Std             57.8114
trainer/PolicyLossWithoutReg Max            418.949
trainer/PolicyLossWithoutReg Min             38.0563
exploration/num steps total              628000
exploration/num paths total                1402
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69819
exploration/Rewards Std                       0.996172
exploration/Rewards Max                       6.91209
exploration/Rewards Min                      -0.589458
exploration/Returns Mean                   4698.19
exploration/Returns Std                       0
exploration/Returns Max                    4698.19
exploration/Returns Min                    4698.19
exploration/Num Paths                         1
exploration/Average Returns                4698.19
evaluation_0/num steps total                  4.86403e+06
evaluation_0/num paths total               8471
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74447
evaluation_0/Rewards Std                      1.03014
evaluation_0/Rewards Max                      7.1323
evaluation_0/Rewards Min                     -0.802542
evaluation_0/Returns Mean                  4744.47
evaluation_0/Returns Std                     58.4763
evaluation_0/Returns Max                   4843.43
evaluation_0/Returns Min                   4657.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4744.47
time/epoch (s)                                0
time/total (s)                             9541.75
Epoch                                       623
---------------------------------------  ----------------
2022-11-16 18:53:57.478510 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 624 finished
---------------------------------------  ----------------
epoch                                       624
total_step                               629000
replay_pool/size                         629000
trainer/alpha                                 0.0607508
trainer/alpha_loss                            1.43151
trainer/entropy                              -6.51108
trainer/qf_loss                              25.5745
trainer/policy_loss                        -330.103
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.498
trainer/entropy_penalty                      -0.395554
trainer/entropy_percentage                   -0.00119684
trainer/Q1Pred Mean                         329.167
trainer/Q1Pred Std                           67.3091
trainer/Q1Pred Max                          415.692
trainer/Q1Pred Min                           16.4729
trainer/Q2Pred Mean                         328.673
trainer/Q2Pred Std                           67.4008
trainer/Q2Pred Max                          414.686
trainer/Q2Pred Min                           14.5624
trainer/QTargetWithReg Mean                 329.099
trainer/QTargetWithReg Std                   66.8086
trainer/QTargetWithReg Max                  415.103
trainer/QTargetWithReg Min                   18.0725
trainer/PolicyLossWithoutReg Mean           330.498
trainer/PolicyLossWithoutReg Std             66.7487
trainer/PolicyLossWithoutReg Max            415.288
trainer/PolicyLossWithoutReg Min             14.8767
exploration/num steps total              629000
exploration/num paths total                1403
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53105
exploration/Rewards Std                       0.963137
exploration/Rewards Max                       6.76678
exploration/Rewards Min                      -0.724325
exploration/Returns Mean                   4531.05
exploration/Returns Std                       0
exploration/Returns Max                    4531.05
exploration/Returns Min                    4531.05
exploration/Num Paths                         1
exploration/Average Returns                4531.05
evaluation_0/num steps total                  4.87203e+06
evaluation_0/num paths total               8479
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68539
evaluation_0/Rewards Std                      0.941489
evaluation_0/Rewards Max                      7.35576
evaluation_0/Rewards Min                     -0.658977
evaluation_0/Returns Mean                  4685.39
evaluation_0/Returns Std                    121.685
evaluation_0/Returns Max                   4872.47
evaluation_0/Returns Min                   4510
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4685.39
time/epoch (s)                                0
time/total (s)                             9554.44
Epoch                                       624
---------------------------------------  ----------------
2022-11-16 18:54:09.325236 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 625 finished
---------------------------------------  ----------------
epoch                                       625
total_step                               630000
replay_pool/size                         630000
trainer/alpha                                 0.061233
trainer/alpha_loss                            0.247009
trainer/entropy                              -6.08843
trainer/qf_loss                              18.9089
trainer/policy_loss                        -326.304
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         326.677
trainer/entropy_penalty                      -0.372813
trainer/entropy_percentage                   -0.00114123
trainer/Q1Pred Mean                         325.27
trainer/Q1Pred Std                           70.4483
trainer/Q1Pred Max                          424.336
trainer/Q1Pred Min                           -4.28385
trainer/Q2Pred Mean                         325.582
trainer/Q2Pred Std                           70.5327
trainer/Q2Pred Max                          421.082
trainer/Q2Pred Min                           -5.68192
trainer/QTargetWithReg Mean                 326.148
trainer/QTargetWithReg Std                   70.0613
trainer/QTargetWithReg Max                  422.504
trainer/QTargetWithReg Min                    3.81944
trainer/PolicyLossWithoutReg Mean           326.677
trainer/PolicyLossWithoutReg Std             69.368
trainer/PolicyLossWithoutReg Max            423.641
trainer/PolicyLossWithoutReg Min             -5.62541
exploration/num steps total              630000
exploration/num paths total                1404
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80367
exploration/Rewards Std                       1.01015
exploration/Rewards Max                       6.93309
exploration/Rewards Min                      -0.773783
exploration/Returns Mean                   4803.67
exploration/Returns Std                       0
exploration/Returns Max                    4803.67
exploration/Returns Min                    4803.67
exploration/Num Paths                         1
exploration/Average Returns                4803.67
evaluation_0/num steps total                  4.88003e+06
evaluation_0/num paths total               8487
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75429
evaluation_0/Rewards Std                      0.903521
evaluation_0/Rewards Max                      7.23157
evaluation_0/Rewards Min                     -0.5517
evaluation_0/Returns Mean                  4754.29
evaluation_0/Returns Std                    103.011
evaluation_0/Returns Max                   4870.28
evaluation_0/Returns Min                   4542.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4754.29
time/epoch (s)                                0
time/total (s)                             9566.29
Epoch                                       625
---------------------------------------  ----------------
2022-11-16 18:54:20.383904 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 626 finished
---------------------------------------  ----------------
epoch                                       626
total_step                               631000
replay_pool/size                         631000
trainer/alpha                                 0.0584953
trainer/alpha_loss                            1.30563
trainer/entropy                              -6.45993
trainer/qf_loss                              44.5423
trainer/policy_loss                        -324.759
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         325.137
trainer/entropy_penalty                      -0.377876
trainer/entropy_percentage                   -0.0011622
trainer/Q1Pred Mean                         323.623
trainer/Q1Pred Std                           72.696
trainer/Q1Pred Max                          417.201
trainer/Q1Pred Min                          -34.2162
trainer/Q2Pred Mean                         323.459
trainer/Q2Pred Std                           72.4795
trainer/Q2Pred Max                          415.74
trainer/Q2Pred Min                          -14.3484
trainer/QTargetWithReg Mean                 324.739
trainer/QTargetWithReg Std                   72.4561
trainer/QTargetWithReg Max                  418.103
trainer/QTargetWithReg Min                   -0.396708
trainer/PolicyLossWithoutReg Mean           325.137
trainer/PolicyLossWithoutReg Std             70.6524
trainer/PolicyLossWithoutReg Max            417.933
trainer/PolicyLossWithoutReg Min              1.85263
exploration/num steps total              631000
exploration/num paths total                1405
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37677
exploration/Rewards Std                       0.987051
exploration/Rewards Max                       7.05982
exploration/Rewards Min                      -0.705406
exploration/Returns Mean                   4376.77
exploration/Returns Std                       0
exploration/Returns Max                    4376.77
exploration/Returns Min                    4376.77
exploration/Num Paths                         1
exploration/Average Returns                4376.77
evaluation_0/num steps total                  4.88803e+06
evaluation_0/num paths total               8495
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74294
evaluation_0/Rewards Std                      0.961658
evaluation_0/Rewards Max                      7.02455
evaluation_0/Rewards Min                     -0.780409
evaluation_0/Returns Mean                  4742.94
evaluation_0/Returns Std                     79.48
evaluation_0/Returns Max                   4867.08
evaluation_0/Returns Min                   4601.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4742.94
time/epoch (s)                                0
time/total (s)                             9577.35
Epoch                                       626
---------------------------------------  ----------------
2022-11-16 18:54:31.961117 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 627 finished
---------------------------------------  ----------------
epoch                                       627
total_step                               632000
replay_pool/size                         632000
trainer/alpha                                 0.0593671
trainer/alpha_loss                            0.854271
trainer/entropy                              -6.30249
trainer/qf_loss                              31.365
trainer/policy_loss                        -322.679
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         323.053
trainer/entropy_penalty                      -0.374161
trainer/entropy_percentage                   -0.0011582
trainer/Q1Pred Mean                         322.816
trainer/Q1Pred Std                           67.6316
trainer/Q1Pred Max                          415.954
trainer/Q1Pred Min                           12.395
trainer/Q2Pred Mean                         322.4
trainer/Q2Pred Std                           68.438
trainer/Q2Pred Max                          412.528
trainer/Q2Pred Min                            9.93665
trainer/QTargetWithReg Mean                 322.183
trainer/QTargetWithReg Std                   68.684
trainer/QTargetWithReg Max                  415.134
trainer/QTargetWithReg Min                   11.7724
trainer/PolicyLossWithoutReg Mean           323.053
trainer/PolicyLossWithoutReg Std             67.7416
trainer/PolicyLossWithoutReg Max            412.395
trainer/PolicyLossWithoutReg Min             12.2738
exploration/num steps total              632000
exploration/num paths total                1406
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55276
exploration/Rewards Std                       0.988286
exploration/Rewards Max                       6.94833
exploration/Rewards Min                      -0.979132
exploration/Returns Mean                   4552.76
exploration/Returns Std                       0
exploration/Returns Max                    4552.76
exploration/Returns Min                    4552.76
exploration/Num Paths                         1
exploration/Average Returns                4552.76
evaluation_0/num steps total                  4.89603e+06
evaluation_0/num paths total               8503
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74935
evaluation_0/Rewards Std                      1.04017
evaluation_0/Rewards Max                      6.88828
evaluation_0/Rewards Min                     -0.692051
evaluation_0/Returns Mean                  4749.35
evaluation_0/Returns Std                     48.5686
evaluation_0/Returns Max                   4801.95
evaluation_0/Returns Min                   4658.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4749.35
time/epoch (s)                                0
time/total (s)                             9588.92
Epoch                                       627
---------------------------------------  ----------------
2022-11-16 18:54:45.114670 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 628 finished
---------------------------------------  ----------------
epoch                                       628
total_step                               633000
replay_pool/size                         633000
trainer/alpha                                 0.059802
trainer/alpha_loss                           -2.20038
trainer/entropy                              -5.21876
trainer/qf_loss                              19.0583
trainer/policy_loss                        -334.559
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.871
trainer/entropy_penalty                      -0.312092
trainer/entropy_percentage                   -0.000931977
trainer/Q1Pred Mean                         334.171
trainer/Q1Pred Std                           61.9427
trainer/Q1Pred Max                          419.094
trainer/Q1Pred Min                            9.71281
trainer/Q2Pred Mean                         333.128
trainer/Q2Pred Std                           61.5741
trainer/Q2Pred Max                          419.038
trainer/Q2Pred Min                            9.97917
trainer/QTargetWithReg Mean                 334.477
trainer/QTargetWithReg Std                   62.0261
trainer/QTargetWithReg Max                  419.971
trainer/QTargetWithReg Min                   11.9913
trainer/PolicyLossWithoutReg Mean           334.871
trainer/PolicyLossWithoutReg Std             60.6135
trainer/PolicyLossWithoutReg Max            418.902
trainer/PolicyLossWithoutReg Min             12.9948
exploration/num steps total              633000
exploration/num paths total                1407
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79476
exploration/Rewards Std                       1.05731
exploration/Rewards Max                       6.74973
exploration/Rewards Min                      -0.717202
exploration/Returns Mean                   4794.76
exploration/Returns Std                       0
exploration/Returns Max                    4794.76
exploration/Returns Min                    4794.76
exploration/Num Paths                         1
exploration/Average Returns                4794.76
evaluation_0/num steps total                  4.90403e+06
evaluation_0/num paths total               8511
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63801
evaluation_0/Rewards Std                      1.0987
evaluation_0/Rewards Max                      7.53582
evaluation_0/Rewards Min                     -0.712598
evaluation_0/Returns Mean                  4638.01
evaluation_0/Returns Std                    119.798
evaluation_0/Returns Max                   4844.61
evaluation_0/Returns Min                   4457.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4638.01
time/epoch (s)                                0
time/total (s)                             9602.08
Epoch                                       628
---------------------------------------  ----------------
2022-11-16 18:54:57.388323 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 629 finished
---------------------------------------  ----------------
epoch                                       629
total_step                               634000
replay_pool/size                         634000
trainer/alpha                                 0.0605267
trainer/alpha_loss                           -0.160607
trainer/entropy                              -5.94273
trainer/qf_loss                              20.1492
trainer/policy_loss                        -338.177
trainer/adversary_policy_loss                16.1926
trainer/policy_loss_without_entropy         338.537
trainer/entropy_penalty                      -0.359694
trainer/entropy_percentage                   -0.0010625
trainer/Q1Pred Mean                         337.599
trainer/Q1Pred Std                           60.1095
trainer/Q1Pred Max                          421.615
trainer/Q1Pred Min                           21.8397
trainer/Q2Pred Mean                         337.485
trainer/Q2Pred Std                           59.9967
trainer/Q2Pred Max                          417.957
trainer/Q2Pred Min                           23.4248
trainer/QTargetWithReg Mean                 338.21
trainer/QTargetWithReg Std                   59.8733
trainer/QTargetWithReg Max                  420.467
trainer/QTargetWithReg Min                   26.7103
trainer/PolicyLossWithoutReg Mean           338.537
trainer/PolicyLossWithoutReg Std             58.618
trainer/PolicyLossWithoutReg Max            417.747
trainer/PolicyLossWithoutReg Min             23.2485
exploration/num steps total              634000
exploration/num paths total                1408
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74646
exploration/Rewards Std                       1.1954
exploration/Rewards Max                       7.47783
exploration/Rewards Min                      -0.762886
exploration/Returns Mean                   4746.46
exploration/Returns Std                       0
exploration/Returns Max                    4746.46
exploration/Returns Min                    4746.46
exploration/Num Paths                         1
exploration/Average Returns                4746.46
evaluation_0/num steps total                  4.91203e+06
evaluation_0/num paths total               8519
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7086
evaluation_0/Rewards Std                      0.963636
evaluation_0/Rewards Max                      7.23459
evaluation_0/Rewards Min                     -0.667804
evaluation_0/Returns Mean                  4708.6
evaluation_0/Returns Std                     79.6586
evaluation_0/Returns Max                   4818.54
evaluation_0/Returns Min                   4557.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4708.6
time/epoch (s)                                0
time/total (s)                             9614.35
Epoch                                       629
---------------------------------------  ----------------
2022-11-16 18:55:08.805524 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 630 finished
---------------------------------------  ----------------
epoch                                       630
total_step                               635000
replay_pool/size                         635000
trainer/alpha                                 0.060132
trainer/alpha_loss                           -0.724277
trainer/entropy                              -5.74236
trainer/qf_loss                              24.6399
trainer/policy_loss                        -332.314
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         332.659
trainer/entropy_penalty                      -0.3453
trainer/entropy_percentage                   -0.001038
trainer/Q1Pred Mean                         332.572
trainer/Q1Pred Std                           70.1668
trainer/Q1Pred Max                          421.836
trainer/Q1Pred Min                           13.1065
trainer/Q2Pred Mean                         333.448
trainer/Q2Pred Std                           69.7784
trainer/Q2Pred Max                          422.18
trainer/Q2Pred Min                           15.2263
trainer/QTargetWithReg Mean                 332.486
trainer/QTargetWithReg Std                   70.293
trainer/QTargetWithReg Max                  423.652
trainer/QTargetWithReg Min                   15.144
trainer/PolicyLossWithoutReg Mean           332.659
trainer/PolicyLossWithoutReg Std             69.7301
trainer/PolicyLossWithoutReg Max            422.341
trainer/PolicyLossWithoutReg Min             13.6308
exploration/num steps total              635000
exploration/num paths total                1409
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62876
exploration/Rewards Std                       0.996259
exploration/Rewards Max                       6.96185
exploration/Rewards Min                      -0.62197
exploration/Returns Mean                   4628.76
exploration/Returns Std                       0
exploration/Returns Max                    4628.76
exploration/Returns Min                    4628.76
exploration/Num Paths                         1
exploration/Average Returns                4628.76
evaluation_0/num steps total                  4.92003e+06
evaluation_0/num paths total               8527
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85027
evaluation_0/Rewards Std                      1.06079
evaluation_0/Rewards Max                      7.50555
evaluation_0/Rewards Min                     -0.785638
evaluation_0/Returns Mean                  4850.27
evaluation_0/Returns Std                     99.6306
evaluation_0/Returns Max                   4978.33
evaluation_0/Returns Min                   4690.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4850.27
time/epoch (s)                                0
time/total (s)                             9625.77
Epoch                                       630
---------------------------------------  ----------------
2022-11-16 18:55:21.800312 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 631 finished
---------------------------------------  ----------------
epoch                                       631
total_step                               636000
replay_pool/size                         636000
trainer/alpha                                 0.0601529
trainer/alpha_loss                           -0.723942
trainer/entropy                              -5.74245
trainer/qf_loss                              20.525
trainer/policy_loss                        -338.048
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.393
trainer/entropy_penalty                      -0.345425
trainer/entropy_percentage                   -0.00102078
trainer/Q1Pred Mean                         336.839
trainer/Q1Pred Std                           64.0138
trainer/Q1Pred Max                          424.159
trainer/Q1Pred Min                            6.49869
trainer/Q2Pred Mean                         336.873
trainer/Q2Pred Std                           63.8811
trainer/Q2Pred Max                          422.188
trainer/Q2Pred Min                           12.7902
trainer/QTargetWithReg Mean                 336.009
trainer/QTargetWithReg Std                   65.3206
trainer/QTargetWithReg Max                  421.957
trainer/QTargetWithReg Min                   -0.120973
trainer/PolicyLossWithoutReg Mean           338.393
trainer/PolicyLossWithoutReg Std             60.8675
trainer/PolicyLossWithoutReg Max            421.975
trainer/PolicyLossWithoutReg Min             13.5085
exploration/num steps total              636000
exploration/num paths total                1410
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64712
exploration/Rewards Std                       0.961543
exploration/Rewards Max                       6.95772
exploration/Rewards Min                      -0.621964
exploration/Returns Mean                   4647.12
exploration/Returns Std                       0
exploration/Returns Max                    4647.12
exploration/Returns Min                    4647.12
exploration/Num Paths                         1
exploration/Average Returns                4647.12
evaluation_0/num steps total                  4.92803e+06
evaluation_0/num paths total               8535
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79533
evaluation_0/Rewards Std                      0.960767
evaluation_0/Rewards Max                      7.24079
evaluation_0/Rewards Min                     -0.5599
evaluation_0/Returns Mean                  4795.33
evaluation_0/Returns Std                     45.1352
evaluation_0/Returns Max                   4869.52
evaluation_0/Returns Min                   4729.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4795.33
time/epoch (s)                                0
time/total (s)                             9638.76
Epoch                                       631
---------------------------------------  ----------------
2022-11-16 18:55:32.882836 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 632 finished
---------------------------------------  ----------------
epoch                                       632
total_step                               637000
replay_pool/size                         637000
trainer/alpha                                 0.0607909
trainer/alpha_loss                           -0.835286
trainer/entropy                              -5.70171
trainer/qf_loss                              15.7054
trainer/policy_loss                        -329.703
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.05
trainer/entropy_penalty                      -0.346612
trainer/entropy_percentage                   -0.00105018
trainer/Q1Pred Mean                         330.404
trainer/Q1Pred Std                           74.4422
trainer/Q1Pred Max                          421.076
trainer/Q1Pred Min                            4.56194
trainer/Q2Pred Mean                         330.393
trainer/Q2Pred Std                           73.821
trainer/Q2Pred Max                          420.653
trainer/Q2Pred Min                            2.00486
trainer/QTargetWithReg Mean                 329.785
trainer/QTargetWithReg Std                   74.7551
trainer/QTargetWithReg Max                  420.517
trainer/QTargetWithReg Min                    2.38769
trainer/PolicyLossWithoutReg Mean           330.05
trainer/PolicyLossWithoutReg Std             72.9403
trainer/PolicyLossWithoutReg Max            418.33
trainer/PolicyLossWithoutReg Min              2.12539
exploration/num steps total              637000
exploration/num paths total                1411
exploration/path length this epoch Mean     695
exploration/path length this epoch Std        0
exploration/path length this epoch Max      695
exploration/path length this epoch Min      695
exploration/Rewards Mean                      4.7566
exploration/Rewards Std                       1.13562
exploration/Rewards Max                       6.47498
exploration/Rewards Min                      -0.558754
exploration/Returns Mean                   3305.84
exploration/Returns Std                       0
exploration/Returns Max                    3305.84
exploration/Returns Min                    3305.84
exploration/Num Paths                         1
exploration/Average Returns                3305.84
evaluation_0/num steps total                  4.93603e+06
evaluation_0/num paths total               8543
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9533
evaluation_0/Rewards Std                      0.979355
evaluation_0/Rewards Max                      7.32228
evaluation_0/Rewards Min                     -0.698692
evaluation_0/Returns Mean                  4953.3
evaluation_0/Returns Std                    120.633
evaluation_0/Returns Max                   5079.13
evaluation_0/Returns Min                   4771.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4953.3
time/epoch (s)                                0
time/total (s)                             9649.84
Epoch                                       632
---------------------------------------  ----------------
2022-11-16 18:55:44.098202 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 633 finished
---------------------------------------  ----------------
epoch                                       633
total_step                               638000
replay_pool/size                         638000
trainer/alpha                                 0.0612486
trainer/alpha_loss                            0.212487
trainer/entropy                              -6.07609
trainer/qf_loss                              40.7406
trainer/policy_loss                        -330.441
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         330.813
trainer/entropy_penalty                      -0.372152
trainer/entropy_percentage                   -0.00112496
trainer/Q1Pred Mean                         329.353
trainer/Q1Pred Std                           70.8482
trainer/Q1Pred Max                          425.838
trainer/Q1Pred Min                          -22.7397
trainer/Q2Pred Mean                         329.58
trainer/Q2Pred Std                           70.894
trainer/Q2Pred Max                          424.337
trainer/Q2Pred Min                            1.08674
trainer/QTargetWithReg Mean                 329.325
trainer/QTargetWithReg Std                   72.2216
trainer/QTargetWithReg Max                  425.337
trainer/QTargetWithReg Min                  -15.614
trainer/PolicyLossWithoutReg Mean           330.813
trainer/PolicyLossWithoutReg Std             68.5469
trainer/PolicyLossWithoutReg Max            422.844
trainer/PolicyLossWithoutReg Min            -27.2181
exploration/num steps total              638000
exploration/num paths total                1412
exploration/path length this epoch Mean     473
exploration/path length this epoch Std        0
exploration/path length this epoch Max      473
exploration/path length this epoch Min      473
exploration/Rewards Mean                      3.98294
exploration/Rewards Std                       1.23803
exploration/Rewards Max                       6.63416
exploration/Rewards Min                      -0.770749
exploration/Returns Mean                   1883.93
exploration/Returns Std                       0
exploration/Returns Max                    1883.93
exploration/Returns Min                    1883.93
exploration/Num Paths                         1
exploration/Average Returns                1883.93
evaluation_0/num steps total                  4.94403e+06
evaluation_0/num paths total               8551
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88751
evaluation_0/Rewards Std                      1.02618
evaluation_0/Rewards Max                      7.34729
evaluation_0/Rewards Min                     -0.782291
evaluation_0/Returns Mean                  4887.51
evaluation_0/Returns Std                    105.799
evaluation_0/Returns Max                   5099.78
evaluation_0/Returns Min                   4798.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.51
time/epoch (s)                                0
time/total (s)                             9661.06
Epoch                                       633
---------------------------------------  ----------------
2022-11-16 18:55:58.178490 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 634 finished
---------------------------------------  ----------------
epoch                                       634
total_step                               639000
replay_pool/size                         639000
trainer/alpha                                 0.0603071
trainer/alpha_loss                           -0.942774
trainer/entropy                              -5.66427
trainer/qf_loss                              20.2838
trainer/policy_loss                        -333.093
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.434
trainer/entropy_penalty                      -0.341595
trainer/entropy_percentage                   -0.00102448
trainer/Q1Pred Mean                         332.508
trainer/Q1Pred Std                           65.3131
trainer/Q1Pred Max                          411.589
trainer/Q1Pred Min                           14.4481
trainer/Q2Pred Mean                         332.427
trainer/Q2Pred Std                           65.4726
trainer/Q2Pred Max                          411.853
trainer/Q2Pred Min                           23.92
trainer/QTargetWithReg Mean                 332.821
trainer/QTargetWithReg Std                   65.6954
trainer/QTargetWithReg Max                  411.579
trainer/QTargetWithReg Min                   23.2699
trainer/PolicyLossWithoutReg Mean           333.434
trainer/PolicyLossWithoutReg Std             64.7958
trainer/PolicyLossWithoutReg Max            410.911
trainer/PolicyLossWithoutReg Min             21.3144
exploration/num steps total              639000
exploration/num paths total                1414
exploration/path length this epoch Mean     497
exploration/path length this epoch Std      379
exploration/path length this epoch Max      876
exploration/path length this epoch Min      118
exploration/Rewards Mean                      4.27793
exploration/Rewards Std                       1.35302
exploration/Rewards Max                       7.06272
exploration/Rewards Min                      -0.81169
exploration/Returns Mean                   2126.13
exploration/Returns Std                    1866.65
exploration/Returns Max                    3992.78
exploration/Returns Min                     259.48
exploration/Num Paths                         2
exploration/Average Returns                2126.13
evaluation_0/num steps total                  4.95203e+06
evaluation_0/num paths total               8559
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87109
evaluation_0/Rewards Std                      0.9749
evaluation_0/Rewards Max                      7.15595
evaluation_0/Rewards Min                     -0.687205
evaluation_0/Returns Mean                  4871.09
evaluation_0/Returns Std                     35.3754
evaluation_0/Returns Max                   4929.44
evaluation_0/Returns Min                   4808.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4871.09
time/epoch (s)                                0
time/total (s)                             9675.14
Epoch                                       634
---------------------------------------  ----------------
2022-11-16 18:56:09.824237 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 635 finished
---------------------------------------  ----------------
epoch                                       635
total_step                               640000
replay_pool/size                         640000
trainer/alpha                                 0.0597739
trainer/alpha_loss                           -1.53868
trainer/entropy                              -5.45381
trainer/qf_loss                              22.5564
trainer/policy_loss                        -337.058
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         337.384
trainer/entropy_penalty                      -0.325996
trainer/entropy_percentage                   -0.000966245
trainer/Q1Pred Mean                         336.797
trainer/Q1Pred Std                           57.7584
trainer/Q1Pred Max                          420.389
trainer/Q1Pred Min                            5.58036
trainer/Q2Pred Mean                         335.896
trainer/Q2Pred Std                           58.3034
trainer/Q2Pred Max                          421.726
trainer/Q2Pred Min                           16.4828
trainer/QTargetWithReg Mean                 337.268
trainer/QTargetWithReg Std                   57.9215
trainer/QTargetWithReg Max                  423.474
trainer/QTargetWithReg Min                   22.2194
trainer/PolicyLossWithoutReg Mean           337.384
trainer/PolicyLossWithoutReg Std             56.8733
trainer/PolicyLossWithoutReg Max            421.485
trainer/PolicyLossWithoutReg Min             22.7311
exploration/num steps total              640000
exploration/num paths total                1415
exploration/path length this epoch Mean     916
exploration/path length this epoch Std        0
exploration/path length this epoch Max      916
exploration/path length this epoch Min      916
exploration/Rewards Mean                      4.40041
exploration/Rewards Std                       1.03807
exploration/Rewards Max                       6.65424
exploration/Rewards Min                      -0.42104
exploration/Returns Mean                   4030.77
exploration/Returns Std                       0
exploration/Returns Max                    4030.77
exploration/Returns Min                    4030.77
exploration/Num Paths                         1
exploration/Average Returns                4030.77
evaluation_0/num steps total                  4.96003e+06
evaluation_0/num paths total               8567
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77691
evaluation_0/Rewards Std                      0.941194
evaluation_0/Rewards Max                      7.251
evaluation_0/Rewards Min                     -0.711662
evaluation_0/Returns Mean                  4776.91
evaluation_0/Returns Std                     72.9976
evaluation_0/Returns Max                   4895.33
evaluation_0/Returns Min                   4677.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4776.91
time/epoch (s)                                0
time/total (s)                             9686.78
Epoch                                       635
---------------------------------------  ----------------
2022-11-16 18:56:21.037124 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 636 finished
---------------------------------------  ----------------
epoch                                       636
total_step                               641000
replay_pool/size                         641000
trainer/alpha                                 0.0603815
trainer/alpha_loss                           -1.2274
trainer/entropy                              -5.56275
trainer/qf_loss                              12.3128
trainer/policy_loss                        -339.025
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.361
trainer/entropy_penalty                      -0.335887
trainer/entropy_percentage                   -0.000989763
trainer/Q1Pred Mean                         338.884
trainer/Q1Pred Std                           53.4984
trainer/Q1Pred Max                          424.647
trainer/Q1Pred Min                          100.431
trainer/Q2Pred Mean                         339.116
trainer/Q2Pred Std                           53.661
trainer/Q2Pred Max                          425.07
trainer/Q2Pred Min                           90.482
trainer/QTargetWithReg Mean                 339.508
trainer/QTargetWithReg Std                   53.5652
trainer/QTargetWithReg Max                  424.657
trainer/QTargetWithReg Min                   99.2339
trainer/PolicyLossWithoutReg Mean           339.361
trainer/PolicyLossWithoutReg Std             51.7538
trainer/PolicyLossWithoutReg Max            424.94
trainer/PolicyLossWithoutReg Min             98.58
exploration/num steps total              641000
exploration/num paths total                1416
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7928
exploration/Rewards Std                       1.03493
exploration/Rewards Max                       6.84575
exploration/Rewards Min                      -0.529161
exploration/Returns Mean                   4792.8
exploration/Returns Std                       0
exploration/Returns Max                    4792.8
exploration/Returns Min                    4792.8
exploration/Num Paths                         1
exploration/Average Returns                4792.8
evaluation_0/num steps total                  4.96803e+06
evaluation_0/num paths total               8575
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92267
evaluation_0/Rewards Std                      1.00942
evaluation_0/Rewards Max                      7.60283
evaluation_0/Rewards Min                     -0.896231
evaluation_0/Returns Mean                  4922.67
evaluation_0/Returns Std                     62.2133
evaluation_0/Returns Max                   4988.05
evaluation_0/Returns Min                   4785.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4922.67
time/epoch (s)                                0
time/total (s)                             9698
Epoch                                       636
---------------------------------------  ----------------
2022-11-16 18:56:35.333915 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 637 finished
---------------------------------------  ----------------
epoch                                       637
total_step                               642000
replay_pool/size                         642000
trainer/alpha                                 0.0585865
trainer/alpha_loss                           -0.749028
trainer/entropy                              -5.73599
trainer/qf_loss                              24.6717
trainer/policy_loss                        -334.604
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.94
trainer/entropy_penalty                      -0.336052
trainer/entropy_percentage                   -0.00100332
trainer/Q1Pred Mean                         333.783
trainer/Q1Pred Std                           56.9891
trainer/Q1Pred Max                          409.303
trainer/Q1Pred Min                           37.1169
trainer/Q2Pred Mean                         334.459
trainer/Q2Pred Std                           57.0702
trainer/Q2Pred Max                          410.46
trainer/Q2Pred Min                           39.8275
trainer/QTargetWithReg Mean                 335.098
trainer/QTargetWithReg Std                   57.1254
trainer/QTargetWithReg Max                  417.421
trainer/QTargetWithReg Min                   33.5097
trainer/PolicyLossWithoutReg Mean           334.94
trainer/PolicyLossWithoutReg Std             55.974
trainer/PolicyLossWithoutReg Max            410.399
trainer/PolicyLossWithoutReg Min             47.0849
exploration/num steps total              642000
exploration/num paths total                1417
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6467
exploration/Rewards Std                       1.01779
exploration/Rewards Max                       6.81798
exploration/Rewards Min                      -0.733864
exploration/Returns Mean                   4646.7
exploration/Returns Std                       0
exploration/Returns Max                    4646.7
exploration/Returns Min                    4646.7
exploration/Num Paths                         1
exploration/Average Returns                4646.7
evaluation_0/num steps total                  4.97603e+06
evaluation_0/num paths total               8583
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78506
evaluation_0/Rewards Std                      1.07713
evaluation_0/Rewards Max                      7.08589
evaluation_0/Rewards Min                     -0.766736
evaluation_0/Returns Mean                  4785.06
evaluation_0/Returns Std                     79.5724
evaluation_0/Returns Max                   4908.43
evaluation_0/Returns Min                   4647.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4785.06
time/epoch (s)                                0
time/total (s)                             9712.29
Epoch                                       637
---------------------------------------  ----------------
2022-11-16 18:56:46.890006 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 638 finished
---------------------------------------  ----------------
epoch                                       638
total_step                               643000
replay_pool/size                         643000
trainer/alpha                                 0.0590182
trainer/alpha_loss                           -1.15814
trainer/entropy                              -5.59073
trainer/qf_loss                              18.4779
trainer/policy_loss                        -340.225
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.554
trainer/entropy_penalty                      -0.329955
trainer/entropy_percentage                   -0.000968875
trainer/Q1Pred Mean                         340.791
trainer/Q1Pred Std                           56.6388
trainer/Q1Pred Max                          414.821
trainer/Q1Pred Min                           -7.2069
trainer/Q2Pred Mean                         340.457
trainer/Q2Pred Std                           55.6835
trainer/Q2Pred Max                          417.676
trainer/Q2Pred Min                           30.294
trainer/QTargetWithReg Mean                 340.634
trainer/QTargetWithReg Std                   57.2689
trainer/QTargetWithReg Max                  415.392
trainer/QTargetWithReg Min                  -14.0508
trainer/PolicyLossWithoutReg Mean           340.554
trainer/PolicyLossWithoutReg Std             55.3012
trainer/PolicyLossWithoutReg Max            412.853
trainer/PolicyLossWithoutReg Min             24.0486
exploration/num steps total              643000
exploration/num paths total                1418
exploration/path length this epoch Mean     277
exploration/path length this epoch Std        0
exploration/path length this epoch Max      277
exploration/path length this epoch Min      277
exploration/Rewards Mean                      3.60105
exploration/Rewards Std                       1.27797
exploration/Rewards Max                       5.91296
exploration/Rewards Min                      -0.74005
exploration/Returns Mean                    997.49
exploration/Returns Std                       0
exploration/Returns Max                     997.49
exploration/Returns Min                     997.49
exploration/Num Paths                         1
exploration/Average Returns                 997.49
evaluation_0/num steps total                  4.98403e+06
evaluation_0/num paths total               8591
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8548
evaluation_0/Rewards Std                      0.946323
evaluation_0/Rewards Max                      7.09336
evaluation_0/Rewards Min                     -0.742293
evaluation_0/Returns Mean                  4854.8
evaluation_0/Returns Std                     19.4326
evaluation_0/Returns Max                   4895.97
evaluation_0/Returns Min                   4823.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4854.8
time/epoch (s)                                0
time/total (s)                             9723.85
Epoch                                       638
---------------------------------------  ----------------
2022-11-16 18:56:58.935522 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 639 finished
---------------------------------------  ----------------
epoch                                       639
total_step                               644000
replay_pool/size                         644000
trainer/alpha                                 0.0576295
trainer/alpha_loss                           -0.441963
trainer/entropy                              -5.84513
trainer/qf_loss                              24.2409
trainer/policy_loss                        -332.852
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.189
trainer/entropy_penalty                      -0.336851
trainer/entropy_percentage                   -0.00101099
trainer/Q1Pred Mean                         331.513
trainer/Q1Pred Std                           70.3975
trainer/Q1Pred Max                          416.55
trainer/Q1Pred Min                           23.08
trainer/Q2Pred Mean                         331.552
trainer/Q2Pred Std                           70.6378
trainer/Q2Pred Max                          418.479
trainer/Q2Pred Min                           23.842
trainer/QTargetWithReg Mean                 330.946
trainer/QTargetWithReg Std                   70.1162
trainer/QTargetWithReg Max                  414.662
trainer/QTargetWithReg Min                   20.1595
trainer/PolicyLossWithoutReg Mean           333.189
trainer/PolicyLossWithoutReg Std             68.5526
trainer/PolicyLossWithoutReg Max            418.231
trainer/PolicyLossWithoutReg Min             28.6067
exploration/num steps total              644000
exploration/num paths total                1419
exploration/path length this epoch Mean     830
exploration/path length this epoch Std        0
exploration/path length this epoch Max      830
exploration/path length this epoch Min      830
exploration/Rewards Mean                      4.49402
exploration/Rewards Std                       1.061
exploration/Rewards Max                       6.95424
exploration/Rewards Min                      -0.539167
exploration/Returns Mean                   3730.04
exploration/Returns Std                       0
exploration/Returns Max                    3730.04
exploration/Returns Min                    3730.04
exploration/Num Paths                         1
exploration/Average Returns                3730.04
evaluation_0/num steps total                  4.99203e+06
evaluation_0/num paths total               8599
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82237
evaluation_0/Rewards Std                      1.15505
evaluation_0/Rewards Max                      7.42036
evaluation_0/Rewards Min                     -0.827372
evaluation_0/Returns Mean                  4822.37
evaluation_0/Returns Std                     48.9046
evaluation_0/Returns Max                   4904.63
evaluation_0/Returns Min                   4743.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4822.37
time/epoch (s)                                0
time/total (s)                             9735.89
Epoch                                       639
---------------------------------------  ----------------
2022-11-16 18:57:12.666322 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 640 finished
---------------------------------------  ----------------
epoch                                       640
total_step                               645000
replay_pool/size                         645000
trainer/alpha                                 0.0609615
trainer/alpha_loss                            0.491
trainer/entropy                              -6.17552
trainer/qf_loss                              22.3222
trainer/policy_loss                        -333.704
trainer/adversary_policy_loss                15.9604
trainer/policy_loss_without_entropy         334.081
trainer/entropy_penalty                      -0.376469
trainer/entropy_percentage                   -0.00112688
trainer/Q1Pred Mean                         332.941
trainer/Q1Pred Std                           63.6447
trainer/Q1Pred Max                          417.122
trainer/Q1Pred Min                          -16.9631
trainer/Q2Pred Mean                         333.007
trainer/Q2Pred Std                           63.2979
trainer/Q2Pred Max                          419.431
trainer/Q2Pred Min                           -6.7951
trainer/QTargetWithReg Mean                 332.876
trainer/QTargetWithReg Std                   63.3998
trainer/QTargetWithReg Max                  418.693
trainer/QTargetWithReg Min                   -0.374525
trainer/PolicyLossWithoutReg Mean           334.081
trainer/PolicyLossWithoutReg Std             62.1235
trainer/PolicyLossWithoutReg Max            417.907
trainer/PolicyLossWithoutReg Min             -1.07779
exploration/num steps total              645000
exploration/num paths total                1420
exploration/path length this epoch Mean     450
exploration/path length this epoch Std        0
exploration/path length this epoch Max      450
exploration/path length this epoch Min      450
exploration/Rewards Mean                      4.23642
exploration/Rewards Std                       1.23375
exploration/Rewards Max                       6.94955
exploration/Rewards Min                      -0.91141
exploration/Returns Mean                   1906.39
exploration/Returns Std                       0
exploration/Returns Max                    1906.39
exploration/Returns Min                    1906.39
exploration/Num Paths                         1
exploration/Average Returns                1906.39
evaluation_0/num steps total                  5.00003e+06
evaluation_0/num paths total               8607
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78203
evaluation_0/Rewards Std                      0.952497
evaluation_0/Rewards Max                      7.05543
evaluation_0/Rewards Min                     -0.722535
evaluation_0/Returns Mean                  4782.03
evaluation_0/Returns Std                     59.1465
evaluation_0/Returns Max                   4843.89
evaluation_0/Returns Min                   4646.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4782.03
time/epoch (s)                                0
time/total (s)                             9749.62
Epoch                                       640
---------------------------------------  ----------------
2022-11-16 18:57:24.465157 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 641 finished
---------------------------------------  ----------------
epoch                                       641
total_step                               646000
replay_pool/size                         646000
trainer/alpha                                 0.059971
trainer/alpha_loss                           -0.759439
trainer/entropy                              -5.7301
trainer/qf_loss                              21.7766
trainer/policy_loss                        -331.895
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         332.239
trainer/entropy_penalty                      -0.34364
trainer/entropy_percentage                   -0.00103432
trainer/Q1Pred Mean                         331.943
trainer/Q1Pred Std                           64.6999
trainer/Q1Pred Max                          419.008
trainer/Q1Pred Min                          -16.8451
trainer/Q2Pred Mean                         331.86
trainer/Q2Pred Std                           64.3267
trainer/Q2Pred Max                          420.221
trainer/Q2Pred Min                           -2.01642
trainer/QTargetWithReg Mean                 331.794
trainer/QTargetWithReg Std                   63.8612
trainer/QTargetWithReg Max                  419.535
trainer/QTargetWithReg Min                    4.40704
trainer/PolicyLossWithoutReg Mean           332.239
trainer/PolicyLossWithoutReg Std             63.2344
trainer/PolicyLossWithoutReg Max            419.696
trainer/PolicyLossWithoutReg Min              1.81545
exploration/num steps total              646000
exploration/num paths total                1421
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52697
exploration/Rewards Std                       0.985083
exploration/Rewards Max                       6.86691
exploration/Rewards Min                      -0.77462
exploration/Returns Mean                   4526.97
exploration/Returns Std                       0
exploration/Returns Max                    4526.97
exploration/Returns Min                    4526.97
exploration/Num Paths                         1
exploration/Average Returns                4526.97
evaluation_0/num steps total                  5.00803e+06
evaluation_0/num paths total               8615
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6611
evaluation_0/Rewards Std                      0.923767
evaluation_0/Rewards Max                      7.30258
evaluation_0/Rewards Min                     -0.597908
evaluation_0/Returns Mean                  4661.1
evaluation_0/Returns Std                     79.7406
evaluation_0/Returns Max                   4831.29
evaluation_0/Returns Min                   4534.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4661.1
time/epoch (s)                                0
time/total (s)                             9761.42
Epoch                                       641
---------------------------------------  ----------------
2022-11-16 18:57:37.365481 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 642 finished
---------------------------------------  ----------------
epoch                                       642
total_step                               647000
replay_pool/size                         647000
trainer/alpha                                 0.0591047
trainer/alpha_loss                           -0.415027
trainer/entropy                              -5.85327
trainer/qf_loss                              18.2532
trainer/policy_loss                        -334.747
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.093
trainer/entropy_penalty                      -0.345956
trainer/entropy_percentage                   -0.00103242
trainer/Q1Pred Mean                         333.864
trainer/Q1Pred Std                           60.4333
trainer/Q1Pred Max                          407.631
trainer/Q1Pred Min                           10.8395
trainer/Q2Pred Mean                         333.384
trainer/Q2Pred Std                           60.9657
trainer/Q2Pred Max                          406.873
trainer/Q2Pred Min                            9.08026
trainer/QTargetWithReg Mean                 334.524
trainer/QTargetWithReg Std                   61.1787
trainer/QTargetWithReg Max                  412.95
trainer/QTargetWithReg Min                    8.53951
trainer/PolicyLossWithoutReg Mean           335.093
trainer/PolicyLossWithoutReg Std             59.7033
trainer/PolicyLossWithoutReg Max            406.861
trainer/PolicyLossWithoutReg Min              7.51699
exploration/num steps total              647000
exploration/num paths total                1422
exploration/path length this epoch Mean     162
exploration/path length this epoch Std        0
exploration/path length this epoch Max      162
exploration/path length this epoch Min      162
exploration/Rewards Mean                      3.39617
exploration/Rewards Std                       1.44115
exploration/Rewards Max                       6.19512
exploration/Rewards Min                      -0.696143
exploration/Returns Mean                    550.179
exploration/Returns Std                       0
exploration/Returns Max                     550.179
exploration/Returns Min                     550.179
exploration/Num Paths                         1
exploration/Average Returns                 550.179
evaluation_0/num steps total                  5.01603e+06
evaluation_0/num paths total               8623
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80091
evaluation_0/Rewards Std                      0.983213
evaluation_0/Rewards Max                      7.40773
evaluation_0/Rewards Min                     -0.814391
evaluation_0/Returns Mean                  4800.91
evaluation_0/Returns Std                     52.2529
evaluation_0/Returns Max                   4898.53
evaluation_0/Returns Min                   4739.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4800.91
time/epoch (s)                                0
time/total (s)                             9774.32
Epoch                                       642
---------------------------------------  ----------------
2022-11-16 18:57:51.036886 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 643 finished
---------------------------------------  ----------------
epoch                                       643
total_step                               648000
replay_pool/size                         648000
trainer/alpha                                 0.0593105
trainer/alpha_loss                            1.72268
trainer/entropy                              -6.60978
trainer/qf_loss                              27.3022
trainer/policy_loss                        -327.199
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         327.591
trainer/entropy_penalty                      -0.392029
trainer/entropy_percentage                   -0.0011967
trainer/Q1Pred Mean                         326.557
trainer/Q1Pred Std                           79.2197
trainer/Q1Pred Max                          421.354
trainer/Q1Pred Min                         -208.458
trainer/Q2Pred Mean                         326.659
trainer/Q2Pred Std                           78.7942
trainer/Q2Pred Max                          418.42
trainer/Q2Pred Min                         -172.667
trainer/QTargetWithReg Mean                 327.976
trainer/QTargetWithReg Std                   80.2227
trainer/QTargetWithReg Max                  420.834
trainer/QTargetWithReg Min                 -213.271
trainer/PolicyLossWithoutReg Mean           327.591
trainer/PolicyLossWithoutReg Std             78.5047
trainer/PolicyLossWithoutReg Max            417.924
trainer/PolicyLossWithoutReg Min           -206.12
exploration/num steps total              648000
exploration/num paths total                1423
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77354
exploration/Rewards Std                       1.07372
exploration/Rewards Max                       7.08359
exploration/Rewards Min                      -0.968669
exploration/Returns Mean                   4773.54
exploration/Returns Std                       0
exploration/Returns Max                    4773.54
exploration/Returns Min                    4773.54
exploration/Num Paths                         1
exploration/Average Returns                4773.54
evaluation_0/num steps total                  5.02403e+06
evaluation_0/num paths total               8631
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73576
evaluation_0/Rewards Std                      1.02692
evaluation_0/Rewards Max                      7.12108
evaluation_0/Rewards Min                     -1.01055
evaluation_0/Returns Mean                  4735.76
evaluation_0/Returns Std                     92.1699
evaluation_0/Returns Max                   4822.87
evaluation_0/Returns Min                   4535.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4735.76
time/epoch (s)                                0
time/total (s)                             9787.99
Epoch                                       643
---------------------------------------  ----------------
2022-11-16 18:58:02.716337 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 644 finished
---------------------------------------  ----------------
epoch                                       644
total_step                               649000
replay_pool/size                         649000
trainer/alpha                                 0.0611423
trainer/alpha_loss                           -0.561511
trainer/entropy                              -5.79906
trainer/qf_loss                              19.6507
trainer/policy_loss                        -333.072
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.426
trainer/entropy_penalty                      -0.354568
trainer/entropy_percentage                   -0.00106341
trainer/Q1Pred Mean                         333.391
trainer/Q1Pred Std                           72.069
trainer/Q1Pred Max                          428.319
trainer/Q1Pred Min                           30.8015
trainer/Q2Pred Mean                         332.913
trainer/Q2Pred Std                           72.3121
trainer/Q2Pred Max                          426.081
trainer/Q2Pred Min                           22.5985
trainer/QTargetWithReg Mean                 332.904
trainer/QTargetWithReg Std                   72.9778
trainer/QTargetWithReg Max                  427.477
trainer/QTargetWithReg Min                   17.8201
trainer/PolicyLossWithoutReg Mean           333.426
trainer/PolicyLossWithoutReg Std             70.9812
trainer/PolicyLossWithoutReg Max            425.99
trainer/PolicyLossWithoutReg Min             28.4752
exploration/num steps total              649000
exploration/num paths total                1424
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.30592
exploration/Rewards Std                       1.18845
exploration/Rewards Max                       6.85789
exploration/Rewards Min                      -1.35156
exploration/Returns Mean                   4305.92
exploration/Returns Std                       0
exploration/Returns Max                    4305.92
exploration/Returns Min                    4305.92
exploration/Num Paths                         1
exploration/Average Returns                4305.92
evaluation_0/num steps total                  5.03203e+06
evaluation_0/num paths total               8639
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95336
evaluation_0/Rewards Std                      1.10753
evaluation_0/Rewards Max                      7.57383
evaluation_0/Rewards Min                     -0.991937
evaluation_0/Returns Mean                  4953.36
evaluation_0/Returns Std                     54.3315
evaluation_0/Returns Max                   5027.29
evaluation_0/Returns Min                   4874.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4953.36
time/epoch (s)                                0
time/total (s)                             9799.67
Epoch                                       644
---------------------------------------  ----------------
2022-11-16 18:58:13.946580 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 645 finished
---------------------------------------  ----------------
epoch                                       645
total_step                               650000
replay_pool/size                         650000
trainer/alpha                                 0.060682
trainer/alpha_loss                            1.44286
trainer/entropy                              -6.51491
trainer/qf_loss                              26.761
trainer/policy_loss                        -332.908
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.303
trainer/entropy_penalty                      -0.395338
trainer/entropy_percentage                   -0.00118612
trainer/Q1Pred Mean                         332.765
trainer/Q1Pred Std                           72.9337
trainer/Q1Pred Max                          419.005
trainer/Q1Pred Min                           -0.0768585
trainer/Q2Pred Mean                         331.465
trainer/Q2Pred Std                           73.3065
trainer/Q2Pred Max                          419.012
trainer/Q2Pred Min                          -43.7465
trainer/QTargetWithReg Mean                 332.234
trainer/QTargetWithReg Std                   72.8985
trainer/QTargetWithReg Max                  416.394
trainer/QTargetWithReg Min                    0.270645
trainer/PolicyLossWithoutReg Mean           333.303
trainer/PolicyLossWithoutReg Std             71.1271
trainer/PolicyLossWithoutReg Max            416.765
trainer/PolicyLossWithoutReg Min              2.16933
exploration/num steps total              650000
exploration/num paths total                1426
exploration/path length this epoch Mean     444
exploration/path length this epoch Std       50
exploration/path length this epoch Max      494
exploration/path length this epoch Min      394
exploration/Rewards Mean                      4.23753
exploration/Rewards Std                       1.29628
exploration/Rewards Max                       6.98457
exploration/Rewards Min                      -0.928393
exploration/Returns Mean                   1881.46
exploration/Returns Std                     306.908
exploration/Returns Max                    2188.37
exploration/Returns Min                    1574.55
exploration/Num Paths                         2
exploration/Average Returns                1881.46
evaluation_0/num steps total                  5.04003e+06
evaluation_0/num paths total               8647
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81172
evaluation_0/Rewards Std                      0.949693
evaluation_0/Rewards Max                      7.28472
evaluation_0/Rewards Min                     -0.791959
evaluation_0/Returns Mean                  4811.72
evaluation_0/Returns Std                     72.2833
evaluation_0/Returns Max                   4899.43
evaluation_0/Returns Min                   4689.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4811.72
time/epoch (s)                                0
time/total (s)                             9810.9
Epoch                                       645
---------------------------------------  ----------------
2022-11-16 18:58:28.156877 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 646 finished
---------------------------------------  ----------------
epoch                                       646
total_step                               651000
replay_pool/size                         651000
trainer/alpha                                 0.0612238
trainer/alpha_loss                           -0.726901
trainer/entropy                              -5.73975
trainer/qf_loss                              23.0344
trainer/policy_loss                        -330.977
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.328
trainer/entropy_penalty                      -0.351409
trainer/entropy_percentage                   -0.00106061
trainer/Q1Pred Mean                         330.493
trainer/Q1Pred Std                           68.285
trainer/Q1Pred Max                          421.768
trainer/Q1Pred Min                           -3.18055
trainer/Q2Pred Mean                         330.727
trainer/Q2Pred Std                           68.1227
trainer/Q2Pred Max                          421.402
trainer/Q2Pred Min                            8.50603
trainer/QTargetWithReg Mean                 331.385
trainer/QTargetWithReg Std                   68.7481
trainer/QTargetWithReg Max                  420.49
trainer/QTargetWithReg Min                    5.06753
trainer/PolicyLossWithoutReg Mean           331.328
trainer/PolicyLossWithoutReg Std             67.2418
trainer/PolicyLossWithoutReg Max            422.381
trainer/PolicyLossWithoutReg Min             11.0206
exploration/num steps total              651000
exploration/num paths total                1427
exploration/path length this epoch Mean     113
exploration/path length this epoch Std        0
exploration/path length this epoch Max      113
exploration/path length this epoch Min      113
exploration/Rewards Mean                      2.78855
exploration/Rewards Std                       1.23578
exploration/Rewards Max                       4.42025
exploration/Rewards Min                      -0.776691
exploration/Returns Mean                    315.106
exploration/Returns Std                       0
exploration/Returns Max                     315.106
exploration/Returns Min                     315.106
exploration/Num Paths                         1
exploration/Average Returns                 315.106
evaluation_0/num steps total                  5.04803e+06
evaluation_0/num paths total               8655
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77231
evaluation_0/Rewards Std                      0.92064
evaluation_0/Rewards Max                      7.17911
evaluation_0/Rewards Min                     -0.803815
evaluation_0/Returns Mean                  4772.31
evaluation_0/Returns Std                    100.068
evaluation_0/Returns Max                   4924.01
evaluation_0/Returns Min                   4636.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4772.31
time/epoch (s)                                0
time/total (s)                             9825.11
Epoch                                       646
---------------------------------------  ----------------
2022-11-16 18:58:39.365018 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 647 finished
---------------------------------------  ----------------
epoch                                       647
total_step                               652000
replay_pool/size                         652000
trainer/alpha                                 0.0609046
trainer/alpha_loss                            0.964833
trainer/entropy                              -6.34477
trainer/qf_loss                              22.5297
trainer/policy_loss                        -337.021
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         337.407
trainer/entropy_penalty                      -0.386425
trainer/entropy_percentage                   -0.00114528
trainer/Q1Pred Mean                         336.942
trainer/Q1Pred Std                           66.4225
trainer/Q1Pred Max                          414.153
trainer/Q1Pred Min                            4.01004
trainer/Q2Pred Mean                         337.268
trainer/Q2Pred Std                           66.6213
trainer/Q2Pred Max                          417.356
trainer/Q2Pred Min                           -1.51296
trainer/QTargetWithReg Mean                 336.02
trainer/QTargetWithReg Std                   67.0666
trainer/QTargetWithReg Max                  415.631
trainer/QTargetWithReg Min                    5.67613
trainer/PolicyLossWithoutReg Mean           337.407
trainer/PolicyLossWithoutReg Std             66.0384
trainer/PolicyLossWithoutReg Max            417.949
trainer/PolicyLossWithoutReg Min              4.03404
exploration/num steps total              652000
exploration/num paths total                1428
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53737
exploration/Rewards Std                       0.997837
exploration/Rewards Max                       6.50742
exploration/Rewards Min                      -0.873394
exploration/Returns Mean                   4537.37
exploration/Returns Std                       0
exploration/Returns Max                    4537.37
exploration/Returns Min                    4537.37
exploration/Num Paths                         1
exploration/Average Returns                4537.37
evaluation_0/num steps total                  5.05603e+06
evaluation_0/num paths total               8663
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02979
evaluation_0/Rewards Std                      1.18916
evaluation_0/Rewards Max                      7.46391
evaluation_0/Rewards Min                     -0.738349
evaluation_0/Returns Mean                  5029.79
evaluation_0/Returns Std                     32.9738
evaluation_0/Returns Max                   5089.63
evaluation_0/Returns Min                   4988.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5029.79
time/epoch (s)                                0
time/total (s)                             9836.32
Epoch                                       647
---------------------------------------  ----------------
2022-11-16 18:58:52.035349 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 648 finished
---------------------------------------  ----------------
epoch                                       648
total_step                               653000
replay_pool/size                         653000
trainer/alpha                                 0.0607298
trainer/alpha_loss                            1.64013
trainer/entropy                              -6.58549
trainer/qf_loss                              47.4086
trainer/policy_loss                        -326.673
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         327.073
trainer/entropy_penalty                      -0.399935
trainer/entropy_percentage                   -0.00122277
trainer/Q1Pred Mean                         324.665
trainer/Q1Pred Std                           69.5939
trainer/Q1Pred Max                          419.872
trainer/Q1Pred Min                            5.56013
trainer/Q2Pred Mean                         325.315
trainer/Q2Pred Std                           69.2004
trainer/Q2Pred Max                          423.297
trainer/Q2Pred Min                            2.12413
trainer/QTargetWithReg Mean                 325.508
trainer/QTargetWithReg Std                   68.6278
trainer/QTargetWithReg Max                  420.895
trainer/QTargetWithReg Min                    5.06696
trainer/PolicyLossWithoutReg Mean           327.073
trainer/PolicyLossWithoutReg Std             66.1685
trainer/PolicyLossWithoutReg Max            420.767
trainer/PolicyLossWithoutReg Min              1.48069
exploration/num steps total              653000
exploration/num paths total                1429
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43007
exploration/Rewards Std                       0.956664
exploration/Rewards Max                       6.65973
exploration/Rewards Min                      -0.841456
exploration/Returns Mean                   4430.07
exploration/Returns Std                       0
exploration/Returns Max                    4430.07
exploration/Returns Min                    4430.07
exploration/Num Paths                         1
exploration/Average Returns                4430.07
evaluation_0/num steps total                  5.06403e+06
evaluation_0/num paths total               8671
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70229
evaluation_0/Rewards Std                      0.994798
evaluation_0/Rewards Max                      7.36114
evaluation_0/Rewards Min                     -0.851003
evaluation_0/Returns Mean                  4702.29
evaluation_0/Returns Std                     50.7798
evaluation_0/Returns Max                   4820.31
evaluation_0/Returns Min                   4636.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4702.29
time/epoch (s)                                0
time/total (s)                             9848.99
Epoch                                       648
---------------------------------------  ----------------
2022-11-16 18:59:05.984455 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 649 finished
---------------------------------------  ----------------
epoch                                       649
total_step                               654000
replay_pool/size                         654000
trainer/alpha                                 0.0595517
trainer/alpha_loss                           -0.821827
trainer/entropy                              -5.70866
trainer/qf_loss                              21.3979
trainer/policy_loss                        -339.138
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.478
trainer/entropy_penalty                      -0.339961
trainer/entropy_percentage                   -0.00100142
trainer/Q1Pred Mean                         338.804
trainer/Q1Pred Std                           60.6051
trainer/Q1Pred Max                          416.816
trainer/Q1Pred Min                            8.47129
trainer/Q2Pred Mean                         338.752
trainer/Q2Pred Std                           60.2456
trainer/Q2Pred Max                          418.969
trainer/Q2Pred Min                           10.1494
trainer/QTargetWithReg Mean                 339.2
trainer/QTargetWithReg Std                   61.9353
trainer/QTargetWithReg Max                  419.005
trainer/QTargetWithReg Min                    1.91639
trainer/PolicyLossWithoutReg Mean           339.478
trainer/PolicyLossWithoutReg Std             60.2504
trainer/PolicyLossWithoutReg Max            417.846
trainer/PolicyLossWithoutReg Min              9.00224
exploration/num steps total              654000
exploration/num paths total                1430
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66186
exploration/Rewards Std                       1.01573
exploration/Rewards Max                       6.547
exploration/Rewards Min                      -0.774508
exploration/Returns Mean                   4661.86
exploration/Returns Std                       0
exploration/Returns Max                    4661.86
exploration/Returns Min                    4661.86
exploration/Num Paths                         1
exploration/Average Returns                4661.86
evaluation_0/num steps total                  5.07203e+06
evaluation_0/num paths total               8679
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9378
evaluation_0/Rewards Std                      0.989474
evaluation_0/Rewards Max                      7.45021
evaluation_0/Rewards Min                     -0.745219
evaluation_0/Returns Mean                  4937.8
evaluation_0/Returns Std                     91.5281
evaluation_0/Returns Max                   5027.89
evaluation_0/Returns Min                   4751.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4937.8
time/epoch (s)                                0
time/total (s)                             9862.94
Epoch                                       649
---------------------------------------  ----------------
2022-11-16 18:59:17.803992 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 650 finished
---------------------------------------  ----------------
epoch                                       650
total_step                               655000
replay_pool/size                         655000
trainer/alpha                                 0.0608234
trainer/alpha_loss                           -2.1126
trainer/entropy                              -5.24539
trainer/qf_loss                              16.0226
trainer/policy_loss                        -341.707
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.026
trainer/entropy_penalty                      -0.319043
trainer/entropy_percentage                   -0.000932801
trainer/Q1Pred Mean                         341.501
trainer/Q1Pred Std                           58.37
trainer/Q1Pred Max                          421.404
trainer/Q1Pred Min                           39.8002
trainer/Q2Pred Mean                         341.364
trainer/Q2Pred Std                           58.685
trainer/Q2Pred Max                          422.469
trainer/Q2Pred Min                           40.6185
trainer/QTargetWithReg Mean                 341.742
trainer/QTargetWithReg Std                   58.4213
trainer/QTargetWithReg Max                  421.472
trainer/QTargetWithReg Min                   33.7969
trainer/PolicyLossWithoutReg Mean           342.026
trainer/PolicyLossWithoutReg Std             57.4942
trainer/PolicyLossWithoutReg Max            421.705
trainer/PolicyLossWithoutReg Min             40.1951
exploration/num steps total              655000
exploration/num paths total                1431
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75189
exploration/Rewards Std                       1.00217
exploration/Rewards Max                       7.10924
exploration/Rewards Min                      -0.66459
exploration/Returns Mean                   4751.89
exploration/Returns Std                       0
exploration/Returns Max                    4751.89
exploration/Returns Min                    4751.89
exploration/Num Paths                         1
exploration/Average Returns                4751.89
evaluation_0/num steps total                  5.08003e+06
evaluation_0/num paths total               8687
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87296
evaluation_0/Rewards Std                      1.06262
evaluation_0/Rewards Max                      7.29978
evaluation_0/Rewards Min                     -0.833586
evaluation_0/Returns Mean                  4872.96
evaluation_0/Returns Std                     53.8356
evaluation_0/Returns Max                   4962.22
evaluation_0/Returns Min                   4796.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4872.96
time/epoch (s)                                0
time/total (s)                             9874.76
Epoch                                       650
---------------------------------------  ----------------
2022-11-16 18:59:29.275815 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 651 finished
---------------------------------------  ----------------
epoch                                       651
total_step                               656000
replay_pool/size                         656000
trainer/alpha                                 0.0612127
trainer/alpha_loss                           -1.86616
trainer/entropy                              -5.33192
trainer/qf_loss                              26.2465
trainer/policy_loss                        -336.766
trainer/adversary_policy_loss                16.1969
trainer/policy_loss_without_entropy         337.093
trainer/entropy_penalty                      -0.326381
trainer/entropy_percentage                   -0.000968224
trainer/Q1Pred Mean                         335.729
trainer/Q1Pred Std                           66.8228
trainer/Q1Pred Max                          415.897
trainer/Q1Pred Min                            8.95001
trainer/Q2Pred Mean                         335.617
trainer/Q2Pred Std                           66.8715
trainer/Q2Pred Max                          414.496
trainer/Q2Pred Min                           11.6312
trainer/QTargetWithReg Mean                 336.061
trainer/QTargetWithReg Std                   67.8927
trainer/QTargetWithReg Max                  417.022
trainer/QTargetWithReg Min                    3.67477
trainer/PolicyLossWithoutReg Mean           337.093
trainer/PolicyLossWithoutReg Std             65.9021
trainer/PolicyLossWithoutReg Max            415.348
trainer/PolicyLossWithoutReg Min              8.56618
exploration/num steps total              656000
exploration/num paths total                1432
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60024
exploration/Rewards Std                       1.25634
exploration/Rewards Max                       7.58766
exploration/Rewards Min                      -0.848547
exploration/Returns Mean                   4600.24
exploration/Returns Std                       0
exploration/Returns Max                    4600.24
exploration/Returns Min                    4600.24
exploration/Num Paths                         1
exploration/Average Returns                4600.24
evaluation_0/num steps total                  5.08803e+06
evaluation_0/num paths total               8695
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74826
evaluation_0/Rewards Std                      1.03541
evaluation_0/Rewards Max                      7.2738
evaluation_0/Rewards Min                     -0.984252
evaluation_0/Returns Mean                  4748.26
evaluation_0/Returns Std                     85.0444
evaluation_0/Returns Max                   4898.96
evaluation_0/Returns Min                   4651.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4748.26
time/epoch (s)                                0
time/total (s)                             9886.23
Epoch                                       651
---------------------------------------  ----------------
2022-11-16 18:59:42.717745 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 652 finished
---------------------------------------  ----------------
epoch                                       652
total_step                               657000
replay_pool/size                         657000
trainer/alpha                                 0.0626925
trainer/alpha_loss                           -0.258302
trainer/entropy                              -5.90673
trainer/qf_loss                              23.1749
trainer/policy_loss                        -342.39
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.76
trainer/entropy_penalty                      -0.370308
trainer/entropy_percentage                   -0.00108037
trainer/Q1Pred Mean                         341.11
trainer/Q1Pred Std                           64.5059
trainer/Q1Pred Max                          408.137
trainer/Q1Pred Min                            0.374403
trainer/Q2Pred Mean                         342.069
trainer/Q2Pred Std                           64.7473
trainer/Q2Pred Max                          409.355
trainer/Q2Pred Min                            2.21389
trainer/QTargetWithReg Mean                 341.355
trainer/QTargetWithReg Std                   64.5235
trainer/QTargetWithReg Max                  412.217
trainer/QTargetWithReg Min                   -8.5809
trainer/PolicyLossWithoutReg Mean           342.76
trainer/PolicyLossWithoutReg Std             64.0663
trainer/PolicyLossWithoutReg Max            409.799
trainer/PolicyLossWithoutReg Min             -3.159
exploration/num steps total              657000
exploration/num paths total                1433
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57834
exploration/Rewards Std                       1.11284
exploration/Rewards Max                       7.30327
exploration/Rewards Min                      -0.929592
exploration/Returns Mean                   4578.34
exploration/Returns Std                       0
exploration/Returns Max                    4578.34
exploration/Returns Min                    4578.34
exploration/Num Paths                         1
exploration/Average Returns                4578.34
evaluation_0/num steps total                  5.09603e+06
evaluation_0/num paths total               8703
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88672
evaluation_0/Rewards Std                      0.962642
evaluation_0/Rewards Max                      7.28811
evaluation_0/Rewards Min                     -0.856918
evaluation_0/Returns Mean                  4886.72
evaluation_0/Returns Std                     49.7838
evaluation_0/Returns Max                   4971.08
evaluation_0/Returns Min                   4832.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4886.72
time/epoch (s)                                0
time/total (s)                             9899.67
Epoch                                       652
---------------------------------------  ----------------
2022-11-16 18:59:53.977684 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 653 finished
---------------------------------------  ----------------
epoch                                       653
total_step                               658000
replay_pool/size                         658000
trainer/alpha                                 0.0608353
trainer/alpha_loss                            0.761512
trainer/entropy                              -6.27201
trainer/qf_loss                              80.4149
trainer/policy_loss                        -331.349
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         331.731
trainer/entropy_penalty                      -0.38156
trainer/entropy_percentage                   -0.00115021
trainer/Q1Pred Mean                         329.726
trainer/Q1Pred Std                           68.8333
trainer/Q1Pred Max                          425.027
trainer/Q1Pred Min                         -127.051
trainer/Q2Pred Mean                         329.652
trainer/Q2Pred Std                           66.3591
trainer/Q2Pred Max                          422.825
trainer/Q2Pred Min                          -50.5314
trainer/QTargetWithReg Mean                 329.748
trainer/QTargetWithReg Std                   65.4345
trainer/QTargetWithReg Max                  422.829
trainer/QTargetWithReg Min                    4.27904
trainer/PolicyLossWithoutReg Mean           331.731
trainer/PolicyLossWithoutReg Std             67.0726
trainer/PolicyLossWithoutReg Max            424.587
trainer/PolicyLossWithoutReg Min           -105.714
exploration/num steps total              658000
exploration/num paths total                1434
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84369
exploration/Rewards Std                       1.03803
exploration/Rewards Max                       7.14133
exploration/Rewards Min                      -0.954424
exploration/Returns Mean                   4843.69
exploration/Returns Std                       0
exploration/Returns Max                    4843.69
exploration/Returns Min                    4843.69
exploration/Num Paths                         1
exploration/Average Returns                4843.69
evaluation_0/num steps total                  5.10403e+06
evaluation_0/num paths total               8711
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63101
evaluation_0/Rewards Std                      1.03487
evaluation_0/Rewards Max                      7.14295
evaluation_0/Rewards Min                     -0.833861
evaluation_0/Returns Mean                  4631.01
evaluation_0/Returns Std                     81.2387
evaluation_0/Returns Max                   4761.69
evaluation_0/Returns Min                   4518.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4631.01
time/epoch (s)                                0
time/total (s)                             9910.93
Epoch                                       653
---------------------------------------  ----------------
2022-11-16 19:00:05.582874 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 654 finished
---------------------------------------  ----------------
epoch                                       654
total_step                               659000
replay_pool/size                         659000
trainer/alpha                                 0.05981
trainer/alpha_loss                           -0.724571
trainer/entropy                              -5.74275
trainer/qf_loss                              17.3324
trainer/policy_loss                        -335.383
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.727
trainer/entropy_penalty                      -0.343474
trainer/entropy_percentage                   -0.00102307
trainer/Q1Pred Mean                         333.822
trainer/Q1Pred Std                           64.2133
trainer/Q1Pred Max                          415.382
trainer/Q1Pred Min                           23.8285
trainer/Q2Pred Mean                         334.198
trainer/Q2Pred Std                           63.4057
trainer/Q2Pred Max                          416.237
trainer/Q2Pred Min                           18.7179
trainer/QTargetWithReg Mean                 334.474
trainer/QTargetWithReg Std                   63.5621
trainer/QTargetWithReg Max                  415.65
trainer/QTargetWithReg Min                   20.5257
trainer/PolicyLossWithoutReg Mean           335.727
trainer/PolicyLossWithoutReg Std             62.4245
trainer/PolicyLossWithoutReg Max            415.893
trainer/PolicyLossWithoutReg Min             24.1745
exploration/num steps total              659000
exploration/num paths total                1435
exploration/path length this epoch Mean     280
exploration/path length this epoch Std        0
exploration/path length this epoch Max      280
exploration/path length this epoch Min      280
exploration/Rewards Mean                      3.34643
exploration/Rewards Std                       1.26067
exploration/Rewards Max                       6.065
exploration/Rewards Min                      -0.973929
exploration/Returns Mean                    937
exploration/Returns Std                       0
exploration/Returns Max                     937
exploration/Returns Min                     937
exploration/Num Paths                         1
exploration/Average Returns                 937
evaluation_0/num steps total                  5.11203e+06
evaluation_0/num paths total               8719
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77942
evaluation_0/Rewards Std                      1.12168
evaluation_0/Rewards Max                      7.43536
evaluation_0/Rewards Min                     -1.01008
evaluation_0/Returns Mean                  4779.42
evaluation_0/Returns Std                    139.711
evaluation_0/Returns Max                   4985.28
evaluation_0/Returns Min                   4623.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4779.42
time/epoch (s)                                0
time/total (s)                             9922.54
Epoch                                       654
---------------------------------------  ----------------
2022-11-16 19:00:19.582623 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 655 finished
---------------------------------------  ----------------
epoch                                       655
total_step                               660000
replay_pool/size                         660000
trainer/alpha                                 0.0601903
trainer/alpha_loss                           -0.465907
trainer/entropy                              -5.83421
trainer/qf_loss                              18.0865
trainer/policy_loss                        -333.498
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.849
trainer/entropy_penalty                      -0.351163
trainer/entropy_percentage                   -0.00105186
trainer/Q1Pred Mean                         332.61
trainer/Q1Pred Std                           76.7773
trainer/Q1Pred Max                          416.812
trainer/Q1Pred Min                          -39.477
trainer/Q2Pred Mean                         332.519
trainer/Q2Pred Std                           76.2542
trainer/Q2Pred Max                          414.678
trainer/Q2Pred Min                           -1.88588
trainer/QTargetWithReg Mean                 332.718
trainer/QTargetWithReg Std                   76.1482
trainer/QTargetWithReg Max                  417.066
trainer/QTargetWithReg Min                   -0.0410668
trainer/PolicyLossWithoutReg Mean           333.849
trainer/PolicyLossWithoutReg Std             73.8875
trainer/PolicyLossWithoutReg Max            415.885
trainer/PolicyLossWithoutReg Min              9.22298
exploration/num steps total              660000
exploration/num paths total                1436
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61119
exploration/Rewards Std                       1.22883
exploration/Rewards Max                       6.84683
exploration/Rewards Min                      -0.929192
exploration/Returns Mean                   4611.19
exploration/Returns Std                       0
exploration/Returns Max                    4611.19
exploration/Returns Min                    4611.19
exploration/Num Paths                         1
exploration/Average Returns                4611.19
evaluation_0/num steps total                  5.12003e+06
evaluation_0/num paths total               8727
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74397
evaluation_0/Rewards Std                      1.05243
evaluation_0/Rewards Max                      7.24607
evaluation_0/Rewards Min                     -0.832625
evaluation_0/Returns Mean                  4743.97
evaluation_0/Returns Std                    104.66
evaluation_0/Returns Max                   4906.48
evaluation_0/Returns Min                   4570.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4743.97
time/epoch (s)                                0
time/total (s)                             9936.54
Epoch                                       655
---------------------------------------  ----------------
2022-11-16 19:00:30.864128 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 656 finished
---------------------------------------  ----------------
epoch                                       656
total_step                               661000
replay_pool/size                         661000
trainer/alpha                                 0.0599237
trainer/alpha_loss                            0.16523
trainer/entropy                              -6.0587
trainer/qf_loss                              21.4158
trainer/policy_loss                        -333.676
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.039
trainer/entropy_penalty                      -0.36306
trainer/entropy_percentage                   -0.00108688
trainer/Q1Pred Mean                         333.819
trainer/Q1Pred Std                           63.8817
trainer/Q1Pred Max                          425.816
trainer/Q1Pred Min                           14.0291
trainer/Q2Pred Mean                         333.917
trainer/Q2Pred Std                           63.4128
trainer/Q2Pred Max                          424.453
trainer/Q2Pred Min                           15.763
trainer/QTargetWithReg Mean                 332.953
trainer/QTargetWithReg Std                   63.6624
trainer/QTargetWithReg Max                  425.687
trainer/QTargetWithReg Min                   16.1689
trainer/PolicyLossWithoutReg Mean           334.039
trainer/PolicyLossWithoutReg Std             63.1688
trainer/PolicyLossWithoutReg Max            423.272
trainer/PolicyLossWithoutReg Min             14.7212
exploration/num steps total              661000
exploration/num paths total                1437
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55542
exploration/Rewards Std                       1.00093
exploration/Rewards Max                       6.63061
exploration/Rewards Min                      -0.835779
exploration/Returns Mean                   4555.42
exploration/Returns Std                       0
exploration/Returns Max                    4555.42
exploration/Returns Min                    4555.42
exploration/Num Paths                         1
exploration/Average Returns                4555.42
evaluation_0/num steps total                  5.12803e+06
evaluation_0/num paths total               8735
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85427
evaluation_0/Rewards Std                      1.08417
evaluation_0/Rewards Max                      7.52767
evaluation_0/Rewards Min                     -0.826038
evaluation_0/Returns Mean                  4854.27
evaluation_0/Returns Std                     86.9975
evaluation_0/Returns Max                   4962.52
evaluation_0/Returns Min                   4704.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4854.27
time/epoch (s)                                0
time/total (s)                             9947.82
Epoch                                       656
---------------------------------------  ----------------
2022-11-16 19:00:42.104837 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 657 finished
---------------------------------------  ----------------
epoch                                       657
total_step                               662000
replay_pool/size                         662000
trainer/alpha                                 0.0604055
trainer/alpha_loss                            0.763107
trainer/entropy                              -6.27189
trainer/qf_loss                              20.9677
trainer/policy_loss                        -340.346
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.724
trainer/entropy_penalty                      -0.378856
trainer/entropy_percentage                   -0.00111191
trainer/Q1Pred Mean                         339.688
trainer/Q1Pred Std                           61.8912
trainer/Q1Pred Max                          419.2
trainer/Q1Pred Min                           10.2428
trainer/Q2Pred Mean                         339.722
trainer/Q2Pred Std                           61.3398
trainer/Q2Pred Max                          423.511
trainer/Q2Pred Min                           26.1608
trainer/QTargetWithReg Mean                 340.032
trainer/QTargetWithReg Std                   61.7161
trainer/QTargetWithReg Max                  418.623
trainer/QTargetWithReg Min                    3.45634
trainer/PolicyLossWithoutReg Mean           340.724
trainer/PolicyLossWithoutReg Std             60.7746
trainer/PolicyLossWithoutReg Max            420.215
trainer/PolicyLossWithoutReg Min             17.5808
exploration/num steps total              662000
exploration/num paths total                1440
exploration/path length this epoch Mean     228
exploration/path length this epoch Std      280.358
exploration/path length this epoch Max      624
exploration/path length this epoch Min       13
exploration/Rewards Mean                      4.10618
exploration/Rewards Std                       1.62771
exploration/Rewards Max                       6.67317
exploration/Rewards Min                      -1.00528
exploration/Returns Mean                    936.21
exploration/Returns Std                    1265.66
exploration/Returns Max                    2725.41
exploration/Returns Min                      -2.23213
exploration/Num Paths                         3
exploration/Average Returns                 936.21
evaluation_0/num steps total                  5.13603e+06
evaluation_0/num paths total               8743
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81271
evaluation_0/Rewards Std                      1.14592
evaluation_0/Rewards Max                      7.79976
evaluation_0/Rewards Min                     -0.591035
evaluation_0/Returns Mean                  4812.71
evaluation_0/Returns Std                     95.5858
evaluation_0/Returns Max                   4921.64
evaluation_0/Returns Min                   4675.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4812.71
time/epoch (s)                                0
time/total (s)                             9959.06
Epoch                                       657
---------------------------------------  ----------------
2022-11-16 19:00:56.184831 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 658 finished
---------------------------------------  ----------------
epoch                                       658
total_step                               663000
replay_pool/size                         663000
trainer/alpha                                 0.0599582
trainer/alpha_loss                           -1.09333
trainer/entropy                              -5.61148
trainer/qf_loss                              14.6131
trainer/policy_loss                        -334.304
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.641
trainer/entropy_penalty                      -0.336454
trainer/entropy_percentage                   -0.00100542
trainer/Q1Pred Mean                         333.911
trainer/Q1Pred Std                           72.0602
trainer/Q1Pred Max                          418.413
trainer/Q1Pred Min                          -41.2059
trainer/Q2Pred Mean                         334.71
trainer/Q2Pred Std                           72.4801
trainer/Q2Pred Max                          420.721
trainer/Q2Pred Min                          -47.0559
trainer/QTargetWithReg Mean                 334.002
trainer/QTargetWithReg Std                   72.9083
trainer/QTargetWithReg Max                  420.135
trainer/QTargetWithReg Min                  -42.4684
trainer/PolicyLossWithoutReg Mean           334.641
trainer/PolicyLossWithoutReg Std             71.825
trainer/PolicyLossWithoutReg Max            419.236
trainer/PolicyLossWithoutReg Min            -47.7858
exploration/num steps total              663000
exploration/num paths total                1441
exploration/path length this epoch Mean     124
exploration/path length this epoch Std        0
exploration/path length this epoch Max      124
exploration/path length this epoch Min      124
exploration/Rewards Mean                      1.85862
exploration/Rewards Std                       1.26003
exploration/Rewards Max                       5.11691
exploration/Rewards Min                      -0.73395
exploration/Returns Mean                    230.469
exploration/Returns Std                       0
exploration/Returns Max                     230.469
exploration/Returns Min                     230.469
exploration/Num Paths                         1
exploration/Average Returns                 230.469
evaluation_0/num steps total                  5.14403e+06
evaluation_0/num paths total               8751
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88771
evaluation_0/Rewards Std                      1.09113
evaluation_0/Rewards Max                      7.31627
evaluation_0/Rewards Min                     -0.866725
evaluation_0/Returns Mean                  4887.71
evaluation_0/Returns Std                    122.122
evaluation_0/Returns Max                   5063.07
evaluation_0/Returns Min                   4624.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.71
time/epoch (s)                                0
time/total (s)                             9973.14
Epoch                                       658
---------------------------------------  ----------------
2022-11-16 19:01:08.882438 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 659 finished
---------------------------------------  ----------------
epoch                                       659
total_step                               664000
replay_pool/size                         664000
trainer/alpha                                 0.0598183
trainer/alpha_loss                           -1.00033
trainer/entropy                              -5.64484
trainer/qf_loss                              14.9045
trainer/policy_loss                        -343.947
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.285
trainer/entropy_penalty                      -0.337665
trainer/entropy_percentage                   -0.000980772
trainer/Q1Pred Mean                         343.218
trainer/Q1Pred Std                           58.528
trainer/Q1Pred Max                          419.623
trainer/Q1Pred Min                           -3.59289
trainer/Q2Pred Mean                         343.367
trainer/Q2Pred Std                           58.8246
trainer/Q2Pred Max                          417.951
trainer/Q2Pred Min                          -17.2304
trainer/QTargetWithReg Mean                 342.65
trainer/QTargetWithReg Std                   58.5064
trainer/QTargetWithReg Max                  416.846
trainer/QTargetWithReg Min                  -13.7341
trainer/PolicyLossWithoutReg Mean           344.285
trainer/PolicyLossWithoutReg Std             58.1387
trainer/PolicyLossWithoutReg Max            424.885
trainer/PolicyLossWithoutReg Min             -3.64234
exploration/num steps total              664000
exploration/num paths total                1442
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55474
exploration/Rewards Std                       1.08347
exploration/Rewards Max                       7.04574
exploration/Rewards Min                      -0.881109
exploration/Returns Mean                   4554.74
exploration/Returns Std                       0
exploration/Returns Max                    4554.74
exploration/Returns Min                    4554.74
exploration/Num Paths                         1
exploration/Average Returns                4554.74
evaluation_0/num steps total                  5.15203e+06
evaluation_0/num paths total               8759
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81536
evaluation_0/Rewards Std                      1.07118
evaluation_0/Rewards Max                      7.91637
evaluation_0/Rewards Min                     -0.705461
evaluation_0/Returns Mean                  4815.36
evaluation_0/Returns Std                     67.3019
evaluation_0/Returns Max                   4920.83
evaluation_0/Returns Min                   4713.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4815.36
time/epoch (s)                                0
time/total (s)                             9985.83
Epoch                                       659
---------------------------------------  ----------------
2022-11-16 19:01:21.584990 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 660 finished
---------------------------------------  ----------------
epoch                                       660
total_step                               665000
replay_pool/size                         665000
trainer/alpha                                 0.0601559
trainer/alpha_loss                            0.147932
trainer/entropy                              -6.05263
trainer/qf_loss                              20.1651
trainer/policy_loss                        -336.126
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         336.49
trainer/entropy_penalty                      -0.364101
trainer/entropy_percentage                   -0.00108206
trainer/Q1Pred Mean                         334.617
trainer/Q1Pred Std                           70.5457
trainer/Q1Pred Max                          419.308
trainer/Q1Pred Min                            5.18508
trainer/Q2Pred Mean                         335.347
trainer/Q2Pred Std                           70.4826
trainer/Q2Pred Max                          420.639
trainer/Q2Pred Min                           -0.263905
trainer/QTargetWithReg Mean                 334.947
trainer/QTargetWithReg Std                   70.3051
trainer/QTargetWithReg Max                  419.677
trainer/QTargetWithReg Min                    0.481349
trainer/PolicyLossWithoutReg Mean           336.49
trainer/PolicyLossWithoutReg Std             69.9504
trainer/PolicyLossWithoutReg Max            420.666
trainer/PolicyLossWithoutReg Min              2.16455
exploration/num steps total              665000
exploration/num paths total                1443
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44988
exploration/Rewards Std                       1.13883
exploration/Rewards Max                       7.18179
exploration/Rewards Min                      -0.423137
exploration/Returns Mean                   4449.88
exploration/Returns Std                       0
exploration/Returns Max                    4449.88
exploration/Returns Min                    4449.88
exploration/Num Paths                         1
exploration/Average Returns                4449.88
evaluation_0/num steps total                  5.16003e+06
evaluation_0/num paths total               8767
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72078
evaluation_0/Rewards Std                      1.0081
evaluation_0/Rewards Max                      7.61471
evaluation_0/Rewards Min                     -0.94924
evaluation_0/Returns Mean                  4720.78
evaluation_0/Returns Std                    167.867
evaluation_0/Returns Max                   4940.41
evaluation_0/Returns Min                   4335.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4720.78
time/epoch (s)                                0
time/total (s)                             9998.54
Epoch                                       660
---------------------------------------  ----------------
2022-11-16 19:01:34.979622 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 661 finished
---------------------------------------  ----------------
epoch                                       661
total_step                               666000
replay_pool/size                         666000
trainer/alpha                                 0.0606131
trainer/alpha_loss                           -1.30103
trainer/entropy                              -5.53584
trainer/qf_loss                              17.6922
trainer/policy_loss                        -341.015
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.35
trainer/entropy_penalty                      -0.335545
trainer/entropy_percentage                   -0.000982992
trainer/Q1Pred Mean                         340.188
trainer/Q1Pred Std                           59.2592
trainer/Q1Pred Max                          415.418
trainer/Q1Pred Min                          -17.3451
trainer/Q2Pred Mean                         340.198
trainer/Q2Pred Std                           58.6741
trainer/Q2Pred Max                          414.82
trainer/Q2Pred Min                           -0.762602
trainer/QTargetWithReg Mean                 340.737
trainer/QTargetWithReg Std                   59.437
trainer/QTargetWithReg Max                  416.306
trainer/QTargetWithReg Min                   -3.25925
trainer/PolicyLossWithoutReg Mean           341.35
trainer/PolicyLossWithoutReg Std             57.8239
trainer/PolicyLossWithoutReg Max            416.298
trainer/PolicyLossWithoutReg Min             -4.53042
exploration/num steps total              666000
exploration/num paths total                1444
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.36898
exploration/Rewards Std                       1.19195
exploration/Rewards Max                       7.20944
exploration/Rewards Min                      -0.763461
exploration/Returns Mean                   4368.98
exploration/Returns Std                       0
exploration/Returns Max                    4368.98
exploration/Returns Min                    4368.98
exploration/Num Paths                         1
exploration/Average Returns                4368.98
evaluation_0/num steps total                  5.16803e+06
evaluation_0/num paths total               8775
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76948
evaluation_0/Rewards Std                      1.09302
evaluation_0/Rewards Max                      7.31372
evaluation_0/Rewards Min                     -0.822039
evaluation_0/Returns Mean                  4769.48
evaluation_0/Returns Std                     39.4693
evaluation_0/Returns Max                   4841.98
evaluation_0/Returns Min                   4714.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4769.48
time/epoch (s)                                0
time/total (s)                            10011.9
Epoch                                       661
---------------------------------------  ----------------
2022-11-16 19:01:47.757182 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 662 finished
---------------------------------------  ----------------
epoch                                       662
total_step                               667000
replay_pool/size                         667000
trainer/alpha                                 0.0600382
trainer/alpha_loss                            0.497642
trainer/entropy                              -6.17692
trainer/qf_loss                              17.2224
trainer/policy_loss                        -335.604
trainer/adversary_policy_loss                16.0564
trainer/policy_loss_without_entropy         335.975
trainer/entropy_penalty                      -0.370851
trainer/entropy_percentage                   -0.00110381
trainer/Q1Pred Mean                         335.585
trainer/Q1Pred Std                           71.1068
trainer/Q1Pred Max                          432.369
trainer/Q1Pred Min                           -6.93376
trainer/Q2Pred Mean                         335.605
trainer/Q2Pred Std                           70.3637
trainer/Q2Pred Max                          431.279
trainer/Q2Pred Min                            8.21603
trainer/QTargetWithReg Mean                 335.606
trainer/QTargetWithReg Std                   70.0627
trainer/QTargetWithReg Max                  430.295
trainer/QTargetWithReg Min                    5.6621
trainer/PolicyLossWithoutReg Mean           335.975
trainer/PolicyLossWithoutReg Std             69.7817
trainer/PolicyLossWithoutReg Max            431.416
trainer/PolicyLossWithoutReg Min              9.05372
exploration/num steps total              667000
exploration/num paths total                1445
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5637
exploration/Rewards Std                       1.03092
exploration/Rewards Max                       7.32463
exploration/Rewards Min                      -0.823921
exploration/Returns Mean                   4563.7
exploration/Returns Std                       0
exploration/Returns Max                    4563.7
exploration/Returns Min                    4563.7
exploration/Num Paths                         1
exploration/Average Returns                4563.7
evaluation_0/num steps total                  5.17603e+06
evaluation_0/num paths total               8783
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65771
evaluation_0/Rewards Std                      1.06355
evaluation_0/Rewards Max                      7.50425
evaluation_0/Rewards Min                     -0.988985
evaluation_0/Returns Mean                  4657.71
evaluation_0/Returns Std                     85.3256
evaluation_0/Returns Max                   4844.38
evaluation_0/Returns Min                   4575.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4657.71
time/epoch (s)                                0
time/total (s)                            10024.7
Epoch                                       662
---------------------------------------  ----------------
2022-11-16 19:02:00.458872 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 663 finished
---------------------------------------  ----------------
epoch                                       663
total_step                               668000
replay_pool/size                         668000
trainer/alpha                                 0.0595759
trainer/alpha_loss                            0.647663
trainer/entropy                              -6.22962
trainer/qf_loss                              16.1167
trainer/policy_loss                        -335.561
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.932
trainer/entropy_penalty                      -0.371135
trainer/entropy_percentage                   -0.00110479
trainer/Q1Pred Mean                         334.43
trainer/Q1Pred Std                           72.2961
trainer/Q1Pred Max                          419.683
trainer/Q1Pred Min                            6.18435
trainer/Q2Pred Mean                         334.336
trainer/Q2Pred Std                           72.0671
trainer/Q2Pred Max                          418.402
trainer/Q2Pred Min                            2.83693
trainer/QTargetWithReg Mean                 334.491
trainer/QTargetWithReg Std                   72.3045
trainer/QTargetWithReg Max                  419.795
trainer/QTargetWithReg Min                    3.45986
trainer/PolicyLossWithoutReg Mean           335.932
trainer/PolicyLossWithoutReg Std             70.9471
trainer/PolicyLossWithoutReg Max            419.35
trainer/PolicyLossWithoutReg Min              2.95358
exploration/num steps total              668000
exploration/num paths total                1446
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79487
exploration/Rewards Std                       1.01681
exploration/Rewards Max                       7.66348
exploration/Rewards Min                      -1.12755
exploration/Returns Mean                   4794.87
exploration/Returns Std                       0
exploration/Returns Max                    4794.87
exploration/Returns Min                    4794.87
exploration/Num Paths                         1
exploration/Average Returns                4794.87
evaluation_0/num steps total                  5.18403e+06
evaluation_0/num paths total               8791
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88193
evaluation_0/Rewards Std                      1.07029
evaluation_0/Rewards Max                      7.78043
evaluation_0/Rewards Min                     -0.915549
evaluation_0/Returns Mean                  4881.93
evaluation_0/Returns Std                    125.039
evaluation_0/Returns Max                   5023.66
evaluation_0/Returns Min                   4674.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4881.93
time/epoch (s)                                0
time/total (s)                            10037.4
Epoch                                       663
---------------------------------------  ----------------
2022-11-16 19:02:14.257633 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 664 finished
---------------------------------------  ----------------
epoch                                       664
total_step                               669000
replay_pool/size                         669000
trainer/alpha                                 0.0600768
trainer/alpha_loss                           -0.183093
trainer/entropy                              -5.93489
trainer/qf_loss                              21.4875
trainer/policy_loss                        -332.084
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         332.441
trainer/entropy_penalty                      -0.356549
trainer/entropy_percentage                   -0.00107252
trainer/Q1Pred Mean                         331.487
trainer/Q1Pred Std                           67.7016
trainer/Q1Pred Max                          413.868
trainer/Q1Pred Min                           -3.33239
trainer/Q2Pred Mean                         331.771
trainer/Q2Pred Std                           66.9924
trainer/Q2Pred Max                          416.02
trainer/Q2Pred Min                           10.7511
trainer/QTargetWithReg Mean                 332.271
trainer/QTargetWithReg Std                   67.3521
trainer/QTargetWithReg Max                  415.32
trainer/QTargetWithReg Min                    2.27672
trainer/PolicyLossWithoutReg Mean           332.441
trainer/PolicyLossWithoutReg Std             66.4961
trainer/PolicyLossWithoutReg Max            416.007
trainer/PolicyLossWithoutReg Min              3.95523
exploration/num steps total              669000
exploration/num paths total                1447
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7783
exploration/Rewards Std                       1.11552
exploration/Rewards Max                       7.31013
exploration/Rewards Min                      -0.913451
exploration/Returns Mean                   4778.3
exploration/Returns Std                       0
exploration/Returns Max                    4778.3
exploration/Returns Min                    4778.3
exploration/Num Paths                         1
exploration/Average Returns                4778.3
evaluation_0/num steps total                  5.19203e+06
evaluation_0/num paths total               8799
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74441
evaluation_0/Rewards Std                      0.997446
evaluation_0/Rewards Max                      6.99246
evaluation_0/Rewards Min                     -0.975798
evaluation_0/Returns Mean                  4744.41
evaluation_0/Returns Std                    138.577
evaluation_0/Returns Max                   4963.22
evaluation_0/Returns Min                   4532.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4744.41
time/epoch (s)                                0
time/total (s)                            10051.2
Epoch                                       664
---------------------------------------  ----------------
2022-11-16 19:02:29.143184 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 665 finished
---------------------------------------  ----------------
epoch                                       665
total_step                               670000
replay_pool/size                         670000
trainer/alpha                                 0.0612091
trainer/alpha_loss                            1.5526
trainer/entropy                              -6.55576
trainer/qf_loss                              15.8951
trainer/policy_loss                        -328.545
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         328.946
trainer/entropy_penalty                      -0.401272
trainer/entropy_percentage                   -0.00121987
trainer/Q1Pred Mean                         328.232
trainer/Q1Pred Std                           68.6209
trainer/Q1Pred Max                          414.75
trainer/Q1Pred Min                          -20.7503
trainer/Q2Pred Mean                         328.309
trainer/Q2Pred Std                           68.0842
trainer/Q2Pred Max                          413.845
trainer/Q2Pred Min                          -14.9606
trainer/QTargetWithReg Mean                 328.293
trainer/QTargetWithReg Std                   68.6831
trainer/QTargetWithReg Max                  416.258
trainer/QTargetWithReg Min                  -18.3942
trainer/PolicyLossWithoutReg Mean           328.946
trainer/PolicyLossWithoutReg Std             67.0243
trainer/PolicyLossWithoutReg Max            413.477
trainer/PolicyLossWithoutReg Min             -4.93005
exploration/num steps total              670000
exploration/num paths total                1448
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75302
exploration/Rewards Std                       1.02642
exploration/Rewards Max                       7.1811
exploration/Rewards Min                      -0.820313
exploration/Returns Mean                   4753.02
exploration/Returns Std                       0
exploration/Returns Max                    4753.02
exploration/Returns Min                    4753.02
exploration/Num Paths                         1
exploration/Average Returns                4753.02
evaluation_0/num steps total                  5.19911e+06
evaluation_0/num paths total               8807
evaluation_0/path length Mean               885.375
evaluation_0/path length Std                303.269
evaluation_0/path length Max               1000
evaluation_0/path length Min                 83
evaluation_0/Rewards Mean                     4.96008
evaluation_0/Rewards Std                      1.0801
evaluation_0/Rewards Max                      7.8642
evaluation_0/Rewards Min                     -0.963582
evaluation_0/Returns Mean                  4391.53
evaluation_0/Returns Std                   1568.96
evaluation_0/Returns Max                   5080.65
evaluation_0/Returns Min                    243.268
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4391.53
time/epoch (s)                                0
time/total (s)                            10066.1
Epoch                                       665
---------------------------------------  ----------------
2022-11-16 19:02:42.161580 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 666 finished
---------------------------------------  ----------------
epoch                                       666
total_step                               671000
replay_pool/size                         671000
trainer/alpha                                 0.0606806
trainer/alpha_loss                            0.167376
trainer/entropy                              -6.05973
trainer/qf_loss                              27.9346
trainer/policy_loss                        -334.976
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.343
trainer/entropy_penalty                      -0.367708
trainer/entropy_percentage                   -0.00109651
trainer/Q1Pred Mean                         334.141
trainer/Q1Pred Std                           69.1063
trainer/Q1Pred Max                          428.953
trainer/Q1Pred Min                           19.7274
trainer/Q2Pred Mean                         334.482
trainer/Q2Pred Std                           68.968
trainer/Q2Pred Max                          429.381
trainer/Q2Pred Min                           24.8716
trainer/QTargetWithReg Mean                 334.506
trainer/QTargetWithReg Std                   69.5075
trainer/QTargetWithReg Max                  429.538
trainer/QTargetWithReg Min                   22.1033
trainer/PolicyLossWithoutReg Mean           335.343
trainer/PolicyLossWithoutReg Std             67.8431
trainer/PolicyLossWithoutReg Max            429
trainer/PolicyLossWithoutReg Min             30.771
exploration/num steps total              671000
exploration/num paths total                1449
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67893
exploration/Rewards Std                       1.14629
exploration/Rewards Max                       7.11105
exploration/Rewards Min                      -0.836902
exploration/Returns Mean                   4678.93
exploration/Returns Std                       0
exploration/Returns Max                    4678.93
exploration/Returns Min                    4678.93
exploration/Num Paths                         1
exploration/Average Returns                4678.93
evaluation_0/num steps total                  5.20711e+06
evaluation_0/num paths total               8815
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73988
evaluation_0/Rewards Std                      1.06606
evaluation_0/Rewards Max                      7.57264
evaluation_0/Rewards Min                     -0.612843
evaluation_0/Returns Mean                  4739.88
evaluation_0/Returns Std                    147
evaluation_0/Returns Max                   4994.43
evaluation_0/Returns Min                   4522.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4739.88
time/epoch (s)                                0
time/total (s)                            10079.1
Epoch                                       666
---------------------------------------  ----------------
2022-11-16 19:02:55.104433 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 667 finished
---------------------------------------  ----------------
epoch                                       667
total_step                               672000
replay_pool/size                         672000
trainer/alpha                                 0.0604953
trainer/alpha_loss                           -2.18051
trainer/entropy                              -5.22266
trainer/qf_loss                              10.7469
trainer/policy_loss                        -348.366
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.682
trainer/entropy_penalty                      -0.315946
trainer/entropy_percentage                   -0.000906117
trainer/Q1Pred Mean                         347.688
trainer/Q1Pred Std                           52.2779
trainer/Q1Pred Max                          425.127
trainer/Q1Pred Min                           58.4415
trainer/Q2Pred Mean                         348.132
trainer/Q2Pred Std                           52.0745
trainer/Q2Pred Max                          424.032
trainer/Q2Pred Min                           55.659
trainer/QTargetWithReg Mean                 347.756
trainer/QTargetWithReg Std                   52.1078
trainer/QTargetWithReg Max                  423.393
trainer/QTargetWithReg Min                   59.496
trainer/PolicyLossWithoutReg Mean           348.682
trainer/PolicyLossWithoutReg Std             51.436
trainer/PolicyLossWithoutReg Max            425.077
trainer/PolicyLossWithoutReg Min             65.3091
exploration/num steps total              672000
exploration/num paths total                1450
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55273
exploration/Rewards Std                       1.04907
exploration/Rewards Max                       7.01726
exploration/Rewards Min                      -0.707586
exploration/Returns Mean                   4552.73
exploration/Returns Std                       0
exploration/Returns Max                    4552.73
exploration/Returns Min                    4552.73
exploration/Num Paths                         1
exploration/Average Returns                4552.73
evaluation_0/num steps total                  5.21511e+06
evaluation_0/num paths total               8823
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88149
evaluation_0/Rewards Std                      1.16319
evaluation_0/Rewards Max                      7.73381
evaluation_0/Rewards Min                     -0.889745
evaluation_0/Returns Mean                  4881.49
evaluation_0/Returns Std                     85.0063
evaluation_0/Returns Max                   4964.95
evaluation_0/Returns Min                   4719.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4881.49
time/epoch (s)                                0
time/total (s)                            10092.1
Epoch                                       667
---------------------------------------  ----------------
2022-11-16 19:03:08.437827 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 668 finished
---------------------------------------  ----------------
epoch                                       668
total_step                               673000
replay_pool/size                         673000
trainer/alpha                                 0.0607431
trainer/alpha_loss                            0.657102
trainer/entropy                              -6.2346
trainer/qf_loss                              30.972
trainer/policy_loss                        -329.082
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.461
trainer/entropy_penalty                      -0.378709
trainer/entropy_percentage                   -0.00114948
trainer/Q1Pred Mean                         328.597
trainer/Q1Pred Std                           77.0726
trainer/Q1Pred Max                          425.087
trainer/Q1Pred Min                           22.2308
trainer/Q2Pred Mean                         328.407
trainer/Q2Pred Std                           77.4969
trainer/Q2Pred Max                          425.64
trainer/Q2Pred Min                            9.84698
trainer/QTargetWithReg Mean                 329.113
trainer/QTargetWithReg Std                   77.4746
trainer/QTargetWithReg Max                  426.488
trainer/QTargetWithReg Min                   13.4874
trainer/PolicyLossWithoutReg Mean           329.461
trainer/PolicyLossWithoutReg Std             76.4387
trainer/PolicyLossWithoutReg Max            426.048
trainer/PolicyLossWithoutReg Min             12.5794
exploration/num steps total              673000
exploration/num paths total                1451
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58667
exploration/Rewards Std                       0.955248
exploration/Rewards Max                       6.93569
exploration/Rewards Min                      -0.814491
exploration/Returns Mean                   4586.67
exploration/Returns Std                       0
exploration/Returns Max                    4586.67
exploration/Returns Min                    4586.67
exploration/Num Paths                         1
exploration/Average Returns                4586.67
evaluation_0/num steps total                  5.22311e+06
evaluation_0/num paths total               8831
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93719
evaluation_0/Rewards Std                      1.18998
evaluation_0/Rewards Max                      7.62027
evaluation_0/Rewards Min                     -0.966913
evaluation_0/Returns Mean                  4937.19
evaluation_0/Returns Std                     93.2439
evaluation_0/Returns Max                   5100.47
evaluation_0/Returns Min                   4823.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4937.19
time/epoch (s)                                0
time/total (s)                            10105.4
Epoch                                       668
---------------------------------------  ----------------
2022-11-16 19:03:21.331283 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 669 finished
---------------------------------------  ----------------
epoch                                       669
total_step                               674000
replay_pool/size                         674000
trainer/alpha                                 0.0604534
trainer/alpha_loss                            1.27115
trainer/entropy                              -6.45303
trainer/qf_loss                              26.407
trainer/policy_loss                        -334.118
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.508
trainer/entropy_penalty                      -0.390108
trainer/entropy_percentage                   -0.00116621
trainer/Q1Pred Mean                         333.713
trainer/Q1Pred Std                           66.8314
trainer/Q1Pred Max                          424.481
trainer/Q1Pred Min                          -35.4626
trainer/Q2Pred Mean                         333.214
trainer/Q2Pred Std                           67.1431
trainer/Q2Pred Max                          425.918
trainer/Q2Pred Min                          -21.1988
trainer/QTargetWithReg Mean                 333.998
trainer/QTargetWithReg Std                   66.5825
trainer/QTargetWithReg Max                  426.324
trainer/QTargetWithReg Min                    3.48663
trainer/PolicyLossWithoutReg Mean           334.508
trainer/PolicyLossWithoutReg Std             65.4886
trainer/PolicyLossWithoutReg Max            424.766
trainer/PolicyLossWithoutReg Min            -33.0541
exploration/num steps total              674000
exploration/num paths total                1452
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.20009
exploration/Rewards Std                       1.05049
exploration/Rewards Max                       7.26391
exploration/Rewards Min                      -0.847316
exploration/Returns Mean                   4200.09
exploration/Returns Std                       0
exploration/Returns Max                    4200.09
exploration/Returns Min                    4200.09
exploration/Num Paths                         1
exploration/Average Returns                4200.09
evaluation_0/num steps total                  5.23111e+06
evaluation_0/num paths total               8839
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66239
evaluation_0/Rewards Std                      1.05804
evaluation_0/Rewards Max                      7.42514
evaluation_0/Rewards Min                     -1.04273
evaluation_0/Returns Mean                  4662.39
evaluation_0/Returns Std                    108.271
evaluation_0/Returns Max                   4843.49
evaluation_0/Returns Min                   4456.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4662.39
time/epoch (s)                                0
time/total (s)                            10118.3
Epoch                                       669
---------------------------------------  ----------------
2022-11-16 19:03:34.651297 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 670 finished
---------------------------------------  ----------------
epoch                                       670
total_step                               675000
replay_pool/size                         675000
trainer/alpha                                 0.0595445
trainer/alpha_loss                            0.798751
trainer/entropy                              -6.28314
trainer/qf_loss                              28.2457
trainer/policy_loss                        -326.104
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         326.478
trainer/entropy_penalty                      -0.374126
trainer/entropy_percentage                   -0.00114595
trainer/Q1Pred Mean                         325.883
trainer/Q1Pred Std                           80.2858
trainer/Q1Pred Max                          420.295
trainer/Q1Pred Min                          -48.4347
trainer/Q2Pred Mean                         325.091
trainer/Q2Pred Std                           80.1658
trainer/Q2Pred Max                          420.151
trainer/Q2Pred Min                          -12.358
trainer/QTargetWithReg Mean                 325.685
trainer/QTargetWithReg Std                   79.7993
trainer/QTargetWithReg Max                  419.567
trainer/QTargetWithReg Min                    0.931507
trainer/PolicyLossWithoutReg Mean           326.478
trainer/PolicyLossWithoutReg Std             79.7653
trainer/PolicyLossWithoutReg Max            419.741
trainer/PolicyLossWithoutReg Min            -47.8927
exploration/num steps total              675000
exploration/num paths total                1454
exploration/path length this epoch Mean     485
exploration/path length this epoch Std      406
exploration/path length this epoch Max      891
exploration/path length this epoch Min       79
exploration/Rewards Mean                      4.5986
exploration/Rewards Std                       1.3105
exploration/Rewards Max                       7.49098
exploration/Rewards Min                      -0.85748
exploration/Returns Mean                   2230.32
exploration/Returns Std                    2052.09
exploration/Returns Max                    4282.41
exploration/Returns Min                     178.225
exploration/Num Paths                         2
exploration/Average Returns                2230.32
evaluation_0/num steps total                  5.23911e+06
evaluation_0/num paths total               8847
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85681
evaluation_0/Rewards Std                      1.03625
evaluation_0/Rewards Max                      7.76767
evaluation_0/Rewards Min                     -0.759884
evaluation_0/Returns Mean                  4856.81
evaluation_0/Returns Std                     64.7865
evaluation_0/Returns Max                   4952.82
evaluation_0/Returns Min                   4714.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4856.81
time/epoch (s)                                0
time/total (s)                            10131.6
Epoch                                       670
---------------------------------------  ----------------
2022-11-16 19:03:47.319373 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 671 finished
---------------------------------------  ----------------
epoch                                       671
total_step                               676000
replay_pool/size                         676000
trainer/alpha                                 0.0609706
trainer/alpha_loss                           -0.48429
trainer/entropy                              -5.82688
trainer/qf_loss                              23.1751
trainer/policy_loss                        -337.959
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.314
trainer/entropy_penalty                      -0.355268
trainer/entropy_percentage                   -0.00105011
trainer/Q1Pred Mean                         337.371
trainer/Q1Pred Std                           65.2215
trainer/Q1Pred Max                          425.194
trainer/Q1Pred Min                          -12.5705
trainer/Q2Pred Mean                         337.384
trainer/Q2Pred Std                           65.7426
trainer/Q2Pred Max                          426.313
trainer/Q2Pred Min                          -17.6177
trainer/QTargetWithReg Mean                 337.356
trainer/QTargetWithReg Std                   65.3901
trainer/QTargetWithReg Max                  426.095
trainer/QTargetWithReg Min                  -18.5189
trainer/PolicyLossWithoutReg Mean           338.314
trainer/PolicyLossWithoutReg Std             64.7154
trainer/PolicyLossWithoutReg Max            425.696
trainer/PolicyLossWithoutReg Min             -8.38296
exploration/num steps total              676000
exploration/num paths total                1455
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75525
exploration/Rewards Std                       0.995506
exploration/Rewards Max                       7.2892
exploration/Rewards Min                      -0.749086
exploration/Returns Mean                   4755.25
exploration/Returns Std                       0
exploration/Returns Max                    4755.25
exploration/Returns Min                    4755.25
exploration/Num Paths                         1
exploration/Average Returns                4755.25
evaluation_0/num steps total                  5.24711e+06
evaluation_0/num paths total               8855
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75477
evaluation_0/Rewards Std                      1.02931
evaluation_0/Rewards Max                      7.71563
evaluation_0/Rewards Min                     -0.506302
evaluation_0/Returns Mean                  4754.77
evaluation_0/Returns Std                     83.5826
evaluation_0/Returns Max                   4921.6
evaluation_0/Returns Min                   4659.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4754.77
time/epoch (s)                                0
time/total (s)                            10144.3
Epoch                                       671
---------------------------------------  ----------------
2022-11-16 19:04:01.404759 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 672 finished
---------------------------------------  ----------------
epoch                                       672
total_step                               677000
replay_pool/size                         677000
trainer/alpha                                 0.0599154
trainer/alpha_loss                            0.550974
trainer/entropy                              -6.19574
trainer/qf_loss                              25.0272
trainer/policy_loss                        -334.403
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.774
trainer/entropy_penalty                      -0.37122
trainer/entropy_percentage                   -0.00110887
trainer/Q1Pred Mean                         333.028
trainer/Q1Pred Std                           72.7843
trainer/Q1Pred Max                          433.693
trainer/Q1Pred Min                           -2.1129
trainer/Q2Pred Mean                         333.236
trainer/Q2Pred Std                           73.0657
trainer/Q2Pred Max                          434.392
trainer/Q2Pred Min                          -18.7334
trainer/QTargetWithReg Mean                 333.429
trainer/QTargetWithReg Std                   72.6851
trainer/QTargetWithReg Max                  432.496
trainer/QTargetWithReg Min                    0.459939
trainer/PolicyLossWithoutReg Mean           334.774
trainer/PolicyLossWithoutReg Std             71.0148
trainer/PolicyLossWithoutReg Max            433.826
trainer/PolicyLossWithoutReg Min             -9.33398
exploration/num steps total              677000
exploration/num paths total                1456
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43699
exploration/Rewards Std                       1.07691
exploration/Rewards Max                       7.2728
exploration/Rewards Min                      -0.841732
exploration/Returns Mean                   4436.99
exploration/Returns Std                       0
exploration/Returns Max                    4436.99
exploration/Returns Min                    4436.99
exploration/Num Paths                         1
exploration/Average Returns                4436.99
evaluation_0/num steps total                  5.25511e+06
evaluation_0/num paths total               8863
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.52338
evaluation_0/Rewards Std                      1.30385
evaluation_0/Rewards Max                      7.54356
evaluation_0/Rewards Min                     -0.931239
evaluation_0/Returns Mean                  4523.38
evaluation_0/Returns Std                    104.784
evaluation_0/Returns Max                   4739.67
evaluation_0/Returns Min                   4402.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4523.38
time/epoch (s)                                0
time/total (s)                            10158.4
Epoch                                       672
---------------------------------------  ----------------
2022-11-16 19:04:13.234821 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 673 finished
---------------------------------------  ----------------
epoch                                       673
total_step                               678000
replay_pool/size                         678000
trainer/alpha                                 0.0615507
trainer/alpha_loss                           -0.597344
trainer/entropy                              -5.78572
trainer/qf_loss                              23.4825
trainer/policy_loss                        -331.15
trainer/adversary_policy_loss                15.9324
trainer/policy_loss_without_entropy         331.507
trainer/entropy_penalty                      -0.356115
trainer/entropy_percentage                   -0.00107423
trainer/Q1Pred Mean                         331.506
trainer/Q1Pred Std                           76.3212
trainer/Q1Pred Max                          425.669
trainer/Q1Pred Min                           24.2088
trainer/Q2Pred Mean                         331.087
trainer/Q2Pred Std                           75.6085
trainer/Q2Pred Max                          427.908
trainer/Q2Pred Min                           26.1013
trainer/QTargetWithReg Mean                 331.515
trainer/QTargetWithReg Std                   76.205
trainer/QTargetWithReg Max                  423.648
trainer/QTargetWithReg Min                   22.7484
trainer/PolicyLossWithoutReg Mean           331.507
trainer/PolicyLossWithoutReg Std             74.9934
trainer/PolicyLossWithoutReg Max            425.238
trainer/PolicyLossWithoutReg Min             28.459
exploration/num steps total              678000
exploration/num paths total                1457
exploration/path length this epoch Mean     595
exploration/path length this epoch Std        0
exploration/path length this epoch Max      595
exploration/path length this epoch Min      595
exploration/Rewards Mean                      3.93095
exploration/Rewards Std                       1.3339
exploration/Rewards Max                       6.61194
exploration/Rewards Min                      -0.817156
exploration/Returns Mean                   2338.92
exploration/Returns Std                       0
exploration/Returns Max                    2338.92
exploration/Returns Min                    2338.92
exploration/Num Paths                         1
exploration/Average Returns                2338.92
evaluation_0/num steps total                  5.26311e+06
evaluation_0/num paths total               8871
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8217
evaluation_0/Rewards Std                      1.03081
evaluation_0/Rewards Max                      7.6425
evaluation_0/Rewards Min                     -0.70883
evaluation_0/Returns Mean                  4821.7
evaluation_0/Returns Std                     51.6374
evaluation_0/Returns Max                   4915.15
evaluation_0/Returns Min                   4769.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4821.7
time/epoch (s)                                0
time/total (s)                            10170.2
Epoch                                       673
---------------------------------------  ----------------
2022-11-16 19:04:25.286769 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 674 finished
---------------------------------------  ----------------
epoch                                       674
total_step                               679000
replay_pool/size                         679000
trainer/alpha                                 0.0601716
trainer/alpha_loss                           -0.124596
trainer/entropy                              -5.95567
trainer/qf_loss                              25.8525
trainer/policy_loss                        -338.794
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.152
trainer/entropy_penalty                      -0.358362
trainer/entropy_percentage                   -0.00105664
trainer/Q1Pred Mean                         337.679
trainer/Q1Pred Std                           69.7777
trainer/Q1Pred Max                          420.134
trainer/Q1Pred Min                           16.8252
trainer/Q2Pred Mean                         337.558
trainer/Q2Pred Std                           69.9718
trainer/Q2Pred Max                          421.508
trainer/Q2Pred Min                           11.8696
trainer/QTargetWithReg Mean                 336.758
trainer/QTargetWithReg Std                   70.6202
trainer/QTargetWithReg Max                  418.863
trainer/QTargetWithReg Min                   17.7701
trainer/PolicyLossWithoutReg Mean           339.152
trainer/PolicyLossWithoutReg Std             68.1195
trainer/PolicyLossWithoutReg Max            419.782
trainer/PolicyLossWithoutReg Min             18.9155
exploration/num steps total              679000
exploration/num paths total                1458
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37059
exploration/Rewards Std                       0.963103
exploration/Rewards Max                       6.76268
exploration/Rewards Min                      -0.645252
exploration/Returns Mean                   4370.59
exploration/Returns Std                       0
exploration/Returns Max                    4370.59
exploration/Returns Min                    4370.59
exploration/Num Paths                         1
exploration/Average Returns                4370.59
evaluation_0/num steps total                  5.27111e+06
evaluation_0/num paths total               8879
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86907
evaluation_0/Rewards Std                      1.09231
evaluation_0/Rewards Max                      7.46338
evaluation_0/Rewards Min                     -0.926202
evaluation_0/Returns Mean                  4869.07
evaluation_0/Returns Std                     80.4868
evaluation_0/Returns Max                   4988.03
evaluation_0/Returns Min                   4732.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4869.07
time/epoch (s)                                0
time/total (s)                            10182.2
Epoch                                       674
---------------------------------------  ----------------
2022-11-16 19:04:39.093922 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 675 finished
---------------------------------------  ----------------
epoch                                       675
total_step                               680000
replay_pool/size                         680000
trainer/alpha                                 0.0599042
trainer/alpha_loss                           -0.996515
trainer/entropy                              -5.64598
trainer/qf_loss                              18.6137
trainer/policy_loss                        -341.572
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.91
trainer/entropy_penalty                      -0.338218
trainer/entropy_percentage                   -0.000989202
trainer/Q1Pred Mean                         340.402
trainer/Q1Pred Std                           70.145
trainer/Q1Pred Max                          423.977
trainer/Q1Pred Min                            9.93125
trainer/Q2Pred Mean                         341.238
trainer/Q2Pred Std                           70.834
trainer/Q2Pred Max                          424.854
trainer/Q2Pred Min                            6.71222
trainer/QTargetWithReg Mean                 340.925
trainer/QTargetWithReg Std                   71.19
trainer/QTargetWithReg Max                  424.22
trainer/QTargetWithReg Min                    8.62199
trainer/PolicyLossWithoutReg Mean           341.91
trainer/PolicyLossWithoutReg Std             69.607
trainer/PolicyLossWithoutReg Max            425.423
trainer/PolicyLossWithoutReg Min             13.4481
exploration/num steps total              680000
exploration/num paths total                1459
exploration/path length this epoch Mean     393
exploration/path length this epoch Std        0
exploration/path length this epoch Max      393
exploration/path length this epoch Min      393
exploration/Rewards Mean                      3.56018
exploration/Rewards Std                       1.25645
exploration/Rewards Max                       6.48857
exploration/Rewards Min                      -0.900234
exploration/Returns Mean                   1399.15
exploration/Returns Std                       0
exploration/Returns Max                    1399.15
exploration/Returns Min                    1399.15
exploration/Num Paths                         1
exploration/Average Returns                1399.15
evaluation_0/num steps total                  5.27911e+06
evaluation_0/num paths total               8887
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82321
evaluation_0/Rewards Std                      1.00309
evaluation_0/Rewards Max                      7.77855
evaluation_0/Rewards Min                     -0.656062
evaluation_0/Returns Mean                  4823.21
evaluation_0/Returns Std                    114.794
evaluation_0/Returns Max                   4987.82
evaluation_0/Returns Min                   4616.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4823.21
time/epoch (s)                                0
time/total (s)                            10196
Epoch                                       675
---------------------------------------  ----------------
2022-11-16 19:04:50.366063 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 676 finished
---------------------------------------  ----------------
epoch                                       676
total_step                               681000
replay_pool/size                         681000
trainer/alpha                                 0.0621142
trainer/alpha_loss                           -0.562226
trainer/entropy                              -5.79768
trainer/qf_loss                              18.4196
trainer/policy_loss                        -340.078
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.438
trainer/entropy_penalty                      -0.360118
trainer/entropy_percentage                   -0.00105781
trainer/Q1Pred Mean                         340.217
trainer/Q1Pred Std                           63.4841
trainer/Q1Pred Max                          425.507
trainer/Q1Pred Min                            5.27031
trainer/Q2Pred Mean                         339.977
trainer/Q2Pred Std                           63.0122
trainer/Q2Pred Max                          428.498
trainer/Q2Pred Min                            6.66093
trainer/QTargetWithReg Mean                 339.542
trainer/QTargetWithReg Std                   63.4539
trainer/QTargetWithReg Max                  424.77
trainer/QTargetWithReg Min                   10.4447
trainer/PolicyLossWithoutReg Mean           340.438
trainer/PolicyLossWithoutReg Std             62.3589
trainer/PolicyLossWithoutReg Max            425.577
trainer/PolicyLossWithoutReg Min              9.43998
exploration/num steps total              681000
exploration/num paths total                1461
exploration/path length this epoch Mean     219.5
exploration/path length this epoch Std      143.5
exploration/path length this epoch Max      363
exploration/path length this epoch Min       76
exploration/Rewards Mean                      3.60356
exploration/Rewards Std                       1.38426
exploration/Rewards Max                       6.06955
exploration/Rewards Min                      -1.12519
exploration/Returns Mean                    790.981
exploration/Returns Std                     622.497
exploration/Returns Max                    1413.48
exploration/Returns Min                     168.484
exploration/Num Paths                         2
exploration/Average Returns                 790.981
evaluation_0/num steps total                  5.28711e+06
evaluation_0/num paths total               8895
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74216
evaluation_0/Rewards Std                      1.07268
evaluation_0/Rewards Max                      7.42625
evaluation_0/Rewards Min                     -0.924821
evaluation_0/Returns Mean                  4742.16
evaluation_0/Returns Std                     57.2972
evaluation_0/Returns Max                   4812.18
evaluation_0/Returns Min                   4653.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4742.16
time/epoch (s)                                0
time/total (s)                            10207.3
Epoch                                       676
---------------------------------------  ----------------
2022-11-16 19:05:01.489332 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 677 finished
---------------------------------------  ----------------
epoch                                       677
total_step                               682000
replay_pool/size                         682000
trainer/alpha                                 0.0622223
trainer/alpha_loss                            1.23886
trainer/entropy                              -6.44613
trainer/qf_loss                              24.2778
trainer/policy_loss                        -329.596
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         329.997
trainer/entropy_penalty                      -0.401093
trainer/entropy_percentage                   -0.00121544
trainer/Q1Pred Mean                         329.167
trainer/Q1Pred Std                           69.4695
trainer/Q1Pred Max                          413.953
trainer/Q1Pred Min                           28.3035
trainer/Q2Pred Mean                         328.97
trainer/Q2Pred Std                           69.5831
trainer/Q2Pred Max                          413.694
trainer/Q2Pred Min                           22.7262
trainer/QTargetWithReg Mean                 328.53
trainer/QTargetWithReg Std                   70.5441
trainer/QTargetWithReg Max                  415.85
trainer/QTargetWithReg Min                    0.524695
trainer/PolicyLossWithoutReg Mean           329.997
trainer/PolicyLossWithoutReg Std             67.1057
trainer/PolicyLossWithoutReg Max            413.356
trainer/PolicyLossWithoutReg Min             31.4276
exploration/num steps total              682000
exploration/num paths total                1462
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61081
exploration/Rewards Std                       1.03086
exploration/Rewards Max                       6.83761
exploration/Rewards Min                      -1.03619
exploration/Returns Mean                   4610.81
exploration/Returns Std                       0
exploration/Returns Max                    4610.81
exploration/Returns Min                    4610.81
exploration/Num Paths                         1
exploration/Average Returns                4610.81
evaluation_0/num steps total                  5.29511e+06
evaluation_0/num paths total               8903
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75292
evaluation_0/Rewards Std                      1.07002
evaluation_0/Rewards Max                      7.81892
evaluation_0/Rewards Min                     -0.986958
evaluation_0/Returns Mean                  4752.92
evaluation_0/Returns Std                     99.9651
evaluation_0/Returns Max                   4899.67
evaluation_0/Returns Min                   4626.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4752.92
time/epoch (s)                                0
time/total (s)                            10218.4
Epoch                                       677
---------------------------------------  ----------------
2022-11-16 19:05:13.816544 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 678 finished
---------------------------------------  ----------------
epoch                                       678
total_step                               683000
replay_pool/size                         683000
trainer/alpha                                 0.0608679
trainer/alpha_loss                            0.306062
trainer/entropy                              -6.10934
trainer/qf_loss                              52.7215
trainer/policy_loss                        -340.683
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.055
trainer/entropy_penalty                      -0.371863
trainer/entropy_percentage                   -0.00109033
trainer/Q1Pred Mean                         339.984
trainer/Q1Pred Std                           64.3189
trainer/Q1Pred Max                          419.839
trainer/Q1Pred Min                           -0.935756
trainer/Q2Pred Mean                         340.419
trainer/Q2Pred Std                           64.3169
trainer/Q2Pred Max                          417.084
trainer/Q2Pred Min                           -0.47882
trainer/QTargetWithReg Mean                 340.807
trainer/QTargetWithReg Std                   63.6118
trainer/QTargetWithReg Max                  419.59
trainer/QTargetWithReg Min                    2.85014
trainer/PolicyLossWithoutReg Mean           341.055
trainer/PolicyLossWithoutReg Std             63.3429
trainer/PolicyLossWithoutReg Max            418.675
trainer/PolicyLossWithoutReg Min              5.50585
exploration/num steps total              683000
exploration/num paths total                1463
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65919
exploration/Rewards Std                       1.24407
exploration/Rewards Max                       7.06803
exploration/Rewards Min                      -1.01993
exploration/Returns Mean                   4659.19
exploration/Returns Std                       0
exploration/Returns Max                    4659.19
exploration/Returns Min                    4659.19
exploration/Num Paths                         1
exploration/Average Returns                4659.19
evaluation_0/num steps total                  5.30311e+06
evaluation_0/num paths total               8911
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72731
evaluation_0/Rewards Std                      0.992936
evaluation_0/Rewards Max                      7.39747
evaluation_0/Rewards Min                     -0.784202
evaluation_0/Returns Mean                  4727.31
evaluation_0/Returns Std                     18.1365
evaluation_0/Returns Max                   4760.61
evaluation_0/Returns Min                   4699.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4727.31
time/epoch (s)                                0
time/total (s)                            10230.8
Epoch                                       678
---------------------------------------  ----------------
2022-11-16 19:05:26.930669 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 679 finished
---------------------------------------  ----------------
epoch                                       679
total_step                               684000
replay_pool/size                         684000
trainer/alpha                                 0.0610983
trainer/alpha_loss                           -0.162678
trainer/entropy                              -5.9418
trainer/qf_loss                              17.6532
trainer/policy_loss                        -335.009
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.372
trainer/entropy_penalty                      -0.363034
trainer/entropy_percentage                   -0.00108248
trainer/Q1Pred Mean                         334.2
trainer/Q1Pred Std                           73.7079
trainer/Q1Pred Max                          417.648
trainer/Q1Pred Min                           -5.23321
trainer/Q2Pred Mean                         334.684
trainer/Q2Pred Std                           73.6869
trainer/Q2Pred Max                          418.82
trainer/Q2Pred Min                           17.0499
trainer/QTargetWithReg Mean                 334.808
trainer/QTargetWithReg Std                   73.7953
trainer/QTargetWithReg Max                  420.155
trainer/QTargetWithReg Min                   -0.443733
trainer/PolicyLossWithoutReg Mean           335.372
trainer/PolicyLossWithoutReg Std             72.1431
trainer/PolicyLossWithoutReg Max            417.787
trainer/PolicyLossWithoutReg Min             21.446
exploration/num steps total              684000
exploration/num paths total                1464
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63043
exploration/Rewards Std                       0.929306
exploration/Rewards Max                       6.93642
exploration/Rewards Min                      -0.630017
exploration/Returns Mean                   4630.43
exploration/Returns Std                       0
exploration/Returns Max                    4630.43
exploration/Returns Min                    4630.43
exploration/Num Paths                         1
exploration/Average Returns                4630.43
evaluation_0/num steps total                  5.31027e+06
evaluation_0/num paths total               8919
evaluation_0/path length Mean               895.5
evaluation_0/path length Std                276.481
evaluation_0/path length Max               1000
evaluation_0/path length Min                164
evaluation_0/Rewards Mean                     4.69288
evaluation_0/Rewards Std                      1.16393
evaluation_0/Rewards Max                      7.66892
evaluation_0/Rewards Min                     -0.722693
evaluation_0/Returns Mean                  4202.48
evaluation_0/Returns Std                   1382.78
evaluation_0/Returns Max                   4920.71
evaluation_0/Returns Min                    553.333
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4202.48
time/epoch (s)                                0
time/total (s)                            10243.9
Epoch                                       679
---------------------------------------  ----------------
2022-11-16 19:05:38.199711 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 680 finished
---------------------------------------  ----------------
epoch                                       680
total_step                               685000
replay_pool/size                         685000
trainer/alpha                                 0.0619275
trainer/alpha_loss                           -1.43323
trainer/entropy                              -5.48476
trainer/qf_loss                              19.5805
trainer/policy_loss                        -345.787
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.127
trainer/entropy_penalty                      -0.339658
trainer/entropy_percentage                   -0.000981309
trainer/Q1Pred Mean                         344.849
trainer/Q1Pred Std                           61.9926
trainer/Q1Pred Max                          423.198
trainer/Q1Pred Min                           10.1288
trainer/Q2Pred Mean                         345.333
trainer/Q2Pred Std                           62.2028
trainer/Q2Pred Max                          422.521
trainer/Q2Pred Min                           14.1613
trainer/QTargetWithReg Mean                 344.864
trainer/QTargetWithReg Std                   62.377
trainer/QTargetWithReg Max                  419.189
trainer/QTargetWithReg Min                    9.11999
trainer/PolicyLossWithoutReg Mean           346.127
trainer/PolicyLossWithoutReg Std             60.7664
trainer/PolicyLossWithoutReg Max            421.687
trainer/PolicyLossWithoutReg Min             15.1201
exploration/num steps total              685000
exploration/num paths total                1465
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50633
exploration/Rewards Std                       1.08813
exploration/Rewards Max                       6.7285
exploration/Rewards Min                      -0.576722
exploration/Returns Mean                   4506.33
exploration/Returns Std                       0
exploration/Returns Max                    4506.33
exploration/Returns Min                    4506.33
exploration/Num Paths                         1
exploration/Average Returns                4506.33
evaluation_0/num steps total                  5.31827e+06
evaluation_0/num paths total               8927
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.40734
evaluation_0/Rewards Std                      1.2468
evaluation_0/Rewards Max                      7.24878
evaluation_0/Rewards Min                     -0.832416
evaluation_0/Returns Mean                  4407.34
evaluation_0/Returns Std                     94.1557
evaluation_0/Returns Max                   4523.05
evaluation_0/Returns Min                   4285.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4407.34
time/epoch (s)                                0
time/total (s)                            10255.1
Epoch                                       680
---------------------------------------  ----------------
2022-11-16 19:05:51.608750 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 681 finished
---------------------------------------  ----------------
epoch                                       681
total_step                               686000
replay_pool/size                         686000
trainer/alpha                                 0.0596494
trainer/alpha_loss                           -0.483382
trainer/entropy                              -5.82854
trainer/qf_loss                              25.6007
trainer/policy_loss                        -335.373
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.721
trainer/entropy_penalty                      -0.347669
trainer/entropy_percentage                   -0.00103559
trainer/Q1Pred Mean                         334.651
trainer/Q1Pred Std                           75.0546
trainer/Q1Pred Max                          422.262
trainer/Q1Pred Min                           -9.58498
trainer/Q2Pred Mean                         335.145
trainer/Q2Pred Std                           74.038
trainer/Q2Pred Max                          423.666
trainer/Q2Pred Min                           -1.00256
trainer/QTargetWithReg Mean                 335.479
trainer/QTargetWithReg Std                   74.5966
trainer/QTargetWithReg Max                  423.626
trainer/QTargetWithReg Min                    0.0471692
trainer/PolicyLossWithoutReg Mean           335.721
trainer/PolicyLossWithoutReg Std             73.2682
trainer/PolicyLossWithoutReg Max            422.468
trainer/PolicyLossWithoutReg Min             -0.428031
exploration/num steps total              686000
exploration/num paths total                1466
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.26944
exploration/Rewards Std                       1.3836
exploration/Rewards Max                       7.17853
exploration/Rewards Min                      -0.841836
exploration/Returns Mean                   4269.44
exploration/Returns Std                       0
exploration/Returns Max                    4269.44
exploration/Returns Min                    4269.44
exploration/Num Paths                         1
exploration/Average Returns                4269.44
evaluation_0/num steps total                  5.32627e+06
evaluation_0/num paths total               8935
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.54825
evaluation_0/Rewards Std                      1.07581
evaluation_0/Rewards Max                      7.11152
evaluation_0/Rewards Min                     -0.747564
evaluation_0/Returns Mean                  4548.25
evaluation_0/Returns Std                    138.745
evaluation_0/Returns Max                   4660.29
evaluation_0/Returns Min                   4222.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4548.25
time/epoch (s)                                0
time/total (s)                            10268.6
Epoch                                       681
---------------------------------------  ----------------
2022-11-16 19:06:05.696139 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 682 finished
---------------------------------------  ----------------
epoch                                       682
total_step                               687000
replay_pool/size                         687000
trainer/alpha                                 0.0607166
trainer/alpha_loss                            0.10791
trainer/entropy                              -6.03852
trainer/qf_loss                              29.1277
trainer/policy_loss                        -342.157
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.524
trainer/entropy_penalty                      -0.366638
trainer/entropy_percentage                   -0.0010704
trainer/Q1Pred Mean                         340.275
trainer/Q1Pred Std                           58.392
trainer/Q1Pred Max                          431.817
trainer/Q1Pred Min                           26.3319
trainer/Q2Pred Mean                         341.171
trainer/Q2Pred Std                           58.5913
trainer/Q2Pred Max                          432.152
trainer/Q2Pred Min                           37.3261
trainer/QTargetWithReg Mean                 340.876
trainer/QTargetWithReg Std                   58.5533
trainer/QTargetWithReg Max                  431.477
trainer/QTargetWithReg Min                   25.858
trainer/PolicyLossWithoutReg Mean           342.524
trainer/PolicyLossWithoutReg Std             54.8254
trainer/PolicyLossWithoutReg Max            433.04
trainer/PolicyLossWithoutReg Min             29.2976
exploration/num steps total              687000
exploration/num paths total                1467
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4568
exploration/Rewards Std                       0.970556
exploration/Rewards Max                       6.7555
exploration/Rewards Min                      -0.438021
exploration/Returns Mean                   4456.8
exploration/Returns Std                       0
exploration/Returns Max                    4456.8
exploration/Returns Min                    4456.8
exploration/Num Paths                         1
exploration/Average Returns                4456.8
evaluation_0/num steps total                  5.33427e+06
evaluation_0/num paths total               8943
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77605
evaluation_0/Rewards Std                      1.03329
evaluation_0/Rewards Max                      7.4156
evaluation_0/Rewards Min                     -0.742931
evaluation_0/Returns Mean                  4776.05
evaluation_0/Returns Std                    118.378
evaluation_0/Returns Max                   4980.65
evaluation_0/Returns Min                   4582.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4776.05
time/epoch (s)                                0
time/total (s)                            10282.6
Epoch                                       682
---------------------------------------  ----------------
2022-11-16 19:06:18.498128 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 683 finished
---------------------------------------  ----------------
epoch                                       683
total_step                               688000
replay_pool/size                         688000
trainer/alpha                                 0.0605522
trainer/alpha_loss                           -0.472243
trainer/entropy                              -5.8316
trainer/qf_loss                              20.4797
trainer/policy_loss                        -342.39
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.743
trainer/entropy_penalty                      -0.353116
trainer/entropy_percentage                   -0.00103026
trainer/Q1Pred Mean                         340.967
trainer/Q1Pred Std                           58.9821
trainer/Q1Pred Max                          428.114
trainer/Q1Pred Min                            4.51431
trainer/Q2Pred Mean                         341.039
trainer/Q2Pred Std                           59.0652
trainer/Q2Pred Max                          426.092
trainer/Q2Pred Min                            5.71049
trainer/QTargetWithReg Mean                 341.027
trainer/QTargetWithReg Std                   59.3902
trainer/QTargetWithReg Max                  428.881
trainer/QTargetWithReg Min                    1.62659
trainer/PolicyLossWithoutReg Mean           342.743
trainer/PolicyLossWithoutReg Std             58.7693
trainer/PolicyLossWithoutReg Max            429.772
trainer/PolicyLossWithoutReg Min              5.08769
exploration/num steps total              688000
exploration/num paths total                1468
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27549
exploration/Rewards Std                       1.23052
exploration/Rewards Max                       7.11077
exploration/Rewards Min                      -0.621655
exploration/Returns Mean                   4275.49
exploration/Returns Std                       0
exploration/Returns Max                    4275.49
exploration/Returns Min                    4275.49
exploration/Num Paths                         1
exploration/Average Returns                4275.49
evaluation_0/num steps total                  5.34227e+06
evaluation_0/num paths total               8951
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62676
evaluation_0/Rewards Std                      1.00994
evaluation_0/Rewards Max                      7.94612
evaluation_0/Rewards Min                     -0.527384
evaluation_0/Returns Mean                  4626.76
evaluation_0/Returns Std                     96.6211
evaluation_0/Returns Max                   4811.5
evaluation_0/Returns Min                   4488.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4626.76
time/epoch (s)                                0
time/total (s)                            10295.4
Epoch                                       683
---------------------------------------  ----------------
2022-11-16 19:06:32.344179 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 684 finished
---------------------------------------  ----------------
epoch                                       684
total_step                               689000
replay_pool/size                         689000
trainer/alpha                                 0.0600505
trainer/alpha_loss                           -0.368658
trainer/entropy                              -5.86893
trainer/qf_loss                              24.8146
trainer/policy_loss                        -338.957
trainer/adversary_policy_loss                16.2315
trainer/policy_loss_without_entropy         339.309
trainer/entropy_penalty                      -0.352432
trainer/entropy_percentage                   -0.00103867
trainer/Q1Pred Mean                         338.827
trainer/Q1Pred Std                           65.5019
trainer/Q1Pred Max                          424.449
trainer/Q1Pred Min                            5.16311
trainer/Q2Pred Mean                         338.238
trainer/Q2Pred Std                           65.7922
trainer/Q2Pred Max                          422.776
trainer/Q2Pred Min                            8.01875
trainer/QTargetWithReg Mean                 338.838
trainer/QTargetWithReg Std                   65.8671
trainer/QTargetWithReg Max                  425.214
trainer/QTargetWithReg Min                    4.29128
trainer/PolicyLossWithoutReg Mean           339.309
trainer/PolicyLossWithoutReg Std             64.8842
trainer/PolicyLossWithoutReg Max            424.162
trainer/PolicyLossWithoutReg Min             10.3331
exploration/num steps total              689000
exploration/num paths total                1469
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.32362
exploration/Rewards Std                       1.08059
exploration/Rewards Max                       6.9288
exploration/Rewards Min                      -0.629114
exploration/Returns Mean                   4323.62
exploration/Returns Std                       0
exploration/Returns Max                    4323.62
exploration/Returns Min                    4323.62
exploration/Num Paths                         1
exploration/Average Returns                4323.62
evaluation_0/num steps total                  5.35027e+06
evaluation_0/num paths total               8959
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63917
evaluation_0/Rewards Std                      1.06308
evaluation_0/Rewards Max                      7.50549
evaluation_0/Rewards Min                     -0.539633
evaluation_0/Returns Mean                  4639.17
evaluation_0/Returns Std                     67.0519
evaluation_0/Returns Max                   4781.65
evaluation_0/Returns Min                   4539.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4639.17
time/epoch (s)                                0
time/total (s)                            10309.3
Epoch                                       684
---------------------------------------  ----------------
2022-11-16 19:06:45.097228 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 685 finished
---------------------------------------  ----------------
epoch                                       685
total_step                               690000
replay_pool/size                         690000
trainer/alpha                                 0.059983
trainer/alpha_loss                           -0.306808
trainer/entropy                              -5.89096
trainer/qf_loss                              35.9627
trainer/policy_loss                        -340.661
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.015
trainer/entropy_penalty                      -0.353358
trainer/entropy_percentage                   -0.00103619
trainer/Q1Pred Mean                         339.681
trainer/Q1Pred Std                           64.4122
trainer/Q1Pred Max                          420.877
trainer/Q1Pred Min                           17.803
trainer/Q2Pred Mean                         340.023
trainer/Q2Pred Std                           64.6802
trainer/Q2Pred Max                          422.106
trainer/Q2Pred Min                           17.6637
trainer/QTargetWithReg Mean                 339.499
trainer/QTargetWithReg Std                   65.3064
trainer/QTargetWithReg Max                  420.441
trainer/QTargetWithReg Min                   13.3868
trainer/PolicyLossWithoutReg Mean           341.015
trainer/PolicyLossWithoutReg Std             63.695
trainer/PolicyLossWithoutReg Max            421.057
trainer/PolicyLossWithoutReg Min             10.8108
exploration/num steps total              690000
exploration/num paths total                1470
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6547
exploration/Rewards Std                       1.11886
exploration/Rewards Max                       6.88322
exploration/Rewards Min                      -0.54327
exploration/Returns Mean                   4654.7
exploration/Returns Std                       0
exploration/Returns Max                    4654.7
exploration/Returns Min                    4654.7
exploration/Num Paths                         1
exploration/Average Returns                4654.7
evaluation_0/num steps total                  5.35827e+06
evaluation_0/num paths total               8967
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8301
evaluation_0/Rewards Std                      1.15668
evaluation_0/Rewards Max                      7.66736
evaluation_0/Rewards Min                     -0.762413
evaluation_0/Returns Mean                  4830.1
evaluation_0/Returns Std                    173.18
evaluation_0/Returns Max                   5044.8
evaluation_0/Returns Min                   4528.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4830.1
time/epoch (s)                                0
time/total (s)                            10322
Epoch                                       685
---------------------------------------  ----------------
2022-11-16 19:06:56.849601 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 686 finished
---------------------------------------  ----------------
epoch                                       686
total_step                               691000
replay_pool/size                         691000
trainer/alpha                                 0.060288
trainer/alpha_loss                            0.0115413
trainer/entropy                              -6.00411
trainer/qf_loss                              17.4033
trainer/policy_loss                        -345.046
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.408
trainer/entropy_penalty                      -0.361976
trainer/entropy_percentage                   -0.00104797
trainer/Q1Pred Mean                         344.868
trainer/Q1Pred Std                           55.2363
trainer/Q1Pred Max                          424.55
trainer/Q1Pred Min                           41.9017
trainer/Q2Pred Mean                         345.196
trainer/Q2Pred Std                           55.6873
trainer/Q2Pred Max                          423.418
trainer/Q2Pred Min                           28.9344
trainer/QTargetWithReg Mean                 344.988
trainer/QTargetWithReg Std                   55.5712
trainer/QTargetWithReg Max                  414.429
trainer/QTargetWithReg Min                   21.7449
trainer/PolicyLossWithoutReg Mean           345.408
trainer/PolicyLossWithoutReg Std             54.1454
trainer/PolicyLossWithoutReg Max            422.923
trainer/PolicyLossWithoutReg Min             43.8775
exploration/num steps total              691000
exploration/num paths total                1471
exploration/path length this epoch Mean     574
exploration/path length this epoch Std        0
exploration/path length this epoch Max      574
exploration/path length this epoch Min      574
exploration/Rewards Mean                      4.41791
exploration/Rewards Std                       1.17992
exploration/Rewards Max                       6.98673
exploration/Rewards Min                      -0.871066
exploration/Returns Mean                   2535.88
exploration/Returns Std                       0
exploration/Returns Max                    2535.88
exploration/Returns Min                    2535.88
exploration/Num Paths                         1
exploration/Average Returns                2535.88
evaluation_0/num steps total                  5.36627e+06
evaluation_0/num paths total               8975
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67887
evaluation_0/Rewards Std                      1.05974
evaluation_0/Rewards Max                      7.37592
evaluation_0/Rewards Min                     -0.960495
evaluation_0/Returns Mean                  4678.87
evaluation_0/Returns Std                     38.1668
evaluation_0/Returns Max                   4735.16
evaluation_0/Returns Min                   4633.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4678.87
time/epoch (s)                                0
time/total (s)                            10333.8
Epoch                                       686
---------------------------------------  ----------------
2022-11-16 19:07:10.175966 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 687 finished
---------------------------------------  ----------------
epoch                                       687
total_step                               692000
replay_pool/size                         692000
trainer/alpha                                 0.0601612
trainer/alpha_loss                            1.29705
trainer/entropy                              -6.46147
trainer/qf_loss                              22.7158
trainer/policy_loss                        -344.645
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.034
trainer/entropy_penalty                      -0.388729
trainer/entropy_percentage                   -0.00112664
trainer/Q1Pred Mean                         344.446
trainer/Q1Pred Std                           62.4508
trainer/Q1Pred Max                          427.876
trainer/Q1Pred Min                          -26.705
trainer/Q2Pred Mean                         343.275
trainer/Q2Pred Std                           62.335
trainer/Q2Pred Max                          422.324
trainer/Q2Pred Min                          -16.7927
trainer/QTargetWithReg Mean                 343.42
trainer/QTargetWithReg Std                   61.5688
trainer/QTargetWithReg Max                  425.01
trainer/QTargetWithReg Min                    0.276528
trainer/PolicyLossWithoutReg Mean           345.034
trainer/PolicyLossWithoutReg Std             58.2376
trainer/PolicyLossWithoutReg Max            425.195
trainer/PolicyLossWithoutReg Min             23.0124
exploration/num steps total              692000
exploration/num paths total                1472
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.24702
exploration/Rewards Std                       0.999915
exploration/Rewards Max                       6.61253
exploration/Rewards Min                      -0.891509
exploration/Returns Mean                   4247.02
exploration/Returns Std                       0
exploration/Returns Max                    4247.02
exploration/Returns Min                    4247.02
exploration/Num Paths                         1
exploration/Average Returns                4247.02
evaluation_0/num steps total                  5.37427e+06
evaluation_0/num paths total               8983
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00778
evaluation_0/Rewards Std                      1.09507
evaluation_0/Rewards Max                      7.55663
evaluation_0/Rewards Min                     -0.642388
evaluation_0/Returns Mean                  5007.78
evaluation_0/Returns Std                    126.425
evaluation_0/Returns Max                   5199.74
evaluation_0/Returns Min                   4801.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5007.78
time/epoch (s)                                0
time/total (s)                            10347.1
Epoch                                       687
---------------------------------------  ----------------
2022-11-16 19:07:21.701391 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 688 finished
---------------------------------------  ----------------
epoch                                       688
total_step                               693000
replay_pool/size                         693000
trainer/alpha                                 0.0592082
trainer/alpha_loss                            0.259629
trainer/entropy                              -6.09185
trainer/qf_loss                              27.0654
trainer/policy_loss                        -335.379
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.739
trainer/entropy_penalty                      -0.360687
trainer/entropy_percentage                   -0.00107431
trainer/Q1Pred Mean                         334.405
trainer/Q1Pred Std                           68.1744
trainer/Q1Pred Max                          423.781
trainer/Q1Pred Min                            6.48524
trainer/Q2Pred Mean                         333.995
trainer/Q2Pred Std                           68.2628
trainer/Q2Pred Max                          426.804
trainer/Q2Pred Min                           13.674
trainer/QTargetWithReg Mean                 334.372
trainer/QTargetWithReg Std                   68.8043
trainer/QTargetWithReg Max                  424.663
trainer/QTargetWithReg Min                    0.465241
trainer/PolicyLossWithoutReg Mean           335.739
trainer/PolicyLossWithoutReg Std             66.5509
trainer/PolicyLossWithoutReg Max            425.052
trainer/PolicyLossWithoutReg Min             10.794
exploration/num steps total              693000
exploration/num paths total                1473
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54324
exploration/Rewards Std                       0.964848
exploration/Rewards Max                       7.3181
exploration/Rewards Min                      -0.536016
exploration/Returns Mean                   4543.24
exploration/Returns Std                       0
exploration/Returns Max                    4543.24
exploration/Returns Min                    4543.24
exploration/Num Paths                         1
exploration/Average Returns                4543.24
evaluation_0/num steps total                  5.38227e+06
evaluation_0/num paths total               8991
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73118
evaluation_0/Rewards Std                      0.997004
evaluation_0/Rewards Max                      7.41346
evaluation_0/Rewards Min                     -0.856153
evaluation_0/Returns Mean                  4731.18
evaluation_0/Returns Std                     31.64
evaluation_0/Returns Max                   4772.08
evaluation_0/Returns Min                   4662.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4731.18
time/epoch (s)                                0
time/total (s)                            10358.6
Epoch                                       688
---------------------------------------  ----------------
2022-11-16 19:07:34.152577 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 689 finished
---------------------------------------  ----------------
epoch                                       689
total_step                               694000
replay_pool/size                         694000
trainer/alpha                                 0.0595545
trainer/alpha_loss                            0.477523
trainer/entropy                              -6.16928
trainer/qf_loss                              15.9913
trainer/policy_loss                        -344.451
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.818
trainer/entropy_penalty                      -0.367409
trainer/entropy_percentage                   -0.00106551
trainer/Q1Pred Mean                         343.159
trainer/Q1Pred Std                           64.4662
trainer/Q1Pred Max                          423.861
trainer/Q1Pred Min                           10.6069
trainer/Q2Pred Mean                         343.532
trainer/Q2Pred Std                           64.2019
trainer/Q2Pred Max                          418.296
trainer/Q2Pred Min                            6.86165
trainer/QTargetWithReg Mean                 343.446
trainer/QTargetWithReg Std                   64.6549
trainer/QTargetWithReg Max                  417.054
trainer/QTargetWithReg Min                    2.08581
trainer/PolicyLossWithoutReg Mean           344.818
trainer/PolicyLossWithoutReg Std             61.2211
trainer/PolicyLossWithoutReg Max            418.096
trainer/PolicyLossWithoutReg Min             13.6311
exploration/num steps total              694000
exploration/num paths total                1474
exploration/path length this epoch Mean     148
exploration/path length this epoch Std        0
exploration/path length this epoch Max      148
exploration/path length this epoch Min      148
exploration/Rewards Mean                      3.1251
exploration/Rewards Std                       1.30837
exploration/Rewards Max                       5.08678
exploration/Rewards Min                      -0.684071
exploration/Returns Mean                    462.515
exploration/Returns Std                       0
exploration/Returns Max                     462.515
exploration/Returns Min                     462.515
exploration/Num Paths                         1
exploration/Average Returns                 462.515
evaluation_0/num steps total                  5.39027e+06
evaluation_0/num paths total               8999
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76333
evaluation_0/Rewards Std                      1.16029
evaluation_0/Rewards Max                      7.62961
evaluation_0/Rewards Min                     -0.941844
evaluation_0/Returns Mean                  4763.33
evaluation_0/Returns Std                    125.335
evaluation_0/Returns Max                   4985.43
evaluation_0/Returns Min                   4551.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4763.33
time/epoch (s)                                0
time/total (s)                            10371.1
Epoch                                       689
---------------------------------------  ----------------
2022-11-16 19:07:47.731219 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 690 finished
---------------------------------------  ----------------
epoch                                       690
total_step                               695000
replay_pool/size                         695000
trainer/alpha                                 0.0623075
trainer/alpha_loss                            0.167562
trainer/entropy                              -6.06037
trainer/qf_loss                              19.0281
trainer/policy_loss                        -341.959
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.337
trainer/entropy_penalty                      -0.377606
trainer/entropy_percentage                   -0.00110303
trainer/Q1Pred Mean                         341.577
trainer/Q1Pred Std                           64.1
trainer/Q1Pred Max                          433.052
trainer/Q1Pred Min                           21.4194
trainer/Q2Pred Mean                         341.581
trainer/Q2Pred Std                           63.633
trainer/Q2Pred Max                          432.152
trainer/Q2Pred Min                           27.6424
trainer/QTargetWithReg Mean                 341.452
trainer/QTargetWithReg Std                   63.6418
trainer/QTargetWithReg Max                  431.969
trainer/QTargetWithReg Min                   21.7181
trainer/PolicyLossWithoutReg Mean           342.337
trainer/PolicyLossWithoutReg Std             62.5821
trainer/PolicyLossWithoutReg Max            432.007
trainer/PolicyLossWithoutReg Min             27.891
exploration/num steps total              695000
exploration/num paths total                1475
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68603
exploration/Rewards Std                       0.993229
exploration/Rewards Max                       7.32005
exploration/Rewards Min                      -0.846974
exploration/Returns Mean                   4686.03
exploration/Returns Std                       0
exploration/Returns Max                    4686.03
exploration/Returns Min                    4686.03
exploration/Num Paths                         1
exploration/Average Returns                4686.03
evaluation_0/num steps total                  5.39827e+06
evaluation_0/num paths total               9007
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73468
evaluation_0/Rewards Std                      1.02214
evaluation_0/Rewards Max                      7.44845
evaluation_0/Rewards Min                     -0.787091
evaluation_0/Returns Mean                  4734.68
evaluation_0/Returns Std                    140.266
evaluation_0/Returns Max                   4969.08
evaluation_0/Returns Min                   4546.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4734.68
time/epoch (s)                                0
time/total (s)                            10384.7
Epoch                                       690
---------------------------------------  ----------------
2022-11-16 19:08:00.273179 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 691 finished
---------------------------------------  ----------------
epoch                                       691
total_step                               696000
replay_pool/size                         696000
trainer/alpha                                 0.0599191
trainer/alpha_loss                           -1.10321
trainer/entropy                              -5.60806
trainer/qf_loss                              21.3521
trainer/policy_loss                        -340.718
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.054
trainer/entropy_penalty                      -0.33603
trainer/entropy_percentage                   -0.00098527
trainer/Q1Pred Mean                         340.508
trainer/Q1Pred Std                           63.7006
trainer/Q1Pred Max                          425.639
trainer/Q1Pred Min                           43.5444
trainer/Q2Pred Mean                         340.642
trainer/Q2Pred Std                           63.992
trainer/Q2Pred Max                          424.326
trainer/Q2Pred Min                           40.0402
trainer/QTargetWithReg Mean                 340.791
trainer/QTargetWithReg Std                   64.048
trainer/QTargetWithReg Max                  426.003
trainer/QTargetWithReg Min                   41.8122
trainer/PolicyLossWithoutReg Mean           341.054
trainer/PolicyLossWithoutReg Std             62.6483
trainer/PolicyLossWithoutReg Max            423.976
trainer/PolicyLossWithoutReg Min             36.6093
exploration/num steps total              696000
exploration/num paths total                1476
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57374
exploration/Rewards Std                       1.10941
exploration/Rewards Max                       6.74434
exploration/Rewards Min                      -0.797194
exploration/Returns Mean                   4573.74
exploration/Returns Std                       0
exploration/Returns Max                    4573.74
exploration/Returns Min                    4573.74
exploration/Num Paths                         1
exploration/Average Returns                4573.74
evaluation_0/num steps total                  5.40627e+06
evaluation_0/num paths total               9015
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74628
evaluation_0/Rewards Std                      1.08181
evaluation_0/Rewards Max                      7.46705
evaluation_0/Rewards Min                     -0.632578
evaluation_0/Returns Mean                  4746.28
evaluation_0/Returns Std                     60.4908
evaluation_0/Returns Max                   4818.08
evaluation_0/Returns Min                   4634.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4746.28
time/epoch (s)                                0
time/total (s)                            10397.2
Epoch                                       691
---------------------------------------  ----------------
2022-11-16 19:08:11.426528 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 692 finished
---------------------------------------  ----------------
epoch                                       692
total_step                               697000
replay_pool/size                         697000
trainer/alpha                                 0.061704
trainer/alpha_loss                           -0.087914
trainer/entropy                              -5.96844
trainer/qf_loss                              19.5587
trainer/policy_loss                        -334.624
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         334.992
trainer/entropy_penalty                      -0.368276
trainer/entropy_percentage                   -0.00109936
trainer/Q1Pred Mean                         334.371
trainer/Q1Pred Std                           67.4519
trainer/Q1Pred Max                          412.424
trainer/Q1Pred Min                           22.1326
trainer/Q2Pred Mean                         334.25
trainer/Q2Pred Std                           67.9004
trainer/Q2Pred Max                          412.095
trainer/Q2Pred Min                           21.8472
trainer/QTargetWithReg Mean                 334.282
trainer/QTargetWithReg Std                   68.6399
trainer/QTargetWithReg Max                  413.623
trainer/QTargetWithReg Min                   15.6672
trainer/PolicyLossWithoutReg Mean           334.992
trainer/PolicyLossWithoutReg Std             65.9801
trainer/PolicyLossWithoutReg Max            414.829
trainer/PolicyLossWithoutReg Min             22.1064
exploration/num steps total              697000
exploration/num paths total                1477
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.42204
exploration/Rewards Std                       1.04909
exploration/Rewards Max                       7.23815
exploration/Rewards Min                      -0.589192
exploration/Returns Mean                   4422.04
exploration/Returns Std                       0
exploration/Returns Max                    4422.04
exploration/Returns Min                    4422.04
exploration/Num Paths                         1
exploration/Average Returns                4422.04
evaluation_0/num steps total                  5.41427e+06
evaluation_0/num paths total               9023
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69714
evaluation_0/Rewards Std                      1.00383
evaluation_0/Rewards Max                      7.36364
evaluation_0/Rewards Min                     -0.811723
evaluation_0/Returns Mean                  4697.14
evaluation_0/Returns Std                     31.4822
evaluation_0/Returns Max                   4751.92
evaluation_0/Returns Min                   4655.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4697.14
time/epoch (s)                                0
time/total (s)                            10408.4
Epoch                                       692
---------------------------------------  ----------------
2022-11-16 19:08:25.386681 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 693 finished
---------------------------------------  ----------------
epoch                                       693
total_step                               698000
replay_pool/size                         698000
trainer/alpha                                 0.0606108
trainer/alpha_loss                           -1.60561
trainer/entropy                              -5.42721
trainer/qf_loss                              18.5035
trainer/policy_loss                        -347.218
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.547
trainer/entropy_penalty                      -0.328948
trainer/entropy_percentage                   -0.000946483
trainer/Q1Pred Mean                         347.176
trainer/Q1Pred Std                           55.686
trainer/Q1Pred Max                          427.85
trainer/Q1Pred Min                           37.4299
trainer/Q2Pred Mean                         347.455
trainer/Q2Pred Std                           55.3719
trainer/Q2Pred Max                          427.617
trainer/Q2Pred Min                           30.2358
trainer/QTargetWithReg Mean                 346.89
trainer/QTargetWithReg Std                   54.8987
trainer/QTargetWithReg Max                  426.704
trainer/QTargetWithReg Min                   45.0189
trainer/PolicyLossWithoutReg Mean           347.547
trainer/PolicyLossWithoutReg Std             54.8436
trainer/PolicyLossWithoutReg Max            426.934
trainer/PolicyLossWithoutReg Min             33.2681
exploration/num steps total              698000
exploration/num paths total                1478
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51429
exploration/Rewards Std                       1.01374
exploration/Rewards Max                       7.18958
exploration/Rewards Min                      -0.568651
exploration/Returns Mean                   4514.29
exploration/Returns Std                       0
exploration/Returns Max                    4514.29
exploration/Returns Min                    4514.29
exploration/Num Paths                         1
exploration/Average Returns                4514.29
evaluation_0/num steps total                  5.42227e+06
evaluation_0/num paths total               9031
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67582
evaluation_0/Rewards Std                      1.05383
evaluation_0/Rewards Max                      7.66685
evaluation_0/Rewards Min                     -0.767433
evaluation_0/Returns Mean                  4675.82
evaluation_0/Returns Std                     39.5192
evaluation_0/Returns Max                   4742.37
evaluation_0/Returns Min                   4624.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.82
time/epoch (s)                                0
time/total (s)                            10422.3
Epoch                                       693
---------------------------------------  ----------------
2022-11-16 19:08:36.703637 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 694 finished
---------------------------------------  ----------------
epoch                                       694
total_step                               699000
replay_pool/size                         699000
trainer/alpha                                 0.059043
trainer/alpha_loss                           -0.891985
trainer/entropy                              -5.68476
trainer/qf_loss                              23.2408
trainer/policy_loss                        -339.439
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.775
trainer/entropy_penalty                      -0.335645
trainer/entropy_percentage                   -0.000987847
trainer/Q1Pred Mean                         339.103
trainer/Q1Pred Std                           64.889
trainer/Q1Pred Max                          416.053
trainer/Q1Pred Min                           16.5737
trainer/Q2Pred Mean                         338.612
trainer/Q2Pred Std                           64.7512
trainer/Q2Pred Max                          415.11
trainer/Q2Pred Min                           19.3925
trainer/QTargetWithReg Mean                 339.555
trainer/QTargetWithReg Std                   65.3397
trainer/QTargetWithReg Max                  415.607
trainer/QTargetWithReg Min                    9.24886
trainer/PolicyLossWithoutReg Mean           339.775
trainer/PolicyLossWithoutReg Std             63.6999
trainer/PolicyLossWithoutReg Max            415.224
trainer/PolicyLossWithoutReg Min             18.4082
exploration/num steps total              699000
exploration/num paths total                1479
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41365
exploration/Rewards Std                       0.987153
exploration/Rewards Max                       6.91568
exploration/Rewards Min                      -0.551514
exploration/Returns Mean                   4413.65
exploration/Returns Std                       0
exploration/Returns Max                    4413.65
exploration/Returns Min                    4413.65
exploration/Num Paths                         1
exploration/Average Returns                4413.65
evaluation_0/num steps total                  5.43027e+06
evaluation_0/num paths total               9039
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61264
evaluation_0/Rewards Std                      1.00825
evaluation_0/Rewards Max                      7.2214
evaluation_0/Rewards Min                     -0.558446
evaluation_0/Returns Mean                  4612.64
evaluation_0/Returns Std                     54.6093
evaluation_0/Returns Max                   4700.7
evaluation_0/Returns Min                   4524.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4612.64
time/epoch (s)                                0
time/total (s)                            10433.6
Epoch                                       694
---------------------------------------  ----------------
2022-11-16 19:08:47.992541 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 695 finished
---------------------------------------  ----------------
epoch                                       695
total_step                               700000
replay_pool/size                         700000
trainer/alpha                                 0.058832
trainer/alpha_loss                            1.25103
trainer/entropy                              -6.44156
trainer/qf_loss                              20.4709
trainer/policy_loss                        -330.375
trainer/adversary_policy_loss                15.8239
trainer/policy_loss_without_entropy         330.754
trainer/entropy_penalty                      -0.37897
trainer/entropy_percentage                   -0.00114578
trainer/Q1Pred Mean                         330.04
trainer/Q1Pred Std                           73.1094
trainer/Q1Pred Max                          423.963
trainer/Q1Pred Min                          -10.7063
trainer/Q2Pred Mean                         330.403
trainer/Q2Pred Std                           72.6304
trainer/Q2Pred Max                          423.757
trainer/Q2Pred Min                           -8.43798
trainer/QTargetWithReg Mean                 329.751
trainer/QTargetWithReg Std                   72.8007
trainer/QTargetWithReg Max                  423.926
trainer/QTargetWithReg Min                   -8.09026
trainer/PolicyLossWithoutReg Mean           330.754
trainer/PolicyLossWithoutReg Std             71.9432
trainer/PolicyLossWithoutReg Max            423.271
trainer/PolicyLossWithoutReg Min             -4.46148
exploration/num steps total              700000
exploration/num paths total                1480
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45845
exploration/Rewards Std                       1.04839
exploration/Rewards Max                       7.17307
exploration/Rewards Min                      -0.886883
exploration/Returns Mean                   4458.45
exploration/Returns Std                       0
exploration/Returns Max                    4458.45
exploration/Returns Min                    4458.45
exploration/Num Paths                         1
exploration/Average Returns                4458.45
evaluation_0/num steps total                  5.43827e+06
evaluation_0/num paths total               9047
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.60304
evaluation_0/Rewards Std                      1.02959
evaluation_0/Rewards Max                      7.3976
evaluation_0/Rewards Min                     -0.407939
evaluation_0/Returns Mean                  4603.04
evaluation_0/Returns Std                     96.8571
evaluation_0/Returns Max                   4711.42
evaluation_0/Returns Min                   4436.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4603.04
time/epoch (s)                                0
time/total (s)                            10444.9
Epoch                                       695
---------------------------------------  ----------------
2022-11-16 19:09:01.432311 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 696 finished
---------------------------------------  ----------------
epoch                                       696
total_step                               701000
replay_pool/size                         701000
trainer/alpha                                 0.0611299
trainer/alpha_loss                            1.96439
trainer/entropy                              -6.70287
trainer/qf_loss                              32.3
trainer/policy_loss                        -338.463
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.872
trainer/entropy_penalty                      -0.409746
trainer/entropy_percentage                   -0.00120914
trainer/Q1Pred Mean                         336.33
trainer/Q1Pred Std                           73.613
trainer/Q1Pred Max                          426.851
trainer/Q1Pred Min                          -61.6027
trainer/Q2Pred Mean                         336.26
trainer/Q2Pred Std                           72.0509
trainer/Q2Pred Max                          429.445
trainer/Q2Pred Min                          -12.8992
trainer/QTargetWithReg Mean                 336.56
trainer/QTargetWithReg Std                   72.181
trainer/QTargetWithReg Max                  425.715
trainer/QTargetWithReg Min                   -0.0180582
trainer/PolicyLossWithoutReg Mean           338.872
trainer/PolicyLossWithoutReg Std             69.1565
trainer/PolicyLossWithoutReg Max            427.06
trainer/PolicyLossWithoutReg Min             15.1489
exploration/num steps total              701000
exploration/num paths total                1481
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73911
exploration/Rewards Std                       1.09345
exploration/Rewards Max                       7.52901
exploration/Rewards Min                      -0.375276
exploration/Returns Mean                   4739.11
exploration/Returns Std                       0
exploration/Returns Max                    4739.11
exploration/Returns Min                    4739.11
exploration/Num Paths                         1
exploration/Average Returns                4739.11
evaluation_0/num steps total                  5.44627e+06
evaluation_0/num paths total               9055
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68509
evaluation_0/Rewards Std                      0.977045
evaluation_0/Rewards Max                      7.31858
evaluation_0/Rewards Min                     -0.508212
evaluation_0/Returns Mean                  4685.09
evaluation_0/Returns Std                     58.7259
evaluation_0/Returns Max                   4787.16
evaluation_0/Returns Min                   4612.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4685.09
time/epoch (s)                                0
time/total (s)                            10458.4
Epoch                                       696
---------------------------------------  ----------------
2022-11-16 19:09:13.301854 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 697 finished
---------------------------------------  ----------------
epoch                                       697
total_step                               702000
replay_pool/size                         702000
trainer/alpha                                 0.0620341
trainer/alpha_loss                           -0.464976
trainer/entropy                              -5.83274
trainer/qf_loss                              19.1992
trainer/policy_loss                        -336.348
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         336.709
trainer/entropy_penalty                      -0.361829
trainer/entropy_percentage                   -0.0010746
trainer/Q1Pred Mean                         335.99
trainer/Q1Pred Std                           71.7839
trainer/Q1Pred Max                          427.292
trainer/Q1Pred Min                           18.6546
trainer/Q2Pred Mean                         335.422
trainer/Q2Pred Std                           72.2221
trainer/Q2Pred Max                          428.412
trainer/Q2Pred Min                           -2.19911
trainer/QTargetWithReg Mean                 334.745
trainer/QTargetWithReg Std                   72.4112
trainer/QTargetWithReg Max                  429.541
trainer/QTargetWithReg Min                   -0.319668
trainer/PolicyLossWithoutReg Mean           336.709
trainer/PolicyLossWithoutReg Std             68.8249
trainer/PolicyLossWithoutReg Max            427.711
trainer/PolicyLossWithoutReg Min             24.7369
exploration/num steps total              702000
exploration/num paths total                1482
exploration/path length this epoch Mean     314
exploration/path length this epoch Std        0
exploration/path length this epoch Max      314
exploration/path length this epoch Min      314
exploration/Rewards Mean                      3.72114
exploration/Rewards Std                       1.33288
exploration/Rewards Max                       6.32589
exploration/Rewards Min                      -0.677761
exploration/Returns Mean                   1168.44
exploration/Returns Std                       0
exploration/Returns Max                    1168.44
exploration/Returns Min                    1168.44
exploration/Num Paths                         1
exploration/Average Returns                1168.44
evaluation_0/num steps total                  5.45427e+06
evaluation_0/num paths total               9063
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92849
evaluation_0/Rewards Std                      1.06271
evaluation_0/Rewards Max                      7.66166
evaluation_0/Rewards Min                     -0.593676
evaluation_0/Returns Mean                  4928.49
evaluation_0/Returns Std                     58.5939
evaluation_0/Returns Max                   5025.65
evaluation_0/Returns Min                   4847.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4928.49
time/epoch (s)                                0
time/total (s)                            10470.2
Epoch                                       697
---------------------------------------  ----------------
2022-11-16 19:09:24.598192 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 698 finished
---------------------------------------  ----------------
epoch                                       698
total_step                               703000
replay_pool/size                         703000
trainer/alpha                                 0.0608086
trainer/alpha_loss                            0.208022
trainer/entropy                              -6.07429
trainer/qf_loss                              18.6041
trainer/policy_loss                        -343.341
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.711
trainer/entropy_penalty                      -0.369369
trainer/entropy_percentage                   -0.00107465
trainer/Q1Pred Mean                         342.734
trainer/Q1Pred Std                           61.1336
trainer/Q1Pred Max                          415
trainer/Q1Pred Min                            9.20977
trainer/Q2Pred Mean                         343.481
trainer/Q2Pred Std                           61.1623
trainer/Q2Pred Max                          418.547
trainer/Q2Pred Min                           22.8739
trainer/QTargetWithReg Mean                 343.848
trainer/QTargetWithReg Std                   61.1272
trainer/QTargetWithReg Max                  417.236
trainer/QTargetWithReg Min                   17.4691
trainer/PolicyLossWithoutReg Mean           343.711
trainer/PolicyLossWithoutReg Std             59.9738
trainer/PolicyLossWithoutReg Max            414.528
trainer/PolicyLossWithoutReg Min              8.81736
exploration/num steps total              703000
exploration/num paths total                1483
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67781
exploration/Rewards Std                       0.978291
exploration/Rewards Max                       6.71576
exploration/Rewards Min                      -0.596151
exploration/Returns Mean                   4677.81
exploration/Returns Std                       0
exploration/Returns Max                    4677.81
exploration/Returns Min                    4677.81
exploration/Num Paths                         1
exploration/Average Returns                4677.81
evaluation_0/num steps total                  5.46227e+06
evaluation_0/num paths total               9071
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62226
evaluation_0/Rewards Std                      1.02927
evaluation_0/Rewards Max                      7.33636
evaluation_0/Rewards Min                     -0.908673
evaluation_0/Returns Mean                  4622.26
evaluation_0/Returns Std                     84.3195
evaluation_0/Returns Max                   4770.58
evaluation_0/Returns Min                   4449.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4622.26
time/epoch (s)                                0
time/total (s)                            10481.5
Epoch                                       698
---------------------------------------  ----------------
2022-11-16 19:09:36.671791 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 699 finished
---------------------------------------  ----------------
epoch                                       699
total_step                               704000
replay_pool/size                         704000
trainer/alpha                                 0.061684
trainer/alpha_loss                           -1.15037
trainer/entropy                              -5.58702
trainer/qf_loss                              23.2264
trainer/policy_loss                        -344.063
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.407
trainer/entropy_penalty                      -0.34463
trainer/entropy_percentage                   -0.00100065
trainer/Q1Pred Mean                         343.998
trainer/Q1Pred Std                           66.6491
trainer/Q1Pred Max                          427.098
trainer/Q1Pred Min                           17.5537
trainer/Q2Pred Mean                         344.342
trainer/Q2Pred Std                           66.164
trainer/Q2Pred Max                          425.909
trainer/Q2Pred Min                           22.9769
trainer/QTargetWithReg Mean                 344.064
trainer/QTargetWithReg Std                   66.3877
trainer/QTargetWithReg Max                  428.021
trainer/QTargetWithReg Min                   21.5611
trainer/PolicyLossWithoutReg Mean           344.407
trainer/PolicyLossWithoutReg Std             65.1682
trainer/PolicyLossWithoutReg Max            425.509
trainer/PolicyLossWithoutReg Min             22.9186
exploration/num steps total              704000
exploration/num paths total                1484
exploration/path length this epoch Mean      90
exploration/path length this epoch Std        0
exploration/path length this epoch Max       90
exploration/path length this epoch Min       90
exploration/Rewards Mean                      2.32843
exploration/Rewards Std                       1.73984
exploration/Rewards Max                       8.02401
exploration/Rewards Min                      -0.81501
exploration/Returns Mean                    209.559
exploration/Returns Std                       0
exploration/Returns Max                     209.559
exploration/Returns Min                     209.559
exploration/Num Paths                         1
exploration/Average Returns                 209.559
evaluation_0/num steps total                  5.47027e+06
evaluation_0/num paths total               9079
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76584
evaluation_0/Rewards Std                      1.04183
evaluation_0/Rewards Max                      7.33716
evaluation_0/Rewards Min                     -1.0339
evaluation_0/Returns Mean                  4765.84
evaluation_0/Returns Std                    123.36
evaluation_0/Returns Max                   5032.19
evaluation_0/Returns Min                   4597.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4765.84
time/epoch (s)                                0
time/total (s)                            10493.6
Epoch                                       699
---------------------------------------  ----------------
2022-11-16 19:09:49.324494 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 700 finished
---------------------------------------  ----------------
epoch                                       700
total_step                               705000
replay_pool/size                         705000
trainer/alpha                                 0.0614896
trainer/alpha_loss                            0.159052
trainer/entropy                              -6.05703
trainer/qf_loss                              22.463
trainer/policy_loss                        -339.811
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.183
trainer/entropy_penalty                      -0.372444
trainer/entropy_percentage                   -0.00109484
trainer/Q1Pred Mean                         338.339
trainer/Q1Pred Std                           59.0162
trainer/Q1Pred Max                          424.501
trainer/Q1Pred Min                           30.3602
trainer/Q2Pred Mean                         338.992
trainer/Q2Pred Std                           59.7428
trainer/Q2Pred Max                          425
trainer/Q2Pred Min                           27.8477
trainer/QTargetWithReg Mean                 339.067
trainer/QTargetWithReg Std                   60.1843
trainer/QTargetWithReg Max                  426.818
trainer/QTargetWithReg Min                   26.7427
trainer/PolicyLossWithoutReg Mean           340.183
trainer/PolicyLossWithoutReg Std             58.8368
trainer/PolicyLossWithoutReg Max            424.881
trainer/PolicyLossWithoutReg Min             26.1756
exploration/num steps total              705000
exploration/num paths total                1485
exploration/path length this epoch Mean     740
exploration/path length this epoch Std        0
exploration/path length this epoch Max      740
exploration/path length this epoch Min      740
exploration/Rewards Mean                      4.28289
exploration/Rewards Std                       1.1159
exploration/Rewards Max                       6.77922
exploration/Rewards Min                      -0.755212
exploration/Returns Mean                   3169.34
exploration/Returns Std                       0
exploration/Returns Max                    3169.34
exploration/Returns Min                    3169.34
exploration/Num Paths                         1
exploration/Average Returns                3169.34
evaluation_0/num steps total                  5.47827e+06
evaluation_0/num paths total               9087
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70011
evaluation_0/Rewards Std                      1.04036
evaluation_0/Rewards Max                      7.5551
evaluation_0/Rewards Min                     -0.643948
evaluation_0/Returns Mean                  4700.11
evaluation_0/Returns Std                    123.099
evaluation_0/Returns Max                   4839.21
evaluation_0/Returns Min                   4440.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4700.11
time/epoch (s)                                0
time/total (s)                            10506.3
Epoch                                       700
---------------------------------------  ----------------
2022-11-16 19:10:00.286135 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 701 finished
---------------------------------------  ----------------
epoch                                       701
total_step                               706000
replay_pool/size                         706000
trainer/alpha                                 0.0605391
trainer/alpha_loss                           -0.248015
trainer/entropy                              -5.91157
trainer/qf_loss                              18.1921
trainer/policy_loss                        -341.392
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.75
trainer/entropy_penalty                      -0.357881
trainer/entropy_percentage                   -0.0010472
trainer/Q1Pred Mean                         340.559
trainer/Q1Pred Std                           66.3443
trainer/Q1Pred Max                          426.873
trainer/Q1Pred Min                            1.27606
trainer/Q2Pred Mean                         340.855
trainer/Q2Pred Std                           66.461
trainer/Q2Pred Max                          426.73
trainer/Q2Pred Min                           10.4486
trainer/QTargetWithReg Mean                 340.467
trainer/QTargetWithReg Std                   67.0262
trainer/QTargetWithReg Max                  427.461
trainer/QTargetWithReg Min                   10.2064
trainer/PolicyLossWithoutReg Mean           341.75
trainer/PolicyLossWithoutReg Std             64.5004
trainer/PolicyLossWithoutReg Max            426.548
trainer/PolicyLossWithoutReg Min              8.3304
exploration/num steps total              706000
exploration/num paths total                1486
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52948
exploration/Rewards Std                       1.04041
exploration/Rewards Max                       7.49005
exploration/Rewards Min                      -0.862836
exploration/Returns Mean                   4529.48
exploration/Returns Std                       0
exploration/Returns Max                    4529.48
exploration/Returns Min                    4529.48
exploration/Num Paths                         1
exploration/Average Returns                4529.48
evaluation_0/num steps total                  5.48627e+06
evaluation_0/num paths total               9095
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84025
evaluation_0/Rewards Std                      1.10074
evaluation_0/Rewards Max                      7.62493
evaluation_0/Rewards Min                     -0.869985
evaluation_0/Returns Mean                  4840.25
evaluation_0/Returns Std                     94.4084
evaluation_0/Returns Max                   5035.53
evaluation_0/Returns Min                   4706.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4840.25
time/epoch (s)                                0
time/total (s)                            10517.2
Epoch                                       701
---------------------------------------  ----------------
2022-11-16 19:10:14.052655 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 702 finished
---------------------------------------  ----------------
epoch                                       702
total_step                               707000
replay_pool/size                         707000
trainer/alpha                                 0.0594973
trainer/alpha_loss                            1.69443
trainer/entropy                              -6.60048
trainer/qf_loss                              16.9747
trainer/policy_loss                        -342.929
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.322
trainer/entropy_penalty                      -0.392711
trainer/entropy_percentage                   -0.00114386
trainer/Q1Pred Mean                         341.932
trainer/Q1Pred Std                           74.2217
trainer/Q1Pred Max                          430.055
trainer/Q1Pred Min                          -15.8329
trainer/Q2Pred Mean                         342.423
trainer/Q2Pred Std                           73.3998
trainer/Q2Pred Max                          430.479
trainer/Q2Pred Min                           -0.897816
trainer/QTargetWithReg Mean                 341.898
trainer/QTargetWithReg Std                   74.001
trainer/QTargetWithReg Max                  430.384
trainer/QTargetWithReg Min                   -1.57929
trainer/PolicyLossWithoutReg Mean           343.322
trainer/PolicyLossWithoutReg Std             71.3638
trainer/PolicyLossWithoutReg Max            430.308
trainer/PolicyLossWithoutReg Min            -15.1073
exploration/num steps total              707000
exploration/num paths total                1487
exploration/path length this epoch Mean     926
exploration/path length this epoch Std        0
exploration/path length this epoch Max      926
exploration/path length this epoch Min      926
exploration/Rewards Mean                      4.39005
exploration/Rewards Std                       1.14505
exploration/Rewards Max                       6.97705
exploration/Rewards Min                      -0.29368
exploration/Returns Mean                   4065.19
exploration/Returns Std                       0
exploration/Returns Max                    4065.19
exploration/Returns Min                    4065.19
exploration/Num Paths                         1
exploration/Average Returns                4065.19
evaluation_0/num steps total                  5.49427e+06
evaluation_0/num paths total               9103
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66143
evaluation_0/Rewards Std                      1.15008
evaluation_0/Rewards Max                      7.71181
evaluation_0/Rewards Min                     -0.775959
evaluation_0/Returns Mean                  4661.43
evaluation_0/Returns Std                     84.8138
evaluation_0/Returns Max                   4756.46
evaluation_0/Returns Min                   4512.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4661.43
time/epoch (s)                                0
time/total (s)                            10531
Epoch                                       702
---------------------------------------  ----------------
2022-11-16 19:10:25.873076 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 703 finished
---------------------------------------  ----------------
epoch                                       703
total_step                               708000
replay_pool/size                         708000
trainer/alpha                                 0.0607265
trainer/alpha_loss                            0.392707
trainer/entropy                              -6.14018
trainer/qf_loss                             150.086
trainer/policy_loss                        -332.841
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.214
trainer/entropy_penalty                      -0.372871
trainer/entropy_percentage                   -0.00111901
trainer/Q1Pred Mean                         333.182
trainer/Q1Pred Std                           62.2906
trainer/Q1Pred Max                          422.274
trainer/Q1Pred Min                           89.3931
trainer/Q2Pred Mean                         332.842
trainer/Q2Pred Std                           61.5734
trainer/Q2Pred Max                          421.376
trainer/Q2Pred Min                           95.7226
trainer/QTargetWithReg Mean                 332.725
trainer/QTargetWithReg Std                   65.7155
trainer/QTargetWithReg Max                  422.407
trainer/QTargetWithReg Min                    4.9755
trainer/PolicyLossWithoutReg Mean           333.214
trainer/PolicyLossWithoutReg Std             60.3445
trainer/PolicyLossWithoutReg Max            420.675
trainer/PolicyLossWithoutReg Min            102.96
exploration/num steps total              708000
exploration/num paths total                1488
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.29216
exploration/Rewards Std                       1.05056
exploration/Rewards Max                       6.97563
exploration/Rewards Min                      -0.808248
exploration/Returns Mean                   4292.16
exploration/Returns Std                       0
exploration/Returns Max                    4292.16
exploration/Returns Min                    4292.16
exploration/Num Paths                         1
exploration/Average Returns                4292.16
evaluation_0/num steps total                  5.50227e+06
evaluation_0/num paths total               9111
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74835
evaluation_0/Rewards Std                      1.06053
evaluation_0/Rewards Max                      7.5262
evaluation_0/Rewards Min                     -0.815194
evaluation_0/Returns Mean                  4748.35
evaluation_0/Returns Std                     99.8251
evaluation_0/Returns Max                   4858.46
evaluation_0/Returns Min                   4549.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4748.35
time/epoch (s)                                0
time/total (s)                            10542.8
Epoch                                       703
---------------------------------------  ----------------
2022-11-16 19:10:37.046066 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 704 finished
---------------------------------------  ----------------
epoch                                       704
total_step                               709000
replay_pool/size                         709000
trainer/alpha                                 0.0601309
trainer/alpha_loss                            0.873785
trainer/entropy                              -6.31082
trainer/qf_loss                              16.3861
trainer/policy_loss                        -337.878
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.257
trainer/entropy_penalty                      -0.379475
trainer/entropy_percentage                   -0.00112185
trainer/Q1Pred Mean                         337.557
trainer/Q1Pred Std                           66.9834
trainer/Q1Pred Max                          433.35
trainer/Q1Pred Min                           20.2019
trainer/Q2Pred Mean                         337.542
trainer/Q2Pred Std                           66.7986
trainer/Q2Pred Max                          432.069
trainer/Q2Pred Min                           21.9654
trainer/QTargetWithReg Mean                 336.797
trainer/QTargetWithReg Std                   66.6988
trainer/QTargetWithReg Max                  432.152
trainer/QTargetWithReg Min                   25.1012
trainer/PolicyLossWithoutReg Mean           338.257
trainer/PolicyLossWithoutReg Std             66.0399
trainer/PolicyLossWithoutReg Max            432.146
trainer/PolicyLossWithoutReg Min             23.6535
exploration/num steps total              709000
exploration/num paths total                1489
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41485
exploration/Rewards Std                       1.10531
exploration/Rewards Max                       7.3773
exploration/Rewards Min                      -0.988804
exploration/Returns Mean                   4414.85
exploration/Returns Std                       0
exploration/Returns Max                    4414.85
exploration/Returns Min                    4414.85
exploration/Num Paths                         1
exploration/Average Returns                4414.85
evaluation_0/num steps total                  5.51027e+06
evaluation_0/num paths total               9119
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66774
evaluation_0/Rewards Std                      1.0115
evaluation_0/Rewards Max                      7.46034
evaluation_0/Rewards Min                     -0.671372
evaluation_0/Returns Mean                  4667.74
evaluation_0/Returns Std                    140.307
evaluation_0/Returns Max                   4899.04
evaluation_0/Returns Min                   4448.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4667.74
time/epoch (s)                                0
time/total (s)                            10554
Epoch                                       704
---------------------------------------  ----------------
2022-11-16 19:10:51.142033 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 705 finished
---------------------------------------  ----------------
epoch                                       705
total_step                               710000
replay_pool/size                         710000
trainer/alpha                                 0.0605577
trainer/alpha_loss                           -0.353259
trainer/entropy                              -5.87402
trainer/qf_loss                              22.7307
trainer/policy_loss                        -344.11
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.466
trainer/entropy_penalty                      -0.355717
trainer/entropy_percentage                   -0.00103266
trainer/Q1Pred Mean                         343.601
trainer/Q1Pred Std                           64.1466
trainer/Q1Pred Max                          418.919
trainer/Q1Pred Min                           14.2993
trainer/Q2Pred Mean                         343.276
trainer/Q2Pred Std                           64.5769
trainer/Q2Pred Max                          417.782
trainer/Q2Pred Min                           14.089
trainer/QTargetWithReg Mean                 344.291
trainer/QTargetWithReg Std                   65.1077
trainer/QTargetWithReg Max                  417.989
trainer/QTargetWithReg Min                   10.7713
trainer/PolicyLossWithoutReg Mean           344.466
trainer/PolicyLossWithoutReg Std             63.8993
trainer/PolicyLossWithoutReg Max            417.477
trainer/PolicyLossWithoutReg Min             11.3668
exploration/num steps total              710000
exploration/num paths total                1490
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.713
exploration/Rewards Std                       0.990218
exploration/Rewards Max                       7.26054
exploration/Rewards Min                      -0.566727
exploration/Returns Mean                   4713
exploration/Returns Std                       0
exploration/Returns Max                    4713
exploration/Returns Min                    4713
exploration/Num Paths                         1
exploration/Average Returns                4713
evaluation_0/num steps total                  5.51827e+06
evaluation_0/num paths total               9127
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90717
evaluation_0/Rewards Std                      1.10988
evaluation_0/Rewards Max                      7.37933
evaluation_0/Rewards Min                     -0.865323
evaluation_0/Returns Mean                  4907.17
evaluation_0/Returns Std                     82.7571
evaluation_0/Returns Max                   5042.89
evaluation_0/Returns Min                   4773.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4907.17
time/epoch (s)                                0
time/total (s)                            10568.1
Epoch                                       705
---------------------------------------  ----------------
2022-11-16 19:11:02.650008 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 706 finished
---------------------------------------  ----------------
epoch                                       706
total_step                               711000
replay_pool/size                         711000
trainer/alpha                                 0.0577901
trainer/alpha_loss                            0.0503623
trainer/entropy                              -6.01767
trainer/qf_loss                              27.2171
trainer/policy_loss                        -344.033
trainer/adversary_policy_loss                16.4395
trainer/policy_loss_without_entropy         344.381
trainer/entropy_penalty                      -0.347762
trainer/entropy_percentage                   -0.00100982
trainer/Q1Pred Mean                         343.143
trainer/Q1Pred Std                           55.5994
trainer/Q1Pred Max                          421.301
trainer/Q1Pred Min                           51.337
trainer/Q2Pred Mean                         342.81
trainer/Q2Pred Std                           55.204
trainer/Q2Pred Max                          421.26
trainer/Q2Pred Min                           57.7294
trainer/QTargetWithReg Mean                 343.717
trainer/QTargetWithReg Std                   56.4713
trainer/QTargetWithReg Max                  422.943
trainer/QTargetWithReg Min                   44.7799
trainer/PolicyLossWithoutReg Mean           344.381
trainer/PolicyLossWithoutReg Std             54.8151
trainer/PolicyLossWithoutReg Max            423.838
trainer/PolicyLossWithoutReg Min             62.549
exploration/num steps total              711000
exploration/num paths total                1491
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60395
exploration/Rewards Std                       0.971452
exploration/Rewards Max                       7.24815
exploration/Rewards Min                      -0.712073
exploration/Returns Mean                   4603.95
exploration/Returns Std                       0
exploration/Returns Max                    4603.95
exploration/Returns Min                    4603.95
exploration/Num Paths                         1
exploration/Average Returns                4603.95
evaluation_0/num steps total                  5.52627e+06
evaluation_0/num paths total               9135
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92171
evaluation_0/Rewards Std                      1.07602
evaluation_0/Rewards Max                      7.53443
evaluation_0/Rewards Min                     -0.797458
evaluation_0/Returns Mean                  4921.71
evaluation_0/Returns Std                    147.644
evaluation_0/Returns Max                   5092.6
evaluation_0/Returns Min                   4624.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4921.71
time/epoch (s)                                0
time/total (s)                            10579.6
Epoch                                       706
---------------------------------------  ----------------
2022-11-16 19:11:13.832934 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 707 finished
---------------------------------------  ----------------
epoch                                       707
total_step                               712000
replay_pool/size                         712000
trainer/alpha                                 0.0597999
trainer/alpha_loss                           -2.17525
trainer/entropy                              -5.22767
trainer/qf_loss                              12.7534
trainer/policy_loss                        -346.842
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.154
trainer/entropy_penalty                      -0.312614
trainer/entropy_percentage                   -0.000900505
trainer/Q1Pred Mean                         346.178
trainer/Q1Pred Std                           60.1568
trainer/Q1Pred Max                          427.66
trainer/Q1Pred Min                          -49.2885
trainer/Q2Pred Mean                         346.169
trainer/Q2Pred Std                           58.8236
trainer/Q2Pred Max                          427.209
trainer/Q2Pred Min                          -15.9728
trainer/QTargetWithReg Mean                 346.441
trainer/QTargetWithReg Std                   59.6333
trainer/QTargetWithReg Max                  427.45
trainer/QTargetWithReg Min                  -28.9329
trainer/PolicyLossWithoutReg Mean           347.154
trainer/PolicyLossWithoutReg Std             59.149
trainer/PolicyLossWithoutReg Max            426.607
trainer/PolicyLossWithoutReg Min            -31.5891
exploration/num steps total              712000
exploration/num paths total                1492
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.3512
exploration/Rewards Std                       1.07082
exploration/Rewards Max                       7.12461
exploration/Rewards Min                      -0.790495
exploration/Returns Mean                   4351.2
exploration/Returns Std                       0
exploration/Returns Max                    4351.2
exploration/Returns Min                    4351.2
exploration/Num Paths                         1
exploration/Average Returns                4351.2
evaluation_0/num steps total                  5.53427e+06
evaluation_0/num paths total               9143
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76151
evaluation_0/Rewards Std                      1.07138
evaluation_0/Rewards Max                      7.50145
evaluation_0/Rewards Min                     -0.523623
evaluation_0/Returns Mean                  4761.51
evaluation_0/Returns Std                    102.991
evaluation_0/Returns Max                   4900.7
evaluation_0/Returns Min                   4560.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4761.51
time/epoch (s)                                0
time/total (s)                            10590.8
Epoch                                       707
---------------------------------------  ----------------
2022-11-16 19:11:28.365502 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 708 finished
---------------------------------------  ----------------
epoch                                       708
total_step                               713000
replay_pool/size                         713000
trainer/alpha                                 0.0604224
trainer/alpha_loss                           -0.0974911
trainer/entropy                              -5.96526
trainer/qf_loss                              18.7906
trainer/policy_loss                        -340.485
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.846
trainer/entropy_penalty                      -0.360435
trainer/entropy_percentage                   -0.00105747
trainer/Q1Pred Mean                         340.178
trainer/Q1Pred Std                           63.6561
trainer/Q1Pred Max                          425.847
trainer/Q1Pred Min                           20.266
trainer/Q2Pred Mean                         340.518
trainer/Q2Pred Std                           64.0385
trainer/Q2Pred Max                          428.227
trainer/Q2Pred Min                           17.8542
trainer/QTargetWithReg Mean                 340.053
trainer/QTargetWithReg Std                   64.1692
trainer/QTargetWithReg Max                  426.503
trainer/QTargetWithReg Min                   16.5058
trainer/PolicyLossWithoutReg Mean           340.846
trainer/PolicyLossWithoutReg Std             62.3013
trainer/PolicyLossWithoutReg Max            425.142
trainer/PolicyLossWithoutReg Min             16.0848
exploration/num steps total              713000
exploration/num paths total                1493
exploration/path length this epoch Mean     923
exploration/path length this epoch Std        0
exploration/path length this epoch Max      923
exploration/path length this epoch Min      923
exploration/Rewards Mean                      4.40413
exploration/Rewards Std                       1.04516
exploration/Rewards Max                       7.08554
exploration/Rewards Min                      -0.606241
exploration/Returns Mean                   4065.01
exploration/Returns Std                       0
exploration/Returns Max                    4065.01
exploration/Returns Min                    4065.01
exploration/Num Paths                         1
exploration/Average Returns                4065.01
evaluation_0/num steps total                  5.54227e+06
evaluation_0/num paths total               9151
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82912
evaluation_0/Rewards Std                      1.13427
evaluation_0/Rewards Max                      7.61357
evaluation_0/Rewards Min                     -0.858821
evaluation_0/Returns Mean                  4829.12
evaluation_0/Returns Std                    105.361
evaluation_0/Returns Max                   5005.66
evaluation_0/Returns Min                   4651.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4829.12
time/epoch (s)                                0
time/total (s)                            10605.3
Epoch                                       708
---------------------------------------  ----------------
2022-11-16 19:11:39.846515 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 709 finished
---------------------------------------  ----------------
epoch                                       709
total_step                               714000
replay_pool/size                         714000
trainer/alpha                                 0.0594489
trainer/alpha_loss                            0.190366
trainer/entropy                              -6.06744
trainer/qf_loss                              15.3739
trainer/policy_loss                        -338.375
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.736
trainer/entropy_penalty                      -0.360703
trainer/entropy_percentage                   -0.00106485
trainer/Q1Pred Mean                         337.685
trainer/Q1Pred Std                           66.7665
trainer/Q1Pred Max                          419.819
trainer/Q1Pred Min                            7.40169
trainer/Q2Pred Mean                         337.662
trainer/Q2Pred Std                           67.0235
trainer/Q2Pred Max                          420.213
trainer/Q2Pred Min                           13.7101
trainer/QTargetWithReg Mean                 337.947
trainer/QTargetWithReg Std                   67.2492
trainer/QTargetWithReg Max                  419.724
trainer/QTargetWithReg Min                    1.71664
trainer/PolicyLossWithoutReg Mean           338.736
trainer/PolicyLossWithoutReg Std             66.4935
trainer/PolicyLossWithoutReg Max            420.427
trainer/PolicyLossWithoutReg Min             -1.92547
exploration/num steps total              714000
exploration/num paths total                1494
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49987
exploration/Rewards Std                       1.07189
exploration/Rewards Max                       7.43029
exploration/Rewards Min                      -0.950745
exploration/Returns Mean                   4499.87
exploration/Returns Std                       0
exploration/Returns Max                    4499.87
exploration/Returns Min                    4499.87
exploration/Num Paths                         1
exploration/Average Returns                4499.87
evaluation_0/num steps total                  5.55027e+06
evaluation_0/num paths total               9159
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92455
evaluation_0/Rewards Std                      1.11259
evaluation_0/Rewards Max                      7.42509
evaluation_0/Rewards Min                     -0.674058
evaluation_0/Returns Mean                  4924.55
evaluation_0/Returns Std                     44.9061
evaluation_0/Returns Max                   4997.94
evaluation_0/Returns Min                   4837.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4924.55
time/epoch (s)                                0
time/total (s)                            10616.8
Epoch                                       709
---------------------------------------  ----------------
2022-11-16 19:11:51.856091 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 710 finished
---------------------------------------  ----------------
epoch                                       710
total_step                               715000
replay_pool/size                         715000
trainer/alpha                                 0.0605259
trainer/alpha_loss                           -0.503186
trainer/entropy                              -5.8206
trainer/qf_loss                              16.8038
trainer/policy_loss                        -339.8
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.152
trainer/entropy_penalty                      -0.352297
trainer/entropy_percentage                   -0.0010357
trainer/Q1Pred Mean                         339.743
trainer/Q1Pred Std                           59.627
trainer/Q1Pred Max                          421.272
trainer/Q1Pred Min                           41.0993
trainer/Q2Pred Mean                         339.423
trainer/Q2Pred Std                           59.688
trainer/Q2Pred Max                          419.071
trainer/Q2Pred Min                           53.6549
trainer/QTargetWithReg Mean                 338.882
trainer/QTargetWithReg Std                   59.5574
trainer/QTargetWithReg Max                  419.241
trainer/QTargetWithReg Min                   44.2402
trainer/PolicyLossWithoutReg Mean           340.152
trainer/PolicyLossWithoutReg Std             58.4553
trainer/PolicyLossWithoutReg Max            420.799
trainer/PolicyLossWithoutReg Min             45.5988
exploration/num steps total              715000
exploration/num paths total                1495
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56733
exploration/Rewards Std                       0.958735
exploration/Rewards Max                       6.69549
exploration/Rewards Min                      -0.781473
exploration/Returns Mean                   4567.33
exploration/Returns Std                       0
exploration/Returns Max                    4567.33
exploration/Returns Min                    4567.33
exploration/Num Paths                         1
exploration/Average Returns                4567.33
evaluation_0/num steps total                  5.55827e+06
evaluation_0/num paths total               9167
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89205
evaluation_0/Rewards Std                      1.06583
evaluation_0/Rewards Max                      7.70974
evaluation_0/Rewards Min                     -0.499322
evaluation_0/Returns Mean                  4892.05
evaluation_0/Returns Std                     49.3604
evaluation_0/Returns Max                   4978.3
evaluation_0/Returns Min                   4814.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4892.05
time/epoch (s)                                0
time/total (s)                            10628.8
Epoch                                       710
---------------------------------------  ----------------
2022-11-16 19:12:05.231218 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 711 finished
---------------------------------------  ----------------
epoch                                       711
total_step                               716000
replay_pool/size                         716000
trainer/alpha                                 0.0599019
trainer/alpha_loss                           -0.681677
trainer/entropy                              -5.75784
trainer/qf_loss                              18.6412
trainer/policy_loss                        -341.984
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.329
trainer/entropy_penalty                      -0.344905
trainer/entropy_percentage                   -0.00100753
trainer/Q1Pred Mean                         341.822
trainer/Q1Pred Std                           75.3712
trainer/Q1Pred Max                          422.504
trainer/Q1Pred Min                            8.32678
trainer/Q2Pred Mean                         341.354
trainer/Q2Pred Std                           75.5968
trainer/Q2Pred Max                          427.971
trainer/Q2Pred Min                           15.3762
trainer/QTargetWithReg Mean                 342.006
trainer/QTargetWithReg Std                   75.8524
trainer/QTargetWithReg Max                  426.041
trainer/QTargetWithReg Min                   11.5323
trainer/PolicyLossWithoutReg Mean           342.329
trainer/PolicyLossWithoutReg Std             74.818
trainer/PolicyLossWithoutReg Max            422.999
trainer/PolicyLossWithoutReg Min             10.2303
exploration/num steps total              716000
exploration/num paths total                1497
exploration/path length this epoch Mean     385
exploration/path length this epoch Std      299
exploration/path length this epoch Max      684
exploration/path length this epoch Min       86
exploration/Rewards Mean                      3.90985
exploration/Rewards Std                       1.43836
exploration/Rewards Max                       7.34499
exploration/Rewards Min                      -1.00545
exploration/Returns Mean                   1505.29
exploration/Returns Std                    1304.27
exploration/Returns Max                    2809.57
exploration/Returns Min                     201.018
exploration/Num Paths                         2
exploration/Average Returns                1505.29
evaluation_0/num steps total                  5.56627e+06
evaluation_0/num paths total               9175
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73822
evaluation_0/Rewards Std                      1.12302
evaluation_0/Rewards Max                      7.53662
evaluation_0/Rewards Min                     -0.660655
evaluation_0/Returns Mean                  4738.22
evaluation_0/Returns Std                     90.3125
evaluation_0/Returns Max                   4909.18
evaluation_0/Returns Min                   4609.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4738.22
time/epoch (s)                                0
time/total (s)                            10642.2
Epoch                                       711
---------------------------------------  ----------------
2022-11-16 19:12:16.649334 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 712 finished
---------------------------------------  ----------------
epoch                                       712
total_step                               717000
replay_pool/size                         717000
trainer/alpha                                 0.058779
trainer/alpha_loss                           -0.492816
trainer/entropy                              -5.82611
trainer/qf_loss                              17.5095
trainer/policy_loss                        -339.182
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.525
trainer/entropy_penalty                      -0.342453
trainer/entropy_percentage                   -0.00100862
trainer/Q1Pred Mean                         337.858
trainer/Q1Pred Std                           71.5743
trainer/Q1Pred Max                          424.423
trainer/Q1Pred Min                           -1.28791
trainer/Q2Pred Mean                         337.761
trainer/Q2Pred Std                           71.2322
trainer/Q2Pred Max                          424.961
trainer/Q2Pred Min                            2.70942
trainer/QTargetWithReg Mean                 338.286
trainer/QTargetWithReg Std                   71.881
trainer/QTargetWithReg Max                  425.68
trainer/QTargetWithReg Min                    3.53927
trainer/PolicyLossWithoutReg Mean           339.525
trainer/PolicyLossWithoutReg Std             71.0614
trainer/PolicyLossWithoutReg Max            425.995
trainer/PolicyLossWithoutReg Min              4.25913
exploration/num steps total              717000
exploration/num paths total                1498
exploration/path length this epoch Mean     723
exploration/path length this epoch Std        0
exploration/path length this epoch Max      723
exploration/path length this epoch Min      723
exploration/Rewards Mean                      4.19787
exploration/Rewards Std                       1.04313
exploration/Rewards Max                       7.09347
exploration/Rewards Min                      -0.697978
exploration/Returns Mean                   3035.06
exploration/Returns Std                       0
exploration/Returns Max                    3035.06
exploration/Returns Min                    3035.06
exploration/Num Paths                         1
exploration/Average Returns                3035.06
evaluation_0/num steps total                  5.57427e+06
evaluation_0/num paths total               9183
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75664
evaluation_0/Rewards Std                      1.09074
evaluation_0/Rewards Max                      7.40431
evaluation_0/Rewards Min                     -1.01942
evaluation_0/Returns Mean                  4756.64
evaluation_0/Returns Std                     54.5555
evaluation_0/Returns Max                   4842.78
evaluation_0/Returns Min                   4662.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4756.64
time/epoch (s)                                0
time/total (s)                            10653.6
Epoch                                       712
---------------------------------------  ----------------
2022-11-16 19:12:27.866165 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 713 finished
---------------------------------------  ----------------
epoch                                       713
total_step                               718000
replay_pool/size                         718000
trainer/alpha                                 0.0589797
trainer/alpha_loss                            0.472013
trainer/entropy                              -6.16676
trainer/qf_loss                              27.395
trainer/policy_loss                        -342.339
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.702
trainer/entropy_penalty                      -0.363713
trainer/entropy_percentage                   -0.00106131
trainer/Q1Pred Mean                         342.555
trainer/Q1Pred Std                           63.6248
trainer/Q1Pred Max                          420.839
trainer/Q1Pred Min                           31.7926
trainer/Q2Pred Mean                         342.215
trainer/Q2Pred Std                           63.9141
trainer/Q2Pred Max                          418.509
trainer/Q2Pred Min                            8.89352
trainer/QTargetWithReg Mean                 341.908
trainer/QTargetWithReg Std                   63.9383
trainer/QTargetWithReg Max                  420.299
trainer/QTargetWithReg Min                   22.4502
trainer/PolicyLossWithoutReg Mean           342.702
trainer/PolicyLossWithoutReg Std             63.4233
trainer/PolicyLossWithoutReg Max            419.558
trainer/PolicyLossWithoutReg Min             19.1471
exploration/num steps total              718000
exploration/num paths total                1499
exploration/path length this epoch Mean      33
exploration/path length this epoch Std        0
exploration/path length this epoch Max       33
exploration/path length this epoch Min       33
exploration/Rewards Mean                      0.941615
exploration/Rewards Std                       1.10357
exploration/Rewards Max                       2.59026
exploration/Rewards Min                      -1.01298
exploration/Returns Mean                     31.0733
exploration/Returns Std                       0
exploration/Returns Max                      31.0733
exploration/Returns Min                      31.0733
exploration/Num Paths                         1
exploration/Average Returns                  31.0733
evaluation_0/num steps total                  5.58227e+06
evaluation_0/num paths total               9191
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66388
evaluation_0/Rewards Std                      1.08309
evaluation_0/Rewards Max                      7.37131
evaluation_0/Rewards Min                     -0.672167
evaluation_0/Returns Mean                  4663.88
evaluation_0/Returns Std                    105.687
evaluation_0/Returns Max                   4815.4
evaluation_0/Returns Min                   4474.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4663.88
time/epoch (s)                                0
time/total (s)                            10664.8
Epoch                                       713
---------------------------------------  ----------------
2022-11-16 19:12:42.310584 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 714 finished
---------------------------------------  ----------------
epoch                                       714
total_step                               719000
replay_pool/size                         719000
trainer/alpha                                 0.0589861
trainer/alpha_loss                           -1.93693
trainer/entropy                              -5.31568
trainer/qf_loss                              26.6781
trainer/policy_loss                        -343.464
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.778
trainer/entropy_penalty                      -0.313551
trainer/entropy_percentage                   -0.000912075
trainer/Q1Pred Mean                         343.767
trainer/Q1Pred Std                           67.3497
trainer/Q1Pred Max                          433.327
trainer/Q1Pred Min                            0.780228
trainer/Q2Pred Mean                         342.909
trainer/Q2Pred Std                           68.0381
trainer/Q2Pred Max                          431.991
trainer/Q2Pred Min                           -0.479951
trainer/QTargetWithReg Mean                 343.635
trainer/QTargetWithReg Std                   67.2421
trainer/QTargetWithReg Max                  431.389
trainer/QTargetWithReg Min                    4.06429
trainer/PolicyLossWithoutReg Mean           343.778
trainer/PolicyLossWithoutReg Std             67.1359
trainer/PolicyLossWithoutReg Max            432.098
trainer/PolicyLossWithoutReg Min             -1.26432
exploration/num steps total              719000
exploration/num paths total                1500
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45169
exploration/Rewards Std                       0.986591
exploration/Rewards Max                       7.10719
exploration/Rewards Min                      -0.719701
exploration/Returns Mean                   4451.69
exploration/Returns Std                       0
exploration/Returns Max                    4451.69
exploration/Returns Min                    4451.69
exploration/Num Paths                         1
exploration/Average Returns                4451.69
evaluation_0/num steps total                  5.59027e+06
evaluation_0/num paths total               9199
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74321
evaluation_0/Rewards Std                      1.10191
evaluation_0/Rewards Max                      7.70448
evaluation_0/Rewards Min                     -1.00731
evaluation_0/Returns Mean                  4743.21
evaluation_0/Returns Std                     51.3258
evaluation_0/Returns Max                   4822.15
evaluation_0/Returns Min                   4665.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4743.21
time/epoch (s)                                0
time/total (s)                            10679.2
Epoch                                       714
---------------------------------------  ----------------
2022-11-16 19:12:54.081082 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 715 finished
---------------------------------------  ----------------
epoch                                       715
total_step                               720000
replay_pool/size                         720000
trainer/alpha                                 0.0595916
trainer/alpha_loss                           -1.0511
trainer/entropy                              -5.62732
trainer/qf_loss                              19.887
trainer/policy_loss                        -339.222
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.558
trainer/entropy_penalty                      -0.335341
trainer/entropy_percentage                   -0.000987582
trainer/Q1Pred Mean                         338.401
trainer/Q1Pred Std                           67.5609
trainer/Q1Pred Max                          426.833
trainer/Q1Pred Min                           11.1586
trainer/Q2Pred Mean                         338.251
trainer/Q2Pred Std                           67.7425
trainer/Q2Pred Max                          421.873
trainer/Q2Pred Min                            7.88067
trainer/QTargetWithReg Mean                 338.365
trainer/QTargetWithReg Std                   68.0718
trainer/QTargetWithReg Max                  424.143
trainer/QTargetWithReg Min                    0.58619
trainer/PolicyLossWithoutReg Mean           339.558
trainer/PolicyLossWithoutReg Std             65.5401
trainer/PolicyLossWithoutReg Max            422.489
trainer/PolicyLossWithoutReg Min             10.2695
exploration/num steps total              720000
exploration/num paths total                1501
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49652
exploration/Rewards Std                       1.08129
exploration/Rewards Max                       7.02781
exploration/Rewards Min                      -0.804416
exploration/Returns Mean                   4496.52
exploration/Returns Std                       0
exploration/Returns Max                    4496.52
exploration/Returns Min                    4496.52
exploration/Num Paths                         1
exploration/Average Returns                4496.52
evaluation_0/num steps total                  5.59827e+06
evaluation_0/num paths total               9207
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71906
evaluation_0/Rewards Std                      1.08631
evaluation_0/Rewards Max                      7.58177
evaluation_0/Rewards Min                     -0.993285
evaluation_0/Returns Mean                  4719.06
evaluation_0/Returns Std                     92.7052
evaluation_0/Returns Max                   4838.02
evaluation_0/Returns Min                   4589.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4719.06
time/epoch (s)                                0
time/total (s)                            10691
Epoch                                       715
---------------------------------------  ----------------
2022-11-16 19:13:06.877749 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 716 finished
---------------------------------------  ----------------
epoch                                       716
total_step                               721000
replay_pool/size                         721000
trainer/alpha                                 0.0620217
trainer/alpha_loss                            0.441503
trainer/entropy                              -6.15878
trainer/qf_loss                              22.3728
trainer/policy_loss                        -340.902
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.284
trainer/entropy_penalty                      -0.381978
trainer/entropy_percentage                   -0.00111924
trainer/Q1Pred Mean                         339.707
trainer/Q1Pred Std                           71.9445
trainer/Q1Pred Max                          424.146
trainer/Q1Pred Min                          -29.9598
trainer/Q2Pred Mean                         340.018
trainer/Q2Pred Std                           71.8387
trainer/Q2Pred Max                          425.269
trainer/Q2Pred Min                          -21.8041
trainer/QTargetWithReg Mean                 340.473
trainer/QTargetWithReg Std                   72.2867
trainer/QTargetWithReg Max                  426.393
trainer/QTargetWithReg Min                  -27.962
trainer/PolicyLossWithoutReg Mean           341.284
trainer/PolicyLossWithoutReg Std             69.9949
trainer/PolicyLossWithoutReg Max            424.031
trainer/PolicyLossWithoutReg Min            -28.3511
exploration/num steps total              721000
exploration/num paths total                1502
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78994
exploration/Rewards Std                       1.16624
exploration/Rewards Max                       7.35862
exploration/Rewards Min                      -0.864443
exploration/Returns Mean                   4789.94
exploration/Returns Std                       0
exploration/Returns Max                    4789.94
exploration/Returns Min                    4789.94
exploration/Num Paths                         1
exploration/Average Returns                4789.94
evaluation_0/num steps total                  5.60612e+06
evaluation_0/num paths total               9215
evaluation_0/path length Mean               981.375
evaluation_0/path length Std                 49.2771
evaluation_0/path length Max               1000
evaluation_0/path length Min                851
evaluation_0/Rewards Mean                     4.84003
evaluation_0/Rewards Std                      1.17496
evaluation_0/Rewards Max                      7.74152
evaluation_0/Rewards Min                     -0.843459
evaluation_0/Returns Mean                  4749.89
evaluation_0/Returns Std                    360.818
evaluation_0/Returns Max                   4994.06
evaluation_0/Returns Min                   3808.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4749.89
time/epoch (s)                                0
time/total (s)                            10703.8
Epoch                                       716
---------------------------------------  ----------------
2022-11-16 19:13:20.580948 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 717 finished
---------------------------------------  ----------------
epoch                                       717
total_step                               722000
replay_pool/size                         722000
trainer/alpha                                 0.0619307
trainer/alpha_loss                            1.11138
trainer/entropy                              -6.3995
trainer/qf_loss                              24.8565
trainer/policy_loss                        -341.255
trainer/adversary_policy_loss                16.1823
trainer/policy_loss_without_entropy         341.651
trainer/entropy_penalty                      -0.396326
trainer/entropy_percentage                   -0.00116003
trainer/Q1Pred Mean                         341.204
trainer/Q1Pred Std                           72.8022
trainer/Q1Pred Max                          425.582
trainer/Q1Pred Min                            5.19149
trainer/Q2Pred Mean                         340.662
trainer/Q2Pred Std                           73.0523
trainer/Q2Pred Max                          425.314
trainer/Q2Pred Min                           -4.04448
trainer/QTargetWithReg Mean                 340.831
trainer/QTargetWithReg Std                   73.33
trainer/QTargetWithReg Max                  426.317
trainer/QTargetWithReg Min                   -2.07606
trainer/PolicyLossWithoutReg Mean           341.651
trainer/PolicyLossWithoutReg Std             71.7573
trainer/PolicyLossWithoutReg Max            423.194
trainer/PolicyLossWithoutReg Min              7.19987
exploration/num steps total              722000
exploration/num paths total                1503
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57421
exploration/Rewards Std                       1.0716
exploration/Rewards Max                       7.19151
exploration/Rewards Min                      -0.765631
exploration/Returns Mean                   4574.21
exploration/Returns Std                       0
exploration/Returns Max                    4574.21
exploration/Returns Min                    4574.21
exploration/Num Paths                         1
exploration/Average Returns                4574.21
evaluation_0/num steps total                  5.61412e+06
evaluation_0/num paths total               9223
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70062
evaluation_0/Rewards Std                      1.04676
evaluation_0/Rewards Max                      7.44734
evaluation_0/Rewards Min                     -0.985964
evaluation_0/Returns Mean                  4700.62
evaluation_0/Returns Std                    104.127
evaluation_0/Returns Max                   4873.28
evaluation_0/Returns Min                   4517.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4700.62
time/epoch (s)                                0
time/total (s)                            10717.5
Epoch                                       717
---------------------------------------  ----------------
2022-11-16 19:13:31.817571 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 718 finished
---------------------------------------  ----------------
epoch                                       718
total_step                               723000
replay_pool/size                         723000
trainer/alpha                                 0.0609349
trainer/alpha_loss                           -0.122451
trainer/entropy                              -5.95623
trainer/qf_loss                              32.125
trainer/policy_loss                        -339.776
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.139
trainer/entropy_penalty                      -0.362943
trainer/entropy_percentage                   -0.00106704
trainer/Q1Pred Mean                         340.209
trainer/Q1Pred Std                           71.0842
trainer/Q1Pred Max                          436.33
trainer/Q1Pred Min                            9.13646
trainer/Q2Pred Mean                         340.637
trainer/Q2Pred Std                           70.8318
trainer/Q2Pred Max                          434.537
trainer/Q2Pred Min                           21.2074
trainer/QTargetWithReg Mean                 340.703
trainer/QTargetWithReg Std                   70.7483
trainer/QTargetWithReg Max                  436.065
trainer/QTargetWithReg Min                   16.809
trainer/PolicyLossWithoutReg Mean           340.139
trainer/PolicyLossWithoutReg Std             70.2881
trainer/PolicyLossWithoutReg Max            433.1
trainer/PolicyLossWithoutReg Min             16.2415
exploration/num steps total              723000
exploration/num paths total                1504
exploration/path length this epoch Mean     435
exploration/path length this epoch Std        0
exploration/path length this epoch Max      435
exploration/path length this epoch Min      435
exploration/Rewards Mean                      3.90636
exploration/Rewards Std                       1.2612
exploration/Rewards Max                       6.83486
exploration/Rewards Min                      -1.02802
exploration/Returns Mean                   1699.27
exploration/Returns Std                       0
exploration/Returns Max                    1699.27
exploration/Returns Min                    1699.27
exploration/Num Paths                         1
exploration/Average Returns                1699.27
evaluation_0/num steps total                  5.62212e+06
evaluation_0/num paths total               9231
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85156
evaluation_0/Rewards Std                      1.11182
evaluation_0/Rewards Max                      7.59671
evaluation_0/Rewards Min                     -0.834868
evaluation_0/Returns Mean                  4851.56
evaluation_0/Returns Std                     66.14
evaluation_0/Returns Max                   4953.14
evaluation_0/Returns Min                   4731.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4851.56
time/epoch (s)                                0
time/total (s)                            10728.7
Epoch                                       718
---------------------------------------  ----------------
2022-11-16 19:13:43.497336 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 719 finished
---------------------------------------  ----------------
epoch                                       719
total_step                               724000
replay_pool/size                         724000
trainer/alpha                                 0.0597954
trainer/alpha_loss                            0.088545
trainer/entropy                              -6.03144
trainer/qf_loss                              30.4607
trainer/policy_loss                        -341.747
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.108
trainer/entropy_penalty                      -0.360652
trainer/entropy_percentage                   -0.0010542
trainer/Q1Pred Mean                         339.77
trainer/Q1Pred Std                           74.379
trainer/Q1Pred Max                          425.009
trainer/Q1Pred Min                          -16.3252
trainer/Q2Pred Mean                         338.924
trainer/Q2Pred Std                           75.7023
trainer/Q2Pred Max                          423.07
trainer/Q2Pred Min                          -34.3107
trainer/QTargetWithReg Mean                 339.577
trainer/QTargetWithReg Std                   74.1689
trainer/QTargetWithReg Max                  423.768
trainer/QTargetWithReg Min                   -0.562052
trainer/PolicyLossWithoutReg Mean           342.108
trainer/PolicyLossWithoutReg Std             68.0074
trainer/PolicyLossWithoutReg Max            423.135
trainer/PolicyLossWithoutReg Min             -1.70697
exploration/num steps total              724000
exploration/num paths total                1505
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43832
exploration/Rewards Std                       1.18616
exploration/Rewards Max                       6.86339
exploration/Rewards Min                      -1.09348
exploration/Returns Mean                   4438.32
exploration/Returns Std                       0
exploration/Returns Max                    4438.32
exploration/Returns Min                    4438.32
exploration/Num Paths                         1
exploration/Average Returns                4438.32
evaluation_0/num steps total                  5.63012e+06
evaluation_0/num paths total               9239
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83685
evaluation_0/Rewards Std                      1.11515
evaluation_0/Rewards Max                      7.68811
evaluation_0/Rewards Min                     -0.819068
evaluation_0/Returns Mean                  4836.85
evaluation_0/Returns Std                     29.4054
evaluation_0/Returns Max                   4876.56
evaluation_0/Returns Min                   4776.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.85
time/epoch (s)                                0
time/total (s)                            10740.4
Epoch                                       719
---------------------------------------  ----------------
2022-11-16 19:13:57.358326 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 720 finished
---------------------------------------  ----------------
epoch                                       720
total_step                               725000
replay_pool/size                         725000
trainer/alpha                                 0.0602309
trainer/alpha_loss                           -1.49449
trainer/entropy                              -5.46803
trainer/qf_loss                              17.5856
trainer/policy_loss                        -342.257
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.586
trainer/entropy_penalty                      -0.329344
trainer/entropy_percentage                   -0.000961348
trainer/Q1Pred Mean                         341.409
trainer/Q1Pred Std                           68.7468
trainer/Q1Pred Max                          426.367
trainer/Q1Pred Min                            6.72892
trainer/Q2Pred Mean                         341.625
trainer/Q2Pred Std                           68.74
trainer/Q2Pred Max                          427.057
trainer/Q2Pred Min                            6.42064
trainer/QTargetWithReg Mean                 341.993
trainer/QTargetWithReg Std                   68.0391
trainer/QTargetWithReg Max                  426.835
trainer/QTargetWithReg Min                   10.5199
trainer/PolicyLossWithoutReg Mean           342.586
trainer/PolicyLossWithoutReg Std             68.2213
trainer/PolicyLossWithoutReg Max            427.145
trainer/PolicyLossWithoutReg Min              6.44215
exploration/num steps total              725000
exploration/num paths total                1506
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.34864
exploration/Rewards Std                       1.04716
exploration/Rewards Max                       6.99195
exploration/Rewards Min                      -0.581194
exploration/Returns Mean                   4348.64
exploration/Returns Std                       0
exploration/Returns Max                    4348.64
exploration/Returns Min                    4348.64
exploration/Num Paths                         1
exploration/Average Returns                4348.64
evaluation_0/num steps total                  5.63812e+06
evaluation_0/num paths total               9247
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62651
evaluation_0/Rewards Std                      1.03174
evaluation_0/Rewards Max                      7.43766
evaluation_0/Rewards Min                     -0.448247
evaluation_0/Returns Mean                  4626.51
evaluation_0/Returns Std                     64.3063
evaluation_0/Returns Max                   4679.84
evaluation_0/Returns Min                   4471.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4626.51
time/epoch (s)                                0
time/total (s)                            10754.3
Epoch                                       720
---------------------------------------  ----------------
2022-11-16 19:14:09.358414 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 721 finished
---------------------------------------  ----------------
epoch                                       721
total_step                               726000
replay_pool/size                         726000
trainer/alpha                                 0.0577045
trainer/alpha_loss                            0.0349179
trainer/entropy                              -6.01224
trainer/qf_loss                              25.0153
trainer/policy_loss                        -341.627
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.974
trainer/entropy_penalty                      -0.346934
trainer/entropy_percentage                   -0.0010145
trainer/Q1Pred Mean                         341.492
trainer/Q1Pred Std                           67.9856
trainer/Q1Pred Max                          419.416
trainer/Q1Pred Min                            0.933126
trainer/Q2Pred Mean                         341.562
trainer/Q2Pred Std                           67.169
trainer/Q2Pred Max                          417.553
trainer/Q2Pred Min                            4.02732
trainer/QTargetWithReg Mean                 341.044
trainer/QTargetWithReg Std                   67.9964
trainer/QTargetWithReg Max                  419.797
trainer/QTargetWithReg Min                    4.55311
trainer/PolicyLossWithoutReg Mean           341.974
trainer/PolicyLossWithoutReg Std             65.9221
trainer/PolicyLossWithoutReg Max            417.636
trainer/PolicyLossWithoutReg Min             10.5402
exploration/num steps total              726000
exploration/num paths total                1507
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41915
exploration/Rewards Std                       1.00925
exploration/Rewards Max                       7.32294
exploration/Rewards Min                      -0.551746
exploration/Returns Mean                   4419.15
exploration/Returns Std                       0
exploration/Returns Max                    4419.15
exploration/Returns Min                    4419.15
exploration/Num Paths                         1
exploration/Average Returns                4419.15
evaluation_0/num steps total                  5.64612e+06
evaluation_0/num paths total               9255
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69025
evaluation_0/Rewards Std                      1.17674
evaluation_0/Rewards Max                      7.62085
evaluation_0/Rewards Min                     -1.04167
evaluation_0/Returns Mean                  4690.25
evaluation_0/Returns Std                     82.2633
evaluation_0/Returns Max                   4803.58
evaluation_0/Returns Min                   4544.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4690.25
time/epoch (s)                                0
time/total (s)                            10766.3
Epoch                                       721
---------------------------------------  ----------------
2022-11-16 19:14:20.627493 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 722 finished
---------------------------------------  ----------------
epoch                                       722
total_step                               727000
replay_pool/size                         727000
trainer/alpha                                 0.0585601
trainer/alpha_loss                            0.464291
trainer/entropy                              -6.16361
trainer/qf_loss                              19.1784
trainer/policy_loss                        -341.219
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.58
trainer/entropy_penalty                      -0.360941
trainer/entropy_percentage                   -0.00105668
trainer/Q1Pred Mean                         341.228
trainer/Q1Pred Std                           66.6706
trainer/Q1Pred Max                          419.392
trainer/Q1Pred Min                            4.33163
trainer/Q2Pred Mean                         340.959
trainer/Q2Pred Std                           67.0568
trainer/Q2Pred Max                          420.386
trainer/Q2Pred Min                            1.88535
trainer/QTargetWithReg Mean                 341.883
trainer/QTargetWithReg Std                   66.9927
trainer/QTargetWithReg Max                  419.225
trainer/QTargetWithReg Min                   -0.124064
trainer/PolicyLossWithoutReg Mean           341.58
trainer/PolicyLossWithoutReg Std             66.6634
trainer/PolicyLossWithoutReg Max            418.246
trainer/PolicyLossWithoutReg Min            -18.3468
exploration/num steps total              727000
exploration/num paths total                1508
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.33343
exploration/Rewards Std                       0.949802
exploration/Rewards Max                       6.88149
exploration/Rewards Min                      -1.17113
exploration/Returns Mean                   4333.43
exploration/Returns Std                       0
exploration/Returns Max                    4333.43
exploration/Returns Min                    4333.43
exploration/Num Paths                         1
exploration/Average Returns                4333.43
evaluation_0/num steps total                  5.65412e+06
evaluation_0/num paths total               9263
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7249
evaluation_0/Rewards Std                      1.06293
evaluation_0/Rewards Max                      7.6733
evaluation_0/Rewards Min                     -0.948975
evaluation_0/Returns Mean                  4724.9
evaluation_0/Returns Std                     31.4398
evaluation_0/Returns Max                   4770.8
evaluation_0/Returns Min                   4682.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4724.9
time/epoch (s)                                0
time/total (s)                            10777.6
Epoch                                       722
---------------------------------------  ----------------
2022-11-16 19:14:34.028244 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 723 finished
---------------------------------------  ----------------
epoch                                       723
total_step                               728000
replay_pool/size                         728000
trainer/alpha                                 0.0585837
trainer/alpha_loss                            0.468761
trainer/entropy                              -6.16521
trainer/qf_loss                              21.6531
trainer/policy_loss                        -339.76
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.121
trainer/entropy_penalty                      -0.361181
trainer/entropy_percentage                   -0.00106192
trainer/Q1Pred Mean                         339.679
trainer/Q1Pred Std                           65.6308
trainer/Q1Pred Max                          425.371
trainer/Q1Pred Min                           16.741
trainer/Q2Pred Mean                         339.62
trainer/Q2Pred Std                           65.4268
trainer/Q2Pred Max                          422.843
trainer/Q2Pred Min                           23.1698
trainer/QTargetWithReg Mean                 339.605
trainer/QTargetWithReg Std                   65.7356
trainer/QTargetWithReg Max                  420.946
trainer/QTargetWithReg Min                   19.2853
trainer/PolicyLossWithoutReg Mean           340.121
trainer/PolicyLossWithoutReg Std             64.5557
trainer/PolicyLossWithoutReg Max            424.164
trainer/PolicyLossWithoutReg Min             20.2765
exploration/num steps total              728000
exploration/num paths total                1509
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54078
exploration/Rewards Std                       1.17569
exploration/Rewards Max                       7.23679
exploration/Rewards Min                      -1.50525
exploration/Returns Mean                   4540.78
exploration/Returns Std                       0
exploration/Returns Max                    4540.78
exploration/Returns Min                    4540.78
exploration/Num Paths                         1
exploration/Average Returns                4540.78
evaluation_0/num steps total                  5.66212e+06
evaluation_0/num paths total               9271
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81172
evaluation_0/Rewards Std                      1.06599
evaluation_0/Rewards Max                      7.66846
evaluation_0/Rewards Min                     -0.999935
evaluation_0/Returns Mean                  4811.72
evaluation_0/Returns Std                     79.8619
evaluation_0/Returns Max                   4950.81
evaluation_0/Returns Min                   4694.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4811.72
time/epoch (s)                                0
time/total (s)                            10791
Epoch                                       723
---------------------------------------  ----------------
2022-11-16 19:14:45.382264 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 724 finished
---------------------------------------  ----------------
epoch                                       724
total_step                               729000
replay_pool/size                         729000
trainer/alpha                                 0.0591554
trainer/alpha_loss                           -0.362088
trainer/entropy                              -5.87195
trainer/qf_loss                              15.8457
trainer/policy_loss                        -345.374
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.722
trainer/entropy_penalty                      -0.347358
trainer/entropy_percentage                   -0.00100473
trainer/Q1Pred Mean                         345.567
trainer/Q1Pred Std                           58.8461
trainer/Q1Pred Max                          435.149
trainer/Q1Pred Min                          -14.3439
trainer/Q2Pred Mean                         344.858
trainer/Q2Pred Std                           59.1589
trainer/Q2Pred Max                          434.541
trainer/Q2Pred Min                          -19.7982
trainer/QTargetWithReg Mean                 344.743
trainer/QTargetWithReg Std                   59.9664
trainer/QTargetWithReg Max                  437.167
trainer/QTargetWithReg Min                  -45.7502
trainer/PolicyLossWithoutReg Mean           345.722
trainer/PolicyLossWithoutReg Std             58.0087
trainer/PolicyLossWithoutReg Max            434.568
trainer/PolicyLossWithoutReg Min            -25.3363
exploration/num steps total              729000
exploration/num paths total                1510
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49069
exploration/Rewards Std                       0.992745
exploration/Rewards Max                       7.06684
exploration/Rewards Min                      -1.00774
exploration/Returns Mean                   4490.69
exploration/Returns Std                       0
exploration/Returns Max                    4490.69
exploration/Returns Min                    4490.69
exploration/Num Paths                         1
exploration/Average Returns                4490.69
evaluation_0/num steps total                  5.67012e+06
evaluation_0/num paths total               9279
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63677
evaluation_0/Rewards Std                      0.973102
evaluation_0/Rewards Max                      7.34123
evaluation_0/Rewards Min                     -0.823557
evaluation_0/Returns Mean                  4636.77
evaluation_0/Returns Std                     78.2424
evaluation_0/Returns Max                   4798.43
evaluation_0/Returns Min                   4515.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4636.77
time/epoch (s)                                0
time/total (s)                            10802.3
Epoch                                       724
---------------------------------------  ----------------
2022-11-16 19:14:57.364302 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 725 finished
---------------------------------------  ----------------
epoch                                       725
total_step                               730000
replay_pool/size                         730000
trainer/alpha                                 0.0593572
trainer/alpha_loss                           -0.878511
trainer/entropy                              -5.68892
trainer/qf_loss                              33.0583
trainer/policy_loss                        -339.577
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.915
trainer/entropy_penalty                      -0.337679
trainer/entropy_percentage                   -0.000993422
trainer/Q1Pred Mean                         340.15
trainer/Q1Pred Std                           74.3418
trainer/Q1Pred Max                          420.437
trainer/Q1Pred Min                           -9.35705
trainer/Q2Pred Mean                         340.511
trainer/Q2Pred Std                           74.7806
trainer/Q2Pred Max                          424.442
trainer/Q2Pred Min                          -11.291
trainer/QTargetWithReg Mean                 338.771
trainer/QTargetWithReg Std                   74.4646
trainer/QTargetWithReg Max                  421.594
trainer/QTargetWithReg Min                   -4.70668
trainer/PolicyLossWithoutReg Mean           339.915
trainer/PolicyLossWithoutReg Std             74.4053
trainer/PolicyLossWithoutReg Max            420.907
trainer/PolicyLossWithoutReg Min             -5.67959
exploration/num steps total              730000
exploration/num paths total                1511
exploration/path length this epoch Mean     856
exploration/path length this epoch Std        0
exploration/path length this epoch Max      856
exploration/path length this epoch Min      856
exploration/Rewards Mean                      4.47894
exploration/Rewards Std                       1.08902
exploration/Rewards Max                       7.60911
exploration/Rewards Min                      -0.586302
exploration/Returns Mean                   3833.97
exploration/Returns Std                       0
exploration/Returns Max                    3833.97
exploration/Returns Min                    3833.97
exploration/Num Paths                         1
exploration/Average Returns                3833.97
evaluation_0/num steps total                  5.67812e+06
evaluation_0/num paths total               9287
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68286
evaluation_0/Rewards Std                      1.13906
evaluation_0/Rewards Max                      7.42168
evaluation_0/Rewards Min                     -0.855164
evaluation_0/Returns Mean                  4682.86
evaluation_0/Returns Std                    158.724
evaluation_0/Returns Max                   4836.76
evaluation_0/Returns Min                   4292.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4682.86
time/epoch (s)                                0
time/total (s)                            10814.3
Epoch                                       725
---------------------------------------  ----------------
2022-11-16 19:15:10.114074 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 726 finished
---------------------------------------  ----------------
epoch                                       726
total_step                               731000
replay_pool/size                         731000
trainer/alpha                                 0.0593197
trainer/alpha_loss                            0.19695
trainer/entropy                              -6.06972
trainer/qf_loss                              29.0844
trainer/policy_loss                        -350.649
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.009
trainer/entropy_penalty                      -0.360054
trainer/entropy_percentage                   -0.00102577
trainer/Q1Pred Mean                         349.022
trainer/Q1Pred Std                           56.3781
trainer/Q1Pred Max                          420.598
trainer/Q1Pred Min                           16.6934
trainer/Q2Pred Mean                         349.361
trainer/Q2Pred Std                           56.6278
trainer/Q2Pred Max                          422.939
trainer/Q2Pred Min                            0.789982
trainer/QTargetWithReg Mean                 350.176
trainer/QTargetWithReg Std                   56.6224
trainer/QTargetWithReg Max                  420.655
trainer/QTargetWithReg Min                    8.84568
trainer/PolicyLossWithoutReg Mean           351.009
trainer/PolicyLossWithoutReg Std             55.551
trainer/PolicyLossWithoutReg Max            421.121
trainer/PolicyLossWithoutReg Min             16.1731
exploration/num steps total              731000
exploration/num paths total                1512
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.21866
exploration/Rewards Std                       1.13511
exploration/Rewards Max                       7.12223
exploration/Rewards Min                      -0.913708
exploration/Returns Mean                   4218.66
exploration/Returns Std                       0
exploration/Returns Max                    4218.66
exploration/Returns Min                    4218.66
exploration/Num Paths                         1
exploration/Average Returns                4218.66
evaluation_0/num steps total                  5.68612e+06
evaluation_0/num paths total               9295
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92101
evaluation_0/Rewards Std                      1.09648
evaluation_0/Rewards Max                      7.91826
evaluation_0/Rewards Min                     -0.830374
evaluation_0/Returns Mean                  4921.01
evaluation_0/Returns Std                     67.5245
evaluation_0/Returns Max                   5002.4
evaluation_0/Returns Min                   4822.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4921.01
time/epoch (s)                                0
time/total (s)                            10827
Epoch                                       726
---------------------------------------  ----------------
2022-11-16 19:15:22.057095 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 727 finished
---------------------------------------  ----------------
epoch                                       727
total_step                               732000
replay_pool/size                         732000
trainer/alpha                                 0.060913
trainer/alpha_loss                           -1.1281
trainer/entropy                              -5.59685
trainer/qf_loss                              17.8705
trainer/policy_loss                        -347.909
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.25
trainer/entropy_penalty                      -0.340921
trainer/entropy_percentage                   -0.000978953
trainer/Q1Pred Mean                         347.511
trainer/Q1Pred Std                           65.7029
trainer/Q1Pred Max                          425.119
trainer/Q1Pred Min                            2.041
trainer/Q2Pred Mean                         346.526
trainer/Q2Pred Std                           65.5534
trainer/Q2Pred Max                          422.601
trainer/Q2Pred Min                            2.66541
trainer/QTargetWithReg Mean                 347.63
trainer/QTargetWithReg Std                   65.9511
trainer/QTargetWithReg Max                  424.096
trainer/QTargetWithReg Min                   13.0938
trainer/PolicyLossWithoutReg Mean           348.25
trainer/PolicyLossWithoutReg Std             64.9774
trainer/PolicyLossWithoutReg Max            422.651
trainer/PolicyLossWithoutReg Min             -0.00540173
exploration/num steps total              732000
exploration/num paths total                1513
exploration/path length this epoch Mean     421
exploration/path length this epoch Std        0
exploration/path length this epoch Max      421
exploration/path length this epoch Min      421
exploration/Rewards Mean                      3.76389
exploration/Rewards Std                       1.1444
exploration/Rewards Max                       6.16138
exploration/Rewards Min                      -0.83886
exploration/Returns Mean                   1584.6
exploration/Returns Std                       0
exploration/Returns Max                    1584.6
exploration/Returns Min                    1584.6
exploration/Num Paths                         1
exploration/Average Returns                1584.6
evaluation_0/num steps total                  5.69412e+06
evaluation_0/num paths total               9303
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7156
evaluation_0/Rewards Std                      1.05802
evaluation_0/Rewards Max                      7.30657
evaluation_0/Rewards Min                     -0.944727
evaluation_0/Returns Mean                  4715.6
evaluation_0/Returns Std                     59.6603
evaluation_0/Returns Max                   4800.37
evaluation_0/Returns Min                   4606.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4715.6
time/epoch (s)                                0
time/total (s)                            10839
Epoch                                       727
---------------------------------------  ----------------
2022-11-16 19:15:33.671717 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 728 finished
---------------------------------------  ----------------
epoch                                       728
total_step                               733000
replay_pool/size                         733000
trainer/alpha                                 0.060693
trainer/alpha_loss                           -0.201685
trainer/entropy                              -5.92801
trainer/qf_loss                              21.8316
trainer/policy_loss                        -339.072
trainer/adversary_policy_loss                16.1724
trainer/policy_loss_without_entropy         339.432
trainer/entropy_penalty                      -0.359789
trainer/entropy_percentage                   -0.00105997
trainer/Q1Pred Mean                         338.027
trainer/Q1Pred Std                           71.3822
trainer/Q1Pred Max                          422.67
trainer/Q1Pred Min                            2.58888
trainer/Q2Pred Mean                         338.686
trainer/Q2Pred Std                           71.1137
trainer/Q2Pred Max                          423.393
trainer/Q2Pred Min                            9.12779
trainer/QTargetWithReg Mean                 338.964
trainer/QTargetWithReg Std                   71.0563
trainer/QTargetWithReg Max                  423.799
trainer/QTargetWithReg Min                    4.99064
trainer/PolicyLossWithoutReg Mean           339.432
trainer/PolicyLossWithoutReg Std             70.1473
trainer/PolicyLossWithoutReg Max            423.141
trainer/PolicyLossWithoutReg Min              3.93831
exploration/num steps total              733000
exploration/num paths total                1514
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.40725
exploration/Rewards Std                       1.24231
exploration/Rewards Max                       7.43073
exploration/Rewards Min                      -0.917751
exploration/Returns Mean                   4407.25
exploration/Returns Std                       0
exploration/Returns Max                    4407.25
exploration/Returns Min                    4407.25
exploration/Num Paths                         1
exploration/Average Returns                4407.25
evaluation_0/num steps total                  5.70212e+06
evaluation_0/num paths total               9311
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88568
evaluation_0/Rewards Std                      1.11618
evaluation_0/Rewards Max                      7.77939
evaluation_0/Rewards Min                     -0.85323
evaluation_0/Returns Mean                  4885.68
evaluation_0/Returns Std                     74.3851
evaluation_0/Returns Max                   4961.3
evaluation_0/Returns Min                   4731.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4885.68
time/epoch (s)                                0
time/total (s)                            10850.6
Epoch                                       728
---------------------------------------  ----------------
2022-11-16 19:15:46.356055 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 729 finished
---------------------------------------  ----------------
epoch                                       729
total_step                               734000
replay_pool/size                         734000
trainer/alpha                                 0.0584917
trainer/alpha_loss                           -0.150865
trainer/entropy                              -5.94686
trainer/qf_loss                              51.9391
trainer/policy_loss                        -339.931
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.279
trainer/entropy_penalty                      -0.347841
trainer/entropy_percentage                   -0.00102223
trainer/Q1Pred Mean                         338.686
trainer/Q1Pred Std                           70.1952
trainer/Q1Pred Max                          423.228
trainer/Q1Pred Min                           15.2883
trainer/Q2Pred Mean                         339.402
trainer/Q2Pred Std                           70.3359
trainer/Q2Pred Max                          426.507
trainer/Q2Pred Min                           21.4765
trainer/QTargetWithReg Mean                 339.919
trainer/QTargetWithReg Std                   70.6539
trainer/QTargetWithReg Max                  427.857
trainer/QTargetWithReg Min                   19.5604
trainer/PolicyLossWithoutReg Mean           340.279
trainer/PolicyLossWithoutReg Std             69.6298
trainer/PolicyLossWithoutReg Max            423.389
trainer/PolicyLossWithoutReg Min             14.6606
exploration/num steps total              734000
exploration/num paths total                1517
exploration/path length this epoch Mean     275.333
exploration/path length this epoch Std       83.906
exploration/path length this epoch Max      360
exploration/path length this epoch Min      161
exploration/Rewards Mean                      3.46742
exploration/Rewards Std                       1.39902
exploration/Rewards Max                       6.87077
exploration/Rewards Min                      -0.960262
exploration/Returns Mean                    954.697
exploration/Returns Std                     361.342
exploration/Returns Max                    1348.3
exploration/Returns Min                     475.652
exploration/Num Paths                         3
exploration/Average Returns                 954.697
evaluation_0/num steps total                  5.71012e+06
evaluation_0/num paths total               9319
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66627
evaluation_0/Rewards Std                      0.998543
evaluation_0/Rewards Max                      7.55072
evaluation_0/Rewards Min                     -0.811443
evaluation_0/Returns Mean                  4666.27
evaluation_0/Returns Std                    113.604
evaluation_0/Returns Max                   4947.02
evaluation_0/Returns Min                   4574.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4666.27
time/epoch (s)                                0
time/total (s)                            10863.3
Epoch                                       729
---------------------------------------  ----------------
2022-11-16 19:15:57.822228 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 730 finished
---------------------------------------  ----------------
epoch                                       730
total_step                               735000
replay_pool/size                         735000
trainer/alpha                                 0.0605384
trainer/alpha_loss                            1.05601
trainer/entropy                              -6.37654
trainer/qf_loss                              17.3085
trainer/policy_loss                        -341.445
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.831
trainer/entropy_penalty                      -0.386026
trainer/entropy_percentage                   -0.00112929
trainer/Q1Pred Mean                         340.688
trainer/Q1Pred Std                           69.8831
trainer/Q1Pred Max                          423.899
trainer/Q1Pred Min                           -6.69179
trainer/Q2Pred Mean                         341.34
trainer/Q2Pred Std                           70.4846
trainer/Q2Pred Max                          427.197
trainer/Q2Pred Min                          -25.8672
trainer/QTargetWithReg Mean                 341.152
trainer/QTargetWithReg Std                   69.6091
trainer/QTargetWithReg Max                  425.758
trainer/QTargetWithReg Min                   -3.11504
trainer/PolicyLossWithoutReg Mean           341.831
trainer/PolicyLossWithoutReg Std             66.5532
trainer/PolicyLossWithoutReg Max            422.37
trainer/PolicyLossWithoutReg Min             -2.41751
exploration/num steps total              735000
exploration/num paths total                1519
exploration/path length this epoch Mean     271.5
exploration/path length this epoch Std      251.5
exploration/path length this epoch Max      523
exploration/path length this epoch Min       20
exploration/Rewards Mean                      3.78079
exploration/Rewards Std                       1.65535
exploration/Rewards Max                       6.77182
exploration/Rewards Min                      -0.907645
exploration/Returns Mean                   1026.49
exploration/Returns Std                    1022.63
exploration/Returns Max                    2049.12
exploration/Returns Min                       3.85481
exploration/Num Paths                         2
exploration/Average Returns                1026.49
evaluation_0/num steps total                  5.71812e+06
evaluation_0/num paths total               9327
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.771
evaluation_0/Rewards Std                      1.10261
evaluation_0/Rewards Max                      7.63146
evaluation_0/Rewards Min                     -0.809133
evaluation_0/Returns Mean                  4771
evaluation_0/Returns Std                     87.942
evaluation_0/Returns Max                   4890.87
evaluation_0/Returns Min                   4590.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4771
time/epoch (s)                                0
time/total (s)                            10874.7
Epoch                                       730
---------------------------------------  ----------------
2022-11-16 19:16:09.442830 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 731 finished
---------------------------------------  ----------------
epoch                                       731
total_step                               736000
replay_pool/size                         736000
trainer/alpha                                 0.060197
trainer/alpha_loss                            0.66047
trainer/entropy                              -6.23503
trainer/qf_loss                              21.5795
trainer/policy_loss                        -333.022
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.397
trainer/entropy_penalty                      -0.37533
trainer/entropy_percentage                   -0.00112577
trainer/Q1Pred Mean                         331.78
trainer/Q1Pred Std                           72.316
trainer/Q1Pred Max                          430.003
trainer/Q1Pred Min                           -6.25502
trainer/Q2Pred Mean                         332.17
trainer/Q2Pred Std                           72.5547
trainer/Q2Pred Max                          430.311
trainer/Q2Pred Min                           -6.95667
trainer/QTargetWithReg Mean                 332.695
trainer/QTargetWithReg Std                   72.5846
trainer/QTargetWithReg Max                  429.635
trainer/QTargetWithReg Min                    4.00558
trainer/PolicyLossWithoutReg Mean           333.397
trainer/PolicyLossWithoutReg Std             70.8824
trainer/PolicyLossWithoutReg Max            429.957
trainer/PolicyLossWithoutReg Min             22.8089
exploration/num steps total              736000
exploration/num paths total                1521
exploration/path length this epoch Mean     373.5
exploration/path length this epoch Std      274.5
exploration/path length this epoch Max      648
exploration/path length this epoch Min       99
exploration/Rewards Mean                      4.28575
exploration/Rewards Std                       1.52157
exploration/Rewards Max                       7.39243
exploration/Rewards Min                      -0.698292
exploration/Returns Mean                   1600.73
exploration/Returns Std                    1374.05
exploration/Returns Max                    2974.78
exploration/Returns Min                     226.674
exploration/Num Paths                         2
exploration/Average Returns                1600.73
evaluation_0/num steps total                  5.72612e+06
evaluation_0/num paths total               9335
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93523
evaluation_0/Rewards Std                      1.09665
evaluation_0/Rewards Max                      8.08371
evaluation_0/Rewards Min                     -0.812825
evaluation_0/Returns Mean                  4935.23
evaluation_0/Returns Std                     86.4341
evaluation_0/Returns Max                   5087.93
evaluation_0/Returns Min                   4778.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4935.23
time/epoch (s)                                0
time/total (s)                            10886.4
Epoch                                       731
---------------------------------------  ----------------
2022-11-16 19:16:23.963681 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 732 finished
---------------------------------------  ---------------
epoch                                       732
total_step                               737000
replay_pool/size                         737000
trainer/alpha                                 0.0596753
trainer/alpha_loss                           -0.193746
trainer/entropy                              -5.93127
trainer/qf_loss                              23.1572
trainer/policy_loss                        -347.933
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.287
trainer/entropy_penalty                      -0.35395
trainer/entropy_percentage                   -0.00101626
trainer/Q1Pred Mean                         348.499
trainer/Q1Pred Std                           65.4111
trainer/Q1Pred Max                          438.262
trainer/Q1Pred Min                           -3.40618
trainer/Q2Pred Mean                         348.414
trainer/Q2Pred Std                           65.3689
trainer/Q2Pred Max                          440.224
trainer/Q2Pred Min                            0.928298
trainer/QTargetWithReg Mean                 347.089
trainer/QTargetWithReg Std                   65.3448
trainer/QTargetWithReg Max                  436.006
trainer/QTargetWithReg Min                    3.46172
trainer/PolicyLossWithoutReg Mean           348.287
trainer/PolicyLossWithoutReg Std             64.2271
trainer/PolicyLossWithoutReg Max            437.849
trainer/PolicyLossWithoutReg Min              2.39715
exploration/num steps total              737000
exploration/num paths total                1522
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49215
exploration/Rewards Std                       0.986678
exploration/Rewards Max                       6.92123
exploration/Rewards Min                      -0.542373
exploration/Returns Mean                   4492.15
exploration/Returns Std                       0
exploration/Returns Max                    4492.15
exploration/Returns Min                    4492.15
exploration/Num Paths                         1
exploration/Average Returns                4492.15
evaluation_0/num steps total                  5.7332e+06
evaluation_0/num paths total               9343
evaluation_0/path length Mean               884.5
evaluation_0/path length Std                305.584
evaluation_0/path length Max               1000
evaluation_0/path length Min                 76
evaluation_0/Rewards Mean                     4.73812
evaluation_0/Rewards Std                      1.08305
evaluation_0/Rewards Max                      7.4595
evaluation_0/Rewards Min                     -0.890495
evaluation_0/Returns Mean                  4190.87
evaluation_0/Returns Std                   1514.95
evaluation_0/Returns Max                   4852.71
evaluation_0/Returns Min                    186.241
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4190.87
time/epoch (s)                                0
time/total (s)                            10900.9
Epoch                                       732
---------------------------------------  ---------------
2022-11-16 19:16:35.022800 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 733 finished
---------------------------------------  ---------------
epoch                                       733
total_step                               738000
replay_pool/size                         738000
trainer/alpha                                 0.0623593
trainer/alpha_loss                            0.382533
trainer/entropy                              -6.13786
trainer/qf_loss                              18.2878
trainer/policy_loss                        -338.292
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.675
trainer/entropy_penalty                      -0.382752
trainer/entropy_percentage                   -0.00113015
trainer/Q1Pred Mean                         337.714
trainer/Q1Pred Std                           73.3582
trainer/Q1Pred Max                          432.974
trainer/Q1Pred Min                            4.01727
trainer/Q2Pred Mean                         337.464
trainer/Q2Pred Std                           73.4609
trainer/Q2Pred Max                          430.277
trainer/Q2Pred Min                           -6.43839
trainer/QTargetWithReg Mean                 337.256
trainer/QTargetWithReg Std                   73.1204
trainer/QTargetWithReg Max                  431.549
trainer/QTargetWithReg Min                    3.50687
trainer/PolicyLossWithoutReg Mean           338.675
trainer/PolicyLossWithoutReg Std             71.6386
trainer/PolicyLossWithoutReg Max            429.817
trainer/PolicyLossWithoutReg Min             -6.31881
exploration/num steps total              738000
exploration/num paths total                1523
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47783
exploration/Rewards Std                       1.06546
exploration/Rewards Max                       6.87201
exploration/Rewards Min                      -0.707671
exploration/Returns Mean                   4477.83
exploration/Returns Std                       0
exploration/Returns Max                    4477.83
exploration/Returns Min                    4477.83
exploration/Num Paths                         1
exploration/Average Returns                4477.83
evaluation_0/num steps total                  5.7412e+06
evaluation_0/num paths total               9351
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92785
evaluation_0/Rewards Std                      1.10103
evaluation_0/Rewards Max                      7.57733
evaluation_0/Rewards Min                     -0.681764
evaluation_0/Returns Mean                  4927.85
evaluation_0/Returns Std                     42.8567
evaluation_0/Returns Max                   5022.14
evaluation_0/Returns Min                   4890.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4927.85
time/epoch (s)                                0
time/total (s)                            10911.9
Epoch                                       733
---------------------------------------  ---------------
2022-11-16 19:16:46.879647 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 734 finished
---------------------------------------  ---------------
epoch                                       734
total_step                               739000
replay_pool/size                         739000
trainer/alpha                                 0.0621327
trainer/alpha_loss                            1.19645
trainer/entropy                              -6.43058
trainer/qf_loss                              31.6254
trainer/policy_loss                        -343.248
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.648
trainer/entropy_penalty                      -0.399549
trainer/entropy_percentage                   -0.00116267
trainer/Q1Pred Mean                         343.246
trainer/Q1Pred Std                           62.2651
trainer/Q1Pred Max                          430.783
trainer/Q1Pred Min                          -35.8028
trainer/Q2Pred Mean                         342.773
trainer/Q2Pred Std                           61.7628
trainer/Q2Pred Max                          429.944
trainer/Q2Pred Min                          -26.3289
trainer/QTargetWithReg Mean                 343.441
trainer/QTargetWithReg Std                   60.8737
trainer/QTargetWithReg Max                  427.868
trainer/QTargetWithReg Min                    0.545052
trainer/PolicyLossWithoutReg Mean           343.648
trainer/PolicyLossWithoutReg Std             60.9387
trainer/PolicyLossWithoutReg Max            430.253
trainer/PolicyLossWithoutReg Min             -7.40545
exploration/num steps total              739000
exploration/num paths total                1524
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50117
exploration/Rewards Std                       0.995616
exploration/Rewards Max                       6.76744
exploration/Rewards Min                      -0.819496
exploration/Returns Mean                   4501.17
exploration/Returns Std                       0
exploration/Returns Max                    4501.17
exploration/Returns Min                    4501.17
exploration/Num Paths                         1
exploration/Average Returns                4501.17
evaluation_0/num steps total                  5.7492e+06
evaluation_0/num paths total               9359
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9233
evaluation_0/Rewards Std                      1.10744
evaluation_0/Rewards Max                      7.68584
evaluation_0/Rewards Min                     -0.676604
evaluation_0/Returns Mean                  4923.3
evaluation_0/Returns Std                     79.0326
evaluation_0/Returns Max                   5011.66
evaluation_0/Returns Min                   4757.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4923.3
time/epoch (s)                                0
time/total (s)                            10923.8
Epoch                                       734
---------------------------------------  ---------------
2022-11-16 19:16:59.891691 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 735 finished
---------------------------------------  ---------------
epoch                                       735
total_step                               740000
replay_pool/size                         740000
trainer/alpha                                 0.0603887
trainer/alpha_loss                           -0.683525
trainer/entropy                              -5.75648
trainer/qf_loss                              35.8949
trainer/policy_loss                        -346.516
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.864
trainer/entropy_penalty                      -0.347626
trainer/entropy_percentage                   -0.0010022
trainer/Q1Pred Mean                         346.757
trainer/Q1Pred Std                           63.9266
trainer/Q1Pred Max                          422.149
trainer/Q1Pred Min                           28.6461
trainer/Q2Pred Mean                         346.551
trainer/Q2Pred Std                           64.3385
trainer/Q2Pred Max                          424.402
trainer/Q2Pred Min                           25.9318
trainer/QTargetWithReg Mean                 346.152
trainer/QTargetWithReg Std                   65.6406
trainer/QTargetWithReg Max                  420.957
trainer/QTargetWithReg Min                   23.2084
trainer/PolicyLossWithoutReg Mean           346.864
trainer/PolicyLossWithoutReg Std             63.7342
trainer/PolicyLossWithoutReg Max            423.115
trainer/PolicyLossWithoutReg Min             21.4046
exploration/num steps total              740000
exploration/num paths total                1525
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49429
exploration/Rewards Std                       0.962756
exploration/Rewards Max                       7.27998
exploration/Rewards Min                      -0.488669
exploration/Returns Mean                   4494.29
exploration/Returns Std                       0
exploration/Returns Max                    4494.29
exploration/Returns Min                    4494.29
exploration/Num Paths                         1
exploration/Average Returns                4494.29
evaluation_0/num steps total                  5.7572e+06
evaluation_0/num paths total               9367
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74058
evaluation_0/Rewards Std                      1.01695
evaluation_0/Rewards Max                      7.4623
evaluation_0/Rewards Min                     -0.6224
evaluation_0/Returns Mean                  4740.58
evaluation_0/Returns Std                     68.4671
evaluation_0/Returns Max                   4835.47
evaluation_0/Returns Min                   4628.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4740.58
time/epoch (s)                                0
time/total (s)                            10936.8
Epoch                                       735
---------------------------------------  ---------------
2022-11-16 19:17:13.479565 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 736 finished
---------------------------------------  ----------------
epoch                                       736
total_step                               741000
replay_pool/size                         741000
trainer/alpha                                 0.0609613
trainer/alpha_loss                           -1.34163
trainer/entropy                              -5.52042
trainer/qf_loss                              21.0017
trainer/policy_loss                        -345.655
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.991
trainer/entropy_penalty                      -0.336532
trainer/entropy_percentage                   -0.000972661
trainer/Q1Pred Mean                         345.993
trainer/Q1Pred Std                           64.853
trainer/Q1Pred Max                          426.053
trainer/Q1Pred Min                            9.14969
trainer/Q2Pred Mean                         345.645
trainer/Q2Pred Std                           65.0132
trainer/Q2Pred Max                          427.656
trainer/Q2Pred Min                            5.48997
trainer/QTargetWithReg Mean                 345.192
trainer/QTargetWithReg Std                   65.4775
trainer/QTargetWithReg Max                  427.483
trainer/QTargetWithReg Min                    3.52409
trainer/PolicyLossWithoutReg Mean           345.991
trainer/PolicyLossWithoutReg Std             63.945
trainer/PolicyLossWithoutReg Max            424.165
trainer/PolicyLossWithoutReg Min              7.22903
exploration/num steps total              741000
exploration/num paths total                1526
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43521
exploration/Rewards Std                       1.04218
exploration/Rewards Max                       6.56861
exploration/Rewards Min                      -0.690936
exploration/Returns Mean                   4435.21
exploration/Returns Std                       0
exploration/Returns Max                    4435.21
exploration/Returns Min                    4435.21
exploration/Num Paths                         1
exploration/Average Returns                4435.21
evaluation_0/num steps total                  5.76431e+06
evaluation_0/num paths total               9375
evaluation_0/path length Mean               888.75
evaluation_0/path length Std                294.34
evaluation_0/path length Max               1000
evaluation_0/path length Min                110
evaluation_0/Rewards Mean                     4.96515
evaluation_0/Rewards Std                      1.17179
evaluation_0/Rewards Max                      7.68246
evaluation_0/Rewards Min                     -0.622767
evaluation_0/Returns Mean                  4412.78
evaluation_0/Returns Std                   1545.38
evaluation_0/Returns Max                   5069.46
evaluation_0/Returns Min                    326.156
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4412.78
time/epoch (s)                                0
time/total (s)                            10950.4
Epoch                                       736
---------------------------------------  ----------------
2022-11-16 19:17:27.180034 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 737 finished
---------------------------------------  ----------------
epoch                                       737
total_step                               742000
replay_pool/size                         742000
trainer/alpha                                 0.0599806
trainer/alpha_loss                           -0.284946
trainer/entropy                              -5.89874
trainer/qf_loss                              23.3414
trainer/policy_loss                        -336.239
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         336.593
trainer/entropy_penalty                      -0.35381
trainer/entropy_percentage                   -0.00105115
trainer/Q1Pred Mean                         335.248
trainer/Q1Pred Std                           76.5723
trainer/Q1Pred Max                          427.346
trainer/Q1Pred Min                          -30.6261
trainer/Q2Pred Mean                         335.405
trainer/Q2Pred Std                           76.4954
trainer/Q2Pred Max                          428.16
trainer/Q2Pred Min                          -26.8464
trainer/QTargetWithReg Mean                 335.262
trainer/QTargetWithReg Std                   76.5605
trainer/QTargetWithReg Max                  431.897
trainer/QTargetWithReg Min                  -24.0539
trainer/PolicyLossWithoutReg Mean           336.592
trainer/PolicyLossWithoutReg Std             75.1093
trainer/PolicyLossWithoutReg Max            427.238
trainer/PolicyLossWithoutReg Min            -25.0538
exploration/num steps total              742000
exploration/num paths total                1529
exploration/path length this epoch Mean     274
exploration/path length this epoch Std       82.7083
exploration/path length this epoch Max      389
exploration/path length this epoch Min      198
exploration/Rewards Mean                      3.28571
exploration/Rewards Std                       1.24212
exploration/Rewards Max                       6.15088
exploration/Rewards Min                      -1.00637
exploration/Returns Mean                    900.284
exploration/Returns Std                     313.342
exploration/Returns Max                    1340.14
exploration/Returns Min                     633.777
exploration/Num Paths                         3
exploration/Average Returns                 900.284
evaluation_0/num steps total                  5.77231e+06
evaluation_0/num paths total               9383
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75211
evaluation_0/Rewards Std                      0.989693
evaluation_0/Rewards Max                      7.61737
evaluation_0/Rewards Min                     -0.607599
evaluation_0/Returns Mean                  4752.11
evaluation_0/Returns Std                     50.7568
evaluation_0/Returns Max                   4799.69
evaluation_0/Returns Min                   4649.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4752.11
time/epoch (s)                                0
time/total (s)                            10964.1
Epoch                                       737
---------------------------------------  ----------------
2022-11-16 19:17:39.883903 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 738 finished
---------------------------------------  ----------------
epoch                                       738
total_step                               743000
replay_pool/size                         743000
trainer/alpha                                 0.0598144
trainer/alpha_loss                            1.09229
trainer/entropy                              -6.3878
trainer/qf_loss                              25.4808
trainer/policy_loss                        -343.579
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.961
trainer/entropy_penalty                      -0.382083
trainer/entropy_percentage                   -0.00111083
trainer/Q1Pred Mean                         342.534
trainer/Q1Pred Std                           64.1354
trainer/Q1Pred Max                          424.601
trainer/Q1Pred Min                           30.2234
trainer/Q2Pred Mean                         341.811
trainer/Q2Pred Std                           64.2416
trainer/Q2Pred Max                          422.197
trainer/Q2Pred Min                           29.1047
trainer/QTargetWithReg Mean                 343.335
trainer/QTargetWithReg Std                   63.4629
trainer/QTargetWithReg Max                  423.852
trainer/QTargetWithReg Min                   29.9543
trainer/PolicyLossWithoutReg Mean           343.961
trainer/PolicyLossWithoutReg Std             62.6965
trainer/PolicyLossWithoutReg Max            422.607
trainer/PolicyLossWithoutReg Min             35.0406
exploration/num steps total              743000
exploration/num paths total                1530
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64225
exploration/Rewards Std                       1.10582
exploration/Rewards Max                       7.02127
exploration/Rewards Min                      -0.636854
exploration/Returns Mean                   4642.25
exploration/Returns Std                       0
exploration/Returns Max                    4642.25
exploration/Returns Min                    4642.25
exploration/Num Paths                         1
exploration/Average Returns                4642.25
evaluation_0/num steps total                  5.77944e+06
evaluation_0/num paths total               9391
evaluation_0/path length Mean               890.625
evaluation_0/path length Std                236.904
evaluation_0/path length Max               1000
evaluation_0/path length Min                278
evaluation_0/Rewards Mean                     4.66864
evaluation_0/Rewards Std                      1.02523
evaluation_0/Rewards Max                      7.65905
evaluation_0/Rewards Min                     -0.561586
evaluation_0/Returns Mean                  4158
evaluation_0/Returns Std                   1190.26
evaluation_0/Returns Max                   4788.43
evaluation_0/Returns Min                   1072.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4158
time/epoch (s)                                0
time/total (s)                            10976.8
Epoch                                       738
---------------------------------------  ----------------
2022-11-16 19:17:51.150644 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 739 finished
---------------------------------------  ----------------
epoch                                       739
total_step                               744000
replay_pool/size                         744000
trainer/alpha                                 0.0599237
trainer/alpha_loss                           -0.966263
trainer/entropy                              -5.65671
trainer/qf_loss                              33.2005
trainer/policy_loss                        -342.546
trainer/adversary_policy_loss                16.4297
trainer/policy_loss_without_entropy         342.885
trainer/entropy_penalty                      -0.338971
trainer/entropy_percentage                   -0.000988585
trainer/Q1Pred Mean                         342.147
trainer/Q1Pred Std                           65.9678
trainer/Q1Pred Max                          425.036
trainer/Q1Pred Min                           -5.88849
trainer/Q2Pred Mean                         341.872
trainer/Q2Pred Std                           65.9434
trainer/Q2Pred Max                          424.418
trainer/Q2Pred Min                           -9.63595
trainer/QTargetWithReg Mean                 342.396
trainer/QTargetWithReg Std                   65.8149
trainer/QTargetWithReg Max                  423.422
trainer/QTargetWithReg Min                  -20.7136
trainer/PolicyLossWithoutReg Mean           342.885
trainer/PolicyLossWithoutReg Std             64.6256
trainer/PolicyLossWithoutReg Max            425.609
trainer/PolicyLossWithoutReg Min            -10.6684
exploration/num steps total              744000
exploration/num paths total                1531
exploration/path length this epoch Mean     165
exploration/path length this epoch Std        0
exploration/path length this epoch Max      165
exploration/path length this epoch Min      165
exploration/Rewards Mean                      2.79144
exploration/Rewards Std                       1.3052
exploration/Rewards Max                       5.77774
exploration/Rewards Min                      -0.536081
exploration/Returns Mean                    460.588
exploration/Returns Std                       0
exploration/Returns Max                     460.588
exploration/Returns Min                     460.588
exploration/Num Paths                         1
exploration/Average Returns                 460.588
evaluation_0/num steps total                  5.78744e+06
evaluation_0/num paths total               9399
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88382
evaluation_0/Rewards Std                      1.04793
evaluation_0/Rewards Max                      7.65915
evaluation_0/Rewards Min                     -0.501503
evaluation_0/Returns Mean                  4883.82
evaluation_0/Returns Std                     70.9073
evaluation_0/Returns Max                   5012.37
evaluation_0/Returns Min                   4782.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4883.82
time/epoch (s)                                0
time/total (s)                            10988.1
Epoch                                       739
---------------------------------------  ----------------
2022-11-16 19:18:05.834637 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 740 finished
---------------------------------------  ----------------
epoch                                       740
total_step                               745000
replay_pool/size                         745000
trainer/alpha                                 0.0591466
trainer/alpha_loss                           -0.223359
trainer/entropy                              -5.92101
trainer/qf_loss                              21.5263
trainer/policy_loss                        -342.865
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.215
trainer/entropy_penalty                      -0.350208
trainer/entropy_percentage                   -0.00102037
trainer/Q1Pred Mean                         340.649
trainer/Q1Pred Std                           69.9548
trainer/Q1Pred Max                          423.205
trainer/Q1Pred Min                          -39.6305
trainer/Q2Pred Mean                         341.099
trainer/Q2Pred Std                           70.2076
trainer/Q2Pred Max                          426.113
trainer/Q2Pred Min                          -56.4754
trainer/QTargetWithReg Mean                 340.666
trainer/QTargetWithReg Std                   69.7866
trainer/QTargetWithReg Max                  425.664
trainer/QTargetWithReg Min                  -30.8592
trainer/PolicyLossWithoutReg Mean           343.215
trainer/PolicyLossWithoutReg Std             67.4215
trainer/PolicyLossWithoutReg Max            425.896
trainer/PolicyLossWithoutReg Min              7.34833
exploration/num steps total              745000
exploration/num paths total                1532
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64053
exploration/Rewards Std                       1.07611
exploration/Rewards Max                       7.40133
exploration/Rewards Min                      -0.647805
exploration/Returns Mean                   4640.53
exploration/Returns Std                       0
exploration/Returns Max                    4640.53
exploration/Returns Min                    4640.53
exploration/Num Paths                         1
exploration/Average Returns                4640.53
evaluation_0/num steps total                  5.79489e+06
evaluation_0/num paths total               9407
evaluation_0/path length Mean               931.625
evaluation_0/path length Std                180.903
evaluation_0/path length Max               1000
evaluation_0/path length Min                453
evaluation_0/Rewards Mean                     4.84228
evaluation_0/Rewards Std                      1.07854
evaluation_0/Rewards Max                      7.66735
evaluation_0/Rewards Min                     -0.581214
evaluation_0/Returns Mean                  4511.19
evaluation_0/Returns Std                    938.609
evaluation_0/Returns Max                   4959.59
evaluation_0/Returns Min                   2032.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4511.19
time/epoch (s)                                0
time/total (s)                            11002.8
Epoch                                       740
---------------------------------------  ----------------
2022-11-16 19:18:17.969360 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 741 finished
---------------------------------------  ----------------
epoch                                       741
total_step                               746000
replay_pool/size                         746000
trainer/alpha                                 0.0597044
trainer/alpha_loss                            0.0769082
trainer/entropy                              -6.02729
trainer/qf_loss                              17.3321
trainer/policy_loss                        -352.286
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.645
trainer/entropy_penalty                      -0.359855
trainer/entropy_percentage                   -0.00102045
trainer/Q1Pred Mean                         351.674
trainer/Q1Pred Std                           55.109
trainer/Q1Pred Max                          438.401
trainer/Q1Pred Min                           19.7709
trainer/Q2Pred Mean                         352.033
trainer/Q2Pred Std                           55.1137
trainer/Q2Pred Max                          437.33
trainer/Q2Pred Min                           32.1509
trainer/QTargetWithReg Mean                 351.873
trainer/QTargetWithReg Std                   55.1586
trainer/QTargetWithReg Max                  436.741
trainer/QTargetWithReg Min                   14.2534
trainer/PolicyLossWithoutReg Mean           352.645
trainer/PolicyLossWithoutReg Std             54.0412
trainer/PolicyLossWithoutReg Max            437.283
trainer/PolicyLossWithoutReg Min             32.3334
exploration/num steps total              746000
exploration/num paths total                1533
exploration/path length this epoch Mean     628
exploration/path length this epoch Std        0
exploration/path length this epoch Max      628
exploration/path length this epoch Min      628
exploration/Rewards Mean                      4.24296
exploration/Rewards Std                       1.17665
exploration/Rewards Max                       7.27646
exploration/Rewards Min                      -0.523997
exploration/Returns Mean                   2664.58
exploration/Returns Std                       0
exploration/Returns Max                    2664.58
exploration/Returns Min                    2664.58
exploration/Num Paths                         1
exploration/Average Returns                2664.58
evaluation_0/num steps total                  5.80289e+06
evaluation_0/num paths total               9415
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76887
evaluation_0/Rewards Std                      1.09409
evaluation_0/Rewards Max                      7.60832
evaluation_0/Rewards Min                     -0.709666
evaluation_0/Returns Mean                  4768.87
evaluation_0/Returns Std                     75.433
evaluation_0/Returns Max                   4867.53
evaluation_0/Returns Min                   4628.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4768.87
time/epoch (s)                                0
time/total (s)                            11014.9
Epoch                                       741
---------------------------------------  ----------------
2022-11-16 19:18:29.311743 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 742 finished
---------------------------------------  ----------------
epoch                                       742
total_step                               747000
replay_pool/size                         747000
trainer/alpha                                 0.0599003
trainer/alpha_loss                            0.573363
trainer/entropy                              -6.20369
trainer/qf_loss                              46.3816
trainer/policy_loss                        -339.697
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.069
trainer/entropy_penalty                      -0.371603
trainer/entropy_percentage                   -0.00109273
trainer/Q1Pred Mean                         339.046
trainer/Q1Pred Std                           75.2993
trainer/Q1Pred Max                          425.976
trainer/Q1Pred Min                          -86.8774
trainer/Q2Pred Mean                         339.123
trainer/Q2Pred Std                           74.2549
trainer/Q2Pred Max                          426.092
trainer/Q2Pred Min                          -50.7609
trainer/QTargetWithReg Mean                 339.263
trainer/QTargetWithReg Std                   73.8142
trainer/QTargetWithReg Max                  425.825
trainer/QTargetWithReg Min                   -2.02007
trainer/PolicyLossWithoutReg Mean           340.068
trainer/PolicyLossWithoutReg Std             74.1948
trainer/PolicyLossWithoutReg Max            426.059
trainer/PolicyLossWithoutReg Min            -80.2145
exploration/num steps total              747000
exploration/num paths total                1534
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68966
exploration/Rewards Std                       0.972107
exploration/Rewards Max                       7.25776
exploration/Rewards Min                      -0.577343
exploration/Returns Mean                   4689.66
exploration/Returns Std                       0
exploration/Returns Max                    4689.66
exploration/Returns Min                    4689.66
exploration/Num Paths                         1
exploration/Average Returns                4689.66
evaluation_0/num steps total                  5.81089e+06
evaluation_0/num paths total               9423
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.56274
evaluation_0/Rewards Std                      1.05014
evaluation_0/Rewards Max                      7.42598
evaluation_0/Rewards Min                     -0.504692
evaluation_0/Returns Mean                  4562.74
evaluation_0/Returns Std                     71.937
evaluation_0/Returns Max                   4662.16
evaluation_0/Returns Min                   4419.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4562.74
time/epoch (s)                                0
time/total (s)                            11026.2
Epoch                                       742
---------------------------------------  ----------------
2022-11-16 19:18:42.653865 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 743 finished
---------------------------------------  ----------------
epoch                                       743
total_step                               748000
replay_pool/size                         748000
trainer/alpha                                 0.0596572
trainer/alpha_loss                           -1.26981
trainer/entropy                              -5.54958
trainer/qf_loss                              19.4802
trainer/policy_loss                        -343.227
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.558
trainer/entropy_penalty                      -0.331072
trainer/entropy_percentage                   -0.000963657
trainer/Q1Pred Mean                         342.657
trainer/Q1Pred Std                           66.1267
trainer/Q1Pred Max                          426.267
trainer/Q1Pred Min                          -25.7732
trainer/Q2Pred Mean                         342.261
trainer/Q2Pred Std                           65.9538
trainer/Q2Pred Max                          425.116
trainer/Q2Pred Min                          -16.9868
trainer/QTargetWithReg Mean                 342.836
trainer/QTargetWithReg Std                   66.2409
trainer/QTargetWithReg Max                  426.473
trainer/QTargetWithReg Min                   -8.87467
trainer/PolicyLossWithoutReg Mean           343.558
trainer/PolicyLossWithoutReg Std             65.193
trainer/PolicyLossWithoutReg Max            425.427
trainer/PolicyLossWithoutReg Min            -23.0318
exploration/num steps total              748000
exploration/num paths total                1535
exploration/path length this epoch Mean      23
exploration/path length this epoch Std        0
exploration/path length this epoch Max       23
exploration/path length this epoch Min       23
exploration/Rewards Mean                      0.297856
exploration/Rewards Std                       0.542535
exploration/Rewards Max                       1.32474
exploration/Rewards Min                      -0.920211
exploration/Returns Mean                      6.85068
exploration/Returns Std                       0
exploration/Returns Max                       6.85068
exploration/Returns Min                       6.85068
exploration/Num Paths                         1
exploration/Average Returns                   6.85068
evaluation_0/num steps total                  5.81889e+06
evaluation_0/num paths total               9431
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88664
evaluation_0/Rewards Std                      1.12544
evaluation_0/Rewards Max                      7.8366
evaluation_0/Rewards Min                     -0.564945
evaluation_0/Returns Mean                  4886.64
evaluation_0/Returns Std                     78.4067
evaluation_0/Returns Max                   5015
evaluation_0/Returns Min                   4798.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4886.64
time/epoch (s)                                0
time/total (s)                            11039.6
Epoch                                       743
---------------------------------------  ----------------
2022-11-16 19:18:53.856489 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 744 finished
---------------------------------------  ----------------
epoch                                       744
total_step                               749000
replay_pool/size                         749000
trainer/alpha                                 0.0612982
trainer/alpha_loss                            2.09868
trainer/entropy                              -6.75163
trainer/qf_loss                              21.2713
trainer/policy_loss                        -336.232
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         336.646
trainer/entropy_penalty                      -0.413863
trainer/entropy_percentage                   -0.00122937
trainer/Q1Pred Mean                         335.456
trainer/Q1Pred Std                           71.351
trainer/Q1Pred Max                          416.601
trainer/Q1Pred Min                            5.63631
trainer/Q2Pred Mean                         336.401
trainer/Q2Pred Std                           71.2672
trainer/Q2Pred Max                          419.449
trainer/Q2Pred Min                            7.15053
trainer/QTargetWithReg Mean                 336.486
trainer/QTargetWithReg Std                   72.1871
trainer/QTargetWithReg Max                  417.707
trainer/QTargetWithReg Min                    0.480657
trainer/PolicyLossWithoutReg Mean           336.646
trainer/PolicyLossWithoutReg Std             69.9425
trainer/PolicyLossWithoutReg Max            418.48
trainer/PolicyLossWithoutReg Min              6.40275
exploration/num steps total              749000
exploration/num paths total                1536
exploration/path length this epoch Mean     354
exploration/path length this epoch Std        0
exploration/path length this epoch Max      354
exploration/path length this epoch Min      354
exploration/Rewards Mean                      4.04726
exploration/Rewards Std                       1.28122
exploration/Rewards Max                       6.72972
exploration/Rewards Min                      -0.690842
exploration/Returns Mean                   1432.73
exploration/Returns Std                       0
exploration/Returns Max                    1432.73
exploration/Returns Min                    1432.73
exploration/Num Paths                         1
exploration/Average Returns                1432.73
evaluation_0/num steps total                  5.82689e+06
evaluation_0/num paths total               9439
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81608
evaluation_0/Rewards Std                      1.14427
evaluation_0/Rewards Max                      7.94364
evaluation_0/Rewards Min                     -0.554954
evaluation_0/Returns Mean                  4816.08
evaluation_0/Returns Std                     67.8939
evaluation_0/Returns Max                   4926.12
evaluation_0/Returns Min                   4698.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4816.08
time/epoch (s)                                0
time/total (s)                            11050.8
Epoch                                       744
---------------------------------------  ----------------
2022-11-16 19:19:05.095709 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 745 finished
---------------------------------------  ----------------
epoch                                       745
total_step                               750000
replay_pool/size                         750000
trainer/alpha                                 0.0586107
trainer/alpha_loss                           -1.01625
trainer/entropy                              -5.64175
trainer/qf_loss                              25.0828
trainer/policy_loss                        -346.99
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.32
trainer/entropy_penalty                      -0.330667
trainer/entropy_percentage                   -0.000952052
trainer/Q1Pred Mean                         347.379
trainer/Q1Pred Std                           58.2335
trainer/Q1Pred Max                          426.118
trainer/Q1Pred Min                           32.1122
trainer/Q2Pred Mean                         347.734
trainer/Q2Pred Std                           58.7635
trainer/Q2Pred Max                          426.631
trainer/Q2Pred Min                           28.0005
trainer/QTargetWithReg Mean                 346.633
trainer/QTargetWithReg Std                   60.1151
trainer/QTargetWithReg Max                  425.305
trainer/QTargetWithReg Min                   21.2546
trainer/PolicyLossWithoutReg Mean           347.32
trainer/PolicyLossWithoutReg Std             57.7524
trainer/PolicyLossWithoutReg Max            425.921
trainer/PolicyLossWithoutReg Min             39.4431
exploration/num steps total              750000
exploration/num paths total                1537
exploration/path length this epoch Mean      79
exploration/path length this epoch Std        0
exploration/path length this epoch Max       79
exploration/path length this epoch Min       79
exploration/Rewards Mean                      2.22827
exploration/Rewards Std                       1.32255
exploration/Rewards Max                       4.69324
exploration/Rewards Min                      -0.609935
exploration/Returns Mean                    176.034
exploration/Returns Std                       0
exploration/Returns Max                     176.034
exploration/Returns Min                     176.034
exploration/Num Paths                         1
exploration/Average Returns                 176.034
evaluation_0/num steps total                  5.83489e+06
evaluation_0/num paths total               9447
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75519
evaluation_0/Rewards Std                      1.14903
evaluation_0/Rewards Max                      7.52576
evaluation_0/Rewards Min                     -0.568314
evaluation_0/Returns Mean                  4755.19
evaluation_0/Returns Std                     84.5767
evaluation_0/Returns Max                   4918.08
evaluation_0/Returns Min                   4662.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4755.19
time/epoch (s)                                0
time/total (s)                            11062
Epoch                                       745
---------------------------------------  ----------------
2022-11-16 19:19:16.940458 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 746 finished
---------------------------------------  ----------------
epoch                                       746
total_step                               751000
replay_pool/size                         751000
trainer/alpha                                 0.0583282
trainer/alpha_loss                            0.472886
trainer/entropy                              -6.16641
trainer/qf_loss                              24.7627
trainer/policy_loss                        -339.495
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.854
trainer/entropy_penalty                      -0.359676
trainer/entropy_percentage                   -0.00105832
trainer/Q1Pred Mean                         339.341
trainer/Q1Pred Std                           79.7267
trainer/Q1Pred Max                          430.97
trainer/Q1Pred Min                           12.8139
trainer/Q2Pred Mean                         339.533
trainer/Q2Pred Std                           79.1693
trainer/Q2Pred Max                          429.209
trainer/Q2Pred Min                           11.3903
trainer/QTargetWithReg Mean                 338.604
trainer/QTargetWithReg Std                   79.3614
trainer/QTargetWithReg Max                  431.95
trainer/QTargetWithReg Min                   16.0126
trainer/PolicyLossWithoutReg Mean           339.854
trainer/PolicyLossWithoutReg Std             78.5989
trainer/PolicyLossWithoutReg Max            427.904
trainer/PolicyLossWithoutReg Min             17.3162
exploration/num steps total              751000
exploration/num paths total                1538
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44236
exploration/Rewards Std                       1.13352
exploration/Rewards Max                       7.09138
exploration/Rewards Min                      -0.621259
exploration/Returns Mean                   4442.36
exploration/Returns Std                       0
exploration/Returns Max                    4442.36
exploration/Returns Min                    4442.36
exploration/Num Paths                         1
exploration/Average Returns                4442.36
evaluation_0/num steps total                  5.84289e+06
evaluation_0/num paths total               9455
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96412
evaluation_0/Rewards Std                      1.09723
evaluation_0/Rewards Max                      7.59323
evaluation_0/Rewards Min                     -0.612368
evaluation_0/Returns Mean                  4964.12
evaluation_0/Returns Std                     64.4143
evaluation_0/Returns Max                   5034.94
evaluation_0/Returns Min                   4840.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4964.12
time/epoch (s)                                0
time/total (s)                            11073.9
Epoch                                       746
---------------------------------------  ----------------
2022-11-16 19:19:28.327030 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 747 finished
---------------------------------------  ----------------
epoch                                       747
total_step                               752000
replay_pool/size                         752000
trainer/alpha                                 0.0607156
trainer/alpha_loss                           -0.328818
trainer/entropy                              -5.88263
trainer/qf_loss                              18.4832
trainer/policy_loss                        -339.373
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.73
trainer/entropy_penalty                      -0.357167
trainer/entropy_percentage                   -0.00105133
trainer/Q1Pred Mean                         339.25
trainer/Q1Pred Std                           69.931
trainer/Q1Pred Max                          422.069
trainer/Q1Pred Min                          -18.8063
trainer/Q2Pred Mean                         339.237
trainer/Q2Pred Std                           70.1489
trainer/Q2Pred Max                          420.979
trainer/Q2Pred Min                          -26.2856
trainer/QTargetWithReg Mean                 338.963
trainer/QTargetWithReg Std                   70.5649
trainer/QTargetWithReg Max                  422.038
trainer/QTargetWithReg Min                  -20.1866
trainer/PolicyLossWithoutReg Mean           339.73
trainer/PolicyLossWithoutReg Std             69.4059
trainer/PolicyLossWithoutReg Max            420.596
trainer/PolicyLossWithoutReg Min            -24.2965
exploration/num steps total              752000
exploration/num paths total                1539
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50758
exploration/Rewards Std                       1.01519
exploration/Rewards Max                       7.06768
exploration/Rewards Min                      -0.724979
exploration/Returns Mean                   4507.58
exploration/Returns Std                       0
exploration/Returns Max                    4507.58
exploration/Returns Min                    4507.58
exploration/Num Paths                         1
exploration/Average Returns                4507.58
evaluation_0/num steps total                  5.85089e+06
evaluation_0/num paths total               9463
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71612
evaluation_0/Rewards Std                      1.14179
evaluation_0/Rewards Max                      7.85083
evaluation_0/Rewards Min                     -0.635432
evaluation_0/Returns Mean                  4716.12
evaluation_0/Returns Std                     95.0886
evaluation_0/Returns Max                   4899.93
evaluation_0/Returns Min                   4569.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4716.12
time/epoch (s)                                0
time/total (s)                            11085.2
Epoch                                       747
---------------------------------------  ----------------
2022-11-16 19:19:39.097480 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 748 finished
---------------------------------------  ----------------
epoch                                       748
total_step                               753000
replay_pool/size                         753000
trainer/alpha                                 0.0619477
trainer/alpha_loss                            0.129765
trainer/entropy                              -6.04665
trainer/qf_loss                              21.6761
trainer/policy_loss                        -345.008
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.382
trainer/entropy_penalty                      -0.374576
trainer/entropy_percentage                   -0.00108453
trainer/Q1Pred Mean                         344.342
trainer/Q1Pred Std                           62.6469
trainer/Q1Pred Max                          426.167
trainer/Q1Pred Min                           41.0679
trainer/Q2Pred Mean                         343.799
trainer/Q2Pred Std                           62.9668
trainer/Q2Pred Max                          425.306
trainer/Q2Pred Min                           40.6421
trainer/QTargetWithReg Mean                 343.814
trainer/QTargetWithReg Std                   63.6355
trainer/QTargetWithReg Max                  427.221
trainer/QTargetWithReg Min                   39.3933
trainer/PolicyLossWithoutReg Mean           345.382
trainer/PolicyLossWithoutReg Std             61.8737
trainer/PolicyLossWithoutReg Max            424.899
trainer/PolicyLossWithoutReg Min             37.379
exploration/num steps total              753000
exploration/num paths total                1540
exploration/path length this epoch Mean     123
exploration/path length this epoch Std        0
exploration/path length this epoch Max      123
exploration/path length this epoch Min      123
exploration/Rewards Mean                      2.18895
exploration/Rewards Std                       1.19525
exploration/Rewards Max                       4.56967
exploration/Rewards Min                      -0.681915
exploration/Returns Mean                    269.241
exploration/Returns Std                       0
exploration/Returns Max                     269.241
exploration/Returns Min                     269.241
exploration/Num Paths                         1
exploration/Average Returns                 269.241
evaluation_0/num steps total                  5.85889e+06
evaluation_0/num paths total               9471
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90172
evaluation_0/Rewards Std                      1.20232
evaluation_0/Rewards Max                      7.65317
evaluation_0/Rewards Min                     -0.616783
evaluation_0/Returns Mean                  4901.72
evaluation_0/Returns Std                     69.8259
evaluation_0/Returns Max                   5005.26
evaluation_0/Returns Min                   4808.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4901.72
time/epoch (s)                                0
time/total (s)                            11096
Epoch                                       748
---------------------------------------  ----------------
2022-11-16 19:19:51.636783 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 749 finished
---------------------------------------  ----------------
epoch                                       749
total_step                               754000
replay_pool/size                         754000
trainer/alpha                                 0.0598908
trainer/alpha_loss                           -0.532836
trainer/entropy                              -5.81072
trainer/qf_loss                              23.5925
trainer/policy_loss                        -333.224
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         333.572
trainer/entropy_penalty                      -0.348008
trainer/entropy_percentage                   -0.00104328
trainer/Q1Pred Mean                         332.206
trainer/Q1Pred Std                           77.8586
trainer/Q1Pred Max                          426.796
trainer/Q1Pred Min                           15.5061
trainer/Q2Pred Mean                         332.744
trainer/Q2Pred Std                           77.7794
trainer/Q2Pred Max                          425.255
trainer/Q2Pred Min                           17.8661
trainer/QTargetWithReg Mean                 331.491
trainer/QTargetWithReg Std                   77.8376
trainer/QTargetWithReg Max                  423.772
trainer/QTargetWithReg Min                   13.5715
trainer/PolicyLossWithoutReg Mean           333.572
trainer/PolicyLossWithoutReg Std             76.4096
trainer/PolicyLossWithoutReg Max            424.903
trainer/PolicyLossWithoutReg Min             12.4161
exploration/num steps total              754000
exploration/num paths total                1541
exploration/path length this epoch Mean     747
exploration/path length this epoch Std        0
exploration/path length this epoch Max      747
exploration/path length this epoch Min      747
exploration/Rewards Mean                      4.43609
exploration/Rewards Std                       1.18018
exploration/Rewards Max                       7.00987
exploration/Rewards Min                      -0.611871
exploration/Returns Mean                   3313.76
exploration/Returns Std                       0
exploration/Returns Max                    3313.76
exploration/Returns Min                    3313.76
exploration/Num Paths                         1
exploration/Average Returns                3313.76
evaluation_0/num steps total                  5.86617e+06
evaluation_0/num paths total               9479
evaluation_0/path length Mean               910
evaluation_0/path length Std                238.118
evaluation_0/path length Max               1000
evaluation_0/path length Min                280
evaluation_0/Rewards Mean                     4.63649
evaluation_0/Rewards Std                      1.18709
evaluation_0/Rewards Max                      7.55175
evaluation_0/Rewards Min                     -0.808338
evaluation_0/Returns Mean                  4219.2
evaluation_0/Returns Std                   1180.38
evaluation_0/Returns Max                   4795.8
evaluation_0/Returns Min                   1117.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4219.2
time/epoch (s)                                0
time/total (s)                            11108.6
Epoch                                       749
---------------------------------------  ----------------
2022-11-16 19:20:47.982312 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 750 finished
---------------------------------------  ----------------
epoch                                       750
total_step                               755000
replay_pool/size                         755000
trainer/alpha                                 0.061087
trainer/alpha_loss                            1.93642
trainer/entropy                              -6.69267
trainer/qf_loss                              44.8516
trainer/policy_loss                        -336.855
trainer/adversary_policy_loss                15.8804
trainer/policy_loss_without_entropy         337.264
trainer/entropy_penalty                      -0.408835
trainer/entropy_percentage                   -0.00121221
trainer/Q1Pred Mean                         336.961
trainer/Q1Pred Std                           68.8358
trainer/Q1Pred Max                          433.378
trainer/Q1Pred Min                           14.1678
trainer/Q2Pred Mean                         336.319
trainer/Q2Pred Std                           70.0158
trainer/Q2Pred Max                          432.332
trainer/Q2Pred Min                           12.3568
trainer/QTargetWithReg Mean                 336.372
trainer/QTargetWithReg Std                   70.3115
trainer/QTargetWithReg Max                  432.989
trainer/QTargetWithReg Min                   16.4236
trainer/PolicyLossWithoutReg Mean           337.264
trainer/PolicyLossWithoutReg Std             68.8778
trainer/PolicyLossWithoutReg Max            432.716
trainer/PolicyLossWithoutReg Min             14.4666
exploration/num steps total              755000
exploration/num paths total                1542
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.2754
exploration/Rewards Std                       1.0908
exploration/Rewards Max                       6.82245
exploration/Rewards Min                      -0.767898
exploration/Returns Mean                   4275.4
exploration/Returns Std                       0
exploration/Returns Max                    4275.4
exploration/Returns Min                    4275.4
exploration/Num Paths                         1
exploration/Average Returns                4275.4
evaluation_0/num steps total                  5.87417e+06
evaluation_0/num paths total               9487
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84852
evaluation_0/Rewards Std                      1.1432
evaluation_0/Rewards Max                      7.94256
evaluation_0/Rewards Min                     -0.445444
evaluation_0/Returns Mean                  4848.52
evaluation_0/Returns Std                     77.8806
evaluation_0/Returns Max                   4995.92
evaluation_0/Returns Min                   4779.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4848.52
time/epoch (s)                                0
time/total (s)                            11164.9
Epoch                                       750
---------------------------------------  ----------------
2022-11-16 19:21:59.631956 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 751 finished
---------------------------------------  ----------------
epoch                                       751
total_step                               756000
replay_pool/size                         756000
trainer/alpha                                 0.0610045
trainer/alpha_loss                           -1.1975
trainer/entropy                              -5.57184
trainer/qf_loss                              18.0897
trainer/policy_loss                        -342.811
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.151
trainer/entropy_penalty                      -0.339907
trainer/entropy_percentage                   -0.000990546
trainer/Q1Pred Mean                         341.849
trainer/Q1Pred Std                           68.9661
trainer/Q1Pred Max                          427.927
trainer/Q1Pred Min                           42.9909
trainer/Q2Pred Mean                         342.124
trainer/Q2Pred Std                           68.968
trainer/Q2Pred Max                          425.296
trainer/Q2Pred Min                           42.7349
trainer/QTargetWithReg Mean                 341.549
trainer/QTargetWithReg Std                   68.9917
trainer/QTargetWithReg Max                  422.696
trainer/QTargetWithReg Min                   42.0136
trainer/PolicyLossWithoutReg Mean           343.151
trainer/PolicyLossWithoutReg Std             68.0387
trainer/PolicyLossWithoutReg Max            424.222
trainer/PolicyLossWithoutReg Min             42.8701
exploration/num steps total              756000
exploration/num paths total                1543
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59986
exploration/Rewards Std                       1.19791
exploration/Rewards Max                       6.86433
exploration/Rewards Min                      -0.954963
exploration/Returns Mean                   4599.86
exploration/Returns Std                       0
exploration/Returns Max                    4599.86
exploration/Returns Min                    4599.86
exploration/Num Paths                         1
exploration/Average Returns                4599.86
evaluation_0/num steps total                  5.88217e+06
evaluation_0/num paths total               9495
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88154
evaluation_0/Rewards Std                      1.07083
evaluation_0/Rewards Max                      7.55535
evaluation_0/Rewards Min                     -0.62388
evaluation_0/Returns Mean                  4881.54
evaluation_0/Returns Std                     41.1404
evaluation_0/Returns Max                   4931.15
evaluation_0/Returns Min                   4831.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4881.54
time/epoch (s)                                0
time/total (s)                            11236.6
Epoch                                       751
---------------------------------------  ----------------
2022-11-16 19:23:28.472040 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 752 finished
---------------------------------------  ----------------
epoch                                       752
total_step                               757000
replay_pool/size                         757000
trainer/alpha                                 0.0617313
trainer/alpha_loss                           -0.960388
trainer/entropy                              -5.65512
trainer/qf_loss                              15.2275
trainer/policy_loss                        -339.974
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.323
trainer/entropy_penalty                      -0.349098
trainer/entropy_percentage                   -0.00102578
trainer/Q1Pred Mean                         339.293
trainer/Q1Pred Std                           62.5798
trainer/Q1Pred Max                          427.361
trainer/Q1Pred Min                           38.6284
trainer/Q2Pred Mean                         339.485
trainer/Q2Pred Std                           62.8928
trainer/Q2Pred Max                          425.297
trainer/Q2Pred Min                           39.5471
trainer/QTargetWithReg Mean                 339.029
trainer/QTargetWithReg Std                   63.3319
trainer/QTargetWithReg Max                  424.678
trainer/QTargetWithReg Min                   41.0654
trainer/PolicyLossWithoutReg Mean           340.323
trainer/PolicyLossWithoutReg Std             61.987
trainer/PolicyLossWithoutReg Max            426.988
trainer/PolicyLossWithoutReg Min             36.9369
exploration/num steps total              757000
exploration/num paths total                1544
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45768
exploration/Rewards Std                       1.08873
exploration/Rewards Max                       6.76907
exploration/Rewards Min                      -0.502855
exploration/Returns Mean                   4457.68
exploration/Returns Std                       0
exploration/Returns Max                    4457.68
exploration/Returns Min                    4457.68
exploration/Num Paths                         1
exploration/Average Returns                4457.68
evaluation_0/num steps total                  5.88952e+06
evaluation_0/num paths total               9503
evaluation_0/path length Mean               919
evaluation_0/path length Std                214.306
evaluation_0/path length Max               1000
evaluation_0/path length Min                352
evaluation_0/Rewards Mean                     4.72092
evaluation_0/Rewards Std                      1.0986
evaluation_0/Rewards Max                      7.53997
evaluation_0/Rewards Min                     -0.518951
evaluation_0/Returns Mean                  4338.52
evaluation_0/Returns Std                   1137.09
evaluation_0/Returns Max                   4883.13
evaluation_0/Returns Min                   1341.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4338.52
time/epoch (s)                                0
time/total (s)                            11325.4
Epoch                                       752
---------------------------------------  ----------------
2022-11-16 19:24:35.529072 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 753 finished
---------------------------------------  ----------------
epoch                                       753
total_step                               758000
replay_pool/size                         758000
trainer/alpha                                 0.0614171
trainer/alpha_loss                            0.0575974
trainer/entropy                              -6.02064
trainer/qf_loss                              26.3485
trainer/policy_loss                        -342.539
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.909
trainer/entropy_penalty                      -0.36977
trainer/entropy_percentage                   -0.00107833
trainer/Q1Pred Mean                         342.57
trainer/Q1Pred Std                           69.0126
trainer/Q1Pred Max                          427.706
trainer/Q1Pred Min                          -22.2092
trainer/Q2Pred Mean                         342.652
trainer/Q2Pred Std                           68.6702
trainer/Q2Pred Max                          427.572
trainer/Q2Pred Min                           -9.397
trainer/QTargetWithReg Mean                 341.569
trainer/QTargetWithReg Std                   68.968
trainer/QTargetWithReg Max                  427.06
trainer/QTargetWithReg Min                  -24.9668
trainer/PolicyLossWithoutReg Mean           342.909
trainer/PolicyLossWithoutReg Std             68.4887
trainer/PolicyLossWithoutReg Max            423.895
trainer/PolicyLossWithoutReg Min            -24.9625
exploration/num steps total              758000
exploration/num paths total                1546
exploration/path length this epoch Mean     435
exploration/path length this epoch Std      155
exploration/path length this epoch Max      590
exploration/path length this epoch Min      280
exploration/Rewards Mean                      4.04308
exploration/Rewards Std                       1.30271
exploration/Rewards Max                       8.09442
exploration/Rewards Min                      -0.903624
exploration/Returns Mean                   1758.74
exploration/Returns Std                     778.057
exploration/Returns Max                    2536.8
exploration/Returns Min                     980.682
exploration/Num Paths                         2
exploration/Average Returns                1758.74
evaluation_0/num steps total                  5.89752e+06
evaluation_0/num paths total               9511
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78637
evaluation_0/Rewards Std                      1.14779
evaluation_0/Rewards Max                      7.72674
evaluation_0/Rewards Min                     -0.735134
evaluation_0/Returns Mean                  4786.37
evaluation_0/Returns Std                    118.508
evaluation_0/Returns Max                   4957.57
evaluation_0/Returns Min                   4526.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4786.37
time/epoch (s)                                0
time/total (s)                            11392.5
Epoch                                       753
---------------------------------------  ----------------
2022-11-16 19:25:43.262498 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 754 finished
---------------------------------------  ----------------
epoch                                       754
total_step                               759000
replay_pool/size                         759000
trainer/alpha                                 0.0611827
trainer/alpha_loss                            1.00447
trainer/entropy                              -6.35953
trainer/qf_loss                              23.8562
trainer/policy_loss                        -334.822
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         335.211
trainer/entropy_penalty                      -0.389093
trainer/entropy_percentage                   -0.00116074
trainer/Q1Pred Mean                         334.072
trainer/Q1Pred Std                           77.4804
trainer/Q1Pred Max                          423.692
trainer/Q1Pred Min                           26.4305
trainer/Q2Pred Mean                         333.59
trainer/Q2Pred Std                           76.907
trainer/Q2Pred Max                          420.574
trainer/Q2Pred Min                           25.8785
trainer/QTargetWithReg Mean                 335.243
trainer/QTargetWithReg Std                   78.0358
trainer/QTargetWithReg Max                  427.304
trainer/QTargetWithReg Min                   25.0392
trainer/PolicyLossWithoutReg Mean           335.211
trainer/PolicyLossWithoutReg Std             76.6848
trainer/PolicyLossWithoutReg Max            421.408
trainer/PolicyLossWithoutReg Min             25.9235
exploration/num steps total              759000
exploration/num paths total                1547
exploration/path length this epoch Mean     671
exploration/path length this epoch Std        0
exploration/path length this epoch Max      671
exploration/path length this epoch Min      671
exploration/Rewards Mean                      4.47559
exploration/Rewards Std                       1.08859
exploration/Rewards Max                       6.83227
exploration/Rewards Min                      -0.679676
exploration/Returns Mean                   3003.12
exploration/Returns Std                       0
exploration/Returns Max                    3003.12
exploration/Returns Min                    3003.12
exploration/Num Paths                         1
exploration/Average Returns                3003.12
evaluation_0/num steps total                  5.90552e+06
evaluation_0/num paths total               9519
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98632
evaluation_0/Rewards Std                      1.08908
evaluation_0/Rewards Max                      7.77924
evaluation_0/Rewards Min                     -0.707648
evaluation_0/Returns Mean                  4986.32
evaluation_0/Returns Std                     66.1144
evaluation_0/Returns Max                   5071.98
evaluation_0/Returns Min                   4887.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4986.32
time/epoch (s)                                0
time/total (s)                            11460.2
Epoch                                       754
---------------------------------------  ----------------
2022-11-16 19:25:54.664100 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 755 finished
---------------------------------------  ----------------
epoch                                       755
total_step                               760000
replay_pool/size                         760000
trainer/alpha                                 0.0618433
trainer/alpha_loss                            1.45321
trainer/entropy                              -6.52213
trainer/qf_loss                              27.2562
trainer/policy_loss                        -340.413
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.817
trainer/entropy_penalty                      -0.40335
trainer/entropy_percentage                   -0.00118348
trainer/Q1Pred Mean                         340.604
trainer/Q1Pred Std                           66.0423
trainer/Q1Pred Max                          421.079
trainer/Q1Pred Min                           -7.97178
trainer/Q2Pred Mean                         340.536
trainer/Q2Pred Std                           66.5468
trainer/Q2Pred Max                          418.187
trainer/Q2Pred Min                          -22.3433
trainer/QTargetWithReg Mean                 339.869
trainer/QTargetWithReg Std                   66.6636
trainer/QTargetWithReg Max                  418.312
trainer/QTargetWithReg Min                  -17.274
trainer/PolicyLossWithoutReg Mean           340.817
trainer/PolicyLossWithoutReg Std             65.7603
trainer/PolicyLossWithoutReg Max            418.799
trainer/PolicyLossWithoutReg Min            -11.3191
exploration/num steps total              760000
exploration/num paths total                1548
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.02374
exploration/Rewards Std                       1.10951
exploration/Rewards Max                       6.43074
exploration/Rewards Min                      -0.795327
exploration/Returns Mean                   4023.74
exploration/Returns Std                       0
exploration/Returns Max                    4023.74
exploration/Returns Min                    4023.74
exploration/Num Paths                         1
exploration/Average Returns                4023.74
evaluation_0/num steps total                  5.91352e+06
evaluation_0/num paths total               9527
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95429
evaluation_0/Rewards Std                      1.04294
evaluation_0/Rewards Max                      7.80293
evaluation_0/Rewards Min                     -0.641156
evaluation_0/Returns Mean                  4954.29
evaluation_0/Returns Std                     31.9548
evaluation_0/Returns Max                   5004.38
evaluation_0/Returns Min                   4905.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4954.29
time/epoch (s)                                0
time/total (s)                            11471.6
Epoch                                       755
---------------------------------------  ----------------
2022-11-16 19:26:05.735312 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 756 finished
---------------------------------------  ----------------
epoch                                       756
total_step                               761000
replay_pool/size                         761000
trainer/alpha                                 0.0609269
trainer/alpha_loss                            0.220065
trainer/entropy                              -6.07865
trainer/qf_loss                              41.2262
trainer/policy_loss                        -342.396
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.766
trainer/entropy_penalty                      -0.370353
trainer/entropy_percentage                   -0.00108048
trainer/Q1Pred Mean                         341.173
trainer/Q1Pred Std                           70.8223
trainer/Q1Pred Max                          419.765
trainer/Q1Pred Min                            5.54098
trainer/Q2Pred Mean                         341.465
trainer/Q2Pred Std                           71.1676
trainer/Q2Pred Max                          423.591
trainer/Q2Pred Min                           -5.25947
trainer/QTargetWithReg Mean                 341.55
trainer/QTargetWithReg Std                   71.5739
trainer/QTargetWithReg Max                  422.71
trainer/QTargetWithReg Min                    4.1158
trainer/PolicyLossWithoutReg Mean           342.766
trainer/PolicyLossWithoutReg Std             70.2999
trainer/PolicyLossWithoutReg Max            421.221
trainer/PolicyLossWithoutReg Min              1.23609
exploration/num steps total              761000
exploration/num paths total                1549
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56236
exploration/Rewards Std                       1.06477
exploration/Rewards Max                       7.03867
exploration/Rewards Min                      -0.827948
exploration/Returns Mean                   4562.36
exploration/Returns Std                       0
exploration/Returns Max                    4562.36
exploration/Returns Min                    4562.36
exploration/Num Paths                         1
exploration/Average Returns                4562.36
evaluation_0/num steps total                  5.92152e+06
evaluation_0/num paths total               9535
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73553
evaluation_0/Rewards Std                      1.19076
evaluation_0/Rewards Max                      7.66498
evaluation_0/Rewards Min                     -0.735859
evaluation_0/Returns Mean                  4735.53
evaluation_0/Returns Std                     78.92
evaluation_0/Returns Max                   4841.01
evaluation_0/Returns Min                   4584.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4735.53
time/epoch (s)                                0
time/total (s)                            11482.6
Epoch                                       756
---------------------------------------  ----------------
2022-11-16 19:26:17.036068 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 757 finished
---------------------------------------  ----------------
epoch                                       757
total_step                               762000
replay_pool/size                         762000
trainer/alpha                                 0.0597852
trainer/alpha_loss                           -1.0169
trainer/entropy                              -5.63903
trainer/qf_loss                              18.237
trainer/policy_loss                        -350.479
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.817
trainer/entropy_penalty                      -0.33713
trainer/entropy_percentage                   -0.000960987
trainer/Q1Pred Mean                         349.569
trainer/Q1Pred Std                           59.5708
trainer/Q1Pred Max                          425.523
trainer/Q1Pred Min                           28.7181
trainer/Q2Pred Mean                         350.869
trainer/Q2Pred Std                           59.0572
trainer/Q2Pred Max                          423.883
trainer/Q2Pred Min                           34.3198
trainer/QTargetWithReg Mean                 349.462
trainer/QTargetWithReg Std                   59.3448
trainer/QTargetWithReg Max                  424.052
trainer/QTargetWithReg Min                   31.974
trainer/PolicyLossWithoutReg Mean           350.817
trainer/PolicyLossWithoutReg Std             59.0584
trainer/PolicyLossWithoutReg Max            427.241
trainer/PolicyLossWithoutReg Min             35.6013
exploration/num steps total              762000
exploration/num paths total                1550
exploration/path length this epoch Mean     917
exploration/path length this epoch Std        0
exploration/path length this epoch Max      917
exploration/path length this epoch Min      917
exploration/Rewards Mean                      4.62482
exploration/Rewards Std                       1.16142
exploration/Rewards Max                       7.30273
exploration/Rewards Min                      -0.796133
exploration/Returns Mean                   4240.96
exploration/Returns Std                       0
exploration/Returns Max                    4240.96
exploration/Returns Min                    4240.96
exploration/Num Paths                         1
exploration/Average Returns                4240.96
evaluation_0/num steps total                  5.92952e+06
evaluation_0/num paths total               9543
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90979
evaluation_0/Rewards Std                      1.09067
evaluation_0/Rewards Max                      7.90654
evaluation_0/Rewards Min                     -0.598449
evaluation_0/Returns Mean                  4909.79
evaluation_0/Returns Std                     79.8091
evaluation_0/Returns Max                   5051.6
evaluation_0/Returns Min                   4757.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4909.79
time/epoch (s)                                0
time/total (s)                            11493.9
Epoch                                       757
---------------------------------------  ----------------
2022-11-16 19:26:29.521884 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 758 finished
---------------------------------------  ----------------
epoch                                       758
total_step                               763000
replay_pool/size                         763000
trainer/alpha                                 0.0626278
trainer/alpha_loss                           -0.378819
trainer/entropy                              -5.86327
trainer/qf_loss                              30.3599
trainer/policy_loss                        -337.863
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.23
trainer/entropy_penalty                      -0.367204
trainer/entropy_percentage                   -0.00108566
trainer/Q1Pred Mean                         337.681
trainer/Q1Pred Std                           74.4849
trainer/Q1Pred Max                          421.914
trainer/Q1Pred Min                            4.71894
trainer/Q2Pred Mean                         337.775
trainer/Q2Pred Std                           74.4411
trainer/Q2Pred Max                          424.025
trainer/Q2Pred Min                            2.37628
trainer/QTargetWithReg Mean                 337.121
trainer/QTargetWithReg Std                   74.784
trainer/QTargetWithReg Max                  424.12
trainer/QTargetWithReg Min                   -1.28893
trainer/PolicyLossWithoutReg Mean           338.23
trainer/PolicyLossWithoutReg Std             73.0221
trainer/PolicyLossWithoutReg Max            422.221
trainer/PolicyLossWithoutReg Min              3.21701
exploration/num steps total              763000
exploration/num paths total                1551
exploration/path length this epoch Mean      14
exploration/path length this epoch Std        0
exploration/path length this epoch Max       14
exploration/path length this epoch Min       14
exploration/Rewards Mean                     -0.0459594
exploration/Rewards Std                       0.373809
exploration/Rewards Max                       0.773994
exploration/Rewards Min                      -0.593603
exploration/Returns Mean                     -0.643431
exploration/Returns Std                       0
exploration/Returns Max                      -0.643431
exploration/Returns Min                      -0.643431
exploration/Num Paths                         1
exploration/Average Returns                  -0.643431
evaluation_0/num steps total                  5.93679e+06
evaluation_0/num paths total               9551
evaluation_0/path length Mean               909.125
evaluation_0/path length Std                240.433
evaluation_0/path length Max               1000
evaluation_0/path length Min                273
evaluation_0/Rewards Mean                     4.70206
evaluation_0/Rewards Std                      1.0837
evaluation_0/Rewards Max                      7.59416
evaluation_0/Rewards Min                     -0.629969
evaluation_0/Returns Mean                  4274.76
evaluation_0/Returns Std                   1224.91
evaluation_0/Returns Max                   4813.55
evaluation_0/Returns Min                   1037.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4274.76
time/epoch (s)                                0
time/total (s)                            11506.4
Epoch                                       758
---------------------------------------  ----------------
2022-11-16 19:26:40.250752 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 759 finished
---------------------------------------  ----------------
epoch                                       759
total_step                               764000
replay_pool/size                         764000
trainer/alpha                                 0.0609289
trainer/alpha_loss                           -0.691792
trainer/entropy                              -5.75275
trainer/qf_loss                              18.7355
trainer/policy_loss                        -348.291
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.642
trainer/entropy_penalty                      -0.350509
trainer/entropy_percentage                   -0.00100535
trainer/Q1Pred Mean                         348.447
trainer/Q1Pred Std                           61.0427
trainer/Q1Pred Max                          429.783
trainer/Q1Pred Min                           -0.0296137
trainer/Q2Pred Mean                         347.804
trainer/Q2Pred Std                           60.7849
trainer/Q2Pred Max                          430.338
trainer/Q2Pred Min                           -1.03358
trainer/QTargetWithReg Mean                 348.743
trainer/QTargetWithReg Std                   61.1709
trainer/QTargetWithReg Max                  431.319
trainer/QTargetWithReg Min                   -3.71548
trainer/PolicyLossWithoutReg Mean           348.642
trainer/PolicyLossWithoutReg Std             59.5958
trainer/PolicyLossWithoutReg Max            430.314
trainer/PolicyLossWithoutReg Min             -0.651683
exploration/num steps total              764000
exploration/num paths total                1552
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48787
exploration/Rewards Std                       1.02322
exploration/Rewards Max                       6.95599
exploration/Rewards Min                      -0.7546
exploration/Returns Mean                   4487.87
exploration/Returns Std                       0
exploration/Returns Max                    4487.87
exploration/Returns Min                    4487.87
exploration/Num Paths                         1
exploration/Average Returns                4487.87
evaluation_0/num steps total                  5.94479e+06
evaluation_0/num paths total               9559
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81124
evaluation_0/Rewards Std                      1.15633
evaluation_0/Rewards Max                      7.83071
evaluation_0/Rewards Min                     -0.489747
evaluation_0/Returns Mean                  4811.24
evaluation_0/Returns Std                    144.206
evaluation_0/Returns Max                   4980.7
evaluation_0/Returns Min                   4606.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4811.24
time/epoch (s)                                0
time/total (s)                            11517.2
Epoch                                       759
---------------------------------------  ----------------
2022-11-16 19:26:51.559740 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 760 finished
---------------------------------------  ----------------
epoch                                       760
total_step                               765000
replay_pool/size                         765000
trainer/alpha                                 0.0597833
trainer/alpha_loss                            3.155
trainer/entropy                              -7.11987
trainer/qf_loss                              33.7916
trainer/policy_loss                        -339.033
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.458
trainer/entropy_penalty                      -0.42565
trainer/entropy_percentage                   -0.00125391
trainer/Q1Pred Mean                         339.206
trainer/Q1Pred Std                           74.2723
trainer/Q1Pred Max                          436.86
trainer/Q1Pred Min                           16.5991
trainer/Q2Pred Mean                         339.323
trainer/Q2Pred Std                           73.5657
trainer/Q2Pred Max                          433.334
trainer/Q2Pred Min                           23.2666
trainer/QTargetWithReg Mean                 338.902
trainer/QTargetWithReg Std                   75.771
trainer/QTargetWithReg Max                  438.181
trainer/QTargetWithReg Min                   21.9993
trainer/PolicyLossWithoutReg Mean           339.458
trainer/PolicyLossWithoutReg Std             72.9116
trainer/PolicyLossWithoutReg Max            435.827
trainer/PolicyLossWithoutReg Min             17.6563
exploration/num steps total              765000
exploration/num paths total                1553
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50356
exploration/Rewards Std                       1.22324
exploration/Rewards Max                       7.42658
exploration/Rewards Min                      -0.57446
exploration/Returns Mean                   4503.56
exploration/Returns Std                       0
exploration/Returns Max                    4503.56
exploration/Returns Min                    4503.56
exploration/Num Paths                         1
exploration/Average Returns                4503.56
evaluation_0/num steps total                  5.95279e+06
evaluation_0/num paths total               9567
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94438
evaluation_0/Rewards Std                      1.08893
evaluation_0/Rewards Max                      7.81115
evaluation_0/Rewards Min                     -0.748887
evaluation_0/Returns Mean                  4944.38
evaluation_0/Returns Std                    122.447
evaluation_0/Returns Max                   5148.45
evaluation_0/Returns Min                   4783.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4944.38
time/epoch (s)                                0
time/total (s)                            11528.5
Epoch                                       760
---------------------------------------  ----------------
2022-11-16 19:27:03.752016 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 761 finished
---------------------------------------  ----------------
epoch                                       761
total_step                               766000
replay_pool/size                         766000
trainer/alpha                                 0.0607071
trainer/alpha_loss                            1.27692
trainer/entropy                              -6.45575
trainer/qf_loss                              24.8419
trainer/policy_loss                        -336.736
trainer/adversary_policy_loss                16.0749
trainer/policy_loss_without_entropy         337.128
trainer/entropy_penalty                      -0.39191
trainer/entropy_percentage                   -0.0011625
trainer/Q1Pred Mean                         337.157
trainer/Q1Pred Std                           69.8253
trainer/Q1Pred Max                          424.719
trainer/Q1Pred Min                          -14.1681
trainer/Q2Pred Mean                         336.944
trainer/Q2Pred Std                           69.9033
trainer/Q2Pred Max                          428.989
trainer/Q2Pred Min                          -22.7861
trainer/QTargetWithReg Mean                 337.023
trainer/QTargetWithReg Std                   70.6617
trainer/QTargetWithReg Max                  428.092
trainer/QTargetWithReg Min                  -15.5507
trainer/PolicyLossWithoutReg Mean           337.128
trainer/PolicyLossWithoutReg Std             68.5555
trainer/PolicyLossWithoutReg Max            424.37
trainer/PolicyLossWithoutReg Min             -2.33019
exploration/num steps total              766000
exploration/num paths total                1554
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71064
exploration/Rewards Std                       1.12663
exploration/Rewards Max                       7.98906
exploration/Rewards Min                      -0.696864
exploration/Returns Mean                   4710.64
exploration/Returns Std                       0
exploration/Returns Max                    4710.64
exploration/Returns Min                    4710.64
exploration/Num Paths                         1
exploration/Average Returns                4710.64
evaluation_0/num steps total                  5.96079e+06
evaluation_0/num paths total               9575
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74617
evaluation_0/Rewards Std                      1.15289
evaluation_0/Rewards Max                      7.47412
evaluation_0/Rewards Min                     -0.55453
evaluation_0/Returns Mean                  4746.17
evaluation_0/Returns Std                    129.955
evaluation_0/Returns Max                   4861.68
evaluation_0/Returns Min                   4499.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4746.17
time/epoch (s)                                0
time/total (s)                            11540.7
Epoch                                       761
---------------------------------------  ----------------
2022-11-16 19:27:16.392146 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 762 finished
---------------------------------------  ----------------
epoch                                       762
total_step                               767000
replay_pool/size                         767000
trainer/alpha                                 0.0613237
trainer/alpha_loss                           -0.570953
trainer/entropy                              -5.79548
trainer/qf_loss                              34.3795
trainer/policy_loss                        -349.46
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.816
trainer/entropy_penalty                      -0.3554
trainer/entropy_percentage                   -0.00101596
trainer/Q1Pred Mean                         348.746
trainer/Q1Pred Std                           59.1065
trainer/Q1Pred Max                          427.255
trainer/Q1Pred Min                            9.79991
trainer/Q2Pred Mean                         349.367
trainer/Q2Pred Std                           59.2777
trainer/Q2Pred Max                          427.406
trainer/Q2Pred Min                            9.31715
trainer/QTargetWithReg Mean                 349.204
trainer/QTargetWithReg Std                   59.622
trainer/QTargetWithReg Max                  426.406
trainer/QTargetWithReg Min                    9.07042
trainer/PolicyLossWithoutReg Mean           349.816
trainer/PolicyLossWithoutReg Std             58.6807
trainer/PolicyLossWithoutReg Max            426.403
trainer/PolicyLossWithoutReg Min             11.7834
exploration/num steps total              767000
exploration/num paths total                1555
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69175
exploration/Rewards Std                       1.09397
exploration/Rewards Max                       7.36357
exploration/Rewards Min                      -0.515842
exploration/Returns Mean                   4691.75
exploration/Returns Std                       0
exploration/Returns Max                    4691.75
exploration/Returns Min                    4691.75
exploration/Num Paths                         1
exploration/Average Returns                4691.75
evaluation_0/num steps total                  5.96879e+06
evaluation_0/num paths total               9583
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81961
evaluation_0/Rewards Std                      1.13527
evaluation_0/Rewards Max                      7.8379
evaluation_0/Rewards Min                     -0.804762
evaluation_0/Returns Mean                  4819.61
evaluation_0/Returns Std                     57.3254
evaluation_0/Returns Max                   4918.15
evaluation_0/Returns Min                   4726.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4819.61
time/epoch (s)                                0
time/total (s)                            11553.3
Epoch                                       762
---------------------------------------  ----------------
2022-11-16 19:27:28.419907 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 763 finished
---------------------------------------  ----------------
epoch                                       763
total_step                               768000
replay_pool/size                         768000
trainer/alpha                                 0.0599051
trainer/alpha_loss                            0.278366
trainer/entropy                              -6.09888
trainer/qf_loss                              27.3487
trainer/policy_loss                        -339.156
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.521
trainer/entropy_penalty                      -0.365354
trainer/entropy_percentage                   -0.00107609
trainer/Q1Pred Mean                         339.904
trainer/Q1Pred Std                           62.039
trainer/Q1Pred Max                          428.636
trainer/Q1Pred Min                            4.57154
trainer/Q2Pred Mean                         339.306
trainer/Q2Pred Std                           61.876
trainer/Q2Pred Max                          430.688
trainer/Q2Pred Min                            6.76687
trainer/QTargetWithReg Mean                 339.695
trainer/QTargetWithReg Std                   62.3107
trainer/QTargetWithReg Max                  431.464
trainer/QTargetWithReg Min                    5.44055
trainer/PolicyLossWithoutReg Mean           339.521
trainer/PolicyLossWithoutReg Std             60.8789
trainer/PolicyLossWithoutReg Max            429.705
trainer/PolicyLossWithoutReg Min              5.48925
exploration/num steps total              768000
exploration/num paths total                1556
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75243
exploration/Rewards Std                       1.00881
exploration/Rewards Max                       7.11836
exploration/Rewards Min                      -0.796223
exploration/Returns Mean                   4752.43
exploration/Returns Std                       0
exploration/Returns Max                    4752.43
exploration/Returns Min                    4752.43
exploration/Num Paths                         1
exploration/Average Returns                4752.43
evaluation_0/num steps total                  5.97679e+06
evaluation_0/num paths total               9591
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87067
evaluation_0/Rewards Std                      1.09105
evaluation_0/Rewards Max                      7.87203
evaluation_0/Rewards Min                     -0.767061
evaluation_0/Returns Mean                  4870.67
evaluation_0/Returns Std                     66.0929
evaluation_0/Returns Max                   4944.36
evaluation_0/Returns Min                   4740.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4870.67
time/epoch (s)                                0
time/total (s)                            11565.3
Epoch                                       763
---------------------------------------  ----------------
2022-11-16 19:27:39.620016 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 764 finished
---------------------------------------  ----------------
epoch                                       764
total_step                               769000
replay_pool/size                         769000
trainer/alpha                                 0.0586949
trainer/alpha_loss                            0.796698
trainer/entropy                              -6.28099
trainer/qf_loss                              27.9796
trainer/policy_loss                        -338.388
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         338.757
trainer/entropy_penalty                      -0.368662
trainer/entropy_percentage                   -0.00108828
trainer/Q1Pred Mean                         338.184
trainer/Q1Pred Std                           70.8938
trainer/Q1Pred Max                          423.894
trainer/Q1Pred Min                            8.1216
trainer/Q2Pred Mean                         337.918
trainer/Q2Pred Std                           71.0539
trainer/Q2Pred Max                          423.326
trainer/Q2Pred Min                            6.7282
trainer/QTargetWithReg Mean                 336.75
trainer/QTargetWithReg Std                   71.5564
trainer/QTargetWithReg Max                  422.715
trainer/QTargetWithReg Min                    5.53783
trainer/PolicyLossWithoutReg Mean           338.757
trainer/PolicyLossWithoutReg Std             70.6502
trainer/PolicyLossWithoutReg Max            423.311
trainer/PolicyLossWithoutReg Min              6.98276
exploration/num steps total              769000
exploration/num paths total                1557
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38995
exploration/Rewards Std                       1.14857
exploration/Rewards Max                       6.94158
exploration/Rewards Min                      -0.79672
exploration/Returns Mean                   4389.95
exploration/Returns Std                       0
exploration/Returns Max                    4389.95
exploration/Returns Min                    4389.95
exploration/Num Paths                         1
exploration/Average Returns                4389.95
evaluation_0/num steps total                  5.98479e+06
evaluation_0/num paths total               9599
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88278
evaluation_0/Rewards Std                      1.15426
evaluation_0/Rewards Max                      7.77027
evaluation_0/Rewards Min                     -0.811208
evaluation_0/Returns Mean                  4882.78
evaluation_0/Returns Std                    179.219
evaluation_0/Returns Max                   5095.81
evaluation_0/Returns Min                   4565.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4882.78
time/epoch (s)                                0
time/total (s)                            11576.5
Epoch                                       764
---------------------------------------  ----------------
2022-11-16 19:27:51.493950 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 765 finished
---------------------------------------  ----------------
epoch                                       765
total_step                               770000
replay_pool/size                         770000
trainer/alpha                                 0.0619528
trainer/alpha_loss                            0.347486
trainer/entropy                              -6.12494
trainer/qf_loss                             165.404
trainer/policy_loss                        -342.753
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.133
trainer/entropy_penalty                      -0.379457
trainer/entropy_percentage                   -0.00110586
trainer/Q1Pred Mean                         342.455
trainer/Q1Pred Std                           65.2981
trainer/Q1Pred Max                          416.621
trainer/Q1Pred Min                            3.68198
trainer/Q2Pred Mean                         342.632
trainer/Q2Pred Std                           65.6032
trainer/Q2Pred Max                          416.524
trainer/Q2Pred Min                            2.20229
trainer/QTargetWithReg Mean                 342.405
trainer/QTargetWithReg Std                   68.5151
trainer/QTargetWithReg Max                  416.393
trainer/QTargetWithReg Min                    4.33231
trainer/PolicyLossWithoutReg Mean           343.132
trainer/PolicyLossWithoutReg Std             64.1091
trainer/PolicyLossWithoutReg Max            414.13
trainer/PolicyLossWithoutReg Min              3.1959
exploration/num steps total              770000
exploration/num paths total                1558
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49419
exploration/Rewards Std                       0.986119
exploration/Rewards Max                       6.90066
exploration/Rewards Min                      -0.907583
exploration/Returns Mean                   4494.19
exploration/Returns Std                       0
exploration/Returns Max                    4494.19
exploration/Returns Min                    4494.19
exploration/Num Paths                         1
exploration/Average Returns                4494.19
evaluation_0/num steps total                  5.99279e+06
evaluation_0/num paths total               9607
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85546
evaluation_0/Rewards Std                      0.991794
evaluation_0/Rewards Max                      7.406
evaluation_0/Rewards Min                     -0.559454
evaluation_0/Returns Mean                  4855.46
evaluation_0/Returns Std                     70.8891
evaluation_0/Returns Max                   4962.39
evaluation_0/Returns Min                   4770.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4855.46
time/epoch (s)                                0
time/total (s)                            11588.4
Epoch                                       765
---------------------------------------  ----------------
2022-11-16 19:28:04.286007 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 766 finished
---------------------------------------  ----------------
epoch                                       766
total_step                               771000
replay_pool/size                         771000
trainer/alpha                                 0.063404
trainer/alpha_loss                           -0.598223
trainer/entropy                              -5.78313
trainer/qf_loss                              16.6122
trainer/policy_loss                        -344.379
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.745
trainer/entropy_penalty                      -0.366674
trainer/entropy_percentage                   -0.00106361
trainer/Q1Pred Mean                         344.529
trainer/Q1Pred Std                           62.7861
trainer/Q1Pred Max                          417.769
trainer/Q1Pred Min                            5.71625
trainer/Q2Pred Mean                         344.324
trainer/Q2Pred Std                           63.3096
trainer/Q2Pred Max                          419.87
trainer/Q2Pred Min                           -5.48339
trainer/QTargetWithReg Mean                 344.817
trainer/QTargetWithReg Std                   64.0677
trainer/QTargetWithReg Max                  417.01
trainer/QTargetWithReg Min                   -9.65567
trainer/PolicyLossWithoutReg Mean           344.745
trainer/PolicyLossWithoutReg Std             62.9881
trainer/PolicyLossWithoutReg Max            417.409
trainer/PolicyLossWithoutReg Min             -9.33699
exploration/num steps total              771000
exploration/num paths total                1559
exploration/path length this epoch Mean     283
exploration/path length this epoch Std        0
exploration/path length this epoch Max      283
exploration/path length this epoch Min      283
exploration/Rewards Mean                      3.44381
exploration/Rewards Std                       1.3007
exploration/Rewards Max                       6.58188
exploration/Rewards Min                      -0.358419
exploration/Returns Mean                    974.597
exploration/Returns Std                       0
exploration/Returns Max                     974.597
exploration/Returns Min                     974.597
exploration/Num Paths                         1
exploration/Average Returns                 974.597
evaluation_0/num steps total                  6.00079e+06
evaluation_0/num paths total               9615
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07455
evaluation_0/Rewards Std                      1.10655
evaluation_0/Rewards Max                      7.79328
evaluation_0/Rewards Min                     -0.732344
evaluation_0/Returns Mean                  5074.55
evaluation_0/Returns Std                     99.9895
evaluation_0/Returns Max                   5178.11
evaluation_0/Returns Min                   4912.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5074.55
time/epoch (s)                                0
time/total (s)                            11601.2
Epoch                                       766
---------------------------------------  ----------------
2022-11-16 19:28:16.977340 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 767 finished
---------------------------------------  ----------------
epoch                                       767
total_step                               772000
replay_pool/size                         772000
trainer/alpha                                 0.062487
trainer/alpha_loss                           -2.48899
trainer/entropy                              -5.10231
trainer/qf_loss                              16.5017
trainer/policy_loss                        -345.359
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.677
trainer/entropy_penalty                      -0.318828
trainer/entropy_percentage                   -0.000922329
trainer/Q1Pred Mean                         345.52
trainer/Q1Pred Std                           58.7889
trainer/Q1Pred Max                          419.93
trainer/Q1Pred Min                            9.34145
trainer/Q2Pred Mean                         344.96
trainer/Q2Pred Std                           59.0671
trainer/Q2Pred Max                          420.243
trainer/Q2Pred Min                            9.809
trainer/QTargetWithReg Mean                 345.575
trainer/QTargetWithReg Std                   58.8529
trainer/QTargetWithReg Max                  418.628
trainer/QTargetWithReg Min                    7.50998
trainer/PolicyLossWithoutReg Mean           345.678
trainer/PolicyLossWithoutReg Std             57.7465
trainer/PolicyLossWithoutReg Max            418.943
trainer/PolicyLossWithoutReg Min              3.89553
exploration/num steps total              772000
exploration/num paths total                1560
exploration/path length this epoch Mean     577
exploration/path length this epoch Std        0
exploration/path length this epoch Max      577
exploration/path length this epoch Min      577
exploration/Rewards Mean                      4.68077
exploration/Rewards Std                       1.3297
exploration/Rewards Max                       8.45668
exploration/Rewards Min                      -0.692304
exploration/Returns Mean                   2700.81
exploration/Returns Std                       0
exploration/Returns Max                    2700.81
exploration/Returns Min                    2700.81
exploration/Num Paths                         1
exploration/Average Returns                2700.81
evaluation_0/num steps total                  6.00879e+06
evaluation_0/num paths total               9623
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92243
evaluation_0/Rewards Std                      1.08441
evaluation_0/Rewards Max                      7.68605
evaluation_0/Rewards Min                     -0.70032
evaluation_0/Returns Mean                  4922.43
evaluation_0/Returns Std                     73.6168
evaluation_0/Returns Max                   5054.46
evaluation_0/Returns Min                   4830.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4922.43
time/epoch (s)                                0
time/total (s)                            11613.9
Epoch                                       767
---------------------------------------  ----------------
2022-11-16 19:28:29.698224 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 768 finished
---------------------------------------  ----------------
epoch                                       768
total_step                               773000
replay_pool/size                         773000
trainer/alpha                                 0.0611733
trainer/alpha_loss                            0.148818
trainer/entropy                              -6.05326
trainer/qf_loss                              20.4997
trainer/policy_loss                        -341.712
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.083
trainer/entropy_penalty                      -0.370298
trainer/entropy_percentage                   -0.00108248
trainer/Q1Pred Mean                         341.903
trainer/Q1Pred Std                           57.7343
trainer/Q1Pred Max                          422.653
trainer/Q1Pred Min                           71.0287
trainer/Q2Pred Mean                         341.353
trainer/Q2Pred Std                           58.0627
trainer/Q2Pred Max                          423.125
trainer/Q2Pred Min                           71.9787
trainer/QTargetWithReg Mean                 341.387
trainer/QTargetWithReg Std                   57.9062
trainer/QTargetWithReg Max                  421.056
trainer/QTargetWithReg Min                   82.0256
trainer/PolicyLossWithoutReg Mean           342.083
trainer/PolicyLossWithoutReg Std             57.1793
trainer/PolicyLossWithoutReg Max            421.521
trainer/PolicyLossWithoutReg Min             78.4866
exploration/num steps total              773000
exploration/num paths total                1561
exploration/path length this epoch Mean     299
exploration/path length this epoch Std        0
exploration/path length this epoch Max      299
exploration/path length this epoch Min      299
exploration/Rewards Mean                      3.89753
exploration/Rewards Std                       1.16021
exploration/Rewards Max                       5.63164
exploration/Rewards Min                      -0.755403
exploration/Returns Mean                   1165.36
exploration/Returns Std                       0
exploration/Returns Max                    1165.36
exploration/Returns Min                    1165.36
exploration/Num Paths                         1
exploration/Average Returns                1165.36
evaluation_0/num steps total                  6.01679e+06
evaluation_0/num paths total               9631
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87764
evaluation_0/Rewards Std                      1.02748
evaluation_0/Rewards Max                      7.65798
evaluation_0/Rewards Min                     -0.776643
evaluation_0/Returns Mean                  4877.64
evaluation_0/Returns Std                     63.1276
evaluation_0/Returns Max                   5005.26
evaluation_0/Returns Min                   4792.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4877.64
time/epoch (s)                                0
time/total (s)                            11626.6
Epoch                                       768
---------------------------------------  ----------------
2022-11-16 19:28:43.681995 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 769 finished
---------------------------------------  ----------------
epoch                                       769
total_step                               774000
replay_pool/size                         774000
trainer/alpha                                 0.0597153
trainer/alpha_loss                            0.950594
trainer/entropy                              -6.33734
trainer/qf_loss                              23.8439
trainer/policy_loss                        -343.544
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.922
trainer/entropy_penalty                      -0.378436
trainer/entropy_percentage                   -0.00110035
trainer/Q1Pred Mean                         341.119
trainer/Q1Pred Std                           73.8731
trainer/Q1Pred Max                          429.738
trainer/Q1Pred Min                           29.1064
trainer/Q2Pred Mean                         341.15
trainer/Q2Pred Std                           74.0249
trainer/Q2Pred Max                          428.684
trainer/Q2Pred Min                           27.0741
trainer/QTargetWithReg Mean                 341.359
trainer/QTargetWithReg Std                   73.8863
trainer/QTargetWithReg Max                  428.971
trainer/QTargetWithReg Min                   28.0049
trainer/PolicyLossWithoutReg Mean           343.922
trainer/PolicyLossWithoutReg Std             70.5474
trainer/PolicyLossWithoutReg Max            429.183
trainer/PolicyLossWithoutReg Min             26.1311
exploration/num steps total              774000
exploration/num paths total                1562
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43525
exploration/Rewards Std                       1.07495
exploration/Rewards Max                       7.25695
exploration/Rewards Min                      -0.696704
exploration/Returns Mean                   4435.25
exploration/Returns Std                       0
exploration/Returns Max                    4435.25
exploration/Returns Min                    4435.25
exploration/Num Paths                         1
exploration/Average Returns                4435.25
evaluation_0/num steps total                  6.02479e+06
evaluation_0/num paths total               9639
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81796
evaluation_0/Rewards Std                      1.08338
evaluation_0/Rewards Max                      8.03763
evaluation_0/Rewards Min                     -0.805818
evaluation_0/Returns Mean                  4817.96
evaluation_0/Returns Std                     51.441
evaluation_0/Returns Max                   4921.01
evaluation_0/Returns Min                   4755.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4817.96
time/epoch (s)                                0
time/total (s)                            11640.6
Epoch                                       769
---------------------------------------  ----------------
2022-11-16 19:28:58.393295 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 770 finished
---------------------------------------  ----------------
epoch                                       770
total_step                               775000
replay_pool/size                         775000
trainer/alpha                                 0.0595291
trainer/alpha_loss                           -1.37682
trainer/entropy                              -5.51195
trainer/qf_loss                              21.4029
trainer/policy_loss                        -340.055
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.383
trainer/entropy_penalty                      -0.328122
trainer/entropy_percentage                   -0.000963979
trainer/Q1Pred Mean                         339.663
trainer/Q1Pred Std                           75.3683
trainer/Q1Pred Max                          423.766
trainer/Q1Pred Min                          -11.2391
trainer/Q2Pred Mean                         339.616
trainer/Q2Pred Std                           74.8555
trainer/Q2Pred Max                          422.432
trainer/Q2Pred Min                           12.9126
trainer/QTargetWithReg Mean                 339.861
trainer/QTargetWithReg Std                   75.5319
trainer/QTargetWithReg Max                  422.934
trainer/QTargetWithReg Min                    0.0211892
trainer/PolicyLossWithoutReg Mean           340.383
trainer/PolicyLossWithoutReg Std             73.0213
trainer/PolicyLossWithoutReg Max            422.792
trainer/PolicyLossWithoutReg Min             16.8756
exploration/num steps total              775000
exploration/num paths total                1563
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56574
exploration/Rewards Std                       1.09352
exploration/Rewards Max                       7.31728
exploration/Rewards Min                      -0.836623
exploration/Returns Mean                   4565.74
exploration/Returns Std                       0
exploration/Returns Max                    4565.74
exploration/Returns Min                    4565.74
exploration/Num Paths                         1
exploration/Average Returns                4565.74
evaluation_0/num steps total                  6.03279e+06
evaluation_0/num paths total               9647
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73638
evaluation_0/Rewards Std                      1.1017
evaluation_0/Rewards Max                      7.55852
evaluation_0/Rewards Min                     -0.461678
evaluation_0/Returns Mean                  4736.38
evaluation_0/Returns Std                     61.0998
evaluation_0/Returns Max                   4807.9
evaluation_0/Returns Min                   4604
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4736.38
time/epoch (s)                                0
time/total (s)                            11655.3
Epoch                                       770
---------------------------------------  ----------------
2022-11-16 19:29:13.112465 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 771 finished
---------------------------------------  ----------------
epoch                                       771
total_step                               776000
replay_pool/size                         776000
trainer/alpha                                 0.05894
trainer/alpha_loss                            1.25662
trainer/entropy                              -6.44382
trainer/qf_loss                              20.2824
trainer/policy_loss                        -344.346
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.726
trainer/entropy_penalty                      -0.379799
trainer/entropy_percentage                   -0.00110174
trainer/Q1Pred Mean                         344.741
trainer/Q1Pred Std                           68.6755
trainer/Q1Pred Max                          429.298
trainer/Q1Pred Min                           22.9333
trainer/Q2Pred Mean                         343.824
trainer/Q2Pred Std                           68.8419
trainer/Q2Pred Max                          426.951
trainer/Q2Pred Min                           19.4904
trainer/QTargetWithReg Mean                 343.502
trainer/QTargetWithReg Std                   69.688
trainer/QTargetWithReg Max                  427.513
trainer/QTargetWithReg Min                    5.44738
trainer/PolicyLossWithoutReg Mean           344.726
trainer/PolicyLossWithoutReg Std             68.2049
trainer/PolicyLossWithoutReg Max            427.019
trainer/PolicyLossWithoutReg Min             19.8245
exploration/num steps total              776000
exploration/num paths total                1564
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61166
exploration/Rewards Std                       1.18324
exploration/Rewards Max                       7.28528
exploration/Rewards Min                      -0.574978
exploration/Returns Mean                   4611.66
exploration/Returns Std                       0
exploration/Returns Max                    4611.66
exploration/Returns Min                    4611.66
exploration/Num Paths                         1
exploration/Average Returns                4611.66
evaluation_0/num steps total                  6.04079e+06
evaluation_0/num paths total               9655
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01594
evaluation_0/Rewards Std                      1.07877
evaluation_0/Rewards Max                      8.00311
evaluation_0/Rewards Min                     -0.723506
evaluation_0/Returns Mean                  5015.94
evaluation_0/Returns Std                     64.888
evaluation_0/Returns Max                   5099.92
evaluation_0/Returns Min                   4943.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5015.94
time/epoch (s)                                0
time/total (s)                            11670
Epoch                                       771
---------------------------------------  ----------------
2022-11-16 19:29:29.638392 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 772 finished
---------------------------------------  ----------------
epoch                                       772
total_step                               777000
replay_pool/size                         777000
trainer/alpha                                 0.0603248
trainer/alpha_loss                           -0.834614
trainer/entropy                              -5.70276
trainer/qf_loss                              31.3301
trainer/policy_loss                        -345.513
trainer/adversary_policy_loss                16.5206
trainer/policy_loss_without_entropy         345.857
trainer/entropy_penalty                      -0.344018
trainer/entropy_percentage                   -0.000994683
trainer/Q1Pred Mean                         344.791
trainer/Q1Pred Std                           64.3812
trainer/Q1Pred Max                          429.876
trainer/Q1Pred Min                          -25.0287
trainer/Q2Pred Mean                         344.956
trainer/Q2Pred Std                           64.9324
trainer/Q2Pred Max                          427.32
trainer/Q2Pred Min                          -75.7599
trainer/QTargetWithReg Mean                 345.495
trainer/QTargetWithReg Std                   62.9602
trainer/QTargetWithReg Max                  427.119
trainer/QTargetWithReg Min                   -0.244027
trainer/PolicyLossWithoutReg Mean           345.857
trainer/PolicyLossWithoutReg Std             61.5887
trainer/PolicyLossWithoutReg Max            427.02
trainer/PolicyLossWithoutReg Min            -10.1844
exploration/num steps total              777000
exploration/num paths total                1565
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83152
exploration/Rewards Std                       1.08579
exploration/Rewards Max                       7.70918
exploration/Rewards Min                      -0.407384
exploration/Returns Mean                   4831.52
exploration/Returns Std                       0
exploration/Returns Max                    4831.52
exploration/Returns Min                    4831.52
exploration/Num Paths                         1
exploration/Average Returns                4831.52
evaluation_0/num steps total                  6.04826e+06
evaluation_0/num paths total               9663
evaluation_0/path length Mean               933.625
evaluation_0/path length Std                175.612
evaluation_0/path length Max               1000
evaluation_0/path length Min                469
evaluation_0/Rewards Mean                     4.96549
evaluation_0/Rewards Std                      1.09881
evaluation_0/Rewards Max                      7.86338
evaluation_0/Rewards Min                     -0.593126
evaluation_0/Returns Mean                  4635.91
evaluation_0/Returns Std                    960.571
evaluation_0/Returns Max                   5065.18
evaluation_0/Returns Min                   2097.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4635.91
time/epoch (s)                                0
time/total (s)                            11686.5
Epoch                                       772
---------------------------------------  ----------------
2022-11-16 19:29:44.260844 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 773 finished
---------------------------------------  ----------------
epoch                                       773
total_step                               778000
replay_pool/size                         778000
trainer/alpha                                 0.0588992
trainer/alpha_loss                           -0.168299
trainer/entropy                              -5.94057
trainer/qf_loss                              69.9051
trainer/policy_loss                        -350.893
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.242
trainer/entropy_penalty                      -0.349895
trainer/entropy_percentage                   -0.000996164
trainer/Q1Pred Mean                         349.35
trainer/Q1Pred Std                           56.78
trainer/Q1Pred Max                          428.37
trainer/Q1Pred Min                          -20.155
trainer/Q2Pred Mean                         348.604
trainer/Q2Pred Std                           57.1816
trainer/Q2Pred Max                          428.235
trainer/Q2Pred Min                          -42.6468
trainer/QTargetWithReg Mean                 349.088
trainer/QTargetWithReg Std                   58.6549
trainer/QTargetWithReg Max                  427.778
trainer/QTargetWithReg Min                   -8.80791
trainer/PolicyLossWithoutReg Mean           351.243
trainer/PolicyLossWithoutReg Std             49.5841
trainer/PolicyLossWithoutReg Max            427.603
trainer/PolicyLossWithoutReg Min            205.38
exploration/num steps total              778000
exploration/num paths total                1566
exploration/path length this epoch Mean     877
exploration/path length this epoch Std        0
exploration/path length this epoch Max      877
exploration/path length this epoch Min      877
exploration/Rewards Mean                      4.43225
exploration/Rewards Std                       1.06251
exploration/Rewards Max                       6.97134
exploration/Rewards Min                      -0.605455
exploration/Returns Mean                   3887.08
exploration/Returns Std                       0
exploration/Returns Max                    3887.08
exploration/Returns Min                    3887.08
exploration/Num Paths                         1
exploration/Average Returns                3887.08
evaluation_0/num steps total                  6.05626e+06
evaluation_0/num paths total               9671
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61718
evaluation_0/Rewards Std                      1.08551
evaluation_0/Rewards Max                      7.52795
evaluation_0/Rewards Min                     -0.543055
evaluation_0/Returns Mean                  4617.18
evaluation_0/Returns Std                     68.1648
evaluation_0/Returns Max                   4718.63
evaluation_0/Returns Min                   4511.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4617.18
time/epoch (s)                                0
time/total (s)                            11701.2
Epoch                                       773
---------------------------------------  ----------------
2022-11-16 19:30:00.894471 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 774 finished
---------------------------------------  ----------------
epoch                                       774
total_step                               779000
replay_pool/size                         779000
trainer/alpha                                 0.0594592
trainer/alpha_loss                            0.664267
trainer/entropy                              -6.23533
trainer/qf_loss                              52.0745
trainer/policy_loss                        -340.024
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.395
trainer/entropy_penalty                      -0.370748
trainer/entropy_percentage                   -0.00108917
trainer/Q1Pred Mean                         339.692
trainer/Q1Pred Std                           66.4131
trainer/Q1Pred Max                          429.03
trainer/Q1Pred Min                           48.7899
trainer/Q2Pred Mean                         338.85
trainer/Q2Pred Std                           65.9834
trainer/Q2Pred Max                          425.724
trainer/Q2Pred Min                           47.3903
trainer/QTargetWithReg Mean                 341.305
trainer/QTargetWithReg Std                   66.3922
trainer/QTargetWithReg Max                  433.382
trainer/QTargetWithReg Min                   51.7425
trainer/PolicyLossWithoutReg Mean           340.395
trainer/PolicyLossWithoutReg Std             64.9678
trainer/PolicyLossWithoutReg Max            424.687
trainer/PolicyLossWithoutReg Min             59.4768
exploration/num steps total              779000
exploration/num paths total                1567
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55146
exploration/Rewards Std                       1.24444
exploration/Rewards Max                       7.50607
exploration/Rewards Min                      -0.763073
exploration/Returns Mean                   4551.46
exploration/Returns Std                       0
exploration/Returns Max                    4551.46
exploration/Returns Min                    4551.46
exploration/Num Paths                         1
exploration/Average Returns                4551.46
evaluation_0/num steps total                  6.06386e+06
evaluation_0/num paths total               9680
evaluation_0/path length Mean               844
evaluation_0/path length Std                270.685
evaluation_0/path length Max               1000
evaluation_0/path length Min                148
evaluation_0/Rewards Mean                     4.69451
evaluation_0/Rewards Std                      1.13832
evaluation_0/Rewards Max                      7.55568
evaluation_0/Rewards Min                     -1.7404
evaluation_0/Returns Mean                  3962.16
evaluation_0/Returns Std                   1419.74
evaluation_0/Returns Max                   4850.81
evaluation_0/Returns Min                    313.202
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3962.16
time/epoch (s)                                0
time/total (s)                            11717.8
Epoch                                       774
---------------------------------------  ----------------
2022-11-16 19:30:15.719075 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 775 finished
---------------------------------------  ----------------
epoch                                       775
total_step                               780000
replay_pool/size                         780000
trainer/alpha                                 0.0614727
trainer/alpha_loss                            0.261904
trainer/entropy                              -6.0939
trainer/qf_loss                              30.6735
trainer/policy_loss                        -341.728
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.102
trainer/entropy_penalty                      -0.374608
trainer/entropy_percentage                   -0.00109502
trainer/Q1Pred Mean                         342.136
trainer/Q1Pred Std                           67.7546
trainer/Q1Pred Max                          418.398
trainer/Q1Pred Min                           22.7289
trainer/Q2Pred Mean                         341.842
trainer/Q2Pred Std                           68.0133
trainer/Q2Pred Max                          419.375
trainer/Q2Pred Min                           28.9474
trainer/QTargetWithReg Mean                 341.039
trainer/QTargetWithReg Std                   67.9444
trainer/QTargetWithReg Max                  418.117
trainer/QTargetWithReg Min                   33.8419
trainer/PolicyLossWithoutReg Mean           342.102
trainer/PolicyLossWithoutReg Std             66.6527
trainer/PolicyLossWithoutReg Max            418.612
trainer/PolicyLossWithoutReg Min             33.0493
exploration/num steps total              780000
exploration/num paths total                1568
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47604
exploration/Rewards Std                       1.05036
exploration/Rewards Max                       7.0584
exploration/Rewards Min                      -0.638656
exploration/Returns Mean                   4476.04
exploration/Returns Std                       0
exploration/Returns Max                    4476.04
exploration/Returns Min                    4476.04
exploration/Num Paths                         1
exploration/Average Returns                4476.04
evaluation_0/num steps total                  6.07186e+06
evaluation_0/num paths total               9688
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77795
evaluation_0/Rewards Std                      1.08561
evaluation_0/Rewards Max                      7.58003
evaluation_0/Rewards Min                     -0.482328
evaluation_0/Returns Mean                  4777.95
evaluation_0/Returns Std                     47.7745
evaluation_0/Returns Max                   4853.22
evaluation_0/Returns Min                   4683.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4777.95
time/epoch (s)                                0
time/total (s)                            11732.6
Epoch                                       775
---------------------------------------  ----------------
2022-11-16 19:30:30.681904 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 776 finished
---------------------------------------  ----------------
epoch                                       776
total_step                               781000
replay_pool/size                         781000
trainer/alpha                                 0.0590008
trainer/alpha_loss                            0.062324
trainer/entropy                              -6.02202
trainer/qf_loss                              37.9829
trainer/policy_loss                        -339.421
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.776
trainer/entropy_penalty                      -0.355304
trainer/entropy_percentage                   -0.0010457
trainer/Q1Pred Mean                         339.864
trainer/Q1Pred Std                           68.108
trainer/Q1Pred Max                          422.213
trainer/Q1Pred Min                          -11.9702
trainer/Q2Pred Mean                         339.673
trainer/Q2Pred Std                           67.9661
trainer/Q2Pred Max                          421.886
trainer/Q2Pred Min                          -22.4942
trainer/QTargetWithReg Mean                 339.631
trainer/QTargetWithReg Std                   68.3862
trainer/QTargetWithReg Max                  423.843
trainer/QTargetWithReg Min                  -12.1478
trainer/PolicyLossWithoutReg Mean           339.776
trainer/PolicyLossWithoutReg Std             67.1335
trainer/PolicyLossWithoutReg Max            422.195
trainer/PolicyLossWithoutReg Min             -2.53806
exploration/num steps total              781000
exploration/num paths total                1569
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48381
exploration/Rewards Std                       1.05949
exploration/Rewards Max                       7.22947
exploration/Rewards Min                      -1.07784
exploration/Returns Mean                   4483.81
exploration/Returns Std                       0
exploration/Returns Max                    4483.81
exploration/Returns Min                    4483.81
exploration/Num Paths                         1
exploration/Average Returns                4483.81
evaluation_0/num steps total                  6.07986e+06
evaluation_0/num paths total               9696
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87842
evaluation_0/Rewards Std                      1.0986
evaluation_0/Rewards Max                      8.01542
evaluation_0/Rewards Min                     -0.628119
evaluation_0/Returns Mean                  4878.42
evaluation_0/Returns Std                     63.1674
evaluation_0/Returns Max                   4995.36
evaluation_0/Returns Min                   4773.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4878.42
time/epoch (s)                                0
time/total (s)                            11747.6
Epoch                                       776
---------------------------------------  ----------------
2022-11-16 19:30:45.579628 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 777 finished
---------------------------------------  ----------------
epoch                                       777
total_step                               782000
replay_pool/size                         782000
trainer/alpha                                 0.0588177
trainer/alpha_loss                           -0.794051
trainer/entropy                              -5.71974
trainer/qf_loss                              27.7174
trainer/policy_loss                        -345.403
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.739
trainer/entropy_penalty                      -0.336422
trainer/entropy_percentage                   -0.000973052
trainer/Q1Pred Mean                         344.933
trainer/Q1Pred Std                           59.5547
trainer/Q1Pred Max                          425.559
trainer/Q1Pred Min                           10.8481
trainer/Q2Pred Mean                         345.56
trainer/Q2Pred Std                           59.947
trainer/Q2Pred Max                          426.08
trainer/Q2Pred Min                            4.40875
trainer/QTargetWithReg Mean                 344.504
trainer/QTargetWithReg Std                   60.0726
trainer/QTargetWithReg Max                  427.558
trainer/QTargetWithReg Min                    6.71876
trainer/PolicyLossWithoutReg Mean           345.739
trainer/PolicyLossWithoutReg Std             59.5819
trainer/PolicyLossWithoutReg Max            426.688
trainer/PolicyLossWithoutReg Min              6.33051
exploration/num steps total              782000
exploration/num paths total                1570
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44825
exploration/Rewards Std                       0.986605
exploration/Rewards Max                       7.17039
exploration/Rewards Min                      -0.751593
exploration/Returns Mean                   4448.25
exploration/Returns Std                       0
exploration/Returns Max                    4448.25
exploration/Returns Min                    4448.25
exploration/Num Paths                         1
exploration/Average Returns                4448.25
evaluation_0/num steps total                  6.08786e+06
evaluation_0/num paths total               9704
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66792
evaluation_0/Rewards Std                      1.15237
evaluation_0/Rewards Max                      7.40594
evaluation_0/Rewards Min                     -0.6555
evaluation_0/Returns Mean                  4667.92
evaluation_0/Returns Std                    167.686
evaluation_0/Returns Max                   4866.96
evaluation_0/Returns Min                   4348.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4667.92
time/epoch (s)                                0
time/total (s)                            11762.5
Epoch                                       777
---------------------------------------  ----------------
2022-11-16 19:31:00.241082 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 778 finished
---------------------------------------  ----------------
epoch                                       778
total_step                               783000
replay_pool/size                         783000
trainer/alpha                                 0.0616252
trainer/alpha_loss                           -1.06128
trainer/entropy                              -5.61916
trainer/qf_loss                              16.3209
trainer/policy_loss                        -354.674
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.02
trainer/entropy_penalty                      -0.346282
trainer/entropy_percentage                   -0.000975386
trainer/Q1Pred Mean                         354.028
trainer/Q1Pred Std                           53.9294
trainer/Q1Pred Max                          432.734
trainer/Q1Pred Min                           84.9417
trainer/Q2Pred Mean                         354.429
trainer/Q2Pred Std                           54.4933
trainer/Q2Pred Max                          428.538
trainer/Q2Pred Min                           70.1453
trainer/QTargetWithReg Mean                 354.82
trainer/QTargetWithReg Std                   53.9772
trainer/QTargetWithReg Max                  429.153
trainer/QTargetWithReg Min                   73.078
trainer/PolicyLossWithoutReg Mean           355.02
trainer/PolicyLossWithoutReg Std             53.3582
trainer/PolicyLossWithoutReg Max            428.648
trainer/PolicyLossWithoutReg Min             96.0405
exploration/num steps total              783000
exploration/num paths total                1571
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61922
exploration/Rewards Std                       1.16395
exploration/Rewards Max                       7.20404
exploration/Rewards Min                      -0.457096
exploration/Returns Mean                   4619.22
exploration/Returns Std                       0
exploration/Returns Max                    4619.22
exploration/Returns Min                    4619.22
exploration/Num Paths                         1
exploration/Average Returns                4619.22
evaluation_0/num steps total                  6.09586e+06
evaluation_0/num paths total               9712
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69419
evaluation_0/Rewards Std                      1.04934
evaluation_0/Rewards Max                      7.56826
evaluation_0/Rewards Min                     -0.700161
evaluation_0/Returns Mean                  4694.19
evaluation_0/Returns Std                     59.1206
evaluation_0/Returns Max                   4777.43
evaluation_0/Returns Min                   4610.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4694.19
time/epoch (s)                                0
time/total (s)                            11777.1
Epoch                                       778
---------------------------------------  ----------------
2022-11-16 19:31:14.799542 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 779 finished
---------------------------------------  ----------------
epoch                                       779
total_step                               784000
replay_pool/size                         784000
trainer/alpha                                 0.0597572
trainer/alpha_loss                           -1.73239
trainer/entropy                              -5.38511
trainer/qf_loss                              19.658
trainer/policy_loss                        -352.967
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.289
trainer/entropy_penalty                      -0.321799
trainer/entropy_percentage                   -0.000910867
trainer/Q1Pred Mean                         353.789
trainer/Q1Pred Std                           58.3661
trainer/Q1Pred Max                          429.439
trainer/Q1Pred Min                           21.4619
trainer/Q2Pred Mean                         353.32
trainer/Q2Pred Std                           58.7296
trainer/Q2Pred Max                          426.72
trainer/Q2Pred Min                           26.9201
trainer/QTargetWithReg Mean                 352.249
trainer/QTargetWithReg Std                   59.1006
trainer/QTargetWithReg Max                  428.329
trainer/QTargetWithReg Min                   21.7171
trainer/PolicyLossWithoutReg Mean           353.289
trainer/PolicyLossWithoutReg Std             57.585
trainer/PolicyLossWithoutReg Max            425.379
trainer/PolicyLossWithoutReg Min             20.8563
exploration/num steps total              784000
exploration/num paths total                1572
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66288
exploration/Rewards Std                       0.977103
exploration/Rewards Max                       7.02489
exploration/Rewards Min                      -0.776024
exploration/Returns Mean                   4662.88
exploration/Returns Std                       0
exploration/Returns Max                    4662.88
exploration/Returns Min                    4662.88
exploration/Num Paths                         1
exploration/Average Returns                4662.88
evaluation_0/num steps total                  6.10386e+06
evaluation_0/num paths total               9720
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80306
evaluation_0/Rewards Std                      1.08455
evaluation_0/Rewards Max                      7.66973
evaluation_0/Rewards Min                     -0.457758
evaluation_0/Returns Mean                  4803.06
evaluation_0/Returns Std                    174.142
evaluation_0/Returns Max                   5000.24
evaluation_0/Returns Min                   4518.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4803.06
time/epoch (s)                                0
time/total (s)                            11791.7
Epoch                                       779
---------------------------------------  ----------------
2022-11-16 19:31:29.538541 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 780 finished
---------------------------------------  ----------------
epoch                                       780
total_step                               785000
replay_pool/size                         785000
trainer/alpha                                 0.0574396
trainer/alpha_loss                            0.760459
trainer/entropy                              -6.26617
trainer/qf_loss                              21.2296
trainer/policy_loss                        -347.077
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.437
trainer/entropy_penalty                      -0.359926
trainer/entropy_percentage                   -0.00103595
trainer/Q1Pred Mean                         346.983
trainer/Q1Pred Std                           67.8955
trainer/Q1Pred Max                          420.305
trainer/Q1Pred Min                           24.6661
trainer/Q2Pred Mean                         347.247
trainer/Q2Pred Std                           67.0101
trainer/Q2Pred Max                          418.454
trainer/Q2Pred Min                           31.5063
trainer/QTargetWithReg Mean                 347.143
trainer/QTargetWithReg Std                   67.3419
trainer/QTargetWithReg Max                  420.61
trainer/QTargetWithReg Min                   30.2302
trainer/PolicyLossWithoutReg Mean           347.437
trainer/PolicyLossWithoutReg Std             66.609
trainer/PolicyLossWithoutReg Max            419.778
trainer/PolicyLossWithoutReg Min             29.5627
exploration/num steps total              785000
exploration/num paths total                1574
exploration/path length this epoch Mean     355
exploration/path length this epoch Std      120
exploration/path length this epoch Max      475
exploration/path length this epoch Min      235
exploration/Rewards Mean                      4.1615
exploration/Rewards Std                       1.46531
exploration/Rewards Max                       8.11524
exploration/Rewards Min                      -0.496984
exploration/Returns Mean                   1477.33
exploration/Returns Std                     636.647
exploration/Returns Max                    2113.98
exploration/Returns Min                     840.686
exploration/Num Paths                         2
exploration/Average Returns                1477.33
evaluation_0/num steps total                  6.11186e+06
evaluation_0/num paths total               9728
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85314
evaluation_0/Rewards Std                      1.0664
evaluation_0/Rewards Max                      7.87297
evaluation_0/Rewards Min                     -0.757439
evaluation_0/Returns Mean                  4853.14
evaluation_0/Returns Std                     88.4098
evaluation_0/Returns Max                   5033.13
evaluation_0/Returns Min                   4724.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4853.14
time/epoch (s)                                0
time/total (s)                            11806.4
Epoch                                       780
---------------------------------------  ----------------
2022-11-16 19:31:44.257815 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 781 finished
---------------------------------------  ----------------
epoch                                       781
total_step                               786000
replay_pool/size                         786000
trainer/alpha                                 0.0572117
trainer/alpha_loss                           -0.0717645
trainer/entropy                              -5.97492
trainer/qf_loss                              25.1519
trainer/policy_loss                        -344.876
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.218
trainer/entropy_penalty                      -0.341835
trainer/entropy_percentage                   -0.0009902
trainer/Q1Pred Mean                         344.17
trainer/Q1Pred Std                           64.3554
trainer/Q1Pred Max                          433.13
trainer/Q1Pred Min                           13.3426
trainer/Q2Pred Mean                         344.617
trainer/Q2Pred Std                           64.3043
trainer/Q2Pred Max                          433.206
trainer/Q2Pred Min                           12.1449
trainer/QTargetWithReg Mean                 343.892
trainer/QTargetWithReg Std                   64.312
trainer/QTargetWithReg Max                  431.558
trainer/QTargetWithReg Min                  -12.4827
trainer/PolicyLossWithoutReg Mean           345.218
trainer/PolicyLossWithoutReg Std             63.9431
trainer/PolicyLossWithoutReg Max            432.706
trainer/PolicyLossWithoutReg Min              9.34131
exploration/num steps total              786000
exploration/num paths total                1575
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73715
exploration/Rewards Std                       1.08202
exploration/Rewards Max                       7.36555
exploration/Rewards Min                      -0.850419
exploration/Returns Mean                   4737.15
exploration/Returns Std                       0
exploration/Returns Max                    4737.15
exploration/Returns Min                    4737.15
exploration/Num Paths                         1
exploration/Average Returns                4737.15
evaluation_0/num steps total                  6.11986e+06
evaluation_0/num paths total               9736
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68861
evaluation_0/Rewards Std                      1.05739
evaluation_0/Rewards Max                      7.61937
evaluation_0/Rewards Min                     -0.660164
evaluation_0/Returns Mean                  4688.61
evaluation_0/Returns Std                     97.6795
evaluation_0/Returns Max                   4911.55
evaluation_0/Returns Min                   4548.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4688.61
time/epoch (s)                                0
time/total (s)                            11821.2
Epoch                                       781
---------------------------------------  ----------------
2022-11-16 19:31:59.076191 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 782 finished
---------------------------------------  ----------------
epoch                                       782
total_step                               787000
replay_pool/size                         787000
trainer/alpha                                 0.059811
trainer/alpha_loss                            0.564358
trainer/entropy                              -6.20037
trainer/qf_loss                              20.1348
trainer/policy_loss                        -343.389
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.76
trainer/entropy_penalty                      -0.37085
trainer/entropy_percentage                   -0.00107881
trainer/Q1Pred Mean                         342.99
trainer/Q1Pred Std                           65.1666
trainer/Q1Pred Max                          433.269
trainer/Q1Pred Min                           13.7122
trainer/Q2Pred Mean                         343.296
trainer/Q2Pred Std                           65.338
trainer/Q2Pred Max                          435.505
trainer/Q2Pred Min                           19.2537
trainer/QTargetWithReg Mean                 344.028
trainer/QTargetWithReg Std                   65.511
trainer/QTargetWithReg Max                  434.352
trainer/QTargetWithReg Min                   23.1046
trainer/PolicyLossWithoutReg Mean           343.76
trainer/PolicyLossWithoutReg Std             64.1637
trainer/PolicyLossWithoutReg Max            434.518
trainer/PolicyLossWithoutReg Min             19.3398
exploration/num steps total              787000
exploration/num paths total                1576
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.44723
exploration/Rewards Std                       1.01952
exploration/Rewards Max                       7.61436
exploration/Rewards Min                      -0.591725
exploration/Returns Mean                   4447.23
exploration/Returns Std                       0
exploration/Returns Max                    4447.23
exploration/Returns Min                    4447.23
exploration/Num Paths                         1
exploration/Average Returns                4447.23
evaluation_0/num steps total                  6.12786e+06
evaluation_0/num paths total               9744
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88209
evaluation_0/Rewards Std                      1.04977
evaluation_0/Rewards Max                      7.52362
evaluation_0/Rewards Min                     -0.662149
evaluation_0/Returns Mean                  4882.09
evaluation_0/Returns Std                     66.0746
evaluation_0/Returns Max                   4963.76
evaluation_0/Returns Min                   4765.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4882.09
time/epoch (s)                                0
time/total (s)                            11836
Epoch                                       782
---------------------------------------  ----------------
2022-11-16 19:32:14.006344 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 783 finished
---------------------------------------  ----------------
epoch                                       783
total_step                               788000
replay_pool/size                         788000
trainer/alpha                                 0.0606103
trainer/alpha_loss                            0.664872
trainer/entropy                              -6.23717
trainer/qf_loss                              23.0049
trainer/policy_loss                        -344.811
trainer/adversary_policy_loss                16.3935
trainer/policy_loss_without_entropy         345.189
trainer/entropy_penalty                      -0.378037
trainer/entropy_percentage                   -0.00109516
trainer/Q1Pred Mean                         343.16
trainer/Q1Pred Std                           66.3209
trainer/Q1Pred Max                          421.521
trainer/Q1Pred Min                           -3.59878
trainer/Q2Pred Mean                         343.726
trainer/Q2Pred Std                           65.9184
trainer/Q2Pred Max                          421.631
trainer/Q2Pred Min                          -10.0215
trainer/QTargetWithReg Mean                 343.112
trainer/QTargetWithReg Std                   66.087
trainer/QTargetWithReg Max                  424.275
trainer/QTargetWithReg Min                   -0.848517
trainer/PolicyLossWithoutReg Mean           345.189
trainer/PolicyLossWithoutReg Std             63.3153
trainer/PolicyLossWithoutReg Max            422.98
trainer/PolicyLossWithoutReg Min             30.4953
exploration/num steps total              788000
exploration/num paths total                1577
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58401
exploration/Rewards Std                       0.972503
exploration/Rewards Max                       7.11389
exploration/Rewards Min                      -0.680119
exploration/Returns Mean                   4584.01
exploration/Returns Std                       0
exploration/Returns Max                    4584.01
exploration/Returns Min                    4584.01
exploration/Num Paths                         1
exploration/Average Returns                4584.01
evaluation_0/num steps total                  6.13586e+06
evaluation_0/num paths total               9752
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.781
evaluation_0/Rewards Std                      1.02762
evaluation_0/Rewards Max                      7.64316
evaluation_0/Rewards Min                     -0.750234
evaluation_0/Returns Mean                  4781
evaluation_0/Returns Std                     54.2776
evaluation_0/Returns Max                   4841.39
evaluation_0/Returns Min                   4675.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4781
time/epoch (s)                                0
time/total (s)                            11850.9
Epoch                                       783
---------------------------------------  ----------------
2022-11-16 19:32:28.879253 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 784 finished
---------------------------------------  ----------------
epoch                                       784
total_step                               789000
replay_pool/size                         789000
trainer/alpha                                 0.0619639
trainer/alpha_loss                            1.255
trainer/entropy                              -6.45127
trainer/qf_loss                              26.6312
trainer/policy_loss                        -341.368
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.768
trainer/entropy_penalty                      -0.399745
trainer/entropy_percentage                   -0.00116964
trainer/Q1Pred Mean                         340.223
trainer/Q1Pred Std                           62.0361
trainer/Q1Pred Max                          424.702
trainer/Q1Pred Min                           30.2653
trainer/Q2Pred Mean                         339.431
trainer/Q2Pred Std                           62.4924
trainer/Q2Pred Max                          423.644
trainer/Q2Pred Min                           28.7389
trainer/QTargetWithReg Mean                 338.988
trainer/QTargetWithReg Std                   62.4251
trainer/QTargetWithReg Max                  423.109
trainer/QTargetWithReg Min                   27.6373
trainer/PolicyLossWithoutReg Mean           341.768
trainer/PolicyLossWithoutReg Std             61.1834
trainer/PolicyLossWithoutReg Max            424.141
trainer/PolicyLossWithoutReg Min             31.4202
exploration/num steps total              789000
exploration/num paths total                1578
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55604
exploration/Rewards Std                       1.04341
exploration/Rewards Max                       6.82955
exploration/Rewards Min                      -0.699941
exploration/Returns Mean                   4556.04
exploration/Returns Std                       0
exploration/Returns Max                    4556.04
exploration/Returns Min                    4556.04
exploration/Num Paths                         1
exploration/Average Returns                4556.04
evaluation_0/num steps total                  6.14386e+06
evaluation_0/num paths total               9760
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80366
evaluation_0/Rewards Std                      1.0757
evaluation_0/Rewards Max                      7.80704
evaluation_0/Rewards Min                     -0.711704
evaluation_0/Returns Mean                  4803.66
evaluation_0/Returns Std                    125.31
evaluation_0/Returns Max                   5012.89
evaluation_0/Returns Min                   4599.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4803.66
time/epoch (s)                                0
time/total (s)                            11865.8
Epoch                                       784
---------------------------------------  ----------------
2022-11-16 19:32:43.690421 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 785 finished
---------------------------------------  ----------------
epoch                                       785
total_step                               790000
replay_pool/size                         790000
trainer/alpha                                 0.0602512
trainer/alpha_loss                            0.23307
trainer/entropy                              -6.08297
trainer/qf_loss                              18.417
trainer/policy_loss                        -341.61
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.977
trainer/entropy_penalty                      -0.366506
trainer/entropy_percentage                   -0.00107173
trainer/Q1Pred Mean                         340.556
trainer/Q1Pred Std                           70.3945
trainer/Q1Pred Max                          435.655
trainer/Q1Pred Min                            8.52192
trainer/Q2Pred Mean                         340.95
trainer/Q2Pred Std                           70.9176
trainer/Q2Pred Max                          434.885
trainer/Q2Pred Min                            4.90818
trainer/QTargetWithReg Mean                 340.47
trainer/QTargetWithReg Std                   70.4743
trainer/QTargetWithReg Max                  433.727
trainer/QTargetWithReg Min                    3.35024
trainer/PolicyLossWithoutReg Mean           341.977
trainer/PolicyLossWithoutReg Std             69.2228
trainer/PolicyLossWithoutReg Max            435.413
trainer/PolicyLossWithoutReg Min              4.45657
exploration/num steps total              790000
exploration/num paths total                1579
exploration/path length this epoch Mean     499
exploration/path length this epoch Std        0
exploration/path length this epoch Max      499
exploration/path length this epoch Min      499
exploration/Rewards Mean                      4.26573
exploration/Rewards Std                       1.26968
exploration/Rewards Max                       7.05528
exploration/Rewards Min                      -0.692685
exploration/Returns Mean                   2128.6
exploration/Returns Std                       0
exploration/Returns Max                    2128.6
exploration/Returns Min                    2128.6
exploration/Num Paths                         1
exploration/Average Returns                2128.6
evaluation_0/num steps total                  6.15186e+06
evaluation_0/num paths total               9768
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73113
evaluation_0/Rewards Std                      1.0363
evaluation_0/Rewards Max                      7.68641
evaluation_0/Rewards Min                     -0.671141
evaluation_0/Returns Mean                  4731.13
evaluation_0/Returns Std                     68.9888
evaluation_0/Returns Max                   4862.39
evaluation_0/Returns Min                   4623.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4731.13
time/epoch (s)                                0
time/total (s)                            11880.6
Epoch                                       785
---------------------------------------  ----------------
2022-11-16 19:32:58.509722 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 786 finished
---------------------------------------  ----------------
epoch                                       786
total_step                               791000
replay_pool/size                         791000
trainer/alpha                                 0.0597575
trainer/alpha_loss                            1.67462
trainer/entropy                              -6.5943
trainer/qf_loss                              27.1611
trainer/policy_loss                        -340.587
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.981
trainer/entropy_penalty                      -0.394059
trainer/entropy_percentage                   -0.00115566
trainer/Q1Pred Mean                         339.511
trainer/Q1Pred Std                           77.3899
trainer/Q1Pred Max                          424.604
trainer/Q1Pred Min                           17.5623
trainer/Q2Pred Mean                         339.75
trainer/Q2Pred Std                           77.3895
trainer/Q2Pred Max                          425.434
trainer/Q2Pred Min                           17.6049
trainer/QTargetWithReg Mean                 340.006
trainer/QTargetWithReg Std                   77.1045
trainer/QTargetWithReg Max                  424.395
trainer/QTargetWithReg Min                   13.5986
trainer/PolicyLossWithoutReg Mean           340.981
trainer/PolicyLossWithoutReg Std             75.8292
trainer/PolicyLossWithoutReg Max            424.365
trainer/PolicyLossWithoutReg Min             19.1356
exploration/num steps total              791000
exploration/num paths total                1580
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71924
exploration/Rewards Std                       1.13585
exploration/Rewards Max                       7.44317
exploration/Rewards Min                      -0.8259
exploration/Returns Mean                   4719.24
exploration/Returns Std                       0
exploration/Returns Max                    4719.24
exploration/Returns Min                    4719.24
exploration/Num Paths                         1
exploration/Average Returns                4719.24
evaluation_0/num steps total                  6.15986e+06
evaluation_0/num paths total               9776
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85115
evaluation_0/Rewards Std                      1.11254
evaluation_0/Rewards Max                      7.90195
evaluation_0/Rewards Min                     -0.802035
evaluation_0/Returns Mean                  4851.15
evaluation_0/Returns Std                    155.891
evaluation_0/Returns Max                   5040.38
evaluation_0/Returns Min                   4616.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4851.15
time/epoch (s)                                0
time/total (s)                            11895.4
Epoch                                       786
---------------------------------------  ----------------
2022-11-16 19:33:15.414156 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 787 finished
---------------------------------------  ----------------
epoch                                       787
total_step                               792000
replay_pool/size                         792000
trainer/alpha                                 0.059265
trainer/alpha_loss                           -1.42617
trainer/entropy                              -5.49525
trainer/qf_loss                              84.9189
trainer/policy_loss                        -345.488
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.814
trainer/entropy_penalty                      -0.325676
trainer/entropy_percentage                   -0.000941767
trainer/Q1Pred Mean                         344.059
trainer/Q1Pred Std                           74.1444
trainer/Q1Pred Max                          424.153
trainer/Q1Pred Min                            6.67732
trainer/Q2Pred Mean                         344.842
trainer/Q2Pred Std                           73.735
trainer/Q2Pred Max                          423.87
trainer/Q2Pred Min                           11.1013
trainer/QTargetWithReg Mean                 344.808
trainer/QTargetWithReg Std                   74.0018
trainer/QTargetWithReg Max                  425.427
trainer/QTargetWithReg Min                   14.0256
trainer/PolicyLossWithoutReg Mean           345.814
trainer/PolicyLossWithoutReg Std             72.8859
trainer/PolicyLossWithoutReg Max            424.744
trainer/PolicyLossWithoutReg Min              9.08551
exploration/num steps total              792000
exploration/num paths total                1581
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51118
exploration/Rewards Std                       1.11673
exploration/Rewards Max                       7.17831
exploration/Rewards Min                      -0.649128
exploration/Returns Mean                   4511.18
exploration/Returns Std                       0
exploration/Returns Max                    4511.18
exploration/Returns Min                    4511.18
exploration/Num Paths                         1
exploration/Average Returns                4511.18
evaluation_0/num steps total                  6.16729e+06
evaluation_0/num paths total               9784
evaluation_0/path length Mean               928.625
evaluation_0/path length Std                188.84
evaluation_0/path length Max               1000
evaluation_0/path length Min                429
evaluation_0/Rewards Mean                     4.64981
evaluation_0/Rewards Std                      1.0411
evaluation_0/Rewards Max                      9.05806
evaluation_0/Rewards Min                     -0.672209
evaluation_0/Returns Mean                  4317.93
evaluation_0/Returns Std                    952.512
evaluation_0/Returns Max                   4870
evaluation_0/Returns Min                   1816.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4317.93
time/epoch (s)                                0
time/total (s)                            11912.3
Epoch                                       787
---------------------------------------  ----------------
2022-11-16 19:33:30.485354 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 788 finished
---------------------------------------  ----------------
epoch                                       788
total_step                               793000
replay_pool/size                         793000
trainer/alpha                                 0.0589457
trainer/alpha_loss                            1.21443
trainer/entropy                              -6.42892
trainer/qf_loss                              22.5828
trainer/policy_loss                        -342.036
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.415
trainer/entropy_penalty                      -0.378957
trainer/entropy_percentage                   -0.00110672
trainer/Q1Pred Mean                         340.99
trainer/Q1Pred Std                           72.6856
trainer/Q1Pred Max                          435.239
trainer/Q1Pred Min                          -16.0289
trainer/Q2Pred Mean                         341.153
trainer/Q2Pred Std                           72.3764
trainer/Q2Pred Max                          436.118
trainer/Q2Pred Min                          -21.3733
trainer/QTargetWithReg Mean                 342.468
trainer/QTargetWithReg Std                   72.0038
trainer/QTargetWithReg Max                  437.662
trainer/QTargetWithReg Min                   -0.850018
trainer/PolicyLossWithoutReg Mean           342.415
trainer/PolicyLossWithoutReg Std             71.1239
trainer/PolicyLossWithoutReg Max            436.523
trainer/PolicyLossWithoutReg Min              0.471554
exploration/num steps total              793000
exploration/num paths total                1582
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72655
exploration/Rewards Std                       1.06392
exploration/Rewards Max                       7.39077
exploration/Rewards Min                      -0.830521
exploration/Returns Mean                   4726.55
exploration/Returns Std                       0
exploration/Returns Max                    4726.55
exploration/Returns Min                    4726.55
exploration/Num Paths                         1
exploration/Average Returns                4726.55
evaluation_0/num steps total                  6.17529e+06
evaluation_0/num paths total               9792
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59916
evaluation_0/Rewards Std                      1.08566
evaluation_0/Rewards Max                      8.29828
evaluation_0/Rewards Min                     -0.659807
evaluation_0/Returns Mean                  4599.16
evaluation_0/Returns Std                    123.72
evaluation_0/Returns Max                   4775.92
evaluation_0/Returns Min                   4450.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4599.16
time/epoch (s)                                0
time/total (s)                            11927.4
Epoch                                       788
---------------------------------------  ----------------
2022-11-16 19:33:45.333535 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 789 finished
---------------------------------------  ----------------
epoch                                       789
total_step                               794000
replay_pool/size                         794000
trainer/alpha                                 0.0600443
trainer/alpha_loss                            1.69721
trainer/entropy                              -6.60341
trainer/qf_loss                              37.7399
trainer/policy_loss                        -336.982
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         337.378
trainer/entropy_penalty                      -0.396498
trainer/entropy_percentage                   -0.00117523
trainer/Q1Pred Mean                         335.264
trainer/Q1Pred Std                           80.3724
trainer/Q1Pred Max                          426.433
trainer/Q1Pred Min                          -37.9652
trainer/Q2Pred Mean                         335.417
trainer/Q2Pred Std                           80.9887
trainer/Q2Pred Max                          423.426
trainer/Q2Pred Min                          -37.2024
trainer/QTargetWithReg Mean                 335.232
trainer/QTargetWithReg Std                   80.8508
trainer/QTargetWithReg Max                  423.883
trainer/QTargetWithReg Min                  -23.2108
trainer/PolicyLossWithoutReg Mean           337.378
trainer/PolicyLossWithoutReg Std             77.4161
trainer/PolicyLossWithoutReg Max            426.658
trainer/PolicyLossWithoutReg Min            -46.7424
exploration/num steps total              794000
exploration/num paths total                1583
exploration/path length this epoch Mean     559
exploration/path length this epoch Std        0
exploration/path length this epoch Max      559
exploration/path length this epoch Min      559
exploration/Rewards Mean                      3.94498
exploration/Rewards Std                       1.12817
exploration/Rewards Max                       7.07018
exploration/Rewards Min                      -0.751567
exploration/Returns Mean                   2205.25
exploration/Returns Std                       0
exploration/Returns Max                    2205.25
exploration/Returns Min                    2205.25
exploration/Num Paths                         1
exploration/Average Returns                2205.25
evaluation_0/num steps total                  6.18329e+06
evaluation_0/num paths total               9800
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85663
evaluation_0/Rewards Std                      1.08227
evaluation_0/Rewards Max                      7.45317
evaluation_0/Rewards Min                     -0.748257
evaluation_0/Returns Mean                  4856.63
evaluation_0/Returns Std                     34.7504
evaluation_0/Returns Max                   4915.92
evaluation_0/Returns Min                   4820.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4856.63
time/epoch (s)                                0
time/total (s)                            11942.2
Epoch                                       789
---------------------------------------  ----------------
2022-11-16 19:34:02.087564 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 790 finished
---------------------------------------  ---------------
epoch                                       790
total_step                               795000
replay_pool/size                         795000
trainer/alpha                                 0.0603714
trainer/alpha_loss                           -0.317657
trainer/entropy                              -5.88685
trainer/qf_loss                              23.6738
trainer/policy_loss                        -349.722
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.077
trainer/entropy_penalty                      -0.355397
trainer/entropy_percentage                   -0.0010152
trainer/Q1Pred Mean                         349.337
trainer/Q1Pred Std                           59.0761
trainer/Q1Pred Max                          437.73
trainer/Q1Pred Min                           74.4622
trainer/Q2Pred Mean                         349.665
trainer/Q2Pred Std                           59.0613
trainer/Q2Pred Max                          442.311
trainer/Q2Pred Min                           80.6925
trainer/QTargetWithReg Mean                 349.517
trainer/QTargetWithReg Std                   59.4052
trainer/QTargetWithReg Max                  436.913
trainer/QTargetWithReg Min                   72.8977
trainer/PolicyLossWithoutReg Mean           350.077
trainer/PolicyLossWithoutReg Std             58.5963
trainer/PolicyLossWithoutReg Max            437.661
trainer/PolicyLossWithoutReg Min             73.3669
exploration/num steps total              795000
exploration/num paths total                1584
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38877
exploration/Rewards Std                       1.04417
exploration/Rewards Max                       6.75301
exploration/Rewards Min                      -0.765323
exploration/Returns Mean                   4388.77
exploration/Returns Std                       0
exploration/Returns Max                    4388.77
exploration/Returns Min                    4388.77
exploration/Num Paths                         1
exploration/Average Returns                4388.77
evaluation_0/num steps total                  6.1904e+06
evaluation_0/num paths total               9809
evaluation_0/path length Mean               789.778
evaluation_0/path length Std                298.664
evaluation_0/path length Max               1000
evaluation_0/path length Min                330
evaluation_0/Rewards Mean                     4.68236
evaluation_0/Rewards Std                      1.09615
evaluation_0/Rewards Max                      7.73791
evaluation_0/Rewards Min                     -0.778469
evaluation_0/Returns Mean                  3698.03
evaluation_0/Returns Std                   1566.37
evaluation_0/Returns Max                   4913.97
evaluation_0/Returns Min                   1254.24
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3698.03
time/epoch (s)                                0
time/total (s)                            11959
Epoch                                       790
---------------------------------------  ---------------
2022-11-16 19:34:17.467277 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 791 finished
---------------------------------------  ---------------
epoch                                       791
total_step                               796000
replay_pool/size                         796000
trainer/alpha                                 0.058973
trainer/alpha_loss                           -0.0505458
trainer/entropy                              -5.98214
trainer/qf_loss                              24.2331
trainer/policy_loss                        -348.308
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.661
trainer/entropy_penalty                      -0.352785
trainer/entropy_percentage                   -0.00101183
trainer/Q1Pred Mean                         346.962
trainer/Q1Pred Std                           59.0627
trainer/Q1Pred Max                          429.969
trainer/Q1Pred Min                           15.0909
trainer/Q2Pred Mean                         347.348
trainer/Q2Pred Std                           59.6281
trainer/Q2Pred Max                          430.538
trainer/Q2Pred Min                           23.002
trainer/QTargetWithReg Mean                 347.833
trainer/QTargetWithReg Std                   59.7239
trainer/QTargetWithReg Max                  429.793
trainer/QTargetWithReg Min                   14.285
trainer/PolicyLossWithoutReg Mean           348.661
trainer/PolicyLossWithoutReg Std             58.8657
trainer/PolicyLossWithoutReg Max            430.794
trainer/PolicyLossWithoutReg Min             17.5228
exploration/num steps total              796000
exploration/num paths total                1585
exploration/path length this epoch Mean     870
exploration/path length this epoch Std        0
exploration/path length this epoch Max      870
exploration/path length this epoch Min      870
exploration/Rewards Mean                      4.5458
exploration/Rewards Std                       1.19349
exploration/Rewards Max                       7.12483
exploration/Rewards Min                      -0.692698
exploration/Returns Mean                   3954.84
exploration/Returns Std                       0
exploration/Returns Max                    3954.84
exploration/Returns Min                    3954.84
exploration/Num Paths                         1
exploration/Average Returns                3954.84
evaluation_0/num steps total                  6.1984e+06
evaluation_0/num paths total               9817
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77395
evaluation_0/Rewards Std                      1.04071
evaluation_0/Rewards Max                      7.8133
evaluation_0/Rewards Min                     -0.745496
evaluation_0/Returns Mean                  4773.95
evaluation_0/Returns Std                     55.3914
evaluation_0/Returns Max                   4865.01
evaluation_0/Returns Min                   4713.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4773.95
time/epoch (s)                                0
time/total (s)                            11974.4
Epoch                                       791
---------------------------------------  ---------------
2022-11-16 19:34:32.528144 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 792 finished
---------------------------------------  ----------------
epoch                                       792
total_step                               797000
replay_pool/size                         797000
trainer/alpha                                 0.0603724
trainer/alpha_loss                           -1.72388
trainer/entropy                              -5.38587
trainer/qf_loss                              19.0851
trainer/policy_loss                        -342.833
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.159
trainer/entropy_penalty                      -0.325158
trainer/entropy_percentage                   -0.000947543
trainer/Q1Pred Mean                         341.859
trainer/Q1Pred Std                           78.2724
trainer/Q1Pred Max                          428.171
trainer/Q1Pred Min                            1.62307
trainer/Q2Pred Mean                         342.117
trainer/Q2Pred Std                           78.2656
trainer/Q2Pred Max                          429.326
trainer/Q2Pred Min                           -2.94673
trainer/QTargetWithReg Mean                 341.454
trainer/QTargetWithReg Std                   78.9289
trainer/QTargetWithReg Max                  426.528
trainer/QTargetWithReg Min                    0.241842
trainer/PolicyLossWithoutReg Mean           343.159
trainer/PolicyLossWithoutReg Std             77.3852
trainer/PolicyLossWithoutReg Max            427.997
trainer/PolicyLossWithoutReg Min             -0.914544
exploration/num steps total              797000
exploration/num paths total                1586
exploration/path length this epoch Mean     670
exploration/path length this epoch Std        0
exploration/path length this epoch Max      670
exploration/path length this epoch Min      670
exploration/Rewards Mean                      4.30381
exploration/Rewards Std                       1.17413
exploration/Rewards Max                       7.25095
exploration/Rewards Min                      -0.638641
exploration/Returns Mean                   2883.55
exploration/Returns Std                       0
exploration/Returns Max                    2883.55
exploration/Returns Min                    2883.55
exploration/Num Paths                         1
exploration/Average Returns                2883.55
evaluation_0/num steps total                  6.2064e+06
evaluation_0/num paths total               9825
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81324
evaluation_0/Rewards Std                      1.08992
evaluation_0/Rewards Max                      7.55473
evaluation_0/Rewards Min                     -0.732601
evaluation_0/Returns Mean                  4813.24
evaluation_0/Returns Std                     63.8314
evaluation_0/Returns Max                   4914.39
evaluation_0/Returns Min                   4722.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4813.24
time/epoch (s)                                0
time/total (s)                            11989.4
Epoch                                       792
---------------------------------------  ----------------
2022-11-16 19:34:47.522734 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 793 finished
---------------------------------------  ---------------
epoch                                       793
total_step                               798000
replay_pool/size                         798000
trainer/alpha                                 0.0601016
trainer/alpha_loss                            1.30685
trainer/entropy                              -6.46482
trainer/qf_loss                              28.9503
trainer/policy_loss                        -339.042
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         339.431
trainer/entropy_penalty                      -0.388546
trainer/entropy_percentage                   -0.0011447
trainer/Q1Pred Mean                         338.716
trainer/Q1Pred Std                           67.6236
trainer/Q1Pred Max                          426.416
trainer/Q1Pred Min                           -4.40762
trainer/Q2Pred Mean                         339.397
trainer/Q2Pred Std                           67.2164
trainer/Q2Pred Max                          426.118
trainer/Q2Pred Min                           -4.1847
trainer/QTargetWithReg Mean                 339.109
trainer/QTargetWithReg Std                   66.7441
trainer/QTargetWithReg Max                  423.735
trainer/QTargetWithReg Min                    2.05731
trainer/PolicyLossWithoutReg Mean           339.431
trainer/PolicyLossWithoutReg Std             66.5058
trainer/PolicyLossWithoutReg Max            425.595
trainer/PolicyLossWithoutReg Min             -2.32381
exploration/num steps total              798000
exploration/num paths total                1587
exploration/path length this epoch Mean     593
exploration/path length this epoch Std        0
exploration/path length this epoch Max      593
exploration/path length this epoch Min      593
exploration/Rewards Mean                      4.56678
exploration/Rewards Std                       1.28477
exploration/Rewards Max                       7.38058
exploration/Rewards Min                      -0.763286
exploration/Returns Mean                   2708.1
exploration/Returns Std                       0
exploration/Returns Max                    2708.1
exploration/Returns Min                    2708.1
exploration/Num Paths                         1
exploration/Average Returns                2708.1
evaluation_0/num steps total                  6.2144e+06
evaluation_0/num paths total               9833
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9965
evaluation_0/Rewards Std                      1.10995
evaluation_0/Rewards Max                      8.08943
evaluation_0/Rewards Min                     -0.764357
evaluation_0/Returns Mean                  4996.5
evaluation_0/Returns Std                     87.1884
evaluation_0/Returns Max                   5114.48
evaluation_0/Returns Min                   4815.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4996.5
time/epoch (s)                                0
time/total (s)                            12004.4
Epoch                                       793
---------------------------------------  ---------------
2022-11-16 19:35:04.268242 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 794 finished
---------------------------------------  ----------------
epoch                                       794
total_step                               799000
replay_pool/size                         799000
trainer/alpha                                 0.0602268
trainer/alpha_loss                            1.39539
trainer/entropy                              -6.49665
trainer/qf_loss                              55.7238
trainer/policy_loss                        -343.786
trainer/adversary_policy_loss                16.3269
trainer/policy_loss_without_entropy         344.177
trainer/entropy_penalty                      -0.391273
trainer/entropy_percentage                   -0.00113684
trainer/Q1Pred Mean                         342.323
trainer/Q1Pred Std                           72.3048
trainer/Q1Pred Max                          435.093
trainer/Q1Pred Min                           -0.436638
trainer/Q2Pred Mean                         342.246
trainer/Q2Pred Std                           73.5454
trainer/Q2Pred Max                          436.592
trainer/Q2Pred Min                          -39.4189
trainer/QTargetWithReg Mean                 342.456
trainer/QTargetWithReg Std                   71.7976
trainer/QTargetWithReg Max                  436.822
trainer/QTargetWithReg Min                    0.181247
trainer/PolicyLossWithoutReg Mean           344.177
trainer/PolicyLossWithoutReg Std             70.5082
trainer/PolicyLossWithoutReg Max            436.776
trainer/PolicyLossWithoutReg Min             25.2078
exploration/num steps total              799000
exploration/num paths total                1588
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.49996
exploration/Rewards Std                       0.983029
exploration/Rewards Max                       6.71594
exploration/Rewards Min                      -0.668581
exploration/Returns Mean                   4499.96
exploration/Returns Std                       0
exploration/Returns Max                    4499.96
exploration/Returns Min                    4499.96
exploration/Num Paths                         1
exploration/Average Returns                4499.96
evaluation_0/num steps total                  6.22147e+06
evaluation_0/num paths total               9841
evaluation_0/path length Mean               884.75
evaluation_0/path length Std                304.923
evaluation_0/path length Max               1000
evaluation_0/path length Min                 78
evaluation_0/Rewards Mean                     4.69881
evaluation_0/Rewards Std                      1.04545
evaluation_0/Rewards Max                      7.96747
evaluation_0/Rewards Min                     -0.713218
evaluation_0/Returns Mean                  4157.27
evaluation_0/Returns Std                   1501.22
evaluation_0/Returns Max                   4891.01
evaluation_0/Returns Min                    194.777
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4157.27
time/epoch (s)                                0
time/total (s)                            12021.2
Epoch                                       794
---------------------------------------  ----------------
2022-11-16 19:35:19.327296 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 795 finished
---------------------------------------  ----------------
epoch                                       795
total_step                               800000
replay_pool/size                         800000
trainer/alpha                                 0.0576822
trainer/alpha_loss                            0.709645
trainer/entropy                              -6.24876
trainer/qf_loss                              28.6779
trainer/policy_loss                        -340.064
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.424
trainer/entropy_penalty                      -0.360443
trainer/entropy_percentage                   -0.0010588
trainer/Q1Pred Mean                         340.165
trainer/Q1Pred Std                           74.1077
trainer/Q1Pred Max                          426.442
trainer/Q1Pred Min                           13.1413
trainer/Q2Pred Mean                         339.708
trainer/Q2Pred Std                           74.2335
trainer/Q2Pred Max                          426.152
trainer/Q2Pred Min                            9.08617
trainer/QTargetWithReg Mean                 339.904
trainer/QTargetWithReg Std                   74.7025
trainer/QTargetWithReg Max                  426.016
trainer/QTargetWithReg Min                   12.1885
trainer/PolicyLossWithoutReg Mean           340.424
trainer/PolicyLossWithoutReg Std             73.4333
trainer/PolicyLossWithoutReg Max            425.157
trainer/PolicyLossWithoutReg Min             11.7901
exploration/num steps total              800000
exploration/num paths total                1589
exploration/path length this epoch Mean      26
exploration/path length this epoch Std        0
exploration/path length this epoch Max       26
exploration/path length this epoch Min       26
exploration/Rewards Mean                      0.691268
exploration/Rewards Std                       1.00522
exploration/Rewards Max                       2.84481
exploration/Rewards Min                      -0.546334
exploration/Returns Mean                     17.973
exploration/Returns Std                       0
exploration/Returns Max                      17.973
exploration/Returns Min                      17.973
exploration/Num Paths                         1
exploration/Average Returns                  17.973
evaluation_0/num steps total                  6.22947e+06
evaluation_0/num paths total               9849
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75337
evaluation_0/Rewards Std                      1.03581
evaluation_0/Rewards Max                      7.80553
evaluation_0/Rewards Min                     -0.602284
evaluation_0/Returns Mean                  4753.37
evaluation_0/Returns Std                     56.1815
evaluation_0/Returns Max                   4840.23
evaluation_0/Returns Min                   4664.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4753.37
time/epoch (s)                                0
time/total (s)                            12036.2
Epoch                                       795
---------------------------------------  ----------------
2022-11-16 19:35:34.301470 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 796 finished
---------------------------------------  ----------------
epoch                                       796
total_step                               801000
replay_pool/size                         801000
trainer/alpha                                 0.0588019
trainer/alpha_loss                            0.504901
trainer/entropy                              -6.17818
trainer/qf_loss                              26.8716
trainer/policy_loss                        -346.124
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.487
trainer/entropy_penalty                      -0.363289
trainer/entropy_percentage                   -0.00104849
trainer/Q1Pred Mean                         345.107
trainer/Q1Pred Std                           63.2949
trainer/Q1Pred Max                          426.576
trainer/Q1Pred Min                           -5.44025
trainer/Q2Pred Mean                         345.925
trainer/Q2Pred Std                           63.6965
trainer/Q2Pred Max                          427.491
trainer/Q2Pred Min                           -3.86541
trainer/QTargetWithReg Mean                 346.2
trainer/QTargetWithReg Std                   62.5163
trainer/QTargetWithReg Max                  424.446
trainer/QTargetWithReg Min                    0.164019
trainer/PolicyLossWithoutReg Mean           346.487
trainer/PolicyLossWithoutReg Std             60.5467
trainer/PolicyLossWithoutReg Max            427.612
trainer/PolicyLossWithoutReg Min             12.158
exploration/num steps total              801000
exploration/num paths total                1590
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65753
exploration/Rewards Std                       1.02451
exploration/Rewards Max                       7.1513
exploration/Rewards Min                      -0.583167
exploration/Returns Mean                   4657.53
exploration/Returns Std                       0
exploration/Returns Max                    4657.53
exploration/Returns Min                    4657.53
exploration/Num Paths                         1
exploration/Average Returns                4657.53
evaluation_0/num steps total                  6.23747e+06
evaluation_0/num paths total               9857
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67362
evaluation_0/Rewards Std                      1.07384
evaluation_0/Rewards Max                      7.37518
evaluation_0/Rewards Min                     -0.87983
evaluation_0/Returns Mean                  4673.62
evaluation_0/Returns Std                    101.709
evaluation_0/Returns Max                   4824.42
evaluation_0/Returns Min                   4550.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4673.62
time/epoch (s)                                0
time/total (s)                            12051.2
Epoch                                       796
---------------------------------------  ----------------
2022-11-16 19:35:49.388168 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 797 finished
---------------------------------------  ----------------
epoch                                       797
total_step                               802000
replay_pool/size                         802000
trainer/alpha                                 0.0601933
trainer/alpha_loss                           -0.260769
trainer/entropy                              -5.9072
trainer/qf_loss                              20.8729
trainer/policy_loss                        -350.679
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.034
trainer/entropy_penalty                      -0.355574
trainer/entropy_percentage                   -0.00101293
trainer/Q1Pred Mean                         350.444
trainer/Q1Pred Std                           60.8742
trainer/Q1Pred Max                          430.204
trainer/Q1Pred Min                           41.5251
trainer/Q2Pred Mean                         350.526
trainer/Q2Pred Std                           61.2021
trainer/Q2Pred Max                          430.112
trainer/Q2Pred Min                           42.0222
trainer/QTargetWithReg Mean                 350.965
trainer/QTargetWithReg Std                   61.773
trainer/QTargetWithReg Max                  427.545
trainer/QTargetWithReg Min                   39.0842
trainer/PolicyLossWithoutReg Mean           351.034
trainer/PolicyLossWithoutReg Std             60.2547
trainer/PolicyLossWithoutReg Max            428.731
trainer/PolicyLossWithoutReg Min             40.2941
exploration/num steps total              802000
exploration/num paths total                1591
exploration/path length this epoch Mean     541
exploration/path length this epoch Std        0
exploration/path length this epoch Max      541
exploration/path length this epoch Min      541
exploration/Rewards Mean                      4.17304
exploration/Rewards Std                       1.28396
exploration/Rewards Max                       7.17332
exploration/Rewards Min                      -0.739537
exploration/Returns Mean                   2257.61
exploration/Returns Std                       0
exploration/Returns Max                    2257.61
exploration/Returns Min                    2257.61
exploration/Num Paths                         1
exploration/Average Returns                2257.61
evaluation_0/num steps total                  6.24547e+06
evaluation_0/num paths total               9865
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76972
evaluation_0/Rewards Std                      1.06908
evaluation_0/Rewards Max                      7.75725
evaluation_0/Rewards Min                     -0.728037
evaluation_0/Returns Mean                  4769.72
evaluation_0/Returns Std                     59.8462
evaluation_0/Returns Max                   4862.53
evaluation_0/Returns Min                   4682.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4769.72
time/epoch (s)                                0
time/total (s)                            12066.3
Epoch                                       797
---------------------------------------  ----------------
2022-11-16 19:36:04.374958 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 798 finished
---------------------------------------  ----------------
epoch                                       798
total_step                               803000
replay_pool/size                         803000
trainer/alpha                                 0.0601724
trainer/alpha_loss                           -0.0986653
trainer/entropy                              -5.96489
trainer/qf_loss                              28.3804
trainer/policy_loss                        -341.762
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.121
trainer/entropy_penalty                      -0.358922
trainer/entropy_percentage                   -0.00104911
trainer/Q1Pred Mean                         340.995
trainer/Q1Pred Std                           65.9131
trainer/Q1Pred Max                          426.659
trainer/Q1Pred Min                           42.9381
trainer/Q2Pred Mean                         340.583
trainer/Q2Pred Std                           65.6729
trainer/Q2Pred Max                          427.67
trainer/Q2Pred Min                           51.0979
trainer/QTargetWithReg Mean                 341.114
trainer/QTargetWithReg Std                   66.3093
trainer/QTargetWithReg Max                  428.953
trainer/QTargetWithReg Min                   43.5656
trainer/PolicyLossWithoutReg Mean           342.121
trainer/PolicyLossWithoutReg Std             65.2944
trainer/PolicyLossWithoutReg Max            426.937
trainer/PolicyLossWithoutReg Min             51.8498
exploration/num steps total              803000
exploration/num paths total                1592
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55748
exploration/Rewards Std                       1.01993
exploration/Rewards Max                       7.39101
exploration/Rewards Min                      -0.602304
exploration/Returns Mean                   4557.48
exploration/Returns Std                       0
exploration/Returns Max                    4557.48
exploration/Returns Min                    4557.48
exploration/Num Paths                         1
exploration/Average Returns                4557.48
evaluation_0/num steps total                  6.25347e+06
evaluation_0/num paths total               9873
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76847
evaluation_0/Rewards Std                      1.08516
evaluation_0/Rewards Max                      7.46105
evaluation_0/Rewards Min                     -0.651274
evaluation_0/Returns Mean                  4768.47
evaluation_0/Returns Std                     65.8216
evaluation_0/Returns Max                   4854.18
evaluation_0/Returns Min                   4669.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4768.47
time/epoch (s)                                0
time/total (s)                            12081.3
Epoch                                       798
---------------------------------------  ----------------
2022-11-16 19:36:19.383151 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 799 finished
---------------------------------------  ----------------
epoch                                       799
total_step                               804000
replay_pool/size                         804000
trainer/alpha                                 0.0601655
trainer/alpha_loss                            1.92773
trainer/entropy                              -6.68584
trainer/qf_loss                              29.044
trainer/policy_loss                        -343.721
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.123
trainer/entropy_penalty                      -0.402257
trainer/entropy_percentage                   -0.00116893
trainer/Q1Pred Mean                         343.442
trainer/Q1Pred Std                           68.3693
trainer/Q1Pred Max                          425.567
trainer/Q1Pred Min                           -4.48475
trainer/Q2Pred Mean                         342.92
trainer/Q2Pred Std                           69.0721
trainer/Q2Pred Max                          423.635
trainer/Q2Pred Min                           -6.4985
trainer/QTargetWithReg Mean                 343.174
trainer/QTargetWithReg Std                   69.7522
trainer/QTargetWithReg Max                  423.487
trainer/QTargetWithReg Min                   -7.12391
trainer/PolicyLossWithoutReg Mean           344.123
trainer/PolicyLossWithoutReg Std             65.8331
trainer/PolicyLossWithoutReg Max            423.464
trainer/PolicyLossWithoutReg Min             -4.47727
exploration/num steps total              804000
exploration/num paths total                1593
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45744
exploration/Rewards Std                       1.13105
exploration/Rewards Max                       6.91772
exploration/Rewards Min                      -0.650299
exploration/Returns Mean                   4457.44
exploration/Returns Std                       0
exploration/Returns Max                    4457.44
exploration/Returns Min                    4457.44
exploration/Num Paths                         1
exploration/Average Returns                4457.44
evaluation_0/num steps total                  6.26147e+06
evaluation_0/num paths total               9881
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79407
evaluation_0/Rewards Std                      1.06127
evaluation_0/Rewards Max                      7.40051
evaluation_0/Rewards Min                     -0.885986
evaluation_0/Returns Mean                  4794.07
evaluation_0/Returns Std                     74.8938
evaluation_0/Returns Max                   4872.13
evaluation_0/Returns Min                   4629.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4794.07
time/epoch (s)                                0
time/total (s)                            12096.3
Epoch                                       799
---------------------------------------  ----------------
2022-11-16 19:36:34.421188 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 800 finished
---------------------------------------  ----------------
epoch                                       800
total_step                               805000
replay_pool/size                         805000
trainer/alpha                                 0.060816
trainer/alpha_loss                            0.398549
trainer/entropy                              -6.14234
trainer/qf_loss                              25.037
trainer/policy_loss                        -346.927
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.301
trainer/entropy_penalty                      -0.373553
trainer/entropy_percentage                   -0.00107559
trainer/Q1Pred Mean                         345.34
trainer/Q1Pred Std                           73.6349
trainer/Q1Pred Max                          421.207
trainer/Q1Pred Min                           16.7374
trainer/Q2Pred Mean                         345.581
trainer/Q2Pred Std                           73.7347
trainer/Q2Pred Max                          422.291
trainer/Q2Pred Min                            5.44786
trainer/QTargetWithReg Mean                 345.914
trainer/QTargetWithReg Std                   73.2077
trainer/QTargetWithReg Max                  421.122
trainer/QTargetWithReg Min                   17.7492
trainer/PolicyLossWithoutReg Mean           347.301
trainer/PolicyLossWithoutReg Std             72.8982
trainer/PolicyLossWithoutReg Max            422.961
trainer/PolicyLossWithoutReg Min             14.4552
exploration/num steps total              805000
exploration/num paths total                1594
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73207
exploration/Rewards Std                       1.07511
exploration/Rewards Max                       7.80417
exploration/Rewards Min                      -0.730379
exploration/Returns Mean                   4732.07
exploration/Returns Std                       0
exploration/Returns Max                    4732.07
exploration/Returns Min                    4732.07
exploration/Num Paths                         1
exploration/Average Returns                4732.07
evaluation_0/num steps total                  6.26947e+06
evaluation_0/num paths total               9889
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71347
evaluation_0/Rewards Std                      1.03093
evaluation_0/Rewards Max                      7.31142
evaluation_0/Rewards Min                     -0.800918
evaluation_0/Returns Mean                  4713.47
evaluation_0/Returns Std                     87.9476
evaluation_0/Returns Max                   4847.88
evaluation_0/Returns Min                   4604.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4713.47
time/epoch (s)                                0
time/total (s)                            12111.3
Epoch                                       800
---------------------------------------  ----------------
2022-11-16 19:36:51.071592 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 801 finished
---------------------------------------  ----------------
epoch                                       801
total_step                               806000
replay_pool/size                         806000
trainer/alpha                                 0.0603573
trainer/alpha_loss                           -1.19348
trainer/entropy                              -5.5749
trainer/qf_loss                              27.3774
trainer/policy_loss                        -345.862
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.199
trainer/entropy_penalty                      -0.336485
trainer/entropy_percentage                   -0.000971943
trainer/Q1Pred Mean                         343.978
trainer/Q1Pred Std                           69.9057
trainer/Q1Pred Max                          424.627
trainer/Q1Pred Min                            7.2512
trainer/Q2Pred Mean                         344.46
trainer/Q2Pred Std                           69.5222
trainer/Q2Pred Max                          425.865
trainer/Q2Pred Min                           -3.33099
trainer/QTargetWithReg Mean                 344.896
trainer/QTargetWithReg Std                   68.6952
trainer/QTargetWithReg Max                  425.134
trainer/QTargetWithReg Min                    3.54258
trainer/PolicyLossWithoutReg Mean           346.199
trainer/PolicyLossWithoutReg Std             68.0566
trainer/PolicyLossWithoutReg Max            425.544
trainer/PolicyLossWithoutReg Min              6.46451
exploration/num steps total              806000
exploration/num paths total                1595
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58202
exploration/Rewards Std                       1.10525
exploration/Rewards Max                       7.30265
exploration/Rewards Min                      -0.715647
exploration/Returns Mean                   4582.02
exploration/Returns Std                       0
exploration/Returns Max                    4582.02
exploration/Returns Min                    4582.02
exploration/Num Paths                         1
exploration/Average Returns                4582.02
evaluation_0/num steps total                  6.27703e+06
evaluation_0/num paths total               9897
evaluation_0/path length Mean               944.5
evaluation_0/path length Std                146.839
evaluation_0/path length Max               1000
evaluation_0/path length Min                556
evaluation_0/Rewards Mean                     4.95014
evaluation_0/Rewards Std                      1.13536
evaluation_0/Rewards Max                      7.86785
evaluation_0/Rewards Min                     -0.733118
evaluation_0/Returns Mean                  4675.41
evaluation_0/Returns Std                    828.928
evaluation_0/Returns Max                   5042.82
evaluation_0/Returns Min                   2489.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.41
time/epoch (s)                                0
time/total (s)                            12128
Epoch                                       801
---------------------------------------  ----------------
2022-11-16 19:37:06.082404 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 802 finished
---------------------------------------  ----------------
epoch                                       802
total_step                               807000
replay_pool/size                         807000
trainer/alpha                                 0.0608365
trainer/alpha_loss                           -1.4743
trainer/entropy                              -5.47336
trainer/qf_loss                              24.7269
trainer/policy_loss                        -349.66
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.993
trainer/entropy_penalty                      -0.33298
trainer/entropy_percentage                   -0.000951391
trainer/Q1Pred Mean                         349.175
trainer/Q1Pred Std                           60.1284
trainer/Q1Pred Max                          427.522
trainer/Q1Pred Min                           -8.71512
trainer/Q2Pred Mean                         350.081
trainer/Q2Pred Std                           59.8035
trainer/Q2Pred Max                          429.289
trainer/Q2Pred Min                           -6.48639
trainer/QTargetWithReg Mean                 348.616
trainer/QTargetWithReg Std                   60.132
trainer/QTargetWithReg Max                  425.048
trainer/QTargetWithReg Min                    3.01137
trainer/PolicyLossWithoutReg Mean           349.993
trainer/PolicyLossWithoutReg Std             59.3708
trainer/PolicyLossWithoutReg Max            426.519
trainer/PolicyLossWithoutReg Min            -10.0113
exploration/num steps total              807000
exploration/num paths total                1596
exploration/path length this epoch Mean     149
exploration/path length this epoch Std        0
exploration/path length this epoch Max      149
exploration/path length this epoch Min      149
exploration/Rewards Mean                      3.043
exploration/Rewards Std                       1.22892
exploration/Rewards Max                       4.66946
exploration/Rewards Min                      -0.63101
exploration/Returns Mean                    453.407
exploration/Returns Std                       0
exploration/Returns Max                     453.407
exploration/Returns Min                     453.407
exploration/Num Paths                         1
exploration/Average Returns                 453.407
evaluation_0/num steps total                  6.28503e+06
evaluation_0/num paths total               9905
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78399
evaluation_0/Rewards Std                      1.07142
evaluation_0/Rewards Max                      7.94735
evaluation_0/Rewards Min                     -0.884315
evaluation_0/Returns Mean                  4783.99
evaluation_0/Returns Std                    110.968
evaluation_0/Returns Max                   4937.07
evaluation_0/Returns Min                   4588.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4783.99
time/epoch (s)                                0
time/total (s)                            12143
Epoch                                       802
---------------------------------------  ----------------
2022-11-16 19:37:21.197044 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 803 finished
---------------------------------------  ----------------
epoch                                       803
total_step                               808000
replay_pool/size                         808000
trainer/alpha                                 0.0614531
trainer/alpha_loss                            0.941577
trainer/entropy                              -6.33755
trainer/qf_loss                              27.4047
trainer/policy_loss                        -340.853
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.242
trainer/entropy_penalty                      -0.389462
trainer/entropy_percentage                   -0.00114131
trainer/Q1Pred Mean                         340.335
trainer/Q1Pred Std                           68.4866
trainer/Q1Pred Max                          430.36
trainer/Q1Pred Min                           -2.30751
trainer/Q2Pred Mean                         340.091
trainer/Q2Pred Std                           69.0964
trainer/Q2Pred Max                          427.806
trainer/Q2Pred Min                          -15.8816
trainer/QTargetWithReg Mean                 340.417
trainer/QTargetWithReg Std                   69.3032
trainer/QTargetWithReg Max                  429.67
trainer/QTargetWithReg Min                  -35.7026
trainer/PolicyLossWithoutReg Mean           341.242
trainer/PolicyLossWithoutReg Std             68.2226
trainer/PolicyLossWithoutReg Max            428.678
trainer/PolicyLossWithoutReg Min            -11.8613
exploration/num steps total              808000
exploration/num paths total                1597
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51258
exploration/Rewards Std                       1.00744
exploration/Rewards Max                       7.00196
exploration/Rewards Min                      -0.878216
exploration/Returns Mean                   4512.58
exploration/Returns Std                       0
exploration/Returns Max                    4512.58
exploration/Returns Min                    4512.58
exploration/Num Paths                         1
exploration/Average Returns                4512.58
evaluation_0/num steps total                  6.29303e+06
evaluation_0/num paths total               9913
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67946
evaluation_0/Rewards Std                      1.06241
evaluation_0/Rewards Max                      7.38196
evaluation_0/Rewards Min                     -0.641073
evaluation_0/Returns Mean                  4679.46
evaluation_0/Returns Std                     72.7898
evaluation_0/Returns Max                   4776.09
evaluation_0/Returns Min                   4579.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4679.46
time/epoch (s)                                0
time/total (s)                            12158.1
Epoch                                       803
---------------------------------------  ----------------
2022-11-16 19:37:36.126822 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 804 finished
---------------------------------------  ----------------
epoch                                       804
total_step                               809000
replay_pool/size                         809000
trainer/alpha                                 0.0593848
trainer/alpha_loss                            0.241253
trainer/entropy                              -6.08543
trainer/qf_loss                              19.4819
trainer/policy_loss                        -336.814
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         337.175
trainer/entropy_penalty                      -0.361382
trainer/entropy_percentage                   -0.00107179
trainer/Q1Pred Mean                         336.611
trainer/Q1Pred Std                           75.1624
trainer/Q1Pred Max                          436.965
trainer/Q1Pred Min                            1.88772
trainer/Q2Pred Mean                         336.256
trainer/Q2Pred Std                           75.0485
trainer/Q2Pred Max                          430.76
trainer/Q2Pred Min                            2.6997
trainer/QTargetWithReg Mean                 336.53
trainer/QTargetWithReg Std                   75.6901
trainer/QTargetWithReg Max                  435.82
trainer/QTargetWithReg Min                    2.18047
trainer/PolicyLossWithoutReg Mean           337.175
trainer/PolicyLossWithoutReg Std             72.7098
trainer/PolicyLossWithoutReg Max            436.883
trainer/PolicyLossWithoutReg Min              9.02112
exploration/num steps total              809000
exploration/num paths total                1598
exploration/path length this epoch Mean     479
exploration/path length this epoch Std        0
exploration/path length this epoch Max      479
exploration/path length this epoch Min      479
exploration/Rewards Mean                      4.17214
exploration/Rewards Std                       1.22564
exploration/Rewards Max                       7.11068
exploration/Rewards Min                      -0.644061
exploration/Returns Mean                   1998.46
exploration/Returns Std                       0
exploration/Returns Max                    1998.46
exploration/Returns Min                    1998.46
exploration/Num Paths                         1
exploration/Average Returns                1998.46
evaluation_0/num steps total                  6.30103e+06
evaluation_0/num paths total               9921
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91304
evaluation_0/Rewards Std                      1.04893
evaluation_0/Rewards Max                      7.60695
evaluation_0/Rewards Min                     -0.732518
evaluation_0/Returns Mean                  4913.04
evaluation_0/Returns Std                     70.7233
evaluation_0/Returns Max                   5018.89
evaluation_0/Returns Min                   4793.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4913.04
time/epoch (s)                                0
time/total (s)                            12173
Epoch                                       804
---------------------------------------  ----------------
2022-11-16 19:37:51.000272 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 805 finished
---------------------------------------  ----------------
epoch                                       805
total_step                               810000
replay_pool/size                         810000
trainer/alpha                                 0.0615025
trainer/alpha_loss                           -1.50619
trainer/entropy                              -5.45986
trainer/qf_loss                              22.6778
trainer/policy_loss                        -348.978
trainer/adversary_policy_loss                16.6976
trainer/policy_loss_without_entropy         349.314
trainer/entropy_penalty                      -0.335795
trainer/entropy_percentage                   -0.000961299
trainer/Q1Pred Mean                         348.952
trainer/Q1Pred Std                           66.1306
trainer/Q1Pred Max                          426.164
trainer/Q1Pred Min                           32.0425
trainer/Q2Pred Mean                         348.962
trainer/Q2Pred Std                           66.0322
trainer/Q2Pred Max                          427.555
trainer/Q2Pred Min                           15.5876
trainer/QTargetWithReg Mean                 348.971
trainer/QTargetWithReg Std                   65.6337
trainer/QTargetWithReg Max                  427.467
trainer/QTargetWithReg Min                   23.3168
trainer/PolicyLossWithoutReg Mean           349.314
trainer/PolicyLossWithoutReg Std             65.3578
trainer/PolicyLossWithoutReg Max            426.415
trainer/PolicyLossWithoutReg Min             25.9328
exploration/num steps total              810000
exploration/num paths total                1599
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54266
exploration/Rewards Std                       1.11881
exploration/Rewards Max                       7.47261
exploration/Rewards Min                      -0.601184
exploration/Returns Mean                   4542.66
exploration/Returns Std                       0
exploration/Returns Max                    4542.66
exploration/Returns Min                    4542.66
exploration/Num Paths                         1
exploration/Average Returns                4542.66
evaluation_0/num steps total                  6.30903e+06
evaluation_0/num paths total               9929
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86574
evaluation_0/Rewards Std                      1.09689
evaluation_0/Rewards Max                      7.53303
evaluation_0/Rewards Min                     -0.645181
evaluation_0/Returns Mean                  4865.74
evaluation_0/Returns Std                    133.921
evaluation_0/Returns Max                   5048.77
evaluation_0/Returns Min                   4654.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4865.74
time/epoch (s)                                0
time/total (s)                            12187.9
Epoch                                       805
---------------------------------------  ----------------
2022-11-16 19:38:07.386528 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 806 finished
---------------------------------------  ----------------
epoch                                       806
total_step                               811000
replay_pool/size                         811000
trainer/alpha                                 0.0595444
trainer/alpha_loss                            2.12723
trainer/entropy                              -6.754
trainer/qf_loss                              29.9033
trainer/policy_loss                        -351.226
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.628
trainer/entropy_penalty                      -0.402163
trainer/entropy_percentage                   -0.00114372
trainer/Q1Pred Mean                         350.68
trainer/Q1Pred Std                           62.5128
trainer/Q1Pred Max                          438.768
trainer/Q1Pred Min                           30.1471
trainer/Q2Pred Mean                         350.19
trainer/Q2Pred Std                           62.8207
trainer/Q2Pred Max                          436.183
trainer/Q2Pred Min                           34.5605
trainer/QTargetWithReg Mean                 349.781
trainer/QTargetWithReg Std                   63.5161
trainer/QTargetWithReg Max                  438.932
trainer/QTargetWithReg Min                   34.3218
trainer/PolicyLossWithoutReg Mean           351.628
trainer/PolicyLossWithoutReg Std             61.3827
trainer/PolicyLossWithoutReg Max            441.065
trainer/PolicyLossWithoutReg Min             44.2797
exploration/num steps total              811000
exploration/num paths total                1600
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56778
exploration/Rewards Std                       1.02187
exploration/Rewards Max                       6.91818
exploration/Rewards Min                      -0.488653
exploration/Returns Mean                   4567.78
exploration/Returns Std                       0
exploration/Returns Max                    4567.78
exploration/Returns Min                    4567.78
exploration/Num Paths                         1
exploration/Average Returns                4567.78
evaluation_0/num steps total                  6.31648e+06
evaluation_0/num paths total               9937
evaluation_0/path length Mean               931.375
evaluation_0/path length Std                152.945
evaluation_0/path length Max               1000
evaluation_0/path length Min                533
evaluation_0/Rewards Mean                     4.66358
evaluation_0/Rewards Std                      1.07744
evaluation_0/Rewards Max                      7.3664
evaluation_0/Rewards Min                     -0.673017
evaluation_0/Returns Mean                  4343.54
evaluation_0/Returns Std                    756.58
evaluation_0/Returns Max                   4910.52
evaluation_0/Returns Min                   2411.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4343.54
time/epoch (s)                                0
time/total (s)                            12204.3
Epoch                                       806
---------------------------------------  ----------------
2022-11-16 19:38:22.260644 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 807 finished
---------------------------------------  ----------------
epoch                                       807
total_step                               812000
replay_pool/size                         812000
trainer/alpha                                 0.060173
trainer/alpha_loss                            0.419811
trainer/entropy                              -6.14937
trainer/qf_loss                              26.8128
trainer/policy_loss                        -347.944
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.314
trainer/entropy_penalty                      -0.370026
trainer/entropy_percentage                   -0.00106233
trainer/Q1Pred Mean                         347.554
trainer/Q1Pred Std                           61.4741
trainer/Q1Pred Max                          434.147
trainer/Q1Pred Min                           19.0371
trainer/Q2Pred Mean                         348.39
trainer/Q2Pred Std                           60.5488
trainer/Q2Pred Max                          436.794
trainer/Q2Pred Min                           24.8469
trainer/QTargetWithReg Mean                 346.913
trainer/QTargetWithReg Std                   61.7376
trainer/QTargetWithReg Max                  434.061
trainer/QTargetWithReg Min                   23.7879
trainer/PolicyLossWithoutReg Mean           348.314
trainer/PolicyLossWithoutReg Std             59.957
trainer/PolicyLossWithoutReg Max            434.734
trainer/PolicyLossWithoutReg Min             20.332
exploration/num steps total              812000
exploration/num paths total                1601
exploration/path length this epoch Mean      97
exploration/path length this epoch Std        0
exploration/path length this epoch Max       97
exploration/path length this epoch Min       97
exploration/Rewards Mean                      2.5072
exploration/Rewards Std                       1.59901
exploration/Rewards Max                       5.86547
exploration/Rewards Min                      -0.772129
exploration/Returns Mean                    243.198
exploration/Returns Std                       0
exploration/Returns Max                     243.198
exploration/Returns Min                     243.198
exploration/Num Paths                         1
exploration/Average Returns                 243.198
evaluation_0/num steps total                  6.32448e+06
evaluation_0/num paths total               9945
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93341
evaluation_0/Rewards Std                      1.03735
evaluation_0/Rewards Max                      7.14987
evaluation_0/Rewards Min                     -0.876306
evaluation_0/Returns Mean                  4933.41
evaluation_0/Returns Std                     63.2281
evaluation_0/Returns Max                   5032.96
evaluation_0/Returns Min                   4812.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4933.41
time/epoch (s)                                0
time/total (s)                            12219.2
Epoch                                       807
---------------------------------------  ----------------
2022-11-16 19:38:37.039992 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 808 finished
---------------------------------------  ----------------
epoch                                       808
total_step                               813000
replay_pool/size                         813000
trainer/alpha                                 0.0604893
trainer/alpha_loss                           -0.17347
trainer/entropy                              -5.93816
trainer/qf_loss                              21.8039
trainer/policy_loss                        -352.221
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.58
trainer/entropy_penalty                      -0.359196
trainer/entropy_percentage                   -0.00101876
trainer/Q1Pred Mean                         350.205
trainer/Q1Pred Std                           59.5491
trainer/Q1Pred Max                          428.01
trainer/Q1Pred Min                           39.5074
trainer/Q2Pred Mean                         349.877
trainer/Q2Pred Std                           60.9999
trainer/Q2Pred Max                          428.173
trainer/Q2Pred Min                           -1.0719
trainer/QTargetWithReg Mean                 349.977
trainer/QTargetWithReg Std                   60.1656
trainer/QTargetWithReg Max                  428.462
trainer/QTargetWithReg Min                   15.2988
trainer/PolicyLossWithoutReg Mean           352.58
trainer/PolicyLossWithoutReg Std             53.4183
trainer/PolicyLossWithoutReg Max            425.925
trainer/PolicyLossWithoutReg Min             53.7778
exploration/num steps total              813000
exploration/num paths total                1602
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38682
exploration/Rewards Std                       1.02034
exploration/Rewards Max                       6.88392
exploration/Rewards Min                      -0.58948
exploration/Returns Mean                   4386.82
exploration/Returns Std                       0
exploration/Returns Max                    4386.82
exploration/Returns Min                    4386.82
exploration/Num Paths                         1
exploration/Average Returns                4386.82
evaluation_0/num steps total                  6.33248e+06
evaluation_0/num paths total               9953
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63904
evaluation_0/Rewards Std                      1.02119
evaluation_0/Rewards Max                      7.53473
evaluation_0/Rewards Min                     -0.602691
evaluation_0/Returns Mean                  4639.04
evaluation_0/Returns Std                     65.7039
evaluation_0/Returns Max                   4728.09
evaluation_0/Returns Min                   4524.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4639.04
time/epoch (s)                                0
time/total (s)                            12233.9
Epoch                                       808
---------------------------------------  ----------------
2022-11-16 19:38:53.532529 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 809 finished
---------------------------------------  ----------------
epoch                                       809
total_step                               814000
replay_pool/size                         814000
trainer/alpha                                 0.0597356
trainer/alpha_loss                           -1.2413
trainer/entropy                              -5.5595
trainer/qf_loss                              26.1222
trainer/policy_loss                        -349.913
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.246
trainer/entropy_penalty                      -0.3321
trainer/entropy_percentage                   -0.000948192
trainer/Q1Pred Mean                         351.153
trainer/Q1Pred Std                           64.1396
trainer/Q1Pred Max                          422.581
trainer/Q1Pred Min                          -14.1661
trainer/Q2Pred Mean                         350.062
trainer/Q2Pred Std                           64.0898
trainer/Q2Pred Max                          423.848
trainer/Q2Pred Min                           -2.00956
trainer/QTargetWithReg Mean                 349.084
trainer/QTargetWithReg Std                   64.1421
trainer/QTargetWithReg Max                  422.701
trainer/QTargetWithReg Min                    2.96816
trainer/PolicyLossWithoutReg Mean           350.246
trainer/PolicyLossWithoutReg Std             64.2199
trainer/PolicyLossWithoutReg Max            423.367
trainer/PolicyLossWithoutReg Min            -35.3406
exploration/num steps total              814000
exploration/num paths total                1603
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5762
exploration/Rewards Std                       1.02069
exploration/Rewards Max                       7.63861
exploration/Rewards Min                      -0.415416
exploration/Returns Mean                   4576.2
exploration/Returns Std                       0
exploration/Returns Max                    4576.2
exploration/Returns Min                    4576.2
exploration/Num Paths                         1
exploration/Average Returns                4576.2
evaluation_0/num steps total                  6.33974e+06
evaluation_0/num paths total               9961
evaluation_0/path length Mean               907.5
evaluation_0/path length Std                244.732
evaluation_0/path length Max               1000
evaluation_0/path length Min                260
evaluation_0/Rewards Mean                     4.78477
evaluation_0/Rewards Std                      1.08637
evaluation_0/Rewards Max                      7.7935
evaluation_0/Rewards Min                     -0.671721
evaluation_0/Returns Mean                  4342.18
evaluation_0/Returns Std                   1279.7
evaluation_0/Returns Max                   4921.92
evaluation_0/Returns Min                    962.722
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4342.18
time/epoch (s)                                0
time/total (s)                            12250.4
Epoch                                       809
---------------------------------------  ----------------
2022-11-16 19:39:08.642034 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 810 finished
---------------------------------------  ----------------
epoch                                       810
total_step                               815000
replay_pool/size                         815000
trainer/alpha                                 0.060297
trainer/alpha_loss                           -1.89392
trainer/entropy                              -5.32559
trainer/qf_loss                              14.4707
trainer/policy_loss                        -353.781
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.102
trainer/entropy_penalty                      -0.321117
trainer/entropy_percentage                   -0.00090685
trainer/Q1Pred Mean                         353.724
trainer/Q1Pred Std                           64.5092
trainer/Q1Pred Max                          427.214
trainer/Q1Pred Min                            6.79875
trainer/Q2Pred Mean                         353.677
trainer/Q2Pred Std                           64.5208
trainer/Q2Pred Max                          428.457
trainer/Q2Pred Min                           23.7366
trainer/QTargetWithReg Mean                 353.195
trainer/QTargetWithReg Std                   65.1515
trainer/QTargetWithReg Max                  426.7
trainer/QTargetWithReg Min                   15.2574
trainer/PolicyLossWithoutReg Mean           354.102
trainer/PolicyLossWithoutReg Std             63.6576
trainer/PolicyLossWithoutReg Max            426.946
trainer/PolicyLossWithoutReg Min             17.9938
exploration/num steps total              815000
exploration/num paths total                1604
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.46504
exploration/Rewards Std                       1.09444
exploration/Rewards Max                       6.85853
exploration/Rewards Min                      -0.593647
exploration/Returns Mean                   4465.04
exploration/Returns Std                       0
exploration/Returns Max                    4465.04
exploration/Returns Min                    4465.04
exploration/Num Paths                         1
exploration/Average Returns                4465.04
evaluation_0/num steps total                  6.34774e+06
evaluation_0/num paths total               9969
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02458
evaluation_0/Rewards Std                      1.13488
evaluation_0/Rewards Max                      8.04314
evaluation_0/Rewards Min                     -0.803003
evaluation_0/Returns Mean                  5024.58
evaluation_0/Returns Std                     91.1629
evaluation_0/Returns Max                   5169.47
evaluation_0/Returns Min                   4907.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5024.58
time/epoch (s)                                0
time/total (s)                            12265.5
Epoch                                       810
---------------------------------------  ----------------
2022-11-16 19:39:25.520315 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 811 finished
---------------------------------------  ----------------
epoch                                       811
total_step                               816000
replay_pool/size                         816000
trainer/alpha                                 0.0622684
trainer/alpha_loss                           -0.280567
trainer/entropy                              -5.89894
trainer/qf_loss                              17.3748
trainer/policy_loss                        -343.368
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.735
trainer/entropy_penalty                      -0.367317
trainer/entropy_percentage                   -0.00106861
trainer/Q1Pred Mean                         343.565
trainer/Q1Pred Std                           68.2654
trainer/Q1Pred Max                          428.605
trainer/Q1Pred Min                           10.3891
trainer/Q2Pred Mean                         343.189
trainer/Q2Pred Std                           68.3892
trainer/Q2Pred Max                          428.734
trainer/Q2Pred Min                           15.4048
trainer/QTargetWithReg Mean                 343.754
trainer/QTargetWithReg Std                   68.7055
trainer/QTargetWithReg Max                  427.873
trainer/QTargetWithReg Min                    8.31895
trainer/PolicyLossWithoutReg Mean           343.735
trainer/PolicyLossWithoutReg Std             67.5654
trainer/PolicyLossWithoutReg Max            429.542
trainer/PolicyLossWithoutReg Min             12.472
exploration/num steps total              816000
exploration/num paths total                1605
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69716
exploration/Rewards Std                       1.17846
exploration/Rewards Max                       7.09221
exploration/Rewards Min                      -0.934952
exploration/Returns Mean                   4697.16
exploration/Returns Std                       0
exploration/Returns Max                    4697.16
exploration/Returns Min                    4697.16
exploration/Num Paths                         1
exploration/Average Returns                4697.16
evaluation_0/num steps total                  6.35486e+06
evaluation_0/num paths total               9977
evaluation_0/path length Mean               890
evaluation_0/path length Std                291.033
evaluation_0/path length Max               1000
evaluation_0/path length Min                120
evaluation_0/Rewards Mean                     4.62337
evaluation_0/Rewards Std                      1.14315
evaluation_0/Rewards Max                      7.45459
evaluation_0/Rewards Min                     -0.853937
evaluation_0/Returns Mean                  4114.8
evaluation_0/Returns Std                   1467.11
evaluation_0/Returns Max                   4789.74
evaluation_0/Returns Min                    245.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4114.8
time/epoch (s)                                0
time/total (s)                            12282.4
Epoch                                       811
---------------------------------------  ----------------
2022-11-16 19:39:40.589009 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 812 finished
---------------------------------------  ----------------
epoch                                       812
total_step                               817000
replay_pool/size                         817000
trainer/alpha                                 0.058983
trainer/alpha_loss                            0.302386
trainer/entropy                              -6.10683
trainer/qf_loss                              19.1421
trainer/policy_loss                        -344.839
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.2
trainer/entropy_penalty                      -0.360199
trainer/entropy_percentage                   -0.00104345
trainer/Q1Pred Mean                         345.242
trainer/Q1Pred Std                           76.5951
trainer/Q1Pred Max                          437.619
trainer/Q1Pred Min                           10.5422
trainer/Q2Pred Mean                         345.786
trainer/Q2Pred Std                           76.3685
trainer/Q2Pred Max                          437.152
trainer/Q2Pred Min                            5.93403
trainer/QTargetWithReg Mean                 344.847
trainer/QTargetWithReg Std                   77.2041
trainer/QTargetWithReg Max                  437.711
trainer/QTargetWithReg Min                   14.0402
trainer/PolicyLossWithoutReg Mean           345.2
trainer/PolicyLossWithoutReg Std             76.0873
trainer/PolicyLossWithoutReg Max            437.359
trainer/PolicyLossWithoutReg Min             12.6634
exploration/num steps total              817000
exploration/num paths total                1606
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66327
exploration/Rewards Std                       1.04797
exploration/Rewards Max                       7.17449
exploration/Rewards Min                      -0.738146
exploration/Returns Mean                   4663.27
exploration/Returns Std                       0
exploration/Returns Max                    4663.27
exploration/Returns Min                    4663.27
exploration/Num Paths                         1
exploration/Average Returns                4663.27
evaluation_0/num steps total                  6.36286e+06
evaluation_0/num paths total               9985
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96591
evaluation_0/Rewards Std                      1.02976
evaluation_0/Rewards Max                      7.57724
evaluation_0/Rewards Min                     -0.807232
evaluation_0/Returns Mean                  4965.91
evaluation_0/Returns Std                    107.499
evaluation_0/Returns Max                   5121.89
evaluation_0/Returns Min                   4773.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4965.91
time/epoch (s)                                0
time/total (s)                            12297.5
Epoch                                       812
---------------------------------------  ----------------
2022-11-16 19:39:55.721208 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 813 finished
---------------------------------------  ----------------
epoch                                       813
total_step                               818000
replay_pool/size                         818000
trainer/alpha                                 0.0603856
trainer/alpha_loss                            1.29601
trainer/entropy                              -6.4617
trainer/qf_loss                              21.1736
trainer/policy_loss                        -341.531
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.921
trainer/entropy_penalty                      -0.390193
trainer/entropy_percentage                   -0.00114118
trainer/Q1Pred Mean                         341.095
trainer/Q1Pred Std                           73.5814
trainer/Q1Pred Max                          421.36
trainer/Q1Pred Min                            1.84104
trainer/Q2Pred Mean                         342.007
trainer/Q2Pred Std                           73.2578
trainer/Q2Pred Max                          420.262
trainer/Q2Pred Min                           10.5909
trainer/QTargetWithReg Mean                 342.432
trainer/QTargetWithReg Std                   73.24
trainer/QTargetWithReg Max                  420.878
trainer/QTargetWithReg Min                   12.1873
trainer/PolicyLossWithoutReg Mean           341.921
trainer/PolicyLossWithoutReg Std             72.9563
trainer/PolicyLossWithoutReg Max            419.666
trainer/PolicyLossWithoutReg Min              4.9606
exploration/num steps total              818000
exploration/num paths total                1607
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63462
exploration/Rewards Std                       1.02917
exploration/Rewards Max                       6.86277
exploration/Rewards Min                      -0.812328
exploration/Returns Mean                   4634.62
exploration/Returns Std                       0
exploration/Returns Max                    4634.62
exploration/Returns Min                    4634.62
exploration/Num Paths                         1
exploration/Average Returns                4634.62
evaluation_0/num steps total                  6.37086e+06
evaluation_0/num paths total               9993
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8356
evaluation_0/Rewards Std                      1.11412
evaluation_0/Rewards Max                      7.8538
evaluation_0/Rewards Min                     -0.75611
evaluation_0/Returns Mean                  4835.6
evaluation_0/Returns Std                    100.445
evaluation_0/Returns Max                   4990.76
evaluation_0/Returns Min                   4693.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4835.6
time/epoch (s)                                0
time/total (s)                            12312.6
Epoch                                       813
---------------------------------------  ----------------
2022-11-16 19:40:10.684972 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 814 finished
---------------------------------------  ----------------
epoch                                       814
total_step                               819000
replay_pool/size                         819000
trainer/alpha                                 0.060842
trainer/alpha_loss                           -1.12421
trainer/entropy                              -5.5984
trainer/qf_loss                              19.7728
trainer/policy_loss                        -351.688
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.029
trainer/entropy_penalty                      -0.340618
trainer/entropy_percentage                   -0.000967585
trainer/Q1Pred Mean                         350.964
trainer/Q1Pred Std                           57.288
trainer/Q1Pred Max                          424.142
trainer/Q1Pred Min                           19.0048
trainer/Q2Pred Mean                         352.264
trainer/Q2Pred Std                           56.8905
trainer/Q2Pred Max                          425.397
trainer/Q2Pred Min                           28.5806
trainer/QTargetWithReg Mean                 351.608
trainer/QTargetWithReg Std                   57.2912
trainer/QTargetWithReg Max                  425.322
trainer/QTargetWithReg Min                   25.406
trainer/PolicyLossWithoutReg Mean           352.029
trainer/PolicyLossWithoutReg Std             56.7615
trainer/PolicyLossWithoutReg Max            424.551
trainer/PolicyLossWithoutReg Min             23.4296
exploration/num steps total              819000
exploration/num paths total                1608
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41314
exploration/Rewards Std                       1.05815
exploration/Rewards Max                       7.78518
exploration/Rewards Min                      -0.715038
exploration/Returns Mean                   4413.14
exploration/Returns Std                       0
exploration/Returns Max                    4413.14
exploration/Returns Min                    4413.14
exploration/Num Paths                         1
exploration/Average Returns                4413.14
evaluation_0/num steps total                  6.37886e+06
evaluation_0/num paths total              10001
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73693
evaluation_0/Rewards Std                      1.04833
evaluation_0/Rewards Max                      7.26152
evaluation_0/Rewards Min                     -1.14528
evaluation_0/Returns Mean                  4736.93
evaluation_0/Returns Std                     91.176
evaluation_0/Returns Max                   4911.48
evaluation_0/Returns Min                   4631.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4736.93
time/epoch (s)                                0
time/total (s)                            12327.6
Epoch                                       814
---------------------------------------  ----------------
2022-11-16 19:40:25.839301 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 815 finished
---------------------------------------  ----------------
epoch                                       815
total_step                               820000
replay_pool/size                         820000
trainer/alpha                                 0.0596377
trainer/alpha_loss                            1.29342
trainer/entropy                              -6.45875
trainer/qf_loss                              15.7334
trainer/policy_loss                        -351.753
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.138
trainer/entropy_penalty                      -0.385185
trainer/entropy_percentage                   -0.00109385
trainer/Q1Pred Mean                         351.603
trainer/Q1Pred Std                           63.3497
trainer/Q1Pred Max                          427.124
trainer/Q1Pred Min                           24.2389
trainer/Q2Pred Mean                         351.586
trainer/Q2Pred Std                           63.9125
trainer/Q2Pred Max                          428.334
trainer/Q2Pred Min                           26.8158
trainer/QTargetWithReg Mean                 351.582
trainer/QTargetWithReg Std                   63.3552
trainer/QTargetWithReg Max                  427.731
trainer/QTargetWithReg Min                   24.4621
trainer/PolicyLossWithoutReg Mean           352.138
trainer/PolicyLossWithoutReg Std             62.3462
trainer/PolicyLossWithoutReg Max            426.666
trainer/PolicyLossWithoutReg Min             25.7016
exploration/num steps total              820000
exploration/num paths total                1609
exploration/path length this epoch Mean     835
exploration/path length this epoch Std        0
exploration/path length this epoch Max      835
exploration/path length this epoch Min      835
exploration/Rewards Mean                      4.52499
exploration/Rewards Std                       1.20705
exploration/Rewards Max                       8.22832
exploration/Rewards Min                      -0.98224
exploration/Returns Mean                   3778.36
exploration/Returns Std                       0
exploration/Returns Max                    3778.36
exploration/Returns Min                    3778.36
exploration/Num Paths                         1
exploration/Average Returns                3778.36
evaluation_0/num steps total                  6.38686e+06
evaluation_0/num paths total              10009
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85885
evaluation_0/Rewards Std                      1.07057
evaluation_0/Rewards Max                      7.61267
evaluation_0/Rewards Min                     -0.798114
evaluation_0/Returns Mean                  4858.85
evaluation_0/Returns Std                     95.5655
evaluation_0/Returns Max                   4994.14
evaluation_0/Returns Min                   4720.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4858.85
time/epoch (s)                                0
time/total (s)                            12342.7
Epoch                                       815
---------------------------------------  ----------------
2022-11-16 19:40:40.804587 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 816 finished
---------------------------------------  ----------------
epoch                                       816
total_step                               821000
replay_pool/size                         821000
trainer/alpha                                 0.059636
trainer/alpha_loss                           -1.1808
trainer/entropy                              -5.58122
trainer/qf_loss                              16.5995
trainer/policy_loss                        -354.474
trainer/adversary_policy_loss                17.0527
trainer/policy_loss_without_entropy         354.807
trainer/entropy_penalty                      -0.332842
trainer/entropy_percentage                   -0.000938094
trainer/Q1Pred Mean                         353.962
trainer/Q1Pred Std                           55.2088
trainer/Q1Pred Max                          426.604
trainer/Q1Pred Min                           -7.08347
trainer/Q2Pred Mean                         354.137
trainer/Q2Pred Std                           54.9325
trainer/Q2Pred Max                          426.74
trainer/Q2Pred Min                           -1.30595
trainer/QTargetWithReg Mean                 354.664
trainer/QTargetWithReg Std                   55.0555
trainer/QTargetWithReg Max                  427.295
trainer/QTargetWithReg Min                    0.896255
trainer/PolicyLossWithoutReg Mean           354.807
trainer/PolicyLossWithoutReg Std             53.0416
trainer/PolicyLossWithoutReg Max            426.162
trainer/PolicyLossWithoutReg Min             63.4812
exploration/num steps total              821000
exploration/num paths total                1610
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65428
exploration/Rewards Std                       0.99727
exploration/Rewards Max                       7.13076
exploration/Rewards Min                      -0.861742
exploration/Returns Mean                   4654.28
exploration/Returns Std                       0
exploration/Returns Max                    4654.28
exploration/Returns Min                    4654.28
exploration/Num Paths                         1
exploration/Average Returns                4654.28
evaluation_0/num steps total                  6.39486e+06
evaluation_0/num paths total              10017
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75803
evaluation_0/Rewards Std                      0.989207
evaluation_0/Rewards Max                      7.23102
evaluation_0/Rewards Min                     -0.712898
evaluation_0/Returns Mean                  4758.03
evaluation_0/Returns Std                     79.7829
evaluation_0/Returns Max                   4875.09
evaluation_0/Returns Min                   4636.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4758.03
time/epoch (s)                                0
time/total (s)                            12357.7
Epoch                                       816
---------------------------------------  ----------------
2022-11-16 19:40:55.723862 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 817 finished
---------------------------------------  ----------------
epoch                                       817
total_step                               822000
replay_pool/size                         822000
trainer/alpha                                 0.0601435
trainer/alpha_loss                            0.0542481
trainer/entropy                              -6.0193
trainer/qf_loss                              25.3471
trainer/policy_loss                        -342.1
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.462
trainer/entropy_penalty                      -0.362022
trainer/entropy_percentage                   -0.00105712
trainer/Q1Pred Mean                         341.299
trainer/Q1Pred Std                           64.257
trainer/Q1Pred Max                          428.885
trainer/Q1Pred Min                           -1.28244
trainer/Q2Pred Mean                         341.044
trainer/Q2Pred Std                           63.9054
trainer/Q2Pred Max                          425.849
trainer/Q2Pred Min                            0.279192
trainer/QTargetWithReg Mean                 342.709
trainer/QTargetWithReg Std                   64.0212
trainer/QTargetWithReg Max                  427.98
trainer/QTargetWithReg Min                   -7.92112
trainer/PolicyLossWithoutReg Mean           342.462
trainer/PolicyLossWithoutReg Std             63.4879
trainer/PolicyLossWithoutReg Max            427.171
trainer/PolicyLossWithoutReg Min             -2.48074
exploration/num steps total              822000
exploration/num paths total                1611
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53811
exploration/Rewards Std                       1.1806
exploration/Rewards Max                       6.90022
exploration/Rewards Min                      -0.676118
exploration/Returns Mean                   4538.11
exploration/Returns Std                       0
exploration/Returns Max                    4538.11
exploration/Returns Min                    4538.11
exploration/Num Paths                         1
exploration/Average Returns                4538.11
evaluation_0/num steps total                  6.40286e+06
evaluation_0/num paths total              10025
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82276
evaluation_0/Rewards Std                      1.00503
evaluation_0/Rewards Max                      7.4555
evaluation_0/Rewards Min                     -0.719015
evaluation_0/Returns Mean                  4822.76
evaluation_0/Returns Std                     37.1482
evaluation_0/Returns Max                   4892.06
evaluation_0/Returns Min                   4772.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4822.76
time/epoch (s)                                0
time/total (s)                            12372.6
Epoch                                       817
---------------------------------------  ----------------
2022-11-16 19:41:10.492622 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 818 finished
---------------------------------------  ----------------
epoch                                       818
total_step                               823000
replay_pool/size                         823000
trainer/alpha                                 0.0598734
trainer/alpha_loss                            0.678369
trainer/entropy                              -6.24093
trainer/qf_loss                              21.2825
trainer/policy_loss                        -349.521
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.895
trainer/entropy_penalty                      -0.373666
trainer/entropy_percentage                   -0.00106794
trainer/Q1Pred Mean                         349.237
trainer/Q1Pred Std                           63.2814
trainer/Q1Pred Max                          424.159
trainer/Q1Pred Min                           17.6249
trainer/Q2Pred Mean                         349.749
trainer/Q2Pred Std                           63.728
trainer/Q2Pred Max                          426.426
trainer/Q2Pred Min                           17.691
trainer/QTargetWithReg Mean                 348.365
trainer/QTargetWithReg Std                   63.4459
trainer/QTargetWithReg Max                  425.371
trainer/QTargetWithReg Min                   18.8011
trainer/PolicyLossWithoutReg Mean           349.895
trainer/PolicyLossWithoutReg Std             62.7305
trainer/PolicyLossWithoutReg Max            424.176
trainer/PolicyLossWithoutReg Min             16.0276
exploration/num steps total              823000
exploration/num paths total                1612
exploration/path length this epoch Mean     720
exploration/path length this epoch Std        0
exploration/path length this epoch Max      720
exploration/path length this epoch Min      720
exploration/Rewards Mean                      4.54293
exploration/Rewards Std                       1.05381
exploration/Rewards Max                       6.7595
exploration/Rewards Min                      -0.784427
exploration/Returns Mean                   3270.91
exploration/Returns Std                       0
exploration/Returns Max                    3270.91
exploration/Returns Min                    3270.91
exploration/Num Paths                         1
exploration/Average Returns                3270.91
evaluation_0/num steps total                  6.41086e+06
evaluation_0/num paths total              10033
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07867
evaluation_0/Rewards Std                      1.09765
evaluation_0/Rewards Max                      7.65872
evaluation_0/Rewards Min                     -0.633961
evaluation_0/Returns Mean                  5078.67
evaluation_0/Returns Std                     64.9756
evaluation_0/Returns Max                   5160.34
evaluation_0/Returns Min                   4942.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5078.67
time/epoch (s)                                0
time/total (s)                            12387.4
Epoch                                       818
---------------------------------------  ----------------
2022-11-16 19:41:25.322540 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 819 finished
---------------------------------------  ----------------
epoch                                       819
total_step                               824000
replay_pool/size                         824000
trainer/alpha                                 0.0597717
trainer/alpha_loss                            1.17848
trainer/entropy                              -6.41831
trainer/qf_loss                              32.2396
trainer/policy_loss                        -342.856
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.239
trainer/entropy_penalty                      -0.383633
trainer/entropy_percentage                   -0.00111768
trainer/Q1Pred Mean                         341.941
trainer/Q1Pred Std                           71.3322
trainer/Q1Pred Max                          420.584
trainer/Q1Pred Min                          -37.4581
trainer/Q2Pred Mean                         342.283
trainer/Q2Pred Std                           71.3178
trainer/Q2Pred Max                          420.098
trainer/Q2Pred Min                          -48.8403
trainer/QTargetWithReg Mean                 342.474
trainer/QTargetWithReg Std                   70.8381
trainer/QTargetWithReg Max                  419.689
trainer/QTargetWithReg Min                  -38.3244
trainer/PolicyLossWithoutReg Mean           343.239
trainer/PolicyLossWithoutReg Std             70.3508
trainer/PolicyLossWithoutReg Max            420.131
trainer/PolicyLossWithoutReg Min            -42.6709
exploration/num steps total              824000
exploration/num paths total                1613
exploration/path length this epoch Mean     799
exploration/path length this epoch Std        0
exploration/path length this epoch Max      799
exploration/path length this epoch Min      799
exploration/Rewards Mean                      4.53756
exploration/Rewards Std                       1.08066
exploration/Rewards Max                       6.96037
exploration/Rewards Min                      -0.52533
exploration/Returns Mean                   3625.51
exploration/Returns Std                       0
exploration/Returns Max                    3625.51
exploration/Returns Min                    3625.51
exploration/Num Paths                         1
exploration/Average Returns                3625.51
evaluation_0/num steps total                  6.41886e+06
evaluation_0/num paths total              10041
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84777
evaluation_0/Rewards Std                      1.06642
evaluation_0/Rewards Max                      7.64257
evaluation_0/Rewards Min                     -0.58118
evaluation_0/Returns Mean                  4847.77
evaluation_0/Returns Std                     59.0672
evaluation_0/Returns Max                   4936.26
evaluation_0/Returns Min                   4744.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4847.77
time/epoch (s)                                0
time/total (s)                            12402.2
Epoch                                       819
---------------------------------------  ----------------
2022-11-16 19:41:42.113225 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 820 finished
---------------------------------------  ----------------
epoch                                       820
total_step                               825000
replay_pool/size                         825000
trainer/alpha                                 0.0584326
trainer/alpha_loss                            0.697406
trainer/entropy                              -6.24558
trainer/qf_loss                              28.9305
trainer/policy_loss                        -349.439
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.804
trainer/entropy_penalty                      -0.364945
trainer/entropy_percentage                   -0.00104328
trainer/Q1Pred Mean                         349.029
trainer/Q1Pred Std                           63.3884
trainer/Q1Pred Max                          427.856
trainer/Q1Pred Min                            9.07398
trainer/Q2Pred Mean                         349.794
trainer/Q2Pred Std                           63.6038
trainer/Q2Pred Max                          432.174
trainer/Q2Pred Min                            2.38217
trainer/QTargetWithReg Mean                 349.107
trainer/QTargetWithReg Std                   62.9744
trainer/QTargetWithReg Max                  429.997
trainer/QTargetWithReg Min                    4.53922
trainer/PolicyLossWithoutReg Mean           349.804
trainer/PolicyLossWithoutReg Std             63.146
trainer/PolicyLossWithoutReg Max            432.034
trainer/PolicyLossWithoutReg Min             11.1781
exploration/num steps total              825000
exploration/num paths total                1614
exploration/path length this epoch Mean     232
exploration/path length this epoch Std        0
exploration/path length this epoch Max      232
exploration/path length this epoch Min      232
exploration/Rewards Mean                      3.27386
exploration/Rewards Std                       1.13759
exploration/Rewards Max                       5.25969
exploration/Rewards Min                      -0.469695
exploration/Returns Mean                    759.535
exploration/Returns Std                       0
exploration/Returns Max                     759.535
exploration/Returns Min                     759.535
exploration/Num Paths                         1
exploration/Average Returns                 759.535
evaluation_0/num steps total                  6.42594e+06
evaluation_0/num paths total              10049
evaluation_0/path length Mean               885
evaluation_0/path length Std                304.261
evaluation_0/path length Max               1000
evaluation_0/path length Min                 80
evaluation_0/Rewards Mean                     4.92945
evaluation_0/Rewards Std                      1.08803
evaluation_0/Rewards Max                      7.72913
evaluation_0/Rewards Min                     -0.842274
evaluation_0/Returns Mean                  4362.56
evaluation_0/Returns Std                   1561.95
evaluation_0/Returns Max                   4996.73
evaluation_0/Returns Min                    231.557
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4362.56
time/epoch (s)                                0
time/total (s)                            12419
Epoch                                       820
---------------------------------------  ----------------
2022-11-16 19:41:57.139835 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 821 finished
---------------------------------------  ----------------
epoch                                       821
total_step                               826000
replay_pool/size                         826000
trainer/alpha                                 0.0597847
trainer/alpha_loss                           -0.736637
trainer/entropy                              -5.7385
trainer/qf_loss                              21.3735
trainer/policy_loss                        -348.888
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.231
trainer/entropy_penalty                      -0.343075
trainer/entropy_percentage                   -0.000982371
trainer/Q1Pred Mean                         348.707
trainer/Q1Pred Std                           58.8526
trainer/Q1Pred Max                          432.766
trainer/Q1Pred Min                           62.1515
trainer/Q2Pred Mean                         347.745
trainer/Q2Pred Std                           58.6672
trainer/Q2Pred Max                          431.398
trainer/Q2Pred Min                           78.9857
trainer/QTargetWithReg Mean                 348.027
trainer/QTargetWithReg Std                   58.8275
trainer/QTargetWithReg Max                  431.229
trainer/QTargetWithReg Min                   47.792
trainer/PolicyLossWithoutReg Mean           349.231
trainer/PolicyLossWithoutReg Std             57.8207
trainer/PolicyLossWithoutReg Max            431.267
trainer/PolicyLossWithoutReg Min             64.5717
exploration/num steps total              826000
exploration/num paths total                1616
exploration/path length this epoch Mean     313
exploration/path length this epoch Std      166
exploration/path length this epoch Max      479
exploration/path length this epoch Min      147
exploration/Rewards Mean                      3.75584
exploration/Rewards Std                       1.49774
exploration/Rewards Max                       6.87757
exploration/Rewards Min                      -1.00405
exploration/Returns Mean                   1175.58
exploration/Returns Std                     817.852
exploration/Returns Max                    1993.43
exploration/Returns Min                     357.727
exploration/Num Paths                         2
exploration/Average Returns                1175.58
evaluation_0/num steps total                  6.43394e+06
evaluation_0/num paths total              10057
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77466
evaluation_0/Rewards Std                      0.976564
evaluation_0/Rewards Max                      7.28953
evaluation_0/Rewards Min                     -0.809365
evaluation_0/Returns Mean                  4774.66
evaluation_0/Returns Std                     80.6982
evaluation_0/Returns Max                   4908.18
evaluation_0/Returns Min                   4700.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4774.66
time/epoch (s)                                0
time/total (s)                            12434
Epoch                                       821
---------------------------------------  ----------------
2022-11-16 19:42:12.028860 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 822 finished
---------------------------------------  ----------------
epoch                                       822
total_step                               827000
replay_pool/size                         827000
trainer/alpha                                 0.0589793
trainer/alpha_loss                            0.188799
trainer/entropy                              -6.0667
trainer/qf_loss                              33.6009
trainer/policy_loss                        -345.259
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.617
trainer/entropy_penalty                      -0.35781
trainer/entropy_percentage                   -0.00103528
trainer/Q1Pred Mean                         344.434
trainer/Q1Pred Std                           65.4745
trainer/Q1Pred Max                          426.675
trainer/Q1Pred Min                           20.9376
trainer/Q2Pred Mean                         344.402
trainer/Q2Pred Std                           64.2317
trainer/Q2Pred Max                          424.933
trainer/Q2Pred Min                           17.7572
trainer/QTargetWithReg Mean                 344.25
trainer/QTargetWithReg Std                   65.779
trainer/QTargetWithReg Max                  427.143
trainer/QTargetWithReg Min                    1.56521
trainer/PolicyLossWithoutReg Mean           345.617
trainer/PolicyLossWithoutReg Std             63.7704
trainer/PolicyLossWithoutReg Max            424.494
trainer/PolicyLossWithoutReg Min             19.0004
exploration/num steps total              827000
exploration/num paths total                1617
exploration/path length this epoch Mean      97
exploration/path length this epoch Std        0
exploration/path length this epoch Max       97
exploration/path length this epoch Min       97
exploration/Rewards Mean                      2.80438
exploration/Rewards Std                       1.49206
exploration/Rewards Max                       5.11321
exploration/Rewards Min                      -0.756358
exploration/Returns Mean                    272.025
exploration/Returns Std                       0
exploration/Returns Max                     272.025
exploration/Returns Min                     272.025
exploration/Num Paths                         1
exploration/Average Returns                 272.025
evaluation_0/num steps total                  6.44194e+06
evaluation_0/num paths total              10065
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79003
evaluation_0/Rewards Std                      1.05772
evaluation_0/Rewards Max                      7.59157
evaluation_0/Rewards Min                     -0.716942
evaluation_0/Returns Mean                  4790.03
evaluation_0/Returns Std                     59.2931
evaluation_0/Returns Max                   4923.24
evaluation_0/Returns Min                   4733.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4790.03
time/epoch (s)                                0
time/total (s)                            12448.9
Epoch                                       822
---------------------------------------  ----------------
2022-11-16 19:42:26.942477 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 823 finished
---------------------------------------  ----------------
epoch                                       823
total_step                               828000
replay_pool/size                         828000
trainer/alpha                                 0.0600504
trainer/alpha_loss                           -1.27445
trainer/entropy                              -5.54687
trainer/qf_loss                              21.2195
trainer/policy_loss                        -345.784
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.117
trainer/entropy_penalty                      -0.333092
trainer/entropy_percentage                   -0.000962367
trainer/Q1Pred Mean                         345.341
trainer/Q1Pred Std                           71.7506
trainer/Q1Pred Max                          432.964
trainer/Q1Pred Min                          -30.8907
trainer/Q2Pred Mean                         345.537
trainer/Q2Pred Std                           71.7198
trainer/Q2Pred Max                          430.643
trainer/Q2Pred Min                          -32.5878
trainer/QTargetWithReg Mean                 345.282
trainer/QTargetWithReg Std                   71.5392
trainer/QTargetWithReg Max                  432.693
trainer/QTargetWithReg Min                  -38.0957
trainer/PolicyLossWithoutReg Mean           346.117
trainer/PolicyLossWithoutReg Std             70.3016
trainer/PolicyLossWithoutReg Max            429.698
trainer/PolicyLossWithoutReg Min            -26.5261
exploration/num steps total              828000
exploration/num paths total                1619
exploration/path length this epoch Mean      25.5
exploration/path length this epoch Std        5.5
exploration/path length this epoch Max       31
exploration/path length this epoch Min       20
exploration/Rewards Mean                      0.56823
exploration/Rewards Std                       0.734002
exploration/Rewards Max                       1.93495
exploration/Rewards Min                      -0.776956
exploration/Returns Mean                     14.4899
exploration/Returns Std                       9.6803
exploration/Returns Max                      24.1702
exploration/Returns Min                       4.80955
exploration/Num Paths                         2
exploration/Average Returns                  14.4899
evaluation_0/num steps total                  6.44994e+06
evaluation_0/num paths total              10073
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96244
evaluation_0/Rewards Std                      1.134
evaluation_0/Rewards Max                      8.52612
evaluation_0/Rewards Min                     -0.746206
evaluation_0/Returns Mean                  4962.44
evaluation_0/Returns Std                     85.4497
evaluation_0/Returns Max                   5114.01
evaluation_0/Returns Min                   4809.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4962.44
time/epoch (s)                                0
time/total (s)                            12463.8
Epoch                                       823
---------------------------------------  ----------------
2022-11-16 19:42:42.211060 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 824 finished
---------------------------------------  ----------------
epoch                                       824
total_step                               829000
replay_pool/size                         829000
trainer/alpha                                 0.0581785
trainer/alpha_loss                           -1.42181
trainer/entropy                              -5.50013
trainer/qf_loss                              31.21
trainer/policy_loss                        -345.939
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.259
trainer/entropy_penalty                      -0.319989
trainer/entropy_percentage                   -0.000924134
trainer/Q1Pred Mean                         345.455
trainer/Q1Pred Std                           69.6532
trainer/Q1Pred Max                          430.794
trainer/Q1Pred Min                            5.95277
trainer/Q2Pred Mean                         345.34
trainer/Q2Pred Std                           69.1141
trainer/Q2Pred Max                          432.839
trainer/Q2Pred Min                           10.2193
trainer/QTargetWithReg Mean                 345.519
trainer/QTargetWithReg Std                   69.9142
trainer/QTargetWithReg Max                  432.576
trainer/QTargetWithReg Min                    3.31533
trainer/PolicyLossWithoutReg Mean           346.259
trainer/PolicyLossWithoutReg Std             68.9401
trainer/PolicyLossWithoutReg Max            433.473
trainer/PolicyLossWithoutReg Min              7.34974
exploration/num steps total              829000
exploration/num paths total                1620
exploration/path length this epoch Mean      52
exploration/path length this epoch Std        0
exploration/path length this epoch Max       52
exploration/path length this epoch Min       52
exploration/Rewards Mean                      1.60953
exploration/Rewards Std                       1.21851
exploration/Rewards Max                       3.83454
exploration/Rewards Min                      -0.59134
exploration/Returns Mean                     83.6956
exploration/Returns Std                       0
exploration/Returns Max                      83.6956
exploration/Returns Min                      83.6956
exploration/Num Paths                         1
exploration/Average Returns                  83.6956
evaluation_0/num steps total                  6.45794e+06
evaluation_0/num paths total              10081
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84568
evaluation_0/Rewards Std                      0.992789
evaluation_0/Rewards Max                      7.50033
evaluation_0/Rewards Min                     -0.698811
evaluation_0/Returns Mean                  4845.68
evaluation_0/Returns Std                     26.6904
evaluation_0/Returns Max                   4901.78
evaluation_0/Returns Min                   4818.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4845.68
time/epoch (s)                                0
time/total (s)                            12479.1
Epoch                                       824
---------------------------------------  ----------------
2022-11-16 19:42:57.156319 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 825 finished
---------------------------------------  ----------------
epoch                                       825
total_step                               830000
replay_pool/size                         830000
trainer/alpha                                 0.0598402
trainer/alpha_loss                            1.0923
trainer/entropy                              -6.38786
trainer/qf_loss                              19.5204
trainer/policy_loss                        -342.034
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.416
trainer/entropy_penalty                      -0.382251
trainer/entropy_percentage                   -0.00111633
trainer/Q1Pred Mean                         342.753
trainer/Q1Pred Std                           72.1789
trainer/Q1Pred Max                          437.463
trainer/Q1Pred Min                          -20.9954
trainer/Q2Pred Mean                         342.141
trainer/Q2Pred Std                           72.8685
trainer/Q2Pred Max                          440.847
trainer/Q2Pred Min                           -1.11696
trainer/QTargetWithReg Mean                 342.462
trainer/QTargetWithReg Std                   72.9231
trainer/QTargetWithReg Max                  437.862
trainer/QTargetWithReg Min                   -3.50358
trainer/PolicyLossWithoutReg Mean           342.416
trainer/PolicyLossWithoutReg Std             72.2452
trainer/PolicyLossWithoutReg Max            438.37
trainer/PolicyLossWithoutReg Min            -17.6664
exploration/num steps total              830000
exploration/num paths total                1621
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78928
exploration/Rewards Std                       1.01562
exploration/Rewards Max                       7.40786
exploration/Rewards Min                      -0.669955
exploration/Returns Mean                   4789.28
exploration/Returns Std                       0
exploration/Returns Max                    4789.28
exploration/Returns Min                    4789.28
exploration/Num Paths                         1
exploration/Average Returns                4789.28
evaluation_0/num steps total                  6.46594e+06
evaluation_0/num paths total              10089
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99817
evaluation_0/Rewards Std                      1.02245
evaluation_0/Rewards Max                      7.36098
evaluation_0/Rewards Min                     -0.704946
evaluation_0/Returns Mean                  4998.17
evaluation_0/Returns Std                     52.8372
evaluation_0/Returns Max                   5118.06
evaluation_0/Returns Min                   4943.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4998.17
time/epoch (s)                                0
time/total (s)                            12494
Epoch                                       825
---------------------------------------  ----------------
2022-11-16 19:43:13.898755 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 826 finished
---------------------------------------  ----------------
epoch                                       826
total_step                               831000
replay_pool/size                         831000
trainer/alpha                                 0.058764
trainer/alpha_loss                            1.82101
trainer/entropy                              -6.64244
trainer/qf_loss                              30.0993
trainer/policy_loss                        -340.562
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         340.952
trainer/entropy_penalty                      -0.390337
trainer/entropy_percentage                   -0.00114484
trainer/Q1Pred Mean                         340.414
trainer/Q1Pred Std                           66.8691
trainer/Q1Pred Max                          433.295
trainer/Q1Pred Min                           -2.61532
trainer/Q2Pred Mean                         340.935
trainer/Q2Pred Std                           67.3286
trainer/Q2Pred Max                          433.545
trainer/Q2Pred Min                          -15.2337
trainer/QTargetWithReg Mean                 339.911
trainer/QTargetWithReg Std                   67.703
trainer/QTargetWithReg Max                  432.633
trainer/QTargetWithReg Min                   -0.124064
trainer/PolicyLossWithoutReg Mean           340.952
trainer/PolicyLossWithoutReg Std             66.3108
trainer/PolicyLossWithoutReg Max            432.619
trainer/PolicyLossWithoutReg Min              6.92424
exploration/num steps total              831000
exploration/num paths total                1622
exploration/path length this epoch Mean     892
exploration/path length this epoch Std        0
exploration/path length this epoch Max      892
exploration/path length this epoch Min      892
exploration/Rewards Mean                      4.64748
exploration/Rewards Std                       1.2002
exploration/Rewards Max                       7.38151
exploration/Rewards Min                      -0.787707
exploration/Returns Mean                   4145.55
exploration/Returns Std                       0
exploration/Returns Max                    4145.55
exploration/Returns Min                    4145.55
exploration/Num Paths                         1
exploration/Average Returns                4145.55
evaluation_0/num steps total                  6.47303e+06
evaluation_0/num paths total              10097
evaluation_0/path length Mean               886.75
evaluation_0/path length Std                299.631
evaluation_0/path length Max               1000
evaluation_0/path length Min                 94
evaluation_0/Rewards Mean                     4.82197
evaluation_0/Rewards Std                      1.08311
evaluation_0/Rewards Max                      7.23887
evaluation_0/Rewards Min                     -0.943027
evaluation_0/Returns Mean                  4275.89
evaluation_0/Returns Std                   1520.07
evaluation_0/Returns Max                   4989.54
evaluation_0/Returns Min                    257.745
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4275.89
time/epoch (s)                                0
time/total (s)                            12510.8
Epoch                                       826
---------------------------------------  ----------------
2022-11-16 19:43:29.054843 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 827 finished
---------------------------------------  ----------------
epoch                                       827
total_step                               832000
replay_pool/size                         832000
trainer/alpha                                 0.0579334
trainer/alpha_loss                           -2.08898
trainer/entropy                              -5.26663
trainer/qf_loss                              16.0221
trainer/policy_loss                        -355.3
trainer/adversary_policy_loss                17.1346
trainer/policy_loss_without_entropy         355.605
trainer/entropy_penalty                      -0.305114
trainer/entropy_percentage                   -0.000858013
trainer/Q1Pred Mean                         355.226
trainer/Q1Pred Std                           54.5584
trainer/Q1Pred Max                          426.723
trainer/Q1Pred Min                           47.8143
trainer/Q2Pred Mean                         355.358
trainer/Q2Pred Std                           54.437
trainer/Q2Pred Max                          428.065
trainer/Q2Pred Min                           47.134
trainer/QTargetWithReg Mean                 354.778
trainer/QTargetWithReg Std                   55.2107
trainer/QTargetWithReg Max                  425.778
trainer/QTargetWithReg Min                   45.272
trainer/PolicyLossWithoutReg Mean           355.605
trainer/PolicyLossWithoutReg Std             53.145
trainer/PolicyLossWithoutReg Max            427.306
trainer/PolicyLossWithoutReg Min             49.3124
exploration/num steps total              832000
exploration/num paths total                1623
exploration/path length this epoch Mean     802
exploration/path length this epoch Std        0
exploration/path length this epoch Max      802
exploration/path length this epoch Min      802
exploration/Rewards Mean                      4.33464
exploration/Rewards Std                       1.21948
exploration/Rewards Max                       7.00678
exploration/Rewards Min                      -0.962168
exploration/Returns Mean                   3476.38
exploration/Returns Std                       0
exploration/Returns Max                    3476.38
exploration/Returns Min                    3476.38
exploration/Num Paths                         1
exploration/Average Returns                3476.38
evaluation_0/num steps total                  6.48103e+06
evaluation_0/num paths total              10105
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89855
evaluation_0/Rewards Std                      0.982676
evaluation_0/Rewards Max                      7.66273
evaluation_0/Rewards Min                     -0.53837
evaluation_0/Returns Mean                  4898.55
evaluation_0/Returns Std                     57.522
evaluation_0/Returns Max                   4962.85
evaluation_0/Returns Min                   4776.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4898.55
time/epoch (s)                                0
time/total (s)                            12525.9
Epoch                                       827
---------------------------------------  ----------------
2022-11-16 19:43:43.936873 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 828 finished
---------------------------------------  ----------------
epoch                                       828
total_step                               833000
replay_pool/size                         833000
trainer/alpha                                 0.0564279
trainer/alpha_loss                            1.44119
trainer/entropy                              -6.5013
trainer/qf_loss                              30.2449
trainer/policy_loss                        -349.519
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.886
trainer/entropy_penalty                      -0.366855
trainer/entropy_percentage                   -0.0010485
trainer/Q1Pred Mean                         349.342
trainer/Q1Pred Std                           62.9898
trainer/Q1Pred Max                          421.805
trainer/Q1Pred Min                           10.0966
trainer/Q2Pred Mean                         349.47
trainer/Q2Pred Std                           63.0892
trainer/Q2Pred Max                          423.851
trainer/Q2Pred Min                           -3.33844
trainer/QTargetWithReg Mean                 349.288
trainer/QTargetWithReg Std                   63.2236
trainer/QTargetWithReg Max                  422.975
trainer/QTargetWithReg Min                   -0.00630374
trainer/PolicyLossWithoutReg Mean           349.886
trainer/PolicyLossWithoutReg Std             62.1881
trainer/PolicyLossWithoutReg Max            421.579
trainer/PolicyLossWithoutReg Min              3.33342
exploration/num steps total              833000
exploration/num paths total                1624
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69363
exploration/Rewards Std                       1.10049
exploration/Rewards Max                       7.3893
exploration/Rewards Min                      -0.452431
exploration/Returns Mean                   4693.63
exploration/Returns Std                       0
exploration/Returns Max                    4693.63
exploration/Returns Min                    4693.63
exploration/Num Paths                         1
exploration/Average Returns                4693.63
evaluation_0/num steps total                  6.48903e+06
evaluation_0/num paths total              10113
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76347
evaluation_0/Rewards Std                      0.970885
evaluation_0/Rewards Max                      7.27122
evaluation_0/Rewards Min                     -0.544874
evaluation_0/Returns Mean                  4763.47
evaluation_0/Returns Std                    100.133
evaluation_0/Returns Max                   4926.95
evaluation_0/Returns Min                   4606.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4763.47
time/epoch (s)                                0
time/total (s)                            12540.8
Epoch                                       828
---------------------------------------  ----------------
2022-11-16 19:43:58.947720 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 829 finished
---------------------------------------  ----------------
epoch                                       829
total_step                               834000
replay_pool/size                         834000
trainer/alpha                                 0.0576342
trainer/alpha_loss                           -0.736873
trainer/entropy                              -5.74177
trainer/qf_loss                              25.4964
trainer/policy_loss                        -344.603
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.934
trainer/entropy_penalty                      -0.330922
trainer/entropy_percentage                   -0.000959378
trainer/Q1Pred Mean                         344.72
trainer/Q1Pred Std                           62.2485
trainer/Q1Pred Max                          425.643
trainer/Q1Pred Min                           30.6798
trainer/Q2Pred Mean                         345.003
trainer/Q2Pred Std                           62.6373
trainer/Q2Pred Max                          424.15
trainer/Q2Pred Min                           20.653
trainer/QTargetWithReg Mean                 343.882
trainer/QTargetWithReg Std                   62.4408
trainer/QTargetWithReg Max                  426.566
trainer/QTargetWithReg Min                   15.8564
trainer/PolicyLossWithoutReg Mean           344.934
trainer/PolicyLossWithoutReg Std             60.766
trainer/PolicyLossWithoutReg Max            424.89
trainer/PolicyLossWithoutReg Min             22.2725
exploration/num steps total              834000
exploration/num paths total                1625
exploration/path length this epoch Mean     689
exploration/path length this epoch Std        0
exploration/path length this epoch Max      689
exploration/path length this epoch Min      689
exploration/Rewards Mean                      3.8854
exploration/Rewards Std                       1.30918
exploration/Rewards Max                       6.65185
exploration/Rewards Min                      -1.68625
exploration/Returns Mean                   2677.04
exploration/Returns Std                       0
exploration/Returns Max                    2677.04
exploration/Returns Min                    2677.04
exploration/Num Paths                         1
exploration/Average Returns                2677.04
evaluation_0/num steps total                  6.49703e+06
evaluation_0/num paths total              10121
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92475
evaluation_0/Rewards Std                      0.99321
evaluation_0/Rewards Max                      8.25318
evaluation_0/Rewards Min                     -0.761436
evaluation_0/Returns Mean                  4924.75
evaluation_0/Returns Std                     83.1414
evaluation_0/Returns Max                   5072.17
evaluation_0/Returns Min                   4851.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4924.75
time/epoch (s)                                0
time/total (s)                            12555.8
Epoch                                       829
---------------------------------------  ----------------
2022-11-16 19:44:13.876635 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 830 finished
---------------------------------------  ----------------
epoch                                       830
total_step                               835000
replay_pool/size                         835000
trainer/alpha                                 0.0583277
trainer/alpha_loss                           -0.246233
trainer/entropy                              -5.91335
trainer/qf_loss                              27.8569
trainer/policy_loss                        -350.599
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.944
trainer/entropy_penalty                      -0.344912
trainer/entropy_percentage                   -0.000982813
trainer/Q1Pred Mean                         350.104
trainer/Q1Pred Std                           65.2811
trainer/Q1Pred Max                          430.064
trainer/Q1Pred Min                            5.09646
trainer/Q2Pred Mean                         350.92
trainer/Q2Pred Std                           65.0134
trainer/Q2Pred Max                          427.19
trainer/Q2Pred Min                            7.14007
trainer/QTargetWithReg Mean                 349.587
trainer/QTargetWithReg Std                   65.4822
trainer/QTargetWithReg Max                  425.959
trainer/QTargetWithReg Min                    2.99894
trainer/PolicyLossWithoutReg Mean           350.944
trainer/PolicyLossWithoutReg Std             64.0725
trainer/PolicyLossWithoutReg Max            426.191
trainer/PolicyLossWithoutReg Min              2.54279
exploration/num steps total              835000
exploration/num paths total                1626
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.34124
exploration/Rewards Std                       1.30161
exploration/Rewards Max                       6.72103
exploration/Rewards Min                      -0.710567
exploration/Returns Mean                   4341.24
exploration/Returns Std                       0
exploration/Returns Max                    4341.24
exploration/Returns Min                    4341.24
exploration/Num Paths                         1
exploration/Average Returns                4341.24
evaluation_0/num steps total                  6.50503e+06
evaluation_0/num paths total              10129
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04294
evaluation_0/Rewards Std                      1.10945
evaluation_0/Rewards Max                      7.76186
evaluation_0/Rewards Min                     -0.834745
evaluation_0/Returns Mean                  5042.94
evaluation_0/Returns Std                     62.2878
evaluation_0/Returns Max                   5154.35
evaluation_0/Returns Min                   4971.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5042.94
time/epoch (s)                                0
time/total (s)                            12570.8
Epoch                                       830
---------------------------------------  ----------------
2022-11-16 19:44:28.944701 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 831 finished
---------------------------------------  ----------------
epoch                                       831
total_step                               836000
replay_pool/size                         836000
trainer/alpha                                 0.0592145
trainer/alpha_loss                           -0.938018
trainer/entropy                              -5.66814
trainer/qf_loss                              26.8109
trainer/policy_loss                        -347.895
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.23
trainer/entropy_penalty                      -0.335636
trainer/entropy_percentage                   -0.000963834
trainer/Q1Pred Mean                         347.738
trainer/Q1Pred Std                           58.5
trainer/Q1Pred Max                          421.476
trainer/Q1Pred Min                           91.8723
trainer/Q2Pred Mean                         347.135
trainer/Q2Pred Std                           58.1889
trainer/Q2Pred Max                          419.981
trainer/Q2Pred Min                           92.4403
trainer/QTargetWithReg Mean                 347.969
trainer/QTargetWithReg Std                   58.0775
trainer/QTargetWithReg Max                  422.24
trainer/QTargetWithReg Min                   81.7983
trainer/PolicyLossWithoutReg Mean           348.23
trainer/PolicyLossWithoutReg Std             57.4148
trainer/PolicyLossWithoutReg Max            420.89
trainer/PolicyLossWithoutReg Min             94.4838
exploration/num steps total              836000
exploration/num paths total                1627
exploration/path length this epoch Mean     357
exploration/path length this epoch Std        0
exploration/path length this epoch Max      357
exploration/path length this epoch Min      357
exploration/Rewards Mean                      3.77616
exploration/Rewards Std                       1.38258
exploration/Rewards Max                       6.10011
exploration/Rewards Min                      -0.814983
exploration/Returns Mean                   1348.09
exploration/Returns Std                       0
exploration/Returns Max                    1348.09
exploration/Returns Min                    1348.09
exploration/Num Paths                         1
exploration/Average Returns                1348.09
evaluation_0/num steps total                  6.51303e+06
evaluation_0/num paths total              10137
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04662
evaluation_0/Rewards Std                      1.03123
evaluation_0/Rewards Max                      7.73861
evaluation_0/Rewards Min                     -0.575329
evaluation_0/Returns Mean                  5046.62
evaluation_0/Returns Std                     61.6301
evaluation_0/Returns Max                   5151.66
evaluation_0/Returns Min                   4965.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5046.62
time/epoch (s)                                0
time/total (s)                            12585.8
Epoch                                       831
---------------------------------------  ----------------
2022-11-16 19:44:43.794734 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 832 finished
---------------------------------------  ----------------
epoch                                       832
total_step                               837000
replay_pool/size                         837000
trainer/alpha                                 0.0607896
trainer/alpha_loss                            1.73591
trainer/entropy                              -6.61986
trainer/qf_loss                              23.7723
trainer/policy_loss                        -345.391
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.793
trainer/entropy_penalty                      -0.402418
trainer/entropy_percentage                   -0.00116375
trainer/Q1Pred Mean                         345.105
trainer/Q1Pred Std                           64.601
trainer/Q1Pred Max                          434.743
trainer/Q1Pred Min                            1.0046
trainer/Q2Pred Mean                         344.995
trainer/Q2Pred Std                           64.0045
trainer/Q2Pred Max                          432.651
trainer/Q2Pred Min                            7.16549
trainer/QTargetWithReg Mean                 345.34
trainer/QTargetWithReg Std                   65.1279
trainer/QTargetWithReg Max                  433.338
trainer/QTargetWithReg Min                    3.31533
trainer/PolicyLossWithoutReg Mean           345.793
trainer/PolicyLossWithoutReg Std             63.5942
trainer/PolicyLossWithoutReg Max            434.183
trainer/PolicyLossWithoutReg Min              5.37371
exploration/num steps total              837000
exploration/num paths total                1628
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75593
exploration/Rewards Std                       1.06139
exploration/Rewards Max                       7.1875
exploration/Rewards Min                      -0.308441
exploration/Returns Mean                   4755.93
exploration/Returns Std                       0
exploration/Returns Max                    4755.93
exploration/Returns Min                    4755.93
exploration/Num Paths                         1
exploration/Average Returns                4755.93
evaluation_0/num steps total                  6.52103e+06
evaluation_0/num paths total              10145
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91019
evaluation_0/Rewards Std                      1.01215
evaluation_0/Rewards Max                      7.43953
evaluation_0/Rewards Min                     -0.669966
evaluation_0/Returns Mean                  4910.19
evaluation_0/Returns Std                     43.2256
evaluation_0/Returns Max                   4973.37
evaluation_0/Returns Min                   4845.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4910.19
time/epoch (s)                                0
time/total (s)                            12600.7
Epoch                                       832
---------------------------------------  ----------------
2022-11-16 19:44:58.711577 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 833 finished
---------------------------------------  ----------------
epoch                                       833
total_step                               838000
replay_pool/size                         838000
trainer/alpha                                 0.0606065
trainer/alpha_loss                           -0.359043
trainer/entropy                              -5.87192
trainer/qf_loss                              27.4398
trainer/policy_loss                        -351.052
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.408
trainer/entropy_penalty                      -0.355877
trainer/entropy_percentage                   -0.00101272
trainer/Q1Pred Mean                         350.085
trainer/Q1Pred Std                           63.8025
trainer/Q1Pred Max                          430.347
trainer/Q1Pred Min                           18.6507
trainer/Q2Pred Mean                         350.137
trainer/Q2Pred Std                           64.0824
trainer/Q2Pred Max                          431.285
trainer/Q2Pred Min                           19.8305
trainer/QTargetWithReg Mean                 350.205
trainer/QTargetWithReg Std                   63.9394
trainer/QTargetWithReg Max                  432.001
trainer/QTargetWithReg Min                   18.2443
trainer/PolicyLossWithoutReg Mean           351.408
trainer/PolicyLossWithoutReg Std             63.113
trainer/PolicyLossWithoutReg Max            431.147
trainer/PolicyLossWithoutReg Min             18.7048
exploration/num steps total              838000
exploration/num paths total                1629
exploration/path length this epoch Mean     404
exploration/path length this epoch Std        0
exploration/path length this epoch Max      404
exploration/path length this epoch Min      404
exploration/Rewards Mean                      4.1403
exploration/Rewards Std                       1.37448
exploration/Rewards Max                       6.50602
exploration/Rewards Min                      -0.905117
exploration/Returns Mean                   1672.68
exploration/Returns Std                       0
exploration/Returns Max                    1672.68
exploration/Returns Min                    1672.68
exploration/Num Paths                         1
exploration/Average Returns                1672.68
evaluation_0/num steps total                  6.52903e+06
evaluation_0/num paths total              10153
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00366
evaluation_0/Rewards Std                      1.06214
evaluation_0/Rewards Max                      7.52054
evaluation_0/Rewards Min                     -0.671298
evaluation_0/Returns Mean                  5003.66
evaluation_0/Returns Std                     50.0116
evaluation_0/Returns Max                   5073.05
evaluation_0/Returns Min                   4914.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5003.66
time/epoch (s)                                0
time/total (s)                            12615.6
Epoch                                       833
---------------------------------------  ----------------
2022-11-16 19:45:15.471970 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 834 finished
---------------------------------------  ----------------
epoch                                       834
total_step                               839000
replay_pool/size                         839000
trainer/alpha                                 0.0600695
trainer/alpha_loss                           -0.950922
trainer/entropy                              -5.66187
trainer/qf_loss                              17.9277
trainer/policy_loss                        -345.681
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.021
trainer/entropy_penalty                      -0.340106
trainer/entropy_percentage                   -0.000982906
trainer/Q1Pred Mean                         345.076
trainer/Q1Pred Std                           72.5416
trainer/Q1Pred Max                          428.174
trainer/Q1Pred Min                            5.23937
trainer/Q2Pred Mean                         345.417
trainer/Q2Pred Std                           72.6337
trainer/Q2Pred Max                          430.515
trainer/Q2Pred Min                            0.263092
trainer/QTargetWithReg Mean                 345.662
trainer/QTargetWithReg Std                   72.2341
trainer/QTargetWithReg Max                  428.27
trainer/QTargetWithReg Min                    3.44698
trainer/PolicyLossWithoutReg Mean           346.021
trainer/PolicyLossWithoutReg Std             72.4246
trainer/PolicyLossWithoutReg Max            429.115
trainer/PolicyLossWithoutReg Min              5.73801
exploration/num steps total              839000
exploration/num paths total                1630
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70258
exploration/Rewards Std                       0.971115
exploration/Rewards Max                       7.047
exploration/Rewards Min                      -0.652326
exploration/Returns Mean                   4702.58
exploration/Returns Std                       0
exploration/Returns Max                    4702.58
exploration/Returns Min                    4702.58
exploration/Num Paths                         1
exploration/Average Returns                4702.58
evaluation_0/num steps total                  6.53668e+06
evaluation_0/num paths total              10161
evaluation_0/path length Mean               955.75
evaluation_0/path length Std                117.074
evaluation_0/path length Max               1000
evaluation_0/path length Min                646
evaluation_0/Rewards Mean                     4.69523
evaluation_0/Rewards Std                      1.05097
evaluation_0/Rewards Max                      7.41047
evaluation_0/Rewards Min                     -0.70168
evaluation_0/Returns Mean                  4487.46
evaluation_0/Returns Std                    541.125
evaluation_0/Returns Max                   4837.6
evaluation_0/Returns Min                   3070.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4487.46
time/epoch (s)                                0
time/total (s)                            12632.4
Epoch                                       834
---------------------------------------  ----------------
2022-11-16 19:45:30.282498 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 835 finished
---------------------------------------  ----------------
epoch                                       835
total_step                               840000
replay_pool/size                         840000
trainer/alpha                                 0.0577378
trainer/alpha_loss                            0.539327
trainer/entropy                              -6.18912
trainer/qf_loss                              24.6502
trainer/policy_loss                        -354.372
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.729
trainer/entropy_penalty                      -0.357347
trainer/entropy_percentage                   -0.00100738
trainer/Q1Pred Mean                         354.868
trainer/Q1Pred Std                           57.7903
trainer/Q1Pred Max                          441.328
trainer/Q1Pred Min                            9.97141
trainer/Q2Pred Mean                         354.323
trainer/Q2Pred Std                           57.822
trainer/Q2Pred Max                          443.42
trainer/Q2Pred Min                            9.00059
trainer/QTargetWithReg Mean                 353.509
trainer/QTargetWithReg Std                   58.2636
trainer/QTargetWithReg Max                  440.296
trainer/QTargetWithReg Min                    3.44227
trainer/PolicyLossWithoutReg Mean           354.729
trainer/PolicyLossWithoutReg Std             57.1965
trainer/PolicyLossWithoutReg Max            439.997
trainer/PolicyLossWithoutReg Min             12.5765
exploration/num steps total              840000
exploration/num paths total                1631
exploration/path length this epoch Mean     911
exploration/path length this epoch Std        0
exploration/path length this epoch Max      911
exploration/path length this epoch Min      911
exploration/Rewards Mean                      4.66695
exploration/Rewards Std                       1.17857
exploration/Rewards Max                       6.91344
exploration/Rewards Min                      -0.669783
exploration/Returns Mean                   4251.59
exploration/Returns Std                       0
exploration/Returns Max                    4251.59
exploration/Returns Min                    4251.59
exploration/Num Paths                         1
exploration/Average Returns                4251.59
evaluation_0/num steps total                  6.54468e+06
evaluation_0/num paths total              10169
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9177
evaluation_0/Rewards Std                      1.13484
evaluation_0/Rewards Max                      7.5332
evaluation_0/Rewards Min                     -0.608461
evaluation_0/Returns Mean                  4917.7
evaluation_0/Returns Std                     62.1798
evaluation_0/Returns Max                   5019.01
evaluation_0/Returns Min                   4808.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4917.7
time/epoch (s)                                0
time/total (s)                            12647.2
Epoch                                       835
---------------------------------------  ----------------
2022-11-16 19:45:45.166528 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 836 finished
---------------------------------------  ----------------
epoch                                       836
total_step                               841000
replay_pool/size                         841000
trainer/alpha                                 0.0594083
trainer/alpha_loss                           -0.678692
trainer/entropy                              -5.75961
trainer/qf_loss                              25.6906
trainer/policy_loss                        -345.01
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.352
trainer/entropy_penalty                      -0.342169
trainer/entropy_percentage                   -0.000990781
trainer/Q1Pred Mean                         344.149
trainer/Q1Pred Std                           73.2554
trainer/Q1Pred Max                          421.098
trainer/Q1Pred Min                            8.07231
trainer/Q2Pred Mean                         343.999
trainer/Q2Pred Std                           73.1822
trainer/Q2Pred Max                          422.27
trainer/Q2Pred Min                            8.32317
trainer/QTargetWithReg Mean                 344.072
trainer/QTargetWithReg Std                   73.841
trainer/QTargetWithReg Max                  421.594
trainer/QTargetWithReg Min                    3.08379
trainer/PolicyLossWithoutReg Mean           345.352
trainer/PolicyLossWithoutReg Std             72.1672
trainer/PolicyLossWithoutReg Max            420.878
trainer/PolicyLossWithoutReg Min              7.52536
exploration/num steps total              841000
exploration/num paths total                1632
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41448
exploration/Rewards Std                       1.01012
exploration/Rewards Max                       6.54895
exploration/Rewards Min                      -0.520594
exploration/Returns Mean                   4414.48
exploration/Returns Std                       0
exploration/Returns Max                    4414.48
exploration/Returns Min                    4414.48
exploration/Num Paths                         1
exploration/Average Returns                4414.48
evaluation_0/num steps total                  6.55268e+06
evaluation_0/num paths total              10177
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79317
evaluation_0/Rewards Std                      1.06321
evaluation_0/Rewards Max                      7.46545
evaluation_0/Rewards Min                     -0.688053
evaluation_0/Returns Mean                  4793.17
evaluation_0/Returns Std                    139.137
evaluation_0/Returns Max                   4938.77
evaluation_0/Returns Min                   4558.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4793.17
time/epoch (s)                                0
time/total (s)                            12662
Epoch                                       836
---------------------------------------  ----------------
2022-11-16 19:46:03.373651 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 837 finished
---------------------------------------  ----------------
epoch                                       837
total_step                               842000
replay_pool/size                         842000
trainer/alpha                                 0.058457
trainer/alpha_loss                           -0.974603
trainer/entropy                              -5.65676
trainer/qf_loss                              19.7005
trainer/policy_loss                        -349.065
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.396
trainer/entropy_penalty                      -0.330677
trainer/entropy_percentage                   -0.000946424
trainer/Q1Pred Mean                         349.732
trainer/Q1Pred Std                           65.0397
trainer/Q1Pred Max                          426.133
trainer/Q1Pred Min                           12.3754
trainer/Q2Pred Mean                         349.391
trainer/Q2Pred Std                           64.8512
trainer/Q2Pred Max                          431.295
trainer/Q2Pred Min                            5.97506
trainer/QTargetWithReg Mean                 349.415
trainer/QTargetWithReg Std                   65.0337
trainer/QTargetWithReg Max                  432.183
trainer/QTargetWithReg Min                    4.95374
trainer/PolicyLossWithoutReg Mean           349.396
trainer/PolicyLossWithoutReg Std             64.2969
trainer/PolicyLossWithoutReg Max            426.34
trainer/PolicyLossWithoutReg Min             11.8004
exploration/num steps total              842000
exploration/num paths total                1633
exploration/path length this epoch Mean      90
exploration/path length this epoch Std        0
exploration/path length this epoch Max       90
exploration/path length this epoch Min       90
exploration/Rewards Mean                      2.37712
exploration/Rewards Std                       1.57096
exploration/Rewards Max                       5.44263
exploration/Rewards Min                      -0.667108
exploration/Returns Mean                    213.941
exploration/Returns Std                       0
exploration/Returns Max                     213.941
exploration/Returns Min                     213.941
exploration/Num Paths                         1
exploration/Average Returns                 213.941
evaluation_0/num steps total                  6.56046e+06
evaluation_0/num paths total              10194
evaluation_0/path length Mean               457.765
evaluation_0/path length Std                453.685
evaluation_0/path length Max               1000
evaluation_0/path length Min                 73
evaluation_0/Rewards Mean                     4.77467
evaluation_0/Rewards Std                      1.34102
evaluation_0/Rewards Max                      7.81751
evaluation_0/Rewards Min                     -0.808533
evaluation_0/Returns Mean                  2185.68
evaluation_0/Returns Std                   2355.75
evaluation_0/Returns Max                   5069.9
evaluation_0/Returns Min                    168.232
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               2185.68
time/epoch (s)                                0
time/total (s)                            12680.3
Epoch                                       837
---------------------------------------  ----------------
2022-11-16 19:46:18.374800 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 838 finished
---------------------------------------  ----------------
epoch                                       838
total_step                               843000
replay_pool/size                         843000
trainer/alpha                                 0.0571539
trainer/alpha_loss                           -0.119036
trainer/entropy                              -5.95841
trainer/qf_loss                              18.5472
trainer/policy_loss                        -350.08
trainer/adversary_policy_loss                16.7992
trainer/policy_loss_without_entropy         350.42
trainer/entropy_penalty                      -0.340546
trainer/entropy_percentage                   -0.000971823
trainer/Q1Pred Mean                         349.116
trainer/Q1Pred Std                           65.7606
trainer/Q1Pred Max                          433.906
trainer/Q1Pred Min                           32.9197
trainer/Q2Pred Mean                         349.621
trainer/Q2Pred Std                           65.3625
trainer/Q2Pred Max                          435.873
trainer/Q2Pred Min                           32.4849
trainer/QTargetWithReg Mean                 349.157
trainer/QTargetWithReg Std                   65.9083
trainer/QTargetWithReg Max                  433.728
trainer/QTargetWithReg Min                   31.3656
trainer/PolicyLossWithoutReg Mean           350.42
trainer/PolicyLossWithoutReg Std             64.5715
trainer/PolicyLossWithoutReg Max            433.609
trainer/PolicyLossWithoutReg Min             29.8807
exploration/num steps total              843000
exploration/num paths total                1634
exploration/path length this epoch Mean     885
exploration/path length this epoch Std        0
exploration/path length this epoch Max      885
exploration/path length this epoch Min      885
exploration/Rewards Mean                      4.95711
exploration/Rewards Std                       1.07289
exploration/Rewards Max                       7.37682
exploration/Rewards Min                      -0.87094
exploration/Returns Mean                   4387.05
exploration/Returns Std                       0
exploration/Returns Max                    4387.05
exploration/Returns Min                    4387.05
exploration/Num Paths                         1
exploration/Average Returns                4387.05
evaluation_0/num steps total                  6.56846e+06
evaluation_0/num paths total              10202
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89083
evaluation_0/Rewards Std                      1.08002
evaluation_0/Rewards Max                      7.73965
evaluation_0/Rewards Min                     -0.645254
evaluation_0/Returns Mean                  4890.83
evaluation_0/Returns Std                     36.2502
evaluation_0/Returns Max                   4956.16
evaluation_0/Returns Min                   4841.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4890.83
time/epoch (s)                                0
time/total (s)                            12695.3
Epoch                                       838
---------------------------------------  ----------------
2022-11-16 19:46:33.259610 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 839 finished
---------------------------------------  ----------------
epoch                                       839
total_step                               844000
replay_pool/size                         844000
trainer/alpha                                 0.0591504
trainer/alpha_loss                            0.72151
trainer/entropy                              -6.25515
trainer/qf_loss                              24.5999
trainer/policy_loss                        -344.05
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.42
trainer/entropy_penalty                      -0.369995
trainer/entropy_percentage                   -0.00107425
trainer/Q1Pred Mean                         343.442
trainer/Q1Pred Std                           75.5484
trainer/Q1Pred Max                          439.609
trainer/Q1Pred Min                           -4.49445
trainer/Q2Pred Mean                         342.985
trainer/Q2Pred Std                           76.1454
trainer/Q2Pred Max                          437.701
trainer/Q2Pred Min                           -4.01694
trainer/QTargetWithReg Mean                 343.604
trainer/QTargetWithReg Std                   76.0042
trainer/QTargetWithReg Max                  441.082
trainer/QTargetWithReg Min                    0.279862
trainer/PolicyLossWithoutReg Mean           344.42
trainer/PolicyLossWithoutReg Std             74.935
trainer/PolicyLossWithoutReg Max            437.869
trainer/PolicyLossWithoutReg Min            -12.0109
exploration/num steps total              844000
exploration/num paths total                1635
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67194
exploration/Rewards Std                       1.06235
exploration/Rewards Max                       7.24083
exploration/Rewards Min                      -0.554053
exploration/Returns Mean                   4671.94
exploration/Returns Std                       0
exploration/Returns Max                    4671.94
exploration/Returns Min                    4671.94
exploration/Num Paths                         1
exploration/Average Returns                4671.94
evaluation_0/num steps total                  6.57646e+06
evaluation_0/num paths total              10210
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89184
evaluation_0/Rewards Std                      1.13013
evaluation_0/Rewards Max                      7.78443
evaluation_0/Rewards Min                     -0.585018
evaluation_0/Returns Mean                  4891.84
evaluation_0/Returns Std                     89.6691
evaluation_0/Returns Max                   5050.59
evaluation_0/Returns Min                   4757.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4891.84
time/epoch (s)                                0
time/total (s)                            12710.1
Epoch                                       839
---------------------------------------  ----------------
2022-11-16 19:46:50.172384 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 840 finished
---------------------------------------  ----------------
epoch                                       840
total_step                               845000
replay_pool/size                         845000
trainer/alpha                                 0.0597254
trainer/alpha_loss                           -0.72111
trainer/entropy                              -5.74412
trainer/qf_loss                              30.7566
trainer/policy_loss                        -352.448
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.791
trainer/entropy_penalty                      -0.34307
trainer/entropy_percentage                   -0.000972444
trainer/Q1Pred Mean                         351.85
trainer/Q1Pred Std                           62.7253
trainer/Q1Pred Max                          428.97
trainer/Q1Pred Min                           13.0285
trainer/Q2Pred Mean                         352.667
trainer/Q2Pred Std                           62.6544
trainer/Q2Pred Max                          430.778
trainer/Q2Pred Min                            5.03861
trainer/QTargetWithReg Mean                 351.564
trainer/QTargetWithReg Std                   63.0012
trainer/QTargetWithReg Max                  427.053
trainer/QTargetWithReg Min                   14.304
trainer/PolicyLossWithoutReg Mean           352.791
trainer/PolicyLossWithoutReg Std             61.6319
trainer/PolicyLossWithoutReg Max            429.308
trainer/PolicyLossWithoutReg Min             11.0371
exploration/num steps total              845000
exploration/num paths total                1636
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72472
exploration/Rewards Std                       1.0469
exploration/Rewards Max                       7.33065
exploration/Rewards Min                      -0.582624
exploration/Returns Mean                   4724.72
exploration/Returns Std                       0
exploration/Returns Max                    4724.72
exploration/Returns Min                    4724.72
exploration/Num Paths                         1
exploration/Average Returns                4724.72
evaluation_0/num steps total                  6.5837e+06
evaluation_0/num paths total              10218
evaluation_0/path length Mean               904.125
evaluation_0/path length Std                167.75
evaluation_0/path length Max               1000
evaluation_0/path length Min                569
evaluation_0/Rewards Mean                     4.84661
evaluation_0/Rewards Std                      1.02975
evaluation_0/Rewards Max                      7.63224
evaluation_0/Rewards Min                     -0.558748
evaluation_0/Returns Mean                  4381.95
evaluation_0/Returns Std                    868.205
evaluation_0/Returns Max                   4995.7
evaluation_0/Returns Min                   2628.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4381.95
time/epoch (s)                                0
time/total (s)                            12727.1
Epoch                                       840
---------------------------------------  ----------------
2022-11-16 19:47:04.994032 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 841 finished
---------------------------------------  ---------------
epoch                                       841
total_step                               846000
replay_pool/size                         846000
trainer/alpha                                 0.0583582
trainer/alpha_loss                            0.917726
trainer/entropy                              -6.323
trainer/qf_loss                              26.8858
trainer/policy_loss                        -340.73
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.099
trainer/entropy_penalty                      -0.368999
trainer/entropy_percentage                   -0.00108179
trainer/Q1Pred Mean                         339.873
trainer/Q1Pred Std                           72.4317
trainer/Q1Pred Max                          429.058
trainer/Q1Pred Min                           -7.73584
trainer/Q2Pred Mean                         340.49
trainer/Q2Pred Std                           72.5523
trainer/Q2Pred Max                          430.88
trainer/Q2Pred Min                           -5.00098
trainer/QTargetWithReg Mean                 340.81
trainer/QTargetWithReg Std                   72.321
trainer/QTargetWithReg Max                  430.912
trainer/QTargetWithReg Min                    2.49149
trainer/PolicyLossWithoutReg Mean           341.099
trainer/PolicyLossWithoutReg Std             71.2786
trainer/PolicyLossWithoutReg Max            428.877
trainer/PolicyLossWithoutReg Min             -5.00296
exploration/num steps total              846000
exploration/num paths total                1637
exploration/path length this epoch Mean     974
exploration/path length this epoch Std        0
exploration/path length this epoch Max      974
exploration/path length this epoch Min      974
exploration/Rewards Mean                      4.70979
exploration/Rewards Std                       1.13683
exploration/Rewards Max                       8.93601
exploration/Rewards Min                      -0.424166
exploration/Returns Mean                   4587.33
exploration/Returns Std                       0
exploration/Returns Max                    4587.33
exploration/Returns Min                    4587.33
exploration/Num Paths                         1
exploration/Average Returns                4587.33
evaluation_0/num steps total                  6.5917e+06
evaluation_0/num paths total              10226
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88873
evaluation_0/Rewards Std                      1.10054
evaluation_0/Rewards Max                      7.72155
evaluation_0/Rewards Min                     -0.516615
evaluation_0/Returns Mean                  4888.73
evaluation_0/Returns Std                    108.003
evaluation_0/Returns Max                   5091.68
evaluation_0/Returns Min                   4754.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4888.73
time/epoch (s)                                0
time/total (s)                            12741.9
Epoch                                       841
---------------------------------------  ---------------
2022-11-16 19:47:21.867493 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 842 finished
---------------------------------------  ----------------
epoch                                       842
total_step                               847000
replay_pool/size                         847000
trainer/alpha                                 0.05914
trainer/alpha_loss                            0.913089
trainer/entropy                              -6.32288
trainer/qf_loss                              16.0118
trainer/policy_loss                        -345.416
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.789
trainer/entropy_penalty                      -0.373935
trainer/entropy_percentage                   -0.0010814
trainer/Q1Pred Mean                         344.842
trainer/Q1Pred Std                           71.7639
trainer/Q1Pred Max                          430.694
trainer/Q1Pred Min                           -1.38116
trainer/Q2Pred Mean                         344.131
trainer/Q2Pred Std                           71.3039
trainer/Q2Pred Max                          425.623
trainer/Q2Pred Min                          -13.926
trainer/QTargetWithReg Mean                 344.653
trainer/QTargetWithReg Std                   71.0279
trainer/QTargetWithReg Max                  428.143
trainer/QTargetWithReg Min                   -6.24094
trainer/PolicyLossWithoutReg Mean           345.789
trainer/PolicyLossWithoutReg Std             71.576
trainer/PolicyLossWithoutReg Max            424.436
trainer/PolicyLossWithoutReg Min             -3.26916
exploration/num steps total              847000
exploration/num paths total                1638
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82765
exploration/Rewards Std                       1.01252
exploration/Rewards Max                       7.59778
exploration/Rewards Min                      -0.445097
exploration/Returns Mean                   4827.65
exploration/Returns Std                       0
exploration/Returns Max                    4827.65
exploration/Returns Min                    4827.65
exploration/Num Paths                         1
exploration/Average Returns                4827.65
evaluation_0/num steps total                  6.59885e+06
evaluation_0/num paths total              10235
evaluation_0/path length Mean               794.778
evaluation_0/path length Std                383.936
evaluation_0/path length Max               1000
evaluation_0/path length Min                 76
evaluation_0/Rewards Mean                     4.8088
evaluation_0/Rewards Std                      1.04472
evaluation_0/Rewards Max                      7.78426
evaluation_0/Rewards Min                     -0.749778
evaluation_0/Returns Mean                  3821.93
evaluation_0/Returns Std                   1924.71
evaluation_0/Returns Max                   4923.55
evaluation_0/Returns Min                    219.604
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3821.93
time/epoch (s)                                0
time/total (s)                            12758.7
Epoch                                       842
---------------------------------------  ----------------
2022-11-16 19:47:36.864859 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 843 finished
---------------------------------------  ----------------
epoch                                       843
total_step                               848000
replay_pool/size                         848000
trainer/alpha                                 0.0589332
trainer/alpha_loss                            0.47388
trainer/entropy                              -6.16738
trainer/qf_loss                              25.9711
trainer/policy_loss                        -346.329
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.693
trainer/entropy_penalty                      -0.363463
trainer/entropy_percentage                   -0.00104837
trainer/Q1Pred Mean                         346.399
trainer/Q1Pred Std                           64.8715
trainer/Q1Pred Max                          428.222
trainer/Q1Pred Min                           34.2345
trainer/Q2Pred Mean                         346.704
trainer/Q2Pred Std                           64.9238
trainer/Q2Pred Max                          428.719
trainer/Q2Pred Min                           38.4186
trainer/QTargetWithReg Mean                 345.706
trainer/QTargetWithReg Std                   65.627
trainer/QTargetWithReg Max                  428.488
trainer/QTargetWithReg Min                   38.8377
trainer/PolicyLossWithoutReg Mean           346.693
trainer/PolicyLossWithoutReg Std             64.0277
trainer/PolicyLossWithoutReg Max            426.752
trainer/PolicyLossWithoutReg Min             36.0085
exploration/num steps total              848000
exploration/num paths total                1639
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57891
exploration/Rewards Std                       0.984818
exploration/Rewards Max                       7.46998
exploration/Rewards Min                      -0.708675
exploration/Returns Mean                   4578.91
exploration/Returns Std                       0
exploration/Returns Max                    4578.91
exploration/Returns Min                    4578.91
exploration/Num Paths                         1
exploration/Average Returns                4578.91
evaluation_0/num steps total                  6.60685e+06
evaluation_0/num paths total              10243
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85781
evaluation_0/Rewards Std                      1.03134
evaluation_0/Rewards Max                      7.7774
evaluation_0/Rewards Min                     -0.742942
evaluation_0/Returns Mean                  4857.81
evaluation_0/Returns Std                     78.3702
evaluation_0/Returns Max                   5005.56
evaluation_0/Returns Min                   4759.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4857.81
time/epoch (s)                                0
time/total (s)                            12773.7
Epoch                                       843
---------------------------------------  ----------------
2022-11-16 19:47:51.634531 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 844 finished
---------------------------------------  ----------------
epoch                                       844
total_step                               849000
replay_pool/size                         849000
trainer/alpha                                 0.0588453
trainer/alpha_loss                           -0.203053
trainer/entropy                              -5.92832
trainer/qf_loss                              18.9577
trainer/policy_loss                        -347.17
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.519
trainer/entropy_penalty                      -0.348854
trainer/entropy_percentage                   -0.00100384
trainer/Q1Pred Mean                         347.217
trainer/Q1Pred Std                           67.4646
trainer/Q1Pred Max                          437.29
trainer/Q1Pred Min                           -2.78059
trainer/Q2Pred Mean                         346.266
trainer/Q2Pred Std                           67.1611
trainer/Q2Pred Max                          429.598
trainer/Q2Pred Min                            3.14331
trainer/QTargetWithReg Mean                 347.376
trainer/QTargetWithReg Std                   67.3156
trainer/QTargetWithReg Max                  433.728
trainer/QTargetWithReg Min                    9.02492
trainer/PolicyLossWithoutReg Mean           347.519
trainer/PolicyLossWithoutReg Std             66.5391
trainer/PolicyLossWithoutReg Max            430.128
trainer/PolicyLossWithoutReg Min              2.51427
exploration/num steps total              849000
exploration/num paths total                1640
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58334
exploration/Rewards Std                       1.14939
exploration/Rewards Max                       7.79537
exploration/Rewards Min                      -0.970955
exploration/Returns Mean                   4583.34
exploration/Returns Std                       0
exploration/Returns Max                    4583.34
exploration/Returns Min                    4583.34
exploration/Num Paths                         1
exploration/Average Returns                4583.34
evaluation_0/num steps total                  6.61485e+06
evaluation_0/num paths total              10251
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95418
evaluation_0/Rewards Std                      1.15058
evaluation_0/Rewards Max                      7.94433
evaluation_0/Rewards Min                     -0.920101
evaluation_0/Returns Mean                  4954.18
evaluation_0/Returns Std                     77.5449
evaluation_0/Returns Max                   5069.36
evaluation_0/Returns Min                   4859.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4954.18
time/epoch (s)                                0
time/total (s)                            12788.5
Epoch                                       844
---------------------------------------  ----------------
2022-11-16 19:48:06.563235 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 845 finished
---------------------------------------  ----------------
epoch                                       845
total_step                               850000
replay_pool/size                         850000
trainer/alpha                                 0.058504
trainer/alpha_loss                           -0.56193
trainer/entropy                              -5.80204
trainer/qf_loss                              24.1926
trainer/policy_loss                        -349.121
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.46
trainer/entropy_penalty                      -0.339442
trainer/entropy_percentage                   -0.000971334
trainer/Q1Pred Mean                         349.154
trainer/Q1Pred Std                           57.9594
trainer/Q1Pred Max                          423.166
trainer/Q1Pred Min                           41.5402
trainer/Q2Pred Mean                         349.059
trainer/Q2Pred Std                           57.8058
trainer/Q2Pred Max                          422.68
trainer/Q2Pred Min                           32.7703
trainer/QTargetWithReg Mean                 349.577
trainer/QTargetWithReg Std                   58.1478
trainer/QTargetWithReg Max                  422.368
trainer/QTargetWithReg Min                   46.3306
trainer/PolicyLossWithoutReg Mean           349.46
trainer/PolicyLossWithoutReg Std             57.0622
trainer/PolicyLossWithoutReg Max            421.369
trainer/PolicyLossWithoutReg Min             33.5159
exploration/num steps total              850000
exploration/num paths total                1641
exploration/path length this epoch Mean     425
exploration/path length this epoch Std        0
exploration/path length this epoch Max      425
exploration/path length this epoch Min      425
exploration/Rewards Mean                      4.1911
exploration/Rewards Std                       1.25194
exploration/Rewards Max                       6.23095
exploration/Rewards Min                      -0.838983
exploration/Returns Mean                   1781.22
exploration/Returns Std                       0
exploration/Returns Max                    1781.22
exploration/Returns Min                    1781.22
exploration/Num Paths                         1
exploration/Average Returns                1781.22
evaluation_0/num steps total                  6.62285e+06
evaluation_0/num paths total              10259
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95374
evaluation_0/Rewards Std                      1.10635
evaluation_0/Rewards Max                      7.68262
evaluation_0/Rewards Min                     -0.690434
evaluation_0/Returns Mean                  4953.74
evaluation_0/Returns Std                     64.6606
evaluation_0/Returns Max                   5092.8
evaluation_0/Returns Min                   4862.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4953.74
time/epoch (s)                                0
time/total (s)                            12803.4
Epoch                                       845
---------------------------------------  ----------------
2022-11-16 19:48:23.382820 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 846 finished
---------------------------------------  ----------------
epoch                                       846
total_step                               851000
replay_pool/size                         851000
trainer/alpha                                 0.0595556
trainer/alpha_loss                           -0.682453
trainer/entropy                              -5.75807
trainer/qf_loss                              47.5346
trainer/policy_loss                        -350.691
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.033
trainer/entropy_penalty                      -0.342925
trainer/entropy_percentage                   -0.000976902
trainer/Q1Pred Mean                         350.07
trainer/Q1Pred Std                           65.3332
trainer/Q1Pred Max                          421.639
trainer/Q1Pred Min                           12.9691
trainer/Q2Pred Mean                         350.753
trainer/Q2Pred Std                           65.9077
trainer/Q2Pred Max                          426.419
trainer/Q2Pred Min                            9.36947
trainer/QTargetWithReg Mean                 350.981
trainer/QTargetWithReg Std                   64.8044
trainer/QTargetWithReg Max                  423.284
trainer/QTargetWithReg Min                   14.3838
trainer/PolicyLossWithoutReg Mean           351.033
trainer/PolicyLossWithoutReg Std             65.2655
trainer/PolicyLossWithoutReg Max            422.214
trainer/PolicyLossWithoutReg Min             14.1708
exploration/num steps total              851000
exploration/num paths total                1642
exploration/path length this epoch Mean     245
exploration/path length this epoch Std        0
exploration/path length this epoch Max      245
exploration/path length this epoch Min      245
exploration/Rewards Mean                      3.17872
exploration/Rewards Std                       1.18476
exploration/Rewards Max                       5.44872
exploration/Rewards Min                      -0.653272
exploration/Returns Mean                    778.787
exploration/Returns Std                       0
exploration/Returns Max                     778.787
exploration/Returns Min                     778.787
exploration/Num Paths                         1
exploration/Average Returns                 778.787
evaluation_0/num steps total                  6.63004e+06
evaluation_0/num paths total              10268
evaluation_0/path length Mean               799.111
evaluation_0/path length Std                375.829
evaluation_0/path length Max               1000
evaluation_0/path length Min                 95
evaluation_0/Rewards Mean                     4.89391
evaluation_0/Rewards Std                      1.18469
evaluation_0/Rewards Max                      7.54668
evaluation_0/Rewards Min                     -0.909331
evaluation_0/Returns Mean                  3910.77
evaluation_0/Returns Std                   1951.06
evaluation_0/Returns Max                   5070.59
evaluation_0/Returns Min                    263.422
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3910.77
time/epoch (s)                                0
time/total (s)                            12820.3
Epoch                                       846
---------------------------------------  ----------------
2022-11-16 19:48:40.173041 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 847 finished
---------------------------------------  ----------------
epoch                                       847
total_step                               852000
replay_pool/size                         852000
trainer/alpha                                 0.0587911
trainer/alpha_loss                            2.19296
trainer/entropy                              -6.77378
trainer/qf_loss                              26.9478
trainer/policy_loss                        -344.797
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         345.195
trainer/entropy_penalty                      -0.398238
trainer/entropy_percentage                   -0.00115366
trainer/Q1Pred Mean                         345.27
trainer/Q1Pred Std                           76.5471
trainer/Q1Pred Max                          428.35
trainer/Q1Pred Min                           -4.27731
trainer/Q2Pred Mean                         345.216
trainer/Q2Pred Std                           75.7262
trainer/Q2Pred Max                          429.334
trainer/Q2Pred Min                            8.80552
trainer/QTargetWithReg Mean                 343.456
trainer/QTargetWithReg Std                   76.1814
trainer/QTargetWithReg Max                  428.927
trainer/QTargetWithReg Min                    3.93188
trainer/PolicyLossWithoutReg Mean           345.195
trainer/PolicyLossWithoutReg Std             74.9004
trainer/PolicyLossWithoutReg Max            426.956
trainer/PolicyLossWithoutReg Min              5.52684
exploration/num steps total              852000
exploration/num paths total                1643
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97724
exploration/Rewards Std                       1.01475
exploration/Rewards Max                       7.50344
exploration/Rewards Min                      -0.810525
exploration/Returns Mean                   4977.24
exploration/Returns Std                       0
exploration/Returns Max                    4977.24
exploration/Returns Min                    4977.24
exploration/Num Paths                         1
exploration/Average Returns                4977.24
evaluation_0/num steps total                  6.63801e+06
evaluation_0/num paths total              10276
evaluation_0/path length Mean               996.375
evaluation_0/path length Std                  9.59085
evaluation_0/path length Max               1000
evaluation_0/path length Min                971
evaluation_0/Rewards Mean                     4.93745
evaluation_0/Rewards Std                      1.08571
evaluation_0/Rewards Max                      8.72539
evaluation_0/Rewards Min                     -0.850942
evaluation_0/Returns Mean                  4919.56
evaluation_0/Returns Std                     63.5066
evaluation_0/Returns Max                   4969.97
evaluation_0/Returns Min                   4780.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4919.56
time/epoch (s)                                0
time/total (s)                            12837.1
Epoch                                       847
---------------------------------------  ----------------
2022-11-16 19:48:54.721438 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 848 finished
---------------------------------------  ----------------
epoch                                       848
total_step                               853000
replay_pool/size                         853000
trainer/alpha                                 0.059448
trainer/alpha_loss                           -0.169183
trainer/entropy                              -5.94006
trainer/qf_loss                              21.3428
trainer/policy_loss                        -351.953
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.306
trainer/entropy_penalty                      -0.353125
trainer/entropy_percentage                   -0.00100232
trainer/Q1Pred Mean                         351.249
trainer/Q1Pred Std                           66.8715
trainer/Q1Pred Max                          431.116
trainer/Q1Pred Min                           11.5031
trainer/Q2Pred Mean                         351.431
trainer/Q2Pred Std                           66.4931
trainer/Q2Pred Max                          431.226
trainer/Q2Pred Min                           10.0298
trainer/QTargetWithReg Mean                 351.555
trainer/QTargetWithReg Std                   67.3029
trainer/QTargetWithReg Max                  432.543
trainer/QTargetWithReg Min                    1.00515
trainer/PolicyLossWithoutReg Mean           352.306
trainer/PolicyLossWithoutReg Std             66.2764
trainer/PolicyLossWithoutReg Max            432.508
trainer/PolicyLossWithoutReg Min              5.76942
exploration/num steps total              853000
exploration/num paths total                1644
exploration/path length this epoch Mean     369
exploration/path length this epoch Std        0
exploration/path length this epoch Max      369
exploration/path length this epoch Min      369
exploration/Rewards Mean                      4.30976
exploration/Rewards Std                       1.30088
exploration/Rewards Max                       6.66997
exploration/Rewards Min                      -0.726651
exploration/Returns Mean                   1590.3
exploration/Returns Std                       0
exploration/Returns Max                    1590.3
exploration/Returns Min                    1590.3
exploration/Num Paths                         1
exploration/Average Returns                1590.3
evaluation_0/num steps total                  6.64601e+06
evaluation_0/num paths total              10284
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74617
evaluation_0/Rewards Std                      1.04236
evaluation_0/Rewards Max                      7.68148
evaluation_0/Rewards Min                     -0.728209
evaluation_0/Returns Mean                  4746.17
evaluation_0/Returns Std                     35.4461
evaluation_0/Returns Max                   4795.89
evaluation_0/Returns Min                   4689.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4746.17
time/epoch (s)                                0
time/total (s)                            12851.6
Epoch                                       848
---------------------------------------  ----------------
2022-11-16 19:49:11.276274 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 849 finished
---------------------------------------  ----------------
epoch                                       849
total_step                               854000
replay_pool/size                         854000
trainer/alpha                                 0.0581917
trainer/alpha_loss                           -0.694845
trainer/entropy                              -5.75568
trainer/qf_loss                              32.193
trainer/policy_loss                        -354.845
trainer/adversary_policy_loss                17.0957
trainer/policy_loss_without_entropy         355.18
trainer/entropy_penalty                      -0.334933
trainer/entropy_percentage                   -0.000942993
trainer/Q1Pred Mean                         354.205
trainer/Q1Pred Std                           57.3306
trainer/Q1Pred Max                          427.631
trainer/Q1Pred Min                           22.2383
trainer/Q2Pred Mean                         353.938
trainer/Q2Pred Std                           56.6336
trainer/Q2Pred Max                          426.635
trainer/Q2Pred Min                           32.0701
trainer/QTargetWithReg Mean                 354.32
trainer/QTargetWithReg Std                   56.7648
trainer/QTargetWithReg Max                  424.048
trainer/QTargetWithReg Min                   26.8194
trainer/PolicyLossWithoutReg Mean           355.18
trainer/PolicyLossWithoutReg Std             56.2324
trainer/PolicyLossWithoutReg Max            424.236
trainer/PolicyLossWithoutReg Min             15.5282
exploration/num steps total              854000
exploration/num paths total                1645
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5976
exploration/Rewards Std                       1.07977
exploration/Rewards Max                       6.98461
exploration/Rewards Min                      -0.666033
exploration/Returns Mean                   4597.6
exploration/Returns Std                       0
exploration/Returns Max                    4597.6
exploration/Returns Min                    4597.6
exploration/Num Paths                         1
exploration/Average Returns                4597.6
evaluation_0/num steps total                  6.65332e+06
evaluation_0/num paths total              10292
evaluation_0/path length Mean               913.125
evaluation_0/path length Std                229.85
evaluation_0/path length Max               1000
evaluation_0/path length Min                305
evaluation_0/Rewards Mean                     4.76689
evaluation_0/Rewards Std                      1.08322
evaluation_0/Rewards Max                      7.59354
evaluation_0/Rewards Min                     -0.866077
evaluation_0/Returns Mean                  4352.76
evaluation_0/Returns Std                   1232.56
evaluation_0/Returns Max                   4947.88
evaluation_0/Returns Min                   1101.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4352.76
time/epoch (s)                                0
time/total (s)                            12868.2
Epoch                                       849
---------------------------------------  ----------------
2022-11-16 19:49:27.764427 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 850 finished
---------------------------------------  ----------------
epoch                                       850
total_step                               855000
replay_pool/size                         855000
trainer/alpha                                 0.0602272
trainer/alpha_loss                            2.36006
trainer/entropy                              -6.83991
trainer/qf_loss                              29.3124
trainer/policy_loss                        -341.868
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.28
trainer/entropy_penalty                      -0.411948
trainer/entropy_percentage                   -0.00120354
trainer/Q1Pred Mean                         340.279
trainer/Q1Pred Std                           72.7381
trainer/Q1Pred Max                          425.976
trainer/Q1Pred Min                          -23.9506
trainer/Q2Pred Mean                         341.325
trainer/Q2Pred Std                           72.1853
trainer/Q2Pred Max                          431.305
trainer/Q2Pred Min                            2.66365
trainer/QTargetWithReg Mean                 341.543
trainer/QTargetWithReg Std                   71.6676
trainer/QTargetWithReg Max                  426.599
trainer/QTargetWithReg Min                    0.198768
trainer/PolicyLossWithoutReg Mean           342.28
trainer/PolicyLossWithoutReg Std             70.3853
trainer/PolicyLossWithoutReg Max            426.114
trainer/PolicyLossWithoutReg Min             28.3932
exploration/num steps total              855000
exploration/num paths total                1646
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7474
exploration/Rewards Std                       1.02575
exploration/Rewards Max                       7.21496
exploration/Rewards Min                      -0.62617
exploration/Returns Mean                   4747.4
exploration/Returns Std                       0
exploration/Returns Max                    4747.4
exploration/Returns Min                    4747.4
exploration/Num Paths                         1
exploration/Average Returns                4747.4
evaluation_0/num steps total                  6.66084e+06
evaluation_0/num paths total              10300
evaluation_0/path length Mean               940.125
evaluation_0/path length Std                158.414
evaluation_0/path length Max               1000
evaluation_0/path length Min                521
evaluation_0/Rewards Mean                     4.75559
evaluation_0/Rewards Std                      1.05003
evaluation_0/Rewards Max                      7.52728
evaluation_0/Rewards Min                     -0.61547
evaluation_0/Returns Mean                  4470.85
evaluation_0/Returns Std                    819.703
evaluation_0/Returns Max                   4853.29
evaluation_0/Returns Min                   2306.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4470.85
time/epoch (s)                                0
time/total (s)                            12884.6
Epoch                                       850
---------------------------------------  ----------------
2022-11-16 19:49:42.491738 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 851 finished
---------------------------------------  ----------------
epoch                                       851
total_step                               856000
replay_pool/size                         856000
trainer/alpha                                 0.0599299
trainer/alpha_loss                            2.86863
trainer/entropy                              -7.01911
trainer/qf_loss                              22.9442
trainer/policy_loss                        -347.203
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.623
trainer/entropy_penalty                      -0.420654
trainer/entropy_percentage                   -0.00121009
trainer/Q1Pred Mean                         346.199
trainer/Q1Pred Std                           70.0427
trainer/Q1Pred Max                          424.926
trainer/Q1Pred Min                           -6.03068
trainer/Q2Pred Mean                         346.645
trainer/Q2Pred Std                           69.9899
trainer/Q2Pred Max                          425.092
trainer/Q2Pred Min                           -0.636688
trainer/QTargetWithReg Mean                 347.28
trainer/QTargetWithReg Std                   70.2359
trainer/QTargetWithReg Max                  425.318
trainer/QTargetWithReg Min                   -0.176632
trainer/PolicyLossWithoutReg Mean           347.623
trainer/PolicyLossWithoutReg Std             68.8559
trainer/PolicyLossWithoutReg Max            424.419
trainer/PolicyLossWithoutReg Min              7.65038
exploration/num steps total              856000
exploration/num paths total                1647
exploration/path length this epoch Mean     270
exploration/path length this epoch Std        0
exploration/path length this epoch Max      270
exploration/path length this epoch Min      270
exploration/Rewards Mean                      3.77073
exploration/Rewards Std                       1.47322
exploration/Rewards Max                       6.26558
exploration/Rewards Min                      -0.33571
exploration/Returns Mean                   1018.1
exploration/Returns Std                       0
exploration/Returns Max                    1018.1
exploration/Returns Min                    1018.1
exploration/Num Paths                         1
exploration/Average Returns                1018.1
evaluation_0/num steps total                  6.66884e+06
evaluation_0/num paths total              10308
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83797
evaluation_0/Rewards Std                      1.0116
evaluation_0/Rewards Max                      7.33329
evaluation_0/Rewards Min                     -0.946564
evaluation_0/Returns Mean                  4837.97
evaluation_0/Returns Std                     33.2798
evaluation_0/Returns Max                   4883.33
evaluation_0/Returns Min                   4777.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4837.97
time/epoch (s)                                0
time/total (s)                            12899.4
Epoch                                       851
---------------------------------------  ----------------
2022-11-16 19:49:57.538438 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 852 finished
---------------------------------------  ----------------
epoch                                       852
total_step                               857000
replay_pool/size                         857000
trainer/alpha                                 0.0589876
trainer/alpha_loss                           -1.90708
trainer/entropy                              -5.32621
trainer/qf_loss                              19.3519
trainer/policy_loss                        -349.333
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.648
trainer/entropy_penalty                      -0.31418
trainer/entropy_percentage                   -0.000898563
trainer/Q1Pred Mean                         348.495
trainer/Q1Pred Std                           67.1224
trainer/Q1Pred Max                          426.845
trainer/Q1Pred Min                          -13.7228
trainer/Q2Pred Mean                         348.551
trainer/Q2Pred Std                           66.9901
trainer/Q2Pred Max                          427.219
trainer/Q2Pred Min                            5.15144
trainer/QTargetWithReg Mean                 349.869
trainer/QTargetWithReg Std                   66.8635
trainer/QTargetWithReg Max                  427.945
trainer/QTargetWithReg Min                   -0.604962
trainer/PolicyLossWithoutReg Mean           349.647
trainer/PolicyLossWithoutReg Std             64.4035
trainer/PolicyLossWithoutReg Max            427.592
trainer/PolicyLossWithoutReg Min              7.92978
exploration/num steps total              857000
exploration/num paths total                1648
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61556
exploration/Rewards Std                       1.05701
exploration/Rewards Max                       7.84832
exploration/Rewards Min                      -0.908761
exploration/Returns Mean                   4615.56
exploration/Returns Std                       0
exploration/Returns Max                    4615.56
exploration/Returns Min                    4615.56
exploration/Num Paths                         1
exploration/Average Returns                4615.56
evaluation_0/num steps total                  6.67684e+06
evaluation_0/num paths total              10316
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84632
evaluation_0/Rewards Std                      1.04341
evaluation_0/Rewards Max                      7.54124
evaluation_0/Rewards Min                     -0.59231
evaluation_0/Returns Mean                  4846.32
evaluation_0/Returns Std                     41.8994
evaluation_0/Returns Max                   4923.77
evaluation_0/Returns Min                   4763.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4846.32
time/epoch (s)                                0
time/total (s)                            12914.4
Epoch                                       852
---------------------------------------  ----------------
2022-11-16 19:50:12.214951 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 853 finished
---------------------------------------  ----------------
epoch                                       853
total_step                               858000
replay_pool/size                         858000
trainer/alpha                                 0.0582758
trainer/alpha_loss                            0.0105164
trainer/entropy                              -6.0037
trainer/qf_loss                              21.9731
trainer/policy_loss                        -342.13
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         342.48
trainer/entropy_penalty                      -0.349871
trainer/entropy_percentage                   -0.00102158
trainer/Q1Pred Mean                         341.388
trainer/Q1Pred Std                           79.0139
trainer/Q1Pred Max                          425.372
trainer/Q1Pred Min                          -16.2641
trainer/Q2Pred Mean                         341.118
trainer/Q2Pred Std                           77.9853
trainer/Q2Pred Max                          422.95
trainer/Q2Pred Min                           -0.0107901
trainer/QTargetWithReg Mean                 341.888
trainer/QTargetWithReg Std                   78.4201
trainer/QTargetWithReg Max                  427.29
trainer/QTargetWithReg Min                   -6.22903
trainer/PolicyLossWithoutReg Mean           342.48
trainer/PolicyLossWithoutReg Std             77.3976
trainer/PolicyLossWithoutReg Max            424.575
trainer/PolicyLossWithoutReg Min             -5.59675
exploration/num steps total              858000
exploration/num paths total                1652
exploration/path length this epoch Mean     241.75
exploration/path length this epoch Std      248.466
exploration/path length this epoch Max      663
exploration/path length this epoch Min       44
exploration/Rewards Mean                      3.87821
exploration/Rewards Std                       1.52109
exploration/Rewards Max                       6.99146
exploration/Rewards Min                      -0.571724
exploration/Returns Mean                    937.557
exploration/Returns Std                    1141.63
exploration/Returns Max                    2889.69
exploration/Returns Min                      62.9642
exploration/Num Paths                         4
exploration/Average Returns                 937.557
evaluation_0/num steps total                  6.68484e+06
evaluation_0/num paths total              10324
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68628
evaluation_0/Rewards Std                      1.0633
evaluation_0/Rewards Max                      7.48036
evaluation_0/Rewards Min                     -0.592097
evaluation_0/Returns Mean                  4686.28
evaluation_0/Returns Std                    106.509
evaluation_0/Returns Max                   4833.91
evaluation_0/Returns Min                   4477.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4686.28
time/epoch (s)                                0
time/total (s)                            12929.1
Epoch                                       853
---------------------------------------  ----------------
2022-11-16 19:50:27.094225 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 854 finished
---------------------------------------  ----------------
epoch                                       854
total_step                               859000
replay_pool/size                         859000
trainer/alpha                                 0.0592398
trainer/alpha_loss                            1.15822
trainer/entropy                              -6.4098
trainer/qf_loss                              27.4766
trainer/policy_loss                        -346.675
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.054
trainer/entropy_penalty                      -0.379715
trainer/entropy_percentage                   -0.00109411
trainer/Q1Pred Mean                         346.04
trainer/Q1Pred Std                           69.414
trainer/Q1Pred Max                          434.697
trainer/Q1Pred Min                           26.984
trainer/Q2Pred Mean                         346.404
trainer/Q2Pred Std                           70.1404
trainer/Q2Pred Max                          434.069
trainer/Q2Pred Min                           17.4306
trainer/QTargetWithReg Mean                 346.507
trainer/QTargetWithReg Std                   70.1491
trainer/QTargetWithReg Max                  434.785
trainer/QTargetWithReg Min                   26.0802
trainer/PolicyLossWithoutReg Mean           347.054
trainer/PolicyLossWithoutReg Std             69.2922
trainer/PolicyLossWithoutReg Max            434.239
trainer/PolicyLossWithoutReg Min             20.6228
exploration/num steps total              859000
exploration/num paths total                1653
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53588
exploration/Rewards Std                       0.991823
exploration/Rewards Max                       6.76392
exploration/Rewards Min                      -0.415535
exploration/Returns Mean                   4535.88
exploration/Returns Std                       0
exploration/Returns Max                    4535.88
exploration/Returns Min                    4535.88
exploration/Num Paths                         1
exploration/Average Returns                4535.88
evaluation_0/num steps total                  6.69284e+06
evaluation_0/num paths total              10332
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83699
evaluation_0/Rewards Std                      1.02498
evaluation_0/Rewards Max                      7.32918
evaluation_0/Rewards Min                     -0.789085
evaluation_0/Returns Mean                  4836.99
evaluation_0/Returns Std                     98.1213
evaluation_0/Returns Max                   4956.44
evaluation_0/Returns Min                   4642.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.99
time/epoch (s)                                0
time/total (s)                            12944
Epoch                                       854
---------------------------------------  ----------------
2022-11-16 19:50:42.044626 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 855 finished
---------------------------------------  ----------------
epoch                                       855
total_step                               860000
replay_pool/size                         860000
trainer/alpha                                 0.059366
trainer/alpha_loss                            0.241678
trainer/entropy                              -6.08558
trainer/qf_loss                              25.8153
trainer/policy_loss                        -346.321
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.682
trainer/entropy_penalty                      -0.361276
trainer/entropy_percentage                   -0.0010421
trainer/Q1Pred Mean                         344.763
trainer/Q1Pred Std                           76.2354
trainer/Q1Pred Max                          431.072
trainer/Q1Pred Min                            9.54914
trainer/Q2Pred Mean                         344.642
trainer/Q2Pred Std                           74.9355
trainer/Q2Pred Max                          429.077
trainer/Q2Pred Min                           10.8374
trainer/QTargetWithReg Mean                 344.232
trainer/QTargetWithReg Std                   74.8912
trainer/QTargetWithReg Max                  428.768
trainer/QTargetWithReg Min                   12.0138
trainer/PolicyLossWithoutReg Mean           346.682
trainer/PolicyLossWithoutReg Std             71.4057
trainer/PolicyLossWithoutReg Max            429.49
trainer/PolicyLossWithoutReg Min              9.61277
exploration/num steps total              860000
exploration/num paths total                1654
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67688
exploration/Rewards Std                       1.02548
exploration/Rewards Max                       7.20115
exploration/Rewards Min                      -0.75654
exploration/Returns Mean                   4676.88
exploration/Returns Std                       0
exploration/Returns Max                    4676.88
exploration/Returns Min                    4676.88
exploration/Num Paths                         1
exploration/Average Returns                4676.88
evaluation_0/num steps total                  6.70084e+06
evaluation_0/num paths total              10340
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79369
evaluation_0/Rewards Std                      0.988692
evaluation_0/Rewards Max                      7.52557
evaluation_0/Rewards Min                     -0.794725
evaluation_0/Returns Mean                  4793.69
evaluation_0/Returns Std                     42.1325
evaluation_0/Returns Max                   4863.86
evaluation_0/Returns Min                   4744.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4793.69
time/epoch (s)                                0
time/total (s)                            12958.9
Epoch                                       855
---------------------------------------  ----------------
2022-11-16 19:50:56.968260 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 856 finished
---------------------------------------  ----------------
epoch                                       856
total_step                               861000
replay_pool/size                         861000
trainer/alpha                                 0.0607299
trainer/alpha_loss                           -0.242881
trainer/entropy                              -5.9133
trainer/qf_loss                              24.2263
trainer/policy_loss                        -348.805
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.164
trainer/entropy_penalty                      -0.359114
trainer/entropy_percentage                   -0.00102849
trainer/Q1Pred Mean                         348.743
trainer/Q1Pred Std                           58.9167
trainer/Q1Pred Max                          422.812
trainer/Q1Pred Min                           73.0302
trainer/Q2Pred Mean                         348.935
trainer/Q2Pred Std                           59.029
trainer/Q2Pred Max                          423.862
trainer/Q2Pred Min                           66.2505
trainer/QTargetWithReg Mean                 348.806
trainer/QTargetWithReg Std                   59.8551
trainer/QTargetWithReg Max                  426.037
trainer/QTargetWithReg Min                   52.7274
trainer/PolicyLossWithoutReg Mean           349.164
trainer/PolicyLossWithoutReg Std             57.8833
trainer/PolicyLossWithoutReg Max            423.532
trainer/PolicyLossWithoutReg Min             80.2846
exploration/num steps total              861000
exploration/num paths total                1655
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72112
exploration/Rewards Std                       1.01256
exploration/Rewards Max                       7.08006
exploration/Rewards Min                      -0.67797
exploration/Returns Mean                   4721.12
exploration/Returns Std                       0
exploration/Returns Max                    4721.12
exploration/Returns Min                    4721.12
exploration/Num Paths                         1
exploration/Average Returns                4721.12
evaluation_0/num steps total                  6.70884e+06
evaluation_0/num paths total              10348
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83985
evaluation_0/Rewards Std                      1.03242
evaluation_0/Rewards Max                      7.57624
evaluation_0/Rewards Min                     -0.525932
evaluation_0/Returns Mean                  4839.85
evaluation_0/Returns Std                     57.6475
evaluation_0/Returns Max                   4908.46
evaluation_0/Returns Min                   4738.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4839.85
time/epoch (s)                                0
time/total (s)                            12973.8
Epoch                                       856
---------------------------------------  ----------------
2022-11-16 19:51:11.994683 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 857 finished
---------------------------------------  ----------------
epoch                                       857
total_step                               862000
replay_pool/size                         862000
trainer/alpha                                 0.0598707
trainer/alpha_loss                           -0.0969918
trainer/entropy                              -5.96555
trainer/qf_loss                              25.0829
trainer/policy_loss                        -349.156
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.514
trainer/entropy_penalty                      -0.357162
trainer/entropy_percentage                   -0.00102188
trainer/Q1Pred Mean                         349.131
trainer/Q1Pred Std                           74.4296
trainer/Q1Pred Max                          429.849
trainer/Q1Pred Min                            1.29771
trainer/Q2Pred Mean                         348.574
trainer/Q2Pred Std                           74.6449
trainer/Q2Pred Max                          431.256
trainer/Q2Pred Min                           -5.95593
trainer/QTargetWithReg Mean                 348.379
trainer/QTargetWithReg Std                   74.8738
trainer/QTargetWithReg Max                  430.014
trainer/QTargetWithReg Min                   -4.92604
trainer/PolicyLossWithoutReg Mean           349.514
trainer/PolicyLossWithoutReg Std             73.4748
trainer/PolicyLossWithoutReg Max            428.142
trainer/PolicyLossWithoutReg Min              1.67326
exploration/num steps total              862000
exploration/num paths total                1656
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77042
exploration/Rewards Std                       1.06025
exploration/Rewards Max                       7.0194
exploration/Rewards Min                      -0.485551
exploration/Returns Mean                   4770.42
exploration/Returns Std                       0
exploration/Returns Max                    4770.42
exploration/Returns Min                    4770.42
exploration/Num Paths                         1
exploration/Average Returns                4770.42
evaluation_0/num steps total                  6.71684e+06
evaluation_0/num paths total              10356
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75609
evaluation_0/Rewards Std                      1.03232
evaluation_0/Rewards Max                      7.28917
evaluation_0/Rewards Min                     -0.641984
evaluation_0/Returns Mean                  4756.09
evaluation_0/Returns Std                     51.0797
evaluation_0/Returns Max                   4842.26
evaluation_0/Returns Min                   4657.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4756.09
time/epoch (s)                                0
time/total (s)                            12988.9
Epoch                                       857
---------------------------------------  ----------------
2022-11-16 19:51:28.623077 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 858 finished
---------------------------------------  ----------------
epoch                                       858
total_step                               863000
replay_pool/size                         863000
trainer/alpha                                 0.0612254
trainer/alpha_loss                            0.142183
trainer/entropy                              -6.0509
trainer/qf_loss                              32.5685
trainer/policy_loss                        -352.431
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.801
trainer/entropy_penalty                      -0.370469
trainer/entropy_percentage                   -0.00105008
trainer/Q1Pred Mean                         352.223
trainer/Q1Pred Std                           61.9625
trainer/Q1Pred Max                          436.016
trainer/Q1Pred Min                           -0.178992
trainer/Q2Pred Mean                         352.304
trainer/Q2Pred Std                           61.1817
trainer/Q2Pred Max                          434.249
trainer/Q2Pred Min                           18.873
trainer/QTargetWithReg Mean                 351.334
trainer/QTargetWithReg Std                   60.7751
trainer/QTargetWithReg Max                  435.792
trainer/QTargetWithReg Min                    0.126535
trainer/PolicyLossWithoutReg Mean           352.801
trainer/PolicyLossWithoutReg Std             59.2167
trainer/PolicyLossWithoutReg Max            433.485
trainer/PolicyLossWithoutReg Min              3.87366
exploration/num steps total              863000
exploration/num paths total                1657
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60095
exploration/Rewards Std                       1.07645
exploration/Rewards Max                       6.96064
exploration/Rewards Min                      -0.607016
exploration/Returns Mean                   4600.95
exploration/Returns Std                       0
exploration/Returns Max                    4600.95
exploration/Returns Min                    4600.95
exploration/Num Paths                         1
exploration/Average Returns                4600.95
evaluation_0/num steps total                  6.72425e+06
evaluation_0/num paths total              10364
evaluation_0/path length Mean               927.125
evaluation_0/path length Std                192.809
evaluation_0/path length Max               1000
evaluation_0/path length Min                417
evaluation_0/Rewards Mean                     4.77049
evaluation_0/Rewards Std                      1.11084
evaluation_0/Rewards Max                      7.62496
evaluation_0/Rewards Min                     -0.636655
evaluation_0/Returns Mean                  4422.84
evaluation_0/Returns Std                   1054.5
evaluation_0/Returns Max                   4967.44
evaluation_0/Returns Min                   1641.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4422.84
time/epoch (s)                                0
time/total (s)                            13005.5
Epoch                                       858
---------------------------------------  ----------------
2022-11-16 19:51:43.840688 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 859 finished
---------------------------------------  ----------------
epoch                                       859
total_step                               864000
replay_pool/size                         864000
trainer/alpha                                 0.0599688
trainer/alpha_loss                           -0.761662
trainer/entropy                              -5.72932
trainer/qf_loss                              21.3422
trainer/policy_loss                        -353.517
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.861
trainer/entropy_penalty                      -0.34358
trainer/entropy_percentage                   -0.000970947
trainer/Q1Pred Mean                         354.369
trainer/Q1Pred Std                           62.6269
trainer/Q1Pred Max                          440.018
trainer/Q1Pred Min                           11.894
trainer/Q2Pred Mean                         353.29
trainer/Q2Pred Std                           62.9637
trainer/Q2Pred Max                          438.831
trainer/Q2Pred Min                           12.6929
trainer/QTargetWithReg Mean                 353.553
trainer/QTargetWithReg Std                   62.5966
trainer/QTargetWithReg Max                  438.873
trainer/QTargetWithReg Min                   13.1681
trainer/PolicyLossWithoutReg Mean           353.861
trainer/PolicyLossWithoutReg Std             62.7854
trainer/PolicyLossWithoutReg Max            438.788
trainer/PolicyLossWithoutReg Min              9.97841
exploration/num steps total              864000
exploration/num paths total                1658
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68645
exploration/Rewards Std                       1.30122
exploration/Rewards Max                       7.10918
exploration/Rewards Min                      -0.544661
exploration/Returns Mean                   4686.45
exploration/Returns Std                       0
exploration/Returns Max                    4686.45
exploration/Returns Min                    4686.45
exploration/Num Paths                         1
exploration/Average Returns                4686.45
evaluation_0/num steps total                  6.73225e+06
evaluation_0/num paths total              10372
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77595
evaluation_0/Rewards Std                      1.02596
evaluation_0/Rewards Max                      7.52591
evaluation_0/Rewards Min                     -0.70133
evaluation_0/Returns Mean                  4775.95
evaluation_0/Returns Std                     43.8049
evaluation_0/Returns Max                   4855.29
evaluation_0/Returns Min                   4713.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4775.95
time/epoch (s)                                0
time/total (s)                            13020.7
Epoch                                       859
---------------------------------------  ----------------
2022-11-16 19:51:58.775272 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 860 finished
---------------------------------------  ----------------
epoch                                       860
total_step                               865000
replay_pool/size                         865000
trainer/alpha                                 0.0600843
trainer/alpha_loss                           -2.23105
trainer/entropy                              -5.20654
trainer/qf_loss                              18.1072
trainer/policy_loss                        -352.086
trainer/adversary_policy_loss                16.7853
trainer/policy_loss_without_entropy         352.398
trainer/entropy_penalty                      -0.312831
trainer/entropy_percentage                   -0.00088772
trainer/Q1Pred Mean                         351.806
trainer/Q1Pred Std                           64.0782
trainer/Q1Pred Max                          430.637
trainer/Q1Pred Min                           33.4531
trainer/Q2Pred Mean                         351.241
trainer/Q2Pred Std                           65.035
trainer/Q2Pred Max                          432.287
trainer/Q2Pred Min                           28.7248
trainer/QTargetWithReg Mean                 351.639
trainer/QTargetWithReg Std                   64.2082
trainer/QTargetWithReg Max                  431.312
trainer/QTargetWithReg Min                   31.6493
trainer/PolicyLossWithoutReg Mean           352.399
trainer/PolicyLossWithoutReg Std             64.1758
trainer/PolicyLossWithoutReg Max            430.89
trainer/PolicyLossWithoutReg Min             32.1757
exploration/num steps total              865000
exploration/num paths total                1659
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5218
exploration/Rewards Std                       1.0613
exploration/Rewards Max                       7.21805
exploration/Rewards Min                      -0.717529
exploration/Returns Mean                   4521.8
exploration/Returns Std                       0
exploration/Returns Max                    4521.8
exploration/Returns Min                    4521.8
exploration/Num Paths                         1
exploration/Average Returns                4521.8
evaluation_0/num steps total                  6.74025e+06
evaluation_0/num paths total              10380
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70871
evaluation_0/Rewards Std                      1.04164
evaluation_0/Rewards Max                      7.56675
evaluation_0/Rewards Min                     -0.634573
evaluation_0/Returns Mean                  4708.71
evaluation_0/Returns Std                     64.1667
evaluation_0/Returns Max                   4793.24
evaluation_0/Returns Min                   4608.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4708.71
time/epoch (s)                                0
time/total (s)                            13035.6
Epoch                                       860
---------------------------------------  ----------------
2022-11-16 19:52:15.438962 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 861 finished
---------------------------------------  ----------------
epoch                                       861
total_step                               866000
replay_pool/size                         866000
trainer/alpha                                 0.060744
trainer/alpha_loss                           -0.199188
trainer/entropy                              -5.92888
trainer/qf_loss                              15.6457
trainer/policy_loss                        -350.375
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.736
trainer/entropy_penalty                      -0.360144
trainer/entropy_percentage                   -0.00102683
trainer/Q1Pred Mean                         349.131
trainer/Q1Pred Std                           67.3631
trainer/Q1Pred Max                          431.017
trainer/Q1Pred Min                           -7.62617
trainer/Q2Pred Mean                         349.397
trainer/Q2Pred Std                           66.5955
trainer/Q2Pred Max                          429.497
trainer/Q2Pred Min                            1.5705
trainer/QTargetWithReg Mean                 349.133
trainer/QTargetWithReg Std                   67.46
trainer/QTargetWithReg Max                  429.709
trainer/QTargetWithReg Min                   -0.737634
trainer/PolicyLossWithoutReg Mean           350.736
trainer/PolicyLossWithoutReg Std             61.4234
trainer/PolicyLossWithoutReg Max            429.544
trainer/PolicyLossWithoutReg Min             42.8069
exploration/num steps total              866000
exploration/num paths total                1660
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64383
exploration/Rewards Std                       1.08582
exploration/Rewards Max                       6.91234
exploration/Rewards Min                      -0.382644
exploration/Returns Mean                   4643.83
exploration/Returns Std                       0
exploration/Returns Max                    4643.83
exploration/Returns Min                    4643.83
exploration/Num Paths                         1
exploration/Average Returns                4643.83
evaluation_0/num steps total                  6.74734e+06
evaluation_0/num paths total              10388
evaluation_0/path length Mean               885.875
evaluation_0/path length Std                301.946
evaluation_0/path length Max               1000
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     4.85312
evaluation_0/Rewards Std                      1.11635
evaluation_0/Rewards Max                      8.08942
evaluation_0/Rewards Min                     -0.646229
evaluation_0/Returns Mean                  4299.26
evaluation_0/Returns Std                   1537.88
evaluation_0/Returns Max                   4977.89
evaluation_0/Returns Min                    236.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4299.26
time/epoch (s)                                0
time/total (s)                            13052.3
Epoch                                       861
---------------------------------------  ----------------
2022-11-16 19:52:30.299406 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 862 finished
---------------------------------------  ----------------
epoch                                       862
total_step                               867000
replay_pool/size                         867000
trainer/alpha                                 0.0586444
trainer/alpha_loss                           -1.09572
trainer/entropy                              -5.61365
trainer/qf_loss                              14.7138
trainer/policy_loss                        -353.863
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.192
trainer/entropy_penalty                      -0.329209
trainer/entropy_percentage                   -0.000929465
trainer/Q1Pred Mean                         352.415
trainer/Q1Pred Std                           63.2925
trainer/Q1Pred Max                          436.529
trainer/Q1Pred Min                           16.4937
trainer/Q2Pred Mean                         352.831
trainer/Q2Pred Std                           62.8835
trainer/Q2Pred Max                          437.264
trainer/Q2Pred Min                           17.1447
trainer/QTargetWithReg Mean                 352.559
trainer/QTargetWithReg Std                   63.0034
trainer/QTargetWithReg Max                  437.075
trainer/QTargetWithReg Min                   17.4748
trainer/PolicyLossWithoutReg Mean           354.192
trainer/PolicyLossWithoutReg Std             62.2461
trainer/PolicyLossWithoutReg Max            436.691
trainer/PolicyLossWithoutReg Min             14.0552
exploration/num steps total              867000
exploration/num paths total                1662
exploration/path length this epoch Mean     318.5
exploration/path length this epoch Std      234.5
exploration/path length this epoch Max      553
exploration/path length this epoch Min       84
exploration/Rewards Mean                      4.22297
exploration/Rewards Std                       1.38486
exploration/Rewards Max                       6.9754
exploration/Rewards Min                      -0.816611
exploration/Returns Mean                   1345.02
exploration/Returns Std                    1115.23
exploration/Returns Max                    2460.25
exploration/Returns Min                     229.785
exploration/Num Paths                         2
exploration/Average Returns                1345.02
evaluation_0/num steps total                  6.75534e+06
evaluation_0/num paths total              10396
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86105
evaluation_0/Rewards Std                      1.04773
evaluation_0/Rewards Max                      7.28415
evaluation_0/Rewards Min                     -0.617591
evaluation_0/Returns Mean                  4861.05
evaluation_0/Returns Std                     54.9711
evaluation_0/Returns Max                   4988
evaluation_0/Returns Min                   4783.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4861.05
time/epoch (s)                                0
time/total (s)                            13067.2
Epoch                                       862
---------------------------------------  ----------------
2022-11-16 19:52:45.436446 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 863 finished
---------------------------------------  ----------------
epoch                                       863
total_step                               868000
replay_pool/size                         868000
trainer/alpha                                 0.0579996
trainer/alpha_loss                           -2.38599
trainer/entropy                              -5.16197
trainer/qf_loss                              26.3171
trainer/policy_loss                        -356.9
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.199
trainer/entropy_penalty                      -0.299392
trainer/entropy_percentage                   -0.000838166
trainer/Q1Pred Mean                         357.13
trainer/Q1Pred Std                           51.9772
trainer/Q1Pred Max                          431.675
trainer/Q1Pred Min                          158.592
trainer/Q2Pred Mean                         356.325
trainer/Q2Pred Std                           52.3228
trainer/Q2Pred Max                          432.913
trainer/Q2Pred Min                          141.132
trainer/QTargetWithReg Mean                 356.516
trainer/QTargetWithReg Std                   52.7389
trainer/QTargetWithReg Max                  432.769
trainer/QTargetWithReg Min                  139.892
trainer/PolicyLossWithoutReg Mean           357.199
trainer/PolicyLossWithoutReg Std             51.4653
trainer/PolicyLossWithoutReg Max            429.624
trainer/PolicyLossWithoutReg Min            155.848
exploration/num steps total              868000
exploration/num paths total                1663
exploration/path length this epoch Mean     858
exploration/path length this epoch Std        0
exploration/path length this epoch Max      858
exploration/path length this epoch Min      858
exploration/Rewards Mean                      4.57767
exploration/Rewards Std                       1.18567
exploration/Rewards Max                       7.07767
exploration/Rewards Min                      -0.763459
exploration/Returns Mean                   3927.64
exploration/Returns Std                       0
exploration/Returns Max                    3927.64
exploration/Returns Min                    3927.64
exploration/Num Paths                         1
exploration/Average Returns                3927.64
evaluation_0/num steps total                  6.76334e+06
evaluation_0/num paths total              10404
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77563
evaluation_0/Rewards Std                      1.03319
evaluation_0/Rewards Max                      7.68425
evaluation_0/Rewards Min                     -0.595024
evaluation_0/Returns Mean                  4775.63
evaluation_0/Returns Std                     93.2958
evaluation_0/Returns Max                   4906.95
evaluation_0/Returns Min                   4629.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4775.63
time/epoch (s)                                0
time/total (s)                            13082.3
Epoch                                       863
---------------------------------------  ----------------
2022-11-16 19:53:00.566687 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 864 finished
---------------------------------------  ----------------
epoch                                       864
total_step                               869000
replay_pool/size                         869000
trainer/alpha                                 0.0575565
trainer/alpha_loss                           -0.863358
trainer/entropy                              -5.6976
trainer/qf_loss                              27.9843
trainer/policy_loss                        -350.142
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.47
trainer/entropy_penalty                      -0.327934
trainer/entropy_percentage                   -0.000935697
trainer/Q1Pred Mean                         348.567
trainer/Q1Pred Std                           67.2258
trainer/Q1Pred Max                          432.036
trainer/Q1Pred Min                          -14.9359
trainer/Q2Pred Mean                         348.952
trainer/Q2Pred Std                           67.3038
trainer/Q2Pred Max                          427.382
trainer/Q2Pred Min                           -6.14672
trainer/QTargetWithReg Mean                 349.242
trainer/QTargetWithReg Std                   67.3984
trainer/QTargetWithReg Max                  432.334
trainer/QTargetWithReg Min                    3.84566
trainer/PolicyLossWithoutReg Mean           350.47
trainer/PolicyLossWithoutReg Std             66.7622
trainer/PolicyLossWithoutReg Max            427.375
trainer/PolicyLossWithoutReg Min              3.71127
exploration/num steps total              869000
exploration/num paths total                1664
exploration/path length this epoch Mean     748
exploration/path length this epoch Std        0
exploration/path length this epoch Max      748
exploration/path length this epoch Min      748
exploration/Rewards Mean                      4.5325
exploration/Rewards Std                       1.18807
exploration/Rewards Max                       6.86414
exploration/Rewards Min                      -0.673859
exploration/Returns Mean                   3390.31
exploration/Returns Std                       0
exploration/Returns Max                    3390.31
exploration/Returns Min                    3390.31
exploration/Num Paths                         1
exploration/Average Returns                3390.31
evaluation_0/num steps total                  6.77134e+06
evaluation_0/num paths total              10412
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94755
evaluation_0/Rewards Std                      1.01727
evaluation_0/Rewards Max                      7.50688
evaluation_0/Rewards Min                     -0.574699
evaluation_0/Returns Mean                  4947.55
evaluation_0/Returns Std                    106.473
evaluation_0/Returns Max                   5085.67
evaluation_0/Returns Min                   4763.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4947.55
time/epoch (s)                                0
time/total (s)                            13097.4
Epoch                                       864
---------------------------------------  ----------------
2022-11-16 19:53:15.434420 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 865 finished
---------------------------------------  ----------------
epoch                                       865
total_step                               870000
replay_pool/size                         870000
trainer/alpha                                 0.0585106
trainer/alpha_loss                           -0.707746
trainer/entropy                              -5.75066
trainer/qf_loss                              14.4191
trainer/policy_loss                        -349.886
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.223
trainer/entropy_penalty                      -0.336475
trainer/entropy_percentage                   -0.000960744
trainer/Q1Pred Mean                         349.406
trainer/Q1Pred Std                           57.9375
trainer/Q1Pred Max                          427.037
trainer/Q1Pred Min                           55.8833
trainer/Q2Pred Mean                         349.287
trainer/Q2Pred Std                           57.93
trainer/Q2Pred Max                          427.439
trainer/Q2Pred Min                           66.1381
trainer/QTargetWithReg Mean                 349.503
trainer/QTargetWithReg Std                   58.2012
trainer/QTargetWithReg Max                  428.62
trainer/QTargetWithReg Min                   68.712
trainer/PolicyLossWithoutReg Mean           350.223
trainer/PolicyLossWithoutReg Std             57.7174
trainer/PolicyLossWithoutReg Max            427.681
trainer/PolicyLossWithoutReg Min             61.3647
exploration/num steps total              870000
exploration/num paths total                1665
exploration/path length this epoch Mean     777
exploration/path length this epoch Std        0
exploration/path length this epoch Max      777
exploration/path length this epoch Min      777
exploration/Rewards Mean                      4.36391
exploration/Rewards Std                       1.11985
exploration/Rewards Max                       6.55999
exploration/Rewards Min                      -0.251055
exploration/Returns Mean                   3390.76
exploration/Returns Std                       0
exploration/Returns Max                    3390.76
exploration/Returns Min                    3390.76
exploration/Num Paths                         1
exploration/Average Returns                3390.76
evaluation_0/num steps total                  6.77934e+06
evaluation_0/num paths total              10420
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8878
evaluation_0/Rewards Std                      1.23874
evaluation_0/Rewards Max                      8.1408
evaluation_0/Rewards Min                     -0.781262
evaluation_0/Returns Mean                  4887.8
evaluation_0/Returns Std                    188.112
evaluation_0/Returns Max                   5099.62
evaluation_0/Returns Min                   4491.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.8
time/epoch (s)                                0
time/total (s)                            13112.3
Epoch                                       865
---------------------------------------  ----------------
2022-11-16 19:53:30.299623 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 866 finished
---------------------------------------  ----------------
epoch                                       866
total_step                               871000
replay_pool/size                         871000
trainer/alpha                                 0.058624
trainer/alpha_loss                           -0.297679
trainer/entropy                              -5.89505
trainer/qf_loss                              20.9086
trainer/policy_loss                        -352.841
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.187
trainer/entropy_penalty                      -0.345591
trainer/entropy_percentage                   -0.000978494
trainer/Q1Pred Mean                         351.003
trainer/Q1Pred Std                           64.6261
trainer/Q1Pred Max                          437.091
trainer/Q1Pred Min                           37.1906
trainer/Q2Pred Mean                         351.471
trainer/Q2Pred Std                           64.4316
trainer/Q2Pred Max                          437.487
trainer/Q2Pred Min                           37.7039
trainer/QTargetWithReg Mean                 352.015
trainer/QTargetWithReg Std                   64.8939
trainer/QTargetWithReg Max                  437.904
trainer/QTargetWithReg Min                   43.2898
trainer/PolicyLossWithoutReg Mean           353.187
trainer/PolicyLossWithoutReg Std             63.2666
trainer/PolicyLossWithoutReg Max            437.822
trainer/PolicyLossWithoutReg Min             39.402
exploration/num steps total              871000
exploration/num paths total                1666
exploration/path length this epoch Mean     463
exploration/path length this epoch Std        0
exploration/path length this epoch Max      463
exploration/path length this epoch Min      463
exploration/Rewards Mean                      4.20338
exploration/Rewards Std                       1.26453
exploration/Rewards Max                       6.42715
exploration/Rewards Min                      -0.683025
exploration/Returns Mean                   1946.16
exploration/Returns Std                       0
exploration/Returns Max                    1946.16
exploration/Returns Min                    1946.16
exploration/Num Paths                         1
exploration/Average Returns                1946.16
evaluation_0/num steps total                  6.78734e+06
evaluation_0/num paths total              10428
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91246
evaluation_0/Rewards Std                      1.02554
evaluation_0/Rewards Max                      7.95991
evaluation_0/Rewards Min                     -0.763254
evaluation_0/Returns Mean                  4912.46
evaluation_0/Returns Std                     79.1465
evaluation_0/Returns Max                   5037.89
evaluation_0/Returns Min                   4817.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4912.46
time/epoch (s)                                0
time/total (s)                            13127.2
Epoch                                       866
---------------------------------------  ----------------
2022-11-16 19:53:45.180895 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 867 finished
---------------------------------------  ----------------
epoch                                       867
total_step                               872000
replay_pool/size                         872000
trainer/alpha                                 0.0573842
trainer/alpha_loss                            1.00243
trainer/entropy                              -6.35075
trainer/qf_loss                              20.4379
trainer/policy_loss                        -351.67
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.035
trainer/entropy_penalty                      -0.364433
trainer/entropy_percentage                   -0.00103522
trainer/Q1Pred Mean                         350.371
trainer/Q1Pred Std                           59.4794
trainer/Q1Pred Max                          437.494
trainer/Q1Pred Min                           18.7521
trainer/Q2Pred Mean                         350.067
trainer/Q2Pred Std                           60.4374
trainer/Q2Pred Max                          436.463
trainer/Q2Pred Min                            2.28342
trainer/QTargetWithReg Mean                 350.529
trainer/QTargetWithReg Std                   59.8692
trainer/QTargetWithReg Max                  438.901
trainer/QTargetWithReg Min                    9.98377
trainer/PolicyLossWithoutReg Mean           352.035
trainer/PolicyLossWithoutReg Std             58.8116
trainer/PolicyLossWithoutReg Max            436.637
trainer/PolicyLossWithoutReg Min              7.56209
exploration/num steps total              872000
exploration/num paths total                1667
exploration/path length this epoch Mean     716
exploration/path length this epoch Std        0
exploration/path length this epoch Max      716
exploration/path length this epoch Min      716
exploration/Rewards Mean                      4.5747
exploration/Rewards Std                       1.16725
exploration/Rewards Max                       6.76151
exploration/Rewards Min                      -0.689599
exploration/Returns Mean                   3275.48
exploration/Returns Std                       0
exploration/Returns Max                    3275.48
exploration/Returns Min                    3275.48
exploration/Num Paths                         1
exploration/Average Returns                3275.48
evaluation_0/num steps total                  6.79534e+06
evaluation_0/num paths total              10436
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85709
evaluation_0/Rewards Std                      1.00337
evaluation_0/Rewards Max                      7.61249
evaluation_0/Rewards Min                     -0.80249
evaluation_0/Returns Mean                  4857.09
evaluation_0/Returns Std                     68.7315
evaluation_0/Returns Max                   4944.36
evaluation_0/Returns Min                   4726.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4857.09
time/epoch (s)                                0
time/total (s)                            13142.1
Epoch                                       867
---------------------------------------  ----------------
2022-11-16 19:54:00.112661 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 868 finished
---------------------------------------  ----------------
epoch                                       868
total_step                               873000
replay_pool/size                         873000
trainer/alpha                                 0.0595448
trainer/alpha_loss                            0.977399
trainer/entropy                              -6.34648
trainer/qf_loss                              21.2574
trainer/policy_loss                        -349.476
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.854
trainer/entropy_penalty                      -0.3779
trainer/entropy_percentage                   -0.00108016
trainer/Q1Pred Mean                         349.677
trainer/Q1Pred Std                           68.2038
trainer/Q1Pred Max                          434.409
trainer/Q1Pred Min                            7.4273
trainer/Q2Pred Mean                         349.498
trainer/Q2Pred Std                           67.5524
trainer/Q2Pred Max                          424.729
trainer/Q2Pred Min                            1.27286
trainer/QTargetWithReg Mean                 350.042
trainer/QTargetWithReg Std                   68.188
trainer/QTargetWithReg Max                  429.228
trainer/QTargetWithReg Min                    4.44861
trainer/PolicyLossWithoutReg Mean           349.854
trainer/PolicyLossWithoutReg Std             66.9955
trainer/PolicyLossWithoutReg Max            425.015
trainer/PolicyLossWithoutReg Min              1.24892
exploration/num steps total              873000
exploration/num paths total                1668
exploration/path length this epoch Mean     870
exploration/path length this epoch Std        0
exploration/path length this epoch Max      870
exploration/path length this epoch Min      870
exploration/Rewards Mean                      4.60221
exploration/Rewards Std                       1.05079
exploration/Rewards Max                       7.48767
exploration/Rewards Min                      -1.1883
exploration/Returns Mean                   4003.92
exploration/Returns Std                       0
exploration/Returns Max                    4003.92
exploration/Returns Min                    4003.92
exploration/Num Paths                         1
exploration/Average Returns                4003.92
evaluation_0/num steps total                  6.80334e+06
evaluation_0/num paths total              10444
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87321
evaluation_0/Rewards Std                      0.991116
evaluation_0/Rewards Max                      7.25076
evaluation_0/Rewards Min                     -0.736254
evaluation_0/Returns Mean                  4873.21
evaluation_0/Returns Std                     68.7842
evaluation_0/Returns Max                   4973.22
evaluation_0/Returns Min                   4762.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4873.21
time/epoch (s)                                0
time/total (s)                            13157
Epoch                                       868
---------------------------------------  ----------------
2022-11-16 19:54:14.836341 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 869 finished
---------------------------------------  ----------------
epoch                                       869
total_step                               874000
replay_pool/size                         874000
trainer/alpha                                 0.0578981
trainer/alpha_loss                           -0.221209
trainer/entropy                              -5.92236
trainer/qf_loss                              21.3436
trainer/policy_loss                        -353.348
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.691
trainer/entropy_penalty                      -0.342893
trainer/entropy_percentage                   -0.000969473
trainer/Q1Pred Mean                         353.178
trainer/Q1Pred Std                           56.4615
trainer/Q1Pred Max                          434.182
trainer/Q1Pred Min                           24.8476
trainer/Q2Pred Mean                         353.468
trainer/Q2Pred Std                           56.4491
trainer/Q2Pred Max                          436.133
trainer/Q2Pred Min                           29.6039
trainer/QTargetWithReg Mean                 353.265
trainer/QTargetWithReg Std                   57.6735
trainer/QTargetWithReg Max                  435.968
trainer/QTargetWithReg Min                    2.57659
trainer/PolicyLossWithoutReg Mean           353.691
trainer/PolicyLossWithoutReg Std             55.5054
trainer/PolicyLossWithoutReg Max            434.212
trainer/PolicyLossWithoutReg Min             33.4908
exploration/num steps total              874000
exploration/num paths total                1669
exploration/path length this epoch Mean     378
exploration/path length this epoch Std        0
exploration/path length this epoch Max      378
exploration/path length this epoch Min      378
exploration/Rewards Mean                      4.06232
exploration/Rewards Std                       1.46922
exploration/Rewards Max                       7.3556
exploration/Rewards Min                      -0.668598
exploration/Returns Mean                   1535.56
exploration/Returns Std                       0
exploration/Returns Max                    1535.56
exploration/Returns Min                    1535.56
exploration/Num Paths                         1
exploration/Average Returns                1535.56
evaluation_0/num steps total                  6.81134e+06
evaluation_0/num paths total              10452
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86116
evaluation_0/Rewards Std                      0.959257
evaluation_0/Rewards Max                      8.16768
evaluation_0/Rewards Min                     -0.504258
evaluation_0/Returns Mean                  4861.16
evaluation_0/Returns Std                     80.232
evaluation_0/Returns Max                   4999.47
evaluation_0/Returns Min                   4708.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4861.16
time/epoch (s)                                0
time/total (s)                            13171.7
Epoch                                       869
---------------------------------------  ----------------
2022-11-16 19:54:29.677020 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 870 finished
---------------------------------------  ----------------
epoch                                       870
total_step                               875000
replay_pool/size                         875000
trainer/alpha                                 0.0592668
trainer/alpha_loss                            0.925624
trainer/entropy                              -6.32758
trainer/qf_loss                              35.2855
trainer/policy_loss                        -342.872
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         343.247
trainer/entropy_penalty                      -0.375015
trainer/entropy_percentage                   -0.00109255
trainer/Q1Pred Mean                         342.013
trainer/Q1Pred Std                           72.0279
trainer/Q1Pred Max                          434.936
trainer/Q1Pred Min                           -8.04936
trainer/Q2Pred Mean                         341.936
trainer/Q2Pred Std                           72.1249
trainer/Q2Pred Max                          431.912
trainer/Q2Pred Min                          -15.125
trainer/QTargetWithReg Mean                 342.324
trainer/QTargetWithReg Std                   72.3404
trainer/QTargetWithReg Max                  433.968
trainer/QTargetWithReg Min                  -27.7272
trainer/PolicyLossWithoutReg Mean           343.247
trainer/PolicyLossWithoutReg Std             69.8911
trainer/PolicyLossWithoutReg Max            433.686
trainer/PolicyLossWithoutReg Min            -21.6861
exploration/num steps total              875000
exploration/num paths total                1670
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71111
exploration/Rewards Std                       1.12125
exploration/Rewards Max                       7.51137
exploration/Rewards Min                      -0.958635
exploration/Returns Mean                   4711.11
exploration/Returns Std                       0
exploration/Returns Max                    4711.11
exploration/Returns Min                    4711.11
exploration/Num Paths                         1
exploration/Average Returns                4711.11
evaluation_0/num steps total                  6.81934e+06
evaluation_0/num paths total              10460
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87242
evaluation_0/Rewards Std                      0.977305
evaluation_0/Rewards Max                      7.27595
evaluation_0/Rewards Min                     -0.381396
evaluation_0/Returns Mean                  4872.42
evaluation_0/Returns Std                     31.1147
evaluation_0/Returns Max                   4927.01
evaluation_0/Returns Min                   4828.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4872.42
time/epoch (s)                                0
time/total (s)                            13186.5
Epoch                                       870
---------------------------------------  ----------------
2022-11-16 19:54:44.443835 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 871 finished
---------------------------------------  ----------------
epoch                                       871
total_step                               876000
replay_pool/size                         876000
trainer/alpha                                 0.0566826
trainer/alpha_loss                            0.0124383
trainer/entropy                              -6.00433
trainer/qf_loss                              27.6514
trainer/policy_loss                        -350.784
trainer/adversary_policy_loss                16.6325
trainer/policy_loss_without_entropy         351.124
trainer/entropy_penalty                      -0.340341
trainer/entropy_percentage                   -0.00096929
trainer/Q1Pred Mean                         351.195
trainer/Q1Pred Std                           67.4202
trainer/Q1Pred Max                          437.602
trainer/Q1Pred Min                            2.25127
trainer/Q2Pred Mean                         351.517
trainer/Q2Pred Std                           66.9155
trainer/Q2Pred Max                          437.533
trainer/Q2Pred Min                           -0.138181
trainer/QTargetWithReg Mean                 351.32
trainer/QTargetWithReg Std                   67.5147
trainer/QTargetWithReg Max                  437.55
trainer/QTargetWithReg Min                    4.42246
trainer/PolicyLossWithoutReg Mean           351.124
trainer/PolicyLossWithoutReg Std             66.5501
trainer/PolicyLossWithoutReg Max            436.557
trainer/PolicyLossWithoutReg Min              4.18021
exploration/num steps total              876000
exploration/num paths total                1671
exploration/path length this epoch Mean     677
exploration/path length this epoch Std        0
exploration/path length this epoch Max      677
exploration/path length this epoch Min      677
exploration/Rewards Mean                      4.5405
exploration/Rewards Std                       1.08982
exploration/Rewards Max                       6.94613
exploration/Rewards Min                      -0.388524
exploration/Returns Mean                   3073.92
exploration/Returns Std                       0
exploration/Returns Max                    3073.92
exploration/Returns Min                    3073.92
exploration/Num Paths                         1
exploration/Average Returns                3073.92
evaluation_0/num steps total                  6.82734e+06
evaluation_0/num paths total              10468
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92028
evaluation_0/Rewards Std                      1.02794
evaluation_0/Rewards Max                      7.53421
evaluation_0/Rewards Min                     -0.617307
evaluation_0/Returns Mean                  4920.28
evaluation_0/Returns Std                     46.0971
evaluation_0/Returns Max                   4972.02
evaluation_0/Returns Min                   4826.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4920.28
time/epoch (s)                                0
time/total (s)                            13201.3
Epoch                                       871
---------------------------------------  ----------------
2022-11-16 19:55:01.073109 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 872 finished
---------------------------------------  ----------------
epoch                                       872
total_step                               877000
replay_pool/size                         877000
trainer/alpha                                 0.0587618
trainer/alpha_loss                            0.0369149
trainer/entropy                              -6.01302
trainer/qf_loss                              19.1251
trainer/policy_loss                        -346.832
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.186
trainer/entropy_penalty                      -0.353336
trainer/entropy_percentage                   -0.00101771
trainer/Q1Pred Mean                         346.235
trainer/Q1Pred Std                           66.9882
trainer/Q1Pred Max                          432.886
trainer/Q1Pred Min                           18.1394
trainer/Q2Pred Mean                         345.655
trainer/Q2Pred Std                           67.5002
trainer/Q2Pred Max                          435.927
trainer/Q2Pred Min                           18.9933
trainer/QTargetWithReg Mean                 346.627
trainer/QTargetWithReg Std                   67.6132
trainer/QTargetWithReg Max                  435.392
trainer/QTargetWithReg Min                   20.5081
trainer/PolicyLossWithoutReg Mean           347.186
trainer/PolicyLossWithoutReg Std             66.5627
trainer/PolicyLossWithoutReg Max            434.916
trainer/PolicyLossWithoutReg Min             20.8725
exploration/num steps total              877000
exploration/num paths total                1672
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87371
exploration/Rewards Std                       1.11017
exploration/Rewards Max                       7.45303
exploration/Rewards Min                      -0.728874
exploration/Returns Mean                   4873.71
exploration/Returns Std                       0
exploration/Returns Max                    4873.71
exploration/Returns Min                    4873.71
exploration/Num Paths                         1
exploration/Average Returns                4873.71
evaluation_0/num steps total                  6.83493e+06
evaluation_0/num paths total              10477
evaluation_0/path length Mean               843
evaluation_0/path length Std                228.293
evaluation_0/path length Max               1000
evaluation_0/path length Min                405
evaluation_0/Rewards Mean                     4.93001
evaluation_0/Rewards Std                      1.07215
evaluation_0/Rewards Max                      8.20603
evaluation_0/Rewards Min                     -0.64093
evaluation_0/Returns Mean                  4156
evaluation_0/Returns Std                   1272.51
evaluation_0/Returns Max                   5102.78
evaluation_0/Returns Min                   1798.76
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4156
time/epoch (s)                                0
time/total (s)                            13217.9
Epoch                                       872
---------------------------------------  ----------------
2022-11-16 19:55:17.636833 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 873 finished
---------------------------------------  ----------------
epoch                                       873
total_step                               878000
replay_pool/size                         878000
trainer/alpha                                 0.0574059
trainer/alpha_loss                            0.455748
trainer/entropy                              -6.15948
trainer/qf_loss                              32.0936
trainer/policy_loss                        -349.464
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.818
trainer/entropy_penalty                      -0.353591
trainer/entropy_percentage                   -0.00101079
trainer/Q1Pred Mean                         349.13
trainer/Q1Pred Std                           73.4423
trainer/Q1Pred Max                          432.837
trainer/Q1Pred Min                            3.74376
trainer/Q2Pred Mean                         349.728
trainer/Q2Pred Std                           73.34
trainer/Q2Pred Max                          436.777
trainer/Q2Pred Min                           -5.9159
trainer/QTargetWithReg Mean                 349.019
trainer/QTargetWithReg Std                   73.9047
trainer/QTargetWithReg Max                  436.438
trainer/QTargetWithReg Min                    2.15278
trainer/PolicyLossWithoutReg Mean           349.818
trainer/PolicyLossWithoutReg Std             73.0867
trainer/PolicyLossWithoutReg Max            434.821
trainer/PolicyLossWithoutReg Min             -1.1298
exploration/num steps total              878000
exploration/num paths total                1673
exploration/path length this epoch Mean     965
exploration/path length this epoch Std        0
exploration/path length this epoch Max      965
exploration/path length this epoch Min      965
exploration/Rewards Mean                      4.67213
exploration/Rewards Std                       1.22469
exploration/Rewards Max                       7.33668
exploration/Rewards Min                      -0.53457
exploration/Returns Mean                   4508.6
exploration/Returns Std                       0
exploration/Returns Max                    4508.6
exploration/Returns Min                    4508.6
exploration/Num Paths                         1
exploration/Average Returns                4508.6
evaluation_0/num steps total                  6.84261e+06
evaluation_0/num paths total              10485
evaluation_0/path length Mean               960.125
evaluation_0/path length Std                 71.1871
evaluation_0/path length Max               1000
evaluation_0/path length Min                806
evaluation_0/Rewards Mean                     4.77093
evaluation_0/Rewards Std                      1.13195
evaluation_0/Rewards Max                      8.02472
evaluation_0/Rewards Min                     -0.637597
evaluation_0/Returns Mean                  4580.69
evaluation_0/Returns Std                    390.338
evaluation_0/Returns Max                   4896.42
evaluation_0/Returns Min                   3650.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4580.69
time/epoch (s)                                0
time/total (s)                            13234.5
Epoch                                       873
---------------------------------------  ----------------
2022-11-16 19:55:32.429134 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 874 finished
---------------------------------------  ----------------
epoch                                       874
total_step                               879000
replay_pool/size                         879000
trainer/alpha                                 0.0570706
trainer/alpha_loss                            0.218357
trainer/entropy                              -6.07625
trainer/qf_loss                              79.3066
trainer/policy_loss                        -347.681
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.027
trainer/entropy_penalty                      -0.346775
trainer/entropy_percentage                   -0.000996402
trainer/Q1Pred Mean                         348.694
trainer/Q1Pred Std                           66.2911
trainer/Q1Pred Max                          435.964
trainer/Q1Pred Min                            0.0107057
trainer/Q2Pred Mean                         348.472
trainer/Q2Pred Std                           65.9812
trainer/Q2Pred Max                          436.121
trainer/Q2Pred Min                           -6.57906
trainer/QTargetWithReg Mean                 348.014
trainer/QTargetWithReg Std                   68.0494
trainer/QTargetWithReg Max                  438.178
trainer/QTargetWithReg Min                 -107.279
trainer/PolicyLossWithoutReg Mean           348.027
trainer/PolicyLossWithoutReg Std             64.9066
trainer/PolicyLossWithoutReg Max            435.21
trainer/PolicyLossWithoutReg Min             45.6825
exploration/num steps total              879000
exploration/num paths total                1674
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60531
exploration/Rewards Std                       1.0407
exploration/Rewards Max                       7.50474
exploration/Rewards Min                      -0.426104
exploration/Returns Mean                   4605.31
exploration/Returns Std                       0
exploration/Returns Max                    4605.31
exploration/Returns Min                    4605.31
exploration/Num Paths                         1
exploration/Average Returns                4605.31
evaluation_0/num steps total                  6.85061e+06
evaluation_0/num paths total              10493
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78812
evaluation_0/Rewards Std                      1.06365
evaluation_0/Rewards Max                      7.70043
evaluation_0/Rewards Min                     -0.491804
evaluation_0/Returns Mean                  4788.12
evaluation_0/Returns Std                     94.5012
evaluation_0/Returns Max                   4899.17
evaluation_0/Returns Min                   4641.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4788.12
time/epoch (s)                                0
time/total (s)                            13249.3
Epoch                                       874
---------------------------------------  ----------------
2022-11-16 19:55:46.868081 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 875 finished
---------------------------------------  ----------------
epoch                                       875
total_step                               880000
replay_pool/size                         880000
trainer/alpha                                 0.0575343
trainer/alpha_loss                           -0.856705
trainer/entropy                              -5.69996
trainer/qf_loss                              24.6278
trainer/policy_loss                        -359.707
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         360.035
trainer/entropy_penalty                      -0.327943
trainer/entropy_percentage                   -0.000910864
trainer/Q1Pred Mean                         358.863
trainer/Q1Pred Std                           56.8361
trainer/Q1Pred Max                          432.068
trainer/Q1Pred Min                           14.6789
trainer/Q2Pred Mean                         358.788
trainer/Q2Pred Std                           56.8001
trainer/Q2Pred Max                          429.735
trainer/Q2Pred Min                           14.8779
trainer/QTargetWithReg Mean                 358.296
trainer/QTargetWithReg Std                   57.1438
trainer/QTargetWithReg Max                  429.29
trainer/QTargetWithReg Min                   18.4835
trainer/PolicyLossWithoutReg Mean           360.035
trainer/PolicyLossWithoutReg Std             54.9635
trainer/PolicyLossWithoutReg Max            429.962
trainer/PolicyLossWithoutReg Min             17.5014
exploration/num steps total              880000
exploration/num paths total                1676
exploration/path length this epoch Mean     318
exploration/path length this epoch Std      139
exploration/path length this epoch Max      457
exploration/path length this epoch Min      179
exploration/Rewards Mean                      3.95954
exploration/Rewards Std                       1.27911
exploration/Rewards Max                       6.44252
exploration/Rewards Min                      -0.756759
exploration/Returns Mean                   1259.13
exploration/Returns Std                     673.979
exploration/Returns Max                    1933.11
exploration/Returns Min                     585.154
exploration/Num Paths                         2
exploration/Average Returns                1259.13
evaluation_0/num steps total                  6.85861e+06
evaluation_0/num paths total              10501
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94751
evaluation_0/Rewards Std                      1.01999
evaluation_0/Rewards Max                      7.224
evaluation_0/Rewards Min                     -0.64955
evaluation_0/Returns Mean                  4947.51
evaluation_0/Returns Std                     98.6505
evaluation_0/Returns Max                   5150.95
evaluation_0/Returns Min                   4789.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4947.51
time/epoch (s)                                0
time/total (s)                            13263.7
Epoch                                       875
---------------------------------------  ----------------
2022-11-16 19:56:01.601948 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 876 finished
---------------------------------------  ----------------
epoch                                       876
total_step                               881000
replay_pool/size                         881000
trainer/alpha                                 0.057838
trainer/alpha_loss                            0.329905
trainer/entropy                              -6.11575
trainer/qf_loss                              22.2626
trainer/policy_loss                        -347.195
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.548
trainer/entropy_penalty                      -0.353722
trainer/entropy_percentage                   -0.00101776
trainer/Q1Pred Mean                         345.674
trainer/Q1Pred Std                           71.3551
trainer/Q1Pred Max                          431.973
trainer/Q1Pred Min                           13.5215
trainer/Q2Pred Mean                         346.266
trainer/Q2Pred Std                           71.4822
trainer/Q2Pred Max                          427.83
trainer/Q2Pred Min                            7.55222
trainer/QTargetWithReg Mean                 345.604
trainer/QTargetWithReg Std                   70.8826
trainer/QTargetWithReg Max                  431.488
trainer/QTargetWithReg Min                    3.9641
trainer/PolicyLossWithoutReg Mean           347.548
trainer/PolicyLossWithoutReg Std             70.2233
trainer/PolicyLossWithoutReg Max            429.295
trainer/PolicyLossWithoutReg Min             16.9203
exploration/num steps total              881000
exploration/num paths total                1677
exploration/path length this epoch Mean     450
exploration/path length this epoch Std        0
exploration/path length this epoch Max      450
exploration/path length this epoch Min      450
exploration/Rewards Mean                      3.54732
exploration/Rewards Std                       1.34866
exploration/Rewards Max                       6.26976
exploration/Rewards Min                      -0.791535
exploration/Returns Mean                   1596.29
exploration/Returns Std                       0
exploration/Returns Max                    1596.29
exploration/Returns Min                    1596.29
exploration/Num Paths                         1
exploration/Average Returns                1596.29
evaluation_0/num steps total                  6.86661e+06
evaluation_0/num paths total              10509
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00949
evaluation_0/Rewards Std                      1.08775
evaluation_0/Rewards Max                      7.50195
evaluation_0/Rewards Min                     -0.80773
evaluation_0/Returns Mean                  5009.49
evaluation_0/Returns Std                    121.512
evaluation_0/Returns Max                   5294.72
evaluation_0/Returns Min                   4825.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5009.49
time/epoch (s)                                0
time/total (s)                            13278.5
Epoch                                       876
---------------------------------------  ----------------
2022-11-16 19:56:16.525042 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 877 finished
---------------------------------------  ----------------
epoch                                       877
total_step                               882000
replay_pool/size                         882000
trainer/alpha                                 0.0602736
trainer/alpha_loss                           -1.79512
trainer/entropy                              -5.36086
trainer/qf_loss                              22.4934
trainer/policy_loss                        -358.961
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         359.284
trainer/entropy_penalty                      -0.323118
trainer/entropy_percentage                   -0.00089934
trainer/Q1Pred Mean                         357.743
trainer/Q1Pred Std                           52.2569
trainer/Q1Pred Max                          429.977
trainer/Q1Pred Min                            5.70907
trainer/Q2Pred Mean                         358.054
trainer/Q2Pred Std                           52.7072
trainer/Q2Pred Max                          428.594
trainer/Q2Pred Min                            8.70493
trainer/QTargetWithReg Mean                 358.082
trainer/QTargetWithReg Std                   52.0785
trainer/QTargetWithReg Max                  430.496
trainer/QTargetWithReg Min                    8.77582
trainer/PolicyLossWithoutReg Mean           359.284
trainer/PolicyLossWithoutReg Std             51.2323
trainer/PolicyLossWithoutReg Max            430.05
trainer/PolicyLossWithoutReg Min              9.97147
exploration/num steps total              882000
exploration/num paths total                1678
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91099
exploration/Rewards Std                       1.05047
exploration/Rewards Max                       7.10889
exploration/Rewards Min                      -0.64477
exploration/Returns Mean                   4910.99
exploration/Returns Std                       0
exploration/Returns Max                    4910.99
exploration/Returns Min                    4910.99
exploration/Num Paths                         1
exploration/Average Returns                4910.99
evaluation_0/num steps total                  6.87461e+06
evaluation_0/num paths total              10517
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88759
evaluation_0/Rewards Std                      1.16622
evaluation_0/Rewards Max                      7.90774
evaluation_0/Rewards Min                     -0.844777
evaluation_0/Returns Mean                  4887.59
evaluation_0/Returns Std                    143.326
evaluation_0/Returns Max                   5126.79
evaluation_0/Returns Min                   4638
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.59
time/epoch (s)                                0
time/total (s)                            13293.4
Epoch                                       877
---------------------------------------  ----------------
2022-11-16 19:56:33.192485 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 878 finished
---------------------------------------  ----------------
epoch                                       878
total_step                               883000
replay_pool/size                         883000
trainer/alpha                                 0.0588578
trainer/alpha_loss                           -0.172612
trainer/entropy                              -5.93907
trainer/qf_loss                              17.2121
trainer/policy_loss                        -356.933
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.282
trainer/entropy_penalty                      -0.34956
trainer/entropy_percentage                   -0.000978387
trainer/Q1Pred Mean                         356.803
trainer/Q1Pred Std                           59.3559
trainer/Q1Pred Max                          433.637
trainer/Q1Pred Min                           48.0643
trainer/Q2Pred Mean                         356.983
trainer/Q2Pred Std                           58.9777
trainer/Q2Pred Max                          435.037
trainer/Q2Pred Min                           44.0979
trainer/QTargetWithReg Mean                 356.69
trainer/QTargetWithReg Std                   59.1926
trainer/QTargetWithReg Max                  433.531
trainer/QTargetWithReg Min                   44.814
trainer/PolicyLossWithoutReg Mean           357.282
trainer/PolicyLossWithoutReg Std             58.6757
trainer/PolicyLossWithoutReg Max            433.739
trainer/PolicyLossWithoutReg Min             51.8051
exploration/num steps total              883000
exploration/num paths total                1679
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60601
exploration/Rewards Std                       1.00247
exploration/Rewards Max                       7.77533
exploration/Rewards Min                      -0.840412
exploration/Returns Mean                   4606.01
exploration/Returns Std                       0
exploration/Returns Max                    4606.01
exploration/Returns Min                    4606.01
exploration/Num Paths                         1
exploration/Average Returns                4606.01
evaluation_0/num steps total                  6.88207e+06
evaluation_0/num paths total              10525
evaluation_0/path length Mean               932.375
evaluation_0/path length Std                178.919
evaluation_0/path length Max               1000
evaluation_0/path length Min                459
evaluation_0/Rewards Mean                     4.78617
evaluation_0/Rewards Std                      1.12235
evaluation_0/Rewards Max                      7.42354
evaluation_0/Rewards Min                     -0.536405
evaluation_0/Returns Mean                  4462.51
evaluation_0/Returns Std                    969.295
evaluation_0/Returns Max                   4963.85
evaluation_0/Returns Min                   1910.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4462.51
time/epoch (s)                                0
time/total (s)                            13310.1
Epoch                                       878
---------------------------------------  ----------------
2022-11-16 19:56:48.058897 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 879 finished
---------------------------------------  ----------------
epoch                                       879
total_step                               884000
replay_pool/size                         884000
trainer/alpha                                 0.0591881
trainer/alpha_loss                            1.49072
trainer/entropy                              -6.5273
trainer/qf_loss                              37.7057
trainer/policy_loss                        -351.183
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.569
trainer/entropy_penalty                      -0.386339
trainer/entropy_percentage                   -0.0010989
trainer/Q1Pred Mean                         350.063
trainer/Q1Pred Std                           67.6301
trainer/Q1Pred Max                          428.756
trainer/Q1Pred Min                           17.8386
trainer/Q2Pred Mean                         349.58
trainer/Q2Pred Std                           66.8345
trainer/Q2Pred Max                          426.727
trainer/Q2Pred Min                           19.3124
trainer/QTargetWithReg Mean                 349.721
trainer/QTargetWithReg Std                   67.8436
trainer/QTargetWithReg Max                  425.993
trainer/QTargetWithReg Min                   -0.05878
trainer/PolicyLossWithoutReg Mean           351.569
trainer/PolicyLossWithoutReg Std             64.4328
trainer/PolicyLossWithoutReg Max            427.841
trainer/PolicyLossWithoutReg Min             18.5983
exploration/num steps total              884000
exploration/num paths total                1680
exploration/path length this epoch Mean     194
exploration/path length this epoch Std        0
exploration/path length this epoch Max      194
exploration/path length this epoch Min      194
exploration/Rewards Mean                      3.20746
exploration/Rewards Std                       1.33826
exploration/Rewards Max                       5.36649
exploration/Rewards Min                      -0.544451
exploration/Returns Mean                    622.247
exploration/Returns Std                       0
exploration/Returns Max                     622.247
exploration/Returns Min                     622.247
exploration/Num Paths                         1
exploration/Average Returns                 622.247
evaluation_0/num steps total                  6.89007e+06
evaluation_0/num paths total              10533
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76137
evaluation_0/Rewards Std                      1.01946
evaluation_0/Rewards Max                      6.9169
evaluation_0/Rewards Min                     -0.634233
evaluation_0/Returns Mean                  4761.37
evaluation_0/Returns Std                     92.029
evaluation_0/Returns Max                   4918.72
evaluation_0/Returns Min                   4645.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4761.37
time/epoch (s)                                0
time/total (s)                            13324.9
Epoch                                       879
---------------------------------------  ----------------
2022-11-16 19:57:03.034616 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 880 finished
---------------------------------------  ----------------
epoch                                       880
total_step                               885000
replay_pool/size                         885000
trainer/alpha                                 0.0584876
trainer/alpha_loss                            0.0142954
trainer/entropy                              -6.00504
trainer/qf_loss                              21.1803
trainer/policy_loss                        -344.033
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.385
trainer/entropy_penalty                      -0.35122
trainer/entropy_percentage                   -0.00101985
trainer/Q1Pred Mean                         344.47
trainer/Q1Pred Std                           71.0459
trainer/Q1Pred Max                          426.41
trainer/Q1Pred Min                           14.3998
trainer/Q2Pred Mean                         343.877
trainer/Q2Pred Std                           71.0472
trainer/Q2Pred Max                          425.662
trainer/Q2Pred Min                           12.1177
trainer/QTargetWithReg Mean                 343.826
trainer/QTargetWithReg Std                   70.7786
trainer/QTargetWithReg Max                  425.91
trainer/QTargetWithReg Min                   18.1813
trainer/PolicyLossWithoutReg Mean           344.385
trainer/PolicyLossWithoutReg Std             70.0625
trainer/PolicyLossWithoutReg Max            425.266
trainer/PolicyLossWithoutReg Min             15.9335
exploration/num steps total              885000
exploration/num paths total                1682
exploration/path length this epoch Mean     364
exploration/path length this epoch Std      123
exploration/path length this epoch Max      487
exploration/path length this epoch Min      241
exploration/Rewards Mean                      3.86727
exploration/Rewards Std                       1.2375
exploration/Rewards Max                       6.55393
exploration/Rewards Min                      -0.606021
exploration/Returns Mean                   1407.69
exploration/Returns Std                     530.753
exploration/Returns Max                    1938.44
exploration/Returns Min                     876.932
exploration/Num Paths                         2
exploration/Average Returns                1407.69
evaluation_0/num steps total                  6.89807e+06
evaluation_0/num paths total              10541
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86819
evaluation_0/Rewards Std                      1.03383
evaluation_0/Rewards Max                      7.25792
evaluation_0/Rewards Min                     -0.853806
evaluation_0/Returns Mean                  4868.19
evaluation_0/Returns Std                     53.4086
evaluation_0/Returns Max                   4936.31
evaluation_0/Returns Min                   4784.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4868.19
time/epoch (s)                                0
time/total (s)                            13339.9
Epoch                                       880
---------------------------------------  ----------------
2022-11-16 19:57:17.999167 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 881 finished
---------------------------------------  ----------------
epoch                                       881
total_step                               886000
replay_pool/size                         886000
trainer/alpha                                 0.0583793
trainer/alpha_loss                           -0.066421
trainer/entropy                              -5.97662
trainer/qf_loss                              21.3971
trainer/policy_loss                        -346.259
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.608
trainer/entropy_penalty                      -0.348911
trainer/entropy_percentage                   -0.00100664
trainer/Q1Pred Mean                         344.409
trainer/Q1Pred Std                           80.859
trainer/Q1Pred Max                          424.864
trainer/Q1Pred Min                            2.24984
trainer/Q2Pred Mean                         344.276
trainer/Q2Pred Std                           80.8025
trainer/Q2Pred Max                          424.521
trainer/Q2Pred Min                           -2.76999
trainer/QTargetWithReg Mean                 345.106
trainer/QTargetWithReg Std                   81.3863
trainer/QTargetWithReg Max                  425.551
trainer/QTargetWithReg Min                    3.12871
trainer/PolicyLossWithoutReg Mean           346.608
trainer/PolicyLossWithoutReg Std             79.6311
trainer/PolicyLossWithoutReg Max            425.49
trainer/PolicyLossWithoutReg Min              1.41917
exploration/num steps total              886000
exploration/num paths total                1683
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81608
exploration/Rewards Std                       1.00317
exploration/Rewards Max                       7.11884
exploration/Rewards Min                      -1.01121
exploration/Returns Mean                   4816.08
exploration/Returns Std                       0
exploration/Returns Max                    4816.08
exploration/Returns Min                    4816.08
exploration/Num Paths                         1
exploration/Average Returns                4816.08
evaluation_0/num steps total                  6.90607e+06
evaluation_0/num paths total              10549
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68079
evaluation_0/Rewards Std                      1.01462
evaluation_0/Rewards Max                      7.21255
evaluation_0/Rewards Min                     -0.707002
evaluation_0/Returns Mean                  4680.79
evaluation_0/Returns Std                     34.8874
evaluation_0/Returns Max                   4720.88
evaluation_0/Returns Min                   4613.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4680.79
time/epoch (s)                                0
time/total (s)                            13354.9
Epoch                                       881
---------------------------------------  ----------------
2022-11-16 19:57:32.968658 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 882 finished
---------------------------------------  ----------------
epoch                                       882
total_step                               887000
replay_pool/size                         887000
trainer/alpha                                 0.0560559
trainer/alpha_loss                           -0.544606
trainer/entropy                              -5.81099
trainer/qf_loss                              20.2543
trainer/policy_loss                        -358.205
trainer/adversary_policy_loss                17.2168
trainer/policy_loss_without_entropy         358.53
trainer/entropy_penalty                      -0.32574
trainer/entropy_percentage                   -0.000908543
trainer/Q1Pred Mean                         357.952
trainer/Q1Pred Std                           62.2676
trainer/Q1Pred Max                          430.27
trainer/Q1Pred Min                           44.3028
trainer/Q2Pred Mean                         357.253
trainer/Q2Pred Std                           62.6073
trainer/Q2Pred Max                          430.551
trainer/Q2Pred Min                           32.5747
trainer/QTargetWithReg Mean                 356.969
trainer/QTargetWithReg Std                   63.7094
trainer/QTargetWithReg Max                  427.789
trainer/QTargetWithReg Min                   -0.287318
trainer/PolicyLossWithoutReg Mean           358.53
trainer/PolicyLossWithoutReg Std             60.6062
trainer/PolicyLossWithoutReg Max            429.208
trainer/PolicyLossWithoutReg Min             61.041
exploration/num steps total              887000
exploration/num paths total                1684
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75748
exploration/Rewards Std                       1.07196
exploration/Rewards Max                       7.39112
exploration/Rewards Min                      -0.71302
exploration/Returns Mean                   4757.48
exploration/Returns Std                       0
exploration/Returns Max                    4757.48
exploration/Returns Min                    4757.48
exploration/Num Paths                         1
exploration/Average Returns                4757.48
evaluation_0/num steps total                  6.91407e+06
evaluation_0/num paths total              10557
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9276
evaluation_0/Rewards Std                      1.08078
evaluation_0/Rewards Max                      7.79822
evaluation_0/Rewards Min                     -0.380247
evaluation_0/Returns Mean                  4927.6
evaluation_0/Returns Std                    114.929
evaluation_0/Returns Max                   5055.1
evaluation_0/Returns Min                   4758.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4927.6
time/epoch (s)                                0
time/total (s)                            13369.8
Epoch                                       882
---------------------------------------  ----------------
2022-11-16 19:57:47.846183 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 883 finished
---------------------------------------  ----------------
epoch                                       883
total_step                               888000
replay_pool/size                         888000
trainer/alpha                                 0.0573858
trainer/alpha_loss                           -1.27811
trainer/entropy                              -5.55278
trainer/qf_loss                              14.9442
trainer/policy_loss                        -355.162
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.481
trainer/entropy_penalty                      -0.318651
trainer/entropy_percentage                   -0.000896393
trainer/Q1Pred Mean                         355.141
trainer/Q1Pred Std                           62.944
trainer/Q1Pred Max                          426.072
trainer/Q1Pred Min                           -0.499924
trainer/Q2Pred Mean                         355.772
trainer/Q2Pred Std                           62.9912
trainer/Q2Pred Max                          426.736
trainer/Q2Pred Min                           10.6994
trainer/QTargetWithReg Mean                 355.375
trainer/QTargetWithReg Std                   63.9938
trainer/QTargetWithReg Max                  425.748
trainer/QTargetWithReg Min                    2.82222
trainer/PolicyLossWithoutReg Mean           355.481
trainer/PolicyLossWithoutReg Std             63.0397
trainer/PolicyLossWithoutReg Max            425.864
trainer/PolicyLossWithoutReg Min              1.33339
exploration/num steps total              888000
exploration/num paths total                1685
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77388
exploration/Rewards Std                       1.00287
exploration/Rewards Max                       7.1776
exploration/Rewards Min                      -0.364329
exploration/Returns Mean                   4773.88
exploration/Returns Std                       0
exploration/Returns Max                    4773.88
exploration/Returns Min                    4773.88
exploration/Num Paths                         1
exploration/Average Returns                4773.88
evaluation_0/num steps total                  6.92207e+06
evaluation_0/num paths total              10565
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91526
evaluation_0/Rewards Std                      1.05501
evaluation_0/Rewards Max                      7.78792
evaluation_0/Rewards Min                     -0.686058
evaluation_0/Returns Mean                  4915.26
evaluation_0/Returns Std                     85.7289
evaluation_0/Returns Max                   5078.68
evaluation_0/Returns Min                   4807.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4915.26
time/epoch (s)                                0
time/total (s)                            13384.7
Epoch                                       883
---------------------------------------  ----------------
2022-11-16 19:58:02.848733 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 884 finished
---------------------------------------  ----------------
epoch                                       884
total_step                               889000
replay_pool/size                         889000
trainer/alpha                                 0.05693
trainer/alpha_loss                           -0.868802
trainer/entropy                              -5.69684
trainer/qf_loss                              23.6744
trainer/policy_loss                        -354.054
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.378
trainer/entropy_penalty                      -0.324321
trainer/entropy_percentage                   -0.000915184
trainer/Q1Pred Mean                         354.132
trainer/Q1Pred Std                           59.4166
trainer/Q1Pred Max                          430.559
trainer/Q1Pred Min                           13.7342
trainer/Q2Pred Mean                         353.684
trainer/Q2Pred Std                           59.2964
trainer/Q2Pred Max                          429.886
trainer/Q2Pred Min                            8.55082
trainer/QTargetWithReg Mean                 353.936
trainer/QTargetWithReg Std                   58.5736
trainer/QTargetWithReg Max                  429.385
trainer/QTargetWithReg Min                    5.82311
trainer/PolicyLossWithoutReg Mean           354.378
trainer/PolicyLossWithoutReg Std             58.2248
trainer/PolicyLossWithoutReg Max            429.869
trainer/PolicyLossWithoutReg Min             20.6016
exploration/num steps total              889000
exploration/num paths total                1687
exploration/path length this epoch Mean     268.5
exploration/path length this epoch Std      170.5
exploration/path length this epoch Max      439
exploration/path length this epoch Min       98
exploration/Rewards Mean                      3.68401
exploration/Rewards Std                       1.46802
exploration/Rewards Max                       6.29718
exploration/Rewards Min                      -0.681773
exploration/Returns Mean                    989.157
exploration/Returns Std                     773.644
exploration/Returns Max                    1762.8
exploration/Returns Min                     215.512
exploration/Num Paths                         2
exploration/Average Returns                 989.157
evaluation_0/num steps total                  6.93007e+06
evaluation_0/num paths total              10573
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74549
evaluation_0/Rewards Std                      1.00719
evaluation_0/Rewards Max                      8.18863
evaluation_0/Rewards Min                     -0.76327
evaluation_0/Returns Mean                  4745.49
evaluation_0/Returns Std                     66.5166
evaluation_0/Returns Max                   4861.46
evaluation_0/Returns Min                   4626.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4745.49
time/epoch (s)                                0
time/total (s)                            13399.7
Epoch                                       884
---------------------------------------  ----------------
2022-11-16 19:58:17.834953 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 885 finished
---------------------------------------  ----------------
epoch                                       885
total_step                               890000
replay_pool/size                         890000
trainer/alpha                                 0.0572052
trainer/alpha_loss                            0.786515
trainer/entropy                              -6.2749
trainer/qf_loss                              21.0918
trainer/policy_loss                        -350.93
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.289
trainer/entropy_penalty                      -0.358957
trainer/entropy_percentage                   -0.00102183
trainer/Q1Pred Mean                         349.305
trainer/Q1Pred Std                           64.1823
trainer/Q1Pred Max                          425.229
trainer/Q1Pred Min                           17.3878
trainer/Q2Pred Mean                         350.757
trainer/Q2Pred Std                           63.7883
trainer/Q2Pred Max                          431.101
trainer/Q2Pred Min                           17.3565
trainer/QTargetWithReg Mean                 351.127
trainer/QTargetWithReg Std                   63.7301
trainer/QTargetWithReg Max                  429.185
trainer/QTargetWithReg Min                   27.8719
trainer/PolicyLossWithoutReg Mean           351.289
trainer/PolicyLossWithoutReg Std             63.4218
trainer/PolicyLossWithoutReg Max            426.131
trainer/PolicyLossWithoutReg Min             20.1648
exploration/num steps total              890000
exploration/num paths total                1688
exploration/path length this epoch Mean     472
exploration/path length this epoch Std        0
exploration/path length this epoch Max      472
exploration/path length this epoch Min      472
exploration/Rewards Mean                      3.96422
exploration/Rewards Std                       1.2036
exploration/Rewards Max                       6.63003
exploration/Rewards Min                      -0.729697
exploration/Returns Mean                   1871.11
exploration/Returns Std                       0
exploration/Returns Max                    1871.11
exploration/Returns Min                    1871.11
exploration/Num Paths                         1
exploration/Average Returns                1871.11
evaluation_0/num steps total                  6.93807e+06
evaluation_0/num paths total              10581
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73173
evaluation_0/Rewards Std                      1.05116
evaluation_0/Rewards Max                      7.73825
evaluation_0/Rewards Min                     -0.801052
evaluation_0/Returns Mean                  4731.73
evaluation_0/Returns Std                     63.8006
evaluation_0/Returns Max                   4826.33
evaluation_0/Returns Min                   4621.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4731.73
time/epoch (s)                                0
time/total (s)                            13414.7
Epoch                                       885
---------------------------------------  ----------------
2022-11-16 19:58:32.821973 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 886 finished
---------------------------------------  ----------------
epoch                                       886
total_step                               891000
replay_pool/size                         891000
trainer/alpha                                 0.0588906
trainer/alpha_loss                            1.48963
trainer/entropy                              -6.52595
trainer/qf_loss                              22.7178
trainer/policy_loss                        -346.818
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.202
trainer/entropy_penalty                      -0.384317
trainer/entropy_percentage                   -0.0011069
trainer/Q1Pred Mean                         346.637
trainer/Q1Pred Std                           69.7954
trainer/Q1Pred Max                          436.078
trainer/Q1Pred Min                           18.63
trainer/Q2Pred Mean                         346.673
trainer/Q2Pred Std                           69.738
trainer/Q2Pred Max                          433.036
trainer/Q2Pred Min                           22.659
trainer/QTargetWithReg Mean                 347.12
trainer/QTargetWithReg Std                   69.9575
trainer/QTargetWithReg Max                  434.792
trainer/QTargetWithReg Min                   18.9171
trainer/PolicyLossWithoutReg Mean           347.202
trainer/PolicyLossWithoutReg Std             68.7544
trainer/PolicyLossWithoutReg Max            434.274
trainer/PolicyLossWithoutReg Min             18.1247
exploration/num steps total              891000
exploration/num paths total                1689
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79149
exploration/Rewards Std                       1.17087
exploration/Rewards Max                       7.38492
exploration/Rewards Min                      -0.709928
exploration/Returns Mean                   4791.49
exploration/Returns Std                       0
exploration/Returns Max                    4791.49
exploration/Returns Min                    4791.49
exploration/Num Paths                         1
exploration/Average Returns                4791.49
evaluation_0/num steps total                  6.94607e+06
evaluation_0/num paths total              10589
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86912
evaluation_0/Rewards Std                      1.09325
evaluation_0/Rewards Max                      7.63356
evaluation_0/Rewards Min                     -0.704945
evaluation_0/Returns Mean                  4869.12
evaluation_0/Returns Std                     57.2837
evaluation_0/Returns Max                   4948.37
evaluation_0/Returns Min                   4762.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4869.12
time/epoch (s)                                0
time/total (s)                            13429.7
Epoch                                       886
---------------------------------------  ----------------
2022-11-16 19:58:47.655980 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 887 finished
---------------------------------------  ----------------
epoch                                       887
total_step                               892000
replay_pool/size                         892000
trainer/alpha                                 0.0612623
trainer/alpha_loss                            0.901638
trainer/entropy                              -6.32286
trainer/qf_loss                              56.0161
trainer/policy_loss                        -340.908
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         341.295
trainer/entropy_penalty                      -0.387353
trainer/entropy_percentage                   -0.00113495
trainer/Q1Pred Mean                         340.664
trainer/Q1Pred Std                           79.4739
trainer/Q1Pred Max                          428.339
trainer/Q1Pred Min                          -97.8076
trainer/Q2Pred Mean                         340.852
trainer/Q2Pred Std                           78.3273
trainer/Q2Pred Max                          428.934
trainer/Q2Pred Min                          -45.0279
trainer/QTargetWithReg Mean                 340.913
trainer/QTargetWithReg Std                   77.1565
trainer/QTargetWithReg Max                  429.562
trainer/QTargetWithReg Min                    2.65277
trainer/PolicyLossWithoutReg Mean           341.295
trainer/PolicyLossWithoutReg Std             80.7721
trainer/PolicyLossWithoutReg Max            428.966
trainer/PolicyLossWithoutReg Min           -132.72
exploration/num steps total              892000
exploration/num paths total                1690
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75855
exploration/Rewards Std                       1.06131
exploration/Rewards Max                       6.98968
exploration/Rewards Min                      -0.777911
exploration/Returns Mean                   4758.55
exploration/Returns Std                       0
exploration/Returns Max                    4758.55
exploration/Returns Min                    4758.55
exploration/Num Paths                         1
exploration/Average Returns                4758.55
evaluation_0/num steps total                  6.95407e+06
evaluation_0/num paths total              10597
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70209
evaluation_0/Rewards Std                      1.01132
evaluation_0/Rewards Max                      7.39785
evaluation_0/Rewards Min                     -0.65943
evaluation_0/Returns Mean                  4702.09
evaluation_0/Returns Std                     49.9621
evaluation_0/Returns Max                   4787.23
evaluation_0/Returns Min                   4614.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4702.09
time/epoch (s)                                0
time/total (s)                            13444.5
Epoch                                       887
---------------------------------------  ----------------
2022-11-16 19:59:02.253799 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 888 finished
---------------------------------------  ----------------
epoch                                       888
total_step                               893000
replay_pool/size                         893000
trainer/alpha                                 0.0602471
trainer/alpha_loss                            1.55809
trainer/entropy                              -6.55455
trainer/qf_loss                              20.6651
trainer/policy_loss                        -355.05
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.445
trainer/entropy_penalty                      -0.394892
trainer/entropy_percentage                   -0.00111098
trainer/Q1Pred Mean                         355.396
trainer/Q1Pred Std                           60.1161
trainer/Q1Pred Max                          424.092
trainer/Q1Pred Min                          112.21
trainer/Q2Pred Mean                         355.61
trainer/Q2Pred Std                           59.6663
trainer/Q2Pred Max                          425.478
trainer/Q2Pred Min                          117.67
trainer/QTargetWithReg Mean                 354.426
trainer/QTargetWithReg Std                   60.273
trainer/QTargetWithReg Max                  422.54
trainer/QTargetWithReg Min                  120.758
trainer/PolicyLossWithoutReg Mean           355.445
trainer/PolicyLossWithoutReg Std             59.1801
trainer/PolicyLossWithoutReg Max            425.316
trainer/PolicyLossWithoutReg Min            121.672
exploration/num steps total              893000
exploration/num paths total                1691
exploration/path length this epoch Mean     763
exploration/path length this epoch Std        0
exploration/path length this epoch Max      763
exploration/path length this epoch Min      763
exploration/Rewards Mean                      4.43015
exploration/Rewards Std                       1.16921
exploration/Rewards Max                       7.16776
exploration/Rewards Min                      -0.684816
exploration/Returns Mean                   3380.21
exploration/Returns Std                       0
exploration/Returns Max                    3380.21
exploration/Returns Min                    3380.21
exploration/Num Paths                         1
exploration/Average Returns                3380.21
evaluation_0/num steps total                  6.96207e+06
evaluation_0/num paths total              10605
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83823
evaluation_0/Rewards Std                      0.974564
evaluation_0/Rewards Max                      7.59929
evaluation_0/Rewards Min                     -0.777495
evaluation_0/Returns Mean                  4838.23
evaluation_0/Returns Std                     92.3199
evaluation_0/Returns Max                   4992.67
evaluation_0/Returns Min                   4710.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4838.23
time/epoch (s)                                0
time/total (s)                            13459.1
Epoch                                       888
---------------------------------------  ----------------
2022-11-16 19:59:17.341166 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 889 finished
---------------------------------------  ----------------
epoch                                       889
total_step                               894000
replay_pool/size                         894000
trainer/alpha                                 0.0592277
trainer/alpha_loss                           -2.26764
trainer/entropy                              -5.19762
trainer/qf_loss                              24.3558
trainer/policy_loss                        -347.185
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.493
trainer/entropy_penalty                      -0.307843
trainer/entropy_percentage                   -0.000885897
trainer/Q1Pred Mean                         346.67
trainer/Q1Pred Std                           67.6962
trainer/Q1Pred Max                          426.87
trainer/Q1Pred Min                           19.7158
trainer/Q2Pred Mean                         346.742
trainer/Q2Pred Std                           68.0024
trainer/Q2Pred Max                          427.448
trainer/Q2Pred Min                           19.2752
trainer/QTargetWithReg Mean                 346.324
trainer/QTargetWithReg Std                   68.4699
trainer/QTargetWithReg Max                  427.258
trainer/QTargetWithReg Min                   12.8427
trainer/PolicyLossWithoutReg Mean           347.493
trainer/PolicyLossWithoutReg Std             66.9884
trainer/PolicyLossWithoutReg Max            426.367
trainer/PolicyLossWithoutReg Min             11.6228
exploration/num steps total              894000
exploration/num paths total                1692
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51644
exploration/Rewards Std                       0.982091
exploration/Rewards Max                       6.70437
exploration/Rewards Min                      -0.777446
exploration/Returns Mean                   4516.44
exploration/Returns Std                       0
exploration/Returns Max                    4516.44
exploration/Returns Min                    4516.44
exploration/Num Paths                         1
exploration/Average Returns                4516.44
evaluation_0/num steps total                  6.97007e+06
evaluation_0/num paths total              10613
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78269
evaluation_0/Rewards Std                      1.06232
evaluation_0/Rewards Max                      7.24835
evaluation_0/Rewards Min                     -0.532909
evaluation_0/Returns Mean                  4782.69
evaluation_0/Returns Std                     87.8741
evaluation_0/Returns Max                   4888.52
evaluation_0/Returns Min                   4631.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4782.69
time/epoch (s)                                0
time/total (s)                            13474.2
Epoch                                       889
---------------------------------------  ----------------
2022-11-16 19:59:32.461361 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 890 finished
---------------------------------------  ----------------
epoch                                       890
total_step                               895000
replay_pool/size                         895000
trainer/alpha                                 0.0584912
trainer/alpha_loss                           -0.604445
trainer/entropy                              -5.78709
trainer/qf_loss                              16.3068
trainer/policy_loss                        -349.564
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.902
trainer/entropy_penalty                      -0.338494
trainer/entropy_percentage                   -0.000967395
trainer/Q1Pred Mean                         349.248
trainer/Q1Pred Std                           72.3043
trainer/Q1Pred Max                          431.005
trainer/Q1Pred Min                          -29.2108
trainer/Q2Pred Mean                         349.888
trainer/Q2Pred Std                           73.2041
trainer/Q2Pred Max                          431.456
trainer/Q2Pred Min                          -28.2035
trainer/QTargetWithReg Mean                 350.25
trainer/QTargetWithReg Std                   72.8353
trainer/QTargetWithReg Max                  431.431
trainer/QTargetWithReg Min                  -27.8288
trainer/PolicyLossWithoutReg Mean           349.902
trainer/PolicyLossWithoutReg Std             72.7707
trainer/PolicyLossWithoutReg Max            431.705
trainer/PolicyLossWithoutReg Min            -30.6004
exploration/num steps total              895000
exploration/num paths total                1693
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68232
exploration/Rewards Std                       1.10844
exploration/Rewards Max                       7.22967
exploration/Rewards Min                      -0.450586
exploration/Returns Mean                   4682.32
exploration/Returns Std                       0
exploration/Returns Max                    4682.32
exploration/Returns Min                    4682.32
exploration/Num Paths                         1
exploration/Average Returns                4682.32
evaluation_0/num steps total                  6.97807e+06
evaluation_0/num paths total              10621
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72203
evaluation_0/Rewards Std                      1.03806
evaluation_0/Rewards Max                      7.47854
evaluation_0/Rewards Min                     -0.603023
evaluation_0/Returns Mean                  4722.03
evaluation_0/Returns Std                     82.2772
evaluation_0/Returns Max                   4839.93
evaluation_0/Returns Min                   4585.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4722.03
time/epoch (s)                                0
time/total (s)                            13489.3
Epoch                                       890
---------------------------------------  ----------------
2022-11-16 19:59:47.437289 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 891 finished
---------------------------------------  ----------------
epoch                                       891
total_step                               896000
replay_pool/size                         896000
trainer/alpha                                 0.0584521
trainer/alpha_loss                           -1.44461
trainer/entropy                              -5.49123
trainer/qf_loss                              44.1095
trainer/policy_loss                        -358.547
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         358.868
trainer/entropy_penalty                      -0.320974
trainer/entropy_percentage                   -0.000894408
trainer/Q1Pred Mean                         358.332
trainer/Q1Pred Std                           66.3324
trainer/Q1Pred Max                          441.605
trainer/Q1Pred Min                           11.1153
trainer/Q2Pred Mean                         357.395
trainer/Q2Pred Std                           66.2749
trainer/Q2Pred Max                          438.721
trainer/Q2Pred Min                           11.3603
trainer/QTargetWithReg Mean                 357.566
trainer/QTargetWithReg Std                   66.4017
trainer/QTargetWithReg Max                  440.232
trainer/QTargetWithReg Min                   10.2203
trainer/PolicyLossWithoutReg Mean           358.868
trainer/PolicyLossWithoutReg Std             65.7169
trainer/PolicyLossWithoutReg Max            440.463
trainer/PolicyLossWithoutReg Min              6.55202
exploration/num steps total              896000
exploration/num paths total                1694
exploration/path length this epoch Mean     911
exploration/path length this epoch Std        0
exploration/path length this epoch Max      911
exploration/path length this epoch Min      911
exploration/Rewards Mean                      4.54919
exploration/Rewards Std                       1.09243
exploration/Rewards Max                       7.01039
exploration/Rewards Min                      -0.52509
exploration/Returns Mean                   4144.31
exploration/Returns Std                       0
exploration/Returns Max                    4144.31
exploration/Returns Min                    4144.31
exploration/Num Paths                         1
exploration/Average Returns                4144.31
evaluation_0/num steps total                  6.98607e+06
evaluation_0/num paths total              10629
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69272
evaluation_0/Rewards Std                      1.10712
evaluation_0/Rewards Max                      7.4485
evaluation_0/Rewards Min                     -0.855396
evaluation_0/Returns Mean                  4692.72
evaluation_0/Returns Std                    133.153
evaluation_0/Returns Max                   4908.99
evaluation_0/Returns Min                   4403.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4692.72
time/epoch (s)                                0
time/total (s)                            13504.3
Epoch                                       891
---------------------------------------  ----------------
2022-11-16 20:00:02.370538 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 892 finished
---------------------------------------  ----------------
epoch                                       892
total_step                               897000
replay_pool/size                         897000
trainer/alpha                                 0.0592414
trainer/alpha_loss                            0.619751
trainer/entropy                              -6.21929
trainer/qf_loss                              17.8354
trainer/policy_loss                        -350.869
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.237
trainer/entropy_penalty                      -0.36844
trainer/entropy_percentage                   -0.00104898
trainer/Q1Pred Mean                         350.845
trainer/Q1Pred Std                           72.9371
trainer/Q1Pred Max                          426.648
trainer/Q1Pred Min                            5.36543
trainer/Q2Pred Mean                         350.755
trainer/Q2Pred Std                           72.7779
trainer/Q2Pred Max                          427.275
trainer/Q2Pred Min                           12.3917
trainer/QTargetWithReg Mean                 350.325
trainer/QTargetWithReg Std                   73.0927
trainer/QTargetWithReg Max                  426.422
trainer/QTargetWithReg Min                    3.25136
trainer/PolicyLossWithoutReg Mean           351.237
trainer/PolicyLossWithoutReg Std             71.973
trainer/PolicyLossWithoutReg Max            427.176
trainer/PolicyLossWithoutReg Min             17.6638
exploration/num steps total              897000
exploration/num paths total                1696
exploration/path length this epoch Mean     443.5
exploration/path length this epoch Std      115.5
exploration/path length this epoch Max      559
exploration/path length this epoch Min      328
exploration/Rewards Mean                      4.33125
exploration/Rewards Std                       1.33933
exploration/Rewards Max                       6.94775
exploration/Rewards Min                      -0.909911
exploration/Returns Mean                   1920.91
exploration/Returns Std                     656.631
exploration/Returns Max                    2577.54
exploration/Returns Min                    1264.28
exploration/Num Paths                         2
exploration/Average Returns                1920.91
evaluation_0/num steps total                  6.99407e+06
evaluation_0/num paths total              10637
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70449
evaluation_0/Rewards Std                      0.962276
evaluation_0/Rewards Max                      7.34547
evaluation_0/Rewards Min                     -0.842298
evaluation_0/Returns Mean                  4704.49
evaluation_0/Returns Std                     57.3767
evaluation_0/Returns Max                   4768.88
evaluation_0/Returns Min                   4610.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4704.49
time/epoch (s)                                0
time/total (s)                            13519.2
Epoch                                       892
---------------------------------------  ----------------
2022-11-16 20:00:17.529407 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 893 finished
---------------------------------------  ----------------
epoch                                       893
total_step                               898000
replay_pool/size                         898000
trainer/alpha                                 0.0586588
trainer/alpha_loss                           -0.379057
trainer/entropy                              -5.86633
trainer/qf_loss                              20.1935
trainer/policy_loss                        -349.524
trainer/adversary_policy_loss                16.7855
trainer/policy_loss_without_entropy         349.868
trainer/entropy_penalty                      -0.344112
trainer/entropy_percentage                   -0.000983548
trainer/Q1Pred Mean                         348.817
trainer/Q1Pred Std                           74.7586
trainer/Q1Pred Max                          429.624
trainer/Q1Pred Min                           21.4556
trainer/Q2Pred Mean                         348.447
trainer/Q2Pred Std                           74.8837
trainer/Q2Pred Max                          431.126
trainer/Q2Pred Min                           22.0009
trainer/QTargetWithReg Mean                 349.099
trainer/QTargetWithReg Std                   75.7817
trainer/QTargetWithReg Max                  432.491
trainer/QTargetWithReg Min                   19.6994
trainer/PolicyLossWithoutReg Mean           349.868
trainer/PolicyLossWithoutReg Std             74.0623
trainer/PolicyLossWithoutReg Max            430.31
trainer/PolicyLossWithoutReg Min             28.9854
exploration/num steps total              898000
exploration/num paths total                1697
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64123
exploration/Rewards Std                       1.01139
exploration/Rewards Max                       7.06371
exploration/Rewards Min                      -0.629726
exploration/Returns Mean                   4641.23
exploration/Returns Std                       0
exploration/Returns Max                    4641.23
exploration/Returns Min                    4641.23
exploration/Num Paths                         1
exploration/Average Returns                4641.23
evaluation_0/num steps total                  7.00207e+06
evaluation_0/num paths total              10645
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81807
evaluation_0/Rewards Std                      1.07748
evaluation_0/Rewards Max                      7.49539
evaluation_0/Rewards Min                     -0.83131
evaluation_0/Returns Mean                  4818.07
evaluation_0/Returns Std                    124.032
evaluation_0/Returns Max                   5023.48
evaluation_0/Returns Min                   4597.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4818.07
time/epoch (s)                                0
time/total (s)                            13534.4
Epoch                                       893
---------------------------------------  ----------------
2022-11-16 20:00:32.332932 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 894 finished
---------------------------------------  ----------------
epoch                                       894
total_step                               899000
replay_pool/size                         899000
trainer/alpha                                 0.0588291
trainer/alpha_loss                           -1.36695
trainer/entropy                              -5.51749
trainer/qf_loss                              27.6273
trainer/policy_loss                        -352
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.324
trainer/entropy_penalty                      -0.324589
trainer/entropy_percentage                   -0.00092128
trainer/Q1Pred Mean                         351.522
trainer/Q1Pred Std                           64.8656
trainer/Q1Pred Max                          431.68
trainer/Q1Pred Min                           18.1699
trainer/Q2Pred Mean                         351.455
trainer/Q2Pred Std                           65.5682
trainer/Q2Pred Max                          432.463
trainer/Q2Pred Min                           12.2491
trainer/QTargetWithReg Mean                 350.558
trainer/QTargetWithReg Std                   65.9993
trainer/QTargetWithReg Max                  427.17
trainer/QTargetWithReg Min                   12.093
trainer/PolicyLossWithoutReg Mean           352.324
trainer/PolicyLossWithoutReg Std             65.4608
trainer/PolicyLossWithoutReg Max            438.537
trainer/PolicyLossWithoutReg Min             10.4711
exploration/num steps total              899000
exploration/num paths total                1698
exploration/path length this epoch Mean     935
exploration/path length this epoch Std        0
exploration/path length this epoch Max      935
exploration/path length this epoch Min      935
exploration/Rewards Mean                      4.63823
exploration/Rewards Std                       1.03764
exploration/Rewards Max                       7.57349
exploration/Rewards Min                      -0.830524
exploration/Returns Mean                   4336.75
exploration/Returns Std                       0
exploration/Returns Max                    4336.75
exploration/Returns Min                    4336.75
exploration/Num Paths                         1
exploration/Average Returns                4336.75
evaluation_0/num steps total                  7.01007e+06
evaluation_0/num paths total              10653
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91082
evaluation_0/Rewards Std                      1.07301
evaluation_0/Rewards Max                      7.21085
evaluation_0/Rewards Min                     -0.796755
evaluation_0/Returns Mean                  4910.82
evaluation_0/Returns Std                    139.054
evaluation_0/Returns Max                   5045.28
evaluation_0/Returns Min                   4674.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4910.82
time/epoch (s)                                0
time/total (s)                            13549.2
Epoch                                       894
---------------------------------------  ----------------
2022-11-16 20:00:47.154024 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 895 finished
---------------------------------------  ----------------
epoch                                       895
total_step                               900000
replay_pool/size                         900000
trainer/alpha                                 0.0586877
trainer/alpha_loss                           -0.973118
trainer/entropy                              -5.6568
trainer/qf_loss                              14.1447
trainer/policy_loss                        -352.774
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.106
trainer/entropy_penalty                      -0.331985
trainer/entropy_percentage                   -0.000940186
trainer/Q1Pred Mean                         352.638
trainer/Q1Pred Std                           57.575
trainer/Q1Pred Max                          435.496
trainer/Q1Pred Min                           90.0383
trainer/Q2Pred Mean                         352.743
trainer/Q2Pred Std                           57.8516
trainer/Q2Pred Max                          433.76
trainer/Q2Pred Min                           84.6091
trainer/QTargetWithReg Mean                 352.306
trainer/QTargetWithReg Std                   57.7249
trainer/QTargetWithReg Max                  434.324
trainer/QTargetWithReg Min                   95.0747
trainer/PolicyLossWithoutReg Mean           353.106
trainer/PolicyLossWithoutReg Std             56.687
trainer/PolicyLossWithoutReg Max            433.303
trainer/PolicyLossWithoutReg Min             95.4042
exploration/num steps total              900000
exploration/num paths total                1699
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73359
exploration/Rewards Std                       1.03764
exploration/Rewards Max                       7.52442
exploration/Rewards Min                      -0.539141
exploration/Returns Mean                   4733.59
exploration/Returns Std                       0
exploration/Returns Max                    4733.59
exploration/Returns Min                    4733.59
exploration/Num Paths                         1
exploration/Average Returns                4733.59
evaluation_0/num steps total                  7.01807e+06
evaluation_0/num paths total              10661
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86385
evaluation_0/Rewards Std                      1.10545
evaluation_0/Rewards Max                      7.44995
evaluation_0/Rewards Min                     -0.872806
evaluation_0/Returns Mean                  4863.85
evaluation_0/Returns Std                    117.798
evaluation_0/Returns Max                   4992.66
evaluation_0/Returns Min                   4600.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4863.85
time/epoch (s)                                0
time/total (s)                            13564
Epoch                                       895
---------------------------------------  ----------------
2022-11-16 20:01:02.064859 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 896 finished
---------------------------------------  ----------------
epoch                                       896
total_step                               901000
replay_pool/size                         901000
trainer/alpha                                 0.0578339
trainer/alpha_loss                           -1.33421
trainer/entropy                              -5.53189
trainer/qf_loss                              19.0749
trainer/policy_loss                        -355.37
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.69
trainer/entropy_penalty                      -0.319931
trainer/entropy_percentage                   -0.000899466
trainer/Q1Pred Mean                         354.985
trainer/Q1Pred Std                           63.0218
trainer/Q1Pred Max                          427.698
trainer/Q1Pred Min                           65.5097
trainer/Q2Pred Mean                         355.172
trainer/Q2Pred Std                           62.4209
trainer/Q2Pred Max                          426.798
trainer/Q2Pred Min                           82.2871
trainer/QTargetWithReg Mean                 354.245
trainer/QTargetWithReg Std                   62.6884
trainer/QTargetWithReg Max                  426.945
trainer/QTargetWithReg Min                   69.8465
trainer/PolicyLossWithoutReg Mean           355.69
trainer/PolicyLossWithoutReg Std             61.7549
trainer/PolicyLossWithoutReg Max            426.23
trainer/PolicyLossWithoutReg Min             86.8447
exploration/num steps total              901000
exploration/num paths total                1700
exploration/path length this epoch Mean     968
exploration/path length this epoch Std        0
exploration/path length this epoch Max      968
exploration/path length this epoch Min      968
exploration/Rewards Mean                      4.58143
exploration/Rewards Std                       1.06129
exploration/Rewards Max                       7.27601
exploration/Rewards Min                      -0.925783
exploration/Returns Mean                   4434.82
exploration/Returns Std                       0
exploration/Returns Max                    4434.82
exploration/Returns Min                    4434.82
exploration/Num Paths                         1
exploration/Average Returns                4434.82
evaluation_0/num steps total                  7.02607e+06
evaluation_0/num paths total              10669
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75379
evaluation_0/Rewards Std                      1.06425
evaluation_0/Rewards Max                      8.30529
evaluation_0/Rewards Min                     -0.692492
evaluation_0/Returns Mean                  4753.79
evaluation_0/Returns Std                    160.83
evaluation_0/Returns Max                   4958.94
evaluation_0/Returns Min                   4515.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4753.79
time/epoch (s)                                0
time/total (s)                            13578.9
Epoch                                       896
---------------------------------------  ----------------
2022-11-16 20:01:16.997600 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 897 finished
---------------------------------------  ----------------
epoch                                       897
total_step                               902000
replay_pool/size                         902000
trainer/alpha                                 0.059253
trainer/alpha_loss                           -0.693757
trainer/entropy                              -5.7545
trainer/qf_loss                              18.8644
trainer/policy_loss                        -351.332
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.673
trainer/entropy_penalty                      -0.340972
trainer/entropy_percentage                   -0.000969569
trainer/Q1Pred Mean                         351.39
trainer/Q1Pred Std                           64.9188
trainer/Q1Pred Max                          422.925
trainer/Q1Pred Min                            3.39533
trainer/Q2Pred Mean                         351.637
trainer/Q2Pred Std                           64.3249
trainer/Q2Pred Max                          424.863
trainer/Q2Pred Min                            3.92617
trainer/QTargetWithReg Mean                 351.733
trainer/QTargetWithReg Std                   64.2382
trainer/QTargetWithReg Max                  422.775
trainer/QTargetWithReg Min                    3.40603
trainer/PolicyLossWithoutReg Mean           351.673
trainer/PolicyLossWithoutReg Std             63.9375
trainer/PolicyLossWithoutReg Max            421.544
trainer/PolicyLossWithoutReg Min              2.85301
exploration/num steps total              902000
exploration/num paths total                1701
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72157
exploration/Rewards Std                       0.940601
exploration/Rewards Max                       7.39902
exploration/Rewards Min                      -0.627274
exploration/Returns Mean                   4721.57
exploration/Returns Std                       0
exploration/Returns Max                    4721.57
exploration/Returns Min                    4721.57
exploration/Num Paths                         1
exploration/Average Returns                4721.57
evaluation_0/num steps total                  7.03407e+06
evaluation_0/num paths total              10677
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.50893
evaluation_0/Rewards Std                      0.962221
evaluation_0/Rewards Max                      7.31218
evaluation_0/Rewards Min                     -0.871233
evaluation_0/Returns Mean                  4508.93
evaluation_0/Returns Std                    123.214
evaluation_0/Returns Max                   4760.59
evaluation_0/Returns Min                   4297.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4508.93
time/epoch (s)                                0
time/total (s)                            13593.9
Epoch                                       897
---------------------------------------  ----------------
2022-11-16 20:01:31.788559 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 898 finished
---------------------------------------  ----------------
epoch                                       898
total_step                               903000
replay_pool/size                         903000
trainer/alpha                                 0.0571795
trainer/alpha_loss                           -1.05933
trainer/entropy                              -5.6298
trainer/qf_loss                              24.691
trainer/policy_loss                        -354.299
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.621
trainer/entropy_penalty                      -0.321909
trainer/entropy_percentage                   -0.000907754
trainer/Q1Pred Mean                         353.788
trainer/Q1Pred Std                           57.8456
trainer/Q1Pred Max                          432.633
trainer/Q1Pred Min                           42.3482
trainer/Q2Pred Mean                         354.045
trainer/Q2Pred Std                           58.3004
trainer/Q2Pred Max                          431.573
trainer/Q2Pred Min                           35.3849
trainer/QTargetWithReg Mean                 354.031
trainer/QTargetWithReg Std                   58.3338
trainer/QTargetWithReg Max                  431.53
trainer/QTargetWithReg Min                   40.8335
trainer/PolicyLossWithoutReg Mean           354.621
trainer/PolicyLossWithoutReg Std             57.1407
trainer/PolicyLossWithoutReg Max            432.062
trainer/PolicyLossWithoutReg Min             51.5153
exploration/num steps total              903000
exploration/num paths total                1702
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77796
exploration/Rewards Std                       1.03166
exploration/Rewards Max                       7.34984
exploration/Rewards Min                      -0.805967
exploration/Returns Mean                   4777.96
exploration/Returns Std                       0
exploration/Returns Max                    4777.96
exploration/Returns Min                    4777.96
exploration/Num Paths                         1
exploration/Average Returns                4777.96
evaluation_0/num steps total                  7.04207e+06
evaluation_0/num paths total              10685
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74892
evaluation_0/Rewards Std                      1.13049
evaluation_0/Rewards Max                      7.86604
evaluation_0/Rewards Min                     -0.767772
evaluation_0/Returns Mean                  4748.92
evaluation_0/Returns Std                     73.6252
evaluation_0/Returns Max                   4911.04
evaluation_0/Returns Min                   4666.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4748.92
time/epoch (s)                                0
time/total (s)                            13608.7
Epoch                                       898
---------------------------------------  ----------------
2022-11-16 20:01:46.576899 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 899 finished
---------------------------------------  ----------------
epoch                                       899
total_step                               904000
replay_pool/size                         904000
trainer/alpha                                 0.0593286
trainer/alpha_loss                           -0.134463
trainer/entropy                              -5.9524
trainer/qf_loss                              19.2639
trainer/policy_loss                        -347.994
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.347
trainer/entropy_penalty                      -0.353148
trainer/entropy_percentage                   -0.00101378
trainer/Q1Pred Mean                         347.015
trainer/Q1Pred Std                           72.3669
trainer/Q1Pred Max                          424.934
trainer/Q1Pred Min                          -19.6443
trainer/Q2Pred Mean                         347.71
trainer/Q2Pred Std                           72.3316
trainer/Q2Pred Max                          425.427
trainer/Q2Pred Min                          -19.4967
trainer/QTargetWithReg Mean                 348.108
trainer/QTargetWithReg Std                   72.4598
trainer/QTargetWithReg Max                  426.732
trainer/QTargetWithReg Min                  -20.3332
trainer/PolicyLossWithoutReg Mean           348.347
trainer/PolicyLossWithoutReg Std             70.6722
trainer/PolicyLossWithoutReg Max            425.075
trainer/PolicyLossWithoutReg Min             15.8707
exploration/num steps total              904000
exploration/num paths total                1703
exploration/path length this epoch Mean     892
exploration/path length this epoch Std        0
exploration/path length this epoch Max      892
exploration/path length this epoch Min      892
exploration/Rewards Mean                      4.78987
exploration/Rewards Std                       1.11709
exploration/Rewards Max                       7.17419
exploration/Rewards Min                      -0.659194
exploration/Returns Mean                   4272.57
exploration/Returns Std                       0
exploration/Returns Max                    4272.57
exploration/Returns Min                    4272.57
exploration/Num Paths                         1
exploration/Average Returns                4272.57
evaluation_0/num steps total                  7.05007e+06
evaluation_0/num paths total              10693
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84904
evaluation_0/Rewards Std                      0.991229
evaluation_0/Rewards Max                      7.66001
evaluation_0/Rewards Min                     -0.757986
evaluation_0/Returns Mean                  4849.04
evaluation_0/Returns Std                    152.883
evaluation_0/Returns Max                   5063.15
evaluation_0/Returns Min                   4611.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4849.04
time/epoch (s)                                0
time/total (s)                            13623.4
Epoch                                       899
---------------------------------------  ----------------
2022-11-16 20:02:01.534272 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 900 finished
---------------------------------------  ----------------
epoch                                       900
total_step                               905000
replay_pool/size                         905000
trainer/alpha                                 0.0585767
trainer/alpha_loss                            0.79117
trainer/entropy                              -6.27883
trainer/qf_loss                              17.1551
trainer/policy_loss                        -358.065
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         358.433
trainer/entropy_penalty                      -0.367793
trainer/entropy_percentage                   -0.00102611
trainer/Q1Pred Mean                         357.586
trainer/Q1Pred Std                           68.1923
trainer/Q1Pred Max                          429.007
trainer/Q1Pred Min                           16.0721
trainer/Q2Pred Mean                         357.722
trainer/Q2Pred Std                           68.5665
trainer/Q2Pred Max                          434.979
trainer/Q2Pred Min                           13.704
trainer/QTargetWithReg Mean                 357.55
trainer/QTargetWithReg Std                   68.6771
trainer/QTargetWithReg Max                  432.875
trainer/QTargetWithReg Min                   13.9817
trainer/PolicyLossWithoutReg Mean           358.433
trainer/PolicyLossWithoutReg Std             67.2393
trainer/PolicyLossWithoutReg Max            429.373
trainer/PolicyLossWithoutReg Min             17.3587
exploration/num steps total              905000
exploration/num paths total                1706
exploration/path length this epoch Mean     320.667
exploration/path length this epoch Std       60.4667
exploration/path length this epoch Max      393
exploration/path length this epoch Min      245
exploration/Rewards Mean                      3.97449
exploration/Rewards Std                       1.23197
exploration/Rewards Max                       7.23434
exploration/Rewards Min                      -0.667092
exploration/Returns Mean                   1274.49
exploration/Returns Std                     291.31
exploration/Returns Max                    1638.1
exploration/Returns Min                     924.956
exploration/Num Paths                         3
exploration/Average Returns                1274.49
evaluation_0/num steps total                  7.05807e+06
evaluation_0/num paths total              10701
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07326
evaluation_0/Rewards Std                      1.09272
evaluation_0/Rewards Max                      8.10489
evaluation_0/Rewards Min                     -0.838768
evaluation_0/Returns Mean                  5073.26
evaluation_0/Returns Std                     65.7874
evaluation_0/Returns Max                   5176.98
evaluation_0/Returns Min                   4977.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5073.26
time/epoch (s)                                0
time/total (s)                            13638.4
Epoch                                       900
---------------------------------------  ----------------
2022-11-16 20:02:16.377472 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 901 finished
---------------------------------------  ----------------
epoch                                       901
total_step                               906000
replay_pool/size                         906000
trainer/alpha                                 0.0582541
trainer/alpha_loss                           -0.900875
trainer/entropy                              -5.68309
trainer/qf_loss                              23.839
trainer/policy_loss                        -352.013
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.344
trainer/entropy_penalty                      -0.331063
trainer/entropy_percentage                   -0.000939602
trainer/Q1Pred Mean                         350.445
trainer/Q1Pred Std                           61.749
trainer/Q1Pred Max                          429.24
trainer/Q1Pred Min                           54.9062
trainer/Q2Pred Mean                         350.949
trainer/Q2Pred Std                           61.7538
trainer/Q2Pred Max                          428.082
trainer/Q2Pred Min                           57.2937
trainer/QTargetWithReg Mean                 351.594
trainer/QTargetWithReg Std                   61.9452
trainer/QTargetWithReg Max                  433.425
trainer/QTargetWithReg Min                   47.6001
trainer/PolicyLossWithoutReg Mean           352.344
trainer/PolicyLossWithoutReg Std             60.2095
trainer/PolicyLossWithoutReg Max            429.907
trainer/PolicyLossWithoutReg Min             61.5616
exploration/num steps total              906000
exploration/num paths total                1707
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75038
exploration/Rewards Std                       1.12841
exploration/Rewards Max                       7.27993
exploration/Rewards Min                      -0.853063
exploration/Returns Mean                   4750.38
exploration/Returns Std                       0
exploration/Returns Max                    4750.38
exploration/Returns Min                    4750.38
exploration/Num Paths                         1
exploration/Average Returns                4750.38
evaluation_0/num steps total                  7.06607e+06
evaluation_0/num paths total              10709
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97042
evaluation_0/Rewards Std                      1.07857
evaluation_0/Rewards Max                      7.95529
evaluation_0/Rewards Min                     -0.881528
evaluation_0/Returns Mean                  4970.42
evaluation_0/Returns Std                     75.2832
evaluation_0/Returns Max                   5052.4
evaluation_0/Returns Min                   4831.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4970.42
time/epoch (s)                                0
time/total (s)                            13653.2
Epoch                                       901
---------------------------------------  ----------------
2022-11-16 20:02:31.330669 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 902 finished
---------------------------------------  ----------------
epoch                                       902
total_step                               907000
replay_pool/size                         907000
trainer/alpha                                 0.0594217
trainer/alpha_loss                            0.186538
trainer/entropy                              -6.06607
trainer/qf_loss                              28.8097
trainer/policy_loss                        -347.992
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.353
trainer/entropy_penalty                      -0.360456
trainer/entropy_percentage                   -0.00103474
trainer/Q1Pred Mean                         346.904
trainer/Q1Pred Std                           63.9734
trainer/Q1Pred Max                          428.834
trainer/Q1Pred Min                           70.8581
trainer/Q2Pred Mean                         346.815
trainer/Q2Pred Std                           64.4219
trainer/Q2Pred Max                          429.707
trainer/Q2Pred Min                           76.5036
trainer/QTargetWithReg Mean                 348.002
trainer/QTargetWithReg Std                   65.338
trainer/QTargetWithReg Max                  430.536
trainer/QTargetWithReg Min                   67.1018
trainer/PolicyLossWithoutReg Mean           348.353
trainer/PolicyLossWithoutReg Std             63.5398
trainer/PolicyLossWithoutReg Max            428.867
trainer/PolicyLossWithoutReg Min             67.6061
exploration/num steps total              907000
exploration/num paths total                1708
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.20875
exploration/Rewards Std                       1.28611
exploration/Rewards Max                       7.20636
exploration/Rewards Min                      -0.379353
exploration/Returns Mean                   4208.75
exploration/Returns Std                       0
exploration/Returns Max                    4208.75
exploration/Returns Min                    4208.75
exploration/Num Paths                         1
exploration/Average Returns                4208.75
evaluation_0/num steps total                  7.07407e+06
evaluation_0/num paths total              10717
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94567
evaluation_0/Rewards Std                      1.16924
evaluation_0/Rewards Max                      7.88211
evaluation_0/Rewards Min                     -0.808848
evaluation_0/Returns Mean                  4945.67
evaluation_0/Returns Std                     60.6485
evaluation_0/Returns Max                   5043.25
evaluation_0/Returns Min                   4841.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4945.67
time/epoch (s)                                0
time/total (s)                            13668.2
Epoch                                       902
---------------------------------------  ----------------
2022-11-16 20:02:46.217851 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 903 finished
---------------------------------------  ----------------
epoch                                       903
total_step                               908000
replay_pool/size                         908000
trainer/alpha                                 0.0589221
trainer/alpha_loss                           -0.504392
trainer/entropy                              -5.82188
trainer/qf_loss                              20.144
trainer/policy_loss                        -353.048
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.391
trainer/entropy_penalty                      -0.343037
trainer/entropy_percentage                   -0.0009707
trainer/Q1Pred Mean                         352.409
trainer/Q1Pred Std                           61.4462
trainer/Q1Pred Max                          425.088
trainer/Q1Pred Min                           15.9401
trainer/Q2Pred Mean                         353.643
trainer/Q2Pred Std                           61.1075
trainer/Q2Pred Max                          429.401
trainer/Q2Pred Min                            8.37019
trainer/QTargetWithReg Mean                 353.345
trainer/QTargetWithReg Std                   60.577
trainer/QTargetWithReg Max                  429.646
trainer/QTargetWithReg Min                   13.7359
trainer/PolicyLossWithoutReg Mean           353.391
trainer/PolicyLossWithoutReg Std             60.7976
trainer/PolicyLossWithoutReg Max            426.329
trainer/PolicyLossWithoutReg Min             14.9165
exploration/num steps total              908000
exploration/num paths total                1709
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93518
exploration/Rewards Std                       1.13159
exploration/Rewards Max                       7.6403
exploration/Rewards Min                      -0.454699
exploration/Returns Mean                   4935.18
exploration/Returns Std                       0
exploration/Returns Max                    4935.18
exploration/Returns Min                    4935.18
exploration/Num Paths                         1
exploration/Average Returns                4935.18
evaluation_0/num steps total                  7.08207e+06
evaluation_0/num paths total              10725
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98024
evaluation_0/Rewards Std                      1.06699
evaluation_0/Rewards Max                      8.21408
evaluation_0/Rewards Min                     -0.904252
evaluation_0/Returns Mean                  4980.24
evaluation_0/Returns Std                     49.7462
evaluation_0/Returns Max                   5040.82
evaluation_0/Returns Min                   4910.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4980.24
time/epoch (s)                                0
time/total (s)                            13683.1
Epoch                                       903
---------------------------------------  ----------------
2022-11-16 20:03:01.184648 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 904 finished
---------------------------------------  ----------------
epoch                                       904
total_step                               909000
replay_pool/size                         909000
trainer/alpha                                 0.0585859
trainer/alpha_loss                           -0.0544394
trainer/entropy                              -5.98081
trainer/qf_loss                              27.9403
trainer/policy_loss                        -351.637
trainer/adversary_policy_loss                16.9022
trainer/policy_loss_without_entropy         351.988
trainer/entropy_penalty                      -0.350391
trainer/entropy_percentage                   -0.000995464
trainer/Q1Pred Mean                         350.368
trainer/Q1Pred Std                           67.3108
trainer/Q1Pred Max                          429.536
trainer/Q1Pred Min                            5.26724
trainer/Q2Pred Mean                         350.221
trainer/Q2Pred Std                           67.4642
trainer/Q2Pred Max                          433.568
trainer/Q2Pred Min                            6.25365
trainer/QTargetWithReg Mean                 351.357
trainer/QTargetWithReg Std                   67.0376
trainer/QTargetWithReg Max                  430.271
trainer/QTargetWithReg Min                    2.99254
trainer/PolicyLossWithoutReg Mean           351.988
trainer/PolicyLossWithoutReg Std             66.4631
trainer/PolicyLossWithoutReg Max            431.623
trainer/PolicyLossWithoutReg Min              4.19275
exploration/num steps total              909000
exploration/num paths total                1711
exploration/path length this epoch Mean     386
exploration/path length this epoch Std      104
exploration/path length this epoch Max      490
exploration/path length this epoch Min      282
exploration/Rewards Mean                      3.92695
exploration/Rewards Std                       1.2987
exploration/Rewards Max                       7.15051
exploration/Rewards Min                      -0.903779
exploration/Returns Mean                   1515.8
exploration/Returns Std                     493.257
exploration/Returns Max                    2009.06
exploration/Returns Min                    1022.55
exploration/Num Paths                         2
exploration/Average Returns                1515.8
evaluation_0/num steps total                  7.09007e+06
evaluation_0/num paths total              10733
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87357
evaluation_0/Rewards Std                      1.00342
evaluation_0/Rewards Max                      7.70514
evaluation_0/Rewards Min                     -0.835965
evaluation_0/Returns Mean                  4873.57
evaluation_0/Returns Std                     86.1718
evaluation_0/Returns Max                   5009.82
evaluation_0/Returns Min                   4732.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4873.57
time/epoch (s)                                0
time/total (s)                            13698
Epoch                                       904
---------------------------------------  ----------------
2022-11-16 20:03:16.283551 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 905 finished
---------------------------------------  ----------------
epoch                                       905
total_step                               910000
replay_pool/size                         910000
trainer/alpha                                 0.0591582
trainer/alpha_loss                           -1.1036
trainer/entropy                              -5.6097
trainer/qf_loss                              20.0467
trainer/policy_loss                        -350.501
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.833
trainer/entropy_penalty                      -0.33186
trainer/entropy_percentage                   -0.000945919
trainer/Q1Pred Mean                         350.834
trainer/Q1Pred Std                           69.3528
trainer/Q1Pred Max                          439.747
trainer/Q1Pred Min                          -24.589
trainer/Q2Pred Mean                         350.974
trainer/Q2Pred Std                           69.184
trainer/Q2Pred Max                          438.463
trainer/Q2Pred Min                          -20.9305
trainer/QTargetWithReg Mean                 351.342
trainer/QTargetWithReg Std                   68.8975
trainer/QTargetWithReg Max                  440.518
trainer/QTargetWithReg Min                    0.138618
trainer/PolicyLossWithoutReg Mean           350.833
trainer/PolicyLossWithoutReg Std             68.3229
trainer/PolicyLossWithoutReg Max            438.796
trainer/PolicyLossWithoutReg Min            -11.5368
exploration/num steps total              910000
exploration/num paths total                1712
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72696
exploration/Rewards Std                       0.986672
exploration/Rewards Max                       7.16088
exploration/Rewards Min                      -0.92669
exploration/Returns Mean                   4726.96
exploration/Returns Std                       0
exploration/Returns Max                    4726.96
exploration/Returns Min                    4726.96
exploration/Num Paths                         1
exploration/Average Returns                4726.96
evaluation_0/num steps total                  7.09807e+06
evaluation_0/num paths total              10741
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85009
evaluation_0/Rewards Std                      0.933986
evaluation_0/Rewards Max                      7.04389
evaluation_0/Rewards Min                     -0.737428
evaluation_0/Returns Mean                  4850.09
evaluation_0/Returns Std                     54.365
evaluation_0/Returns Max                   4910.75
evaluation_0/Returns Min                   4731.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4850.09
time/epoch (s)                                0
time/total (s)                            13713.1
Epoch                                       905
---------------------------------------  ----------------
2022-11-16 20:03:31.354612 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 906 finished
---------------------------------------  ----------------
epoch                                       906
total_step                               911000
replay_pool/size                         911000
trainer/alpha                                 0.0583068
trainer/alpha_loss                            1.05843
trainer/entropy                              -6.3724
trainer/qf_loss                              19.7714
trainer/policy_loss                        -345.821
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.193
trainer/entropy_penalty                      -0.371555
trainer/entropy_percentage                   -0.00107326
trainer/Q1Pred Mean                         346.098
trainer/Q1Pred Std                           71.6438
trainer/Q1Pred Max                          432.667
trainer/Q1Pred Min                           26.0698
trainer/Q2Pred Mean                         345.98
trainer/Q2Pred Std                           71.0007
trainer/Q2Pred Max                          430.765
trainer/Q2Pred Min                           19.1407
trainer/QTargetWithReg Mean                 345.699
trainer/QTargetWithReg Std                   71.2941
trainer/QTargetWithReg Max                  430.166
trainer/QTargetWithReg Min                   16.819
trainer/PolicyLossWithoutReg Mean           346.193
trainer/PolicyLossWithoutReg Std             70.941
trainer/PolicyLossWithoutReg Max            430.734
trainer/PolicyLossWithoutReg Min             26.1714
exploration/num steps total              911000
exploration/num paths total                1713
exploration/path length this epoch Mean     971
exploration/path length this epoch Std        0
exploration/path length this epoch Max      971
exploration/path length this epoch Min      971
exploration/Rewards Mean                      4.56013
exploration/Rewards Std                       1.14831
exploration/Rewards Max                       6.76622
exploration/Rewards Min                      -0.609159
exploration/Returns Mean                   4427.89
exploration/Returns Std                       0
exploration/Returns Max                    4427.89
exploration/Returns Min                    4427.89
exploration/Num Paths                         1
exploration/Average Returns                4427.89
evaluation_0/num steps total                  7.10607e+06
evaluation_0/num paths total              10749
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88916
evaluation_0/Rewards Std                      1.15717
evaluation_0/Rewards Max                      8.03133
evaluation_0/Rewards Min                     -0.625707
evaluation_0/Returns Mean                  4889.16
evaluation_0/Returns Std                     94.4302
evaluation_0/Returns Max                   4994.18
evaluation_0/Returns Min                   4683.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4889.16
time/epoch (s)                                0
time/total (s)                            13728.2
Epoch                                       906
---------------------------------------  ----------------
2022-11-16 20:03:46.409274 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 907 finished
---------------------------------------  ----------------
epoch                                       907
total_step                               912000
replay_pool/size                         912000
trainer/alpha                                 0.0572503
trainer/alpha_loss                           -1.23241
trainer/entropy                              -5.5691
trainer/qf_loss                              20.2078
trainer/policy_loss                        -352.06
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.379
trainer/entropy_penalty                      -0.318832
trainer/entropy_percentage                   -0.0009048
trainer/Q1Pred Mean                         351.759
trainer/Q1Pred Std                           61.4594
trainer/Q1Pred Max                          423.458
trainer/Q1Pred Min                           29.7144
trainer/Q2Pred Mean                         351.693
trainer/Q2Pred Std                           61.1331
trainer/Q2Pred Max                          424.401
trainer/Q2Pred Min                           26.7753
trainer/QTargetWithReg Mean                 352.145
trainer/QTargetWithReg Std                   60.8051
trainer/QTargetWithReg Max                  425.399
trainer/QTargetWithReg Min                   33.5702
trainer/PolicyLossWithoutReg Mean           352.379
trainer/PolicyLossWithoutReg Std             60.8433
trainer/PolicyLossWithoutReg Max            423.818
trainer/PolicyLossWithoutReg Min             30.3666
exploration/num steps total              912000
exploration/num paths total                1714
exploration/path length this epoch Mean     581
exploration/path length this epoch Std        0
exploration/path length this epoch Max      581
exploration/path length this epoch Min      581
exploration/Rewards Mean                      4.44674
exploration/Rewards Std                       1.13432
exploration/Rewards Max                       7.12391
exploration/Rewards Min                      -0.716234
exploration/Returns Mean                   2583.56
exploration/Returns Std                       0
exploration/Returns Max                    2583.56
exploration/Returns Min                    2583.56
exploration/Num Paths                         1
exploration/Average Returns                2583.56
evaluation_0/num steps total                  7.11407e+06
evaluation_0/num paths total              10757
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01349
evaluation_0/Rewards Std                      1.11554
evaluation_0/Rewards Max                      8.4164
evaluation_0/Rewards Min                     -0.692375
evaluation_0/Returns Mean                  5013.49
evaluation_0/Returns Std                     75.98
evaluation_0/Returns Max                   5130.37
evaluation_0/Returns Min                   4924.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5013.49
time/epoch (s)                                0
time/total (s)                            13743.3
Epoch                                       907
---------------------------------------  ----------------
2022-11-16 20:04:01.468193 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 908 finished
---------------------------------------  ----------------
epoch                                       908
total_step                               913000
replay_pool/size                         913000
trainer/alpha                                 0.0592833
trainer/alpha_loss                            0.14909
trainer/entropy                              -6.05277
trainer/qf_loss                              42.3576
trainer/policy_loss                        -350.605
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.964
trainer/entropy_penalty                      -0.358828
trainer/entropy_percentage                   -0.00102241
trainer/Q1Pred Mean                         348.15
trainer/Q1Pred Std                           62.6931
trainer/Q1Pred Max                          427.331
trainer/Q1Pred Min                           13.9609
trainer/Q2Pred Mean                         348.704
trainer/Q2Pred Std                           62.2854
trainer/Q2Pred Max                          426.425
trainer/Q2Pred Min                            7.00933
trainer/QTargetWithReg Mean                 349.248
trainer/QTargetWithReg Std                   63.1709
trainer/QTargetWithReg Max                  431.362
trainer/QTargetWithReg Min                   -1.05273
trainer/PolicyLossWithoutReg Mean           350.964
trainer/PolicyLossWithoutReg Std             60.7548
trainer/PolicyLossWithoutReg Max            427.609
trainer/PolicyLossWithoutReg Min             11.9807
exploration/num steps total              913000
exploration/num paths total                1715
exploration/path length this epoch Mean     425
exploration/path length this epoch Std        0
exploration/path length this epoch Max      425
exploration/path length this epoch Min      425
exploration/Rewards Mean                      4.45057
exploration/Rewards Std                       1.25826
exploration/Rewards Max                       7.15296
exploration/Rewards Min                      -0.598996
exploration/Returns Mean                   1891.49
exploration/Returns Std                       0
exploration/Returns Max                    1891.49
exploration/Returns Min                    1891.49
exploration/Num Paths                         1
exploration/Average Returns                1891.49
evaluation_0/num steps total                  7.12207e+06
evaluation_0/num paths total              10765
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81204
evaluation_0/Rewards Std                      1.02352
evaluation_0/Rewards Max                      7.48248
evaluation_0/Rewards Min                     -0.446351
evaluation_0/Returns Mean                  4812.04
evaluation_0/Returns Std                     58.3026
evaluation_0/Returns Max                   4920.18
evaluation_0/Returns Min                   4709.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4812.04
time/epoch (s)                                0
time/total (s)                            13758.3
Epoch                                       908
---------------------------------------  ----------------
2022-11-16 20:04:16.108565 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 909 finished
---------------------------------------  ----------------
epoch                                       909
total_step                               914000
replay_pool/size                         914000
trainer/alpha                                 0.0582016
trainer/alpha_loss                           -0.390134
trainer/entropy                              -5.86281
trainer/qf_loss                              20.3036
trainer/policy_loss                        -354.492
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.834
trainer/entropy_penalty                      -0.341225
trainer/entropy_percentage                   -0.000961647
trainer/Q1Pred Mean                         354.594
trainer/Q1Pred Std                           63.0829
trainer/Q1Pred Max                          434.375
trainer/Q1Pred Min                           -7.24787
trainer/Q2Pred Mean                         354.669
trainer/Q2Pred Std                           62.189
trainer/Q2Pred Max                          435.259
trainer/Q2Pred Min                            8.82913
trainer/QTargetWithReg Mean                 354.14
trainer/QTargetWithReg Std                   62.8165
trainer/QTargetWithReg Max                  438.421
trainer/QTargetWithReg Min                    2.79242
trainer/PolicyLossWithoutReg Mean           354.834
trainer/PolicyLossWithoutReg Std             61.8863
trainer/PolicyLossWithoutReg Max            435.129
trainer/PolicyLossWithoutReg Min             14.1627
exploration/num steps total              914000
exploration/num paths total                1716
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.516
exploration/Rewards Std                       1.16452
exploration/Rewards Max                       6.87497
exploration/Rewards Min                      -0.43087
exploration/Returns Mean                   4516
exploration/Returns Std                       0
exploration/Returns Max                    4516
exploration/Returns Min                    4516
exploration/Num Paths                         1
exploration/Average Returns                4516
evaluation_0/num steps total                  7.13007e+06
evaluation_0/num paths total              10773
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87071
evaluation_0/Rewards Std                      0.978947
evaluation_0/Rewards Max                      7.6563
evaluation_0/Rewards Min                     -0.665225
evaluation_0/Returns Mean                  4870.71
evaluation_0/Returns Std                    147.035
evaluation_0/Returns Max                   5077.49
evaluation_0/Returns Min                   4674.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4870.71
time/epoch (s)                                0
time/total (s)                            13773
Epoch                                       909
---------------------------------------  ----------------
2022-11-16 20:04:33.050482 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 910 finished
---------------------------------------  ----------------
epoch                                       910
total_step                               915000
replay_pool/size                         915000
trainer/alpha                                 0.0585092
trainer/alpha_loss                           -1.61221
trainer/entropy                              -5.432
trainer/qf_loss                              30.1467
trainer/policy_loss                        -362.41
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         362.728
trainer/entropy_penalty                      -0.317822
trainer/entropy_percentage                   -0.000876199
trainer/Q1Pred Mean                         361.038
trainer/Q1Pred Std                           56.356
trainer/Q1Pred Max                          430.352
trainer/Q1Pred Min                           29.827
trainer/Q2Pred Mean                         361.162
trainer/Q2Pred Std                           56.5679
trainer/Q2Pred Max                          432.228
trainer/Q2Pred Min                           27.3724
trainer/QTargetWithReg Mean                 362.005
trainer/QTargetWithReg Std                   56.2657
trainer/QTargetWithReg Max                  432.167
trainer/QTargetWithReg Min                   28.4539
trainer/PolicyLossWithoutReg Mean           362.728
trainer/PolicyLossWithoutReg Std             54.9395
trainer/PolicyLossWithoutReg Max            431.888
trainer/PolicyLossWithoutReg Min             25.6387
exploration/num steps total              915000
exploration/num paths total                1717
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60938
exploration/Rewards Std                       1.02897
exploration/Rewards Max                       7.51849
exploration/Rewards Min                      -0.544683
exploration/Returns Mean                   4609.38
exploration/Returns Std                       0
exploration/Returns Max                    4609.38
exploration/Returns Min                    4609.38
exploration/Num Paths                         1
exploration/Average Returns                4609.38
evaluation_0/num steps total                  7.13789e+06
evaluation_0/num paths total              10781
evaluation_0/path length Mean               978
evaluation_0/path length Std                 58.2065
evaluation_0/path length Max               1000
evaluation_0/path length Min                824
evaluation_0/Rewards Mean                     5.00619
evaluation_0/Rewards Std                      1.14313
evaluation_0/Rewards Max                      7.95821
evaluation_0/Rewards Min                     -2.17257
evaluation_0/Returns Mean                  4896.05
evaluation_0/Returns Std                    288.955
evaluation_0/Returns Max                   5104.91
evaluation_0/Returns Min                   4161.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4896.05
time/epoch (s)                                0
time/total (s)                            13789.9
Epoch                                       910
---------------------------------------  ----------------
2022-11-16 20:04:48.387378 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 911 finished
---------------------------------------  ----------------
epoch                                       911
total_step                               916000
replay_pool/size                         916000
trainer/alpha                                 0.0571405
trainer/alpha_loss                            0.168275
trainer/entropy                              -6.05879
trainer/qf_loss                              19.0164
trainer/policy_loss                        -355.333
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.679
trainer/entropy_penalty                      -0.346202
trainer/entropy_percentage                   -0.000973355
trainer/Q1Pred Mean                         353.029
trainer/Q1Pred Std                           67.4533
trainer/Q1Pred Max                          425.446
trainer/Q1Pred Min                            2.69581
trainer/Q2Pred Mean                         353.118
trainer/Q2Pred Std                           67.852
trainer/Q2Pred Max                          425.529
trainer/Q2Pred Min                            9.03068
trainer/QTargetWithReg Mean                 353.375
trainer/QTargetWithReg Std                   67.328
trainer/QTargetWithReg Max                  426.345
trainer/QTargetWithReg Min                   -0.201236
trainer/PolicyLossWithoutReg Mean           355.679
trainer/PolicyLossWithoutReg Std             63.7719
trainer/PolicyLossWithoutReg Max            425.007
trainer/PolicyLossWithoutReg Min             21.2945
exploration/num steps total              916000
exploration/num paths total                1718
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87062
exploration/Rewards Std                       0.95537
exploration/Rewards Max                       6.99362
exploration/Rewards Min                      -0.983729
exploration/Returns Mean                   4870.62
exploration/Returns Std                       0
exploration/Returns Max                    4870.62
exploration/Returns Min                    4870.62
exploration/Num Paths                         1
exploration/Average Returns                4870.62
evaluation_0/num steps total                  7.14589e+06
evaluation_0/num paths total              10789
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66609
evaluation_0/Rewards Std                      1.05582
evaluation_0/Rewards Max                      6.90754
evaluation_0/Rewards Min                     -0.758505
evaluation_0/Returns Mean                  4666.09
evaluation_0/Returns Std                    139.375
evaluation_0/Returns Max                   4871.72
evaluation_0/Returns Min                   4419.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4666.09
time/epoch (s)                                0
time/total (s)                            13805.2
Epoch                                       911
---------------------------------------  ----------------
2022-11-16 20:05:03.393189 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 912 finished
---------------------------------------  ----------------
epoch                                       912
total_step                               917000
replay_pool/size                         917000
trainer/alpha                                 0.0584177
trainer/alpha_loss                           -1.52296
trainer/entropy                              -5.46376
trainer/qf_loss                              20.6261
trainer/policy_loss                        -357.931
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         358.25
trainer/entropy_penalty                      -0.319181
trainer/entropy_percentage                   -0.000890942
trainer/Q1Pred Mean                         358.158
trainer/Q1Pred Std                           60.2574
trainer/Q1Pred Max                          431.56
trainer/Q1Pred Min                           41.1838
trainer/Q2Pred Mean                         358.011
trainer/Q2Pred Std                           60.3539
trainer/Q2Pred Max                          431.06
trainer/Q2Pred Min                           44.0328
trainer/QTargetWithReg Mean                 358.261
trainer/QTargetWithReg Std                   59.9327
trainer/QTargetWithReg Max                  432.688
trainer/QTargetWithReg Min                   39.3269
trainer/PolicyLossWithoutReg Mean           358.25
trainer/PolicyLossWithoutReg Std             59.9241
trainer/PolicyLossWithoutReg Max            430.492
trainer/PolicyLossWithoutReg Min             42.8389
exploration/num steps total              917000
exploration/num paths total                1719
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61319
exploration/Rewards Std                       0.977798
exploration/Rewards Max                       6.93651
exploration/Rewards Min                      -0.894207
exploration/Returns Mean                   4613.19
exploration/Returns Std                       0
exploration/Returns Max                    4613.19
exploration/Returns Min                    4613.19
exploration/Num Paths                         1
exploration/Average Returns                4613.19
evaluation_0/num steps total                  7.15389e+06
evaluation_0/num paths total              10797
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79952
evaluation_0/Rewards Std                      1.05168
evaluation_0/Rewards Max                      7.71026
evaluation_0/Rewards Min                     -0.792071
evaluation_0/Returns Mean                  4799.52
evaluation_0/Returns Std                    107.507
evaluation_0/Returns Max                   4977.3
evaluation_0/Returns Min                   4692.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4799.52
time/epoch (s)                                0
time/total (s)                            13820.2
Epoch                                       912
---------------------------------------  ----------------
2022-11-16 20:05:18.405351 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 913 finished
---------------------------------------  ----------------
epoch                                       913
total_step                               918000
replay_pool/size                         918000
trainer/alpha                                 0.0565463
trainer/alpha_loss                            1.90218
trainer/entropy                              -6.66214
trainer/qf_loss                              33.9875
trainer/policy_loss                        -350.256
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.632
trainer/entropy_penalty                      -0.376719
trainer/entropy_percentage                   -0.0010744
trainer/Q1Pred Mean                         349.726
trainer/Q1Pred Std                           68.7804
trainer/Q1Pred Max                          425.44
trainer/Q1Pred Min                            4.02104
trainer/Q2Pred Mean                         349.999
trainer/Q2Pred Std                           68.711
trainer/Q2Pred Max                          430.473
trainer/Q2Pred Min                            0.696412
trainer/QTargetWithReg Mean                 349.393
trainer/QTargetWithReg Std                   68.9625
trainer/QTargetWithReg Max                  425.459
trainer/QTargetWithReg Min                    6.97103
trainer/PolicyLossWithoutReg Mean           350.632
trainer/PolicyLossWithoutReg Std             67.7582
trainer/PolicyLossWithoutReg Max            426.682
trainer/PolicyLossWithoutReg Min             14.2204
exploration/num steps total              918000
exploration/num paths total                1720
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66851
exploration/Rewards Std                       1.05669
exploration/Rewards Max                       7.04064
exploration/Rewards Min                      -0.834537
exploration/Returns Mean                   4668.51
exploration/Returns Std                       0
exploration/Returns Max                    4668.51
exploration/Returns Min                    4668.51
exploration/Num Paths                         1
exploration/Average Returns                4668.51
evaluation_0/num steps total                  7.16189e+06
evaluation_0/num paths total              10805
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70761
evaluation_0/Rewards Std                      1.02373
evaluation_0/Rewards Max                      7.7412
evaluation_0/Rewards Min                     -0.675946
evaluation_0/Returns Mean                  4707.61
evaluation_0/Returns Std                     92.9807
evaluation_0/Returns Max                   4847.13
evaluation_0/Returns Min                   4586.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4707.61
time/epoch (s)                                0
time/total (s)                            13835.3
Epoch                                       913
---------------------------------------  ----------------
2022-11-16 20:05:33.597946 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 914 finished
---------------------------------------  ----------------
epoch                                       914
total_step                               919000
replay_pool/size                         919000
trainer/alpha                                 0.05761
trainer/alpha_loss                           -1.32927
trainer/entropy                              -5.53423
trainer/qf_loss                              25.8802
trainer/policy_loss                        -358.142
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         358.461
trainer/entropy_penalty                      -0.318827
trainer/entropy_percentage                   -0.000889433
trainer/Q1Pred Mean                         357.535
trainer/Q1Pred Std                           60.8482
trainer/Q1Pred Max                          429.061
trainer/Q1Pred Min                           36.3446
trainer/Q2Pred Mean                         356.939
trainer/Q2Pred Std                           61.6066
trainer/Q2Pred Max                          428.89
trainer/Q2Pred Min                           29.8081
trainer/QTargetWithReg Mean                 357.009
trainer/QTargetWithReg Std                   61.7617
trainer/QTargetWithReg Max                  431.019
trainer/QTargetWithReg Min                   31.5591
trainer/PolicyLossWithoutReg Mean           358.461
trainer/PolicyLossWithoutReg Std             58.814
trainer/PolicyLossWithoutReg Max            429.871
trainer/PolicyLossWithoutReg Min             32.4298
exploration/num steps total              919000
exploration/num paths total                1721
exploration/path length this epoch Mean     861
exploration/path length this epoch Std        0
exploration/path length this epoch Max      861
exploration/path length this epoch Min      861
exploration/Rewards Mean                      4.46232
exploration/Rewards Std                       1.10737
exploration/Rewards Max                       6.98798
exploration/Rewards Min                      -0.980445
exploration/Returns Mean                   3842.06
exploration/Returns Std                       0
exploration/Returns Max                    3842.06
exploration/Returns Min                    3842.06
exploration/Num Paths                         1
exploration/Average Returns                3842.06
evaluation_0/num steps total                  7.16989e+06
evaluation_0/num paths total              10813
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68126
evaluation_0/Rewards Std                      1.04069
evaluation_0/Rewards Max                      7.65181
evaluation_0/Rewards Min                     -0.75663
evaluation_0/Returns Mean                  4681.26
evaluation_0/Returns Std                     76.3111
evaluation_0/Returns Max                   4823.04
evaluation_0/Returns Min                   4578.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4681.26
time/epoch (s)                                0
time/total (s)                            13850.5
Epoch                                       914
---------------------------------------  ----------------
2022-11-16 20:05:50.417822 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 915 finished
---------------------------------------  ----------------
epoch                                       915
total_step                               920000
replay_pool/size                         920000
trainer/alpha                                 0.0569918
trainer/alpha_loss                            0.989148
trainer/entropy                              -6.34527
trainer/qf_loss                              45.0701
trainer/policy_loss                        -350.799
trainer/adversary_policy_loss                16.5201
trainer/policy_loss_without_entropy         351.161
trainer/entropy_penalty                      -0.361628
trainer/entropy_percentage                   -0.00102981
trainer/Q1Pred Mean                         349.638
trainer/Q1Pred Std                           75.4106
trainer/Q1Pred Max                          430.253
trainer/Q1Pred Min                           -5.73417
trainer/Q2Pred Mean                         350.532
trainer/Q2Pred Std                           74.1497
trainer/Q2Pred Max                          428.884
trainer/Q2Pred Min                            8.30547
trainer/QTargetWithReg Mean                 349.623
trainer/QTargetWithReg Std                   75.5796
trainer/QTargetWithReg Max                  429.888
trainer/QTargetWithReg Min                   -8.02803
trainer/PolicyLossWithoutReg Mean           351.161
trainer/PolicyLossWithoutReg Std             71.4693
trainer/PolicyLossWithoutReg Max            427.04
trainer/PolicyLossWithoutReg Min              3.87039
exploration/num steps total              920000
exploration/num paths total                1722
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74349
exploration/Rewards Std                       1.08942
exploration/Rewards Max                       6.83762
exploration/Rewards Min                      -0.60516
exploration/Returns Mean                   4743.49
exploration/Returns Std                       0
exploration/Returns Max                    4743.49
exploration/Returns Min                    4743.49
exploration/Num Paths                         1
exploration/Average Returns                4743.49
evaluation_0/num steps total                  7.17743e+06
evaluation_0/num paths total              10821
evaluation_0/path length Mean               942
evaluation_0/path length Std                103.286
evaluation_0/path length Max               1000
evaluation_0/path length Min                720
evaluation_0/Rewards Mean                     4.68999
evaluation_0/Rewards Std                      1.07086
evaluation_0/Rewards Max                      7.24018
evaluation_0/Rewards Min                     -0.802455
evaluation_0/Returns Mean                  4417.97
evaluation_0/Returns Std                    517.139
evaluation_0/Returns Max                   4876.9
evaluation_0/Returns Min                   3323.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4417.97
time/epoch (s)                                0
time/total (s)                            13867.3
Epoch                                       915
---------------------------------------  ----------------
2022-11-16 20:06:05.250343 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 916 finished
---------------------------------------  ----------------
epoch                                       916
total_step                               921000
replay_pool/size                         921000
trainer/alpha                                 0.0574143
trainer/alpha_loss                           -1.38335
trainer/entropy                              -5.51587
trainer/qf_loss                              15.3274
trainer/policy_loss                        -350.161
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.478
trainer/entropy_penalty                      -0.31669
trainer/entropy_percentage                   -0.000903595
trainer/Q1Pred Mean                         351.12
trainer/Q1Pred Std                           64.704
trainer/Q1Pred Max                          427.051
trainer/Q1Pred Min                            3.59511
trainer/Q2Pred Mean                         350.198
trainer/Q2Pred Std                           64.1859
trainer/Q2Pred Max                          427.285
trainer/Q2Pred Min                            9.41971
trainer/QTargetWithReg Mean                 350.417
trainer/QTargetWithReg Std                   64.2835
trainer/QTargetWithReg Max                  428.104
trainer/QTargetWithReg Min                    3.60671
trainer/PolicyLossWithoutReg Mean           350.478
trainer/PolicyLossWithoutReg Std             63.3952
trainer/PolicyLossWithoutReg Max            426.62
trainer/PolicyLossWithoutReg Min              6.97816
exploration/num steps total              921000
exploration/num paths total                1723
exploration/path length this epoch Mean     161
exploration/path length this epoch Std        0
exploration/path length this epoch Max      161
exploration/path length this epoch Min      161
exploration/Rewards Mean                      2.48855
exploration/Rewards Std                       1.1405
exploration/Rewards Max                       5.48435
exploration/Rewards Min                      -0.762507
exploration/Returns Mean                    400.657
exploration/Returns Std                       0
exploration/Returns Max                     400.657
exploration/Returns Min                     400.657
exploration/Num Paths                         1
exploration/Average Returns                 400.657
evaluation_0/num steps total                  7.18543e+06
evaluation_0/num paths total              10829
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65153
evaluation_0/Rewards Std                      1.02973
evaluation_0/Rewards Max                      7.0703
evaluation_0/Rewards Min                     -0.8357
evaluation_0/Returns Mean                  4651.53
evaluation_0/Returns Std                    102.102
evaluation_0/Returns Max                   4776.32
evaluation_0/Returns Min                   4445.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4651.53
time/epoch (s)                                0
time/total (s)                            13882.1
Epoch                                       916
---------------------------------------  ----------------
2022-11-16 20:06:20.265721 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 917 finished
---------------------------------------  ----------------
epoch                                       917
total_step                               922000
replay_pool/size                         922000
trainer/alpha                                 0.0582534
trainer/alpha_loss                           -0.351786
trainer/entropy                              -5.87627
trainer/qf_loss                              19.815
trainer/policy_loss                        -352.469
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.811
trainer/entropy_penalty                      -0.342313
trainer/entropy_percentage                   -0.000970243
trainer/Q1Pred Mean                         351.959
trainer/Q1Pred Std                           63.8118
trainer/Q1Pred Max                          426.279
trainer/Q1Pred Min                           24.5907
trainer/Q2Pred Mean                         352.241
trainer/Q2Pred Std                           64.0005
trainer/Q2Pred Max                          426.528
trainer/Q2Pred Min                           18.8541
trainer/QTargetWithReg Mean                 352.231
trainer/QTargetWithReg Std                   63.9648
trainer/QTargetWithReg Max                  426.946
trainer/QTargetWithReg Min                   27.6496
trainer/PolicyLossWithoutReg Mean           352.811
trainer/PolicyLossWithoutReg Std             63.376
trainer/PolicyLossWithoutReg Max            426.312
trainer/PolicyLossWithoutReg Min             18.7211
exploration/num steps total              922000
exploration/num paths total                1724
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48503
exploration/Rewards Std                       1.06256
exploration/Rewards Max                       7.01353
exploration/Rewards Min                      -0.865001
exploration/Returns Mean                   4485.03
exploration/Returns Std                       0
exploration/Returns Max                    4485.03
exploration/Returns Min                    4485.03
exploration/Num Paths                         1
exploration/Average Returns                4485.03
evaluation_0/num steps total                  7.19343e+06
evaluation_0/num paths total              10837
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87403
evaluation_0/Rewards Std                      1.08398
evaluation_0/Rewards Max                      7.29327
evaluation_0/Rewards Min                     -0.673658
evaluation_0/Returns Mean                  4874.03
evaluation_0/Returns Std                     79.342
evaluation_0/Returns Max                   5031.05
evaluation_0/Returns Min                   4778.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4874.03
time/epoch (s)                                0
time/total (s)                            13897.1
Epoch                                       917
---------------------------------------  ----------------
2022-11-16 20:06:36.952059 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 918 finished
---------------------------------------  ---------------
epoch                                       918
total_step                               923000
replay_pool/size                         923000
trainer/alpha                                 0.059276
trainer/alpha_loss                            0.646761
trainer/entropy                              -6.22888
trainer/qf_loss                              22.9997
trainer/policy_loss                        -356.204
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.573
trainer/entropy_penalty                      -0.369223
trainer/entropy_percentage                   -0.00103548
trainer/Q1Pred Mean                         355.732
trainer/Q1Pred Std                           61.3099
trainer/Q1Pred Max                          431.999
trainer/Q1Pred Min                           75.2843
trainer/Q2Pred Mean                         355.837
trainer/Q2Pred Std                           61.7635
trainer/Q2Pred Max                          432.89
trainer/Q2Pred Min                           64.131
trainer/QTargetWithReg Mean                 355.747
trainer/QTargetWithReg Std                   61.1384
trainer/QTargetWithReg Max                  431.477
trainer/QTargetWithReg Min                   68.2
trainer/PolicyLossWithoutReg Mean           356.573
trainer/PolicyLossWithoutReg Std             60.2945
trainer/PolicyLossWithoutReg Max            430.559
trainer/PolicyLossWithoutReg Min             59.9562
exploration/num steps total              923000
exploration/num paths total                1725
exploration/path length this epoch Mean     287
exploration/path length this epoch Std        0
exploration/path length this epoch Max      287
exploration/path length this epoch Min      287
exploration/Rewards Mean                      3.51929
exploration/Rewards Std                       1.30028
exploration/Rewards Max                       6.56725
exploration/Rewards Min                      -0.872324
exploration/Returns Mean                   1010.04
exploration/Returns Std                       0
exploration/Returns Max                    1010.04
exploration/Returns Min                    1010.04
exploration/Num Paths                         1
exploration/Average Returns                1010.04
evaluation_0/num steps total                  7.2005e+06
evaluation_0/num paths total              10845
evaluation_0/path length Mean               884.5
evaluation_0/path length Std                305.584
evaluation_0/path length Max               1000
evaluation_0/path length Min                 76
evaluation_0/Rewards Mean                     4.49273
evaluation_0/Rewards Std                      1.11538
evaluation_0/Rewards Max                      7.30231
evaluation_0/Rewards Min                     -0.638383
evaluation_0/Returns Mean                  3973.82
evaluation_0/Returns Std                   1443.29
evaluation_0/Returns Max                   4683.39
evaluation_0/Returns Min                    167.155
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3973.82
time/epoch (s)                                0
time/total (s)                            13913.8
Epoch                                       918
---------------------------------------  ---------------
2022-11-16 20:06:51.673769 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 919 finished
---------------------------------------  ----------------
epoch                                       919
total_step                               924000
replay_pool/size                         924000
trainer/alpha                                 0.0570638
trainer/alpha_loss                           -1.06937
trainer/entropy                              -5.62653
trainer/qf_loss                              25.391
trainer/policy_loss                        -350.251
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.572
trainer/entropy_penalty                      -0.321071
trainer/entropy_percentage                   -0.000915849
trainer/Q1Pred Mean                         350.635
trainer/Q1Pred Std                           76.3072
trainer/Q1Pred Max                          431.202
trainer/Q1Pred Min                            0.677199
trainer/Q2Pred Mean                         349.827
trainer/Q2Pred Std                           75.9779
trainer/Q2Pred Max                          429.23
trainer/Q2Pred Min                          -11.1643
trainer/QTargetWithReg Mean                 349.116
trainer/QTargetWithReg Std                   76.103
trainer/QTargetWithReg Max                  433.578
trainer/QTargetWithReg Min                   -9.41193
trainer/PolicyLossWithoutReg Mean           350.572
trainer/PolicyLossWithoutReg Std             73.2335
trainer/PolicyLossWithoutReg Max            432.885
trainer/PolicyLossWithoutReg Min             13.1063
exploration/num steps total              924000
exploration/num paths total                1726
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51464
exploration/Rewards Std                       0.978608
exploration/Rewards Max                       6.83097
exploration/Rewards Min                      -0.980628
exploration/Returns Mean                   4514.64
exploration/Returns Std                       0
exploration/Returns Max                    4514.64
exploration/Returns Min                    4514.64
exploration/Num Paths                         1
exploration/Average Returns                4514.64
evaluation_0/num steps total                  7.2085e+06
evaluation_0/num paths total              10853
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91111
evaluation_0/Rewards Std                      1.08726
evaluation_0/Rewards Max                      7.72157
evaluation_0/Rewards Min                     -0.86207
evaluation_0/Returns Mean                  4911.11
evaluation_0/Returns Std                     74.1374
evaluation_0/Returns Max                   5034.52
evaluation_0/Returns Min                   4794.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4911.11
time/epoch (s)                                0
time/total (s)                            13928.5
Epoch                                       919
---------------------------------------  ----------------
2022-11-16 20:07:06.472418 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 920 finished
---------------------------------------  ---------------
epoch                                       920
total_step                               925000
replay_pool/size                         925000
trainer/alpha                                 0.0579369
trainer/alpha_loss                           -0.674405
trainer/entropy                              -5.76323
trainer/qf_loss                              22.5576
trainer/policy_loss                        -346.222
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.556
trainer/entropy_penalty                      -0.333903
trainer/entropy_percentage                   -0.00096349
trainer/Q1Pred Mean                         346.771
trainer/Q1Pred Std                           79.3601
trainer/Q1Pred Max                          426.024
trainer/Q1Pred Min                           -3.96087
trainer/Q2Pred Mean                         346.137
trainer/Q2Pred Std                           79.2516
trainer/Q2Pred Max                          423.652
trainer/Q2Pred Min                           -4.2338
trainer/QTargetWithReg Mean                 347.039
trainer/QTargetWithReg Std                   78.8544
trainer/QTargetWithReg Max                  424.562
trainer/QTargetWithReg Min                    1.32073
trainer/PolicyLossWithoutReg Mean           346.556
trainer/PolicyLossWithoutReg Std             78.3209
trainer/PolicyLossWithoutReg Max            423.338
trainer/PolicyLossWithoutReg Min            -10.2395
exploration/num steps total              925000
exploration/num paths total                1727
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65907
exploration/Rewards Std                       1.06777
exploration/Rewards Max                       7.59209
exploration/Rewards Min                      -0.886317
exploration/Returns Mean                   4659.07
exploration/Returns Std                       0
exploration/Returns Max                    4659.07
exploration/Returns Min                    4659.07
exploration/Num Paths                         1
exploration/Average Returns                4659.07
evaluation_0/num steps total                  7.2165e+06
evaluation_0/num paths total              10861
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84099
evaluation_0/Rewards Std                      0.998897
evaluation_0/Rewards Max                      7.14373
evaluation_0/Rewards Min                     -0.57788
evaluation_0/Returns Mean                  4840.99
evaluation_0/Returns Std                     51.2345
evaluation_0/Returns Max                   4934.42
evaluation_0/Returns Min                   4769.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4840.99
time/epoch (s)                                0
time/total (s)                            13943.3
Epoch                                       920
---------------------------------------  ---------------
2022-11-16 20:07:21.397635 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 921 finished
---------------------------------------  ---------------
epoch                                       921
total_step                               926000
replay_pool/size                         926000
trainer/alpha                                 0.0574151
trainer/alpha_loss                            1.82505
trainer/entropy                              -6.63868
trainer/qf_loss                              31.9991
trainer/policy_loss                        -348.208
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.589
trainer/entropy_penalty                      -0.38116
trainer/entropy_percentage                   -0.00109344
trainer/Q1Pred Mean                         347.304
trainer/Q1Pred Std                           74.6641
trainer/Q1Pred Max                          441.87
trainer/Q1Pred Min                            4.52301
trainer/Q2Pred Mean                         348.31
trainer/Q2Pred Std                           74.6298
trainer/Q2Pred Max                          439.238
trainer/Q2Pred Min                           -6.93849
trainer/QTargetWithReg Mean                 347.357
trainer/QTargetWithReg Std                   75.2279
trainer/QTargetWithReg Max                  436.509
trainer/QTargetWithReg Min                    3.35318
trainer/PolicyLossWithoutReg Mean           348.589
trainer/PolicyLossWithoutReg Std             73.3885
trainer/PolicyLossWithoutReg Max            438.58
trainer/PolicyLossWithoutReg Min              2.53159
exploration/num steps total              926000
exploration/num paths total                1728
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70926
exploration/Rewards Std                       1.07051
exploration/Rewards Max                       7.28361
exploration/Rewards Min                      -0.527994
exploration/Returns Mean                   4709.26
exploration/Returns Std                       0
exploration/Returns Max                    4709.26
exploration/Returns Min                    4709.26
exploration/Num Paths                         1
exploration/Average Returns                4709.26
evaluation_0/num steps total                  7.2245e+06
evaluation_0/num paths total              10869
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73282
evaluation_0/Rewards Std                      1.06606
evaluation_0/Rewards Max                      7.58148
evaluation_0/Rewards Min                     -0.777972
evaluation_0/Returns Mean                  4732.82
evaluation_0/Returns Std                    122.758
evaluation_0/Returns Max                   4889.63
evaluation_0/Returns Min                   4542.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4732.82
time/epoch (s)                                0
time/total (s)                            13958.3
Epoch                                       921
---------------------------------------  ---------------
2022-11-16 20:07:36.337515 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 922 finished
---------------------------------------  ----------------
epoch                                       922
total_step                               927000
replay_pool/size                         927000
trainer/alpha                                 0.0588206
trainer/alpha_loss                           -0.3024
trainer/entropy                              -5.89326
trainer/qf_loss                              16.3854
trainer/policy_loss                        -352.846
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.193
trainer/entropy_penalty                      -0.346645
trainer/entropy_percentage                   -0.000981461
trainer/Q1Pred Mean                         353.853
trainer/Q1Pred Std                           60.042
trainer/Q1Pred Max                          432.459
trainer/Q1Pred Min                           17.2149
trainer/Q2Pred Mean                         353.445
trainer/Q2Pred Std                           60.5296
trainer/Q2Pred Max                          437.816
trainer/Q2Pred Min                           14.2508
trainer/QTargetWithReg Mean                 352.782
trainer/QTargetWithReg Std                   60.236
trainer/QTargetWithReg Max                  432.653
trainer/QTargetWithReg Min                   11.3228
trainer/PolicyLossWithoutReg Mean           353.193
trainer/PolicyLossWithoutReg Std             59.5633
trainer/PolicyLossWithoutReg Max            432.234
trainer/PolicyLossWithoutReg Min             13.9635
exploration/num steps total              927000
exploration/num paths total                1729
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6245
exploration/Rewards Std                       1.16103
exploration/Rewards Max                       7.2089
exploration/Rewards Min                      -0.596727
exploration/Returns Mean                   4624.5
exploration/Returns Std                       0
exploration/Returns Max                    4624.5
exploration/Returns Min                    4624.5
exploration/Num Paths                         1
exploration/Average Returns                4624.5
evaluation_0/num steps total                  7.2325e+06
evaluation_0/num paths total              10877
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80165
evaluation_0/Rewards Std                      1.05384
evaluation_0/Rewards Max                      7.35923
evaluation_0/Rewards Min                     -0.55189
evaluation_0/Returns Mean                  4801.65
evaluation_0/Returns Std                     39.6948
evaluation_0/Returns Max                   4850.62
evaluation_0/Returns Min                   4717.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4801.65
time/epoch (s)                                0
time/total (s)                            13973.2
Epoch                                       922
---------------------------------------  ----------------
2022-11-16 20:07:51.483480 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 923 finished
---------------------------------------  ---------------
epoch                                       923
total_step                               928000
replay_pool/size                         928000
trainer/alpha                                 0.0572702
trainer/alpha_loss                            1.14362
trainer/entropy                              -6.39984
trainer/qf_loss                             128.584
trainer/policy_loss                        -350.198
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.564
trainer/entropy_penalty                      -0.36652
trainer/entropy_percentage                   -0.00104552
trainer/Q1Pred Mean                         349
trainer/Q1Pred Std                           71.0007
trainer/Q1Pred Max                          429.563
trainer/Q1Pred Min                          -34.6797
trainer/Q2Pred Mean                         349.154
trainer/Q2Pred Std                           70.3435
trainer/Q2Pred Max                          429.361
trainer/Q2Pred Min                          -16.1702
trainer/QTargetWithReg Mean                 348.905
trainer/QTargetWithReg Std                   72.579
trainer/QTargetWithReg Max                  426.161
trainer/QTargetWithReg Min                    0.0589732
trainer/PolicyLossWithoutReg Mean           350.564
trainer/PolicyLossWithoutReg Std             68.3187
trainer/PolicyLossWithoutReg Max            429.95
trainer/PolicyLossWithoutReg Min             26.0338
exploration/num steps total              928000
exploration/num paths total                1730
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6464
exploration/Rewards Std                       1.00181
exploration/Rewards Max                       6.92335
exploration/Rewards Min                      -0.526415
exploration/Returns Mean                   4646.4
exploration/Returns Std                       0
exploration/Returns Max                    4646.4
exploration/Returns Min                    4646.4
exploration/Num Paths                         1
exploration/Average Returns                4646.4
evaluation_0/num steps total                  7.2405e+06
evaluation_0/num paths total              10885
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7774
evaluation_0/Rewards Std                      0.999174
evaluation_0/Rewards Max                      7.30883
evaluation_0/Rewards Min                     -0.746605
evaluation_0/Returns Mean                  4777.4
evaluation_0/Returns Std                     63.0343
evaluation_0/Returns Max                   4892.7
evaluation_0/Returns Min                   4658.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4777.4
time/epoch (s)                                0
time/total (s)                            13988.3
Epoch                                       923
---------------------------------------  ---------------
2022-11-16 20:08:06.279639 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 924 finished
---------------------------------------  ---------------
epoch                                       924
total_step                               929000
replay_pool/size                         929000
trainer/alpha                                 0.0591526
trainer/alpha_loss                           -0.00125528
trainer/entropy                              -5.99956
trainer/qf_loss                              33.3954
trainer/policy_loss                        -352.251
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.606
trainer/entropy_penalty                      -0.35489
trainer/entropy_percentage                   -0.00100648
trainer/Q1Pred Mean                         351.688
trainer/Q1Pred Std                           73.3825
trainer/Q1Pred Max                          424.097
trainer/Q1Pred Min                           12.6412
trainer/Q2Pred Mean                         351.694
trainer/Q2Pred Std                           73.9928
trainer/Q2Pred Max                          426.092
trainer/Q2Pred Min                           11.7992
trainer/QTargetWithReg Mean                 351.316
trainer/QTargetWithReg Std                   74.3912
trainer/QTargetWithReg Max                  424.586
trainer/QTargetWithReg Min                   14.7373
trainer/PolicyLossWithoutReg Mean           352.606
trainer/PolicyLossWithoutReg Std             73.072
trainer/PolicyLossWithoutReg Max            425.367
trainer/PolicyLossWithoutReg Min             18.1389
exploration/num steps total              929000
exploration/num paths total                1731
exploration/path length this epoch Mean     659
exploration/path length this epoch Std        0
exploration/path length this epoch Max      659
exploration/path length this epoch Min      659
exploration/Rewards Mean                      4.49965
exploration/Rewards Std                       1.18063
exploration/Rewards Max                       6.82611
exploration/Rewards Min                      -0.806768
exploration/Returns Mean                   2965.27
exploration/Returns Std                       0
exploration/Returns Max                    2965.27
exploration/Returns Min                    2965.27
exploration/Num Paths                         1
exploration/Average Returns                2965.27
evaluation_0/num steps total                  7.2485e+06
evaluation_0/num paths total              10893
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78096
evaluation_0/Rewards Std                      1.03784
evaluation_0/Rewards Max                      7.53582
evaluation_0/Rewards Min                     -0.710005
evaluation_0/Returns Mean                  4780.96
evaluation_0/Returns Std                     38.6812
evaluation_0/Returns Max                   4823.82
evaluation_0/Returns Min                   4731.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4780.96
time/epoch (s)                                0
time/total (s)                            14003.1
Epoch                                       924
---------------------------------------  ---------------
2022-11-16 20:08:21.057704 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 925 finished
---------------------------------------  ---------------
epoch                                       925
total_step                               930000
replay_pool/size                         930000
trainer/alpha                                 0.0559474
trainer/alpha_loss                            2.11935
trainer/entropy                              -6.735
trainer/qf_loss                              25.347
trainer/policy_loss                        -356.737
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.114
trainer/entropy_penalty                      -0.376806
trainer/entropy_percentage                   -0.00105514
trainer/Q1Pred Mean                         356.585
trainer/Q1Pred Std                           67.591
trainer/Q1Pred Max                          426.445
trainer/Q1Pred Min                          -32.0047
trainer/Q2Pred Mean                         356.922
trainer/Q2Pred Std                           66.0401
trainer/Q2Pred Max                          426.969
trainer/Q2Pred Min                           16.3767
trainer/QTargetWithReg Mean                 356.71
trainer/QTargetWithReg Std                   66.8794
trainer/QTargetWithReg Max                  424.795
trainer/QTargetWithReg Min                   -0.0834447
trainer/PolicyLossWithoutReg Mean           357.114
trainer/PolicyLossWithoutReg Std             63.8855
trainer/PolicyLossWithoutReg Max            426.982
trainer/PolicyLossWithoutReg Min             17.3401
exploration/num steps total              930000
exploration/num paths total                1732
exploration/path length this epoch Mean     318
exploration/path length this epoch Std        0
exploration/path length this epoch Max      318
exploration/path length this epoch Min      318
exploration/Rewards Mean                      3.43498
exploration/Rewards Std                       1.28618
exploration/Rewards Max                       6.37828
exploration/Rewards Min                      -0.788768
exploration/Returns Mean                   1092.32
exploration/Returns Std                       0
exploration/Returns Max                    1092.32
exploration/Returns Min                    1092.32
exploration/Num Paths                         1
exploration/Average Returns                1092.32
evaluation_0/num steps total                  7.2565e+06
evaluation_0/num paths total              10901
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73708
evaluation_0/Rewards Std                      0.949837
evaluation_0/Rewards Max                      7.46934
evaluation_0/Rewards Min                     -0.981177
evaluation_0/Returns Mean                  4737.08
evaluation_0/Returns Std                     60.0365
evaluation_0/Returns Max                   4858.82
evaluation_0/Returns Min                   4637.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4737.08
time/epoch (s)                                0
time/total (s)                            14017.9
Epoch                                       925
---------------------------------------  ---------------
2022-11-16 20:08:36.252764 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 926 finished
---------------------------------------  ----------------
epoch                                       926
total_step                               931000
replay_pool/size                         931000
trainer/alpha                                 0.0578101
trainer/alpha_loss                           -1.08635
trainer/entropy                              -5.61888
trainer/qf_loss                              19.5671
trainer/policy_loss                        -351.08
trainer/adversary_policy_loss                16.8263
trainer/policy_loss_without_entropy         351.405
trainer/entropy_penalty                      -0.324828
trainer/entropy_percentage                   -0.000924368
trainer/Q1Pred Mean                         351.451
trainer/Q1Pred Std                           70.575
trainer/Q1Pred Max                          433.334
trainer/Q1Pred Min                            2.36165
trainer/Q2Pred Mean                         351.186
trainer/Q2Pred Std                           69.9848
trainer/Q2Pred Max                          434.115
trainer/Q2Pred Min                           17.1093
trainer/QTargetWithReg Mean                 351.492
trainer/QTargetWithReg Std                   70.9349
trainer/QTargetWithReg Max                  434.498
trainer/QTargetWithReg Min                    2.70737
trainer/PolicyLossWithoutReg Mean           351.405
trainer/PolicyLossWithoutReg Std             69.6381
trainer/PolicyLossWithoutReg Max            433.058
trainer/PolicyLossWithoutReg Min              6.14168
exploration/num steps total              931000
exploration/num paths total                1734
exploration/path length this epoch Mean     457
exploration/path length this epoch Std       13
exploration/path length this epoch Max      470
exploration/path length this epoch Min      444
exploration/Rewards Mean                      4.22622
exploration/Rewards Std                       1.32255
exploration/Rewards Max                       7.4212
exploration/Rewards Min                      -1.04829
exploration/Returns Mean                   1931.38
exploration/Returns Std                       6.88872
exploration/Returns Max                    1938.27
exploration/Returns Min                    1924.49
exploration/Num Paths                         2
exploration/Average Returns                1931.38
evaluation_0/num steps total                  7.2645e+06
evaluation_0/num paths total              10909
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77996
evaluation_0/Rewards Std                      0.984764
evaluation_0/Rewards Max                      7.6201
evaluation_0/Rewards Min                     -0.77167
evaluation_0/Returns Mean                  4779.96
evaluation_0/Returns Std                    132.954
evaluation_0/Returns Max                   5093.28
evaluation_0/Returns Min                   4639.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4779.96
time/epoch (s)                                0
time/total (s)                            14033.1
Epoch                                       926
---------------------------------------  ----------------
2022-11-16 20:08:51.247090 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 927 finished
---------------------------------------  ----------------
epoch                                       927
total_step                               932000
replay_pool/size                         932000
trainer/alpha                                 0.0572026
trainer/alpha_loss                           -0.0903952
trainer/entropy                              -5.96841
trainer/qf_loss                              18.0547
trainer/policy_loss                        -353.261
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.603
trainer/entropy_penalty                      -0.341408
trainer/entropy_percentage                   -0.000965514
trainer/Q1Pred Mean                         353.155
trainer/Q1Pred Std                           67.9159
trainer/Q1Pred Max                          424.785
trainer/Q1Pred Min                           -8.68084
trainer/Q2Pred Mean                         352.664
trainer/Q2Pred Std                           68.7664
trainer/Q2Pred Max                          427.436
trainer/Q2Pred Min                          -13.1204
trainer/QTargetWithReg Mean                 353.526
trainer/QTargetWithReg Std                   68.3454
trainer/QTargetWithReg Max                  426.365
trainer/QTargetWithReg Min                    0.65918
trainer/PolicyLossWithoutReg Mean           353.603
trainer/PolicyLossWithoutReg Std             67.7992
trainer/PolicyLossWithoutReg Max            425.407
trainer/PolicyLossWithoutReg Min            -14.4841
exploration/num steps total              932000
exploration/num paths total                1735
exploration/path length this epoch Mean      15
exploration/path length this epoch Std        0
exploration/path length this epoch Max       15
exploration/path length this epoch Min       15
exploration/Rewards Mean                     -0.150629
exploration/Rewards Std                       0.458049
exploration/Rewards Max                       0.813547
exploration/Rewards Min                      -0.718515
exploration/Returns Mean                     -2.25944
exploration/Returns Std                       0
exploration/Returns Max                      -2.25944
exploration/Returns Min                      -2.25944
exploration/Num Paths                         1
exploration/Average Returns                  -2.25944
evaluation_0/num steps total                  7.2725e+06
evaluation_0/num paths total              10917
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77249
evaluation_0/Rewards Std                      0.969536
evaluation_0/Rewards Max                      7.22341
evaluation_0/Rewards Min                     -0.529427
evaluation_0/Returns Mean                  4772.49
evaluation_0/Returns Std                     52.2659
evaluation_0/Returns Max                   4835.88
evaluation_0/Returns Min                   4668.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4772.49
time/epoch (s)                                0
time/total (s)                            14048.1
Epoch                                       927
---------------------------------------  ----------------
2022-11-16 20:09:06.150401 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 928 finished
---------------------------------------  ---------------
epoch                                       928
total_step                               933000
replay_pool/size                         933000
trainer/alpha                                 0.0577269
trainer/alpha_loss                            2.14604
trainer/entropy                              -6.75244
trainer/qf_loss                              25.7704
trainer/policy_loss                        -345.81
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.2
trainer/entropy_penalty                      -0.389797
trainer/entropy_percentage                   -0.00112593
trainer/Q1Pred Mean                         344.965
trainer/Q1Pred Std                           70.8231
trainer/Q1Pred Max                          426.716
trainer/Q1Pred Min                            6.79775
trainer/Q2Pred Mean                         344.902
trainer/Q2Pred Std                           70.5065
trainer/Q2Pred Max                          427.318
trainer/Q2Pred Min                            3.40409
trainer/QTargetWithReg Mean                 344.546
trainer/QTargetWithReg Std                   70.2389
trainer/QTargetWithReg Max                  428.104
trainer/QTargetWithReg Min                    6.79468
trainer/PolicyLossWithoutReg Mean           346.2
trainer/PolicyLossWithoutReg Std             69.0212
trainer/PolicyLossWithoutReg Max            429.442
trainer/PolicyLossWithoutReg Min              7.55654
exploration/num steps total              933000
exploration/num paths total                1736
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7699
exploration/Rewards Std                       0.98114
exploration/Rewards Max                       7.09723
exploration/Rewards Min                      -0.527285
exploration/Returns Mean                   4769.9
exploration/Returns Std                       0
exploration/Returns Max                    4769.9
exploration/Returns Min                    4769.9
exploration/Num Paths                         1
exploration/Average Returns                4769.9
evaluation_0/num steps total                  7.2805e+06
evaluation_0/num paths total              10925
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77284
evaluation_0/Rewards Std                      0.959714
evaluation_0/Rewards Max                      7.17932
evaluation_0/Rewards Min                     -0.748791
evaluation_0/Returns Mean                  4772.84
evaluation_0/Returns Std                     87.6585
evaluation_0/Returns Max                   4859.87
evaluation_0/Returns Min                   4600.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4772.84
time/epoch (s)                                0
time/total (s)                            14063
Epoch                                       928
---------------------------------------  ---------------
2022-11-16 20:09:21.279329 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 929 finished
---------------------------------------  ----------------
epoch                                       929
total_step                               934000
replay_pool/size                         934000
trainer/alpha                                 0.0586716
trainer/alpha_loss                           -0.522389
trainer/entropy                              -5.81579
trainer/qf_loss                              36.7512
trainer/policy_loss                        -354.796
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.137
trainer/entropy_penalty                      -0.341222
trainer/entropy_percentage                   -0.000960817
trainer/Q1Pred Mean                         354.599
trainer/Q1Pred Std                           70.8577
trainer/Q1Pred Max                          432.551
trainer/Q1Pred Min                            0.00346124
trainer/Q2Pred Mean                         354.712
trainer/Q2Pred Std                           72.0232
trainer/Q2Pred Max                          433.553
trainer/Q2Pred Min                            7.31707
trainer/QTargetWithReg Mean                 353.098
trainer/QTargetWithReg Std                   71.6917
trainer/QTargetWithReg Max                  430.74
trainer/QTargetWithReg Min                    2.43718
trainer/PolicyLossWithoutReg Mean           355.137
trainer/PolicyLossWithoutReg Std             70.2137
trainer/PolicyLossWithoutReg Max            433.408
trainer/PolicyLossWithoutReg Min              6.92071
exploration/num steps total              934000
exploration/num paths total                1737
exploration/path length this epoch Mean     946
exploration/path length this epoch Std        0
exploration/path length this epoch Max      946
exploration/path length this epoch Min      946
exploration/Rewards Mean                      4.4524
exploration/Rewards Std                       1.00064
exploration/Rewards Max                       7.14105
exploration/Rewards Min                      -0.546546
exploration/Returns Mean                   4211.97
exploration/Returns Std                       0
exploration/Returns Max                    4211.97
exploration/Returns Min                    4211.97
exploration/Num Paths                         1
exploration/Average Returns                4211.97
evaluation_0/num steps total                  7.2885e+06
evaluation_0/num paths total              10933
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87397
evaluation_0/Rewards Std                      0.922569
evaluation_0/Rewards Max                      6.79289
evaluation_0/Rewards Min                     -0.792396
evaluation_0/Returns Mean                  4873.97
evaluation_0/Returns Std                     34.3812
evaluation_0/Returns Max                   4950.88
evaluation_0/Returns Min                   4837.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4873.97
time/epoch (s)                                0
time/total (s)                            14078.1
Epoch                                       929
---------------------------------------  ----------------
2022-11-16 20:09:36.124310 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 930 finished
---------------------------------------  ----------------
epoch                                       930
total_step                               935000
replay_pool/size                         935000
trainer/alpha                                 0.0586145
trainer/alpha_loss                           -1.18495
trainer/entropy                              -5.58225
trainer/qf_loss                              31.1319
trainer/policy_loss                        -352.527
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.854
trainer/entropy_penalty                      -0.327201
trainer/entropy_percentage                   -0.000927299
trainer/Q1Pred Mean                         352.895
trainer/Q1Pred Std                           68.7436
trainer/Q1Pred Max                          438.35
trainer/Q1Pred Min                            2.56512
trainer/Q2Pred Mean                         352.708
trainer/Q2Pred Std                           68.2074
trainer/Q2Pred Max                          437.526
trainer/Q2Pred Min                           -3.51486
trainer/QTargetWithReg Mean                 353.077
trainer/QTargetWithReg Std                   68.5206
trainer/QTargetWithReg Max                  438.228
trainer/QTargetWithReg Min                   -8.48183
trainer/PolicyLossWithoutReg Mean           352.854
trainer/PolicyLossWithoutReg Std             67.3431
trainer/PolicyLossWithoutReg Max            437.33
trainer/PolicyLossWithoutReg Min             -8.1385
exploration/num steps total              935000
exploration/num paths total                1738
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72686
exploration/Rewards Std                       1.05796
exploration/Rewards Max                       7.62164
exploration/Rewards Min                      -0.783045
exploration/Returns Mean                   4726.86
exploration/Returns Std                       0
exploration/Returns Max                    4726.86
exploration/Returns Min                    4726.86
exploration/Num Paths                         1
exploration/Average Returns                4726.86
evaluation_0/num steps total                  7.2965e+06
evaluation_0/num paths total              10941
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90796
evaluation_0/Rewards Std                      1.01127
evaluation_0/Rewards Max                      7.28842
evaluation_0/Rewards Min                     -0.677298
evaluation_0/Returns Mean                  4907.96
evaluation_0/Returns Std                    122.526
evaluation_0/Returns Max                   5120.89
evaluation_0/Returns Min                   4742.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4907.96
time/epoch (s)                                0
time/total (s)                            14093
Epoch                                       930
---------------------------------------  ----------------
2022-11-16 20:09:51.318834 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 931 finished
---------------------------------------  ----------------
epoch                                       931
total_step                               936000
replay_pool/size                         936000
trainer/alpha                                 0.0560983
trainer/alpha_loss                            0.25379
trainer/entropy                              -6.0881
trainer/qf_loss                              11.4532
trainer/policy_loss                        -355.67
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.011
trainer/entropy_penalty                      -0.341532
trainer/entropy_percentage                   -0.000959328
trainer/Q1Pred Mean                         355.784
trainer/Q1Pred Std                           53.8357
trainer/Q1Pred Max                          431.611
trainer/Q1Pred Min                          170.68
trainer/Q2Pred Mean                         356.004
trainer/Q2Pred Std                           53.4171
trainer/Q2Pred Max                          432.274
trainer/Q2Pred Min                          184.642
trainer/QTargetWithReg Mean                 355.851
trainer/QTargetWithReg Std                   54.0644
trainer/QTargetWithReg Max                  433.838
trainer/QTargetWithReg Min                  175.602
trainer/PolicyLossWithoutReg Mean           356.011
trainer/PolicyLossWithoutReg Std             52.8744
trainer/PolicyLossWithoutReg Max            432.309
trainer/PolicyLossWithoutReg Min            189.596
exploration/num steps total              936000
exploration/num paths total                1739
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90254
exploration/Rewards Std                       1.00212
exploration/Rewards Max                       7.70974
exploration/Rewards Min                      -0.657834
exploration/Returns Mean                   4902.54
exploration/Returns Std                       0
exploration/Returns Max                    4902.54
exploration/Returns Min                    4902.54
exploration/Num Paths                         1
exploration/Average Returns                4902.54
evaluation_0/num steps total                  7.3045e+06
evaluation_0/num paths total              10949
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83455
evaluation_0/Rewards Std                      0.997366
evaluation_0/Rewards Max                      7.74073
evaluation_0/Rewards Min                     -0.581213
evaluation_0/Returns Mean                  4834.55
evaluation_0/Returns Std                     59.6249
evaluation_0/Returns Max                   4959.84
evaluation_0/Returns Min                   4754.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4834.55
time/epoch (s)                                0
time/total (s)                            14108.2
Epoch                                       931
---------------------------------------  ----------------
2022-11-16 20:10:06.095669 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 932 finished
---------------------------------------  ----------------
epoch                                       932
total_step                               937000
replay_pool/size                         937000
trainer/alpha                                 0.0547391
trainer/alpha_loss                           -0.908862
trainer/entropy                              -5.68715
trainer/qf_loss                              30.241
trainer/policy_loss                        -355.946
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.257
trainer/entropy_penalty                      -0.311309
trainer/entropy_percentage                   -0.000873834
trainer/Q1Pred Mean                         354.563
trainer/Q1Pred Std                           67.5712
trainer/Q1Pred Max                          429.16
trainer/Q1Pred Min                          -47.691
trainer/Q2Pred Mean                         355.133
trainer/Q2Pred Std                           66.291
trainer/Q2Pred Max                          429.614
trainer/Q2Pred Min                          -11.6572
trainer/QTargetWithReg Mean                 355.091
trainer/QTargetWithReg Std                   66.3172
trainer/QTargetWithReg Max                  428.624
trainer/QTargetWithReg Min                   -0.443733
trainer/PolicyLossWithoutReg Mean           356.257
trainer/PolicyLossWithoutReg Std             63.0641
trainer/PolicyLossWithoutReg Max            429.252
trainer/PolicyLossWithoutReg Min             29.7522
exploration/num steps total              937000
exploration/num paths total                1740
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62498
exploration/Rewards Std                       1.10888
exploration/Rewards Max                       7.2526
exploration/Rewards Min                      -0.902958
exploration/Returns Mean                   4624.98
exploration/Returns Std                       0
exploration/Returns Max                    4624.98
exploration/Returns Min                    4624.98
exploration/Num Paths                         1
exploration/Average Returns                4624.98
evaluation_0/num steps total                  7.3125e+06
evaluation_0/num paths total              10957
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53709
evaluation_0/Rewards Std                      1.0455
evaluation_0/Rewards Max                      7.43411
evaluation_0/Rewards Min                     -0.780583
evaluation_0/Returns Mean                  4537.09
evaluation_0/Returns Std                     76.9938
evaluation_0/Returns Max                   4668.45
evaluation_0/Returns Min                   4443.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4537.09
time/epoch (s)                                0
time/total (s)                            14122.9
Epoch                                       932
---------------------------------------  ----------------
2022-11-16 20:10:22.601298 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 933 finished
---------------------------------------  ----------------
epoch                                       933
total_step                               938000
replay_pool/size                         938000
trainer/alpha                                 0.0568814
trainer/alpha_loss                           -0.984854
trainer/entropy                              -5.65647
trainer/qf_loss                              16.8423
trainer/policy_loss                        -351.232
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.554
trainer/entropy_penalty                      -0.321748
trainer/entropy_percentage                   -0.000915216
trainer/Q1Pred Mean                         351.069
trainer/Q1Pred Std                           60.3506
trainer/Q1Pred Max                          427.943
trainer/Q1Pred Min                           12.4851
trainer/Q2Pred Mean                         351.018
trainer/Q2Pred Std                           59.9661
trainer/Q2Pred Max                          428.664
trainer/Q2Pred Min                           20.8089
trainer/QTargetWithReg Mean                 351.092
trainer/QTargetWithReg Std                   59.8245
trainer/QTargetWithReg Max                  428.788
trainer/QTargetWithReg Min                   18.1346
trainer/PolicyLossWithoutReg Mean           351.554
trainer/PolicyLossWithoutReg Std             59.1242
trainer/PolicyLossWithoutReg Max            428.501
trainer/PolicyLossWithoutReg Min             13.1207
exploration/num steps total              938000
exploration/num paths total                1742
exploration/path length this epoch Mean      95
exploration/path length this epoch Std        4
exploration/path length this epoch Max       99
exploration/path length this epoch Min       91
exploration/Rewards Mean                      2.22746
exploration/Rewards Std                       1.24648
exploration/Rewards Max                       5.22546
exploration/Rewards Min                      -0.808252
exploration/Returns Mean                    211.609
exploration/Returns Std                      16.6369
exploration/Returns Max                     228.246
exploration/Returns Min                     194.972
exploration/Num Paths                         2
exploration/Average Returns                 211.609
evaluation_0/num steps total                  7.32037e+06
evaluation_0/num paths total              10966
evaluation_0/path length Mean               873.778
evaluation_0/path length Std                186.042
evaluation_0/path length Max               1000
evaluation_0/path length Min                523
evaluation_0/Rewards Mean                     4.68643
evaluation_0/Rewards Std                      1.02618
evaluation_0/Rewards Max                      8.47802
evaluation_0/Rewards Min                     -0.923764
evaluation_0/Returns Mean                  4094.9
evaluation_0/Returns Std                    901.936
evaluation_0/Returns Max                   4905.21
evaluation_0/Returns Min                   2373.27
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4094.9
time/epoch (s)                                0
time/total (s)                            14139.4
Epoch                                       933
---------------------------------------  ----------------
2022-11-16 20:10:37.504359 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 934 finished
---------------------------------------  ----------------
epoch                                       934
total_step                               939000
replay_pool/size                         939000
trainer/alpha                                 0.0561704
trainer/alpha_loss                           -2.37636
trainer/entropy                              -5.17468
trainer/qf_loss                              36.632
trainer/policy_loss                        -355.231
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.522
trainer/entropy_penalty                      -0.290664
trainer/entropy_percentage                   -0.000817569
trainer/Q1Pred Mean                         354.931
trainer/Q1Pred Std                           69.1212
trainer/Q1Pred Max                          430.641
trainer/Q1Pred Min                          -11.1264
trainer/Q2Pred Mean                         355.056
trainer/Q2Pred Std                           69.2542
trainer/Q2Pred Max                          425.867
trainer/Q2Pred Min                           -6.2478
trainer/QTargetWithReg Mean                 355.447
trainer/QTargetWithReg Std                   69.559
trainer/QTargetWithReg Max                  429.728
trainer/QTargetWithReg Min                   -3.28631
trainer/PolicyLossWithoutReg Mean           355.522
trainer/PolicyLossWithoutReg Std             68.6295
trainer/PolicyLossWithoutReg Max            426.993
trainer/PolicyLossWithoutReg Min             -9.461
exploration/num steps total              939000
exploration/num paths total                1743
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90499
exploration/Rewards Std                       1.00988
exploration/Rewards Max                       7.37568
exploration/Rewards Min                      -0.95117
exploration/Returns Mean                   4904.99
exploration/Returns Std                       0
exploration/Returns Max                    4904.99
exploration/Returns Min                    4904.99
exploration/Num Paths                         1
exploration/Average Returns                4904.99
evaluation_0/num steps total                  7.32837e+06
evaluation_0/num paths total              10974
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.678
evaluation_0/Rewards Std                      1.0499
evaluation_0/Rewards Max                      7.79331
evaluation_0/Rewards Min                     -0.812178
evaluation_0/Returns Mean                  4678
evaluation_0/Returns Std                     71.6108
evaluation_0/Returns Max                   4814.34
evaluation_0/Returns Min                   4573.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4678
time/epoch (s)                                0
time/total (s)                            14154.4
Epoch                                       934
---------------------------------------  ----------------
2022-11-16 20:10:52.292637 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 935 finished
---------------------------------------  ----------------
epoch                                       935
total_step                               940000
replay_pool/size                         940000
trainer/alpha                                 0.055998
trainer/alpha_loss                           -0.702619
trainer/entropy                              -5.75623
trainer/qf_loss                              23.9632
trainer/policy_loss                        -346.168
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.491
trainer/entropy_penalty                      -0.322337
trainer/entropy_percentage                   -0.000930291
trainer/Q1Pred Mean                         345.821
trainer/Q1Pred Std                           76.8344
trainer/Q1Pred Max                          431.108
trainer/Q1Pred Min                          -22.1504
trainer/Q2Pred Mean                         345.373
trainer/Q2Pred Std                           76.9387
trainer/Q2Pred Max                          428.032
trainer/Q2Pred Min                           -8.65117
trainer/QTargetWithReg Mean                 344.587
trainer/QTargetWithReg Std                   77.0403
trainer/QTargetWithReg Max                  428.021
trainer/QTargetWithReg Min                  -15.1698
trainer/PolicyLossWithoutReg Mean           346.491
trainer/PolicyLossWithoutReg Std             74.6675
trainer/PolicyLossWithoutReg Max            428.031
trainer/PolicyLossWithoutReg Min              5.48595
exploration/num steps total              940000
exploration/num paths total                1744
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5055
exploration/Rewards Std                       1.08036
exploration/Rewards Max                       7.0653
exploration/Rewards Min                      -0.837493
exploration/Returns Mean                   4505.5
exploration/Returns Std                       0
exploration/Returns Max                    4505.5
exploration/Returns Min                    4505.5
exploration/Num Paths                         1
exploration/Average Returns                4505.5
evaluation_0/num steps total                  7.33637e+06
evaluation_0/num paths total              10982
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7697
evaluation_0/Rewards Std                      1.15101
evaluation_0/Rewards Max                      7.48715
evaluation_0/Rewards Min                     -0.870563
evaluation_0/Returns Mean                  4769.7
evaluation_0/Returns Std                     55.7224
evaluation_0/Returns Max                   4858.93
evaluation_0/Returns Min                   4654.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4769.7
time/epoch (s)                                0
time/total (s)                            14169.1
Epoch                                       935
---------------------------------------  ----------------
2022-11-16 20:11:07.028622 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 936 finished
---------------------------------------  ----------------
epoch                                       936
total_step                               941000
replay_pool/size                         941000
trainer/alpha                                 0.0554639
trainer/alpha_loss                           -0.768532
trainer/entropy                              -5.73425
trainer/qf_loss                              21.7306
trainer/policy_loss                        -350.754
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.072
trainer/entropy_penalty                      -0.318044
trainer/entropy_percentage                   -0.000905922
trainer/Q1Pred Mean                         350.159
trainer/Q1Pred Std                           60.1904
trainer/Q1Pred Max                          426.221
trainer/Q1Pred Min                            9.32448
trainer/Q2Pred Mean                         350.639
trainer/Q2Pred Std                           59.8111
trainer/Q2Pred Max                          425.079
trainer/Q2Pred Min                           50.5436
trainer/QTargetWithReg Mean                 350.54
trainer/QTargetWithReg Std                   60.5776
trainer/QTargetWithReg Max                  426.915
trainer/QTargetWithReg Min                   25.5809
trainer/PolicyLossWithoutReg Mean           351.072
trainer/PolicyLossWithoutReg Std             59.504
trainer/PolicyLossWithoutReg Max            423.929
trainer/PolicyLossWithoutReg Min             28.836
exploration/num steps total              941000
exploration/num paths total                1745
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72651
exploration/Rewards Std                       1.15589
exploration/Rewards Max                       6.99852
exploration/Rewards Min                      -1.22063
exploration/Returns Mean                   4726.51
exploration/Returns Std                       0
exploration/Returns Max                    4726.51
exploration/Returns Min                    4726.51
exploration/Num Paths                         1
exploration/Average Returns                4726.51
evaluation_0/num steps total                  7.34437e+06
evaluation_0/num paths total              10990
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58035
evaluation_0/Rewards Std                      0.935884
evaluation_0/Rewards Max                      7.0634
evaluation_0/Rewards Min                     -0.728199
evaluation_0/Returns Mean                  4580.35
evaluation_0/Returns Std                     53.8538
evaluation_0/Returns Max                   4669.53
evaluation_0/Returns Min                   4524.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4580.35
time/epoch (s)                                0
time/total (s)                            14183.9
Epoch                                       936
---------------------------------------  ----------------
2022-11-16 20:11:23.549899 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 937 finished
---------------------------------------  ----------------
epoch                                       937
total_step                               942000
replay_pool/size                         942000
trainer/alpha                                 0.0551632
trainer/alpha_loss                            0.0183475
trainer/entropy                              -6.00633
trainer/qf_loss                              26.2878
trainer/policy_loss                        -356.399
trainer/adversary_policy_loss                17.0806
trainer/policy_loss_without_entropy         356.73
trainer/entropy_penalty                      -0.331328
trainer/entropy_percentage                   -0.000928792
trainer/Q1Pred Mean                         356.217
trainer/Q1Pred Std                           59.7253
trainer/Q1Pred Max                          427.841
trainer/Q1Pred Min                           -5.89693
trainer/Q2Pred Mean                         356.456
trainer/Q2Pred Std                           59.9731
trainer/Q2Pred Max                          427.91
trainer/Q2Pred Min                          -13.4839
trainer/QTargetWithReg Mean                 355.439
trainer/QTargetWithReg Std                   60.1709
trainer/QTargetWithReg Max                  426.884
trainer/QTargetWithReg Min                  -11.6076
trainer/PolicyLossWithoutReg Mean           356.73
trainer/PolicyLossWithoutReg Std             58.8118
trainer/PolicyLossWithoutReg Max            426.855
trainer/PolicyLossWithoutReg Min             -0.191656
exploration/num steps total              942000
exploration/num paths total                1746
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61905
exploration/Rewards Std                       0.997545
exploration/Rewards Max                       7.08622
exploration/Rewards Min                      -0.616997
exploration/Returns Mean                   4619.05
exploration/Returns Std                       0
exploration/Returns Max                    4619.05
exploration/Returns Min                    4619.05
exploration/Num Paths                         1
exploration/Average Returns                4619.05
evaluation_0/num steps total                  7.35154e+06
evaluation_0/num paths total              10998
evaluation_0/path length Mean               895.875
evaluation_0/path length Std                275.489
evaluation_0/path length Max               1000
evaluation_0/path length Min                167
evaluation_0/Rewards Mean                     4.75732
evaluation_0/Rewards Std                      1.1184
evaluation_0/Rewards Max                      9.73726
evaluation_0/Rewards Min                     -0.664267
evaluation_0/Returns Mean                  4261.97
evaluation_0/Returns Std                   1440.27
evaluation_0/Returns Max                   4966.09
evaluation_0/Returns Min                    462.262
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4261.97
time/epoch (s)                                0
time/total (s)                            14200.4
Epoch                                       937
---------------------------------------  ----------------
2022-11-16 20:11:38.531760 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 938 finished
---------------------------------------  ----------------
epoch                                       938
total_step                               943000
replay_pool/size                         943000
trainer/alpha                                 0.0570384
trainer/alpha_loss                            0.502673
trainer/entropy                              -6.17551
trainer/qf_loss                              74.8577
trainer/policy_loss                        -344.482
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         344.834
trainer/entropy_penalty                      -0.352241
trainer/entropy_percentage                   -0.00102148
trainer/Q1Pred Mean                         343.97
trainer/Q1Pred Std                           75.0935
trainer/Q1Pred Max                          430.552
trainer/Q1Pred Min                           11.4722
trainer/Q2Pred Mean                         344.235
trainer/Q2Pred Std                           74.6954
trainer/Q2Pred Max                          437.177
trainer/Q2Pred Min                            7.96375
trainer/QTargetWithReg Mean                 343.672
trainer/QTargetWithReg Std                   76.4918
trainer/QTargetWithReg Max                  431.005
trainer/QTargetWithReg Min                    4.69657
trainer/PolicyLossWithoutReg Mean           344.834
trainer/PolicyLossWithoutReg Std             74.5241
trainer/PolicyLossWithoutReg Max            431.436
trainer/PolicyLossWithoutReg Min             11.9869
exploration/num steps total              943000
exploration/num paths total                1747
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60957
exploration/Rewards Std                       1.1092
exploration/Rewards Max                       6.86443
exploration/Rewards Min                      -0.588913
exploration/Returns Mean                   4609.57
exploration/Returns Std                       0
exploration/Returns Max                    4609.57
exploration/Returns Min                    4609.57
exploration/Num Paths                         1
exploration/Average Returns                4609.57
evaluation_0/num steps total                  7.35954e+06
evaluation_0/num paths total              11006
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58503
evaluation_0/Rewards Std                      0.982406
evaluation_0/Rewards Max                      7.13661
evaluation_0/Rewards Min                     -0.891157
evaluation_0/Returns Mean                  4585.03
evaluation_0/Returns Std                     39.1808
evaluation_0/Returns Max                   4632.74
evaluation_0/Returns Min                   4516.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4585.03
time/epoch (s)                                0
time/total (s)                            14215.4
Epoch                                       938
---------------------------------------  ----------------
2022-11-16 20:11:53.478205 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 939 finished
---------------------------------------  ----------------
epoch                                       939
total_step                               944000
replay_pool/size                         944000
trainer/alpha                                 0.0579669
trainer/alpha_loss                            0.492588
trainer/entropy                              -6.17297
trainer/qf_loss                              38.085
trainer/policy_loss                        -349.705
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.062
trainer/entropy_penalty                      -0.357828
trainer/entropy_percentage                   -0.00102218
trainer/Q1Pred Mean                         348.404
trainer/Q1Pred Std                           76.3548
trainer/Q1Pred Max                          424.692
trainer/Q1Pred Min                           -4.11531
trainer/Q2Pred Mean                         349.298
trainer/Q2Pred Std                           76.2072
trainer/Q2Pred Max                          425.524
trainer/Q2Pred Min                          -10.5446
trainer/QTargetWithReg Mean                 349.437
trainer/QTargetWithReg Std                   76.6029
trainer/QTargetWithReg Max                  426.241
trainer/QTargetWithReg Min                   -8.04943
trainer/PolicyLossWithoutReg Mean           350.063
trainer/PolicyLossWithoutReg Std             74.9779
trainer/PolicyLossWithoutReg Max            425.03
trainer/PolicyLossWithoutReg Min             -1.66785
exploration/num steps total              944000
exploration/num paths total                1748
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86128
exploration/Rewards Std                       1.14472
exploration/Rewards Max                       7.06025
exploration/Rewards Min                      -0.751936
exploration/Returns Mean                   4861.28
exploration/Returns Std                       0
exploration/Returns Max                    4861.28
exploration/Returns Min                    4861.28
exploration/Num Paths                         1
exploration/Average Returns                4861.28
evaluation_0/num steps total                  7.36754e+06
evaluation_0/num paths total              11014
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61661
evaluation_0/Rewards Std                      1.18873
evaluation_0/Rewards Max                      7.48859
evaluation_0/Rewards Min                     -0.92473
evaluation_0/Returns Mean                  4616.61
evaluation_0/Returns Std                     59.1714
evaluation_0/Returns Max                   4714.92
evaluation_0/Returns Min                   4519.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4616.61
time/epoch (s)                                0
time/total (s)                            14230.3
Epoch                                       939
---------------------------------------  ----------------
2022-11-16 20:12:08.324987 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 940 finished
---------------------------------------  ----------------
epoch                                       940
total_step                               945000
replay_pool/size                         945000
trainer/alpha                                 0.0575045
trainer/alpha_loss                            0.267774
trainer/entropy                              -6.09377
trainer/qf_loss                              17.7604
trainer/policy_loss                        -348.416
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.766
trainer/entropy_penalty                      -0.350419
trainer/entropy_percentage                   -0.00100474
trainer/Q1Pred Mean                         347.882
trainer/Q1Pred Std                           68.7251
trainer/Q1Pred Max                          429.976
trainer/Q1Pred Min                           11.2761
trainer/Q2Pred Mean                         348.41
trainer/Q2Pred Std                           68.4755
trainer/Q2Pred Max                          428.965
trainer/Q2Pred Min                           12.9529
trainer/QTargetWithReg Mean                 348.843
trainer/QTargetWithReg Std                   68.4655
trainer/QTargetWithReg Max                  428.861
trainer/QTargetWithReg Min                   17.2218
trainer/PolicyLossWithoutReg Mean           348.766
trainer/PolicyLossWithoutReg Std             68.4317
trainer/PolicyLossWithoutReg Max            431.45
trainer/PolicyLossWithoutReg Min             11.5054
exploration/num steps total              945000
exploration/num paths total                1749
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70763
exploration/Rewards Std                       1.01954
exploration/Rewards Max                       7.02808
exploration/Rewards Min                      -1.40404
exploration/Returns Mean                   4707.63
exploration/Returns Std                       0
exploration/Returns Max                    4707.63
exploration/Returns Min                    4707.63
exploration/Num Paths                         1
exploration/Average Returns                4707.63
evaluation_0/num steps total                  7.37554e+06
evaluation_0/num paths total              11022
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68926
evaluation_0/Rewards Std                      1.09333
evaluation_0/Rewards Max                      7.51893
evaluation_0/Rewards Min                     -1.14584
evaluation_0/Returns Mean                  4689.26
evaluation_0/Returns Std                     96.2197
evaluation_0/Returns Max                   4906.7
evaluation_0/Returns Min                   4556.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4689.26
time/epoch (s)                                0
time/total (s)                            14245.2
Epoch                                       940
---------------------------------------  ----------------
2022-11-16 20:12:23.012361 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 941 finished
---------------------------------------  ----------------
epoch                                       941
total_step                               946000
replay_pool/size                         946000
trainer/alpha                                 0.0562747
trainer/alpha_loss                           -0.22263
trainer/entropy                              -5.92263
trainer/qf_loss                              24.4166
trainer/policy_loss                        -351.999
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.333
trainer/entropy_penalty                      -0.333295
trainer/entropy_percentage                   -0.000945965
trainer/Q1Pred Mean                         351.333
trainer/Q1Pred Std                           67.4332
trainer/Q1Pred Max                          444.964
trainer/Q1Pred Min                            0.0677749
trainer/Q2Pred Mean                         351.106
trainer/Q2Pred Std                           67.7377
trainer/Q2Pred Max                          444.99
trainer/Q2Pred Min                           -8.28167
trainer/QTargetWithReg Mean                 351.089
trainer/QTargetWithReg Std                   67.7263
trainer/QTargetWithReg Max                  443.261
trainer/QTargetWithReg Min                    0.58619
trainer/PolicyLossWithoutReg Mean           352.333
trainer/PolicyLossWithoutReg Std             65.8571
trainer/PolicyLossWithoutReg Max            444.869
trainer/PolicyLossWithoutReg Min             12.9044
exploration/num steps total              946000
exploration/num paths total                1750
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52888
exploration/Rewards Std                       1.23501
exploration/Rewards Max                       6.99824
exploration/Rewards Min                      -1.51948
exploration/Returns Mean                   4528.88
exploration/Returns Std                       0
exploration/Returns Max                    4528.88
exploration/Returns Min                    4528.88
exploration/Num Paths                         1
exploration/Average Returns                4528.88
evaluation_0/num steps total                  7.38354e+06
evaluation_0/num paths total              11030
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78273
evaluation_0/Rewards Std                      1.10373
evaluation_0/Rewards Max                      7.5493
evaluation_0/Rewards Min                     -0.918264
evaluation_0/Returns Mean                  4782.73
evaluation_0/Returns Std                    153.069
evaluation_0/Returns Max                   5059.82
evaluation_0/Returns Min                   4523.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4782.73
time/epoch (s)                                0
time/total (s)                            14259.9
Epoch                                       941
---------------------------------------  ----------------
2022-11-16 20:12:37.977143 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 942 finished
---------------------------------------  ----------------
epoch                                       942
total_step                               947000
replay_pool/size                         947000
trainer/alpha                                 0.0575833
trainer/alpha_loss                           -1.0168
trainer/entropy                              -5.64378
trainer/qf_loss                              24.5789
trainer/policy_loss                        -348.973
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         349.298
trainer/entropy_penalty                      -0.324987
trainer/entropy_percentage                   -0.000930401
trainer/Q1Pred Mean                         349.474
trainer/Q1Pred Std                           71.7271
trainer/Q1Pred Max                          435.705
trainer/Q1Pred Min                           12.0993
trainer/Q2Pred Mean                         349.499
trainer/Q2Pred Std                           71.2568
trainer/Q2Pred Max                          438.812
trainer/Q2Pred Min                            8.0514
trainer/QTargetWithReg Mean                 348.544
trainer/QTargetWithReg Std                   72.0946
trainer/QTargetWithReg Max                  437.508
trainer/QTargetWithReg Min                    2.61579
trainer/PolicyLossWithoutReg Mean           349.298
trainer/PolicyLossWithoutReg Std             70.1253
trainer/PolicyLossWithoutReg Max            433.66
trainer/PolicyLossWithoutReg Min              3.47395
exploration/num steps total              947000
exploration/num paths total                1751
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37987
exploration/Rewards Std                       1.18923
exploration/Rewards Max                       7.17892
exploration/Rewards Min                      -0.853628
exploration/Returns Mean                   4379.87
exploration/Returns Std                       0
exploration/Returns Max                    4379.87
exploration/Returns Min                    4379.87
exploration/Num Paths                         1
exploration/Average Returns                4379.87
evaluation_0/num steps total                  7.39154e+06
evaluation_0/num paths total              11038
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76572
evaluation_0/Rewards Std                      1.08723
evaluation_0/Rewards Max                      7.26777
evaluation_0/Rewards Min                     -0.84513
evaluation_0/Returns Mean                  4765.72
evaluation_0/Returns Std                     84.7355
evaluation_0/Returns Max                   4889.15
evaluation_0/Returns Min                   4646.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4765.72
time/epoch (s)                                0
time/total (s)                            14274.8
Epoch                                       942
---------------------------------------  ----------------
2022-11-16 20:12:52.619289 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 943 finished
---------------------------------------  ----------------
epoch                                       943
total_step                               948000
replay_pool/size                         948000
trainer/alpha                                 0.0566651
trainer/alpha_loss                            0.300911
trainer/entropy                              -6.10482
trainer/qf_loss                              26.1171
trainer/policy_loss                        -356.365
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.711
trainer/entropy_penalty                      -0.34593
trainer/entropy_percentage                   -0.000969779
trainer/Q1Pred Mean                         356.261
trainer/Q1Pred Std                           66.5391
trainer/Q1Pred Max                          432.796
trainer/Q1Pred Min                          -29.2781
trainer/Q2Pred Mean                         355.309
trainer/Q2Pred Std                           65.7192
trainer/Q2Pred Max                          429.541
trainer/Q2Pred Min                          -28.497
trainer/QTargetWithReg Mean                 357.149
trainer/QTargetWithReg Std                   65.0445
trainer/QTargetWithReg Max                  433.917
trainer/QTargetWithReg Min                    2.10831
trainer/PolicyLossWithoutReg Mean           356.711
trainer/PolicyLossWithoutReg Std             63.5353
trainer/PolicyLossWithoutReg Max            430.742
trainer/PolicyLossWithoutReg Min             -8.49178
exploration/num steps total              948000
exploration/num paths total                1752
exploration/path length this epoch Mean     103
exploration/path length this epoch Std        0
exploration/path length this epoch Max      103
exploration/path length this epoch Min      103
exploration/Rewards Mean                      2.29824
exploration/Rewards Std                       1.46987
exploration/Rewards Max                       5.42728
exploration/Rewards Min                      -0.742603
exploration/Returns Mean                    236.718
exploration/Returns Std                       0
exploration/Returns Max                     236.718
exploration/Returns Min                     236.718
exploration/Num Paths                         1
exploration/Average Returns                 236.718
evaluation_0/num steps total                  7.39954e+06
evaluation_0/num paths total              11046
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84665
evaluation_0/Rewards Std                      0.99196
evaluation_0/Rewards Max                      7.30104
evaluation_0/Rewards Min                     -0.873131
evaluation_0/Returns Mean                  4846.65
evaluation_0/Returns Std                     70.2415
evaluation_0/Returns Max                   4970.57
evaluation_0/Returns Min                   4747.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4846.65
time/epoch (s)                                0
time/total (s)                            14289.5
Epoch                                       943
---------------------------------------  ----------------
2022-11-16 20:13:09.266539 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 944 finished
---------------------------------------  ----------------
epoch                                       944
total_step                               949000
replay_pool/size                         949000
trainer/alpha                                 0.0570082
trainer/alpha_loss                           -1.77765
trainer/entropy                              -5.37941
trainer/qf_loss                              57.2233
trainer/policy_loss                        -356.404
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.711
trainer/entropy_penalty                      -0.306671
trainer/entropy_percentage                   -0.000859718
trainer/Q1Pred Mean                         354.737
trainer/Q1Pred Std                           62.4736
trainer/Q1Pred Max                          432.952
trainer/Q1Pred Min                           60.3278
trainer/Q2Pred Mean                         354.169
trainer/Q2Pred Std                           61.7167
trainer/Q2Pred Max                          431.386
trainer/Q2Pred Min                           58.5792
trainer/QTargetWithReg Mean                 355.179
trainer/QTargetWithReg Std                   60.4468
trainer/QTargetWithReg Max                  431.58
trainer/QTargetWithReg Min                   98.7084
trainer/PolicyLossWithoutReg Mean           356.711
trainer/PolicyLossWithoutReg Std             58.1012
trainer/PolicyLossWithoutReg Max            431.809
trainer/PolicyLossWithoutReg Min            100.825
exploration/num steps total              949000
exploration/num paths total                1753
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27618
exploration/Rewards Std                       1.12732
exploration/Rewards Max                       6.7387
exploration/Rewards Min                      -0.815166
exploration/Returns Mean                   4276.18
exploration/Returns Std                       0
exploration/Returns Max                    4276.18
exploration/Returns Min                    4276.18
exploration/Num Paths                         1
exploration/Average Returns                4276.18
evaluation_0/num steps total                  7.40663e+06
evaluation_0/num paths total              11054
evaluation_0/path length Mean               886.375
evaluation_0/path length Std                300.623
evaluation_0/path length Max               1000
evaluation_0/path length Min                 91
evaluation_0/Rewards Mean                     4.60894
evaluation_0/Rewards Std                      1.11285
evaluation_0/Rewards Max                      7.49599
evaluation_0/Rewards Min                     -0.852921
evaluation_0/Returns Mean                  4085.25
evaluation_0/Returns Std                   1457.4
evaluation_0/Returns Max                   4810.57
evaluation_0/Returns Min                    241.258
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4085.25
time/epoch (s)                                0
time/total (s)                            14306.1
Epoch                                       944
---------------------------------------  ----------------
2022-11-16 20:13:26.085313 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 945 finished
---------------------------------------  ----------------
epoch                                       945
total_step                               950000
replay_pool/size                         950000
trainer/alpha                                 0.0585303
trainer/alpha_loss                            0.0338029
trainer/entropy                              -6.01191
trainer/qf_loss                              19.8237
trainer/policy_loss                        -352.584
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.936
trainer/entropy_penalty                      -0.351879
trainer/entropy_percentage                   -0.000997005
trainer/Q1Pred Mean                         352.709
trainer/Q1Pred Std                           62.9983
trainer/Q1Pred Max                          432.565
trainer/Q1Pred Min                           82.6525
trainer/Q2Pred Mean                         352.798
trainer/Q2Pred Std                           62.928
trainer/Q2Pred Max                          430.354
trainer/Q2Pred Min                           85.0262
trainer/QTargetWithReg Mean                 352.668
trainer/QTargetWithReg Std                   62.672
trainer/QTargetWithReg Max                  429.89
trainer/QTargetWithReg Min                   85.335
trainer/PolicyLossWithoutReg Mean           352.936
trainer/PolicyLossWithoutReg Std             62.1323
trainer/PolicyLossWithoutReg Max            432.88
trainer/PolicyLossWithoutReg Min             87.441
exploration/num steps total              950000
exploration/num paths total                1754
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56098
exploration/Rewards Std                       1.03983
exploration/Rewards Max                       7.40424
exploration/Rewards Min                      -0.739416
exploration/Returns Mean                   4560.98
exploration/Returns Std                       0
exploration/Returns Max                    4560.98
exploration/Returns Min                    4560.98
exploration/Num Paths                         1
exploration/Average Returns                4560.98
evaluation_0/num steps total                  7.41372e+06
evaluation_0/num paths total              11062
evaluation_0/path length Mean               886.25
evaluation_0/path length Std                300.954
evaluation_0/path length Max               1000
evaluation_0/path length Min                 90
evaluation_0/Rewards Mean                     4.68297
evaluation_0/Rewards Std                      1.13499
evaluation_0/Rewards Max                      7.71061
evaluation_0/Rewards Min                     -0.968381
evaluation_0/Returns Mean                  4150.28
evaluation_0/Returns Std                   1488.07
evaluation_0/Returns Max                   4821.48
evaluation_0/Returns Min                    217.504
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4150.28
time/epoch (s)                                0
time/total (s)                            14322.9
Epoch                                       945
---------------------------------------  ----------------
2022-11-16 20:13:41.044913 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 946 finished
---------------------------------------  ----------------
epoch                                       946
total_step                               951000
replay_pool/size                         951000
trainer/alpha                                 0.0571351
trainer/alpha_loss                           -0.429452
trainer/entropy                              -5.84997
trainer/qf_loss                              21.4483
trainer/policy_loss                        -362.027
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         362.361
trainer/entropy_penalty                      -0.334238
trainer/entropy_percentage                   -0.00092239
trainer/Q1Pred Mean                         362.443
trainer/Q1Pred Std                           50.2667
trainer/Q1Pred Max                          440.329
trainer/Q1Pred Min                          188.415
trainer/Q2Pred Mean                         362.065
trainer/Q2Pred Std                           51.0876
trainer/Q2Pred Max                          441.328
trainer/Q2Pred Min                          185.861
trainer/QTargetWithReg Mean                 361.052
trainer/QTargetWithReg Std                   50.5551
trainer/QTargetWithReg Max                  438.137
trainer/QTargetWithReg Min                  189.365
trainer/PolicyLossWithoutReg Mean           362.361
trainer/PolicyLossWithoutReg Std             50.2349
trainer/PolicyLossWithoutReg Max            438.874
trainer/PolicyLossWithoutReg Min            188.162
exploration/num steps total              951000
exploration/num paths total                1755
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5854
exploration/Rewards Std                       1.16783
exploration/Rewards Max                       7.3091
exploration/Rewards Min                      -1.05166
exploration/Returns Mean                   4585.4
exploration/Returns Std                       0
exploration/Returns Max                    4585.4
exploration/Returns Min                    4585.4
exploration/Num Paths                         1
exploration/Average Returns                4585.4
evaluation_0/num steps total                  7.42172e+06
evaluation_0/num paths total              11070
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85039
evaluation_0/Rewards Std                      1.10864
evaluation_0/Rewards Max                      7.56929
evaluation_0/Rewards Min                     -0.782087
evaluation_0/Returns Mean                  4850.39
evaluation_0/Returns Std                    157.694
evaluation_0/Returns Max                   5068.32
evaluation_0/Returns Min                   4558.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4850.39
time/epoch (s)                                0
time/total (s)                            14337.9
Epoch                                       946
---------------------------------------  ----------------
2022-11-16 20:13:56.050907 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 947 finished
---------------------------------------  ----------------
epoch                                       947
total_step                               952000
replay_pool/size                         952000
trainer/alpha                                 0.0590879
trainer/alpha_loss                            0.0317373
trainer/entropy                              -6.01122
trainer/qf_loss                              28.9752
trainer/policy_loss                        -352.226
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.581
trainer/entropy_penalty                      -0.35519
trainer/entropy_percentage                   -0.0010074
trainer/Q1Pred Mean                         351.476
trainer/Q1Pred Std                           68.812
trainer/Q1Pred Max                          432.07
trainer/Q1Pred Min                            7.08785
trainer/Q2Pred Mean                         351.592
trainer/Q2Pred Std                           69.8187
trainer/Q2Pred Max                          435.795
trainer/Q2Pred Min                           -3.81444
trainer/QTargetWithReg Mean                 351.786
trainer/QTargetWithReg Std                   68.55
trainer/QTargetWithReg Max                  434.85
trainer/QTargetWithReg Min                    6.76424
trainer/PolicyLossWithoutReg Mean           352.581
trainer/PolicyLossWithoutReg Std             67.9682
trainer/PolicyLossWithoutReg Max            433.615
trainer/PolicyLossWithoutReg Min              8.56778
exploration/num steps total              952000
exploration/num paths total                1756
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45164
exploration/Rewards Std                       1.17497
exploration/Rewards Max                       7.16646
exploration/Rewards Min                      -0.667594
exploration/Returns Mean                   4451.64
exploration/Returns Std                       0
exploration/Returns Max                    4451.64
exploration/Returns Min                    4451.64
exploration/Num Paths                         1
exploration/Average Returns                4451.64
evaluation_0/num steps total                  7.42972e+06
evaluation_0/num paths total              11078
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70997
evaluation_0/Rewards Std                      1.01555
evaluation_0/Rewards Max                      7.52149
evaluation_0/Rewards Min                     -0.772344
evaluation_0/Returns Mean                  4709.97
evaluation_0/Returns Std                    118.602
evaluation_0/Returns Max                   4860.42
evaluation_0/Returns Min                   4508.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4709.97
time/epoch (s)                                0
time/total (s)                            14352.9
Epoch                                       947
---------------------------------------  ----------------
2022-11-16 20:14:11.129314 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 948 finished
---------------------------------------  ----------------
epoch                                       948
total_step                               953000
replay_pool/size                         953000
trainer/alpha                                 0.0587189
trainer/alpha_loss                           -0.456056
trainer/entropy                              -5.83913
trainer/qf_loss                              35.5626
trainer/policy_loss                        -353.798
trainer/adversary_policy_loss                16.9278
trainer/policy_loss_without_entropy         354.141
trainer/entropy_penalty                      -0.342867
trainer/entropy_percentage                   -0.000968167
trainer/Q1Pred Mean                         352.423
trainer/Q1Pred Std                           70.036
trainer/Q1Pred Max                          436.477
trainer/Q1Pred Min                          -10.6459
trainer/Q2Pred Mean                         352.629
trainer/Q2Pred Std                           69.8376
trainer/Q2Pred Max                          437.858
trainer/Q2Pred Min                          -11.2529
trainer/QTargetWithReg Mean                 353.355
trainer/QTargetWithReg Std                   69.7944
trainer/QTargetWithReg Max                  437.849
trainer/QTargetWithReg Min                   -5.81542
trainer/PolicyLossWithoutReg Mean           354.141
trainer/PolicyLossWithoutReg Std             68.2719
trainer/PolicyLossWithoutReg Max            436.639
trainer/PolicyLossWithoutReg Min            -13.1088
exploration/num steps total              953000
exploration/num paths total                1757
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59162
exploration/Rewards Std                       1.15802
exploration/Rewards Max                       7.0131
exploration/Rewards Min                      -0.552187
exploration/Returns Mean                   4591.62
exploration/Returns Std                       0
exploration/Returns Max                    4591.62
exploration/Returns Min                    4591.62
exploration/Num Paths                         1
exploration/Average Returns                4591.62
evaluation_0/num steps total                  7.43772e+06
evaluation_0/num paths total              11086
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7484
evaluation_0/Rewards Std                      1.03017
evaluation_0/Rewards Max                      7.46728
evaluation_0/Rewards Min                     -0.837142
evaluation_0/Returns Mean                  4748.4
evaluation_0/Returns Std                     75.1331
evaluation_0/Returns Max                   4889.94
evaluation_0/Returns Min                   4643.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4748.4
time/epoch (s)                                0
time/total (s)                            14368
Epoch                                       948
---------------------------------------  ----------------
2022-11-16 20:14:27.921364 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 949 finished
---------------------------------------  ----------------
epoch                                       949
total_step                               954000
replay_pool/size                         954000
trainer/alpha                                 0.058101
trainer/alpha_loss                           -1.50664
trainer/entropy                              -5.47052
trainer/qf_loss                              21.9193
trainer/policy_loss                        -356.053
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.371
trainer/entropy_penalty                      -0.317843
trainer/entropy_percentage                   -0.000891887
trainer/Q1Pred Mean                         355.177
trainer/Q1Pred Std                           61.7915
trainer/Q1Pred Max                          436.275
trainer/Q1Pred Min                           32.1006
trainer/Q2Pred Mean                         354.913
trainer/Q2Pred Std                           62.3311
trainer/Q2Pred Max                          437.053
trainer/Q2Pred Min                           27.3402
trainer/QTargetWithReg Mean                 355.135
trainer/QTargetWithReg Std                   61.5547
trainer/QTargetWithReg Max                  436.794
trainer/QTargetWithReg Min                   29.5914
trainer/PolicyLossWithoutReg Mean           356.371
trainer/PolicyLossWithoutReg Std             61.3297
trainer/PolicyLossWithoutReg Max            435.872
trainer/PolicyLossWithoutReg Min             28.5704
exploration/num steps total              954000
exploration/num paths total                1758
exploration/path length this epoch Mean     963
exploration/path length this epoch Std        0
exploration/path length this epoch Max      963
exploration/path length this epoch Min      963
exploration/Rewards Mean                      4.83712
exploration/Rewards Std                       1.05846
exploration/Rewards Max                       7.20333
exploration/Rewards Min                      -0.885899
exploration/Returns Mean                   4658.15
exploration/Returns Std                       0
exploration/Returns Max                    4658.15
exploration/Returns Min                    4658.15
exploration/Num Paths                         1
exploration/Average Returns                4658.15
evaluation_0/num steps total                  7.4449e+06
evaluation_0/num paths total              11094
evaluation_0/path length Mean               897.75
evaluation_0/path length Std                270.528
evaluation_0/path length Max               1000
evaluation_0/path length Min                182
evaluation_0/Rewards Mean                     4.66019
evaluation_0/Rewards Std                      1.06363
evaluation_0/Rewards Max                      8.83023
evaluation_0/Rewards Min                     -0.901007
evaluation_0/Returns Mean                  4183.68
evaluation_0/Returns Std                   1336.21
evaluation_0/Returns Max                   4799.37
evaluation_0/Returns Min                    650.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4183.68
time/epoch (s)                                0
time/total (s)                            14384.8
Epoch                                       949
---------------------------------------  ----------------
2022-11-16 20:14:42.796778 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 950 finished
---------------------------------------  ----------------
epoch                                       950
total_step                               955000
replay_pool/size                         955000
trainer/alpha                                 0.0577786
trainer/alpha_loss                           -0.608172
trainer/entropy                              -5.78667
trainer/qf_loss                              29.042
trainer/policy_loss                        -345.746
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.08
trainer/entropy_penalty                      -0.334346
trainer/entropy_percentage                   -0.000966092
trainer/Q1Pred Mean                         345.181
trainer/Q1Pred Std                           70.4014
trainer/Q1Pred Max                          432.499
trainer/Q1Pred Min                            9.68124
trainer/Q2Pred Mean                         344.175
trainer/Q2Pred Std                           70.7073
trainer/Q2Pred Max                          430.881
trainer/Q2Pred Min                            4.76827
trainer/QTargetWithReg Mean                 345.858
trainer/QTargetWithReg Std                   70.9219
trainer/QTargetWithReg Max                  433.231
trainer/QTargetWithReg Min                    7.34258
trainer/PolicyLossWithoutReg Mean           346.08
trainer/PolicyLossWithoutReg Std             69.7432
trainer/PolicyLossWithoutReg Max            432.03
trainer/PolicyLossWithoutReg Min             15.6206
exploration/num steps total              955000
exploration/num paths total                1759
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62103
exploration/Rewards Std                       1.06441
exploration/Rewards Max                       7.06956
exploration/Rewards Min                      -0.969031
exploration/Returns Mean                   4621.03
exploration/Returns Std                       0
exploration/Returns Max                    4621.03
exploration/Returns Min                    4621.03
exploration/Num Paths                         1
exploration/Average Returns                4621.03
evaluation_0/num steps total                  7.4529e+06
evaluation_0/num paths total              11102
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68542
evaluation_0/Rewards Std                      0.996873
evaluation_0/Rewards Max                      7.37962
evaluation_0/Rewards Min                     -0.662123
evaluation_0/Returns Mean                  4685.42
evaluation_0/Returns Std                     58.6786
evaluation_0/Returns Max                   4803.2
evaluation_0/Returns Min                   4609.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4685.42
time/epoch (s)                                0
time/total (s)                            14399.6
Epoch                                       950
---------------------------------------  ----------------
2022-11-16 20:14:57.790393 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 951 finished
---------------------------------------  ---------------
epoch                                       951
total_step                               956000
replay_pool/size                         956000
trainer/alpha                                 0.0578132
trainer/alpha_loss                           -0.959847
trainer/entropy                              -5.66328
trainer/qf_loss                              24.7932
trainer/policy_loss                        -353.888
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.215
trainer/entropy_penalty                      -0.327412
trainer/entropy_percentage                   -0.00092433
trainer/Q1Pred Mean                         353.759
trainer/Q1Pred Std                           69.3872
trainer/Q1Pred Max                          433.736
trainer/Q1Pred Min                          -48.1253
trainer/Q2Pred Mean                         353.622
trainer/Q2Pred Std                           69.6777
trainer/Q2Pred Max                          439.77
trainer/Q2Pred Min                          -20.5437
trainer/QTargetWithReg Mean                 354.146
trainer/QTargetWithReg Std                   69.1558
trainer/QTargetWithReg Max                  442.023
trainer/QTargetWithReg Min                  -11.9479
trainer/PolicyLossWithoutReg Mean           354.215
trainer/PolicyLossWithoutReg Std             69.333
trainer/PolicyLossWithoutReg Max            434.831
trainer/PolicyLossWithoutReg Min            -42.9116
exploration/num steps total              956000
exploration/num paths total                1760
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67321
exploration/Rewards Std                       1.04596
exploration/Rewards Max                       7.22467
exploration/Rewards Min                      -0.466847
exploration/Returns Mean                   4673.21
exploration/Returns Std                       0
exploration/Returns Max                    4673.21
exploration/Returns Min                    4673.21
exploration/Num Paths                         1
exploration/Average Returns                4673.21
evaluation_0/num steps total                  7.4609e+06
evaluation_0/num paths total              11110
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66312
evaluation_0/Rewards Std                      1.01816
evaluation_0/Rewards Max                      7.36799
evaluation_0/Rewards Min                     -0.816942
evaluation_0/Returns Mean                  4663.12
evaluation_0/Returns Std                     88.892
evaluation_0/Returns Max                   4774.22
evaluation_0/Returns Min                   4509.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4663.12
time/epoch (s)                                0
time/total (s)                            14414.6
Epoch                                       951
---------------------------------------  ---------------
2022-11-16 20:15:12.654134 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 952 finished
---------------------------------------  ----------------
epoch                                       952
total_step                               957000
replay_pool/size                         957000
trainer/alpha                                 0.0575658
trainer/alpha_loss                           -0.0316248
trainer/entropy                              -5.98892
trainer/qf_loss                              26.0402
trainer/policy_loss                        -359.646
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         359.991
trainer/entropy_penalty                      -0.344757
trainer/entropy_percentage                   -0.000957683
trainer/Q1Pred Mean                         359.675
trainer/Q1Pred Std                           56.9845
trainer/Q1Pred Max                          436.005
trainer/Q1Pred Min                           42.468
trainer/Q2Pred Mean                         359.973
trainer/Q2Pred Std                           57.5017
trainer/Q2Pred Max                          435.977
trainer/Q2Pred Min                           42.4122
trainer/QTargetWithReg Mean                 359.589
trainer/QTargetWithReg Std                   56.9103
trainer/QTargetWithReg Max                  435.062
trainer/QTargetWithReg Min                   42.9872
trainer/PolicyLossWithoutReg Mean           359.991
trainer/PolicyLossWithoutReg Std             56.3792
trainer/PolicyLossWithoutReg Max            435.122
trainer/PolicyLossWithoutReg Min             41.3014
exploration/num steps total              957000
exploration/num paths total                1761
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57296
exploration/Rewards Std                       1.03458
exploration/Rewards Max                       7.34118
exploration/Rewards Min                      -0.841904
exploration/Returns Mean                   4572.96
exploration/Returns Std                       0
exploration/Returns Max                    4572.96
exploration/Returns Min                    4572.96
exploration/Num Paths                         1
exploration/Average Returns                4572.96
evaluation_0/num steps total                  7.4689e+06
evaluation_0/num paths total              11118
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92133
evaluation_0/Rewards Std                      1.02233
evaluation_0/Rewards Max                      7.34231
evaluation_0/Rewards Min                     -1.00861
evaluation_0/Returns Mean                  4921.33
evaluation_0/Returns Std                     99.5058
evaluation_0/Returns Max                   5061.52
evaluation_0/Returns Min                   4753.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4921.33
time/epoch (s)                                0
time/total (s)                            14429.5
Epoch                                       952
---------------------------------------  ----------------
2022-11-16 20:15:29.581193 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 953 finished
---------------------------------------  ----------------
epoch                                       953
total_step                               958000
replay_pool/size                         958000
trainer/alpha                                 0.0570427
trainer/alpha_loss                           -0.386449
trainer/entropy                              -5.86505
trainer/qf_loss                              30.9338
trainer/policy_loss                        -350.09
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.424
trainer/entropy_penalty                      -0.334559
trainer/entropy_percentage                   -0.000954724
trainer/Q1Pred Mean                         348.923
trainer/Q1Pred Std                           73.0546
trainer/Q1Pred Max                          433.695
trainer/Q1Pred Min                          -28.706
trainer/Q2Pred Mean                         348.136
trainer/Q2Pred Std                           72.9995
trainer/Q2Pred Max                          433.505
trainer/Q2Pred Min                          -38.5594
trainer/QTargetWithReg Mean                 348.897
trainer/QTargetWithReg Std                   73.0564
trainer/QTargetWithReg Max                  434.11
trainer/QTargetWithReg Min                    0.424254
trainer/PolicyLossWithoutReg Mean           350.424
trainer/PolicyLossWithoutReg Std             68.358
trainer/PolicyLossWithoutReg Max            433.997
trainer/PolicyLossWithoutReg Min              4.91047
exploration/num steps total              958000
exploration/num paths total                1762
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77071
exploration/Rewards Std                       1.03996
exploration/Rewards Max                       7.58264
exploration/Rewards Min                      -1.03795
exploration/Returns Mean                   4770.71
exploration/Returns Std                       0
exploration/Returns Max                    4770.71
exploration/Returns Min                    4770.71
exploration/Num Paths                         1
exploration/Average Returns                4770.71
evaluation_0/num steps total                  7.47638e+06
evaluation_0/num paths total              11126
evaluation_0/path length Mean               934.875
evaluation_0/path length Std                172.305
evaluation_0/path length Max               1000
evaluation_0/path length Min                479
evaluation_0/Rewards Mean                     4.48093
evaluation_0/Rewards Std                      1.21248
evaluation_0/Rewards Max                      7.67667
evaluation_0/Rewards Min                     -0.756072
evaluation_0/Returns Mean                  4189.11
evaluation_0/Returns Std                    871.612
evaluation_0/Returns Max                   4677.77
evaluation_0/Returns Min                   1901.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4189.11
time/epoch (s)                                0
time/total (s)                            14446.4
Epoch                                       953
---------------------------------------  ----------------
2022-11-16 20:15:44.542520 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 954 finished
---------------------------------------  ----------------
epoch                                       954
total_step                               959000
replay_pool/size                         959000
trainer/alpha                                 0.0576572
trainer/alpha_loss                           -0.754896
trainer/entropy                              -5.73542
trainer/qf_loss                              15.2094
trainer/policy_loss                        -357.167
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.498
trainer/entropy_penalty                      -0.330689
trainer/entropy_percentage                   -0.000925009
trainer/Q1Pred Mean                         356.499
trainer/Q1Pred Std                           58.3052
trainer/Q1Pred Max                          425.798
trainer/Q1Pred Min                           35.5237
trainer/Q2Pred Mean                         357.194
trainer/Q2Pred Std                           58.1037
trainer/Q2Pred Max                          426.415
trainer/Q2Pred Min                           34.2171
trainer/QTargetWithReg Mean                 357.295
trainer/QTargetWithReg Std                   58.0893
trainer/QTargetWithReg Max                  431.562
trainer/QTargetWithReg Min                   39.0925
trainer/PolicyLossWithoutReg Mean           357.498
trainer/PolicyLossWithoutReg Std             58.0943
trainer/PolicyLossWithoutReg Max            427.687
trainer/PolicyLossWithoutReg Min             43.8149
exploration/num steps total              959000
exploration/num paths total                1763
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69283
exploration/Rewards Std                       1.0715
exploration/Rewards Max                       7.04457
exploration/Rewards Min                      -0.684108
exploration/Returns Mean                   4692.83
exploration/Returns Std                       0
exploration/Returns Max                    4692.83
exploration/Returns Min                    4692.83
exploration/Num Paths                         1
exploration/Average Returns                4692.83
evaluation_0/num steps total                  7.48438e+06
evaluation_0/num paths total              11134
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88482
evaluation_0/Rewards Std                      0.999572
evaluation_0/Rewards Max                      7.13408
evaluation_0/Rewards Min                     -0.451709
evaluation_0/Returns Mean                  4884.82
evaluation_0/Returns Std                     39.9106
evaluation_0/Returns Max                   4949.7
evaluation_0/Returns Min                   4825.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4884.82
time/epoch (s)                                0
time/total (s)                            14461.4
Epoch                                       954
---------------------------------------  ----------------
2022-11-16 20:16:01.215382 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 955 finished
---------------------------------------  ----------------
epoch                                       955
total_step                               960000
replay_pool/size                         960000
trainer/alpha                                 0.056507
trainer/alpha_loss                           -0.302154
trainer/entropy                              -5.89485
trainer/qf_loss                              18.4256
trainer/policy_loss                        -357.06
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.393
trainer/entropy_penalty                      -0.3331
trainer/entropy_percentage                   -0.000932029
trainer/Q1Pred Mean                         355.131
trainer/Q1Pred Std                           67.5399
trainer/Q1Pred Max                          428.033
trainer/Q1Pred Min                            2.41708
trainer/Q2Pred Mean                         355.402
trainer/Q2Pred Std                           68.1684
trainer/Q2Pred Max                          430.872
trainer/Q2Pred Min                            1.90647
trainer/QTargetWithReg Mean                 356.324
trainer/QTargetWithReg Std                   68.0055
trainer/QTargetWithReg Max                  430.13
trainer/QTargetWithReg Min                    0.0101343
trainer/PolicyLossWithoutReg Mean           357.393
trainer/PolicyLossWithoutReg Std             63.6331
trainer/PolicyLossWithoutReg Max            430.65
trainer/PolicyLossWithoutReg Min             28.523
exploration/num steps total              960000
exploration/num paths total                1764
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55259
exploration/Rewards Std                       0.97465
exploration/Rewards Max                       6.74304
exploration/Rewards Min                      -0.560135
exploration/Returns Mean                   4552.59
exploration/Returns Std                       0
exploration/Returns Max                    4552.59
exploration/Returns Min                    4552.59
exploration/Num Paths                         1
exploration/Average Returns                4552.59
evaluation_0/num steps total                  7.49211e+06
evaluation_0/num paths total              11142
evaluation_0/path length Mean               966.375
evaluation_0/path length Std                 61.0327
evaluation_0/path length Max               1000
evaluation_0/path length Min                829
evaluation_0/Rewards Mean                     4.53888
evaluation_0/Rewards Std                      1.06085
evaluation_0/Rewards Max                      7.31246
evaluation_0/Rewards Min                     -0.51615
evaluation_0/Returns Mean                  4386.26
evaluation_0/Returns Std                    297.472
evaluation_0/Returns Max                   4676.63
evaluation_0/Returns Min                   3789.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4386.26
time/epoch (s)                                0
time/total (s)                            14478.1
Epoch                                       955
---------------------------------------  ----------------
2022-11-16 20:16:16.057252 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 956 finished
---------------------------------------  ----------------
epoch                                       956
total_step                               961000
replay_pool/size                         961000
trainer/alpha                                 0.0588389
trainer/alpha_loss                           -0.336354
trainer/entropy                              -5.88128
trainer/qf_loss                              35.5858
trainer/policy_loss                        -350.369
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.715
trainer/entropy_penalty                      -0.346048
trainer/entropy_percentage                   -0.000986693
trainer/Q1Pred Mean                         348.209
trainer/Q1Pred Std                           77.4403
trainer/Q1Pred Max                          426.778
trainer/Q1Pred Min                          -14.1048
trainer/Q2Pred Mean                         348.54
trainer/Q2Pred Std                           77.8676
trainer/Q2Pred Max                          427.814
trainer/Q2Pred Min                          -24.4515
trainer/QTargetWithReg Mean                 347.449
trainer/QTargetWithReg Std                   78.2857
trainer/QTargetWithReg Max                  425.688
trainer/QTargetWithReg Min                  -21.8918
trainer/PolicyLossWithoutReg Mean           350.715
trainer/PolicyLossWithoutReg Std             74.324
trainer/PolicyLossWithoutReg Max            427.347
trainer/PolicyLossWithoutReg Min            -23.496
exploration/num steps total              961000
exploration/num paths total                1765
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57576
exploration/Rewards Std                       1.04054
exploration/Rewards Max                       7.27326
exploration/Rewards Min                      -0.633813
exploration/Returns Mean                   4575.76
exploration/Returns Std                       0
exploration/Returns Max                    4575.76
exploration/Returns Min                    4575.76
exploration/Num Paths                         1
exploration/Average Returns                4575.76
evaluation_0/num steps total                  7.50011e+06
evaluation_0/num paths total              11150
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83636
evaluation_0/Rewards Std                      1.10145
evaluation_0/Rewards Max                      7.60749
evaluation_0/Rewards Min                     -0.897735
evaluation_0/Returns Mean                  4836.36
evaluation_0/Returns Std                     95.7639
evaluation_0/Returns Max                   4952.36
evaluation_0/Returns Min                   4679.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.36
time/epoch (s)                                0
time/total (s)                            14492.9
Epoch                                       956
---------------------------------------  ----------------
2022-11-16 20:16:31.071312 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 957 finished
---------------------------------------  ----------------
epoch                                       957
total_step                               962000
replay_pool/size                         962000
trainer/alpha                                 0.0592795
trainer/alpha_loss                           -0.711984
trainer/entropy                              -5.748
trainer/qf_loss                              23.9048
trainer/policy_loss                        -360.926
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         361.267
trainer/entropy_penalty                      -0.340738
trainer/entropy_percentage                   -0.000943177
trainer/Q1Pred Mean                         360.916
trainer/Q1Pred Std                           61.5181
trainer/Q1Pred Max                          429.55
trainer/Q1Pred Min                           65.3988
trainer/Q2Pred Mean                         360.817
trainer/Q2Pred Std                           61.8315
trainer/Q2Pred Max                          428.445
trainer/Q2Pred Min                           56.5665
trainer/QTargetWithReg Mean                 360.68
trainer/QTargetWithReg Std                   62.9953
trainer/QTargetWithReg Max                  430.417
trainer/QTargetWithReg Min                   59.2704
trainer/PolicyLossWithoutReg Mean           361.267
trainer/PolicyLossWithoutReg Std             60.4035
trainer/PolicyLossWithoutReg Max            429.277
trainer/PolicyLossWithoutReg Min             63.1414
exploration/num steps total              962000
exploration/num paths total                1766
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66319
exploration/Rewards Std                       0.944997
exploration/Rewards Max                       7.11652
exploration/Rewards Min                      -0.622245
exploration/Returns Mean                   4663.19
exploration/Returns Std                       0
exploration/Returns Max                    4663.19
exploration/Returns Min                    4663.19
exploration/Num Paths                         1
exploration/Average Returns                4663.19
evaluation_0/num steps total                  7.50811e+06
evaluation_0/num paths total              11158
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64671
evaluation_0/Rewards Std                      1.13246
evaluation_0/Rewards Max                      7.61479
evaluation_0/Rewards Min                     -0.897808
evaluation_0/Returns Mean                  4646.71
evaluation_0/Returns Std                    122.968
evaluation_0/Returns Max                   4838.46
evaluation_0/Returns Min                   4381.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4646.71
time/epoch (s)                                0
time/total (s)                            14507.9
Epoch                                       957
---------------------------------------  ----------------
2022-11-16 20:16:45.986599 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 958 finished
---------------------------------------  ----------------
epoch                                       958
total_step                               963000
replay_pool/size                         963000
trainer/alpha                                 0.0574459
trainer/alpha_loss                           -0.435369
trainer/entropy                              -5.8476
trainer/qf_loss                              24.385
trainer/policy_loss                        -351.166
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.501
trainer/entropy_penalty                      -0.335921
trainer/entropy_percentage                   -0.000955674
trainer/Q1Pred Mean                         351.075
trainer/Q1Pred Std                           74.1439
trainer/Q1Pred Max                          436.772
trainer/Q1Pred Min                           29.2504
trainer/Q2Pred Mean                         351.381
trainer/Q2Pred Std                           74.1324
trainer/Q2Pred Max                          434.052
trainer/Q2Pred Min                           33.101
trainer/QTargetWithReg Mean                 350.215
trainer/QTargetWithReg Std                   74.7457
trainer/QTargetWithReg Max                  437.479
trainer/QTargetWithReg Min                   31.6275
trainer/PolicyLossWithoutReg Mean           351.502
trainer/PolicyLossWithoutReg Std             73.6073
trainer/PolicyLossWithoutReg Max            435.161
trainer/PolicyLossWithoutReg Min             32.123
exploration/num steps total              963000
exploration/num paths total                1767
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61961
exploration/Rewards Std                       0.982115
exploration/Rewards Max                       6.83692
exploration/Rewards Min                      -0.755034
exploration/Returns Mean                   4619.61
exploration/Returns Std                       0
exploration/Returns Max                    4619.61
exploration/Returns Min                    4619.61
exploration/Num Paths                         1
exploration/Average Returns                4619.61
evaluation_0/num steps total                  7.51611e+06
evaluation_0/num paths total              11166
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81446
evaluation_0/Rewards Std                      1.02869
evaluation_0/Rewards Max                      7.35234
evaluation_0/Rewards Min                     -0.835539
evaluation_0/Returns Mean                  4814.46
evaluation_0/Returns Std                     60.1758
evaluation_0/Returns Max                   4938.31
evaluation_0/Returns Min                   4714.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4814.46
time/epoch (s)                                0
time/total (s)                            14522.8
Epoch                                       958
---------------------------------------  ----------------
2022-11-16 20:17:00.974916 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 959 finished
---------------------------------------  ----------------
epoch                                       959
total_step                               964000
replay_pool/size                         964000
trainer/alpha                                 0.0585662
trainer/alpha_loss                           -0.455546
trainer/entropy                              -5.83948
trainer/qf_loss                              24.856
trainer/policy_loss                        -352.366
trainer/adversary_policy_loss                16.9741
trainer/policy_loss_without_entropy         352.708
trainer/entropy_penalty                      -0.341996
trainer/entropy_percentage                   -0.000969628
trainer/Q1Pred Mean                         352.432
trainer/Q1Pred Std                           69.2817
trainer/Q1Pred Max                          433.117
trainer/Q1Pred Min                           19.8753
trainer/Q2Pred Mean                         352.477
trainer/Q2Pred Std                           70.3269
trainer/Q2Pred Max                          433.149
trainer/Q2Pred Min                           -3.21972
trainer/QTargetWithReg Mean                 352.312
trainer/QTargetWithReg Std                   70.109
trainer/QTargetWithReg Max                  432.989
trainer/QTargetWithReg Min                    2.17729
trainer/PolicyLossWithoutReg Mean           352.708
trainer/PolicyLossWithoutReg Std             69.3973
trainer/PolicyLossWithoutReg Max            433.348
trainer/PolicyLossWithoutReg Min             -2.45695
exploration/num steps total              964000
exploration/num paths total                1768
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71874
exploration/Rewards Std                       1.01349
exploration/Rewards Max                       7.32725
exploration/Rewards Min                      -0.794277
exploration/Returns Mean                   4718.74
exploration/Returns Std                       0
exploration/Returns Max                    4718.74
exploration/Returns Min                    4718.74
exploration/Num Paths                         1
exploration/Average Returns                4718.74
evaluation_0/num steps total                  7.52411e+06
evaluation_0/num paths total              11174
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73699
evaluation_0/Rewards Std                      1.0745
evaluation_0/Rewards Max                      7.72798
evaluation_0/Rewards Min                     -0.548188
evaluation_0/Returns Mean                  4736.99
evaluation_0/Returns Std                    115.483
evaluation_0/Returns Max                   4943.55
evaluation_0/Returns Min                   4567.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4736.99
time/epoch (s)                                0
time/total (s)                            14537.8
Epoch                                       959
---------------------------------------  ----------------
2022-11-16 20:17:15.815387 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 960 finished
---------------------------------------  ----------------
epoch                                       960
total_step                               965000
replay_pool/size                         965000
trainer/alpha                                 0.0583012
trainer/alpha_loss                           -0.571401
trainer/entropy                              -5.79895
trainer/qf_loss                              23.7902
trainer/policy_loss                        -355.311
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.65
trainer/entropy_penalty                      -0.338085
trainer/entropy_percentage                   -0.000950614
trainer/Q1Pred Mean                         354.878
trainer/Q1Pred Std                           64.8799
trainer/Q1Pred Max                          428.942
trainer/Q1Pred Min                           23.3349
trainer/Q2Pred Mean                         354.764
trainer/Q2Pred Std                           65.0923
trainer/Q2Pred Max                          430.808
trainer/Q2Pred Min                           28.1064
trainer/QTargetWithReg Mean                 355.425
trainer/QTargetWithReg Std                   64.7686
trainer/QTargetWithReg Max                  430.815
trainer/QTargetWithReg Min                   19.5346
trainer/PolicyLossWithoutReg Mean           355.65
trainer/PolicyLossWithoutReg Std             64.4257
trainer/PolicyLossWithoutReg Max            430.286
trainer/PolicyLossWithoutReg Min             20.3902
exploration/num steps total              965000
exploration/num paths total                1769
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.38554
exploration/Rewards Std                       0.964247
exploration/Rewards Max                       7.41906
exploration/Rewards Min                      -0.413023
exploration/Returns Mean                   4385.54
exploration/Returns Std                       0
exploration/Returns Max                    4385.54
exploration/Returns Min                    4385.54
exploration/Num Paths                         1
exploration/Average Returns                4385.54
evaluation_0/num steps total                  7.53211e+06
evaluation_0/num paths total              11182
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6208
evaluation_0/Rewards Std                      0.957587
evaluation_0/Rewards Max                      7.39406
evaluation_0/Rewards Min                     -0.620792
evaluation_0/Returns Mean                  4620.8
evaluation_0/Returns Std                     84.242
evaluation_0/Returns Max                   4758.04
evaluation_0/Returns Min                   4457.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4620.8
time/epoch (s)                                0
time/total (s)                            14552.7
Epoch                                       960
---------------------------------------  ----------------
2022-11-16 20:17:30.834425 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 961 finished
---------------------------------------  ----------------
epoch                                       961
total_step                               966000
replay_pool/size                         966000
trainer/alpha                                 0.0591078
trainer/alpha_loss                           -0.498223
trainer/entropy                              -5.82384
trainer/qf_loss                              32.4432
trainer/policy_loss                        -348.092
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.436
trainer/entropy_penalty                      -0.344234
trainer/entropy_percentage                   -0.00098794
trainer/Q1Pred Mean                         347.602
trainer/Q1Pred Std                           68.0012
trainer/Q1Pred Max                          431.836
trainer/Q1Pred Min                           22.7776
trainer/Q2Pred Mean                         347.198
trainer/Q2Pred Std                           68.1529
trainer/Q2Pred Max                          429.18
trainer/Q2Pred Min                           24.7166
trainer/QTargetWithReg Mean                 347.362
trainer/QTargetWithReg Std                   67.8909
trainer/QTargetWithReg Max                  429.808
trainer/QTargetWithReg Min                   27.0204
trainer/PolicyLossWithoutReg Mean           348.436
trainer/PolicyLossWithoutReg Std             66.7827
trainer/PolicyLossWithoutReg Max            428.471
trainer/PolicyLossWithoutReg Min             23.7574
exploration/num steps total              966000
exploration/num paths total                1770
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65357
exploration/Rewards Std                       0.994437
exploration/Rewards Max                       7.12551
exploration/Rewards Min                      -0.602255
exploration/Returns Mean                   4653.57
exploration/Returns Std                       0
exploration/Returns Max                    4653.57
exploration/Returns Min                    4653.57
exploration/Num Paths                         1
exploration/Average Returns                4653.57
evaluation_0/num steps total                  7.54011e+06
evaluation_0/num paths total              11190
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71311
evaluation_0/Rewards Std                      1.10994
evaluation_0/Rewards Max                      7.52096
evaluation_0/Rewards Min                     -0.603108
evaluation_0/Returns Mean                  4713.11
evaluation_0/Returns Std                    136.715
evaluation_0/Returns Max                   4950.01
evaluation_0/Returns Min                   4554.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4713.11
time/epoch (s)                                0
time/total (s)                            14567.7
Epoch                                       961
---------------------------------------  ----------------
2022-11-16 20:17:44.365846 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 962 finished
---------------------------------------  ----------------
epoch                                       962
total_step                               967000
replay_pool/size                         967000
trainer/alpha                                 0.0573437
trainer/alpha_loss                           -0.218775
trainer/entropy                              -5.92347
trainer/qf_loss                              89.2689
trainer/policy_loss                        -351.394
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.733
trainer/entropy_penalty                      -0.339674
trainer/entropy_percentage                   -0.000965714
trainer/Q1Pred Mean                         349.753
trainer/Q1Pred Std                           75.699
trainer/Q1Pred Max                          427.982
trainer/Q1Pred Min                         -114.869
trainer/Q2Pred Mean                         348.53
trainer/Q2Pred Std                           74.7972
trainer/Q2Pred Max                          426.116
trainer/Q2Pred Min                         -110.619
trainer/QTargetWithReg Mean                 349.425
trainer/QTargetWithReg Std                   74.3694
trainer/QTargetWithReg Max                  427.013
trainer/QTargetWithReg Min                   -3.29439
trainer/PolicyLossWithoutReg Mean           351.733
trainer/PolicyLossWithoutReg Std             67.8001
trainer/PolicyLossWithoutReg Max            426.244
trainer/PolicyLossWithoutReg Min              5.3577
exploration/num steps total              967000
exploration/num paths total                1771
exploration/path length this epoch Mean     842
exploration/path length this epoch Std        0
exploration/path length this epoch Max      842
exploration/path length this epoch Min      842
exploration/Rewards Mean                      4.47416
exploration/Rewards Std                       1.3486
exploration/Rewards Max                       6.82197
exploration/Rewards Min                      -0.420772
exploration/Returns Mean                   3767.24
exploration/Returns Std                       0
exploration/Returns Max                    3767.24
exploration/Returns Min                    3767.24
exploration/Num Paths                         1
exploration/Average Returns                3767.24
evaluation_0/num steps total                  7.54811e+06
evaluation_0/num paths total              11198
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8437
evaluation_0/Rewards Std                      1.04052
evaluation_0/Rewards Max                      7.56529
evaluation_0/Rewards Min                     -0.715617
evaluation_0/Returns Mean                  4843.7
evaluation_0/Returns Std                     49.2199
evaluation_0/Returns Max                   4938.71
evaluation_0/Returns Min                   4758.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4843.7
time/epoch (s)                                0
time/total (s)                            14581.2
Epoch                                       962
---------------------------------------  ----------------
2022-11-16 20:17:55.174622 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 963 finished
---------------------------------------  ----------------
epoch                                       963
total_step                               968000
replay_pool/size                         968000
trainer/alpha                                 0.0583353
trainer/alpha_loss                           -1.10909
trainer/entropy                              -5.60968
trainer/qf_loss                              19.6271
trainer/policy_loss                        -351.786
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.114
trainer/entropy_penalty                      -0.327242
trainer/entropy_percentage                   -0.000929366
trainer/Q1Pred Mean                         351.634
trainer/Q1Pred Std                           67.4356
trainer/Q1Pred Max                          439.112
trainer/Q1Pred Min                           37.7083
trainer/Q2Pred Mean                         351.523
trainer/Q2Pred Std                           67.4176
trainer/Q2Pred Max                          439.449
trainer/Q2Pred Min                           38.9643
trainer/QTargetWithReg Mean                 351.331
trainer/QTargetWithReg Std                   67.9573
trainer/QTargetWithReg Max                  439.836
trainer/QTargetWithReg Min                   36.3944
trainer/PolicyLossWithoutReg Mean           352.114
trainer/PolicyLossWithoutReg Std             66.86
trainer/PolicyLossWithoutReg Max            438.244
trainer/PolicyLossWithoutReg Min             39.2209
exploration/num steps total              968000
exploration/num paths total                1772
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64862
exploration/Rewards Std                       1.02237
exploration/Rewards Max                       7.00935
exploration/Rewards Min                      -0.761233
exploration/Returns Mean                   4648.62
exploration/Returns Std                       0
exploration/Returns Max                    4648.62
exploration/Returns Min                    4648.62
exploration/Num Paths                         1
exploration/Average Returns                4648.62
evaluation_0/num steps total                  7.55611e+06
evaluation_0/num paths total              11206
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98677
evaluation_0/Rewards Std                      1.05899
evaluation_0/Rewards Max                      7.40791
evaluation_0/Rewards Min                     -0.702513
evaluation_0/Returns Mean                  4986.77
evaluation_0/Returns Std                     40.9421
evaluation_0/Returns Max                   5040.56
evaluation_0/Returns Min                   4921.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4986.77
time/epoch (s)                                0
time/total (s)                            14592
Epoch                                       963
---------------------------------------  ----------------
2022-11-16 20:18:06.012592 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 964 finished
---------------------------------------  ----------------
epoch                                       964
total_step                               969000
replay_pool/size                         969000
trainer/alpha                                 0.0570695
trainer/alpha_loss                           -0.132598
trainer/entropy                              -5.95369
trainer/qf_loss                              16.195
trainer/policy_loss                        -356.964
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.303
trainer/entropy_penalty                      -0.339774
trainer/entropy_percentage                   -0.00095094
trainer/Q1Pred Mean                         357.237
trainer/Q1Pred Std                           61.9843
trainer/Q1Pred Max                          433.567
trainer/Q1Pred Min                           -7.79977
trainer/Q2Pred Mean                         357.186
trainer/Q2Pred Std                           61.7382
trainer/Q2Pred Max                          430.478
trainer/Q2Pred Min                            9.25223
trainer/QTargetWithReg Mean                 357.209
trainer/QTargetWithReg Std                   61.4123
trainer/QTargetWithReg Max                  432.941
trainer/QTargetWithReg Min                    5.26754
trainer/PolicyLossWithoutReg Mean           357.303
trainer/PolicyLossWithoutReg Std             61.187
trainer/PolicyLossWithoutReg Max            430
trainer/PolicyLossWithoutReg Min             16.6681
exploration/num steps total              969000
exploration/num paths total                1773
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58089
exploration/Rewards Std                       1.04951
exploration/Rewards Max                       6.98578
exploration/Rewards Min                      -0.745857
exploration/Returns Mean                   4580.89
exploration/Returns Std                       0
exploration/Returns Max                    4580.89
exploration/Returns Min                    4580.89
exploration/Num Paths                         1
exploration/Average Returns                4580.89
evaluation_0/num steps total                  7.56411e+06
evaluation_0/num paths total              11214
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83373
evaluation_0/Rewards Std                      1.06241
evaluation_0/Rewards Max                      7.45448
evaluation_0/Rewards Min                     -0.524198
evaluation_0/Returns Mean                  4833.73
evaluation_0/Returns Std                     26.6639
evaluation_0/Returns Max                   4869.83
evaluation_0/Returns Min                   4788.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4833.73
time/epoch (s)                                0
time/total (s)                            14602.9
Epoch                                       964
---------------------------------------  ----------------
2022-11-16 20:18:16.870379 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 965 finished
---------------------------------------  ----------------
epoch                                       965
total_step                               970000
replay_pool/size                         970000
trainer/alpha                                 0.0573414
trainer/alpha_loss                            0.810963
trainer/entropy                              -6.28368
trainer/qf_loss                              18.6791
trainer/policy_loss                        -355.896
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.256
trainer/entropy_penalty                      -0.360315
trainer/entropy_percentage                   -0.00101139
trainer/Q1Pred Mean                         355.673
trainer/Q1Pred Std                           60.1145
trainer/Q1Pred Max                          431.479
trainer/Q1Pred Min                           47.8031
trainer/Q2Pred Mean                         356.198
trainer/Q2Pred Std                           59.5433
trainer/Q2Pred Max                          430.575
trainer/Q2Pred Min                           37.9161
trainer/QTargetWithReg Mean                 355.35
trainer/QTargetWithReg Std                   59.8862
trainer/QTargetWithReg Max                  430.973
trainer/QTargetWithReg Min                   46.903
trainer/PolicyLossWithoutReg Mean           356.256
trainer/PolicyLossWithoutReg Std             59.5531
trainer/PolicyLossWithoutReg Max            430.446
trainer/PolicyLossWithoutReg Min             40.2555
exploration/num steps total              970000
exploration/num paths total                1774
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78255
exploration/Rewards Std                       1.08531
exploration/Rewards Max                       7.51488
exploration/Rewards Min                      -0.564483
exploration/Returns Mean                   4782.55
exploration/Returns Std                       0
exploration/Returns Max                    4782.55
exploration/Returns Min                    4782.55
exploration/Num Paths                         1
exploration/Average Returns                4782.55
evaluation_0/num steps total                  7.57211e+06
evaluation_0/num paths total              11222
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.52895
evaluation_0/Rewards Std                      1.28178
evaluation_0/Rewards Max                      7.59581
evaluation_0/Rewards Min                     -0.757152
evaluation_0/Returns Mean                  4528.95
evaluation_0/Returns Std                     78.1128
evaluation_0/Returns Max                   4647.52
evaluation_0/Returns Min                   4414.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4528.95
time/epoch (s)                                0
time/total (s)                            14613.7
Epoch                                       965
---------------------------------------  ----------------
2022-11-16 20:18:27.443178 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 966 finished
---------------------------------------  ----------------
epoch                                       966
total_step                               971000
replay_pool/size                         971000
trainer/alpha                                 0.057685
trainer/alpha_loss                            0.050593
trainer/entropy                              -6.01774
trainer/qf_loss                              28.6034
trainer/policy_loss                        -354.273
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.62
trainer/entropy_penalty                      -0.347133
trainer/entropy_percentage                   -0.000978887
trainer/Q1Pred Mean                         353.373
trainer/Q1Pred Std                           64.6666
trainer/Q1Pred Max                          424.144
trainer/Q1Pred Min                           13.9097
trainer/Q2Pred Mean                         353.591
trainer/Q2Pred Std                           65.0254
trainer/Q2Pred Max                          427.092
trainer/Q2Pred Min                            2.86536
trainer/QTargetWithReg Mean                 354.072
trainer/QTargetWithReg Std                   65.6605
trainer/QTargetWithReg Max                  426.464
trainer/QTargetWithReg Min                   12.0082
trainer/PolicyLossWithoutReg Mean           354.62
trainer/PolicyLossWithoutReg Std             64.3867
trainer/PolicyLossWithoutReg Max            425.331
trainer/PolicyLossWithoutReg Min              8.82543
exploration/num steps total              971000
exploration/num paths total                1775
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6131
exploration/Rewards Std                       1.14645
exploration/Rewards Max                       7.44829
exploration/Rewards Min                      -0.705522
exploration/Returns Mean                   4613.1
exploration/Returns Std                       0
exploration/Returns Max                    4613.1
exploration/Returns Min                    4613.1
exploration/Num Paths                         1
exploration/Average Returns                4613.1
evaluation_0/num steps total                  7.58011e+06
evaluation_0/num paths total              11230
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71436
evaluation_0/Rewards Std                      1.01758
evaluation_0/Rewards Max                      7.44328
evaluation_0/Rewards Min                     -0.817171
evaluation_0/Returns Mean                  4714.36
evaluation_0/Returns Std                     89.972
evaluation_0/Returns Max                   4869.97
evaluation_0/Returns Min                   4585.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4714.36
time/epoch (s)                                0
time/total (s)                            14624.3
Epoch                                       966
---------------------------------------  ----------------
2022-11-16 20:18:38.312420 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 967 finished
---------------------------------------  ----------------
epoch                                       967
total_step                               972000
replay_pool/size                         972000
trainer/alpha                                 0.0575473
trainer/alpha_loss                            0.676387
trainer/entropy                              -6.23689
trainer/qf_loss                              37.0625
trainer/policy_loss                        -350.474
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.833
trainer/entropy_penalty                      -0.358917
trainer/entropy_percentage                   -0.00102304
trainer/Q1Pred Mean                         350.076
trainer/Q1Pred Std                           62.0609
trainer/Q1Pred Max                          428.047
trainer/Q1Pred Min                           32.3286
trainer/Q2Pred Mean                         350.473
trainer/Q2Pred Std                           62.7152
trainer/Q2Pred Max                          430.088
trainer/Q2Pred Min                           19.8051
trainer/QTargetWithReg Mean                 350.858
trainer/QTargetWithReg Std                   62.2076
trainer/QTargetWithReg Max                  430.667
trainer/QTargetWithReg Min                   17.5399
trainer/PolicyLossWithoutReg Mean           350.833
trainer/PolicyLossWithoutReg Std             61.326
trainer/PolicyLossWithoutReg Max            427.419
trainer/PolicyLossWithoutReg Min             30.1203
exploration/num steps total              972000
exploration/num paths total                1776
exploration/path length this epoch Mean     804
exploration/path length this epoch Std        0
exploration/path length this epoch Max      804
exploration/path length this epoch Min      804
exploration/Rewards Mean                      4.45061
exploration/Rewards Std                       1.14073
exploration/Rewards Max                       7.3428
exploration/Rewards Min                      -0.911538
exploration/Returns Mean                   3578.29
exploration/Returns Std                       0
exploration/Returns Max                    3578.29
exploration/Returns Min                    3578.29
exploration/Num Paths                         1
exploration/Average Returns                3578.29
evaluation_0/num steps total                  7.58811e+06
evaluation_0/num paths total              11238
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67064
evaluation_0/Rewards Std                      1.0245
evaluation_0/Rewards Max                      7.42164
evaluation_0/Rewards Min                     -0.843219
evaluation_0/Returns Mean                  4670.64
evaluation_0/Returns Std                    142.953
evaluation_0/Returns Max                   4904.44
evaluation_0/Returns Min                   4510.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4670.64
time/epoch (s)                                0
time/total (s)                            14635.1
Epoch                                       967
---------------------------------------  ----------------
2022-11-16 20:18:50.122781 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 968 finished
---------------------------------------  ----------------
epoch                                       968
total_step                               973000
replay_pool/size                         973000
trainer/alpha                                 0.0570716
trainer/alpha_loss                            0.564989
trainer/entropy                              -6.1973
trainer/qf_loss                              23.1864
trainer/policy_loss                        -356.386
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.74
trainer/entropy_penalty                      -0.35369
trainer/entropy_percentage                   -0.000991449
trainer/Q1Pred Mean                         355.44
trainer/Q1Pred Std                           71.5586
trainer/Q1Pred Max                          430.242
trainer/Q1Pred Min                           25.6969
trainer/Q2Pred Mean                         355.685
trainer/Q2Pred Std                           71.6948
trainer/Q2Pred Max                          432.06
trainer/Q2Pred Min                           25.6853
trainer/QTargetWithReg Mean                 355.908
trainer/QTargetWithReg Std                   72.0439
trainer/QTargetWithReg Max                  431.018
trainer/QTargetWithReg Min                   20.2961
trainer/PolicyLossWithoutReg Mean           356.74
trainer/PolicyLossWithoutReg Std             71.4788
trainer/PolicyLossWithoutReg Max            431.881
trainer/PolicyLossWithoutReg Min             26.5975
exploration/num steps total              973000
exploration/num paths total                1777
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4931
exploration/Rewards Std                       1.00485
exploration/Rewards Max                       6.92463
exploration/Rewards Min                      -0.96783
exploration/Returns Mean                   4493.1
exploration/Returns Std                       0
exploration/Returns Max                    4493.1
exploration/Returns Min                    4493.1
exploration/Num Paths                         1
exploration/Average Returns                4493.1
evaluation_0/num steps total                  7.59558e+06
evaluation_0/num paths total              11246
evaluation_0/path length Mean               933.625
evaluation_0/path length Std                175.612
evaluation_0/path length Max               1000
evaluation_0/path length Min                469
evaluation_0/Rewards Mean                     4.91671
evaluation_0/Rewards Std                      1.04518
evaluation_0/Rewards Max                      7.84202
evaluation_0/Rewards Min                     -0.704748
evaluation_0/Returns Mean                  4590.37
evaluation_0/Returns Std                    949.56
evaluation_0/Returns Max                   5144.57
evaluation_0/Returns Min                   2095.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4590.37
time/epoch (s)                                0
time/total (s)                            14647
Epoch                                       968
---------------------------------------  ----------------
2022-11-16 20:19:00.822410 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 969 finished
---------------------------------------  ----------------
epoch                                       969
total_step                               974000
replay_pool/size                         974000
trainer/alpha                                 0.0589949
trainer/alpha_loss                           -0.0364386
trainer/entropy                              -5.98713
trainer/qf_loss                              19.3348
trainer/policy_loss                        -355.727
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.08
trainer/entropy_penalty                      -0.35321
trainer/entropy_percentage                   -0.000991939
trainer/Q1Pred Mean                         354.473
trainer/Q1Pred Std                           60.7433
trainer/Q1Pred Max                          424.286
trainer/Q1Pred Min                           27.3793
trainer/Q2Pred Mean                         354.716
trainer/Q2Pred Std                           61.1166
trainer/Q2Pred Max                          427.68
trainer/Q2Pred Min                           25.5793
trainer/QTargetWithReg Mean                 355.268
trainer/QTargetWithReg Std                   61.3028
trainer/QTargetWithReg Max                  426.024
trainer/QTargetWithReg Min                   21.8412
trainer/PolicyLossWithoutReg Mean           356.08
trainer/PolicyLossWithoutReg Std             58.864
trainer/PolicyLossWithoutReg Max            426.457
trainer/PolicyLossWithoutReg Min             26.5332
exploration/num steps total              974000
exploration/num paths total                1778
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69236
exploration/Rewards Std                       0.996236
exploration/Rewards Max                       7.12939
exploration/Rewards Min                      -0.605026
exploration/Returns Mean                   4692.36
exploration/Returns Std                       0
exploration/Returns Max                    4692.36
exploration/Returns Min                    4692.36
exploration/Num Paths                         1
exploration/Average Returns                4692.36
evaluation_0/num steps total                  7.60358e+06
evaluation_0/num paths total              11254
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81284
evaluation_0/Rewards Std                      1.02296
evaluation_0/Rewards Max                      7.63723
evaluation_0/Rewards Min                     -0.692924
evaluation_0/Returns Mean                  4812.84
evaluation_0/Returns Std                     61.997
evaluation_0/Returns Max                   4896.75
evaluation_0/Returns Min                   4708.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4812.84
time/epoch (s)                                0
time/total (s)                            14657.7
Epoch                                       969
---------------------------------------  ----------------
2022-11-16 20:19:12.835036 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 970 finished
---------------------------------------  ----------------
epoch                                       970
total_step                               975000
replay_pool/size                         975000
trainer/alpha                                 0.0569949
trainer/alpha_loss                           -0.468455
trainer/entropy                              -5.83648
trainer/qf_loss                              18.2296
trainer/policy_loss                        -359.529
trainer/adversary_policy_loss                17.087
trainer/policy_loss_without_entropy         359.861
trainer/entropy_penalty                      -0.332649
trainer/entropy_percentage                   -0.000924382
trainer/Q1Pred Mean                         358.629
trainer/Q1Pred Std                           53.7091
trainer/Q1Pred Max                          440.47
trainer/Q1Pred Min                           12.2803
trainer/Q2Pred Mean                         358.554
trainer/Q2Pred Std                           54.0628
trainer/Q2Pred Max                          437.785
trainer/Q2Pred Min                           19.3666
trainer/QTargetWithReg Mean                 358.618
trainer/QTargetWithReg Std                   54.0979
trainer/QTargetWithReg Max                  437.057
trainer/QTargetWithReg Min                   13.4383
trainer/PolicyLossWithoutReg Mean           359.861
trainer/PolicyLossWithoutReg Std             53.7315
trainer/PolicyLossWithoutReg Max            438.151
trainer/PolicyLossWithoutReg Min             13.2966
exploration/num steps total              975000
exploration/num paths total                1779
exploration/path length this epoch Mean     453
exploration/path length this epoch Std        0
exploration/path length this epoch Max      453
exploration/path length this epoch Min      453
exploration/Rewards Mean                      4.28464
exploration/Rewards Std                       1.41392
exploration/Rewards Max                       6.96513
exploration/Rewards Min                      -0.603307
exploration/Returns Mean                   1940.94
exploration/Returns Std                       0
exploration/Returns Max                    1940.94
exploration/Returns Min                    1940.94
exploration/Num Paths                         1
exploration/Average Returns                1940.94
evaluation_0/num steps total                  7.61062e+06
evaluation_0/num paths total              11262
evaluation_0/path length Mean               880.25
evaluation_0/path length Std                209.431
evaluation_0/path length Max               1000
evaluation_0/path length Min                463
evaluation_0/Rewards Mean                     4.71278
evaluation_0/Rewards Std                      1.08688
evaluation_0/Rewards Max                      7.9073
evaluation_0/Rewards Min                     -0.798514
evaluation_0/Returns Mean                  4148.43
evaluation_0/Returns Std                   1085.01
evaluation_0/Returns Max                   4833.64
evaluation_0/Returns Min                   2032.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4148.43
time/epoch (s)                                0
time/total (s)                            14669.7
Epoch                                       970
---------------------------------------  ----------------
2022-11-16 20:19:24.614216 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 971 finished
---------------------------------------  ----------------
epoch                                       971
total_step                               976000
replay_pool/size                         976000
trainer/alpha                                 0.0583163
trainer/alpha_loss                            0.160886
trainer/entropy                              -6.05661
trainer/qf_loss                              24.0959
trainer/policy_loss                        -360.821
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         361.174
trainer/entropy_penalty                      -0.353199
trainer/entropy_percentage                   -0.000977919
trainer/Q1Pred Mean                         360.118
trainer/Q1Pred Std                           56.3602
trainer/Q1Pred Max                          427.031
trainer/Q1Pred Min                           -5.9934
trainer/Q2Pred Mean                         359.598
trainer/Q2Pred Std                           56.3569
trainer/Q2Pred Max                          427.944
trainer/Q2Pred Min                            1.06045
trainer/QTargetWithReg Mean                 360.309
trainer/QTargetWithReg Std                   56.3775
trainer/QTargetWithReg Max                  427.671
trainer/QTargetWithReg Min                    0.455217
trainer/PolicyLossWithoutReg Mean           361.174
trainer/PolicyLossWithoutReg Std             55.2014
trainer/PolicyLossWithoutReg Max            427.634
trainer/PolicyLossWithoutReg Min             -6.50327
exploration/num steps total              976000
exploration/num paths total                1780
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47849
exploration/Rewards Std                       1.01448
exploration/Rewards Max                       7.18271
exploration/Rewards Min                      -0.76388
exploration/Returns Mean                   4478.49
exploration/Returns Std                       0
exploration/Returns Max                    4478.49
exploration/Returns Min                    4478.49
exploration/Num Paths                         1
exploration/Average Returns                4478.49
evaluation_0/num steps total                  7.61832e+06
evaluation_0/num paths total              11271
evaluation_0/path length Mean               855.111
evaluation_0/path length Std                220.28
evaluation_0/path length Max               1000
evaluation_0/path length Min                411
evaluation_0/Rewards Mean                     4.54343
evaluation_0/Rewards Std                      1.0472
evaluation_0/Rewards Max                      8.05872
evaluation_0/Rewards Min                     -0.890864
evaluation_0/Returns Mean                  3885.13
evaluation_0/Returns Std                   1076.18
evaluation_0/Returns Max                   4673.51
evaluation_0/Returns Min                   1661.85
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3885.13
time/epoch (s)                                0
time/total (s)                            14681.4
Epoch                                       971
---------------------------------------  ----------------
2022-11-16 20:19:36.284191 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 972 finished
---------------------------------------  ----------------
epoch                                       972
total_step                               977000
replay_pool/size                         977000
trainer/alpha                                 0.0588181
trainer/alpha_loss                           -0.837185
trainer/entropy                              -5.70451
trainer/qf_loss                              34.9328
trainer/policy_loss                        -357.319
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         357.655
trainer/entropy_penalty                      -0.335528
trainer/entropy_percentage                   -0.000938135
trainer/Q1Pred Mean                         356.86
trainer/Q1Pred Std                           60.6569
trainer/Q1Pred Max                          437.958
trainer/Q1Pred Min                           44.1229
trainer/Q2Pred Mean                         356.855
trainer/Q2Pred Std                           61.4249
trainer/Q2Pred Max                          437.958
trainer/Q2Pred Min                           36.7622
trainer/QTargetWithReg Mean                 354.475
trainer/QTargetWithReg Std                   61.8901
trainer/QTargetWithReg Max                  436.974
trainer/QTargetWithReg Min                   30.6796
trainer/PolicyLossWithoutReg Mean           357.655
trainer/PolicyLossWithoutReg Std             59.1035
trainer/PolicyLossWithoutReg Max            436.89
trainer/PolicyLossWithoutReg Min             44.439
exploration/num steps total              977000
exploration/num paths total                1783
exploration/path length this epoch Mean     323.667
exploration/path length this epoch Std      240.63
exploration/path length this epoch Max      646
exploration/path length this epoch Min       68
exploration/Rewards Mean                      3.93957
exploration/Rewards Std                       1.46691
exploration/Rewards Max                       7.00561
exploration/Rewards Min                      -0.752948
exploration/Returns Mean                   1275.11
exploration/Returns Std                    1063.66
exploration/Returns Max                    2713.05
exploration/Returns Min                     173.661
exploration/Num Paths                         3
exploration/Average Returns                1275.11
evaluation_0/num steps total                  7.62546e+06
evaluation_0/num paths total              11279
evaluation_0/path length Mean               892.5
evaluation_0/path length Std                284.418
evaluation_0/path length Max               1000
evaluation_0/path length Min                140
evaluation_0/Rewards Mean                     4.57068
evaluation_0/Rewards Std                      1.21396
evaluation_0/Rewards Max                      7.42664
evaluation_0/Rewards Min                     -0.603308
evaluation_0/Returns Mean                  4079.33
evaluation_0/Returns Std                   1422.03
evaluation_0/Returns Max                   4687.2
evaluation_0/Returns Min                    320.054
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4079.33
time/epoch (s)                                0
time/total (s)                            14693.1
Epoch                                       972
---------------------------------------  ----------------
2022-11-16 20:19:47.127417 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 973 finished
---------------------------------------  ----------------
epoch                                       973
total_step                               978000
replay_pool/size                         978000
trainer/alpha                                 0.0602348
trainer/alpha_loss                           -1.49487
trainer/entropy                              -5.46791
trainer/qf_loss                              14.3364
trainer/policy_loss                        -355.15
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.479
trainer/entropy_penalty                      -0.329358
trainer/entropy_percentage                   -0.000926519
trainer/Q1Pred Mean                         354.041
trainer/Q1Pred Std                           69.5967
trainer/Q1Pred Max                          433.005
trainer/Q1Pred Min                           -2.27485
trainer/Q2Pred Mean                         355.215
trainer/Q2Pred Std                           69.7736
trainer/Q2Pred Max                          434.152
trainer/Q2Pred Min                          -16.7457
trainer/QTargetWithReg Mean                 354.725
trainer/QTargetWithReg Std                   69.6973
trainer/QTargetWithReg Max                  433.573
trainer/QTargetWithReg Min                   -0.0262218
trainer/PolicyLossWithoutReg Mean           355.479
trainer/PolicyLossWithoutReg Std             68.2718
trainer/PolicyLossWithoutReg Max            433.848
trainer/PolicyLossWithoutReg Min            -13.371
exploration/num steps total              978000
exploration/num paths total                1785
exploration/path length this epoch Mean     431.5
exploration/path length this epoch Std       43.5
exploration/path length this epoch Max      475
exploration/path length this epoch Min      388
exploration/Rewards Mean                      4.1443
exploration/Rewards Std                       1.20239
exploration/Rewards Max                       7.22142
exploration/Rewards Min                      -1.44457
exploration/Returns Mean                   1788.26
exploration/Returns Std                     260.611
exploration/Returns Max                    2048.88
exploration/Returns Min                    1527.65
exploration/Num Paths                         2
exploration/Average Returns                1788.26
evaluation_0/num steps total                  7.63346e+06
evaluation_0/num paths total              11287
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68867
evaluation_0/Rewards Std                      1.11629
evaluation_0/Rewards Max                      7.42549
evaluation_0/Rewards Min                     -0.847344
evaluation_0/Returns Mean                  4688.67
evaluation_0/Returns Std                    124.247
evaluation_0/Returns Max                   4843.9
evaluation_0/Returns Min                   4422.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4688.67
time/epoch (s)                                0
time/total (s)                            14704
Epoch                                       973
---------------------------------------  ----------------
2022-11-16 20:19:57.754931 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 974 finished
---------------------------------------  ----------------
epoch                                       974
total_step                               979000
replay_pool/size                         979000
trainer/alpha                                 0.0573246
trainer/alpha_loss                            1.17674
trainer/entropy                              -6.41159
trainer/qf_loss                              42.4458
trainer/policy_loss                        -350.633
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.001
trainer/entropy_penalty                      -0.367542
trainer/entropy_percentage                   -0.00104712
trainer/Q1Pred Mean                         349.785
trainer/Q1Pred Std                           65.921
trainer/Q1Pred Max                          429.021
trainer/Q1Pred Min                           18.6849
trainer/Q2Pred Mean                         350.173
trainer/Q2Pred Std                           65.7834
trainer/Q2Pred Max                          430.165
trainer/Q2Pred Min                           26.0149
trainer/QTargetWithReg Mean                 350.388
trainer/QTargetWithReg Std                   66.5134
trainer/QTargetWithReg Max                  430.256
trainer/QTargetWithReg Min                   27.8704
trainer/PolicyLossWithoutReg Mean           351.001
trainer/PolicyLossWithoutReg Std             64.994
trainer/PolicyLossWithoutReg Max            429.23
trainer/PolicyLossWithoutReg Min             20.6964
exploration/num steps total              979000
exploration/num paths total                1786
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70434
exploration/Rewards Std                       1.09564
exploration/Rewards Max                       6.80363
exploration/Rewards Min                      -0.951128
exploration/Returns Mean                   4704.34
exploration/Returns Std                       0
exploration/Returns Max                    4704.34
exploration/Returns Min                    4704.34
exploration/Num Paths                         1
exploration/Average Returns                4704.34
evaluation_0/num steps total                  7.64146e+06
evaluation_0/num paths total              11295
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72344
evaluation_0/Rewards Std                      1.05
evaluation_0/Rewards Max                      7.21337
evaluation_0/Rewards Min                     -0.764643
evaluation_0/Returns Mean                  4723.44
evaluation_0/Returns Std                    104.821
evaluation_0/Returns Max                   4945.15
evaluation_0/Returns Min                   4614.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4723.44
time/epoch (s)                                0
time/total (s)                            14714.6
Epoch                                       974
---------------------------------------  ----------------
2022-11-16 20:20:08.435429 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 975 finished
---------------------------------------  ----------------
epoch                                       975
total_step                               980000
replay_pool/size                         980000
trainer/alpha                                 0.0576769
trainer/alpha_loss                           -1.95483
trainer/entropy                              -5.31473
trainer/qf_loss                              24.1039
trainer/policy_loss                        -353.24
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         353.546
trainer/entropy_penalty                      -0.306537
trainer/entropy_percentage                   -0.000867036
trainer/Q1Pred Mean                         353.046
trainer/Q1Pred Std                           62.4232
trainer/Q1Pred Max                          430.75
trainer/Q1Pred Min                          -39.5226
trainer/Q2Pred Mean                         352.899
trainer/Q2Pred Std                           62.0544
trainer/Q2Pred Max                          429.731
trainer/Q2Pred Min                          -18.7427
trainer/QTargetWithReg Mean                 352.845
trainer/QTargetWithReg Std                   63.6704
trainer/QTargetWithReg Max                  430.837
trainer/QTargetWithReg Min                  -38.2381
trainer/PolicyLossWithoutReg Mean           353.546
trainer/PolicyLossWithoutReg Std             57.5698
trainer/PolicyLossWithoutReg Max            429.227
trainer/PolicyLossWithoutReg Min             73.4728
exploration/num steps total              980000
exploration/num paths total                1787
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.46843
exploration/Rewards Std                       0.976418
exploration/Rewards Max                       7.19367
exploration/Rewards Min                      -0.775308
exploration/Returns Mean                   4468.43
exploration/Returns Std                       0
exploration/Returns Max                    4468.43
exploration/Returns Min                    4468.43
exploration/Num Paths                         1
exploration/Average Returns                4468.43
evaluation_0/num steps total                  7.64946e+06
evaluation_0/num paths total              11303
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72591
evaluation_0/Rewards Std                      1.05059
evaluation_0/Rewards Max                      7.29506
evaluation_0/Rewards Min                     -0.898241
evaluation_0/Returns Mean                  4725.91
evaluation_0/Returns Std                    127.861
evaluation_0/Returns Max                   4959.81
evaluation_0/Returns Min                   4555.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4725.91
time/epoch (s)                                0
time/total (s)                            14725.3
Epoch                                       975
---------------------------------------  ----------------
2022-11-16 20:20:18.952029 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 976 finished
---------------------------------------  ----------------
epoch                                       976
total_step                               981000
replay_pool/size                         981000
trainer/alpha                                 0.0560676
trainer/alpha_loss                           -0.227989
trainer/entropy                              -5.92087
trainer/qf_loss                              18.7008
trainer/policy_loss                        -360.473
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         360.805
trainer/entropy_penalty                      -0.331969
trainer/entropy_percentage                   -0.000920079
trainer/Q1Pred Mean                         360.863
trainer/Q1Pred Std                           62.9961
trainer/Q1Pred Max                          442.898
trainer/Q1Pred Min                          -18.1128
trainer/Q2Pred Mean                         360.593
trainer/Q2Pred Std                           62.7175
trainer/Q2Pred Max                          444.244
trainer/Q2Pred Min                           -9.48327
trainer/QTargetWithReg Mean                 359.562
trainer/QTargetWithReg Std                   62.8474
trainer/QTargetWithReg Max                  443.589
trainer/QTargetWithReg Min                  -14.25
trainer/PolicyLossWithoutReg Mean           360.805
trainer/PolicyLossWithoutReg Std             62.5064
trainer/PolicyLossWithoutReg Max            442.561
trainer/PolicyLossWithoutReg Min            -16.732
exploration/num steps total              981000
exploration/num paths total                1788
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62568
exploration/Rewards Std                       0.956835
exploration/Rewards Max                       6.86642
exploration/Rewards Min                      -0.851491
exploration/Returns Mean                   4625.68
exploration/Returns Std                       0
exploration/Returns Max                    4625.68
exploration/Returns Min                    4625.68
exploration/Num Paths                         1
exploration/Average Returns                4625.68
evaluation_0/num steps total                  7.65746e+06
evaluation_0/num paths total              11311
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69804
evaluation_0/Rewards Std                      0.969828
evaluation_0/Rewards Max                      7.31694
evaluation_0/Rewards Min                     -0.623265
evaluation_0/Returns Mean                  4698.04
evaluation_0/Returns Std                     73.0911
evaluation_0/Returns Max                   4840.05
evaluation_0/Returns Min                   4580.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4698.04
time/epoch (s)                                0
time/total (s)                            14735.8
Epoch                                       976
---------------------------------------  ----------------
2022-11-16 20:20:29.569381 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 977 finished
---------------------------------------  ----------------
epoch                                       977
total_step                               982000
replay_pool/size                         982000
trainer/alpha                                 0.0596682
trainer/alpha_loss                           -1.25464
trainer/entropy                              -5.5549
trainer/qf_loss                              45.4123
trainer/policy_loss                        -348.477
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         348.809
trainer/entropy_penalty                      -0.331451
trainer/entropy_percentage                   -0.000950237
trainer/Q1Pred Mean                         347.23
trainer/Q1Pred Std                           64.1201
trainer/Q1Pred Max                          425.03
trainer/Q1Pred Min                           21.1071
trainer/Q2Pred Mean                         347.551
trainer/Q2Pred Std                           63.3628
trainer/Q2Pred Max                          424.402
trainer/Q2Pred Min                           25.7475
trainer/QTargetWithReg Mean                 348.614
trainer/QTargetWithReg Std                   63.0304
trainer/QTargetWithReg Max                  425.515
trainer/QTargetWithReg Min                   22.0899
trainer/PolicyLossWithoutReg Mean           348.809
trainer/PolicyLossWithoutReg Std             62.592
trainer/PolicyLossWithoutReg Max            426.032
trainer/PolicyLossWithoutReg Min             19.2654
exploration/num steps total              982000
exploration/num paths total                1789
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67984
exploration/Rewards Std                       1.02975
exploration/Rewards Max                       7.05779
exploration/Rewards Min                      -0.669824
exploration/Returns Mean                   4679.84
exploration/Returns Std                       0
exploration/Returns Max                    4679.84
exploration/Returns Min                    4679.84
exploration/Num Paths                         1
exploration/Average Returns                4679.84
evaluation_0/num steps total                  7.66546e+06
evaluation_0/num paths total              11319
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76314
evaluation_0/Rewards Std                      0.999184
evaluation_0/Rewards Max                      7.62019
evaluation_0/Rewards Min                     -0.744358
evaluation_0/Returns Mean                  4763.14
evaluation_0/Returns Std                     95.1797
evaluation_0/Returns Max                   4926.7
evaluation_0/Returns Min                   4617.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4763.14
time/epoch (s)                                0
time/total (s)                            14746.4
Epoch                                       977
---------------------------------------  ----------------
2022-11-16 20:20:40.279096 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 978 finished
---------------------------------------  ----------------
epoch                                       978
total_step                               983000
replay_pool/size                         983000
trainer/alpha                                 0.0574859
trainer/alpha_loss                            0.810955
trainer/entropy                              -6.28392
trainer/qf_loss                              22.901
trainer/policy_loss                        -354.592
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.954
trainer/entropy_penalty                      -0.361237
trainer/entropy_percentage                   -0.0010177
trainer/Q1Pred Mean                         353.605
trainer/Q1Pred Std                           63.0522
trainer/Q1Pred Max                          433.967
trainer/Q1Pred Min                           43.3611
trainer/Q2Pred Mean                         353.517
trainer/Q2Pred Std                           63.238
trainer/Q2Pred Max                          434.459
trainer/Q2Pred Min                           47.3027
trainer/QTargetWithReg Mean                 353.354
trainer/QTargetWithReg Std                   63.797
trainer/QTargetWithReg Max                  434.954
trainer/QTargetWithReg Min                   44.3553
trainer/PolicyLossWithoutReg Mean           354.954
trainer/PolicyLossWithoutReg Std             61.6704
trainer/PolicyLossWithoutReg Max            433.902
trainer/PolicyLossWithoutReg Min             66.6345
exploration/num steps total              983000
exploration/num paths total                1790
exploration/path length this epoch Mean     459
exploration/path length this epoch Std        0
exploration/path length this epoch Max      459
exploration/path length this epoch Min      459
exploration/Rewards Mean                      4.16177
exploration/Rewards Std                       1.21944
exploration/Rewards Max                       7.13325
exploration/Rewards Min                      -0.768586
exploration/Returns Mean                   1910.25
exploration/Returns Std                       0
exploration/Returns Max                    1910.25
exploration/Returns Min                    1910.25
exploration/Num Paths                         1
exploration/Average Returns                1910.25
evaluation_0/num steps total                  7.67346e+06
evaluation_0/num paths total              11327
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75513
evaluation_0/Rewards Std                      1.01295
evaluation_0/Rewards Max                      7.41664
evaluation_0/Rewards Min                     -0.78161
evaluation_0/Returns Mean                  4755.13
evaluation_0/Returns Std                     55.4376
evaluation_0/Returns Max                   4854.06
evaluation_0/Returns Min                   4687.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4755.13
time/epoch (s)                                0
time/total (s)                            14757.1
Epoch                                       978
---------------------------------------  ----------------
2022-11-16 20:20:50.941907 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 979 finished
---------------------------------------  ----------------
epoch                                       979
total_step                               984000
replay_pool/size                         984000
trainer/alpha                                 0.0566362
trainer/alpha_loss                            0.996446
trainer/entropy                              -6.34707
trainer/qf_loss                              21.4049
trainer/policy_loss                        -347.549
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.909
trainer/entropy_penalty                      -0.359474
trainer/entropy_percentage                   -0.00103324
trainer/Q1Pred Mean                         346.85
trainer/Q1Pred Std                           81.3382
trainer/Q1Pred Max                          431.611
trainer/Q1Pred Min                          -24.7397
trainer/Q2Pred Mean                         347.244
trainer/Q2Pred Std                           81.1613
trainer/Q2Pred Max                          433.071
trainer/Q2Pred Min                          -40.2108
trainer/QTargetWithReg Mean                 346.999
trainer/QTargetWithReg Std                   81.3277
trainer/QTargetWithReg Max                  433.83
trainer/QTargetWithReg Min                  -33.2323
trainer/PolicyLossWithoutReg Mean           347.909
trainer/PolicyLossWithoutReg Std             79.4314
trainer/PolicyLossWithoutReg Max            433.642
trainer/PolicyLossWithoutReg Min            -20.6687
exploration/num steps total              984000
exploration/num paths total                1791
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81221
exploration/Rewards Std                       1.0195
exploration/Rewards Max                       7.22596
exploration/Rewards Min                      -0.876343
exploration/Returns Mean                   4812.21
exploration/Returns Std                       0
exploration/Returns Max                    4812.21
exploration/Returns Min                    4812.21
exploration/Num Paths                         1
exploration/Average Returns                4812.21
evaluation_0/num steps total                  7.68146e+06
evaluation_0/num paths total              11335
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6705
evaluation_0/Rewards Std                      1.02893
evaluation_0/Rewards Max                      7.51829
evaluation_0/Rewards Min                     -0.722022
evaluation_0/Returns Mean                  4670.5
evaluation_0/Returns Std                     55.4762
evaluation_0/Returns Max                   4760.16
evaluation_0/Returns Min                   4599.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4670.5
time/epoch (s)                                0
time/total (s)                            14767.8
Epoch                                       979
---------------------------------------  ----------------
2022-11-16 20:21:01.421789 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 980 finished
---------------------------------------  ----------------
epoch                                       980
total_step                               985000
replay_pool/size                         985000
trainer/alpha                                 0.0560098
trainer/alpha_loss                            0.611687
trainer/entropy                              -6.21222
trainer/qf_loss                              39.0736
trainer/policy_loss                        -347.03
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         347.378
trainer/entropy_penalty                      -0.347945
trainer/entropy_percentage                   -0.00100163
trainer/Q1Pred Mean                         345.958
trainer/Q1Pred Std                           72.5572
trainer/Q1Pred Max                          434.174
trainer/Q1Pred Min                           43.5685
trainer/Q2Pred Mean                         345.587
trainer/Q2Pred Std                           72.979
trainer/Q2Pred Max                          436.06
trainer/Q2Pred Min                           36.3371
trainer/QTargetWithReg Mean                 346.146
trainer/QTargetWithReg Std                   72.4321
trainer/QTargetWithReg Max                  436.879
trainer/QTargetWithReg Min                   44.3645
trainer/PolicyLossWithoutReg Mean           347.378
trainer/PolicyLossWithoutReg Std             70.4911
trainer/PolicyLossWithoutReg Max            435.004
trainer/PolicyLossWithoutReg Min             40.6513
exploration/num steps total              985000
exploration/num paths total                1792
exploration/path length this epoch Mean     804
exploration/path length this epoch Std        0
exploration/path length this epoch Max      804
exploration/path length this epoch Min      804
exploration/Rewards Mean                      4.60268
exploration/Rewards Std                       1.09691
exploration/Rewards Max                       6.9713
exploration/Rewards Min                      -0.66383
exploration/Returns Mean                   3700.55
exploration/Returns Std                       0
exploration/Returns Max                    3700.55
exploration/Returns Min                    3700.55
exploration/Num Paths                         1
exploration/Average Returns                3700.55
evaluation_0/num steps total                  7.68946e+06
evaluation_0/num paths total              11343
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78855
evaluation_0/Rewards Std                      0.973325
evaluation_0/Rewards Max                      7.43006
evaluation_0/Rewards Min                     -0.794845
evaluation_0/Returns Mean                  4788.55
evaluation_0/Returns Std                     82.6983
evaluation_0/Returns Max                   4877.27
evaluation_0/Returns Min                   4611.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4788.55
time/epoch (s)                                0
time/total (s)                            14778.3
Epoch                                       980
---------------------------------------  ----------------
2022-11-16 20:21:14.082959 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 981 finished
---------------------------------------  ----------------
epoch                                       981
total_step                               986000
replay_pool/size                         986000
trainer/alpha                                 0.058008
trainer/alpha_loss                            1.37378
trainer/entropy                              -6.48251
trainer/qf_loss                              29.5088
trainer/policy_loss                        -347.795
trainer/adversary_policy_loss                16.5654
trainer/policy_loss_without_entropy         348.171
trainer/entropy_penalty                      -0.376037
trainer/entropy_percentage                   -0.00108004
trainer/Q1Pred Mean                         347.567
trainer/Q1Pred Std                           76.6422
trainer/Q1Pred Max                          427.746
trainer/Q1Pred Min                           22.704
trainer/Q2Pred Mean                         347.108
trainer/Q2Pred Std                           76.561
trainer/Q2Pred Max                          428.412
trainer/Q2Pred Min                           20.9614
trainer/QTargetWithReg Mean                 346.676
trainer/QTargetWithReg Std                   76.3492
trainer/QTargetWithReg Max                  428.317
trainer/QTargetWithReg Min                   20.8366
trainer/PolicyLossWithoutReg Mean           348.171
trainer/PolicyLossWithoutReg Std             75.9748
trainer/PolicyLossWithoutReg Max            429.106
trainer/PolicyLossWithoutReg Min             22.3508
exploration/num steps total              986000
exploration/num paths total                1793
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4982
exploration/Rewards Std                       1.11085
exploration/Rewards Max                       7.41619
exploration/Rewards Min                      -0.762461
exploration/Returns Mean                   4498.2
exploration/Returns Std                       0
exploration/Returns Max                    4498.2
exploration/Returns Min                    4498.2
exploration/Num Paths                         1
exploration/Average Returns                4498.2
evaluation_0/num steps total                  7.69746e+06
evaluation_0/num paths total              11351
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8144
evaluation_0/Rewards Std                      0.98495
evaluation_0/Rewards Max                      7.50349
evaluation_0/Rewards Min                     -0.697095
evaluation_0/Returns Mean                  4814.4
evaluation_0/Returns Std                     53.9851
evaluation_0/Returns Max                   4899.25
evaluation_0/Returns Min                   4727.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4814.4
time/epoch (s)                                0
time/total (s)                            14790.9
Epoch                                       981
---------------------------------------  ----------------
2022-11-16 20:21:30.580242 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 982 finished
---------------------------------------  ----------------
epoch                                       982
total_step                               987000
replay_pool/size                         987000
trainer/alpha                                 0.0575189
trainer/alpha_loss                           -1.47215
trainer/entropy                              -5.48444
trainer/qf_loss                              21.8365
trainer/policy_loss                        -354.865
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.18
trainer/entropy_penalty                      -0.315459
trainer/entropy_percentage                   -0.000888165
trainer/Q1Pred Mean                         354.623
trainer/Q1Pred Std                           61.8571
trainer/Q1Pred Max                          428.795
trainer/Q1Pred Min                           29.8951
trainer/Q2Pred Mean                         354.664
trainer/Q2Pred Std                           62.7307
trainer/Q2Pred Max                          426.2
trainer/Q2Pred Min                           37.4026
trainer/QTargetWithReg Mean                 354.797
trainer/QTargetWithReg Std                   62.2598
trainer/QTargetWithReg Max                  425.417
trainer/QTargetWithReg Min                   35.2325
trainer/PolicyLossWithoutReg Mean           355.18
trainer/PolicyLossWithoutReg Std             61.5389
trainer/PolicyLossWithoutReg Max            426.143
trainer/PolicyLossWithoutReg Min             28.1826
exploration/num steps total              987000
exploration/num paths total                1794
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56251
exploration/Rewards Std                       1.05974
exploration/Rewards Max                       7.1284
exploration/Rewards Min                      -1.04979
exploration/Returns Mean                   4562.51
exploration/Returns Std                       0
exploration/Returns Max                    4562.51
exploration/Returns Min                    4562.51
exploration/Num Paths                         1
exploration/Average Returns                4562.51
evaluation_0/num steps total                  7.7051e+06
evaluation_0/num paths total              11359
evaluation_0/path length Mean               955.75
evaluation_0/path length Std                117.074
evaluation_0/path length Max               1000
evaluation_0/path length Min                646
evaluation_0/Rewards Mean                     4.94515
evaluation_0/Rewards Std                      1.06212
evaluation_0/Rewards Max                      7.80018
evaluation_0/Rewards Min                     -0.795778
evaluation_0/Returns Mean                  4726.32
evaluation_0/Returns Std                    625.655
evaluation_0/Returns Max                   5028.08
evaluation_0/Returns Min                   3078.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4726.32
time/epoch (s)                                0
time/total (s)                            14807.4
Epoch                                       982
---------------------------------------  ----------------
2022-11-16 20:21:47.310652 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 983 finished
---------------------------------------  ----------------
epoch                                       983
total_step                               988000
replay_pool/size                         988000
trainer/alpha                                 0.0582153
trainer/alpha_loss                           -0.818484
trainer/entropy                              -5.71216
trainer/qf_loss                              18.0747
trainer/policy_loss                        -356.346
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.679
trainer/entropy_penalty                      -0.332535
trainer/entropy_percentage                   -0.00093231
trainer/Q1Pred Mean                         355.427
trainer/Q1Pred Std                           57.5257
trainer/Q1Pred Max                          431.334
trainer/Q1Pred Min                           19.6935
trainer/Q2Pred Mean                         355.346
trainer/Q2Pred Std                           57.2808
trainer/Q2Pred Max                          428.523
trainer/Q2Pred Min                           21.9376
trainer/QTargetWithReg Mean                 356.297
trainer/QTargetWithReg Std                   57.565
trainer/QTargetWithReg Max                  429.768
trainer/QTargetWithReg Min                   22.0502
trainer/PolicyLossWithoutReg Mean           356.679
trainer/PolicyLossWithoutReg Std             57.0438
trainer/PolicyLossWithoutReg Max            430.8
trainer/PolicyLossWithoutReg Min             21.6299
exploration/num steps total              988000
exploration/num paths total                1795
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67525
exploration/Rewards Std                       0.948144
exploration/Rewards Max                       7.02491
exploration/Rewards Min                      -0.898867
exploration/Returns Mean                   4675.25
exploration/Returns Std                       0
exploration/Returns Max                    4675.25
exploration/Returns Min                    4675.25
exploration/Num Paths                         1
exploration/Average Returns                4675.25
evaluation_0/num steps total                  7.71275e+06
evaluation_0/num paths total              11367
evaluation_0/path length Mean               956.125
evaluation_0/path length Std                116.082
evaluation_0/path length Max               1000
evaluation_0/path length Min                649
evaluation_0/Rewards Mean                     4.89889
evaluation_0/Rewards Std                      1.05622
evaluation_0/Rewards Max                      8.10049
evaluation_0/Rewards Min                     -0.692048
evaluation_0/Returns Mean                  4683.95
evaluation_0/Returns Std                    569.056
evaluation_0/Returns Max                   4982.35
evaluation_0/Returns Min                   3186.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4683.95
time/epoch (s)                                0
time/total (s)                            14824.1
Epoch                                       983
---------------------------------------  ----------------
2022-11-16 20:22:02.115993 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 984 finished
---------------------------------------  ----------------
epoch                                       984
total_step                               989000
replay_pool/size                         989000
trainer/alpha                                 0.0575114
trainer/alpha_loss                           -0.223996
trainer/entropy                              -5.92156
trainer/qf_loss                              21.2284
trainer/policy_loss                        -346.633
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         346.974
trainer/entropy_penalty                      -0.340558
trainer/entropy_percentage                   -0.000981508
trainer/Q1Pred Mean                         345.727
trainer/Q1Pred Std                           70.3167
trainer/Q1Pred Max                          428.546
trainer/Q1Pred Min                           20.5242
trainer/Q2Pred Mean                         346.39
trainer/Q2Pred Std                           70.3894
trainer/Q2Pred Max                          428.303
trainer/Q2Pred Min                           19.811
trainer/QTargetWithReg Mean                 346.368
trainer/QTargetWithReg Std                   70.7597
trainer/QTargetWithReg Max                  427.448
trainer/QTargetWithReg Min                   26.1921
trainer/PolicyLossWithoutReg Mean           346.974
trainer/PolicyLossWithoutReg Std             68.9347
trainer/PolicyLossWithoutReg Max            428.107
trainer/PolicyLossWithoutReg Min             23.6232
exploration/num steps total              989000
exploration/num paths total                1796
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71945
exploration/Rewards Std                       1.08927
exploration/Rewards Max                       7.4507
exploration/Rewards Min                      -0.66836
exploration/Returns Mean                   4719.45
exploration/Returns Std                       0
exploration/Returns Max                    4719.45
exploration/Returns Min                    4719.45
exploration/Num Paths                         1
exploration/Average Returns                4719.45
evaluation_0/num steps total                  7.72075e+06
evaluation_0/num paths total              11375
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7878
evaluation_0/Rewards Std                      0.98854
evaluation_0/Rewards Max                      7.36661
evaluation_0/Rewards Min                     -0.877231
evaluation_0/Returns Mean                  4787.8
evaluation_0/Returns Std                     95.4861
evaluation_0/Returns Max                   4989.56
evaluation_0/Returns Min                   4692.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4787.8
time/epoch (s)                                0
time/total (s)                            14838.9
Epoch                                       984
---------------------------------------  ----------------
2022-11-16 20:22:18.673602 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 985 finished
---------------------------------------  ----------------
epoch                                       985
total_step                               990000
replay_pool/size                         990000
trainer/alpha                                 0.0578215
trainer/alpha_loss                           -0.587795
trainer/entropy                              -5.79377
trainer/qf_loss                              35.4055
trainer/policy_loss                        -355.07
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         355.405
trainer/entropy_penalty                      -0.335005
trainer/entropy_percentage                   -0.000942599
trainer/Q1Pred Mean                         353.342
trainer/Q1Pred Std                           61.9057
trainer/Q1Pred Max                          432.336
trainer/Q1Pred Min                          100.16
trainer/Q2Pred Mean                         352.931
trainer/Q2Pred Std                           61.8102
trainer/Q2Pred Max                          432.658
trainer/Q2Pred Min                          113.708
trainer/QTargetWithReg Mean                 352.724
trainer/QTargetWithReg Std                   61.6339
trainer/QTargetWithReg Max                  429.57
trainer/QTargetWithReg Min                  106.284
trainer/PolicyLossWithoutReg Mean           355.406
trainer/PolicyLossWithoutReg Std             58.9922
trainer/PolicyLossWithoutReg Max            431.928
trainer/PolicyLossWithoutReg Min            114.125
exploration/num steps total              990000
exploration/num paths total                1797
exploration/path length this epoch Mean     428
exploration/path length this epoch Std        0
exploration/path length this epoch Max      428
exploration/path length this epoch Min      428
exploration/Rewards Mean                      4.05127
exploration/Rewards Std                       1.51172
exploration/Rewards Max                       7.04468
exploration/Rewards Min                      -0.797934
exploration/Returns Mean                   1733.94
exploration/Returns Std                       0
exploration/Returns Max                    1733.94
exploration/Returns Min                    1733.94
exploration/Num Paths                         1
exploration/Average Returns                1733.94
evaluation_0/num steps total                  7.72848e+06
evaluation_0/num paths total              11385
evaluation_0/path length Mean               773.1
evaluation_0/path length Std                235.731
evaluation_0/path length Max               1000
evaluation_0/path length Min                406
evaluation_0/Rewards Mean                     4.74658
evaluation_0/Rewards Std                      1.25099
evaluation_0/Rewards Max                      9.17878
evaluation_0/Rewards Min                     -0.661739
evaluation_0/Returns Mean                  3669.58
evaluation_0/Returns Std                   1201.19
evaluation_0/Returns Max                   4983.74
evaluation_0/Returns Min                   1777.29
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3669.58
time/epoch (s)                                0
time/total (s)                            14855.5
Epoch                                       985
---------------------------------------  ----------------
2022-11-16 20:22:33.455523 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 986 finished
---------------------------------------  ----------------
epoch                                       986
total_step                               991000
replay_pool/size                         991000
trainer/alpha                                 0.0562755
trainer/alpha_loss                            0.291273
trainer/entropy                              -6.10123
trainer/qf_loss                              29.8313
trainer/policy_loss                        -350.677
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         351.02
trainer/entropy_penalty                      -0.34335
trainer/entropy_percentage                   -0.000978148
trainer/Q1Pred Mean                         348.886
trainer/Q1Pred Std                           63.9779
trainer/Q1Pred Max                          425.478
trainer/Q1Pred Min                           29.6207
trainer/Q2Pred Mean                         348.55
trainer/Q2Pred Std                           64.9703
trainer/Q2Pred Max                          427.221
trainer/Q2Pred Min                           38.9178
trainer/QTargetWithReg Mean                 350.394
trainer/QTargetWithReg Std                   64.0381
trainer/QTargetWithReg Max                  426.193
trainer/QTargetWithReg Min                   38.8653
trainer/PolicyLossWithoutReg Mean           351.02
trainer/PolicyLossWithoutReg Std             64.0233
trainer/PolicyLossWithoutReg Max            425.845
trainer/PolicyLossWithoutReg Min             32.7715
exploration/num steps total              991000
exploration/num paths total                1799
exploration/path length this epoch Mean     200
exploration/path length this epoch Std      110
exploration/path length this epoch Max      310
exploration/path length this epoch Min       90
exploration/Rewards Mean                      3.00394
exploration/Rewards Std                       1.21158
exploration/Rewards Max                       5.579
exploration/Rewards Min                      -0.827392
exploration/Returns Mean                    600.787
exploration/Returns Std                     419.292
exploration/Returns Max                    1020.08
exploration/Returns Min                     181.495
exploration/Num Paths                         2
exploration/Average Returns                 600.787
evaluation_0/num steps total                  7.73648e+06
evaluation_0/num paths total              11393
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63903
evaluation_0/Rewards Std                      1.16771
evaluation_0/Rewards Max                      7.46523
evaluation_0/Rewards Min                     -0.740892
evaluation_0/Returns Mean                  4639.03
evaluation_0/Returns Std                     92.7944
evaluation_0/Returns Max                   4778.65
evaluation_0/Returns Min                   4490.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4639.03
time/epoch (s)                                0
time/total (s)                            14870.3
Epoch                                       986
---------------------------------------  ----------------
2022-11-16 20:22:48.274286 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 987 finished
---------------------------------------  ----------------
epoch                                       987
total_step                               992000
replay_pool/size                         992000
trainer/alpha                                 0.0572181
trainer/alpha_loss                            0.0173195
trainer/entropy                              -6.00605
trainer/qf_loss                              22.0496
trainer/policy_loss                        -357.728
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         358.072
trainer/entropy_penalty                      -0.343655
trainer/entropy_percentage                   -0.000959736
trainer/Q1Pred Mean                         356.43
trainer/Q1Pred Std                           70.2776
trainer/Q1Pred Max                          423.136
trainer/Q1Pred Min                           -6.24937
trainer/Q2Pred Mean                         356.591
trainer/Q2Pred Std                           70.2152
trainer/Q2Pred Max                          424.248
trainer/Q2Pred Min                           12.5273
trainer/QTargetWithReg Mean                 356.828
trainer/QTargetWithReg Std                   70.0452
trainer/QTargetWithReg Max                  423.723
trainer/QTargetWithReg Min                   -6.10093
trainer/PolicyLossWithoutReg Mean           358.072
trainer/PolicyLossWithoutReg Std             69.2539
trainer/PolicyLossWithoutReg Max            422.876
trainer/PolicyLossWithoutReg Min              3.32045
exploration/num steps total              992000
exploration/num paths total                1800
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.22029
exploration/Rewards Std                       1.28072
exploration/Rewards Max                       6.99018
exploration/Rewards Min                      -0.814024
exploration/Returns Mean                   4220.29
exploration/Returns Std                       0
exploration/Returns Max                    4220.29
exploration/Returns Min                    4220.29
exploration/Num Paths                         1
exploration/Average Returns                4220.29
evaluation_0/num steps total                  7.74448e+06
evaluation_0/num paths total              11401
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73201
evaluation_0/Rewards Std                      1.02244
evaluation_0/Rewards Max                      7.51395
evaluation_0/Rewards Min                     -0.58318
evaluation_0/Returns Mean                  4732.01
evaluation_0/Returns Std                     81.7644
evaluation_0/Returns Max                   4831.85
evaluation_0/Returns Min                   4557.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4732.01
time/epoch (s)                                0
time/total (s)                            14885.1
Epoch                                       987
---------------------------------------  ----------------
2022-11-16 20:23:04.840000 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 988 finished
---------------------------------------  ----------------
epoch                                       988
total_step                               993000
replay_pool/size                         993000
trainer/alpha                                 0.0567373
trainer/alpha_loss                           -0.0310633
trainer/entropy                              -5.98917
trainer/qf_loss                              28.1846
trainer/policy_loss                        -358.814
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         359.154
trainer/entropy_penalty                      -0.33981
trainer/entropy_percentage                   -0.000946139
trainer/Q1Pred Mean                         358.12
trainer/Q1Pred Std                           65.473
trainer/Q1Pred Max                          438.788
trainer/Q1Pred Min                           11.224
trainer/Q2Pred Mean                         359.039
trainer/Q2Pred Std                           65.7578
trainer/Q2Pred Max                          433.174
trainer/Q2Pred Min                            7.9703
trainer/QTargetWithReg Mean                 358.473
trainer/QTargetWithReg Std                   66.4456
trainer/QTargetWithReg Max                  432.257
trainer/QTargetWithReg Min                   -2.77881
trainer/PolicyLossWithoutReg Mean           359.154
trainer/PolicyLossWithoutReg Std             65.1446
trainer/PolicyLossWithoutReg Max            432.44
trainer/PolicyLossWithoutReg Min              7.3368
exploration/num steps total              993000
exploration/num paths total                1801
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59422
exploration/Rewards Std                       0.965111
exploration/Rewards Max                       7.13427
exploration/Rewards Min                      -0.669684
exploration/Returns Mean                   4594.22
exploration/Returns Std                       0
exploration/Returns Max                    4594.22
exploration/Returns Min                    4594.22
exploration/Num Paths                         1
exploration/Average Returns                4594.22
evaluation_0/num steps total                  7.75228e+06
evaluation_0/num paths total              11410
evaluation_0/path length Mean               866.556
evaluation_0/path length Std                208.318
evaluation_0/path length Max               1000
evaluation_0/path length Min                422
evaluation_0/Rewards Mean                     4.58599
evaluation_0/Rewards Std                      1.20013
evaluation_0/Rewards Max                      7.08396
evaluation_0/Rewards Min                     -0.615951
evaluation_0/Returns Mean                  3974.02
evaluation_0/Returns Std                   1106.99
evaluation_0/Returns Max                   4791.68
evaluation_0/Returns Min                   1622.7
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3974.02
time/epoch (s)                                0
time/total (s)                            14901.7
Epoch                                       988
---------------------------------------  ----------------
2022-11-16 20:23:19.734130 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 989 finished
---------------------------------------  ----------------
epoch                                       989
total_step                               994000
replay_pool/size                         994000
trainer/alpha                                 0.0555782
trainer/alpha_loss                            0.642326
trainer/entropy                              -6.22226
trainer/qf_loss                              21.0851
trainer/policy_loss                        -353.716
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         354.062
trainer/entropy_penalty                      -0.345822
trainer/entropy_percentage                   -0.000976728
trainer/Q1Pred Mean                         354.093
trainer/Q1Pred Std                           58.7354
trainer/Q1Pred Max                          431.143
trainer/Q1Pred Min                           72.8439
trainer/Q2Pred Mean                         354.441
trainer/Q2Pred Std                           59.2562
trainer/Q2Pred Max                          434.725
trainer/Q2Pred Min                           50.7452
trainer/QTargetWithReg Mean                 353.736
trainer/QTargetWithReg Std                   59.0782
trainer/QTargetWithReg Max                  430.955
trainer/QTargetWithReg Min                   52.6943
trainer/PolicyLossWithoutReg Mean           354.062
trainer/PolicyLossWithoutReg Std             57.7743
trainer/PolicyLossWithoutReg Max            431.102
trainer/PolicyLossWithoutReg Min             76.5164
exploration/num steps total              994000
exploration/num paths total                1803
exploration/path length this epoch Mean     282
exploration/path length this epoch Std      146
exploration/path length this epoch Max      428
exploration/path length this epoch Min      136
exploration/Rewards Mean                      3.79952
exploration/Rewards Std                       1.50791
exploration/Rewards Max                       6.67332
exploration/Rewards Min                      -0.77923
exploration/Returns Mean                   1071.47
exploration/Returns Std                     707.173
exploration/Returns Max                    1778.64
exploration/Returns Min                     364.293
exploration/Num Paths                         2
exploration/Average Returns                1071.47
evaluation_0/num steps total                  7.76028e+06
evaluation_0/num paths total              11418
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74952
evaluation_0/Rewards Std                      1.11011
evaluation_0/Rewards Max                      7.50765
evaluation_0/Rewards Min                     -0.651708
evaluation_0/Returns Mean                  4749.52
evaluation_0/Returns Std                     44.7486
evaluation_0/Returns Max                   4812.9
evaluation_0/Returns Min                   4659.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4749.52
time/epoch (s)                                0
time/total (s)                            14916.6
Epoch                                       989
---------------------------------------  ----------------
2022-11-16 20:23:34.867538 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 990 finished
---------------------------------------  ----------------
epoch                                       990
total_step                               995000
replay_pool/size                         995000
trainer/alpha                                 0.056366
trainer/alpha_loss                           -0.729328
trainer/entropy                              -5.74639
trainer/qf_loss                              27.777
trainer/policy_loss                        -352.043
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         352.367
trainer/entropy_penalty                      -0.323901
trainer/entropy_percentage                   -0.000919214
trainer/Q1Pred Mean                         350.775
trainer/Q1Pred Std                           66.4743
trainer/Q1Pred Max                          425.804
trainer/Q1Pred Min                           -5.69297
trainer/Q2Pred Mean                         351.328
trainer/Q2Pred Std                           66.6258
trainer/Q2Pred Max                          427.279
trainer/Q2Pred Min                           -0.552151
trainer/QTargetWithReg Mean                 352.593
trainer/QTargetWithReg Std                   66.0434
trainer/QTargetWithReg Max                  426.933
trainer/QTargetWithReg Min                    3.4009
trainer/PolicyLossWithoutReg Mean           352.367
trainer/PolicyLossWithoutReg Std             65.7328
trainer/PolicyLossWithoutReg Max            426.359
trainer/PolicyLossWithoutReg Min             -1.46337
exploration/num steps total              995000
exploration/num paths total                1804
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59265
exploration/Rewards Std                       1.19806
exploration/Rewards Max                       7.82639
exploration/Rewards Min                      -0.97385
exploration/Returns Mean                   4592.65
exploration/Returns Std                       0
exploration/Returns Max                    4592.65
exploration/Returns Min                    4592.65
exploration/Num Paths                         1
exploration/Average Returns                4592.65
evaluation_0/num steps total                  7.76828e+06
evaluation_0/num paths total              11426
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7069
evaluation_0/Rewards Std                      0.947225
evaluation_0/Rewards Max                      7.24162
evaluation_0/Rewards Min                     -0.719823
evaluation_0/Returns Mean                  4706.9
evaluation_0/Returns Std                     46.7587
evaluation_0/Returns Max                   4784.87
evaluation_0/Returns Min                   4627.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4706.9
time/epoch (s)                                0
time/total (s)                            14931.7
Epoch                                       990
---------------------------------------  ----------------
2022-11-16 20:23:51.547787 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 991 finished
---------------------------------------  ----------------
epoch                                       991
total_step                               996000
replay_pool/size                         996000
trainer/alpha                                 0.0557587
trainer/alpha_loss                            0.721948
trainer/entropy                              -6.25008
trainer/qf_loss                              21.0674
trainer/policy_loss                        -356.091
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         356.44
trainer/entropy_penalty                      -0.348496
trainer/entropy_percentage                   -0.000977714
trainer/Q1Pred Mean                         355.48
trainer/Q1Pred Std                           61.6541
trainer/Q1Pred Max                          432.561
trainer/Q1Pred Min                           35.2713
trainer/Q2Pred Mean                         355.232
trainer/Q2Pred Std                           61.7272
trainer/Q2Pred Max                          434.251
trainer/Q2Pred Min                           39.4283
trainer/QTargetWithReg Mean                 355.864
trainer/QTargetWithReg Std                   62.0708
trainer/QTargetWithReg Max                  433.53
trainer/QTargetWithReg Min                   30.0188
trainer/PolicyLossWithoutReg Mean           356.44
trainer/PolicyLossWithoutReg Std             61.3144
trainer/PolicyLossWithoutReg Max            432.686
trainer/PolicyLossWithoutReg Min             37.2689
exploration/num steps total              996000
exploration/num paths total                1805
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60778
exploration/Rewards Std                       0.945843
exploration/Rewards Max                       6.92047
exploration/Rewards Min                      -0.762189
exploration/Returns Mean                   4607.78
exploration/Returns Std                       0
exploration/Returns Max                    4607.78
exploration/Returns Min                    4607.78
exploration/Num Paths                         1
exploration/Average Returns                4607.78
evaluation_0/num steps total                  7.77617e+06
evaluation_0/num paths total              11434
evaluation_0/path length Mean               986.625
evaluation_0/path length Std                 35.3869
evaluation_0/path length Max               1000
evaluation_0/path length Min                893
evaluation_0/Rewards Mean                     4.60534
evaluation_0/Rewards Std                      1.25463
evaluation_0/Rewards Max                      8.62316
evaluation_0/Rewards Min                     -0.60969
evaluation_0/Returns Mean                  4543.75
evaluation_0/Returns Std                    180.161
evaluation_0/Returns Max                   4720.06
evaluation_0/Returns Min                   4115.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4543.75
time/epoch (s)                                0
time/total (s)                            14948.4
Epoch                                       991
---------------------------------------  ----------------
2022-11-16 20:24:06.306529 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 992 finished
---------------------------------------  ----------------
epoch                                       992
total_step                               997000
replay_pool/size                         997000
trainer/alpha                                 0.0575954
trainer/alpha_loss                            0.723273
trainer/entropy                              -6.25337
trainer/qf_loss                              21.2306
trainer/policy_loss                        -360.813
trainer/adversary_policy_loss                17.0803
trainer/policy_loss_without_entropy         361.173
trainer/entropy_penalty                      -0.360165
trainer/entropy_percentage                   -0.000997208
trainer/Q1Pred Mean                         358.672
trainer/Q1Pred Std                           63.1237
trainer/Q1Pred Max                          429.833
trainer/Q1Pred Min                           -2.34167
trainer/Q2Pred Mean                         359.536
trainer/Q2Pred Std                           62.6624
trainer/Q2Pred Max                          430.649
trainer/Q2Pred Min                           -1.60646
trainer/QTargetWithReg Mean                 359.445
trainer/QTargetWithReg Std                   62.5349
trainer/QTargetWithReg Max                  429.014
trainer/QTargetWithReg Min                    4.09843
trainer/PolicyLossWithoutReg Mean           361.173
trainer/PolicyLossWithoutReg Std             60.6462
trainer/PolicyLossWithoutReg Max            431.564
trainer/PolicyLossWithoutReg Min             12.0058
exploration/num steps total              997000
exploration/num paths total                1806
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6561
exploration/Rewards Std                       0.95419
exploration/Rewards Max                       6.93407
exploration/Rewards Min                      -0.817281
exploration/Returns Mean                   4656.1
exploration/Returns Std                       0
exploration/Returns Max                    4656.1
exploration/Returns Min                    4656.1
exploration/Num Paths                         1
exploration/Average Returns                4656.1
evaluation_0/num steps total                  7.78417e+06
evaluation_0/num paths total              11442
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58101
evaluation_0/Rewards Std                      1.11322
evaluation_0/Rewards Max                      7.3571
evaluation_0/Rewards Min                     -0.537075
evaluation_0/Returns Mean                  4581.01
evaluation_0/Returns Std                     50.6043
evaluation_0/Returns Max                   4674.18
evaluation_0/Returns Min                   4530.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4581.01
time/epoch (s)                                0
time/total (s)                            14963.1
Epoch                                       992
---------------------------------------  ----------------
2022-11-16 20:24:23.180177 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 993 finished
---------------------------------------  ----------------
epoch                                       993
total_step                               998000
replay_pool/size                         998000
trainer/alpha                                 0.0584164
trainer/alpha_loss                           -0.801141
trainer/entropy                              -5.71792
trainer/qf_loss                              27.406
trainer/policy_loss                        -349.803
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         350.137
trainer/entropy_penalty                      -0.33402
trainer/entropy_percentage                   -0.00095397
trainer/Q1Pred Mean                         349.838
trainer/Q1Pred Std                           81.9821
trainer/Q1Pred Max                          428.972
trainer/Q1Pred Min                           -1.5793
trainer/Q2Pred Mean                         349.448
trainer/Q2Pred Std                           81.8011
trainer/Q2Pred Max                          429.189
trainer/Q2Pred Min                           -3.19284
trainer/QTargetWithReg Mean                 350.024
trainer/QTargetWithReg Std                   82.0771
trainer/QTargetWithReg Max                  430.83
trainer/QTargetWithReg Min                   -4.55905
trainer/PolicyLossWithoutReg Mean           350.137
trainer/PolicyLossWithoutReg Std             82.0323
trainer/PolicyLossWithoutReg Max            427.317
trainer/PolicyLossWithoutReg Min             -6.32162
exploration/num steps total              998000
exploration/num paths total                1807
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.43565
exploration/Rewards Std                       1.28879
exploration/Rewards Max                       7.00114
exploration/Rewards Min                      -0.474844
exploration/Returns Mean                   4435.65
exploration/Returns Std                       0
exploration/Returns Max                    4435.65
exploration/Returns Min                    4435.65
exploration/Num Paths                         1
exploration/Average Returns                4435.65
evaluation_0/num steps total                  7.79215e+06
evaluation_0/num paths total              11451
evaluation_0/path length Mean               886.222
evaluation_0/path length Std                212.934
evaluation_0/path length Max               1000
evaluation_0/path length Min                476
evaluation_0/Rewards Mean                     4.73139
evaluation_0/Rewards Std                      1.07067
evaluation_0/Rewards Max                      7.60812
evaluation_0/Rewards Min                     -0.524227
evaluation_0/Returns Mean                  4193.06
evaluation_0/Returns Std                   1089.52
evaluation_0/Returns Max                   4820.23
evaluation_0/Returns Min                   2080.93
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4193.06
time/epoch (s)                                0
time/total (s)                            14980
Epoch                                       993
---------------------------------------  ----------------
2022-11-16 20:24:39.967502 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 994 finished
---------------------------------------  ----------------
epoch                                       994
total_step                               999000
replay_pool/size                         999000
trainer/alpha                                 0.0567794
trainer/alpha_loss                            0.521588
trainer/entropy                              -6.18182
trainer/qf_loss                              17.0661
trainer/policy_loss                        -362.372
trainer/adversary_policy_loss               nan
trainer/policy_loss_without_entropy         362.723
trainer/entropy_penalty                      -0.351
trainer/entropy_percentage                   -0.000967679
trainer/Q1Pred Mean                         361.849
trainer/Q1Pred Std                           58.4365
trainer/Q1Pred Max                          423.62
trainer/Q1Pred Min                           13.7476
trainer/Q2Pred Mean                         361.49
trainer/Q2Pred Std                           58.8574
trainer/Q2Pred Max                          428.928
trainer/Q2Pred Min                           10.9272
trainer/QTargetWithReg Mean                 361.666
trainer/QTargetWithReg Std                   59.0883
trainer/QTargetWithReg Max                  425.556
trainer/QTargetWithReg Min                    7.87243
trainer/PolicyLossWithoutReg Mean           362.723
trainer/PolicyLossWithoutReg Std             57.5881
trainer/PolicyLossWithoutReg Max            424.96
trainer/PolicyLossWithoutReg Min              7.56098
exploration/num steps total              999000
exploration/num paths total                1809
exploration/path length this epoch Mean     414.5
exploration/path length this epoch Std        8.5
exploration/path length this epoch Max      423
exploration/path length this epoch Min      406
exploration/Rewards Mean                      4.38703
exploration/Rewards Std                       1.31705
exploration/Rewards Max                       7.47107
exploration/Rewards Min                      -0.490206
exploration/Returns Mean                   1818.42
exploration/Returns Std                      55.3009
exploration/Returns Max                    1873.72
exploration/Returns Min                    1763.12
exploration/Num Paths                         2
exploration/Average Returns                1818.42
evaluation_0/num steps total                  7.80001e+06
evaluation_0/num paths total              11459
evaluation_0/path length Mean               983.125
evaluation_0/path length Std                 44.6471
evaluation_0/path length Max               1000
evaluation_0/path length Min                865
evaluation_0/Rewards Mean                     4.86941
evaluation_0/Rewards Std                      1.0085
evaluation_0/Rewards Max                      7.04859
evaluation_0/Rewards Min                     -0.519471
evaluation_0/Returns Mean                  4787.24
evaluation_0/Returns Std                    209.824
evaluation_0/Returns Max                   4947.26
evaluation_0/Returns Min                   4251.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4787.24
time/epoch (s)                                0
time/total (s)                            14996.8
Epoch                                       994
---------------------------------------  ----------------
2022-11-16 20:24:55.047592 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 995 finished
---------------------------------------  ---------------
epoch                                      995
total_step                                   1e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0576705
trainer/alpha_loss                          -0.739055
trainer/entropy                             -5.74095
trainer/qf_loss                             20.347
trainer/policy_loss                       -360.953
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        361.284
trainer/entropy_penalty                     -0.331083
trainer/entropy_percentage                  -0.000916407
trainer/Q1Pred Mean                        361.228
trainer/Q1Pred Std                          49.9383
trainer/Q1Pred Max                         428.846
trainer/Q1Pred Min                         202.91
trainer/Q2Pred Mean                        361.863
trainer/Q2Pred Std                          50.0594
trainer/Q2Pred Max                         431.828
trainer/Q2Pred Min                         189.717
trainer/QTargetWithReg Mean                360.812
trainer/QTargetWithReg Std                  50.0065
trainer/QTargetWithReg Max                 430.349
trainer/QTargetWithReg Min                 188.444
trainer/PolicyLossWithoutReg Mean          361.284
trainer/PolicyLossWithoutReg Std            49.4299
trainer/PolicyLossWithoutReg Max           427.959
trainer/PolicyLossWithoutReg Min           209.658
exploration/num steps total                  1e+06
exploration/num paths total               1810
exploration/path length this epoch Mean     39
exploration/path length this epoch Std       0
exploration/path length this epoch Max      39
exploration/path length this epoch Min      39
exploration/Rewards Mean                     1.45246
exploration/Rewards Std                      1.32508
exploration/Rewards Max                      3.54722
exploration/Rewards Min                     -1.23416
exploration/Returns Mean                    56.6459
exploration/Returns Std                      0
exploration/Returns Max                     56.6459
exploration/Returns Min                     56.6459
exploration/Num Paths                        1
exploration/Average Returns                 56.6459
evaluation_0/num steps total                 7.80801e+06
evaluation_0/num paths total             11467
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.61673
evaluation_0/Rewards Std                     0.994065
evaluation_0/Rewards Max                     7.24614
evaluation_0/Rewards Min                    -0.620259
evaluation_0/Returns Mean                 4616.73
evaluation_0/Returns Std                    64.9362
evaluation_0/Returns Max                  4745.92
evaluation_0/Returns Min                  4498.32
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4616.73
time/epoch (s)                               0
time/total (s)                           15011.9
Epoch                                      995
---------------------------------------  ---------------
2022-11-16 20:25:10.212575 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 996 finished
---------------------------------------  ---------------
epoch                                      996
total_step                                   1.001e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0563575
trainer/alpha_loss                          -0.0188351
trainer/entropy                             -5.99345
trainer/qf_loss                             29.8137
trainer/policy_loss                       -365.382
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        365.72
trainer/entropy_penalty                     -0.337776
trainer/entropy_percentage                  -0.000923591
trainer/Q1Pred Mean                        364.666
trainer/Q1Pred Std                          50.7132
trainer/Q1Pred Max                         435.165
trainer/Q1Pred Min                          89.9624
trainer/Q2Pred Mean                        364.946
trainer/Q2Pred Std                          50.1666
trainer/Q2Pred Max                         433.366
trainer/Q2Pred Min                          86.4305
trainer/QTargetWithReg Mean                364.792
trainer/QTargetWithReg Std                  50.6711
trainer/QTargetWithReg Max                 438.678
trainer/QTargetWithReg Min                  76.6293
trainer/PolicyLossWithoutReg Mean          365.72
trainer/PolicyLossWithoutReg Std            49.7358
trainer/PolicyLossWithoutReg Max           434.195
trainer/PolicyLossWithoutReg Min           104.526
exploration/num steps total                  1.001e+06
exploration/num paths total               1811
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.64241
exploration/Rewards Std                      0.992936
exploration/Rewards Max                      6.80995
exploration/Rewards Min                     -0.536374
exploration/Returns Mean                  4642.41
exploration/Returns Std                      0
exploration/Returns Max                   4642.41
exploration/Returns Min                   4642.41
exploration/Num Paths                        1
exploration/Average Returns               4642.41
evaluation_0/num steps total                 7.81601e+06
evaluation_0/num paths total             11475
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.89513
evaluation_0/Rewards Std                     0.985684
evaluation_0/Rewards Max                     7.32496
evaluation_0/Rewards Min                    -0.593386
evaluation_0/Returns Mean                 4895.13
evaluation_0/Returns Std                    22.7415
evaluation_0/Returns Max                  4930.49
evaluation_0/Returns Min                  4849.39
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4895.13
time/epoch (s)                               0
time/total (s)                           15027
Epoch                                      996
---------------------------------------  ---------------
2022-11-16 20:25:27.161357 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 997 finished
---------------------------------------  ---------------
epoch                                      997
total_step                                   1.002e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0580363
trainer/alpha_loss                           1.45223
trainer/entropy                             -6.51014
trainer/qf_loss                             25.2926
trainer/policy_loss                       -351.482
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        351.86
trainer/entropy_penalty                     -0.377824
trainer/entropy_percentage                  -0.00107379
trainer/Q1Pred Mean                        350.618
trainer/Q1Pred Std                          71.552
trainer/Q1Pred Max                         431.066
trainer/Q1Pred Min                          15.7769
trainer/Q2Pred Mean                        351.076
trainer/Q2Pred Std                          71.4483
trainer/Q2Pred Max                         432.865
trainer/Q2Pred Min                          14.0562
trainer/QTargetWithReg Mean                351.293
trainer/QTargetWithReg Std                  71.629
trainer/QTargetWithReg Max                 432.173
trainer/QTargetWithReg Min                  19.9239
trainer/PolicyLossWithoutReg Mean          351.86
trainer/PolicyLossWithoutReg Std            70.9567
trainer/PolicyLossWithoutReg Max           431.793
trainer/PolicyLossWithoutReg Min            17.0733
exploration/num steps total                  1.002e+06
exploration/num paths total               1812
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.71042
exploration/Rewards Std                      1.07876
exploration/Rewards Max                      7.3821
exploration/Rewards Min                     -0.58018
exploration/Returns Mean                  4710.42
exploration/Returns Std                      0
exploration/Returns Max                   4710.42
exploration/Returns Min                   4710.42
exploration/Num Paths                        1
exploration/Average Returns               4710.42
evaluation_0/num steps total                 7.82371e+06
evaluation_0/num paths total             11484
evaluation_0/path length Mean              855.444
evaluation_0/path length Std               225.43
evaluation_0/path length Max              1000
evaluation_0/path length Min               352
evaluation_0/Rewards Mean                    4.80746
evaluation_0/Rewards Std                     1.03278
evaluation_0/Rewards Max                     9.88215
evaluation_0/Rewards Min                    -0.744994
evaluation_0/Returns Mean                 4112.52
evaluation_0/Returns Std                  1168.34
evaluation_0/Returns Max                  5020.2
evaluation_0/Returns Min                  1487.27
evaluation_0/Num Paths                       9
evaluation_0/Average Returns              4112.52
time/epoch (s)                               0
time/total (s)                           15044
Epoch                                      997
---------------------------------------  ---------------
2022-11-16 20:25:43.574736 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 998 finished
---------------------------------------  ---------------
epoch                                      998
total_step                                   1.003e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0549571
trainer/alpha_loss                           0.33476
trainer/entropy                             -6.11539
trainer/qf_loss                             21.0753
trainer/policy_loss                       -359.438
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        359.774
trainer/entropy_penalty                     -0.336084
trainer/entropy_percentage                  -0.000934154
trainer/Q1Pred Mean                        358.372
trainer/Q1Pred Std                          59.8701
trainer/Q1Pred Max                         437.998
trainer/Q1Pred Min                          29.2463
trainer/Q2Pred Mean                        358.482
trainer/Q2Pred Std                          59.8273
trainer/Q2Pred Max                         437.858
trainer/Q2Pred Min                          30.4299
trainer/QTargetWithReg Mean                359.142
trainer/QTargetWithReg Std                  60.3219
trainer/QTargetWithReg Max                 441.115
trainer/QTargetWithReg Min                  30.4034
trainer/PolicyLossWithoutReg Mean          359.774
trainer/PolicyLossWithoutReg Std            58.7107
trainer/PolicyLossWithoutReg Max           439.894
trainer/PolicyLossWithoutReg Min            33.7782
exploration/num steps total                  1.003e+06
exploration/num paths total               1813
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.79932
exploration/Rewards Std                      0.943232
exploration/Rewards Max                      7.1055
exploration/Rewards Min                     -0.580073
exploration/Returns Mean                  4799.32
exploration/Returns Std                      0
exploration/Returns Max                   4799.32
exploration/Returns Min                   4799.32
exploration/Num Paths                        1
exploration/Average Returns               4799.32
evaluation_0/num steps total                 7.83127e+06
evaluation_0/num paths total             11492
evaluation_0/path length Mean              944.75
evaluation_0/path length Std               146.178
evaluation_0/path length Max              1000
evaluation_0/path length Min               558
evaluation_0/Rewards Mean                    4.78601
evaluation_0/Rewards Std                     0.960752
evaluation_0/Rewards Max                     7.38817
evaluation_0/Rewards Min                    -0.617218
evaluation_0/Returns Mean                 4521.58
evaluation_0/Returns Std                   728.808
evaluation_0/Returns Max                  4829.98
evaluation_0/Returns Min                  2593.89
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4521.58
time/epoch (s)                               0
time/total (s)                           15060.4
Epoch                                      998
---------------------------------------  ---------------
2022-11-16 20:25:58.319502 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 999 finished
---------------------------------------  ---------------
epoch                                      999
total_step                                   1.004e+06
replay_pool/size                             1e+06
trainer/alpha                                0.055336
trainer/alpha_loss                          -0.298445
trainer/entropy                             -5.89689
trainer/qf_loss                             35.8994
trainer/policy_loss                       -350.859
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        351.186
trainer/entropy_penalty                     -0.326311
trainer/entropy_percentage                  -0.000929168
trainer/Q1Pred Mean                        350.493
trainer/Q1Pred Std                          77.1351
trainer/Q1Pred Max                         443.989
trainer/Q1Pred Min                          -4.13706
trainer/Q2Pred Mean                        350.322
trainer/Q2Pred Std                          78.2944
trainer/Q2Pred Max                         443.155
trainer/Q2Pred Min                         -47.58
trainer/QTargetWithReg Mean                351.863
trainer/QTargetWithReg Std                  78.1497
trainer/QTargetWithReg Max                 444.132
trainer/QTargetWithReg Min                  -0.740212
trainer/PolicyLossWithoutReg Mean          351.186
trainer/PolicyLossWithoutReg Std            77.4021
trainer/PolicyLossWithoutReg Max           443.172
trainer/PolicyLossWithoutReg Min           -47.2218
exploration/num steps total                  1.004e+06
exploration/num paths total               1814
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.63719
exploration/Rewards Std                      0.99865
exploration/Rewards Max                      7.17569
exploration/Rewards Min                     -0.824083
exploration/Returns Mean                  4637.19
exploration/Returns Std                      0
exploration/Returns Max                   4637.19
exploration/Returns Min                   4637.19
exploration/Num Paths                        1
exploration/Average Returns               4637.19
evaluation_0/num steps total                 7.83927e+06
evaluation_0/num paths total             11500
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.87592
evaluation_0/Rewards Std                     0.973369
evaluation_0/Rewards Max                     7.51409
evaluation_0/Rewards Min                    -0.752748
evaluation_0/Returns Mean                 4875.92
evaluation_0/Returns Std                    67.5198
evaluation_0/Returns Max                  4982.71
evaluation_0/Returns Min                  4741.24
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4875.92
time/epoch (s)                               0
time/total (s)                           15075.1
Epoch                                      999
---------------------------------------  ---------------
2022-11-16 20:26:13.466094 CST | [0_sc-sac_Walker2d-v2_test_pr-sac] Epoch 1000 finished
---------------------------------------  ---------------
epoch                                     1000
total_step                                   1.005e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0562484
trainer/alpha_loss                           0.348449
trainer/entropy                             -6.12107
trainer/qf_loss                            174.629
trainer/policy_loss                       -358.152
trainer/adversary_policy_loss              nan
trainer/policy_loss_without_entropy        358.496
trainer/entropy_penalty                     -0.3443
trainer/entropy_percentage                  -0.000960402
trainer/Q1Pred Mean                        356.46
trainer/Q1Pred Std                          70.5469
trainer/Q1Pred Max                         436.424
trainer/Q1Pred Min                           5.0062
trainer/Q2Pred Mean                        356.201
trainer/Q2Pred Std                          72.1903
trainer/Q2Pred Max                         436.86
trainer/Q2Pred Min                          -8.00554
trainer/QTargetWithReg Mean                357.923
trainer/QTargetWithReg Std                  69.4334
trainer/QTargetWithReg Max                 436.463
trainer/QTargetWithReg Min                  10.4753
trainer/PolicyLossWithoutReg Mean          358.496
trainer/PolicyLossWithoutReg Std            69.976
trainer/PolicyLossWithoutReg Max           437.73
trainer/PolicyLossWithoutReg Min             9.11191
exploration/num steps total                  1.005e+06
exploration/num paths total               1815
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.79063
exploration/Rewards Std                      0.996133
exploration/Rewards Max                      7.25119
exploration/Rewards Min                     -0.692269
exploration/Returns Mean                  4790.63
exploration/Returns Std                      0
exploration/Returns Max                   4790.63
exploration/Returns Min                   4790.63
exploration/Num Paths                        1
exploration/Average Returns               4790.63
evaluation_0/num steps total                 7.84727e+06
evaluation_0/num paths total             11508
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.7603
evaluation_0/Rewards Std                     0.967578
evaluation_0/Rewards Max                     7.40805
evaluation_0/Rewards Min                    -0.67526
evaluation_0/Returns Mean                 4760.3
evaluation_0/Returns Std                    46.0157
evaluation_0/Returns Max                  4830.07
evaluation_0/Returns Min                  4703.07
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4760.3
time/epoch (s)                               0
time/total (s)                           15090.3
Epoch                                     1000
---------------------------------------  ---------------
