2022-11-16 10:46:09.338630 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 1 finished
---------------------------------------  -------------
epoch                                       1
total_step                               6000
replay_pool/size                         6000
trainer/alpha                               0.9997
trainer/alpha_loss                          0
trainer/entropy                             3.82228
trainer/qf_loss                            13.3687
trainer/state_noise                         0.005
trainer/policy_loss                        -3.85931
trainer/policy_loss_without_entropy         0.0397063
trainer/entropy_penalty                     3.82113
trainer/entropy_percentage                 96.2348
trainer/Q1Pred Mean                        -0.0337889
trainer/Q1Pred Std                          0.0704134
trainer/Q1Pred Max                          0.182311
trainer/Q1Pred Min                         -0.194738
trainer/Q2Pred Mean                         0.0527527
trainer/Q2Pred Std                          0.0543806
trainer/Q2Pred Max                          0.185788
trainer/Q2Pred Min                         -0.127393
trainer/QTargetWithReg Mean                 3.38542
trainer/QTargetWithReg Std                  1.40155
trainer/QTargetWithReg Max                  5.81689
trainer/QTargetWithReg Min                 -1.1191
trainer/PolicyLossWithoutReg Mean           0.0397063
trainer/PolicyLossWithoutReg Std            0.0571635
trainer/PolicyLossWithoutReg Max            0.192451
trainer/PolicyLossWithoutReg Min           -0.0942875
trainer/gradient_norm                       0.306109
trainer/gradient_penalty                   -0.00153055
trainer/gradient_percentage                -0.0385467
exploration/num steps total              6000
exploration/num paths total               359
exploration/path length this epoch Mean    37.1154
exploration/path length this epoch Std     27.0005
exploration/path length this epoch Max    114
exploration/path length this epoch Min     11
exploration/Rewards Mean                    0.0738603
exploration/Rewards Std                     0.675449
exploration/Rewards Max                     1.69274
exploration/Rewards Min                    -1.99269
exploration/Returns Mean                    2.74135
exploration/Returns Std                    10.2798
exploration/Returns Max                    17.3987
exploration/Returns Min                   -37.9858
exploration/Num Paths                      26
exploration/Average Returns                 2.74135
evaluation_0/num steps total             7884
evaluation_0/num paths total               33
evaluation_0/path length Mean             238.909
evaluation_0/path length Std               38.3322
evaluation_0/path length Max              358
evaluation_0/path length Min              183
evaluation_0/Rewards Mean                   0.930078
evaluation_0/Rewards Std                    0.819226
evaluation_0/Rewards Max                    3.44547
evaluation_0/Rewards Min                   -1.30984
evaluation_0/Returns Mean                 222.204
evaluation_0/Returns Std                  127.091
evaluation_0/Returns Max                  470.217
evaluation_0/Returns Min                   71.9869
evaluation_0/Num Paths                     33
evaluation_0/Average Returns              222.204
time/epoch (s)                              0
time/total (s)                             23.3327
Epoch                                       1
---------------------------------------  -------------
2022-11-16 10:46:25.996190 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 2 finished
---------------------------------------  --------------
epoch                                        2
total_step                                7000
replay_pool/size                          7000
trainer/alpha                                0.743177
trainer/alpha_loss                          -2.78129
trainer/entropy                              3.37937
trainer/qf_loss                              0.961202
trainer/state_noise                          0.005
trainer/policy_loss                        -15.7338
trainer/policy_loss_without_entropy         13.3341
trainer/entropy_penalty                      2.51147
trainer/entropy_percentage                   0.18835
trainer/Q1Pred Mean                         12.2884
trainer/Q1Pred Std                           5.37031
trainer/Q1Pred Max                          21.9562
trainer/Q1Pred Min                          -1.7413
trainer/Q2Pred Mean                         12.2432
trainer/Q2Pred Std                           5.41895
trainer/Q2Pred Max                          21.3785
trainer/Q2Pred Min                          -2.27521
trainer/QTargetWithReg Mean                 12.3668
trainer/QTargetWithReg Std                   5.44034
trainer/QTargetWithReg Max                  20.7096
trainer/QTargetWithReg Min                  -0.964381
trainer/PolicyLossWithoutReg Mean           13.3341
trainer/PolicyLossWithoutReg Std             4.82866
trainer/PolicyLossWithoutReg Max            22.2218
trainer/PolicyLossWithoutReg Min            -1.93618
trainer/gradient_norm                       22.3485
trainer/gradient_penalty                    -0.111743
trainer/gradient_percentage                 -0.00838024
exploration/num steps total               7000
exploration/num paths total                366
exploration/path length this epoch Mean    117.571
exploration/path length this epoch Std      26.1963
exploration/path length this epoch Max     167
exploration/path length this epoch Min      84
exploration/Rewards Mean                    -0.0713918
exploration/Rewards Std                      0.895844
exploration/Rewards Max                      2.25839
exploration/Rewards Min                     -2.28071
exploration/Returns Mean                    -8.39363
exploration/Returns Std                     15.4987
exploration/Returns Max                     22.176
exploration/Returns Min                    -24.8216
exploration/Num Paths                        7
exploration/Average Returns                 -8.39363
evaluation_0/num steps total             15674
evaluation_0/num paths total                67
evaluation_0/path length Mean              229.118
evaluation_0/path length Std                37.3361
evaluation_0/path length Max               330
evaluation_0/path length Min               181
evaluation_0/Rewards Mean                    0.65929
evaluation_0/Rewards Std                     0.733342
evaluation_0/Rewards Max                     3.28739
evaluation_0/Rewards Min                    -1.15692
evaluation_0/Returns Mean                  151.055
evaluation_0/Returns Std                   104.278
evaluation_0/Returns Max                   409.895
evaluation_0/Returns Min                    69.4752
evaluation_0/Num Paths                      34
evaluation_0/Average Returns               151.055
time/epoch (s)                               0
time/total (s)                              39.9871
Epoch                                        2
---------------------------------------  --------------
2022-11-16 10:46:43.297260 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 3 finished
---------------------------------------  --------------
epoch                                        3
total_step                                8000
replay_pool/size                          8000
trainer/alpha                                0.562056
trainer/alpha_loss                          -4.95834
trainer/entropy                              2.61006
trainer/qf_loss                              1.40384
trainer/state_noise                          0.005
trainer/policy_loss                        -25.6543
trainer/policy_loss_without_entropy         24.4016
trainer/entropy_penalty                      1.467
trainer/entropy_percentage                   0.0601189
trainer/Q1Pred Mean                         22.0829
trainer/Q1Pred Std                           8.49077
trainer/Q1Pred Max                          33.0788
trainer/Q1Pred Min                          -1.98436
trainer/Q2Pred Mean                         22.0846
trainer/Q2Pred Std                           8.50958
trainer/Q2Pred Max                          34.6578
trainer/Q2Pred Min                          -2.32217
trainer/QTargetWithReg Mean                 22.197
trainer/QTargetWithReg Std                   8.60041
trainer/QTargetWithReg Max                  35.5571
trainer/QTargetWithReg Min                  -0.907561
trainer/PolicyLossWithoutReg Mean           24.4016
trainer/PolicyLossWithoutReg Std             7.78673
trainer/PolicyLossWithoutReg Max            35.4612
trainer/PolicyLossWithoutReg Min            -2.52532
trainer/gradient_norm                       42.8699
trainer/gradient_penalty                    -0.214349
trainer/gradient_percentage                 -0.00878424
exploration/num steps total               8000
exploration/num paths total                371
exploration/path length this epoch Mean    197.4
exploration/path length this epoch Std      87.7487
exploration/path length this epoch Max     357
exploration/path length this epoch Min     117
exploration/Rewards Mean                     0.818355
exploration/Rewards Std                      0.911005
exploration/Rewards Max                      3.39287
exploration/Rewards Min                     -1.72678
exploration/Returns Mean                   161.543
exploration/Returns Std                    163.365
exploration/Returns Max                    455.565
exploration/Returns Min                     22.5327
exploration/Num Paths                        5
exploration/Average Returns                161.543
evaluation_0/num steps total             23641
evaluation_0/num paths total               101
evaluation_0/path length Mean              234.324
evaluation_0/path length Std                45.1238
evaluation_0/path length Max               355
evaluation_0/path length Min               191
evaluation_0/Rewards Mean                    1.35552
evaluation_0/Rewards Std                     0.852884
evaluation_0/Rewards Max                     3.31915
evaluation_0/Rewards Min                    -0.907962
evaluation_0/Returns Mean                  317.631
evaluation_0/Returns Std                   130.706
evaluation_0/Returns Max                   501.096
evaluation_0/Returns Min                    86.5945
evaluation_0/Num Paths                      34
evaluation_0/Average Returns               317.631
time/epoch (s)                               0
time/total (s)                              57.2887
Epoch                                        3
---------------------------------------  --------------
2022-11-16 10:47:00.836987 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 4 finished
---------------------------------------  -------------
epoch                                        4
total_step                                9000
replay_pool/size                          9000
trainer/alpha                                0.428471
trainer/alpha_loss                          -6.24812
trainer/entropy                              1.37453
trainer/qf_loss                              1.92712
trainer/state_noise                          0.005
trainer/policy_loss                        -33.6168
trainer/policy_loss_without_entropy         33.2809
trainer/entropy_penalty                      0.588945
trainer/entropy_percentage                   0.0176962
trainer/Q1Pred Mean                         30.4387
trainer/Q1Pred Std                          11.8871
trainer/Q1Pred Max                          47.7706
trainer/Q1Pred Min                          -1.83145
trainer/Q2Pred Mean                         30.1717
trainer/Q2Pred Std                          11.8923
trainer/Q2Pred Max                          48.0672
trainer/Q2Pred Min                          -2.82003
trainer/QTargetWithReg Mean                 30.2755
trainer/QTargetWithReg Std                  12.0134
trainer/QTargetWithReg Max                  46.423
trainer/QTargetWithReg Min                  -1.02648
trainer/PolicyLossWithoutReg Mean           33.2809
trainer/PolicyLossWithoutReg Std            11.2361
trainer/PolicyLossWithoutReg Max            46.6311
trainer/PolicyLossWithoutReg Min            -1.04754
trainer/gradient_norm                       50.6103
trainer/gradient_penalty                    -0.253052
trainer/gradient_percentage                 -0.0076035
exploration/num steps total               9000
exploration/num paths total                375
exploration/path length this epoch Mean    174.75
exploration/path length this epoch Std      51.5625
exploration/path length this epoch Max     243
exploration/path length this epoch Min     106
exploration/Rewards Mean                     0.705438
exploration/Rewards Std                      1.03722
exploration/Rewards Max                      3.50121
exploration/Rewards Min                     -2.001
exploration/Returns Mean                   123.275
exploration/Returns Std                    129.441
exploration/Returns Max                    336.023
exploration/Returns Min                    -13.6751
exploration/Num Paths                        4
exploration/Average Returns                123.275
evaluation_0/num steps total             31514
evaluation_0/num paths total               116
evaluation_0/path length Mean              524.867
evaluation_0/path length Std               293.237
evaluation_0/path length Max              1000
evaluation_0/path length Min               248
evaluation_0/Rewards Mean                    1.10019
evaluation_0/Rewards Std                     0.674984
evaluation_0/Rewards Max                     3.55691
evaluation_0/Rewards Min                    -1.39081
evaluation_0/Returns Mean                  577.451
evaluation_0/Returns Std                   152.564
evaluation_0/Returns Max                   878.654
evaluation_0/Returns Min                   402.388
evaluation_0/Num Paths                      15
evaluation_0/Average Returns               577.451
time/epoch (s)                               0
time/total (s)                              74.8269
Epoch                                        4
---------------------------------------  -------------
2022-11-16 10:47:18.185957 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 5 finished
---------------------------------------  --------------
epoch                                        5
total_step                               10000
replay_pool/size                         10000
trainer/alpha                                0.324476
trainer/alpha_loss                          -8.46405
trainer/entropy                              1.52186
trainer/qf_loss                              2.71731
trainer/state_noise                          0.005
trainer/policy_loss                        -38.9679
trainer/policy_loss_without_entropy         38.7578
trainer/entropy_penalty                      0.493809
trainer/entropy_percentage                   0.0127409
trainer/Q1Pred Mean                         35.5039
trainer/Q1Pred Std                          15.1844
trainer/Q1Pred Max                          59.0505
trainer/Q1Pred Min                          -2.67541
trainer/Q2Pred Mean                         35.5531
trainer/Q2Pred Std                          15.285
trainer/Q2Pred Max                          60.2446
trainer/Q2Pred Min                          -3.83953
trainer/QTargetWithReg Mean                 35.5002
trainer/QTargetWithReg Std                  15.3409
trainer/QTargetWithReg Max                  59.7115
trainer/QTargetWithReg Min                  -5.03162
trainer/PolicyLossWithoutReg Mean           38.7578
trainer/PolicyLossWithoutReg Std            13.0816
trainer/PolicyLossWithoutReg Max            58.2704
trainer/PolicyLossWithoutReg Min            -2.90654
trainer/gradient_norm                       56.7349
trainer/gradient_penalty                    -0.283674
trainer/gradient_percentage                 -0.00731915
exploration/num steps total              10000
exploration/num paths total                380
exploration/path length this epoch Mean    150.6
exploration/path length this epoch Std      48.9269
exploration/path length this epoch Max     211
exploration/path length this epoch Min      76
exploration/Rewards Mean                     0.409958
exploration/Rewards Std                      0.981206
exploration/Rewards Max                      2.8865
exploration/Rewards Min                     -2.46501
exploration/Returns Mean                    61.7397
exploration/Returns Std                     92.9298
exploration/Returns Max                    238.452
exploration/Returns Min                    -13.4969
exploration/Num Paths                        5
exploration/Average Returns                 61.7397
evaluation_0/num steps total             39450
evaluation_0/num paths total               153
evaluation_0/path length Mean              214.486
evaluation_0/path length Std                82.9401
evaluation_0/path length Max               484
evaluation_0/path length Min               104
evaluation_0/Rewards Mean                    0.64608
evaluation_0/Rewards Std                     0.940908
evaluation_0/Rewards Max                     4.13075
evaluation_0/Rewards Min                    -1.87974
evaluation_0/Returns Mean                  138.575
evaluation_0/Returns Std                   152.696
evaluation_0/Returns Max                   567.975
evaluation_0/Returns Min                    11.1676
evaluation_0/Num Paths                      37
evaluation_0/Average Returns               138.575
time/epoch (s)                               0
time/total (s)                              92.1763
Epoch                                        5
---------------------------------------  --------------
2022-11-16 10:47:34.607780 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 6 finished
---------------------------------------  --------------
epoch                                        6
total_step                               11000
replay_pool/size                         11000
trainer/alpha                                0.243784
trainer/alpha_loss                          -8.92221
trainer/entropy                              0.322452
trainer/qf_loss                              2.58441
trainer/state_noise                          0.005
trainer/policy_loss                        -42.9599
trainer/policy_loss_without_entropy         43.246
trainer/entropy_penalty                      0.0786087
trainer/entropy_percentage                   0.00181771
trainer/Q1Pred Mean                         40.0164
trainer/Q1Pred Std                          16.5695
trainer/Q1Pred Max                          65.261
trainer/Q1Pred Min                          -6.9504
trainer/Q2Pred Mean                         39.8966
trainer/Q2Pred Std                          16.603
trainer/Q2Pred Max                          65.167
trainer/Q2Pred Min                          -8.09234
trainer/QTargetWithReg Mean                 39.8514
trainer/QTargetWithReg Std                  16.7002
trainer/QTargetWithReg Max                  64.9346
trainer/QTargetWithReg Min                  -7.14269
trainer/PolicyLossWithoutReg Mean           43.246
trainer/PolicyLossWithoutReg Std            13.8133
trainer/PolicyLossWithoutReg Max            65.8851
trainer/PolicyLossWithoutReg Min            -5.63881
trainer/gradient_norm                       72.9447
trainer/gradient_penalty                    -0.364723
trainer/gradient_percentage                 -0.00843369
exploration/num steps total              11000
exploration/num paths total                384
exploration/path length this epoch Mean    194
exploration/path length this epoch Std      41.2735
exploration/path length this epoch Max     264
exploration/path length this epoch Min     157
exploration/Rewards Mean                     0.545725
exploration/Rewards Std                      1.08617
exploration/Rewards Max                      4.93711
exploration/Rewards Min                     -2.45452
exploration/Returns Mean                   105.871
exploration/Returns Std                     87.4183
exploration/Returns Max                    221.225
exploration/Returns Min                    -16.3075
exploration/Num Paths                        4
exploration/Average Returns                105.871
evaluation_0/num steps total             47428
evaluation_0/num paths total               236
evaluation_0/path length Mean               96.1205
evaluation_0/path length Std                25.9867
evaluation_0/path length Max               163
evaluation_0/path length Min                47
evaluation_0/Rewards Mean                    0.168143
evaluation_0/Rewards Std                     1.03927
evaluation_0/Rewards Max                     3.62105
evaluation_0/Rewards Min                    -2.50971
evaluation_0/Returns Mean                   16.162
evaluation_0/Returns Std                    12.1216
evaluation_0/Returns Max                    40.6824
evaluation_0/Returns Min                   -43.1136
evaluation_0/Num Paths                      83
evaluation_0/Average Returns                16.162
time/epoch (s)                               0
time/total (s)                             108.598
Epoch                                        6
---------------------------------------  --------------
2022-11-16 10:47:50.932107 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 7 finished
---------------------------------------  ---------------
epoch                                        7
total_step                               12000
replay_pool/size                         12000
trainer/alpha                                0.184855
trainer/alpha_loss                          -9.97563
trainer/entropy                             -0.0899738
trainer/qf_loss                              4.80773
trainer/state_noise                          0.005
trainer/policy_loss                        -45.6585
trainer/policy_loss_without_entropy         46.1138
trainer/entropy_penalty                     -0.0166321
trainer/entropy_percentage                  -0.000360674
trainer/Q1Pred Mean                         42.3025
trainer/Q1Pred Std                          19.6068
trainer/Q1Pred Max                          78.4504
trainer/Q1Pred Min                         -12.9911
trainer/Q2Pred Mean                         42.5315
trainer/Q2Pred Std                          19.7771
trainer/Q2Pred Max                          78.2442
trainer/Q2Pred Min                         -13.3251
trainer/QTargetWithReg Mean                 42.8736
trainer/QTargetWithReg Std                  19.7359
trainer/QTargetWithReg Max                  79.5054
trainer/QTargetWithReg Min                 -12.9555
trainer/PolicyLossWithoutReg Mean           46.1138
trainer/PolicyLossWithoutReg Std            17.3501
trainer/PolicyLossWithoutReg Max            77.2346
trainer/PolicyLossWithoutReg Min           -13.5193
trainer/gradient_norm                       87.724
trainer/gradient_penalty                    -0.43862
trainer/gradient_percentage                 -0.00951168
exploration/num steps total              12000
exploration/num paths total                396
exploration/path length this epoch Mean     81.3333
exploration/path length this epoch Std      37.1939
exploration/path length this epoch Max     165
exploration/path length this epoch Min      34
exploration/Rewards Mean                     0.718932
exploration/Rewards Std                      1.04583
exploration/Rewards Max                      4.45237
exploration/Rewards Min                     -1.93287
exploration/Returns Mean                    58.4731
exploration/Returns Std                     67.6341
exploration/Returns Max                    178.019
exploration/Returns Min                     -3.53557
exploration/Num Paths                       12
exploration/Average Returns                 58.4731
evaluation_0/num steps total             55414
evaluation_0/num paths total               352
evaluation_0/path length Mean               68.8448
evaluation_0/path length Std                19.4744
evaluation_0/path length Max               103
evaluation_0/path length Min                39
evaluation_0/Rewards Mean                   -0.0592808
evaluation_0/Rewards Std                     0.777538
evaluation_0/Rewards Max                     3.07238
evaluation_0/Rewards Min                    -2.45671
evaluation_0/Returns Mean                   -4.08117
evaluation_0/Returns Std                     5.30933
evaluation_0/Returns Max                     7.02966
evaluation_0/Returns Min                   -30.0599
evaluation_0/Num Paths                     116
evaluation_0/Average Returns                -4.08117
time/epoch (s)                               0
time/total (s)                             124.923
Epoch                                        7
---------------------------------------  ---------------
2022-11-16 10:48:07.732114 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 8 finished
---------------------------------------  --------------
epoch                                        8
total_step                               13000
replay_pool/size                         13000
trainer/alpha                                0.143042
trainer/alpha_loss                          -9.06549
trainer/entropy                             -1.33757
trainer/qf_loss                              5.35047
trainer/state_noise                          0.005
trainer/policy_loss                        -51.7042
trainer/policy_loss_without_entropy         52.3757
trainer/entropy_penalty                     -0.191329
trainer/entropy_percentage                  -0.003653
trainer/Q1Pred Mean                         48.7053
trainer/Q1Pred Std                          19.7857
trainer/Q1Pred Max                          89.4875
trainer/Q1Pred Min                         -18.9511
trainer/Q2Pred Mean                         48.6959
trainer/Q2Pred Std                          19.817
trainer/Q2Pred Max                          87.2203
trainer/Q2Pred Min                         -18.7177
trainer/QTargetWithReg Mean                 48.5402
trainer/QTargetWithReg Std                  19.871
trainer/QTargetWithReg Max                  88.6236
trainer/QTargetWithReg Min                 -22.9097
trainer/PolicyLossWithoutReg Mean           52.3757
trainer/PolicyLossWithoutReg Std            16.783
trainer/PolicyLossWithoutReg Max            89.1958
trainer/PolicyLossWithoutReg Min           -19.5897
trainer/gradient_norm                       96.0481
trainer/gradient_penalty                    -0.48024
trainer/gradient_percentage                 -0.00916914
exploration/num steps total              13000
exploration/num paths total                408
exploration/path length this epoch Mean     74.1667
exploration/path length this epoch Std      34.8158
exploration/path length this epoch Max     136
exploration/path length this epoch Min      23
exploration/Rewards Mean                     0.260298
exploration/Rewards Std                      1.00142
exploration/Rewards Max                      3.15896
exploration/Rewards Min                     -2.48551
exploration/Returns Mean                    19.3054
exploration/Returns Std                     43.8482
exploration/Returns Max                    154.229
exploration/Returns Min                    -33.6711
exploration/Num Paths                       12
exploration/Average Returns                 19.3054
evaluation_0/num steps total             63346
evaluation_0/num paths total               435
evaluation_0/path length Mean               95.5663
evaluation_0/path length Std                14.7585
evaluation_0/path length Max               187
evaluation_0/path length Min                82
evaluation_0/Rewards Mean                    1.38153
evaluation_0/Rewards Std                     1.02303
evaluation_0/Rewards Max                     4.64163
evaluation_0/Rewards Min                    -0.739076
evaluation_0/Returns Mean                  132.028
evaluation_0/Returns Std                    26.3992
evaluation_0/Returns Max                   283.62
evaluation_0/Returns Min                   100.437
evaluation_0/Num Paths                      83
evaluation_0/Average Returns               132.028
time/epoch (s)                               0
time/total (s)                             141.722
Epoch                                        8
---------------------------------------  --------------
2022-11-16 10:48:23.617411 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 9 finished
---------------------------------------  --------------
epoch                                        9
total_step                               14000
replay_pool/size                         14000
trainer/alpha                                0.112681
trainer/alpha_loss                          -7.40691
trainer/entropy                             -2.60694
trainer/qf_loss                              8.55619
trainer/state_noise                          0.005
trainer/policy_loss                        -52.5546
trainer/policy_loss_without_entropy         53.3815
trainer/entropy_penalty                     -0.293753
trainer/entropy_percentage                  -0.0055029
trainer/Q1Pred Mean                         51.1229
trainer/Q1Pred Std                          19.245
trainer/Q1Pred Max                          78.724
trainer/Q1Pred Min                         -16.694
trainer/Q2Pred Mean                         51.1527
trainer/Q2Pred Std                          19.2824
trainer/Q2Pred Max                          77.5623
trainer/Q2Pred Min                         -18.7721
trainer/QTargetWithReg Mean                 50.8826
trainer/QTargetWithReg Std                  19.2903
trainer/QTargetWithReg Max                  77.0071
trainer/QTargetWithReg Min                 -15.5122
trainer/PolicyLossWithoutReg Mean           53.3815
trainer/PolicyLossWithoutReg Std            17.3284
trainer/PolicyLossWithoutReg Max            76.9307
trainer/PolicyLossWithoutReg Min           -18.5922
trainer/gradient_norm                      106.624
trainer/gradient_penalty                    -0.53312
trainer/gradient_percentage                 -0.00998699
exploration/num steps total              14000
exploration/num paths total                416
exploration/path length this epoch Mean    113.25
exploration/path length this epoch Std      46.1648
exploration/path length this epoch Max     207
exploration/path length this epoch Min      43
exploration/Rewards Mean                     1.44775
exploration/Rewards Std                      0.976104
exploration/Rewards Max                      4.4591
exploration/Rewards Min                     -0.926969
exploration/Returns Mean                   163.957
exploration/Returns Std                     72.5972
exploration/Returns Max                    243.033
exploration/Returns Min                      5.65352
exploration/Num Paths                        8
exploration/Average Returns                163.957
evaluation_0/num steps total             71311
evaluation_0/num paths total               530
evaluation_0/path length Mean               83.8421
evaluation_0/path length Std                 5.1038
evaluation_0/path length Max                91
evaluation_0/path length Min                74
evaluation_0/Rewards Mean                    1.83883
evaluation_0/Rewards Std                     1.04451
evaluation_0/Rewards Max                     4.48645
evaluation_0/Rewards Min                     0.110872
evaluation_0/Returns Mean                  154.171
evaluation_0/Returns Std                    18.056
evaluation_0/Returns Max                   176.911
evaluation_0/Returns Min                   121.217
evaluation_0/Num Paths                      95
evaluation_0/Average Returns               154.171
time/epoch (s)                               0
time/total (s)                             157.608
Epoch                                        9
---------------------------------------  --------------
2022-11-16 10:48:40.155299 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 10 finished
---------------------------------------  --------------
epoch                                       10
total_step                               15000
replay_pool/size                         15000
trainer/alpha                                0.0902608
trainer/alpha_loss                          -6.62593
trainer/entropy                             -3.24475
trainer/qf_loss                              6.24094
trainer/state_noise                          0.005
trainer/policy_loss                        -55.6157
trainer/policy_loss_without_entropy         56.4246
trainer/entropy_penalty                     -0.292873
trainer/entropy_percentage                  -0.00519052
trainer/Q1Pred Mean                         53.7691
trainer/Q1Pred Std                          21.9087
trainer/Q1Pred Max                          94.5911
trainer/Q1Pred Min                         -14.0956
trainer/Q2Pred Mean                         53.5323
trainer/Q2Pred Std                          22.047
trainer/Q2Pred Max                          95.3389
trainer/Q2Pred Min                         -16.6256
trainer/QTargetWithReg Mean                 53.6176
trainer/QTargetWithReg Std                  22.3339
trainer/QTargetWithReg Max                  93.8711
trainer/QTargetWithReg Min                 -13.6758
trainer/PolicyLossWithoutReg Mean           56.4246
trainer/PolicyLossWithoutReg Std            20.7171
trainer/PolicyLossWithoutReg Max            94.2873
trainer/PolicyLossWithoutReg Min           -16.6312
trainer/gradient_norm                      103.209
trainer/gradient_penalty                    -0.516044
trainer/gradient_percentage                 -0.00914572
exploration/num steps total              15000
exploration/num paths total                424
exploration/path length this epoch Mean    119.75
exploration/path length this epoch Std      41.3635
exploration/path length this epoch Max     204
exploration/path length this epoch Min      76
exploration/Rewards Mean                     1.42875
exploration/Rewards Std                      1.15509
exploration/Rewards Max                      5.6251
exploration/Rewards Min                     -2.38329
exploration/Returns Mean                   171.092
exploration/Returns Std                     40.8498
exploration/Returns Max                    242.016
exploration/Returns Min                    120.681
exploration/Num Paths                        8
exploration/Average Returns                171.092
evaluation_0/num steps total             79275
evaluation_0/num paths total               598
evaluation_0/path length Mean              117.118
evaluation_0/path length Std                 2.27861
evaluation_0/path length Max               125
evaluation_0/path length Min               112
evaluation_0/Rewards Mean                    1.74932
evaluation_0/Rewards Std                     1.12688
evaluation_0/Rewards Max                     4.95256
evaluation_0/Rewards Min                     0.0628967
evaluation_0/Returns Mean                  204.877
evaluation_0/Returns Std                     6.43349
evaluation_0/Returns Max                   217.51
evaluation_0/Returns Min                   186.433
evaluation_0/Num Paths                      68
evaluation_0/Average Returns               204.877
time/epoch (s)                               0
time/total (s)                             174.144
Epoch                                       10
---------------------------------------  --------------
2022-11-16 10:48:56.319331 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 11 finished
---------------------------------------  --------------
epoch                                       11
total_step                               16000
replay_pool/size                         16000
trainer/alpha                                0.0740501
trainer/alpha_loss                          -6.12266
trainer/entropy                             -3.64766
trainer/qf_loss                              6.06521
trainer/state_noise                          0.005
trainer/policy_loss                        -59.3028
trainer/policy_loss_without_entropy         60.0962
trainer/entropy_penalty                     -0.27011
trainer/entropy_percentage                  -0.00449462
trainer/Q1Pred Mean                         57.2336
trainer/Q1Pred Std                          20.6404
trainer/Q1Pred Max                         100.962
trainer/Q1Pred Min                          -9.45173
trainer/Q2Pred Mean                         57.3669
trainer/Q2Pred Std                          20.7644
trainer/Q2Pred Max                         101.857
trainer/Q2Pred Min                         -14.0831
trainer/QTargetWithReg Mean                 57.3079
trainer/QTargetWithReg Std                  20.9118
trainer/QTargetWithReg Max                 104.352
trainer/QTargetWithReg Min                 -13.8254
trainer/PolicyLossWithoutReg Mean           60.0962
trainer/PolicyLossWithoutReg Std            18.6522
trainer/PolicyLossWithoutReg Max           101.32
trainer/PolicyLossWithoutReg Min           -11.0488
trainer/gradient_norm                      104.666
trainer/gradient_penalty                    -0.523332
trainer/gradient_percentage                 -0.00870824
exploration/num steps total              16000
exploration/num paths total                434
exploration/path length this epoch Mean     87.9
exploration/path length this epoch Std       9.07138
exploration/path length this epoch Max     107
exploration/path length this epoch Min      77
exploration/Rewards Mean                     1.77823
exploration/Rewards Std                      1.14832
exploration/Rewards Max                      5.55692
exploration/Rewards Min                     -0.316071
exploration/Returns Mean                   156.307
exploration/Returns Std                     24.8662
exploration/Returns Max                    200.688
exploration/Returns Min                    111.434
exploration/Num Paths                       10
exploration/Average Returns                156.307
evaluation_0/num steps total             87238
evaluation_0/num paths total               686
evaluation_0/path length Mean               90.4886
evaluation_0/path length Std                 6.39246
evaluation_0/path length Max               110
evaluation_0/path length Min                79
evaluation_0/Rewards Mean                    1.79386
evaluation_0/Rewards Std                     1.17449
evaluation_0/Rewards Max                     5.64881
evaluation_0/Rewards Min                    -0.704138
evaluation_0/Returns Mean                  162.324
evaluation_0/Returns Std                    18.2833
evaluation_0/Returns Max                   192.131
evaluation_0/Returns Min                   128.975
evaluation_0/Num Paths                      88
evaluation_0/Average Returns               162.324
time/epoch (s)                               0
time/total (s)                             190.31
Epoch                                       11
---------------------------------------  --------------
2022-11-16 10:49:12.934372 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 12 finished
---------------------------------------  --------------
epoch                                       12
total_step                               17000
replay_pool/size                         17000
trainer/alpha                                0.061743
trainer/alpha_loss                          -2.70981
trainer/entropy                             -5.02686
trainer/qf_loss                              5.384
trainer/state_noise                          0.005
trainer/policy_loss                        -60.7816
trainer/policy_loss_without_entropy         61.6105
trainer/entropy_penalty                     -0.310373
trainer/entropy_percentage                  -0.00503766
trainer/Q1Pred Mean                         58.4011
trainer/Q1Pred Std                          25.3048
trainer/Q1Pred Max                         117.999
trainer/Q1Pred Min                          -7.42845
trainer/Q2Pred Mean                         58.4601
trainer/Q2Pred Std                          25.3141
trainer/Q2Pred Max                         117.937
trainer/Q2Pred Min                         -10.8501
trainer/QTargetWithReg Mean                 58.4772
trainer/QTargetWithReg Std                  25.4834
trainer/QTargetWithReg Max                 117.994
trainer/QTargetWithReg Min                  -9.08651
trainer/PolicyLossWithoutReg Mean           61.6105
trainer/PolicyLossWithoutReg Std            22.6613
trainer/PolicyLossWithoutReg Max           117.995
trainer/PolicyLossWithoutReg Min            -7.17335
trainer/gradient_norm                      103.708
trainer/gradient_penalty                    -0.51854
trainer/gradient_percentage                 -0.00841642
exploration/num steps total              17000
exploration/num paths total                443
exploration/path length this epoch Mean     98.7778
exploration/path length this epoch Std      36.3464
exploration/path length this epoch Max     184
exploration/path length this epoch Min      60
exploration/Rewards Mean                     1.60917
exploration/Rewards Std                      1.37261
exploration/Rewards Max                      6.69519
exploration/Rewards Min                     -2.09137
exploration/Returns Mean                   158.95
exploration/Returns Std                     57.2135
exploration/Returns Max                    243.535
exploration/Returns Min                     72.6229
exploration/Num Paths                        9
exploration/Average Returns                158.95
evaluation_0/num steps total             95092
evaluation_0/num paths total               741
evaluation_0/path length Mean              142.8
evaluation_0/path length Std                13.9589
evaluation_0/path length Max               171
evaluation_0/path length Min               109
evaluation_0/Rewards Mean                    1.89522
evaluation_0/Rewards Std                     1.56052
evaluation_0/Rewards Max                     9.23647
evaluation_0/Rewards Min                    -2.52036
evaluation_0/Returns Mean                  270.637
evaluation_0/Returns Std                    47.8942
evaluation_0/Returns Max                   359.816
evaluation_0/Returns Min                   134.007
evaluation_0/Num Paths                      55
evaluation_0/Average Returns               270.637
time/epoch (s)                               0
time/total (s)                             206.924
Epoch                                       12
---------------------------------------  --------------
2022-11-16 10:49:31.789419 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 13 finished
---------------------------------------  ---------------
epoch                                        13
total_step                                18000
replay_pool/size                          18000
trainer/alpha                                 0.0550351
trainer/alpha_loss                            0.0886063
trainer/entropy                              -6.03056
trainer/qf_loss                               6.24356
trainer/state_noise                           0.005
trainer/policy_loss                         -64.673
trainer/policy_loss_without_entropy          65.5403
trainer/entropy_penalty                      -0.331892
trainer/entropy_percentage                   -0.00506395
trainer/Q1Pred Mean                          62.9259
trainer/Q1Pred Std                           24.3153
trainer/Q1Pred Max                          119.9
trainer/Q1Pred Min                           -8.35283
trainer/Q2Pred Mean                          62.8371
trainer/Q2Pred Std                           24.412
trainer/Q2Pred Max                          122.074
trainer/Q2Pred Min                           -7.24198
trainer/QTargetWithReg Mean                  62.5898
trainer/QTargetWithReg Std                   24.5417
trainer/QTargetWithReg Max                  120.864
trainer/QTargetWithReg Min                   -8.37318
trainer/PolicyLossWithoutReg Mean            65.5403
trainer/PolicyLossWithoutReg Std             22.681
trainer/PolicyLossWithoutReg Max            120.832
trainer/PolicyLossWithoutReg Min             -5.65324
trainer/gradient_norm                       107.079
trainer/gradient_penalty                     -0.535395
trainer/gradient_percentage                  -0.00816894
exploration/num steps total               18000
exploration/num paths total                 452
exploration/path length this epoch Mean     109.778
exploration/path length this epoch Std       21.923
exploration/path length this epoch Max      141
exploration/path length this epoch Min       81
exploration/Rewards Mean                      1.90955
exploration/Rewards Std                       1.11202
exploration/Rewards Max                       5.70328
exploration/Rewards Min                      -0.403843
exploration/Returns Mean                    209.627
exploration/Returns Std                      44.0221
exploration/Returns Max                     278.633
exploration/Returns Min                     152.177
exploration/Num Paths                         9
exploration/Average Returns                 209.627
evaluation_0/num steps total             102777
evaluation_0/num paths total                785
evaluation_0/path length Mean               174.659
evaluation_0/path length Std                184.241
evaluation_0/path length Max               1000
evaluation_0/path length Min                119
evaluation_0/Rewards Mean                     0.770885
evaluation_0/Rewards Std                      1.23572
evaluation_0/Rewards Max                      4.78358
evaluation_0/Rewards Min                     -1.66793
evaluation_0/Returns Mean                   134.642
evaluation_0/Returns Std                    203.692
evaluation_0/Returns Max                   1066.66
evaluation_0/Returns Min                     59.4568
evaluation_0/Num Paths                       44
evaluation_0/Average Returns                134.642
time/epoch (s)                                0
time/total (s)                              225.777
Epoch                                        13
---------------------------------------  ---------------
2022-11-16 10:49:48.833480 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 14 finished
---------------------------------------  ---------------
epoch                                        14
total_step                                19000
replay_pool/size                          19000
trainer/alpha                                 0.0549959
trainer/alpha_loss                           -1.23715
trainer/entropy                              -5.57347
trainer/qf_loss                               6.13687
trainer/state_noise                           0.005
trainer/policy_loss                         -67.0961
trainer/policy_loss_without_entropy          67.9517
trainer/entropy_penalty                      -0.306518
trainer/entropy_percentage                   -0.00451082
trainer/Q1Pred Mean                          65.4458
trainer/Q1Pred Std                           24.9206
trainer/Q1Pred Max                          122.541
trainer/Q1Pred Min                          -15.1797
trainer/Q2Pred Mean                          65.2355
trainer/Q2Pred Std                           24.9384
trainer/Q2Pred Max                          125.165
trainer/Q2Pred Min                           -9.94699
trainer/QTargetWithReg Mean                  65.0562
trainer/QTargetWithReg Std                   24.9252
trainer/QTargetWithReg Max                  122.581
trainer/QTargetWithReg Min                  -11.6664
trainer/PolicyLossWithoutReg Mean            67.9517
trainer/PolicyLossWithoutReg Std             23.4909
trainer/PolicyLossWithoutReg Max            122.5
trainer/PolicyLossWithoutReg Min            -13.4778
trainer/gradient_norm                       109.829
trainer/gradient_penalty                     -0.549146
trainer/gradient_percentage                  -0.00808141
exploration/num steps total               19000
exploration/num paths total                 456
exploration/path length this epoch Mean     201.5
exploration/path length this epoch Std       99.8211
exploration/path length this epoch Max      359
exploration/path length this epoch Min       94
exploration/Rewards Mean                      1.36731
exploration/Rewards Std                       1.29753
exploration/Rewards Max                       5.10008
exploration/Rewards Min                      -0.98053
exploration/Returns Mean                    275.514
exploration/Returns Std                     118.875
exploration/Returns Max                     397.125
exploration/Returns Min                     120.774
exploration/Num Paths                         4
exploration/Average Returns                 275.514
evaluation_0/num steps total             110712
evaluation_0/num paths total                827
evaluation_0/path length Mean               188.929
evaluation_0/path length Std                 22.2736
evaluation_0/path length Max                252
evaluation_0/path length Min                147
evaluation_0/Rewards Mean                     1.44507
evaluation_0/Rewards Std                      1.23206
evaluation_0/Rewards Max                      6.11516
evaluation_0/Rewards Min                     -1.01706
evaluation_0/Returns Mean                   273.015
evaluation_0/Returns Std                     53.7371
evaluation_0/Returns Max                    413.294
evaluation_0/Returns Min                     98.6817
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                273.015
time/epoch (s)                                0
time/total (s)                              242.821
Epoch                                        14
---------------------------------------  ---------------
2022-11-16 10:50:05.340380 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 15 finished
---------------------------------------  ---------------
epoch                                        15
total_step                                20000
replay_pool/size                          20000
trainer/alpha                                 0.0578901
trainer/alpha_loss                            0.104768
trainer/entropy                              -6.03677
trainer/qf_loss                               9.5213
trainer/state_noise                           0.005
trainer/policy_loss                         -69.6651
trainer/policy_loss_without_entropy          70.5732
trainer/entropy_penalty                      -0.349469
trainer/entropy_percentage                   -0.00495187
trainer/Q1Pred Mean                          67.2542
trainer/Q1Pred Std                           26.8876
trainer/Q1Pred Max                          121.338
trainer/Q1Pred Min                          -10.801
trainer/Q2Pred Mean                          66.8321
trainer/Q2Pred Std                           27.1533
trainer/Q2Pred Max                          120.841
trainer/Q2Pred Min                           -9.9061
trainer/QTargetWithReg Mean                  67.1119
trainer/QTargetWithReg Std                   27.1748
trainer/QTargetWithReg Max                  121.788
trainer/QTargetWithReg Min                  -14.7747
trainer/PolicyLossWithoutReg Mean            70.5732
trainer/PolicyLossWithoutReg Std             24.6804
trainer/PolicyLossWithoutReg Max            120.253
trainer/PolicyLossWithoutReg Min             -9.1782
trainer/gradient_norm                       111.726
trainer/gradient_penalty                     -0.55863
trainer/gradient_percentage                  -0.00791561
exploration/num steps total               20000
exploration/num paths total                 462
exploration/path length this epoch Mean     162.5
exploration/path length this epoch Std       44.9101
exploration/path length this epoch Max      261
exploration/path length this epoch Min      127
exploration/Rewards Mean                      0.919383
exploration/Rewards Std                       1.39239
exploration/Rewards Max                       5.18972
exploration/Rewards Min                      -2.26586
exploration/Returns Mean                    149.4
exploration/Returns Std                      69.3038
exploration/Returns Max                     262.103
exploration/Returns Min                      72.9331
exploration/Num Paths                         6
exploration/Average Returns                 149.4
evaluation_0/num steps total             118518
evaluation_0/num paths total                855
evaluation_0/path length Mean               278.786
evaluation_0/path length Std                 73.4479
evaluation_0/path length Max                554
evaluation_0/path length Min                182
evaluation_0/Rewards Mean                     1.15405
evaluation_0/Rewards Std                      1.15094
evaluation_0/Rewards Max                      5.04362
evaluation_0/Rewards Min                     -1.29439
evaluation_0/Returns Mean                   321.733
evaluation_0/Returns Std                     69.3129
evaluation_0/Returns Max                    555.42
evaluation_0/Returns Min                    227.46
evaluation_0/Num Paths                       28
evaluation_0/Average Returns                321.733
time/epoch (s)                                0
time/total (s)                              259.327
Epoch                                        15
---------------------------------------  ---------------
2022-11-16 10:50:21.721903 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 16 finished
---------------------------------------  ---------------
epoch                                        16
total_step                                21000
replay_pool/size                          21000
trainer/alpha                                 0.0615523
trainer/alpha_loss                            0.807732
trainer/entropy                              -6.28972
trainer/qf_loss                               6.21557
trainer/state_noise                           0.005
trainer/policy_loss                         -72.2575
trainer/policy_loss_without_entropy          73.1729
trainer/entropy_penalty                      -0.387147
trainer/entropy_percentage                   -0.00529085
trainer/Q1Pred Mean                          69.799
trainer/Q1Pred Std                           28.2101
trainer/Q1Pred Max                          125.762
trainer/Q1Pred Min                          -16.255
trainer/Q2Pred Mean                          70.0465
trainer/Q2Pred Std                           28.1948
trainer/Q2Pred Max                          129.822
trainer/Q2Pred Min                          -14.3767
trainer/QTargetWithReg Mean                  70.4584
trainer/QTargetWithReg Std                   27.9328
trainer/QTargetWithReg Max                  129.961
trainer/QTargetWithReg Min                  -12.8364
trainer/PolicyLossWithoutReg Mean            73.1729
trainer/PolicyLossWithoutReg Std             26.1287
trainer/PolicyLossWithoutReg Max            125.798
trainer/PolicyLossWithoutReg Min            -13.1086
trainer/gradient_norm                       105.641
trainer/gradient_penalty                     -0.528203
trainer/gradient_percentage                  -0.00721857
exploration/num steps total               21000
exploration/num paths total                 466
exploration/path length this epoch Mean     228.25
exploration/path length this epoch Std      124.57
exploration/path length this epoch Max      442
exploration/path length this epoch Min      133
exploration/Rewards Mean                      1.19338
exploration/Rewards Std                       1.27915
exploration/Rewards Max                       6.20571
exploration/Rewards Min                      -1.77194
exploration/Returns Mean                    272.388
exploration/Returns Std                     128.447
exploration/Returns Max                     468.087
exploration/Returns Min                     117.116
exploration/Num Paths                         4
exploration/Average Returns                 272.388
evaluation_0/num steps total             126416
evaluation_0/num paths total                901
evaluation_0/path length Mean               171.696
evaluation_0/path length Std                 17.7836
evaluation_0/path length Max                200
evaluation_0/path length Min                138
evaluation_0/Rewards Mean                     1.96015
evaluation_0/Rewards Std                      1.18345
evaluation_0/Rewards Max                      5.41066
evaluation_0/Rewards Min                     -0.70836
evaluation_0/Returns Mean                   336.55
evaluation_0/Returns Std                     27.6316
evaluation_0/Returns Max                    376.095
evaluation_0/Returns Min                    280.404
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                336.55
time/epoch (s)                                0
time/total (s)                              275.709
Epoch                                        16
---------------------------------------  ---------------
2022-11-16 10:51:14.645391 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 17 finished
---------------------------------------  ---------------
epoch                                        17
total_step                                22000
replay_pool/size                          22000
trainer/alpha                                 0.0615799
trainer/alpha_loss                            0.604924
trainer/entropy                              -6.21701
trainer/qf_loss                               9.60965
trainer/state_noise                           0.005
trainer/policy_loss                         -76.8631
trainer/policy_loss_without_entropy          77.7954
trainer/entropy_penalty                      -0.382843
trainer/entropy_percentage                   -0.00492116
trainer/Q1Pred Mean                          74.5846
trainer/Q1Pred Std                           25.8247
trainer/Q1Pred Max                          128.013
trainer/Q1Pred Min                          -11.0269
trainer/Q2Pred Mean                          74.5353
trainer/Q2Pred Std                           25.9745
trainer/Q2Pred Max                          128.087
trainer/Q2Pred Min                           -9.21302
trainer/QTargetWithReg Mean                  74.4936
trainer/QTargetWithReg Std                   26.3266
trainer/QTargetWithReg Max                  127.48
trainer/QTargetWithReg Min                  -10.0056
trainer/PolicyLossWithoutReg Mean            77.7954
trainer/PolicyLossWithoutReg Std             23.9706
trainer/PolicyLossWithoutReg Max            127.783
trainer/PolicyLossWithoutReg Min             -5.49727
trainer/gradient_norm                       109.899
trainer/gradient_penalty                     -0.549496
trainer/gradient_percentage                  -0.00706335
exploration/num steps total               22000
exploration/num paths total                 473
exploration/path length this epoch Mean     138.143
exploration/path length this epoch Std       59.7768
exploration/path length this epoch Max      257
exploration/path length this epoch Min       75
exploration/Rewards Mean                      1.72142
exploration/Rewards Std                       1.226
exploration/Rewards Max                       5.3573
exploration/Rewards Min                      -0.703245
exploration/Returns Mean                    237.802
exploration/Returns Std                      75.4474
exploration/Returns Max                     352.57
exploration/Returns Min                     137.027
exploration/Num Paths                         7
exploration/Average Returns                 237.802
evaluation_0/num steps total             134388
evaluation_0/num paths total                999
evaluation_0/path length Mean                81.3469
evaluation_0/path length Std                  5.80131
evaluation_0/path length Max                 95
evaluation_0/path length Min                 73
evaluation_0/Rewards Mean                     1.90991
evaluation_0/Rewards Std                      1.42316
evaluation_0/Rewards Max                      5.27815
evaluation_0/Rewards Min                     -0.69566
evaluation_0/Returns Mean                   155.365
evaluation_0/Returns Std                     19.4629
evaluation_0/Returns Max                    192.084
evaluation_0/Returns Min                    121.801
evaluation_0/Num Paths                       98
evaluation_0/Average Returns                155.365
time/epoch (s)                                0
time/total (s)                              328.635
Epoch                                        17
---------------------------------------  ---------------
2022-11-16 10:52:19.774667 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 18 finished
---------------------------------------  ---------------
epoch                                        18
total_step                                23000
replay_pool/size                          23000
trainer/alpha                                 0.0631238
trainer/alpha_loss                            0.573633
trainer/entropy                              -6.20763
trainer/qf_loss                              10.4008
trainer/state_noise                           0.005
trainer/policy_loss                         -75.8253
trainer/policy_loss_without_entropy          76.7881
trainer/entropy_penalty                      -0.391849
trainer/entropy_percentage                   -0.005103
trainer/Q1Pred Mean                          73.486
trainer/Q1Pred Std                           30.8543
trainer/Q1Pred Max                          131.345
trainer/Q1Pred Min                          -16.054
trainer/Q2Pred Mean                          73.694
trainer/Q2Pred Std                           30.8166
trainer/Q2Pred Max                          130.866
trainer/Q2Pred Min                          -13.8515
trainer/QTargetWithReg Mean                  73.9237
trainer/QTargetWithReg Std                   31.5312
trainer/QTargetWithReg Max                  132.597
trainer/QTargetWithReg Min                  -15.2755
trainer/PolicyLossWithoutReg Mean            76.7881
trainer/PolicyLossWithoutReg Std             28.9408
trainer/PolicyLossWithoutReg Max            132.129
trainer/PolicyLossWithoutReg Min            -11.6786
trainer/gradient_norm                       114.186
trainer/gradient_penalty                     -0.570931
trainer/gradient_percentage                  -0.00743515
exploration/num steps total               23000
exploration/num paths total                 482
exploration/path length this epoch Mean     108.444
exploration/path length this epoch Std       23.4004
exploration/path length this epoch Max      149
exploration/path length this epoch Min       73
exploration/Rewards Mean                      2.14807
exploration/Rewards Std                       1.28574
exploration/Rewards Max                       5.43223
exploration/Rewards Min                      -0.599584
exploration/Returns Mean                    232.946
exploration/Returns Std                      58.0479
exploration/Returns Max                     341.6
exploration/Returns Min                     167.685
exploration/Num Paths                         9
exploration/Average Returns                 232.946
evaluation_0/num steps total             142326
evaluation_0/num paths total               1061
evaluation_0/path length Mean               128.032
evaluation_0/path length Std                 11.6508
evaluation_0/path length Max                153
evaluation_0/path length Min                 94
evaluation_0/Rewards Mean                     1.94852
evaluation_0/Rewards Std                      1.19742
evaluation_0/Rewards Max                      5.64295
evaluation_0/Rewards Min                     -0.392278
evaluation_0/Returns Mean                   249.474
evaluation_0/Returns Std                     30.2919
evaluation_0/Returns Max                    314.566
evaluation_0/Returns Min                    172.254
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                249.474
time/epoch (s)                                0
time/total (s)                              393.771
Epoch                                        18
---------------------------------------  ---------------
2022-11-16 10:53:17.563924 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 19 finished
---------------------------------------  ---------------
epoch                                        19
total_step                                24000
replay_pool/size                          24000
trainer/alpha                                 0.0634217
trainer/alpha_loss                           -0.170798
trainer/entropy                              -5.93807
trainer/qf_loss                               7.98044
trainer/state_noise                           0.005
trainer/policy_loss                         -78.8282
trainer/policy_loss_without_entropy          79.7535
trainer/entropy_penalty                      -0.376602
trainer/entropy_percentage                   -0.00472208
trainer/Q1Pred Mean                          76.1334
trainer/Q1Pred Std                           32.0706
trainer/Q1Pred Max                          134.262
trainer/Q1Pred Min                          -11.9183
trainer/Q2Pred Mean                          76.098
trainer/Q2Pred Std                           32.1719
trainer/Q2Pred Max                          133.595
trainer/Q2Pred Min                          -13.6285
trainer/QTargetWithReg Mean                  75.9783
trainer/QTargetWithReg Std                   32.1913
trainer/QTargetWithReg Max                  132.574
trainer/QTargetWithReg Min                  -12.7924
trainer/PolicyLossWithoutReg Mean            79.7535
trainer/PolicyLossWithoutReg Std             30.2746
trainer/PolicyLossWithoutReg Max            133.811
trainer/PolicyLossWithoutReg Min            -12.4937
trainer/gradient_norm                       109.725
trainer/gradient_penalty                     -0.548627
trainer/gradient_percentage                  -0.00687904
exploration/num steps total               24000
exploration/num paths total                 490
exploration/path length this epoch Mean     112.125
exploration/path length this epoch Std       27.9349
exploration/path length this epoch Max      168
exploration/path length this epoch Min       74
exploration/Rewards Mean                      2.02098
exploration/Rewards Std                       1.31956
exploration/Rewards Max                       7.24847
exploration/Rewards Min                      -0.515479
exploration/Returns Mean                    226.603
exploration/Returns Std                      43.5001
exploration/Returns Max                     298.993
exploration/Returns Min                     161.173
exploration/Num Paths                         8
exploration/Average Returns                 226.603
evaluation_0/num steps total             150291
evaluation_0/num paths total               1131
evaluation_0/path length Mean               113.786
evaluation_0/path length Std                 22.674
evaluation_0/path length Max                170
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     2.11646
evaluation_0/Rewards Std                      1.34471
evaluation_0/Rewards Max                      5.98165
evaluation_0/Rewards Min                     -0.456585
evaluation_0/Returns Mean                   240.823
evaluation_0/Returns Std                     60.4081
evaluation_0/Returns Max                    440.855
evaluation_0/Returns Min                    164.211
evaluation_0/Num Paths                       70
evaluation_0/Average Returns                240.823
time/epoch (s)                                0
time/total (s)                              451.55
Epoch                                        19
---------------------------------------  ---------------
2022-11-16 10:53:56.816609 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 20 finished
---------------------------------------  ---------------
epoch                                        20
total_step                                25000
replay_pool/size                          25000
trainer/alpha                                 0.0640055
trainer/alpha_loss                           -1.14401
trainer/entropy                              -5.58381
trainer/qf_loss                               7.05713
trainer/state_noise                           0.005
trainer/policy_loss                         -85.3951
trainer/policy_loss_without_entropy          86.3273
trainer/entropy_penalty                      -0.357394
trainer/entropy_percentage                   -0.00413999
trainer/Q1Pred Mean                          83.2571
trainer/Q1Pred Std                           27.5615
trainer/Q1Pred Max                          134.426
trainer/Q1Pred Min                          -11.1635
trainer/Q2Pred Mean                          82.8886
trainer/Q2Pred Std                           27.6318
trainer/Q2Pred Max                          135.165
trainer/Q2Pred Min                          -11.015
trainer/QTargetWithReg Mean                  83.1527
trainer/QTargetWithReg Std                   27.641
trainer/QTargetWithReg Max                  133.97
trainer/QTargetWithReg Min                  -10.3183
trainer/PolicyLossWithoutReg Mean            86.3273
trainer/PolicyLossWithoutReg Std             24.746
trainer/PolicyLossWithoutReg Max            135.479
trainer/PolicyLossWithoutReg Min            -12.0713
trainer/gradient_norm                       114.966
trainer/gradient_penalty                     -0.574829
trainer/gradient_percentage                  -0.00665872
exploration/num steps total               25000
exploration/num paths total                 498
exploration/path length this epoch Mean     118.5
exploration/path length this epoch Std       19.2808
exploration/path length this epoch Max      143
exploration/path length this epoch Min       83
exploration/Rewards Mean                      2.02125
exploration/Rewards Std                       1.0938
exploration/Rewards Max                       4.68627
exploration/Rewards Min                      -0.614707
exploration/Returns Mean                    239.519
exploration/Returns Std                      46.9454
exploration/Returns Max                     305.643
exploration/Returns Min                     176.864
exploration/Num Paths                         8
exploration/Average Returns                 239.519
evaluation_0/num steps total             158251
evaluation_0/num paths total               1198
evaluation_0/path length Mean               118.806
evaluation_0/path length Std                  4.75124
evaluation_0/path length Max                132
evaluation_0/path length Min                112
evaluation_0/Rewards Mean                     1.95263
evaluation_0/Rewards Std                      1.06213
evaluation_0/Rewards Max                      5.16712
evaluation_0/Rewards Min                     -0.207182
evaluation_0/Returns Mean                   231.984
evaluation_0/Returns Std                     17.2113
evaluation_0/Returns Max                    279.694
evaluation_0/Returns Min                    209.648
evaluation_0/Num Paths                       67
evaluation_0/Average Returns                231.984
time/epoch (s)                                0
time/total (s)                              490.802
Epoch                                        20
---------------------------------------  ---------------
2022-11-16 10:54:32.268641 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 21 finished
---------------------------------------  ---------------
epoch                                        21
total_step                                26000
replay_pool/size                          26000
trainer/alpha                                 0.0628602
trainer/alpha_loss                            0.221802
trainer/entropy                              -6.08016
trainer/qf_loss                               9.31717
trainer/state_noise                           0.005
trainer/policy_loss                         -83.8719
trainer/policy_loss_without_entropy          84.8327
trainer/entropy_penalty                      -0.3822
trainer/entropy_percentage                   -0.00450534
trainer/Q1Pred Mean                          81.2374
trainer/Q1Pred Std                           30.4336
trainer/Q1Pred Max                          130.924
trainer/Q1Pred Min                          -12.3624
trainer/Q2Pred Mean                          81.1488
trainer/Q2Pred Std                           30.6042
trainer/Q2Pred Max                          130.313
trainer/Q2Pred Min                          -14.8699
trainer/QTargetWithReg Mean                  81.5077
trainer/QTargetWithReg Std                   30.7031
trainer/QTargetWithReg Max                  129.66
trainer/QTargetWithReg Min                  -18.9226
trainer/PolicyLossWithoutReg Mean            84.8327
trainer/PolicyLossWithoutReg Std             27.8719
trainer/PolicyLossWithoutReg Max            131.187
trainer/PolicyLossWithoutReg Min            -12.0799
trainer/gradient_norm                       115.7
trainer/gradient_penalty                     -0.5785
trainer/gradient_percentage                  -0.00681931
exploration/num steps total               26000
exploration/num paths total                 506
exploration/path length this epoch Mean     121.75
exploration/path length this epoch Std       38.3951
exploration/path length this epoch Max      214
exploration/path length this epoch Min       89
exploration/Rewards Mean                      1.82624
exploration/Rewards Std                       1.04939
exploration/Rewards Max                       5.21269
exploration/Rewards Min                      -0.741578
exploration/Returns Mean                    222.344
exploration/Returns Std                      58.6457
exploration/Returns Max                     357.932
exploration/Returns Min                     159.958
exploration/Num Paths                         8
exploration/Average Returns                 222.344
evaluation_0/num steps total             166098
evaluation_0/num paths total               1249
evaluation_0/path length Mean               153.863
evaluation_0/path length Std                 61.2219
evaluation_0/path length Max                341
evaluation_0/path length Min                 92
evaluation_0/Rewards Mean                     1.5824
evaluation_0/Rewards Std                      1.05252
evaluation_0/Rewards Max                      5.32558
evaluation_0/Rewards Min                     -1.7439
evaluation_0/Returns Mean                   243.472
evaluation_0/Returns Std                     87.305
evaluation_0/Returns Max                    486.68
evaluation_0/Returns Min                    145.689
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                243.472
time/epoch (s)                                0
time/total (s)                              526.253
Epoch                                        21
---------------------------------------  ---------------
2022-11-16 10:55:41.182167 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 22 finished
---------------------------------------  ---------------
epoch                                        22
total_step                                27000
replay_pool/size                          27000
trainer/alpha                                 0.0640367
trainer/alpha_loss                            1.31621
trainer/entropy                              -6.47886
trainer/qf_loss                               8.79975
trainer/state_noise                           0.005
trainer/policy_loss                         -81.6228
trainer/policy_loss_without_entropy          82.6198
trainer/entropy_penalty                      -0.414885
trainer/entropy_percentage                   -0.00502162
trainer/Q1Pred Mean                          79.7058
trainer/Q1Pred Std                           32.7282
trainer/Q1Pred Max                          133.402
trainer/Q1Pred Min                          -10.5718
trainer/Q2Pred Mean                          79.8912
trainer/Q2Pred Std                           32.6996
trainer/Q2Pred Max                          132.474
trainer/Q2Pred Min                           -8.51537
trainer/QTargetWithReg Mean                  79.5476
trainer/QTargetWithReg Std                   32.6045
trainer/QTargetWithReg Max                  134.256
trainer/QTargetWithReg Min                   -7.67315
trainer/PolicyLossWithoutReg Mean            82.6198
trainer/PolicyLossWithoutReg Std             30.4132
trainer/PolicyLossWithoutReg Max            132.497
trainer/PolicyLossWithoutReg Min             -5.18893
trainer/gradient_norm                       116.429
trainer/gradient_penalty                     -0.582144
trainer/gradient_percentage                  -0.00704605
exploration/num steps total               27000
exploration/num paths total                 514
exploration/path length this epoch Mean     123.125
exploration/path length this epoch Std       16.729
exploration/path length this epoch Max      162
exploration/path length this epoch Min      102
exploration/Rewards Mean                      1.84698
exploration/Rewards Std                       1.1634
exploration/Rewards Max                       5.243
exploration/Rewards Min                      -0.245291
exploration/Returns Mean                    227.409
exploration/Returns Std                      41.2264
exploration/Returns Max                     292.365
exploration/Returns Min                     156.671
exploration/Num Paths                         8
exploration/Average Returns                 227.409
evaluation_0/num steps total             174010
evaluation_0/num paths total               1315
evaluation_0/path length Mean               119.879
evaluation_0/path length Std                 18.3737
evaluation_0/path length Max                178
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     2.09286
evaluation_0/Rewards Std                      1.21032
evaluation_0/Rewards Max                      5.35216
evaluation_0/Rewards Min                     -0.479568
evaluation_0/Returns Mean                   250.889
evaluation_0/Returns Std                     46.5773
evaluation_0/Returns Max                    406.172
evaluation_0/Returns Min                    194.709
evaluation_0/Num Paths                       66
evaluation_0/Average Returns                250.889
time/epoch (s)                                0
time/total (s)                              595.176
Epoch                                        22
---------------------------------------  ---------------
2022-11-16 10:56:17.089098 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 23 finished
---------------------------------------  ---------------
epoch                                        23
total_step                                28000
replay_pool/size                          28000
trainer/alpha                                 0.0642632
trainer/alpha_loss                           -0.63754
trainer/entropy                              -5.76773
trainer/qf_loss                               7.2895
trainer/state_noise                           0.005
trainer/policy_loss                         -85.9657
trainer/policy_loss_without_entropy          86.9015
trainer/entropy_penalty                      -0.370653
trainer/entropy_percentage                   -0.00426521
trainer/Q1Pred Mean                          85.4049
trainer/Q1Pred Std                           31.7494
trainer/Q1Pred Max                          137.209
trainer/Q1Pred Min                          -25.5109
trainer/Q2Pred Mean                          85.1975
trainer/Q2Pred Std                           31.5378
trainer/Q2Pred Max                          136.042
trainer/Q2Pred Min                          -25.6087
trainer/QTargetWithReg Mean                  85.1207
trainer/QTargetWithReg Std                   32.023
trainer/QTargetWithReg Max                  135.615
trainer/QTargetWithReg Min                  -27.0531
trainer/PolicyLossWithoutReg Mean            86.9015
trainer/PolicyLossWithoutReg Std             30.1017
trainer/PolicyLossWithoutReg Max            137.433
trainer/PolicyLossWithoutReg Min            -24.824
trainer/gradient_norm                       113.032
trainer/gradient_penalty                     -0.565159
trainer/gradient_percentage                  -0.00650344
exploration/num steps total               28000
exploration/num paths total                 521
exploration/path length this epoch Mean     134.714
exploration/path length this epoch Std       27.2801
exploration/path length this epoch Max      192
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.01891
exploration/Rewards Std                       1.27131
exploration/Rewards Max                       5.99891
exploration/Rewards Min                      -1.35872
exploration/Returns Mean                    271.976
exploration/Returns Std                      39.8833
exploration/Returns Max                     320.38
exploration/Returns Min                     190.58
exploration/Num Paths                         7
exploration/Average Returns                 271.976
evaluation_0/num steps total             181964
evaluation_0/num paths total               1364
evaluation_0/path length Mean               162.327
evaluation_0/path length Std                 60.8331
evaluation_0/path length Max                419
evaluation_0/path length Min                 75
evaluation_0/Rewards Mean                     2.37176
evaluation_0/Rewards Std                      1.21593
evaluation_0/Rewards Max                      6.33099
evaluation_0/Rewards Min                     -0.449611
evaluation_0/Returns Mean                   384.999
evaluation_0/Returns Std                    136.675
evaluation_0/Returns Max                    765.531
evaluation_0/Returns Min                    143.712
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                384.999
time/epoch (s)                                0
time/total (s)                              631.071
Epoch                                        23
---------------------------------------  ---------------
2022-11-16 10:56:30.774210 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 24 finished
---------------------------------------  ---------------
epoch                                        24
total_step                                29000
replay_pool/size                          29000
trainer/alpha                                 0.0630178
trainer/alpha_loss                            0.221228
trainer/entropy                              -6.08003
trainer/qf_loss                               8.13627
trainer/state_noise                           0.005
trainer/policy_loss                         -88.1285
trainer/policy_loss_without_entropy          89.0783
trainer/entropy_penalty                      -0.38315
trainer/entropy_percentage                   -0.00430127
trainer/Q1Pred Mean                          85.3548
trainer/Q1Pred Std                           33.8401
trainer/Q1Pred Max                          133.229
trainer/Q1Pred Min                          -12.3978
trainer/Q2Pred Mean                          85.2586
trainer/Q2Pred Std                           33.7932
trainer/Q2Pred Max                          134.073
trainer/Q2Pred Min                          -13.8746
trainer/QTargetWithReg Mean                  85.5002
trainer/QTargetWithReg Std                   34.1494
trainer/QTargetWithReg Max                  133.549
trainer/QTargetWithReg Min                  -11.3365
trainer/PolicyLossWithoutReg Mean            89.0783
trainer/PolicyLossWithoutReg Std             31.4059
trainer/PolicyLossWithoutReg Max            133.501
trainer/PolicyLossWithoutReg Min             -9.4178
trainer/gradient_norm                       113.33
trainer/gradient_penalty                     -0.566651
trainer/gradient_percentage                  -0.00636126
exploration/num steps total               29000
exploration/num paths total                 525
exploration/path length this epoch Mean     242.75
exploration/path length this epoch Std      194.407
exploration/path length this epoch Max      579
exploration/path length this epoch Min      114
exploration/Rewards Mean                      1.60041
exploration/Rewards Std                       1.02948
exploration/Rewards Max                       6.08237
exploration/Rewards Min                      -1.63062
exploration/Returns Mean                    388.5
exploration/Returns Std                     191.182
exploration/Returns Max                     716.747
exploration/Returns Min                     241.412
exploration/Num Paths                         4
exploration/Average Returns                 388.5
evaluation_0/num steps total             189893
evaluation_0/num paths total               1428
evaluation_0/path length Mean               123.891
evaluation_0/path length Std                 32.0064
evaluation_0/path length Max                267
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     1.92242
evaluation_0/Rewards Std                      1.19208
evaluation_0/Rewards Max                      5.70655
evaluation_0/Rewards Min                     -0.35728
evaluation_0/Returns Mean                   238.17
evaluation_0/Returns Std                     73.7727
evaluation_0/Returns Max                    507.984
evaluation_0/Returns Min                    124.998
evaluation_0/Num Paths                       64
evaluation_0/Average Returns                238.17
time/epoch (s)                                0
time/total (s)                              644.756
Epoch                                        24
---------------------------------------  ---------------
2022-11-16 10:56:44.023061 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 25 finished
---------------------------------------  --------------
epoch                                        25
total_step                                30000
replay_pool/size                          30000
trainer/alpha                                 0.0604735
trainer/alpha_loss                           -2.44688
trainer/entropy                              -5.1278
trainer/qf_loss                               6.18937
trainer/state_noise                           0.005
trainer/policy_loss                         -91.746
trainer/policy_loss_without_entropy          92.5851
trainer/entropy_penalty                      -0.310096
trainer/entropy_percentage                   -0.0033493
trainer/Q1Pred Mean                          90.7455
trainer/Q1Pred Std                           30.7385
trainer/Q1Pred Max                          133.353
trainer/Q1Pred Min                           -3.9656
trainer/Q2Pred Mean                          90.5084
trainer/Q2Pred Std                           30.7146
trainer/Q2Pred Max                          133.71
trainer/Q2Pred Min                          -10.2574
trainer/QTargetWithReg Mean                  90.4359
trainer/QTargetWithReg Std                   30.8045
trainer/QTargetWithReg Max                  133.819
trainer/QTargetWithReg Min                   -8.83241
trainer/PolicyLossWithoutReg Mean            92.5851
trainer/PolicyLossWithoutReg Std             29.9004
trainer/PolicyLossWithoutReg Max            133.038
trainer/PolicyLossWithoutReg Min             -0.37762
trainer/gradient_norm                       105.804
trainer/gradient_penalty                     -0.529022
trainer/gradient_percentage                  -0.0057139
exploration/num steps total               30000
exploration/num paths total                 533
exploration/path length this epoch Mean     116.5
exploration/path length this epoch Std       19.2938
exploration/path length this epoch Max      154
exploration/path length this epoch Min       84
exploration/Rewards Mean                      2.05935
exploration/Rewards Std                       1.13243
exploration/Rewards Max                       5.0148
exploration/Rewards Min                      -0.537384
exploration/Returns Mean                    239.914
exploration/Returns Std                      50.2082
exploration/Returns Max                     349.09
exploration/Returns Min                     167.552
exploration/Num Paths                         8
exploration/Average Returns                 239.914
evaluation_0/num steps total             197790
evaluation_0/num paths total               1487
evaluation_0/path length Mean               133.847
evaluation_0/path length Std                 30.5308
evaluation_0/path length Max                336
evaluation_0/path length Min                116
evaluation_0/Rewards Mean                     2.30938
evaluation_0/Rewards Std                      1.2251
evaluation_0/Rewards Max                      5.64323
evaluation_0/Rewards Min                     -0.258312
evaluation_0/Returns Mean                   309.104
evaluation_0/Returns Std                     53.7707
evaluation_0/Returns Max                    605.777
evaluation_0/Returns Min                    261.258
evaluation_0/Num Paths                       59
evaluation_0/Average Returns                309.104
time/epoch (s)                                0
time/total (s)                              658.004
Epoch                                        25
---------------------------------------  --------------
2022-11-16 10:56:59.115922 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 26 finished
---------------------------------------  ---------------
epoch                                        26
total_step                                31000
replay_pool/size                          31000
trainer/alpha                                 0.0565141
trainer/alpha_loss                           -1.4033
trainer/entropy                              -5.51159
trainer/qf_loss                               6.55169
trainer/state_noise                           0.005
trainer/policy_loss                         -91.4474
trainer/policy_loss_without_entropy          92.3116
trainer/entropy_penalty                      -0.311482
trainer/entropy_percentage                   -0.00337425
trainer/Q1Pred Mean                          89.3535
trainer/Q1Pred Std                           31.6843
trainer/Q1Pred Max                          132.3
trainer/Q1Pred Min                           -9.73261
trainer/Q2Pred Mean                          89.4961
trainer/Q2Pred Std                           31.299
trainer/Q2Pred Max                          132.523
trainer/Q2Pred Min                           -9.25587
trainer/QTargetWithReg Mean                  89.6506
trainer/QTargetWithReg Std                   31.416
trainer/QTargetWithReg Max                  131.737
trainer/QTargetWithReg Min                   -7.53986
trainer/PolicyLossWithoutReg Mean            92.3116
trainer/PolicyLossWithoutReg Std             29.798
trainer/PolicyLossWithoutReg Max            131.254
trainer/PolicyLossWithoutReg Min             -5.53309
trainer/gradient_norm                       110.54
trainer/gradient_penalty                     -0.552702
trainer/gradient_percentage                  -0.00598736
exploration/num steps total               31000
exploration/num paths total                 540
exploration/path length this epoch Mean     115.429
exploration/path length this epoch Std       11.2486
exploration/path length this epoch Max      137
exploration/path length this epoch Min      103
exploration/Rewards Mean                      1.91504
exploration/Rewards Std                       1.18191
exploration/Rewards Max                       5.19824
exploration/Rewards Min                      -0.390386
exploration/Returns Mean                    221.051
exploration/Returns Std                      20.0125
exploration/Returns Max                     243.693
exploration/Returns Min                     187.463
exploration/Num Paths                         7
exploration/Average Returns                 221.051
evaluation_0/num steps total             205711
evaluation_0/num paths total               1558
evaluation_0/path length Mean               111.563
evaluation_0/path length Std                 37.1467
evaluation_0/path length Max                218
evaluation_0/path length Min                 77
evaluation_0/Rewards Mean                     1.80695
evaluation_0/Rewards Std                      1.1825
evaluation_0/Rewards Max                      6.16494
evaluation_0/Rewards Min                     -1.19281
evaluation_0/Returns Mean                   201.589
evaluation_0/Returns Std                     74.5808
evaluation_0/Returns Max                    432.578
evaluation_0/Returns Min                    130.401
evaluation_0/Num Paths                       71
evaluation_0/Average Returns                201.589
time/epoch (s)                                0
time/total (s)                              673.097
Epoch                                        26
---------------------------------------  ---------------
2022-11-16 10:57:16.048985 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 27 finished
---------------------------------------  ---------------
epoch                                        27
total_step                                32000
replay_pool/size                          32000
trainer/alpha                                 0.0549642
trainer/alpha_loss                           -2.31673
trainer/entropy                              -5.20135
trainer/qf_loss                               6.12879
trainer/state_noise                           0.005
trainer/policy_loss                         -91.7453
trainer/policy_loss_without_entropy          92.5448
trainer/entropy_penalty                      -0.285888
trainer/entropy_percentage                   -0.00308919
trainer/Q1Pred Mean                          91.066
trainer/Q1Pred Std                           32.5048
trainer/Q1Pred Max                          135.392
trainer/Q1Pred Min                            1.61986
trainer/Q2Pred Mean                          90.9642
trainer/Q2Pred Std                           32.5548
trainer/Q2Pred Max                          134.667
trainer/Q2Pred Min                            0.881513
trainer/QTargetWithReg Mean                  90.6734
trainer/QTargetWithReg Std                   32.7652
trainer/QTargetWithReg Max                  134.395
trainer/QTargetWithReg Min                   -0.593429
trainer/PolicyLossWithoutReg Mean            92.5448
trainer/PolicyLossWithoutReg Std             31.7499
trainer/PolicyLossWithoutReg Max            134.631
trainer/PolicyLossWithoutReg Min              2.28817
trainer/gradient_norm                       102.725
trainer/gradient_penalty                     -0.513626
trainer/gradient_percentage                  -0.00555002
exploration/num steps total               32000
exploration/num paths total                 546
exploration/path length this epoch Mean     166.167
exploration/path length this epoch Std      102.608
exploration/path length this epoch Max      387
exploration/path length this epoch Min       86
exploration/Rewards Mean                      1.5402
exploration/Rewards Std                       1.16425
exploration/Rewards Max                       4.72867
exploration/Rewards Min                      -0.874245
exploration/Returns Mean                    255.93
exploration/Returns Std                     123.929
exploration/Returns Max                     509.022
exploration/Returns Min                     149.496
exploration/Num Paths                         6
exploration/Average Returns                 255.93
evaluation_0/num steps total             213489
evaluation_0/num paths total               1621
evaluation_0/path length Mean               123.46
evaluation_0/path length Std                 46.2027
evaluation_0/path length Max                363
evaluation_0/path length Min                 80
evaluation_0/Rewards Mean                     1.69561
evaluation_0/Rewards Std                      1.08047
evaluation_0/Rewards Max                      5.85246
evaluation_0/Rewards Min                     -2.81141
evaluation_0/Returns Mean                   209.341
evaluation_0/Returns Std                     70.3722
evaluation_0/Returns Max                    514.129
evaluation_0/Returns Min                     62.7731
evaluation_0/Num Paths                       63
evaluation_0/Average Returns                209.341
time/epoch (s)                                0
time/total (s)                              690.031
Epoch                                        27
---------------------------------------  ---------------
2022-11-16 10:57:35.811976 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 28 finished
---------------------------------------  ---------------
epoch                                        28
total_step                                33000
replay_pool/size                          33000
trainer/alpha                                 0.0511839
trainer/alpha_loss                            0.0844443
trainer/entropy                              -6.02841
trainer/qf_loss                              11.0561
trainer/state_noise                           0.005
trainer/policy_loss                         -92.1981
trainer/policy_loss_without_entropy          93.0705
trainer/entropy_penalty                      -0.308558
trainer/entropy_percentage                   -0.00331531
trainer/Q1Pred Mean                          90.0694
trainer/Q1Pred Std                           34.744
trainer/Q1Pred Max                          132.398
trainer/Q1Pred Min                           -4.59282
trainer/Q2Pred Mean                          89.9118
trainer/Q2Pred Std                           34.9659
trainer/Q2Pred Max                          131.975
trainer/Q2Pred Min                           -8.73447
trainer/QTargetWithReg Mean                  90.3231
trainer/QTargetWithReg Std                   35.3358
trainer/QTargetWithReg Max                  132.349
trainer/QTargetWithReg Min                   -2.10051
trainer/PolicyLossWithoutReg Mean            93.0705
trainer/PolicyLossWithoutReg Std             32.1384
trainer/PolicyLossWithoutReg Max            132.663
trainer/PolicyLossWithoutReg Min              0.392115
trainer/gradient_norm                       112.752
trainer/gradient_penalty                     -0.563762
trainer/gradient_percentage                  -0.00605737
exploration/num steps total               33000
exploration/num paths total                 547
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      1.00211
exploration/Rewards Std                       0.526115
exploration/Rewards Max                       4.9579
exploration/Rewards Min                      -0.513791
exploration/Returns Mean                   1002.11
exploration/Returns Std                       0
exploration/Returns Max                    1002.11
exploration/Returns Min                    1002.11
exploration/Num Paths                         1
exploration/Average Returns                1002.11
evaluation_0/num steps total             221358
evaluation_0/num paths total               1645
evaluation_0/path length Mean               327.875
evaluation_0/path length Std                270.392
evaluation_0/path length Max               1000
evaluation_0/path length Min                117
evaluation_0/Rewards Mean                     0.995169
evaluation_0/Rewards Std                      1.14538
evaluation_0/Rewards Max                      6.70106
evaluation_0/Rewards Min                     -2.42335
evaluation_0/Returns Mean                   326.291
evaluation_0/Returns Std                    292.169
evaluation_0/Returns Max                   1030.82
evaluation_0/Returns Min                     72.7924
evaluation_0/Num Paths                       24
evaluation_0/Average Returns                326.291
time/epoch (s)                                0
time/total (s)                              709.792
Epoch                                        28
---------------------------------------  ---------------
2022-11-16 10:58:01.473109 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 29 finished
---------------------------------------  ---------------
epoch                                        29
total_step                                34000
replay_pool/size                          34000
trainer/alpha                                 0.0515226
trainer/alpha_loss                            1.01071
trainer/entropy                              -6.34079
trainer/qf_loss                               5.11769
trainer/state_noise                           0.005
trainer/policy_loss                         -93.105
trainer/policy_loss_without_entropy          93.9531
trainer/entropy_penalty                      -0.326694
trainer/entropy_percentage                   -0.0034772
trainer/Q1Pred Mean                          92.285
trainer/Q1Pred Std                           34.6345
trainer/Q1Pred Max                          142.092
trainer/Q1Pred Min                           -7.52497
trainer/Q2Pred Mean                          92.0271
trainer/Q2Pred Std                           34.6959
trainer/Q2Pred Max                          141.369
trainer/Q2Pred Min                           -7.03477
trainer/QTargetWithReg Mean                  92.1909
trainer/QTargetWithReg Std                   34.8052
trainer/QTargetWithReg Max                  142.063
trainer/QTargetWithReg Min                   -3.5923
trainer/PolicyLossWithoutReg Mean            93.9531
trainer/PolicyLossWithoutReg Std             33.8415
trainer/PolicyLossWithoutReg Max            142.466
trainer/PolicyLossWithoutReg Min             -2.48924
trainer/gradient_norm                       104.275
trainer/gradient_penalty                     -0.521377
trainer/gradient_percentage                  -0.00554934
exploration/num steps total               34000
exploration/num paths total                 553
exploration/path length this epoch Mean     150.833
exploration/path length this epoch Std       31.5986
exploration/path length this epoch Max      201
exploration/path length this epoch Min      102
exploration/Rewards Mean                      1.82477
exploration/Rewards Std                       1.39701
exploration/Rewards Max                       5.89994
exploration/Rewards Min                      -1.38877
exploration/Returns Mean                    275.236
exploration/Returns Std                      45.2267
exploration/Returns Max                     330.065
exploration/Returns Min                     199.007
exploration/Num Paths                         6
exploration/Average Returns                 275.236
evaluation_0/num steps total             229312
evaluation_0/num paths total               1714
evaluation_0/path length Mean               115.275
evaluation_0/path length Std                 20.7461
evaluation_0/path length Max                174
evaluation_0/path length Min                 80
evaluation_0/Rewards Mean                     2.49441
evaluation_0/Rewards Std                      1.46614
evaluation_0/Rewards Max                      8.31961
evaluation_0/Rewards Min                     -0.857081
evaluation_0/Returns Mean                   287.544
evaluation_0/Returns Std                     70.8874
evaluation_0/Returns Max                    468.521
evaluation_0/Returns Min                    196.569
evaluation_0/Num Paths                       69
evaluation_0/Average Returns                287.544
time/epoch (s)                                0
time/total (s)                              735.463
Epoch                                        29
---------------------------------------  ---------------
2022-11-16 10:59:28.460144 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 30 finished
---------------------------------------  ---------------
epoch                                        30
total_step                                35000
replay_pool/size                          35000
trainer/alpha                                 0.0509195
trainer/alpha_loss                            0.954063
trainer/entropy                              -6.32043
trainer/qf_loss                               6.21823
trainer/state_noise                           0.005
trainer/policy_loss                         -95.3947
trainer/policy_loss_without_entropy          96.2695
trainer/entropy_penalty                      -0.321833
trainer/entropy_percentage                   -0.00334305
trainer/Q1Pred Mean                          92.735
trainer/Q1Pred Std                           34.3638
trainer/Q1Pred Max                          138.087
trainer/Q1Pred Min                           -3.62472
trainer/Q2Pred Mean                          92.6794
trainer/Q2Pred Std                           33.9286
trainer/Q2Pred Max                          136.915
trainer/Q2Pred Min                           -5.9798
trainer/QTargetWithReg Mean                  92.7015
trainer/QTargetWithReg Std                   34.4797
trainer/QTargetWithReg Max                  137.729
trainer/QTargetWithReg Min                   -5.40627
trainer/PolicyLossWithoutReg Mean            96.2695
trainer/PolicyLossWithoutReg Std             31.2903
trainer/PolicyLossWithoutReg Max            137.734
trainer/PolicyLossWithoutReg Min             -5.18758
trainer/gradient_norm                       110.583
trainer/gradient_penalty                     -0.552913
trainer/gradient_percentage                  -0.00574339
exploration/num steps total               35000
exploration/num paths total                 560
exploration/path length this epoch Mean     134.857
exploration/path length this epoch Std       30.4088
exploration/path length this epoch Max      192
exploration/path length this epoch Min      101
exploration/Rewards Mean                      1.90036
exploration/Rewards Std                       1.4669
exploration/Rewards Max                       6.52258
exploration/Rewards Min                      -1.42387
exploration/Returns Mean                    256.277
exploration/Returns Std                      93.3161
exploration/Returns Max                     366.459
exploration/Returns Min                      76.5238
exploration/Num Paths                         7
exploration/Average Returns                 256.277
evaluation_0/num steps total             237220
evaluation_0/num paths total               1760
evaluation_0/path length Mean               171.913
evaluation_0/path length Std                 45.9947
evaluation_0/path length Max                375
evaluation_0/path length Min                121
evaluation_0/Rewards Mean                     2.12924
evaluation_0/Rewards Std                      1.33287
evaluation_0/Rewards Max                      7.65195
evaluation_0/Rewards Min                     -1.18006
evaluation_0/Returns Mean                   366.044
evaluation_0/Returns Std                     80.3335
evaluation_0/Returns Max                    630.587
evaluation_0/Returns Min                    237.174
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                366.044
time/epoch (s)                                0
time/total (s)                              822.44
Epoch                                        30
---------------------------------------  ---------------
2022-11-16 11:01:02.183029 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 31 finished
---------------------------------------  ---------------
epoch                                        31
total_step                                36000
replay_pool/size                          36000
trainer/alpha                                 0.0517899
trainer/alpha_loss                           -2.01266
trainer/entropy                              -5.32012
trainer/qf_loss                               4.47483
trainer/state_noise                           0.005
trainer/policy_loss                         -94.9745
trainer/policy_loss_without_entropy          95.774
trainer/entropy_penalty                      -0.275529
trainer/entropy_percentage                   -0.00287686
trainer/Q1Pred Mean                          93.5385
trainer/Q1Pred Std                           33.3267
trainer/Q1Pred Max                          133.609
trainer/Q1Pred Min                           -4.19133
trainer/Q2Pred Mean                          93.3486
trainer/Q2Pred Std                           33.8175
trainer/Q2Pred Max                          132.675
trainer/Q2Pred Min                           -8.26664
trainer/QTargetWithReg Mean                  93.817
trainer/QTargetWithReg Std                   33.6698
trainer/QTargetWithReg Max                  133.093
trainer/QTargetWithReg Min                   -2.69502
trainer/PolicyLossWithoutReg Mean            95.774
trainer/PolicyLossWithoutReg Std             31.7908
trainer/PolicyLossWithoutReg Max            133.536
trainer/PolicyLossWithoutReg Min             -7.28739
trainer/gradient_norm                       104.804
trainer/gradient_penalty                     -0.52402
trainer/gradient_percentage                  -0.00547142
exploration/num steps total               36000
exploration/num paths total                 566
exploration/path length this epoch Mean     153.333
exploration/path length this epoch Std       27.6144
exploration/path length this epoch Max      189
exploration/path length this epoch Min      108
exploration/Rewards Mean                      2.03662
exploration/Rewards Std                       1.16233
exploration/Rewards Max                       6.15653
exploration/Rewards Min                      -0.286588
exploration/Returns Mean                    312.282
exploration/Returns Std                      88.9431
exploration/Returns Max                     440.884
exploration/Returns Min                     225
exploration/Num Paths                         6
exploration/Average Returns                 312.282
evaluation_0/num steps total             245148
evaluation_0/num paths total               1817
evaluation_0/path length Mean               139.088
evaluation_0/path length Std                 15.358
evaluation_0/path length Max                173
evaluation_0/path length Min                101
evaluation_0/Rewards Mean                     2.34117
evaluation_0/Rewards Std                      1.40659
evaluation_0/Rewards Max                      9.1344
evaluation_0/Rewards Min                     -0.416068
evaluation_0/Returns Mean                   325.629
evaluation_0/Returns Std                     60.9964
evaluation_0/Returns Max                    453.006
evaluation_0/Returns Min                    202.11
evaluation_0/Num Paths                       57
evaluation_0/Average Returns                325.629
time/epoch (s)                                0
time/total (s)                              916.163
Epoch                                        31
---------------------------------------  ---------------
2022-11-16 11:02:48.479096 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 32 finished
---------------------------------------  ---------------
epoch                                        32
total_step                                37000
replay_pool/size                          37000
trainer/alpha                                 0.0467583
trainer/alpha_loss                           -0.450168
trainer/entropy                              -5.85302
trainer/qf_loss                               4.44319
trainer/state_noise                           0.005
trainer/policy_loss                         -95.9884
trainer/policy_loss_without_entropy          96.767
trainer/entropy_penalty                      -0.273677
trainer/entropy_percentage                   -0.00282821
trainer/Q1Pred Mean                          95.1977
trainer/Q1Pred Std                           33.9718
trainer/Q1Pred Max                          133.583
trainer/Q1Pred Min                           -6.44399
trainer/Q2Pred Mean                          95.0891
trainer/Q2Pred Std                           34.1028
trainer/Q2Pred Max                          133.683
trainer/Q2Pred Min                           -6.51996
trainer/QTargetWithReg Mean                  95.4345
trainer/QTargetWithReg Std                   33.8664
trainer/QTargetWithReg Max                  135.036
trainer/QTargetWithReg Min                   -0.601485
trainer/PolicyLossWithoutReg Mean            96.767
trainer/PolicyLossWithoutReg Std             32.427
trainer/PolicyLossWithoutReg Max            133.448
trainer/PolicyLossWithoutReg Min              3.07611
trainer/gradient_norm                       100.978
trainer/gradient_penalty                     -0.504889
trainer/gradient_percentage                  -0.00521757
exploration/num steps total               37000
exploration/num paths total                 572
exploration/path length this epoch Mean     157.5
exploration/path length this epoch Std       34.8843
exploration/path length this epoch Max      213
exploration/path length this epoch Min      101
exploration/Rewards Mean                      2.02405
exploration/Rewards Std                       1.3261
exploration/Rewards Max                       5.39008
exploration/Rewards Min                      -1.07724
exploration/Returns Mean                    318.787
exploration/Returns Std                     100.01
exploration/Returns Max                     454.484
exploration/Returns Min                     136.106
exploration/Num Paths                         6
exploration/Average Returns                 318.787
evaluation_0/num steps total             252955
evaluation_0/num paths total               1873
evaluation_0/path length Mean               139.411
evaluation_0/path length Std                 37.5346
evaluation_0/path length Max                256
evaluation_0/path length Min                 92
evaluation_0/Rewards Mean                     1.52175
evaluation_0/Rewards Std                      1.20168
evaluation_0/Rewards Max                      6.77829
evaluation_0/Rewards Min                     -3.00528
evaluation_0/Returns Mean                   212.148
evaluation_0/Returns Std                     80.9442
evaluation_0/Returns Max                    437.102
evaluation_0/Returns Min                     73.0124
evaluation_0/Num Paths                       56
evaluation_0/Average Returns                212.148
time/epoch (s)                                0
time/total (s)                             1022.47
Epoch                                        32
---------------------------------------  ---------------
2022-11-16 11:03:48.097662 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 33 finished
---------------------------------------  ---------------
epoch                                        33
total_step                                38000
replay_pool/size                          38000
trainer/alpha                                 0.0441823
trainer/alpha_loss                           -0.624892
trainer/entropy                              -5.79968
trainer/qf_loss                               5.73368
trainer/state_noise                           0.005
trainer/policy_loss                         -92.6867
trainer/policy_loss_without_entropy          93.4605
trainer/entropy_penalty                      -0.256243
trainer/entropy_percentage                   -0.00274173
trainer/Q1Pred Mean                          91.2426
trainer/Q1Pred Std                           35.2983
trainer/Q1Pred Max                          132.548
trainer/Q1Pred Min                           -8.95551
trainer/Q2Pred Mean                          91.3413
trainer/Q2Pred Std                           35.2047
trainer/Q2Pred Max                          131.124
trainer/Q2Pred Min                           -6.56149
trainer/QTargetWithReg Mean                  91.8145
trainer/QTargetWithReg Std                   35.3526
trainer/QTargetWithReg Max                  132.76
trainer/QTargetWithReg Min                   -0.419796
trainer/PolicyLossWithoutReg Mean            93.4605
trainer/PolicyLossWithoutReg Std             33.3492
trainer/PolicyLossWithoutReg Max            132.449
trainer/PolicyLossWithoutReg Min             -0.250473
trainer/gradient_norm                       103.504
trainer/gradient_penalty                     -0.517518
trainer/gradient_percentage                  -0.00553729
exploration/num steps total               38000
exploration/num paths total                 580
exploration/path length this epoch Mean     122.625
exploration/path length this epoch Std       34.6552
exploration/path length this epoch Max      164
exploration/path length this epoch Min       65
exploration/Rewards Mean                      1.88581
exploration/Rewards Std                       1.23089
exploration/Rewards Max                       5.15593
exploration/Rewards Min                      -0.493022
exploration/Returns Mean                    231.248
exploration/Returns Std                      57.4788
exploration/Returns Max                     307.259
exploration/Returns Min                     146.933
exploration/Num Paths                         8
exploration/Average Returns                 231.248
evaluation_0/num steps total             260879
evaluation_0/num paths total               1917
evaluation_0/path length Mean               180.091
evaluation_0/path length Std                 62.1475
evaluation_0/path length Max                315
evaluation_0/path length Min                 81
evaluation_0/Rewards Mean                     1.08809
evaluation_0/Rewards Std                      1.35844
evaluation_0/Rewards Max                      5.76601
evaluation_0/Rewards Min                     -4.31021
evaluation_0/Returns Mean                   195.956
evaluation_0/Returns Std                    140.48
evaluation_0/Returns Max                    531.017
evaluation_0/Returns Min                    -21.6188
evaluation_0/Num Paths                       44
evaluation_0/Average Returns                195.956
time/epoch (s)                                0
time/total (s)                             1082.07
Epoch                                        33
---------------------------------------  ---------------
2022-11-16 11:04:06.590120 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 34 finished
---------------------------------------  ---------------
epoch                                        34
total_step                                39000
replay_pool/size                          39000
trainer/alpha                                 0.0415368
trainer/alpha_loss                            0.911481
trainer/entropy                              -6.28652
trainer/qf_loss                               4.84312
trainer/state_noise                           0.005
trainer/policy_loss                         -92.7462
trainer/policy_loss_without_entropy          93.5162
trainer/entropy_penalty                      -0.261122
trainer/entropy_percentage                   -0.00279226
trainer/Q1Pred Mean                          91.7685
trainer/Q1Pred Std                           34.7734
trainer/Q1Pred Max                          129.408
trainer/Q1Pred Min                          -13.6092
trainer/Q2Pred Mean                          91.4961
trainer/Q2Pred Std                           34.6728
trainer/Q2Pred Max                          129.045
trainer/Q2Pred Min                          -12.5529
trainer/QTargetWithReg Mean                  91.7498
trainer/QTargetWithReg Std                   34.7498
trainer/QTargetWithReg Max                  128.472
trainer/QTargetWithReg Min                  -11.3435
trainer/PolicyLossWithoutReg Mean            93.5162
trainer/PolicyLossWithoutReg Std             33.5661
trainer/PolicyLossWithoutReg Max            129.235
trainer/PolicyLossWithoutReg Min             -7.04732
trainer/gradient_norm                       101.775
trainer/gradient_penalty                     -0.508874
trainer/gradient_percentage                  -0.00544156
exploration/num steps total               39000
exploration/num paths total                 585
exploration/path length this epoch Mean     151
exploration/path length this epoch Std       30.2787
exploration/path length this epoch Max      184
exploration/path length this epoch Min       94
exploration/Rewards Mean                      1.76916
exploration/Rewards Std                       1.00443
exploration/Rewards Max                       5.71817
exploration/Rewards Min                      -0.513824
exploration/Returns Mean                    267.144
exploration/Returns Std                      54.0686
exploration/Returns Max                     315.209
exploration/Returns Min                     163.852
exploration/Num Paths                         5
exploration/Average Returns                 267.144
evaluation_0/num steps total             268820
evaluation_0/num paths total               1957
evaluation_0/path length Mean               198.525
evaluation_0/path length Std                193.853
evaluation_0/path length Max               1000
evaluation_0/path length Min                 88
evaluation_0/Rewards Mean                     1.19795
evaluation_0/Rewards Std                      1.23832
evaluation_0/Rewards Max                      5.70455
evaluation_0/Rewards Min                     -4.07389
evaluation_0/Returns Mean                   237.823
evaluation_0/Returns Std                    203.84
evaluation_0/Returns Max                   1085.05
evaluation_0/Returns Min                     57.5613
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                237.823
time/epoch (s)                                0
time/total (s)                             1100.57
Epoch                                        34
---------------------------------------  ---------------
2022-11-16 11:04:24.576845 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 35 finished
---------------------------------------  ---------------
epoch                                        35
total_step                                40000
replay_pool/size                          40000
trainer/alpha                                 0.0401239
trainer/alpha_loss                           -0.452769
trainer/entropy                              -5.8592
trainer/qf_loss                               4.58671
trainer/state_noise                           0.005
trainer/policy_loss                         -91.8246
trainer/policy_loss_without_entropy          92.5177
trainer/entropy_penalty                      -0.235094
trainer/entropy_percentage                   -0.00254107
trainer/Q1Pred Mean                          90.2331
trainer/Q1Pred Std                           34.2658
trainer/Q1Pred Max                          129.291
trainer/Q1Pred Min                           -5.45307
trainer/Q2Pred Mean                          90.0801
trainer/Q2Pred Std                           34.3717
trainer/Q2Pred Max                          131.283
trainer/Q2Pred Min                           -6.23859
trainer/QTargetWithReg Mean                  90.1939
trainer/QTargetWithReg Std                   34.4493
trainer/QTargetWithReg Max                  131.986
trainer/QTargetWithReg Min                   -1.72566
trainer/PolicyLossWithoutReg Mean            92.5177
trainer/PolicyLossWithoutReg Std             33.5051
trainer/PolicyLossWithoutReg Max            131.488
trainer/PolicyLossWithoutReg Min             -4.25276
trainer/gradient_norm                        91.5836
trainer/gradient_penalty                     -0.457918
trainer/gradient_percentage                  -0.00494952
exploration/num steps total               40000
exploration/num paths total                 591
exploration/path length this epoch Mean     147.5
exploration/path length this epoch Std       67.4901
exploration/path length this epoch Max      266
exploration/path length this epoch Min       38
exploration/Rewards Mean                      1.44162
exploration/Rewards Std                       1.37721
exploration/Rewards Max                       4.90886
exploration/Rewards Min                      -2.69882
exploration/Returns Mean                    212.638
exploration/Returns Std                     158.526
exploration/Returns Max                     504.248
exploration/Returns Min                      15.9853
exploration/Num Paths                         6
exploration/Average Returns                 212.638
evaluation_0/num steps total             276725
evaluation_0/num paths total               1987
evaluation_0/path length Mean               263.5
evaluation_0/path length Std                149.273
evaluation_0/path length Max               1000
evaluation_0/path length Min                129
evaluation_0/Rewards Mean                     1.50464
evaluation_0/Rewards Std                      1.19981
evaluation_0/Rewards Max                      5.41584
evaluation_0/Rewards Min                     -3.56274
evaluation_0/Returns Mean                   396.472
evaluation_0/Returns Std                    163.155
evaluation_0/Returns Max                    982.287
evaluation_0/Returns Min                    120.937
evaluation_0/Num Paths                       30
evaluation_0/Average Returns                396.472
time/epoch (s)                                0
time/total (s)                             1118.55
Epoch                                        35
---------------------------------------  ---------------
2022-11-16 11:04:42.786831 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 36 finished
---------------------------------------  ---------------
epoch                                        36
total_step                                41000
replay_pool/size                          41000
trainer/alpha                                 0.0409519
trainer/alpha_loss                            1.02551
trainer/entropy                              -6.32093
trainer/qf_loss                               5.55435
trainer/state_noise                           0.005
trainer/policy_loss                         -88.7747
trainer/policy_loss_without_entropy          89.5609
trainer/entropy_penalty                      -0.258854
trainer/entropy_percentage                   -0.00289026
trainer/Q1Pred Mean                          87.8644
trainer/Q1Pred Std                           30.6319
trainer/Q1Pred Max                          127.034
trainer/Q1Pred Min                           -6.70162
trainer/Q2Pred Mean                          88.1113
trainer/Q2Pred Std                           30.3788
trainer/Q2Pred Max                          128.909
trainer/Q2Pred Min                           -5.90624
trainer/QTargetWithReg Mean                  87.6744
trainer/QTargetWithReg Std                   30.4313
trainer/QTargetWithReg Max                  130.012
trainer/QTargetWithReg Min                    1.63387
trainer/PolicyLossWithoutReg Mean            89.5609
trainer/PolicyLossWithoutReg Std             29.8037
trainer/PolicyLossWithoutReg Max            129.382
trainer/PolicyLossWithoutReg Min             -5.67509
trainer/gradient_norm                       105.47
trainer/gradient_penalty                     -0.527349
trainer/gradient_percentage                  -0.00588816
exploration/num steps total               41000
exploration/num paths total                 595
exploration/path length this epoch Mean     221.5
exploration/path length this epoch Std       87.6513
exploration/path length this epoch Max      373
exploration/path length this epoch Min      163
exploration/Rewards Mean                      1.38869
exploration/Rewards Std                       1.22136
exploration/Rewards Max                       4.96335
exploration/Rewards Min                      -1.24088
exploration/Returns Mean                    307.595
exploration/Returns Std                      98.2692
exploration/Returns Max                     446.529
exploration/Returns Min                     183.587
exploration/Num Paths                         4
exploration/Average Returns                 307.595
evaluation_0/num steps total             284530
evaluation_0/num paths total               2020
evaluation_0/path length Mean               236.515
evaluation_0/path length Std                231.515
evaluation_0/path length Max               1000
evaluation_0/path length Min                 37
evaluation_0/Rewards Mean                     1.42264
evaluation_0/Rewards Std                      1.11808
evaluation_0/Rewards Max                      7.14694
evaluation_0/Rewards Min                     -1.27765
evaluation_0/Returns Mean                   336.475
evaluation_0/Returns Std                    266.179
evaluation_0/Returns Max                   1054.32
evaluation_0/Returns Min                     24.6673
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                336.475
time/epoch (s)                                0
time/total (s)                             1136.76
Epoch                                        36
---------------------------------------  ---------------
2022-11-16 11:05:01.558737 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 37 finished
---------------------------------------  ---------------
epoch                                        37
total_step                                42000
replay_pool/size                          42000
trainer/alpha                                 0.0414871
trainer/alpha_loss                           -0.044464
trainer/entropy                              -5.98603
trainer/qf_loss                               4.74548
trainer/state_noise                           0.005
trainer/policy_loss                         -87.9576
trainer/policy_loss_without_entropy          88.7109
trainer/entropy_penalty                      -0.248343
trainer/entropy_percentage                   -0.00279946
trainer/Q1Pred Mean                          86.7461
trainer/Q1Pred Std                           34.7387
trainer/Q1Pred Max                          125.468
trainer/Q1Pred Min                          -10.9899
trainer/Q2Pred Mean                          86.3485
trainer/Q2Pred Std                           34.77
trainer/Q2Pred Max                          124.027
trainer/Q2Pred Min                          -13.5309
trainer/QTargetWithReg Mean                  86.2775
trainer/QTargetWithReg Std                   34.6472
trainer/QTargetWithReg Max                  125.169
trainer/QTargetWithReg Min                  -12.1164
trainer/PolicyLossWithoutReg Mean            88.7109
trainer/PolicyLossWithoutReg Std             33.2753
trainer/PolicyLossWithoutReg Max            124.636
trainer/PolicyLossWithoutReg Min            -11.077
trainer/gradient_norm                       100.984
trainer/gradient_penalty                     -0.50492
trainer/gradient_percentage                  -0.00569175
exploration/num steps total               42000
exploration/num paths total                 599
exploration/path length this epoch Mean     221.25
exploration/path length this epoch Std       73.6627
exploration/path length this epoch Max      326
exploration/path length this epoch Min      123
exploration/Rewards Mean                      1.88321
exploration/Rewards Std                       1.28461
exploration/Rewards Max                       7.14814
exploration/Rewards Min                      -0.514432
exploration/Returns Mean                    416.661
exploration/Returns Std                     117.654
exploration/Returns Max                     544.855
exploration/Returns Min                     224.753
exploration/Num Paths                         4
exploration/Average Returns                 416.661
evaluation_0/num steps total             292413
evaluation_0/num paths total               2043
evaluation_0/path length Mean               342.739
evaluation_0/path length Std                244.508
evaluation_0/path length Max               1000
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     1.12972
evaluation_0/Rewards Std                      1.07493
evaluation_0/Rewards Max                      5.16746
evaluation_0/Rewards Min                     -2.20771
evaluation_0/Returns Mean                   387.199
evaluation_0/Returns Std                    252.604
evaluation_0/Returns Max                   1076.71
evaluation_0/Returns Min                    129.335
evaluation_0/Num Paths                       23
evaluation_0/Average Returns                387.199
time/epoch (s)                                0
time/total (s)                             1155.53
Epoch                                        37
---------------------------------------  ---------------
2022-11-16 11:05:21.089783 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 38 finished
---------------------------------------  ---------------
epoch                                        38
total_step                                43000
replay_pool/size                          43000
trainer/alpha                                 0.041293
trainer/alpha_loss                            0.507784
trainer/entropy                              -6.15932
trainer/qf_loss                               4.86478
trainer/state_noise                           0.005
trainer/policy_loss                         -87.5089
trainer/policy_loss_without_entropy          88.2869
trainer/entropy_penalty                      -0.254337
trainer/entropy_percentage                   -0.0028808
trainer/Q1Pred Mean                          87.0243
trainer/Q1Pred Std                           30.5039
trainer/Q1Pred Max                          126.014
trainer/Q1Pred Min                           -6.73359
trainer/Q2Pred Mean                          87.1763
trainer/Q2Pred Std                           30.8564
trainer/Q2Pred Max                          125.634
trainer/Q2Pred Min                           -4.79654
trainer/QTargetWithReg Mean                  87.1639
trainer/QTargetWithReg Std                   30.5193
trainer/QTargetWithReg Max                  126.522
trainer/QTargetWithReg Min                   -1.96968
trainer/PolicyLossWithoutReg Mean            88.2869
trainer/PolicyLossWithoutReg Std             29.9419
trainer/PolicyLossWithoutReg Max            125.805
trainer/PolicyLossWithoutReg Min            -27.2994
trainer/gradient_norm                       104.747
trainer/gradient_penalty                     -0.523735
trainer/gradient_percentage                  -0.00593219
exploration/num steps total               43000
exploration/num paths total                 600
exploration/path length this epoch Mean     815
exploration/path length this epoch Std        0
exploration/path length this epoch Max      815
exploration/path length this epoch Min      815
exploration/Rewards Mean                      1.10197
exploration/Rewards Std                       1.21441
exploration/Rewards Max                       6.14722
exploration/Rewards Min                      -1.03794
exploration/Returns Mean                    898.106
exploration/Returns Std                       0
exploration/Returns Max                     898.106
exploration/Returns Min                     898.106
exploration/Num Paths                         1
exploration/Average Returns                 898.106
evaluation_0/num steps total             300160
evaluation_0/num paths total               2071
evaluation_0/path length Mean               276.679
evaluation_0/path length Std                258.738
evaluation_0/path length Max               1000
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     0.995122
evaluation_0/Rewards Std                      0.956771
evaluation_0/Rewards Max                      5.71775
evaluation_0/Rewards Min                     -3.47197
evaluation_0/Returns Mean                   275.329
evaluation_0/Returns Std                    273.383
evaluation_0/Returns Max                   1029.71
evaluation_0/Returns Min                   -106.983
evaluation_0/Num Paths                       28
evaluation_0/Average Returns                275.329
time/epoch (s)                                0
time/total (s)                             1175.06
Epoch                                        38
---------------------------------------  ---------------
2022-11-16 11:05:40.175071 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 39 finished
---------------------------------------  ---------------
epoch                                        39
total_step                                44000
replay_pool/size                          44000
trainer/alpha                                 0.038888
trainer/alpha_loss                           -3.42809
trainer/entropy                              -4.9442
trainer/qf_loss                               5.91879
trainer/state_noise                           0.005
trainer/policy_loss                         -90.1517
trainer/policy_loss_without_entropy          90.8379
trainer/entropy_penalty                      -0.19227
trainer/entropy_percentage                   -0.00211663
trainer/Q1Pred Mean                          89.6251
trainer/Q1Pred Std                           29.0976
trainer/Q1Pred Max                          126.97
trainer/Q1Pred Min                           -1.25538
trainer/Q2Pred Mean                          89.8046
trainer/Q2Pred Std                           29.022
trainer/Q2Pred Max                          127.085
trainer/Q2Pred Min                           -1.79014
trainer/QTargetWithReg Mean                  89.2664
trainer/QTargetWithReg Std                   29.1043
trainer/QTargetWithReg Max                  127.016
trainer/QTargetWithReg Min                   -1.18967
trainer/PolicyLossWithoutReg Mean            90.8379
trainer/PolicyLossWithoutReg Std             28.0409
trainer/PolicyLossWithoutReg Max            126.759
trainer/PolicyLossWithoutReg Min              2.56013
trainer/gradient_norm                        98.7794
trainer/gradient_penalty                     -0.493897
trainer/gradient_percentage                  -0.00543713
exploration/num steps total               44000
exploration/num paths total                 605
exploration/path length this epoch Mean     188.8
exploration/path length this epoch Std       69.9411
exploration/path length this epoch Max      270
exploration/path length this epoch Min       91
exploration/Rewards Mean                      1.28013
exploration/Rewards Std                       1.37478
exploration/Rewards Max                       5.64648
exploration/Rewards Min                      -2.98251
exploration/Returns Mean                    241.688
exploration/Returns Std                     145.763
exploration/Returns Max                     411.457
exploration/Returns Min                      -0.62621
exploration/Num Paths                         5
exploration/Average Returns                 241.688
evaluation_0/num steps total             308150
evaluation_0/num paths total               2100
evaluation_0/path length Mean               275.517
evaluation_0/path length Std                214.728
evaluation_0/path length Max               1000
evaluation_0/path length Min                115
evaluation_0/Rewards Mean                     1.15592
evaluation_0/Rewards Std                      1.16865
evaluation_0/Rewards Max                      5.62352
evaluation_0/Rewards Min                     -2.90793
evaluation_0/Returns Mean                   318.477
evaluation_0/Returns Std                    248.804
evaluation_0/Returns Max                   1101.02
evaluation_0/Returns Min                    -12.7595
evaluation_0/Num Paths                       29
evaluation_0/Average Returns                318.477
time/epoch (s)                                0
time/total (s)                             1194.15
Epoch                                        39
---------------------------------------  ---------------
2022-11-16 11:05:59.497234 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 40 finished
---------------------------------------  ---------------
epoch                                        40
total_step                                45000
replay_pool/size                          45000
trainer/alpha                                 0.0361921
trainer/alpha_loss                           -1.10659
trainer/entropy                              -5.66657
trainer/qf_loss                               4.29776
trainer/state_noise                           0.005
trainer/policy_loss                         -85.1414
trainer/policy_loss_without_entropy          85.8821
trainer/entropy_penalty                      -0.205085
trainer/entropy_percentage                   -0.00238798
trainer/Q1Pred Mean                          84.58
trainer/Q1Pred Std                           31.1448
trainer/Q1Pred Max                          125.297
trainer/Q1Pred Min                           -5.03328
trainer/Q2Pred Mean                          84.5648
trainer/Q2Pred Std                           30.9347
trainer/Q2Pred Max                          124.856
trainer/Q2Pred Min                           -2.81784
trainer/QTargetWithReg Mean                  84.1964
trainer/QTargetWithReg Std                   30.8896
trainer/QTargetWithReg Max                  125.547
trainer/QTargetWithReg Min                   -3.57648
trainer/PolicyLossWithoutReg Mean            85.8821
trainer/PolicyLossWithoutReg Std             30.3081
trainer/PolicyLossWithoutReg Max            125.509
trainer/PolicyLossWithoutReg Min             -3.03357
trainer/gradient_norm                       107.132
trainer/gradient_penalty                     -0.53566
trainer/gradient_percentage                  -0.00623716
exploration/num steps total               45000
exploration/num paths total                 610
exploration/path length this epoch Mean     146
exploration/path length this epoch Std       48.2701
exploration/path length this epoch Max      231
exploration/path length this epoch Min       84
exploration/Rewards Mean                      1.6743
exploration/Rewards Std                       1.16589
exploration/Rewards Max                       4.71225
exploration/Rewards Min                      -1.27191
exploration/Returns Mean                    244.447
exploration/Returns Std                     106.644
exploration/Returns Max                     347.164
exploration/Returns Min                      39.6556
exploration/Num Paths                         5
exploration/Average Returns                 244.447
evaluation_0/num steps total             315943
evaluation_0/num paths total               2141
evaluation_0/path length Mean               190.073
evaluation_0/path length Std                142.48
evaluation_0/path length Max               1000
evaluation_0/path length Min                107
evaluation_0/Rewards Mean                     1.65946
evaluation_0/Rewards Std                      0.996122
evaluation_0/Rewards Max                      6.3835
evaluation_0/Rewards Min                     -1.86383
evaluation_0/Returns Mean                   315.419
evaluation_0/Returns Std                    168.42
evaluation_0/Returns Max                   1101.25
evaluation_0/Returns Min                     73.5638
evaluation_0/Num Paths                       41
evaluation_0/Average Returns                315.419
time/epoch (s)                                0
time/total (s)                             1213.47
Epoch                                        40
---------------------------------------  ---------------
2022-11-16 11:06:16.910614 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 41 finished
---------------------------------------  ---------------
epoch                                        41
total_step                                46000
replay_pool/size                          46000
trainer/alpha                                 0.0362707
trainer/alpha_loss                            2.01809
trainer/entropy                              -6.60842
trainer/qf_loss                               4.4422
trainer/state_noise                           0.005
trainer/policy_loss                         -88.495
trainer/policy_loss_without_entropy          89.2442
trainer/entropy_penalty                      -0.239692
trainer/entropy_percentage                   -0.0026858
trainer/Q1Pred Mean                          87.6285
trainer/Q1Pred Std                           26.5875
trainer/Q1Pred Max                          123.81
trainer/Q1Pred Min                           -4.11504
trainer/Q2Pred Mean                          87.737
trainer/Q2Pred Std                           26.3547
trainer/Q2Pred Max                          123.252
trainer/Q2Pred Min                           -3.27009
trainer/QTargetWithReg Mean                  88.1505
trainer/QTargetWithReg Std                   26.6496
trainer/QTargetWithReg Max                  124.311
trainer/QTargetWithReg Min                   -3.61269
trainer/PolicyLossWithoutReg Mean            89.2442
trainer/PolicyLossWithoutReg Std             25.5974
trainer/PolicyLossWithoutReg Max            123.714
trainer/PolicyLossWithoutReg Min             -8.94929
trainer/gradient_norm                       101.907
trainer/gradient_penalty                     -0.509533
trainer/gradient_percentage                  -0.00570943
exploration/num steps total               46000
exploration/num paths total                 615
exploration/path length this epoch Mean     180
exploration/path length this epoch Std       74.6458
exploration/path length this epoch Max      295
exploration/path length this epoch Min       89
exploration/Rewards Mean                      1.48039
exploration/Rewards Std                       1.22608
exploration/Rewards Max                       5.6437
exploration/Rewards Min                      -1.64223
exploration/Returns Mean                    266.47
exploration/Returns Std                     105.53
exploration/Returns Max                     436.541
exploration/Returns Min                     138.151
exploration/Num Paths                         5
exploration/Average Returns                 266.47
evaluation_0/num steps total             323814
evaluation_0/num paths total               2186
evaluation_0/path length Mean               174.911
evaluation_0/path length Std                 65.3387
evaluation_0/path length Max                470
evaluation_0/path length Min                 93
evaluation_0/Rewards Mean                     1.76267
evaluation_0/Rewards Std                      1.21549
evaluation_0/Rewards Max                      6.59349
evaluation_0/Rewards Min                     -1.88686
evaluation_0/Returns Mean                   308.31
evaluation_0/Returns Std                     95.5734
evaluation_0/Returns Max                    519.204
evaluation_0/Returns Min                    131.161
evaluation_0/Num Paths                       45
evaluation_0/Average Returns                308.31
time/epoch (s)                                0
time/total (s)                             1230.88
Epoch                                        41
---------------------------------------  ---------------
2022-11-16 11:06:33.311755 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 42 finished
---------------------------------------  ---------------
epoch                                        42
total_step                                47000
replay_pool/size                          47000
trainer/alpha                                 0.0364021
trainer/alpha_loss                           -0.96908
trainer/entropy                              -5.70752
trainer/qf_loss                               3.53113
trainer/state_noise                           0.005
trainer/policy_loss                         -87.9162
trainer/policy_loss_without_entropy          88.6232
trainer/entropy_penalty                      -0.207765
trainer/entropy_percentage                   -0.00234437
trainer/Q1Pred Mean                          87.0929
trainer/Q1Pred Std                           28.2017
trainer/Q1Pred Max                          122.087
trainer/Q1Pred Min                          -13.57
trainer/Q2Pred Mean                          87.3361
trainer/Q2Pred Std                           28.2999
trainer/Q2Pred Max                          123.129
trainer/Q2Pred Min                          -14.6379
trainer/QTargetWithReg Mean                  87.8156
trainer/QTargetWithReg Std                   28.4439
trainer/QTargetWithReg Max                  123.01
trainer/QTargetWithReg Min                  -15.9187
trainer/PolicyLossWithoutReg Mean            88.6232
trainer/PolicyLossWithoutReg Std             27.5053
trainer/PolicyLossWithoutReg Max            122.641
trainer/PolicyLossWithoutReg Min            -11.5063
trainer/gradient_norm                        99.8588
trainer/gradient_penalty                     -0.499294
trainer/gradient_percentage                  -0.0056339
exploration/num steps total               47000
exploration/num paths total                 620
exploration/path length this epoch Mean     176.2
exploration/path length this epoch Std       64.1729
exploration/path length this epoch Max      300
exploration/path length this epoch Min      123
exploration/Rewards Mean                      1.7803
exploration/Rewards Std                       1.37775
exploration/Rewards Max                       6.41476
exploration/Rewards Min                      -1.82409
exploration/Returns Mean                    313.688
exploration/Returns Std                     192.414
exploration/Returns Max                     681.42
exploration/Returns Min                     148.725
exploration/Num Paths                         5
exploration/Average Returns                 313.688
evaluation_0/num steps total             331803
evaluation_0/num paths total               2271
evaluation_0/path length Mean                93.9882
evaluation_0/path length Std                 16.603
evaluation_0/path length Max                137
evaluation_0/path length Min                 70
evaluation_0/Rewards Mean                     2.22249
evaluation_0/Rewards Std                      1.34825
evaluation_0/Rewards Max                      6.51911
evaluation_0/Rewards Min                     -0.601486
evaluation_0/Returns Mean                   208.888
evaluation_0/Returns Std                     53.206
evaluation_0/Returns Max                    375.744
evaluation_0/Returns Min                    140.126
evaluation_0/Num Paths                       85
evaluation_0/Average Returns                208.888
time/epoch (s)                                0
time/total (s)                             1247.29
Epoch                                        42
---------------------------------------  ---------------
2022-11-16 11:06:49.523564 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 43 finished
---------------------------------------  ---------------
epoch                                        43
total_step                                48000
replay_pool/size                          48000
trainer/alpha                                 0.0355932
trainer/alpha_loss                           -0.834697
trainer/entropy                              -5.74976
trainer/qf_loss                               4.13007
trainer/state_noise                           0.005
trainer/policy_loss                         -85.7213
trainer/policy_loss_without_entropy          86.4482
trainer/entropy_penalty                      -0.204652
trainer/entropy_percentage                   -0.00236734
trainer/Q1Pred Mean                          84.9279
trainer/Q1Pred Std                           30.6012
trainer/Q1Pred Max                          124.057
trainer/Q1Pred Min                           -4.99801
trainer/Q2Pred Mean                          84.7455
trainer/Q2Pred Std                           30.7382
trainer/Q2Pred Max                          123.057
trainer/Q2Pred Min                           -8.64086
trainer/QTargetWithReg Mean                  84.542
trainer/QTargetWithReg Std                   30.6463
trainer/QTargetWithReg Max                  122.671
trainer/QTargetWithReg Min                   -1.42145
trainer/PolicyLossWithoutReg Mean            86.4483
trainer/PolicyLossWithoutReg Std             28.8957
trainer/PolicyLossWithoutReg Max            123.749
trainer/PolicyLossWithoutReg Min             -7.49366
trainer/gradient_norm                       104.461
trainer/gradient_penalty                     -0.522306
trainer/gradient_percentage                  -0.00604184
exploration/num steps total               48000
exploration/num paths total                 627
exploration/path length this epoch Mean     133.714
exploration/path length this epoch Std       21.2449
exploration/path length this epoch Max      161
exploration/path length this epoch Min       92
exploration/Rewards Mean                      2.13717
exploration/Rewards Std                       1.52339
exploration/Rewards Max                       6.87585
exploration/Rewards Min                      -2.2318
exploration/Returns Mean                    285.77
exploration/Returns Std                      93.7161
exploration/Returns Max                     441.661
exploration/Returns Min                     134.586
exploration/Num Paths                         7
exploration/Average Returns                 285.77
evaluation_0/num steps total             339783
evaluation_0/num paths total               2333
evaluation_0/path length Mean               128.71
evaluation_0/path length Std                 19.3244
evaluation_0/path length Max                209
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.43991
evaluation_0/Rewards Std                      1.4032
evaluation_0/Rewards Max                      7.11394
evaluation_0/Rewards Min                     -0.596609
evaluation_0/Returns Mean                   314.04
evaluation_0/Returns Std                     59.7477
evaluation_0/Returns Max                    486.945
evaluation_0/Returns Min                    224.029
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                314.04
time/epoch (s)                                0
time/total (s)                             1263.5
Epoch                                        43
---------------------------------------  ---------------
2022-11-16 11:07:06.602877 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 44 finished
---------------------------------------  ---------------
epoch                                        44
total_step                                49000
replay_pool/size                          49000
trainer/alpha                                 0.0356272
trainer/alpha_loss                            0.81504
trainer/entropy                              -6.24442
trainer/qf_loss                               4.64053
trainer/state_noise                           0.005
trainer/policy_loss                         -85.3939
trainer/policy_loss_without_entropy          86.1228
trainer/entropy_penalty                      -0.222471
trainer/entropy_percentage                   -0.00258319
trainer/Q1Pred Mean                          85.5217
trainer/Q1Pred Std                           28.6131
trainer/Q1Pred Max                          125.287
trainer/Q1Pred Min                           -5.53807
trainer/Q2Pred Mean                          85.3514
trainer/Q2Pred Std                           28.582
trainer/Q2Pred Max                          122.864
trainer/Q2Pred Min                           -8.04977
trainer/QTargetWithReg Mean                  85.1833
trainer/QTargetWithReg Std                   28.676
trainer/QTargetWithReg Max                  121.846
trainer/QTargetWithReg Min                  -11.8194
trainer/PolicyLossWithoutReg Mean            86.1228
trainer/PolicyLossWithoutReg Std             27.9754
trainer/PolicyLossWithoutReg Max            123.106
trainer/PolicyLossWithoutReg Min             -0.10537
trainer/gradient_norm                       101.276
trainer/gradient_penalty                     -0.506382
trainer/gradient_percentage                  -0.00587977
exploration/num steps total               49000
exploration/num paths total                 633
exploration/path length this epoch Mean     148.333
exploration/path length this epoch Std       27.9563
exploration/path length this epoch Max      200
exploration/path length this epoch Min      122
exploration/Rewards Mean                      1.7662
exploration/Rewards Std                       1.3941
exploration/Rewards Max                       5.45188
exploration/Rewards Min                      -1.90212
exploration/Returns Mean                    261.987
exploration/Returns Std                      81.6907
exploration/Returns Max                     373.779
exploration/Returns Min                     111.902
exploration/Num Paths                         6
exploration/Average Returns                 261.987
evaluation_0/num steps total             347645
evaluation_0/num paths total               2383
evaluation_0/path length Mean               157.24
evaluation_0/path length Std                 29.7238
evaluation_0/path length Max                266
evaluation_0/path length Min                116
evaluation_0/Rewards Mean                     2.2364
evaluation_0/Rewards Std                      1.19087
evaluation_0/Rewards Max                      6.48493
evaluation_0/Rewards Min                     -0.427731
evaluation_0/Returns Mean                   351.652
evaluation_0/Returns Std                     82.8521
evaluation_0/Returns Max                    543.966
evaluation_0/Returns Min                    217.039
evaluation_0/Num Paths                       50
evaluation_0/Average Returns                351.652
time/epoch (s)                                0
time/total (s)                             1280.58
Epoch                                        44
---------------------------------------  ---------------
2022-11-16 11:07:24.254148 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 45 finished
---------------------------------------  ---------------
epoch                                        45
total_step                                50000
replay_pool/size                          50000
trainer/alpha                                 0.0357216
trainer/alpha_loss                            2.68724
trainer/entropy                              -6.80646
trainer/qf_loss                               5.23417
trainer/state_noise                           0.005
trainer/policy_loss                         -82.8201
trainer/policy_loss_without_entropy          83.6256
trainer/entropy_penalty                      -0.243137
trainer/entropy_percentage                   -0.00290745
trainer/Q1Pred Mean                          81.0641
trainer/Q1Pred Std                           31.6908
trainer/Q1Pred Max                          121.844
trainer/Q1Pred Min                          -13.0141
trainer/Q2Pred Mean                          81.1804
trainer/Q2Pred Std                           31.7271
trainer/Q2Pred Max                          122.239
trainer/Q2Pred Min                          -10.7796
trainer/QTargetWithReg Mean                  81.3985
trainer/QTargetWithReg Std                   31.7772
trainer/QTargetWithReg Max                  122.033
trainer/QTargetWithReg Min                   -9.85067
trainer/PolicyLossWithoutReg Mean            83.6256
trainer/PolicyLossWithoutReg Std             29.1361
trainer/PolicyLossWithoutReg Max            121.779
trainer/PolicyLossWithoutReg Min            -13.3155
trainer/gradient_norm                       112.47
trainer/gradient_penalty                     -0.562352
trainer/gradient_percentage                  -0.00672464
exploration/num steps total               50000
exploration/num paths total                 636
exploration/path length this epoch Mean     275
exploration/path length this epoch Std      110.33
exploration/path length this epoch Max      430
exploration/path length this epoch Min      182
exploration/Rewards Mean                      1.2316
exploration/Rewards Std                       1.22887
exploration/Rewards Max                       4.68473
exploration/Rewards Min                      -1.09457
exploration/Returns Mean                    338.691
exploration/Returns Std                      21.1782
exploration/Returns Max                     366.883
exploration/Returns Min                     315.837
exploration/Num Paths                         3
exploration/Average Returns                 338.691
evaluation_0/num steps total             355599
evaluation_0/num paths total               2423
evaluation_0/path length Mean               198.85
evaluation_0/path length Std                 97.4329
evaluation_0/path length Max                618
evaluation_0/path length Min                110
evaluation_0/Rewards Mean                     0.841118
evaluation_0/Rewards Std                      1.35818
evaluation_0/Rewards Max                      5.91648
evaluation_0/Rewards Min                     -3.81403
evaluation_0/Returns Mean                   167.256
evaluation_0/Returns Std                    147.436
evaluation_0/Returns Max                    563.16
evaluation_0/Returns Min                    -20.0889
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                167.256
time/epoch (s)                                0
time/total (s)                             1298.23
Epoch                                        45
---------------------------------------  ---------------
2022-11-16 11:07:41.617528 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 46 finished
---------------------------------------  ---------------
epoch                                        46
total_step                                51000
replay_pool/size                          51000
trainer/alpha                                 0.0356816
trainer/alpha_loss                            0.220167
trainer/entropy                              -6.06605
trainer/qf_loss                               5.22634
trainer/state_noise                           0.005
trainer/policy_loss                         -82.2466
trainer/policy_loss_without_entropy          83.0184
trainer/entropy_penalty                      -0.216447
trainer/entropy_percentage                   -0.00260721
trainer/Q1Pred Mean                          81.818
trainer/Q1Pred Std                           30.833
trainer/Q1Pred Max                          126.431
trainer/Q1Pred Min                          -27.4599
trainer/Q2Pred Mean                          81.9551
trainer/Q2Pred Std                           30.6582
trainer/Q2Pred Max                          132.407
trainer/Q2Pred Min                          -27.8007
trainer/QTargetWithReg Mean                  81.4845
trainer/QTargetWithReg Std                   31.2008
trainer/QTargetWithReg Max                  130.468
trainer/QTargetWithReg Min                  -29.6209
trainer/PolicyLossWithoutReg Mean            83.0184
trainer/PolicyLossWithoutReg Std             29.9561
trainer/PolicyLossWithoutReg Max            127.878
trainer/PolicyLossWithoutReg Min            -26.4213
trainer/gradient_norm                       111.073
trainer/gradient_penalty                     -0.555365
trainer/gradient_percentage                  -0.00668966
exploration/num steps total               51000
exploration/num paths total                 640
exploration/path length this epoch Mean     213.75
exploration/path length this epoch Std       47.9759
exploration/path length this epoch Max      273
exploration/path length this epoch Min      155
exploration/Rewards Mean                      1.46558
exploration/Rewards Std                       1.2479
exploration/Rewards Max                       5.52085
exploration/Rewards Min                      -1.19626
exploration/Returns Mean                    313.268
exploration/Returns Std                      46.7762
exploration/Returns Max                     372.035
exploration/Returns Min                     244.451
exploration/Num Paths                         4
exploration/Average Returns                 313.268
evaluation_0/num steps total             363472
evaluation_0/num paths total               2446
evaluation_0/path length Mean               342.304
evaluation_0/path length Std                103.583
evaluation_0/path length Max                600
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     1.25472
evaluation_0/Rewards Std                      1.07341
evaluation_0/Rewards Max                      5.70197
evaluation_0/Rewards Min                     -1.91413
evaluation_0/Returns Mean                   429.497
evaluation_0/Returns Std                    100.037
evaluation_0/Returns Max                    605.15
evaluation_0/Returns Min                     84.9656
evaluation_0/Num Paths                       23
evaluation_0/Average Returns                429.497
time/epoch (s)                                0
time/total (s)                             1315.59
Epoch                                        46
---------------------------------------  ---------------
2022-11-16 11:07:58.902124 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 47 finished
---------------------------------------  ---------------
epoch                                        47
total_step                                52000
replay_pool/size                          52000
trainer/alpha                                 0.0361274
trainer/alpha_loss                            0.349529
trainer/entropy                              -6.10526
trainer/qf_loss                               4.97798
trainer/state_noise                           0.005
trainer/policy_loss                         -83.4977
trainer/policy_loss_without_entropy          84.2692
trainer/entropy_penalty                      -0.220567
trainer/entropy_percentage                   -0.00261741
trainer/Q1Pred Mean                          82.7608
trainer/Q1Pred Std                           28.0764
trainer/Q1Pred Max                          121.257
trainer/Q1Pred Min                           -6.64283
trainer/Q2Pred Mean                          83.0321
trainer/Q2Pred Std                           28.0284
trainer/Q2Pred Max                          122.682
trainer/Q2Pred Min                           -3.78374
trainer/QTargetWithReg Mean                  82.337
trainer/QTargetWithReg Std                   28.3458
trainer/QTargetWithReg Max                  122.075
trainer/QTargetWithReg Min                   -6.59492
trainer/PolicyLossWithoutReg Mean            84.2692
trainer/PolicyLossWithoutReg Std             26.5455
trainer/PolicyLossWithoutReg Max            121.864
trainer/PolicyLossWithoutReg Min             -4.6138
trainer/gradient_norm                       110.186
trainer/gradient_penalty                     -0.550929
trainer/gradient_percentage                  -0.00653773
exploration/num steps total               52000
exploration/num paths total                 643
exploration/path length this epoch Mean     225.667
exploration/path length this epoch Std       91.2664
exploration/path length this epoch Max      314
exploration/path length this epoch Min      100
exploration/Rewards Mean                      0.516994
exploration/Rewards Std                       1.36634
exploration/Rewards Max                       4.18012
exploration/Rewards Min                      -2.44657
exploration/Returns Mean                    116.668
exploration/Returns Std                     155.835
exploration/Returns Max                     331.665
exploration/Returns Min                     -32.7707
exploration/Num Paths                         3
exploration/Average Returns                 116.668
evaluation_0/num steps total             371405
evaluation_0/num paths total               2473
evaluation_0/path length Mean               293.815
evaluation_0/path length Std                 95.5375
evaluation_0/path length Max                583
evaluation_0/path length Min                203
evaluation_0/Rewards Mean                     1.43937
evaluation_0/Rewards Std                      1.07551
evaluation_0/Rewards Max                      5.64474
evaluation_0/Rewards Min                     -1.38223
evaluation_0/Returns Mean                   422.908
evaluation_0/Returns Std                    103.531
evaluation_0/Returns Max                    714.474
evaluation_0/Returns Min                    167.871
evaluation_0/Num Paths                       27
evaluation_0/Average Returns                422.908
time/epoch (s)                                0
time/total (s)                             1332.87
Epoch                                        47
---------------------------------------  ---------------
2022-11-16 11:08:15.394204 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 48 finished
---------------------------------------  ---------------
epoch                                        48
total_step                                53000
replay_pool/size                          53000
trainer/alpha                                 0.0353635
trainer/alpha_loss                           -0.153885
trainer/entropy                              -5.95396
trainer/qf_loss                               6.86411
trainer/state_noise                           0.005
trainer/policy_loss                         -82.7381
trainer/policy_loss_without_entropy          83.5125
trainer/entropy_penalty                      -0.210553
trainer/entropy_percentage                   -0.00252121
trainer/Q1Pred Mean                          81.9517
trainer/Q1Pred Std                           28.4821
trainer/Q1Pred Max                          124.607
trainer/Q1Pred Min                          -10.6735
trainer/Q2Pred Mean                          82.0571
trainer/Q2Pred Std                           28.3392
trainer/Q2Pred Max                          124.388
trainer/Q2Pred Min                          -16.0797
trainer/QTargetWithReg Mean                  81.7195
trainer/QTargetWithReg Std                   28.8556
trainer/QTargetWithReg Max                  124.383
trainer/QTargetWithReg Min                  -13.1647
trainer/PolicyLossWithoutReg Mean            83.5125
trainer/PolicyLossWithoutReg Std             27.4211
trainer/PolicyLossWithoutReg Max            125.596
trainer/PolicyLossWithoutReg Min            -16.0017
trainer/gradient_norm                       112.768
trainer/gradient_penalty                     -0.56384
trainer/gradient_percentage                  -0.00675156
exploration/num steps total               53000
exploration/num paths total                 647
exploration/path length this epoch Mean     213.5
exploration/path length this epoch Std      131.306
exploration/path length this epoch Max      433
exploration/path length this epoch Min      102
exploration/Rewards Mean                      1.29025
exploration/Rewards Std                       1.40804
exploration/Rewards Max                       5.99618
exploration/Rewards Min                      -1.95516
exploration/Returns Mean                    275.469
exploration/Returns Std                     205.606
exploration/Returns Max                     608.884
exploration/Returns Min                      93.5209
exploration/Num Paths                         4
exploration/Average Returns                 275.469
evaluation_0/num steps total             379327
evaluation_0/num paths total               2548
evaluation_0/path length Mean               105.627
evaluation_0/path length Std                  3.33376
evaluation_0/path length Max                121
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     0.892942
evaluation_0/Rewards Std                      1.45042
evaluation_0/Rewards Max                      4.64218
evaluation_0/Rewards Min                     -2.03735
evaluation_0/Returns Mean                    94.3185
evaluation_0/Returns Std                      7.57174
evaluation_0/Returns Max                    111.346
evaluation_0/Returns Min                     75.4488
evaluation_0/Num Paths                       75
evaluation_0/Average Returns                 94.3185
time/epoch (s)                                0
time/total (s)                             1349.37
Epoch                                        48
---------------------------------------  ---------------
2022-11-16 11:08:32.511891 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 49 finished
---------------------------------------  ---------------
epoch                                        49
total_step                                54000
replay_pool/size                          54000
trainer/alpha                                 0.0361476
trainer/alpha_loss                            0.818221
trainer/entropy                              -6.24643
trainer/qf_loss                               6.12471
trainer/state_noise                           0.005
trainer/policy_loss                         -81.5722
trainer/policy_loss_without_entropy          82.3724
trainer/entropy_penalty                      -0.225794
trainer/entropy_percentage                   -0.00274114
trainer/Q1Pred Mean                          80.5129
trainer/Q1Pred Std                           31.547
trainer/Q1Pred Max                          128.185
trainer/Q1Pred Min                          -13.3626
trainer/Q2Pred Mean                          80.8457
trainer/Q2Pred Std                           31.5678
trainer/Q2Pred Max                          131.155
trainer/Q2Pred Min                           -7.01645
trainer/QTargetWithReg Mean                  80.4074
trainer/QTargetWithReg Std                   31.837
trainer/QTargetWithReg Max                  129.721
trainer/QTargetWithReg Min                  -13.6323
trainer/PolicyLossWithoutReg Mean            82.3724
trainer/PolicyLossWithoutReg Std             29.7512
trainer/PolicyLossWithoutReg Max            129.887
trainer/PolicyLossWithoutReg Min             -8.50447
trainer/gradient_norm                       114.872
trainer/gradient_penalty                     -0.574359
trainer/gradient_percentage                  -0.00697271
exploration/num steps total               54000
exploration/num paths total                 652
exploration/path length this epoch Mean     165.2
exploration/path length this epoch Std       73.5429
exploration/path length this epoch Max      309
exploration/path length this epoch Min      106
exploration/Rewards Mean                      1.22538
exploration/Rewards Std                       1.16075
exploration/Rewards Max                       4.66709
exploration/Rewards Min                      -1.83326
exploration/Returns Mean                    202.433
exploration/Returns Std                     123.666
exploration/Returns Max                     425.345
exploration/Returns Min                      93.1728
exploration/Num Paths                         5
exploration/Average Returns                 202.433
evaluation_0/num steps total             387140
evaluation_0/num paths total               2589
evaluation_0/path length Mean               190.561
evaluation_0/path length Std                 69.7655
evaluation_0/path length Max                390
evaluation_0/path length Min                114
evaluation_0/Rewards Mean                     1.56156
evaluation_0/Rewards Std                      1.26112
evaluation_0/Rewards Max                      6.18608
evaluation_0/Rewards Min                     -2.67218
evaluation_0/Returns Mean                   297.572
evaluation_0/Returns Std                    126.924
evaluation_0/Returns Max                    680.347
evaluation_0/Returns Min                    103.223
evaluation_0/Num Paths                       41
evaluation_0/Average Returns                297.572
time/epoch (s)                                0
time/total (s)                             1366.48
Epoch                                        49
---------------------------------------  ---------------
2022-11-16 11:08:50.411779 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 50 finished
---------------------------------------  ---------------
epoch                                        50
total_step                                55000
replay_pool/size                          55000
trainer/alpha                                 0.0364518
trainer/alpha_loss                           -1.13974
trainer/entropy                              -5.65583
trainer/qf_loss                               5.94127
trainer/state_noise                           0.005
trainer/policy_loss                         -80.9583
trainer/policy_loss_without_entropy          81.7656
trainer/entropy_penalty                      -0.206166
trainer/entropy_percentage                   -0.00252142
trainer/Q1Pred Mean                          81.312
trainer/Q1Pred Std                           29.273
trainer/Q1Pred Max                          125.185
trainer/Q1Pred Min                          -13.1152
trainer/Q2Pred Mean                          80.8696
trainer/Q2Pred Std                           29.1753
trainer/Q2Pred Max                          123.368
trainer/Q2Pred Min                          -10.6579
trainer/QTargetWithReg Mean                  80.6944
trainer/QTargetWithReg Std                   29.6044
trainer/QTargetWithReg Max                  127.117
trainer/QTargetWithReg Min                  -19.904
trainer/PolicyLossWithoutReg Mean            81.7656
trainer/PolicyLossWithoutReg Std             28.4671
trainer/PolicyLossWithoutReg Max            122.874
trainer/PolicyLossWithoutReg Min            -14.8054
trainer/gradient_norm                       120.244
trainer/gradient_penalty                     -0.601221
trainer/gradient_percentage                  -0.00735297
exploration/num steps total               55000
exploration/num paths total                 656
exploration/path length this epoch Mean     172.25
exploration/path length this epoch Std       31.6652
exploration/path length this epoch Max      207
exploration/path length this epoch Min      128
exploration/Rewards Mean                      1.66139
exploration/Rewards Std                       1.25701
exploration/Rewards Max                       5.39604
exploration/Rewards Min                      -1.81006
exploration/Returns Mean                    286.174
exploration/Returns Std                      94.7713
exploration/Returns Max                     370.765
exploration/Returns Min                     125.846
exploration/Num Paths                         4
exploration/Average Returns                 286.174
evaluation_0/num steps total             395033
evaluation_0/num paths total               2618
evaluation_0/path length Mean               272.172
evaluation_0/path length Std                164.051
evaluation_0/path length Max               1000
evaluation_0/path length Min                114
evaluation_0/Rewards Mean                     1.18113
evaluation_0/Rewards Std                      1.12194
evaluation_0/Rewards Max                      6.67725
evaluation_0/Rewards Min                     -3.69741
evaluation_0/Returns Mean                   321.471
evaluation_0/Returns Std                    183.887
evaluation_0/Returns Max                   1020.94
evaluation_0/Returns Min                     56.6915
evaluation_0/Num Paths                       29
evaluation_0/Average Returns                321.471
time/epoch (s)                                0
time/total (s)                             1384.38
Epoch                                        50
---------------------------------------  ---------------
2022-11-16 11:09:07.139947 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 51 finished
---------------------------------------  ---------------
epoch                                        51
total_step                                56000
replay_pool/size                          56000
trainer/alpha                                 0.0368427
trainer/alpha_loss                           -1.30535
trainer/entropy                              -5.60455
trainer/qf_loss                               4.92993
trainer/state_noise                           0.005
trainer/policy_loss                         -81.2441
trainer/policy_loss_without_entropy          82.0336
trainer/entropy_penalty                      -0.206487
trainer/entropy_percentage                   -0.0025171
trainer/Q1Pred Mean                          80.5113
trainer/Q1Pred Std                           29.9288
trainer/Q1Pred Max                          123.141
trainer/Q1Pred Min                          -10.7471
trainer/Q2Pred Mean                          81.0942
trainer/Q2Pred Std                           29.8475
trainer/Q2Pred Max                          123.381
trainer/Q2Pred Min                           -9.56749
trainer/QTargetWithReg Mean                  80.9425
trainer/QTargetWithReg Std                   30.0631
trainer/QTargetWithReg Max                  123.482
trainer/QTargetWithReg Min                  -11.1115
trainer/PolicyLossWithoutReg Mean            82.0336
trainer/PolicyLossWithoutReg Std             29.1519
trainer/PolicyLossWithoutReg Max            123.776
trainer/PolicyLossWithoutReg Min             -8.2254
trainer/gradient_norm                       116.597
trainer/gradient_penalty                     -0.582984
trainer/gradient_percentage                  -0.00710665
exploration/num steps total               56000
exploration/num paths total                 662
exploration/path length this epoch Mean     160.5
exploration/path length this epoch Std       72.2882
exploration/path length this epoch Max      321
exploration/path length this epoch Min      112
exploration/Rewards Mean                      1.58831
exploration/Rewards Std                       1.146
exploration/Rewards Max                       5.11974
exploration/Rewards Min                      -1.91366
exploration/Returns Mean                    254.923
exploration/Returns Std                      90.0249
exploration/Returns Max                     410.327
exploration/Returns Min                     142.556
exploration/Num Paths                         6
exploration/Average Returns                 254.923
evaluation_0/num steps total             402990
evaluation_0/num paths total               2690
evaluation_0/path length Mean               110.514
evaluation_0/path length Std                 19.8571
evaluation_0/path length Max                177
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     1.79601
evaluation_0/Rewards Std                      1.06568
evaluation_0/Rewards Max                      4.94011
evaluation_0/Rewards Min                     -0.298988
evaluation_0/Returns Mean                   198.484
evaluation_0/Returns Std                     42.6373
evaluation_0/Returns Max                    338.717
evaluation_0/Returns Min                    168.101
evaluation_0/Num Paths                       72
evaluation_0/Average Returns                198.484
time/epoch (s)                                0
time/total (s)                             1401.11
Epoch                                        51
---------------------------------------  ---------------
2022-11-16 11:09:23.591092 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 52 finished
---------------------------------------  ---------------
epoch                                        52
total_step                                57000
replay_pool/size                          57000
trainer/alpha                                 0.0384007
trainer/alpha_loss                            0.954983
trainer/entropy                              -6.29295
trainer/qf_loss                              14.9961
trainer/state_noise                           0.005
trainer/policy_loss                         -80.9942
trainer/policy_loss_without_entropy          81.8365
trainer/entropy_penalty                      -0.241654
trainer/entropy_percentage                   -0.00295288
trainer/Q1Pred Mean                          80.6703
trainer/Q1Pred Std                           28.2645
trainer/Q1Pred Max                          123.928
trainer/Q1Pred Min                          -43.018
trainer/Q2Pred Mean                          80.3371
trainer/Q2Pred Std                           28.4595
trainer/Q2Pred Max                          123.263
trainer/Q2Pred Min                          -47.6934
trainer/QTargetWithReg Mean                  80.4584
trainer/QTargetWithReg Std                   28.8546
trainer/QTargetWithReg Max                  123.671
trainer/QTargetWithReg Min                  -48.3461
trainer/PolicyLossWithoutReg Mean            81.8365
trainer/PolicyLossWithoutReg Std             26.7707
trainer/PolicyLossWithoutReg Max            123.95
trainer/PolicyLossWithoutReg Min            -42.6553
trainer/gradient_norm                       120.141
trainer/gradient_penalty                     -0.600705
trainer/gradient_percentage                  -0.0073403
exploration/num steps total               57000
exploration/num paths total                 670
exploration/path length this epoch Mean     119.5
exploration/path length this epoch Std       23.3184
exploration/path length this epoch Max      169
exploration/path length this epoch Min       87
exploration/Rewards Mean                      1.6081
exploration/Rewards Std                       1.02405
exploration/Rewards Max                       4.97725
exploration/Rewards Min                      -1.65108
exploration/Returns Mean                    192.168
exploration/Returns Std                      51.8688
exploration/Returns Max                     315.331
exploration/Returns Min                     131.175
exploration/Num Paths                         8
exploration/Average Returns                 192.168
evaluation_0/num steps total             410917
evaluation_0/num paths total               2763
evaluation_0/path length Mean               108.589
evaluation_0/path length Std                 10.9217
evaluation_0/path length Max                135
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     1.77076
evaluation_0/Rewards Std                      1.0755
evaluation_0/Rewards Max                      4.61648
evaluation_0/Rewards Min                     -0.330024
evaluation_0/Returns Mean                   192.286
evaluation_0/Returns Std                     30.6388
evaluation_0/Returns Max                    258.996
evaluation_0/Returns Min                    157.625
evaluation_0/Num Paths                       73
evaluation_0/Average Returns                192.286
time/epoch (s)                                0
time/total (s)                             1417.56
Epoch                                        52
---------------------------------------  ---------------
2022-11-16 11:09:39.990801 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 53 finished
---------------------------------------  ---------------
epoch                                        53
total_step                                58000
replay_pool/size                          58000
trainer/alpha                                 0.0397087
trainer/alpha_loss                           -0.583478
trainer/entropy                              -5.81915
trainer/qf_loss                               6.01916
trainer/state_noise                           0.005
trainer/policy_loss                         -77.4232
trainer/policy_loss_without_entropy          78.2881
trainer/entropy_penalty                      -0.231071
trainer/entropy_percentage                   -0.00295154
trainer/Q1Pred Mean                          76.4454
trainer/Q1Pred Std                           28.9156
trainer/Q1Pred Max                          129.966
trainer/Q1Pred Min                          -34.8221
trainer/Q2Pred Mean                          76.793
trainer/Q2Pred Std                           28.9313
trainer/Q2Pred Max                          129.508
trainer/Q2Pred Min                          -32.42
trainer/QTargetWithReg Mean                  77.0506
trainer/QTargetWithReg Std                   29.1049
trainer/QTargetWithReg Max                  130.846
trainer/QTargetWithReg Min                  -36.3009
trainer/PolicyLossWithoutReg Mean            78.2881
trainer/PolicyLossWithoutReg Std             28.0667
trainer/PolicyLossWithoutReg Max            129.743
trainer/PolicyLossWithoutReg Min            -34.4656
trainer/gradient_norm                       126.755
trainer/gradient_penalty                     -0.633774
trainer/gradient_percentage                  -0.0080954
exploration/num steps total               58000
exploration/num paths total                 678
exploration/path length this epoch Mean     121.375
exploration/path length this epoch Std       17.0656
exploration/path length this epoch Max      150
exploration/path length this epoch Min       96
exploration/Rewards Mean                      1.77447
exploration/Rewards Std                       1.11169
exploration/Rewards Max                       5.06308
exploration/Rewards Min                      -0.295914
exploration/Returns Mean                    215.377
exploration/Returns Std                      39.3064
exploration/Returns Max                     270.62
exploration/Returns Min                     151.372
exploration/Num Paths                         8
exploration/Average Returns                 215.377
evaluation_0/num steps total             418869
evaluation_0/num paths total               2830
evaluation_0/path length Mean               118.687
evaluation_0/path length Std                 11.7743
evaluation_0/path length Max                160
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     1.89233
evaluation_0/Rewards Std                      1.13936
evaluation_0/Rewards Max                      6.17115
evaluation_0/Rewards Min                     -0.334774
evaluation_0/Returns Mean                   224.594
evaluation_0/Returns Std                     31.7578
evaluation_0/Returns Max                    314.885
evaluation_0/Returns Min                    162.502
evaluation_0/Num Paths                       67
evaluation_0/Average Returns                224.594
time/epoch (s)                                0
time/total (s)                             1433.96
Epoch                                        53
---------------------------------------  ---------------
2022-11-16 11:09:56.415747 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 54 finished
---------------------------------------  ---------------
epoch                                        54
total_step                                59000
replay_pool/size                          59000
trainer/alpha                                 0.0388709
trainer/alpha_loss                           -0.115488
trainer/entropy                              -5.96444
trainer/qf_loss                               7.29412
trainer/state_noise                           0.005
trainer/policy_loss                         -80.4034
trainer/policy_loss_without_entropy          81.25
trainer/entropy_penalty                      -0.231843
trainer/entropy_percentage                   -0.00285346
trainer/Q1Pred Mean                          79.6711
trainer/Q1Pred Std                           31.9558
trainer/Q1Pred Max                          130.034
trainer/Q1Pred Min                          -41.8654
trainer/Q2Pred Mean                          79.9427
trainer/Q2Pred Std                           31.823
trainer/Q2Pred Max                          130.433
trainer/Q2Pred Min                          -37.6641
trainer/QTargetWithReg Mean                  80.2312
trainer/QTargetWithReg Std                   31.5087
trainer/QTargetWithReg Max                  130.986
trainer/QTargetWithReg Min                  -45.3116
trainer/PolicyLossWithoutReg Mean            81.25
trainer/PolicyLossWithoutReg Std             31.2413
trainer/PolicyLossWithoutReg Max            131.555
trainer/PolicyLossWithoutReg Min            -38.7319
trainer/gradient_norm                       122.962
trainer/gradient_penalty                     -0.61481
trainer/gradient_percentage                  -0.00756689
exploration/num steps total               59000
exploration/num paths total                 686
exploration/path length this epoch Mean     121.625
exploration/path length this epoch Std       14.9327
exploration/path length this epoch Max      158
exploration/path length this epoch Min      105
exploration/Rewards Mean                      1.99116
exploration/Rewards Std                       1.21703
exploration/Rewards Max                       5.56851
exploration/Rewards Min                      -0.420018
exploration/Returns Mean                    242.175
exploration/Returns Std                      40.6421
exploration/Returns Max                     331.509
exploration/Returns Min                     190.612
exploration/Num Paths                         8
exploration/Average Returns                 242.175
evaluation_0/num steps total             426843
evaluation_0/num paths total               2898
evaluation_0/path length Mean               117.265
evaluation_0/path length Std                 20.3084
evaluation_0/path length Max                187
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     1.7444
evaluation_0/Rewards Std                      1.14921
evaluation_0/Rewards Max                      6.4137
evaluation_0/Rewards Min                     -0.39523
evaluation_0/Returns Mean                   204.556
evaluation_0/Returns Std                     59.449
evaluation_0/Returns Max                    418.571
evaluation_0/Returns Min                    141.713
evaluation_0/Num Paths                       68
evaluation_0/Average Returns                204.556
time/epoch (s)                                0
time/total (s)                             1450.39
Epoch                                        54
---------------------------------------  ---------------
2022-11-16 11:10:13.652511 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 55 finished
---------------------------------------  ---------------
epoch                                        55
total_step                                60000
replay_pool/size                          60000
trainer/alpha                                 0.0390183
trainer/alpha_loss                            1.75805
trainer/entropy                              -6.54197
trainer/qf_loss                               6.37297
trainer/state_noise                           0.005
trainer/policy_loss                         -76.3929
trainer/policy_loss_without_entropy          77.2907
trainer/entropy_penalty                      -0.255256
trainer/entropy_percentage                   -0.00330255
trainer/Q1Pred Mean                          76.202
trainer/Q1Pred Std                           31.7162
trainer/Q1Pred Max                          135.044
trainer/Q1Pred Min                           -7.87722
trainer/Q2Pred Mean                          75.8048
trainer/Q2Pred Std                           32.0807
trainer/Q2Pred Max                          134.628
trainer/Q2Pred Min                           -7.87126
trainer/QTargetWithReg Mean                  76.4799
trainer/QTargetWithReg Std                   32.066
trainer/QTargetWithReg Max                  135.417
trainer/QTargetWithReg Min                   -8.08278
trainer/PolicyLossWithoutReg Mean            77.2908
trainer/PolicyLossWithoutReg Std             31.013
trainer/PolicyLossWithoutReg Max            136.186
trainer/PolicyLossWithoutReg Min             -5.54544
trainer/gradient_norm                       128.519
trainer/gradient_penalty                     -0.642594
trainer/gradient_percentage                  -0.00831399
exploration/num steps total               60000
exploration/num paths total                 693
exploration/path length this epoch Mean     124.143
exploration/path length this epoch Std       31.2704
exploration/path length this epoch Max      197
exploration/path length this epoch Min       93
exploration/Rewards Mean                      1.88167
exploration/Rewards Std                       1.13727
exploration/Rewards Max                       5.88701
exploration/Rewards Min                      -0.294788
exploration/Returns Mean                    233.596
exploration/Returns Std                      73.6403
exploration/Returns Max                     398.898
exploration/Returns Min                     149.418
exploration/Num Paths                         7
exploration/Average Returns                 233.596
evaluation_0/num steps total             434826
evaluation_0/num paths total               2959
evaluation_0/path length Mean               130.869
evaluation_0/path length Std                 25.8022
evaluation_0/path length Max                199
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     1.91363
evaluation_0/Rewards Std                      1.2483
evaluation_0/Rewards Max                      6.67635
evaluation_0/Rewards Min                     -0.577857
evaluation_0/Returns Mean                   250.435
evaluation_0/Returns Std                     78.174
evaluation_0/Returns Max                    480.978
evaluation_0/Returns Min                    118.621
evaluation_0/Num Paths                       61
evaluation_0/Average Returns                250.435
time/epoch (s)                                0
time/total (s)                             1467.62
Epoch                                        55
---------------------------------------  ---------------
2022-11-16 11:10:29.896295 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 56 finished
---------------------------------------  ---------------
epoch                                        56
total_step                                61000
replay_pool/size                          61000
trainer/alpha                                 0.0389067
trainer/alpha_loss                            0.291641
trainer/entropy                              -6.08983
trainer/qf_loss                               5.61805
trainer/state_noise                           0.005
trainer/policy_loss                         -77.2121
trainer/policy_loss_without_entropy          78.0611
trainer/entropy_penalty                      -0.236935
trainer/entropy_percentage                   -0.00303526
trainer/Q1Pred Mean                          76.2204
trainer/Q1Pred Std                           31.5077
trainer/Q1Pred Max                          124.079
trainer/Q1Pred Min                           -3.73991
trainer/Q2Pred Mean                          76.3809
trainer/Q2Pred Std                           31.3508
trainer/Q2Pred Max                          124.679
trainer/Q2Pred Min                            1.6226
trainer/QTargetWithReg Mean                  76.6552
trainer/QTargetWithReg Std                   31.5224
trainer/QTargetWithReg Max                  126.588
trainer/QTargetWithReg Min                    0.775109
trainer/PolicyLossWithoutReg Mean            78.0611
trainer/PolicyLossWithoutReg Std             30.3473
trainer/PolicyLossWithoutReg Max            125.952
trainer/PolicyLossWithoutReg Min              1.28216
trainer/gradient_norm                       122.404
trainer/gradient_penalty                     -0.612022
trainer/gradient_percentage                  -0.00784029
exploration/num steps total               61000
exploration/num paths total                 700
exploration/path length this epoch Mean     126
exploration/path length this epoch Std       17.337
exploration/path length this epoch Max      151
exploration/path length this epoch Min       93
exploration/Rewards Mean                      1.8549
exploration/Rewards Std                       1.23271
exploration/Rewards Max                       5.34815
exploration/Rewards Min                      -1.27964
exploration/Returns Mean                    233.717
exploration/Returns Std                      56.5414
exploration/Returns Max                     316.912
exploration/Returns Min                     161.251
exploration/Num Paths                         7
exploration/Average Returns                 233.717
evaluation_0/num steps total             442753
evaluation_0/num paths total               3025
evaluation_0/path length Mean               120.106
evaluation_0/path length Std                 16.8848
evaluation_0/path length Max                208
evaluation_0/path length Min                104
evaluation_0/Rewards Mean                     1.7127
evaluation_0/Rewards Std                      1.21817
evaluation_0/Rewards Max                      6.40447
evaluation_0/Rewards Min                     -0.155632
evaluation_0/Returns Mean                   205.706
evaluation_0/Returns Std                     50.467
evaluation_0/Returns Max                    394.662
evaluation_0/Returns Min                    150.282
evaluation_0/Num Paths                       66
evaluation_0/Average Returns                205.706
time/epoch (s)                                0
time/total (s)                             1483.87
Epoch                                        56
---------------------------------------  ---------------
2022-11-16 11:10:47.137020 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 57 finished
---------------------------------------  ---------------
epoch                                        57
total_step                                62000
replay_pool/size                          62000
trainer/alpha                                 0.0392985
trainer/alpha_loss                            0.775621
trainer/entropy                              -6.23962
trainer/qf_loss                               5.77028
trainer/state_noise                           0.005
trainer/policy_loss                         -77.8572
trainer/policy_loss_without_entropy          78.6992
trainer/entropy_penalty                      -0.245208
trainer/entropy_percentage                   -0.00311576
trainer/Q1Pred Mean                          77.1195
trainer/Q1Pred Std                           30.2935
trainer/Q1Pred Max                          126.922
trainer/Q1Pred Min                          -12.7902
trainer/Q2Pred Mean                          77.4571
trainer/Q2Pred Std                           29.9205
trainer/Q2Pred Max                          127.077
trainer/Q2Pred Min                          -10.9435
trainer/QTargetWithReg Mean                  77.0406
trainer/QTargetWithReg Std                   29.7002
trainer/QTargetWithReg Max                  126.048
trainer/QTargetWithReg Min                   -8.28954
trainer/PolicyLossWithoutReg Mean            78.6993
trainer/PolicyLossWithoutReg Std             29.3864
trainer/PolicyLossWithoutReg Max            127.012
trainer/PolicyLossWithoutReg Min             -7.83882
trainer/gradient_norm                       119.375
trainer/gradient_penalty                     -0.596876
trainer/gradient_percentage                  -0.00758427
exploration/num steps total               62000
exploration/num paths total                 707
exploration/path length this epoch Mean     128.571
exploration/path length this epoch Std       25.2465
exploration/path length this epoch Max      188
exploration/path length this epoch Min      107
exploration/Rewards Mean                      1.78794
exploration/Rewards Std                       1.12052
exploration/Rewards Max                       5.95237
exploration/Rewards Min                      -0.352288
exploration/Returns Mean                    229.877
exploration/Returns Std                      48.778
exploration/Returns Max                     337.617
exploration/Returns Min                     190.566
exploration/Num Paths                         7
exploration/Average Returns                 229.877
evaluation_0/num steps total             450750
evaluation_0/num paths total               3082
evaluation_0/path length Mean               140.298
evaluation_0/path length Std                 29.4386
evaluation_0/path length Max                208
evaluation_0/path length Min                 93
evaluation_0/Rewards Mean                     1.81299
evaluation_0/Rewards Std                      1.19147
evaluation_0/Rewards Max                      6.15118
evaluation_0/Rewards Min                     -0.308633
evaluation_0/Returns Mean                   254.359
evaluation_0/Returns Std                     77.156
evaluation_0/Returns Max                    460.727
evaluation_0/Returns Min                    130.798
evaluation_0/Num Paths                       57
evaluation_0/Average Returns                254.359
time/epoch (s)                                0
time/total (s)                             1501.11
Epoch                                        57
---------------------------------------  ---------------
2022-11-16 11:11:03.908502 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 58 finished
---------------------------------------  ---------------
epoch                                        58
total_step                                63000
replay_pool/size                          63000
trainer/alpha                                 0.0397493
trainer/alpha_loss                           -0.833476
trainer/entropy                              -5.74157
trainer/qf_loss                               5.85079
trainer/state_noise                           0.005
trainer/policy_loss                         -74.9448
trainer/policy_loss_without_entropy          75.8153
trainer/entropy_penalty                      -0.228223
trainer/entropy_percentage                   -0.00301025
trainer/Q1Pred Mean                          74.1497
trainer/Q1Pred Std                           29.9716
trainer/Q1Pred Max                          128.798
trainer/Q1Pred Min                           -7.23541
trainer/Q2Pred Mean                          74.0289
trainer/Q2Pred Std                           29.8403
trainer/Q2Pred Max                          125.52
trainer/Q2Pred Min                           -6.33133
trainer/QTargetWithReg Mean                  74.3862
trainer/QTargetWithReg Std                   30.0242
trainer/QTargetWithReg Max                  127.812
trainer/QTargetWithReg Min                   -4.65023
trainer/PolicyLossWithoutReg Mean            75.8153
trainer/PolicyLossWithoutReg Std             29.044
trainer/PolicyLossWithoutReg Max            127.186
trainer/PolicyLossWithoutReg Min             -7.67536
trainer/gradient_norm                       128.442
trainer/gradient_penalty                     -0.64221
trainer/gradient_percentage                  -0.00847072
exploration/num steps total               63000
exploration/num paths total                 715
exploration/path length this epoch Mean     123.125
exploration/path length this epoch Std       15.0701
exploration/path length this epoch Max      155
exploration/path length this epoch Min      109
exploration/Rewards Mean                      1.9864
exploration/Rewards Std                       1.24198
exploration/Rewards Max                       6.13776
exploration/Rewards Min                      -0.433217
exploration/Returns Mean                    244.575
exploration/Returns Std                      46.3022
exploration/Returns Max                     308.483
exploration/Returns Min                     167.517
exploration/Num Paths                         8
exploration/Average Returns                 244.575
evaluation_0/num steps total             458690
evaluation_0/num paths total               3149
evaluation_0/path length Mean               118.507
evaluation_0/path length Std                 35.7943
evaluation_0/path length Max                230
evaluation_0/path length Min                 72
evaluation_0/Rewards Mean                     1.72079
evaluation_0/Rewards Std                      0.966273
evaluation_0/Rewards Max                      6.10288
evaluation_0/Rewards Min                     -0.218615
evaluation_0/Returns Mean                   203.926
evaluation_0/Returns Std                     78.0771
evaluation_0/Returns Max                    525.45
evaluation_0/Returns Min                    121.011
evaluation_0/Num Paths                       67
evaluation_0/Average Returns                203.926
time/epoch (s)                                0
time/total (s)                             1517.88
Epoch                                        58
---------------------------------------  ---------------
2022-11-16 11:11:20.908379 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 59 finished
---------------------------------------  ---------------
epoch                                        59
total_step                                64000
replay_pool/size                          64000
trainer/alpha                                 0.038376
trainer/alpha_loss                            1.91457
trainer/entropy                              -6.5872
trainer/qf_loss                               6.32013
trainer/state_noise                           0.005
trainer/policy_loss                         -73.7011
trainer/policy_loss_without_entropy          74.6265
trainer/entropy_penalty                      -0.252791
trainer/entropy_percentage                   -0.00338741
trainer/Q1Pred Mean                          72.9078
trainer/Q1Pred Std                           32.4714
trainer/Q1Pred Max                          127.892
trainer/Q1Pred Min                          -46.3135
trainer/Q2Pred Mean                          73.3893
trainer/Q2Pred Std                           32.2883
trainer/Q2Pred Max                          127.898
trainer/Q2Pred Min                          -44.0677
trainer/QTargetWithReg Mean                  73.3761
trainer/QTargetWithReg Std                   32.3544
trainer/QTargetWithReg Max                  128.937
trainer/QTargetWithReg Min                  -42.1461
trainer/PolicyLossWithoutReg Mean            74.6265
trainer/PolicyLossWithoutReg Std             31.7824
trainer/PolicyLossWithoutReg Max            128.455
trainer/PolicyLossWithoutReg Min            -44.1531
trainer/gradient_norm                       134.514
trainer/gradient_penalty                     -0.672571
trainer/gradient_percentage                  -0.00901249
exploration/num steps total               64000
exploration/num paths total                 721
exploration/path length this epoch Mean     136.5
exploration/path length this epoch Std       19.1725
exploration/path length this epoch Max      163
exploration/path length this epoch Min      114
exploration/Rewards Mean                      1.99128
exploration/Rewards Std                       1.19021
exploration/Rewards Max                       5.22051
exploration/Rewards Min                      -0.471569
exploration/Returns Mean                    271.81
exploration/Returns Std                      68.4466
exploration/Returns Max                     384.352
exploration/Returns Min                     204.529
exploration/Num Paths                         6
exploration/Average Returns                 271.81
evaluation_0/num steps total             466676
evaluation_0/num paths total               3203
evaluation_0/path length Mean               147.889
evaluation_0/path length Std                 38.4451
evaluation_0/path length Max                239
evaluation_0/path length Min                 73
evaluation_0/Rewards Mean                     1.73652
evaluation_0/Rewards Std                      1.16594
evaluation_0/Rewards Max                      6.52492
evaluation_0/Rewards Min                     -1.72371
evaluation_0/Returns Mean                   256.812
evaluation_0/Returns Std                    107.48
evaluation_0/Returns Max                    534.089
evaluation_0/Returns Min                    110.32
evaluation_0/Num Paths                       54
evaluation_0/Average Returns                256.812
time/epoch (s)                                0
time/total (s)                             1534.88
Epoch                                        59
---------------------------------------  ---------------
2022-11-16 11:11:37.214121 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 60 finished
---------------------------------------  ---------------
epoch                                        60
total_step                                65000
replay_pool/size                          65000
trainer/alpha                                 0.0374769
trainer/alpha_loss                           -0.279992
trainer/entropy                              -5.91474
trainer/qf_loss                               4.33996
trainer/state_noise                           0.005
trainer/policy_loss                         -77.7135
trainer/policy_loss_without_entropy          78.547
trainer/entropy_penalty                      -0.221666
trainer/entropy_percentage                   -0.00282208
trainer/Q1Pred Mean                          78.237
trainer/Q1Pred Std                           29.1614
trainer/Q1Pred Max                          129.302
trainer/Q1Pred Min                           -5.4496
trainer/Q2Pred Mean                          78.2204
trainer/Q2Pred Std                           29.1186
trainer/Q2Pred Max                          126.742
trainer/Q2Pred Min                           -4.42879
trainer/QTargetWithReg Mean                  77.7133
trainer/QTargetWithReg Std                   29.2502
trainer/QTargetWithReg Max                  127.265
trainer/QTargetWithReg Min                   -4.18032
trainer/PolicyLossWithoutReg Mean            78.547
trainer/PolicyLossWithoutReg Std             28.6226
trainer/PolicyLossWithoutReg Max            127.508
trainer/PolicyLossWithoutReg Min             -0.841464
trainer/gradient_norm                       122.379
trainer/gradient_penalty                     -0.611893
trainer/gradient_percentage                  -0.00779015
exploration/num steps total               65000
exploration/num paths total                 727
exploration/path length this epoch Mean     148.333
exploration/path length this epoch Std       27.4995
exploration/path length this epoch Max      206
exploration/path length this epoch Min      125
exploration/Rewards Mean                      1.90499
exploration/Rewards Std                       1.23944
exploration/Rewards Max                       6.10962
exploration/Rewards Min                      -0.636216
exploration/Returns Mean                    282.574
exploration/Returns Std                      82.1854
exploration/Returns Max                     441.064
exploration/Returns Min                     166.782
exploration/Num Paths                         6
exploration/Average Returns                 282.574
evaluation_0/num steps total             474552
evaluation_0/num paths total               3247
evaluation_0/path length Mean               179
evaluation_0/path length Std                 28.3389
evaluation_0/path length Max                228
evaluation_0/path length Min                 94
evaluation_0/Rewards Mean                     1.83381
evaluation_0/Rewards Std                      1.27905
evaluation_0/Rewards Max                      6.65599
evaluation_0/Rewards Min                     -0.734008
evaluation_0/Returns Mean                   328.252
evaluation_0/Returns Std                     83.0932
evaluation_0/Returns Max                    477.218
evaluation_0/Returns Min                     82.3843
evaluation_0/Num Paths                       44
evaluation_0/Average Returns                328.252
time/epoch (s)                                0
time/total (s)                             1551.18
Epoch                                        60
---------------------------------------  ---------------
2022-11-16 11:11:54.261480 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 61 finished
---------------------------------------  ---------------
epoch                                        61
total_step                                66000
replay_pool/size                          66000
trainer/alpha                                 0.0373166
trainer/alpha_loss                            2.30601
trainer/entropy                              -6.70126
trainer/qf_loss                               5.82938
trainer/state_noise                           0.005
trainer/policy_loss                         -75.1537
trainer/policy_loss_without_entropy          76.0683
trainer/entropy_penalty                      -0.250068
trainer/entropy_percentage                   -0.00328741
trainer/Q1Pred Mean                          75.461
trainer/Q1Pred Std                           28.6307
trainer/Q1Pred Max                          127.018
trainer/Q1Pred Min                           -4.81122
trainer/Q2Pred Mean                          75.5169
trainer/Q2Pred Std                           28.6505
trainer/Q2Pred Max                          127.825
trainer/Q2Pred Min                           -1.2189
trainer/QTargetWithReg Mean                  75.3988
trainer/QTargetWithReg Std                   28.5129
trainer/QTargetWithReg Max                  127.5
trainer/QTargetWithReg Min                   -1.13169
trainer/PolicyLossWithoutReg Mean            76.0683
trainer/PolicyLossWithoutReg Std             28.1056
trainer/PolicyLossWithoutReg Max            128.463
trainer/PolicyLossWithoutReg Min             -7.72166
trainer/gradient_norm                       132.907
trainer/gradient_penalty                     -0.664536
trainer/gradient_percentage                  -0.00873605
exploration/num steps total               66000
exploration/num paths total                 734
exploration/path length this epoch Mean     139
exploration/path length this epoch Std       26.576
exploration/path length this epoch Max      186
exploration/path length this epoch Min      102
exploration/Rewards Mean                      1.90343
exploration/Rewards Std                       1.16569
exploration/Rewards Max                       5.93984
exploration/Rewards Min                      -0.613978
exploration/Returns Mean                    264.576
exploration/Returns Std                      47.5927
exploration/Returns Max                     308.713
exploration/Returns Min                     175.984
exploration/Num Paths                         7
exploration/Average Returns                 264.576
evaluation_0/num steps total             482551
evaluation_0/num paths total               3303
evaluation_0/path length Mean               142.839
evaluation_0/path length Std                 33.5441
evaluation_0/path length Max                273
evaluation_0/path length Min                 91
evaluation_0/Rewards Mean                     1.92422
evaluation_0/Rewards Std                      1.25845
evaluation_0/Rewards Max                      7.22004
evaluation_0/Rewards Min                     -1.54317
evaluation_0/Returns Mean                   274.855
evaluation_0/Returns Std                     76.674
evaluation_0/Returns Max                    456.804
evaluation_0/Returns Min                    139.525
evaluation_0/Num Paths                       56
evaluation_0/Average Returns                274.855
time/epoch (s)                                0
time/total (s)                             1568.23
Epoch                                        61
---------------------------------------  ---------------
2022-11-16 11:12:11.132588 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 62 finished
---------------------------------------  ---------------
epoch                                        62
total_step                                67000
replay_pool/size                          67000
trainer/alpha                                 0.036663
trainer/alpha_loss                           -0.173917
trainer/entropy                              -5.94739
trainer/qf_loss                               6.34143
trainer/state_noise                           0.005
trainer/policy_loss                         -76.1395
trainer/policy_loss_without_entropy          77.0001
trainer/entropy_penalty                      -0.218049
trainer/entropy_percentage                   -0.00283181
trainer/Q1Pred Mean                          75.4757
trainer/Q1Pred Std                           31.7329
trainer/Q1Pred Max                          128.708
trainer/Q1Pred Min                          -39.8898
trainer/Q2Pred Mean                          75.1531
trainer/Q2Pred Std                           31.935
trainer/Q2Pred Max                          127.48
trainer/Q2Pred Min                          -39.2611
trainer/QTargetWithReg Mean                  75.5198
trainer/QTargetWithReg Std                   32.0766
trainer/QTargetWithReg Max                  128.913
trainer/QTargetWithReg Min                  -44.9301
trainer/PolicyLossWithoutReg Mean            77.0001
trainer/PolicyLossWithoutReg Std             30.1711
trainer/PolicyLossWithoutReg Max            127.752
trainer/PolicyLossWithoutReg Min            -41.4734
trainer/gradient_norm                       128.519
trainer/gradient_penalty                     -0.642595
trainer/gradient_percentage                  -0.00834538
exploration/num steps total               67000
exploration/num paths total                 741
exploration/path length this epoch Mean     141.571
exploration/path length this epoch Std       41.4103
exploration/path length this epoch Max      211
exploration/path length this epoch Min       74
exploration/Rewards Mean                      2.14056
exploration/Rewards Std                       1.39256
exploration/Rewards Max                       6.0576
exploration/Rewards Min                      -1.7576
exploration/Returns Mean                    303.042
exploration/Returns Std                     121.653
exploration/Returns Max                     470.906
exploration/Returns Min                      59.4219
exploration/Num Paths                         7
exploration/Average Returns                 303.042
evaluation_0/num steps total             490460
evaluation_0/num paths total               3351
evaluation_0/path length Mean               164.771
evaluation_0/path length Std                 34.2133
evaluation_0/path length Max                278
evaluation_0/path length Min                 97
evaluation_0/Rewards Mean                     2.06177
evaluation_0/Rewards Std                      1.19248
evaluation_0/Rewards Max                      6.65716
evaluation_0/Rewards Min                     -0.620487
evaluation_0/Returns Mean                   339.719
evaluation_0/Returns Std                     83.9159
evaluation_0/Returns Max                    519.998
evaluation_0/Returns Min                     67.9373
evaluation_0/Num Paths                       48
evaluation_0/Average Returns                339.719
time/epoch (s)                                0
time/total (s)                             1585.1
Epoch                                        62
---------------------------------------  ---------------
2022-11-16 11:12:27.521444 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 63 finished
---------------------------------------  ---------------
epoch                                        63
total_step                                68000
replay_pool/size                          68000
trainer/alpha                                 0.0371162
trainer/alpha_loss                            1.22229
trainer/entropy                              -6.37109
trainer/qf_loss                               6.57363
trainer/state_noise                           0.005
trainer/policy_loss                         -74.2396
trainer/policy_loss_without_entropy          75.1297
trainer/entropy_penalty                      -0.23647
trainer/entropy_percentage                   -0.0031475
trainer/Q1Pred Mean                          73.8914
trainer/Q1Pred Std                           30.4181
trainer/Q1Pred Max                          130.293
trainer/Q1Pred Min                          -13.5099
trainer/Q2Pred Mean                          73.5727
trainer/Q2Pred Std                           29.6753
trainer/Q2Pred Max                          130.294
trainer/Q2Pred Min                           -8.98664
trainer/QTargetWithReg Mean                  73.9763
trainer/QTargetWithReg Std                   30.4584
trainer/QTargetWithReg Max                  131.802
trainer/QTargetWithReg Min                  -10.8116
trainer/PolicyLossWithoutReg Mean            75.1296
trainer/PolicyLossWithoutReg Std             28.7765
trainer/PolicyLossWithoutReg Max            130.585
trainer/PolicyLossWithoutReg Min             -6.7405
trainer/gradient_norm                       130.714
trainer/gradient_penalty                     -0.653571
trainer/gradient_percentage                  -0.00869925
exploration/num steps total               68000
exploration/num paths total                 748
exploration/path length this epoch Mean     132.429
exploration/path length this epoch Std       29.8274
exploration/path length this epoch Max      179
exploration/path length this epoch Min       89
exploration/Rewards Mean                      2.16
exploration/Rewards Std                       1.4707
exploration/Rewards Max                       5.8712
exploration/Rewards Min                      -1.05423
exploration/Returns Mean                    286.046
exploration/Returns Std                      63.6985
exploration/Returns Max                     389.249
exploration/Returns Min                     193.552
exploration/Num Paths                         7
exploration/Average Returns                 286.046
evaluation_0/num steps total             498381
evaluation_0/num paths total               3438
evaluation_0/path length Mean                91.046
evaluation_0/path length Std                 15.4443
evaluation_0/path length Max                153
evaluation_0/path length Min                 70
evaluation_0/Rewards Mean                     2.13452
evaluation_0/Rewards Std                      1.58044
evaluation_0/Rewards Max                      5.71853
evaluation_0/Rewards Min                     -3.02122
evaluation_0/Returns Mean                   194.34
evaluation_0/Returns Std                     45.2835
evaluation_0/Returns Max                    347.487
evaluation_0/Returns Min                     91.7417
evaluation_0/Num Paths                       87
evaluation_0/Average Returns                194.34
time/epoch (s)                                0
time/total (s)                             1601.49
Epoch                                        63
---------------------------------------  ---------------
2022-11-16 11:12:46.119017 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 64 finished
---------------------------------------  ---------------
epoch                                        64
total_step                                69000
replay_pool/size                          69000
trainer/alpha                                 0.0361047
trainer/alpha_loss                            0.791783
trainer/entropy                              -6.23839
trainer/qf_loss                               6.77628
trainer/state_noise                           0.005
trainer/policy_loss                         -73.4879
trainer/policy_loss_without_entropy          74.369
trainer/entropy_penalty                      -0.225235
trainer/entropy_percentage                   -0.00302862
trainer/Q1Pred Mean                          73.3817
trainer/Q1Pred Std                           30.0297
trainer/Q1Pred Max                          125.198
trainer/Q1Pred Min                           -8.67882
trainer/Q2Pred Mean                          73.2235
trainer/Q2Pred Std                           30.2231
trainer/Q2Pred Max                          125.877
trainer/Q2Pred Min                          -12.0109
trainer/QTargetWithReg Mean                  73.4663
trainer/QTargetWithReg Std                   30.1788
trainer/QTargetWithReg Max                  125.965
trainer/QTargetWithReg Min                  -11.4891
trainer/PolicyLossWithoutReg Mean            74.369
trainer/PolicyLossWithoutReg Std             29.6719
trainer/PolicyLossWithoutReg Max            125.61
trainer/PolicyLossWithoutReg Min            -11.9239
trainer/gradient_norm                       131.17
trainer/gradient_penalty                     -0.65585
trainer/gradient_percentage                  -0.00881886
exploration/num steps total               69000
exploration/num paths total                 755
exploration/path length this epoch Mean     137.286
exploration/path length this epoch Std       19.5427
exploration/path length this epoch Max      163
exploration/path length this epoch Min      106
exploration/Rewards Mean                      2.19448
exploration/Rewards Std                       1.39406
exploration/Rewards Max                       6.23857
exploration/Rewards Min                      -0.512014
exploration/Returns Mean                    301.271
exploration/Returns Std                      57.576
exploration/Returns Max                     373.821
exploration/Returns Min                     217.196
exploration/Num Paths                         7
exploration/Average Returns                 301.271
evaluation_0/num steps total             506292
evaluation_0/num paths total               3464
evaluation_0/path length Mean               304.269
evaluation_0/path length Std                300.359
evaluation_0/path length Max               1000
evaluation_0/path length Min                120
evaluation_0/Rewards Mean                     1.66341
evaluation_0/Rewards Std                      1.16406
evaluation_0/Rewards Max                      7.04757
evaluation_0/Rewards Min                     -0.243712
evaluation_0/Returns Mean                   506.125
evaluation_0/Returns Std                    299.364
evaluation_0/Returns Max                   1134.1
evaluation_0/Returns Min                    241.412
evaluation_0/Num Paths                       26
evaluation_0/Average Returns                506.125
time/epoch (s)                                0
time/total (s)                             1620.09
Epoch                                        64
---------------------------------------  ---------------
2022-11-16 11:13:03.006104 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 65 finished
---------------------------------------  ---------------
epoch                                        65
total_step                                70000
replay_pool/size                          70000
trainer/alpha                                 0.0369749
trainer/alpha_loss                            1.18212
trainer/entropy                              -6.35849
trainer/qf_loss                               4.18911
trainer/state_noise                           0.005
trainer/policy_loss                         -78.3258
trainer/policy_loss_without_entropy          79.2203
trainer/entropy_penalty                      -0.235105
trainer/entropy_percentage                   -0.00296773
trainer/Q1Pred Mean                          78.4706
trainer/Q1Pred Std                           28.0693
trainer/Q1Pred Max                          136.394
trainer/Q1Pred Min                          -15.5509
trainer/Q2Pred Mean                          78.1446
trainer/Q2Pred Std                           28.0248
trainer/Q2Pred Max                          131.921
trainer/Q2Pred Min                          -15.273
trainer/QTargetWithReg Mean                  78.0658
trainer/QTargetWithReg Std                   27.965
trainer/QTargetWithReg Max                  135.133
trainer/QTargetWithReg Min                  -19.582
trainer/PolicyLossWithoutReg Mean            79.2203
trainer/PolicyLossWithoutReg Std             27.418
trainer/PolicyLossWithoutReg Max            133.457
trainer/PolicyLossWithoutReg Min            -10.1757
trainer/gradient_norm                       131.871
trainer/gradient_penalty                     -0.659355
trainer/gradient_percentage                  -0.00832305
exploration/num steps total               70000
exploration/num paths total                 760
exploration/path length this epoch Mean     172.8
exploration/path length this epoch Std       64.7284
exploration/path length this epoch Max      287
exploration/path length this epoch Min      105
exploration/Rewards Mean                      1.96373
exploration/Rewards Std                       1.30687
exploration/Rewards Max                       5.31337
exploration/Rewards Min                      -0.346329
exploration/Returns Mean                    339.332
exploration/Returns Std                      99.036
exploration/Returns Max                     470.602
exploration/Returns Min                     222.849
exploration/Num Paths                         5
exploration/Average Returns                 339.332
evaluation_0/num steps total             514262
evaluation_0/num paths total               3497
evaluation_0/path length Mean               241.515
evaluation_0/path length Std                 61.6167
evaluation_0/path length Max                506
evaluation_0/path length Min                171
evaluation_0/Rewards Mean                     1.3153
evaluation_0/Rewards Std                      1.43378
evaluation_0/Rewards Max                      6.52428
evaluation_0/Rewards Min                     -5.59912
evaluation_0/Returns Mean                   317.665
evaluation_0/Returns Std                     87.1928
evaluation_0/Returns Max                    658.489
evaluation_0/Returns Min                    136
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                317.665
time/epoch (s)                                0
time/total (s)                             1636.97
Epoch                                        65
---------------------------------------  ---------------
2022-11-16 11:13:20.620513 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 66 finished
---------------------------------------  ---------------
epoch                                        66
total_step                                71000
replay_pool/size                          71000
trainer/alpha                                 0.0360031
trainer/alpha_loss                            1.75046
trainer/entropy                              -6.52654
trainer/qf_loss                               5.74903
trainer/state_noise                           0.005
trainer/policy_loss                         -75.2662
trainer/policy_loss_without_entropy          76.1774
trainer/entropy_penalty                      -0.234975
trainer/entropy_percentage                   -0.00308458
trainer/Q1Pred Mean                          74.9861
trainer/Q1Pred Std                           28.06
trainer/Q1Pred Max                          122.819
trainer/Q1Pred Min                           -8.34212
trainer/Q2Pred Mean                          75.2853
trainer/Q2Pred Std                           28.0156
trainer/Q2Pred Max                          126.976
trainer/Q2Pred Min                           -7.20676
trainer/QTargetWithReg Mean                  74.7816
trainer/QTargetWithReg Std                   28.2383
trainer/QTargetWithReg Max                  126.373
trainer/QTargetWithReg Min                  -10.594
trainer/PolicyLossWithoutReg Mean            76.1774
trainer/PolicyLossWithoutReg Std             27.35
trainer/PolicyLossWithoutReg Max            123.821
trainer/PolicyLossWithoutReg Min             -7.08095
trainer/gradient_norm                       135.237
trainer/gradient_penalty                     -0.676183
trainer/gradient_percentage                  -0.00887643
exploration/num steps total               71000
exploration/num paths total                 766
exploration/path length this epoch Mean     145.333
exploration/path length this epoch Std       30.2581
exploration/path length this epoch Max      208
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.09384
exploration/Rewards Std                       1.38791
exploration/Rewards Max                       5.7593
exploration/Rewards Min                      -0.708067
exploration/Returns Mean                    304.305
exploration/Returns Std                      91.6743
exploration/Returns Max                     484.101
exploration/Returns Min                     186.184
exploration/Num Paths                         6
exploration/Average Returns                 304.305
evaluation_0/num steps total             522229
evaluation_0/num paths total               3547
evaluation_0/path length Mean               159.34
evaluation_0/path length Std                 63.0123
evaluation_0/path length Max                452
evaluation_0/path length Min                 70
evaluation_0/Rewards Mean                     2.02928
evaluation_0/Rewards Std                      1.30181
evaluation_0/Rewards Max                      6.35952
evaluation_0/Rewards Min                     -3.47883
evaluation_0/Returns Mean                   323.345
evaluation_0/Returns Std                     85.7039
evaluation_0/Returns Max                    547.425
evaluation_0/Returns Min                     88.6829
evaluation_0/Num Paths                       50
evaluation_0/Average Returns                323.345
time/epoch (s)                                0
time/total (s)                             1654.59
Epoch                                        66
---------------------------------------  ---------------
2022-11-16 11:13:37.559787 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 67 finished
---------------------------------------  ---------------
epoch                                        67
total_step                                72000
replay_pool/size                          72000
trainer/alpha                                 0.0356632
trainer/alpha_loss                           -0.474049
trainer/entropy                              -5.8578
trainer/qf_loss                               5.76941
trainer/state_noise                           0.005
trainer/policy_loss                         -78.727
trainer/policy_loss_without_entropy          79.5736
trainer/entropy_penalty                      -0.208908
trainer/entropy_percentage                   -0.00262534
trainer/Q1Pred Mean                          78.668
trainer/Q1Pred Std                           27.4755
trainer/Q1Pred Max                          125.546
trainer/Q1Pred Min                          -21.2245
trainer/Q2Pred Mean                          78.316
trainer/Q2Pred Std                           27.5948
trainer/Q2Pred Max                          123.767
trainer/Q2Pred Min                          -27.4817
trainer/QTargetWithReg Mean                  79.2186
trainer/QTargetWithReg Std                   27.4827
trainer/QTargetWithReg Max                  124.605
trainer/QTargetWithReg Min                  -28.6466
trainer/PolicyLossWithoutReg Mean            79.5736
trainer/PolicyLossWithoutReg Std             26.8237
trainer/PolicyLossWithoutReg Max            124.304
trainer/PolicyLossWithoutReg Min            -18.956
trainer/gradient_norm                       127.542
trainer/gradient_penalty                     -0.637712
trainer/gradient_percentage                  -0.00801412
exploration/num steps total               72000
exploration/num paths total                 771
exploration/path length this epoch Mean     172.8
exploration/path length this epoch Std       42.7757
exploration/path length this epoch Max      258
exploration/path length this epoch Min      145
exploration/Rewards Mean                      1.69982
exploration/Rewards Std                       1.44748
exploration/Rewards Max                       5.26051
exploration/Rewards Min                      -2.24965
exploration/Returns Mean                    293.728
exploration/Returns Std                      97.4457
exploration/Returns Max                     392.437
exploration/Returns Min                     123.561
exploration/Num Paths                         5
exploration/Average Returns                 293.728
evaluation_0/num steps total             529968
evaluation_0/num paths total               3587
evaluation_0/path length Mean               193.475
evaluation_0/path length Std                 47.0223
evaluation_0/path length Max                320
evaluation_0/path length Min                131
evaluation_0/Rewards Mean                     1.69701
evaluation_0/Rewards Std                      1.25933
evaluation_0/Rewards Max                      5.98224
evaluation_0/Rewards Min                     -1.68475
evaluation_0/Returns Mean                   328.328
evaluation_0/Returns Std                     83.5595
evaluation_0/Returns Max                    484.572
evaluation_0/Returns Min                    156.09
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                328.328
time/epoch (s)                                0
time/total (s)                             1671.53
Epoch                                        67
---------------------------------------  ---------------
2022-11-16 11:13:54.440067 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 68 finished
---------------------------------------  ---------------
epoch                                        68
total_step                                73000
replay_pool/size                          73000
trainer/alpha                                 0.0353618
trainer/alpha_loss                            0.0687199
trainer/entropy                              -6.02056
trainer/qf_loss                               4.93108
trainer/state_noise                           0.005
trainer/policy_loss                         -75.4241
trainer/policy_loss_without_entropy          76.2652
trainer/entropy_penalty                      -0.212898
trainer/entropy_percentage                   -0.00279155
trainer/Q1Pred Mean                          75.2399
trainer/Q1Pred Std                           30.4974
trainer/Q1Pred Max                          130.847
trainer/Q1Pred Min                          -13.537
trainer/Q2Pred Mean                          74.9972
trainer/Q2Pred Std                           30.5592
trainer/Q2Pred Max                          132.8
trainer/Q2Pred Min                          -12.6207
trainer/QTargetWithReg Mean                  74.82
trainer/QTargetWithReg Std                   30.4615
trainer/QTargetWithReg Max                  132.254
trainer/QTargetWithReg Min                  -11.1706
trainer/PolicyLossWithoutReg Mean            76.2652
trainer/PolicyLossWithoutReg Std             29.8014
trainer/PolicyLossWithoutReg Max            129.916
trainer/PolicyLossWithoutReg Min            -12.0424
trainer/gradient_norm                       125.639
trainer/gradient_penalty                     -0.628193
trainer/gradient_percentage                  -0.00823696
exploration/num steps total               73000
exploration/num paths total                 777
exploration/path length this epoch Mean     147.167
exploration/path length this epoch Std       33.5083
exploration/path length this epoch Max      214
exploration/path length this epoch Min      113
exploration/Rewards Mean                      2.31517
exploration/Rewards Std                       1.28007
exploration/Rewards Max                       6.02117
exploration/Rewards Min                      -0.757667
exploration/Returns Mean                    340.716
exploration/Returns Std                      26.6788
exploration/Returns Max                     367.245
exploration/Returns Min                     296.166
exploration/Num Paths                         6
exploration/Average Returns                 340.716
evaluation_0/num steps total             537944
evaluation_0/num paths total               3633
evaluation_0/path length Mean               173.391
evaluation_0/path length Std                 27.2337
evaluation_0/path length Max                207
evaluation_0/path length Min                116
evaluation_0/Rewards Mean                     2.21602
evaluation_0/Rewards Std                      1.15266
evaluation_0/Rewards Max                      6.78292
evaluation_0/Rewards Min                     -0.51388
evaluation_0/Returns Mean                   384.239
evaluation_0/Returns Std                     41.0162
evaluation_0/Returns Max                    448.993
evaluation_0/Returns Min                    294.152
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                384.239
time/epoch (s)                                0
time/total (s)                             1688.41
Epoch                                        68
---------------------------------------  ---------------
2022-11-16 11:14:10.646465 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 69 finished
---------------------------------------  ---------------
epoch                                        69
total_step                                74000
replay_pool/size                          74000
trainer/alpha                                 0.0354337
trainer/alpha_loss                            0.635115
trainer/entropy                              -6.19015
trainer/qf_loss                               5.10241
trainer/state_noise                           0.005
trainer/policy_loss                         -72.3097
trainer/policy_loss_without_entropy          73.1432
trainer/entropy_penalty                      -0.21934
trainer/entropy_percentage                   -0.00299877
trainer/Q1Pred Mean                          72.0793
trainer/Q1Pred Std                           30.516
trainer/Q1Pred Max                          127.528
trainer/Q1Pred Min                          -15.3376
trainer/Q2Pred Mean                          71.87
trainer/Q2Pred Std                           30.3229
trainer/Q2Pred Max                          127.407
trainer/Q2Pred Min                          -14.5389
trainer/QTargetWithReg Mean                  72.4593
trainer/QTargetWithReg Std                   30.4577
trainer/QTargetWithReg Max                  127.731
trainer/QTargetWithReg Min                  -13.8769
trainer/PolicyLossWithoutReg Mean            73.1432
trainer/PolicyLossWithoutReg Std             29.4701
trainer/PolicyLossWithoutReg Max            128.931
trainer/PolicyLossWithoutReg Min             -7.01921
trainer/gradient_norm                       122.835
trainer/gradient_penalty                     -0.614177
trainer/gradient_percentage                  -0.00839691
exploration/num steps total               74000
exploration/num paths total                 784
exploration/path length this epoch Mean     129.143
exploration/path length this epoch Std       23.0182
exploration/path length this epoch Max      177
exploration/path length this epoch Min      103
exploration/Rewards Mean                      2.46417
exploration/Rewards Std                       1.34741
exploration/Rewards Max                       6.02682
exploration/Rewards Min                      -0.565475
exploration/Returns Mean                    318.23
exploration/Returns Std                      53.4537
exploration/Returns Max                     420.055
exploration/Returns Min                     261.956
exploration/Num Paths                         7
exploration/Average Returns                 318.23
evaluation_0/num steps total             545941
evaluation_0/num paths total               3693
evaluation_0/path length Mean               133.283
evaluation_0/path length Std                 14.5156
evaluation_0/path length Max                171
evaluation_0/path length Min                 97
evaluation_0/Rewards Mean                     2.31942
evaluation_0/Rewards Std                      1.27241
evaluation_0/Rewards Max                      6.4811
evaluation_0/Rewards Min                     -0.434203
evaluation_0/Returns Mean                   309.14
evaluation_0/Returns Std                     47.5826
evaluation_0/Returns Max                    389.24
evaluation_0/Returns Min                    199.749
evaluation_0/Num Paths                       60
evaluation_0/Average Returns                309.14
time/epoch (s)                                0
time/total (s)                             1704.61
Epoch                                        69
---------------------------------------  ---------------
2022-11-16 11:14:27.647042 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 70 finished
---------------------------------------  ---------------
epoch                                        70
total_step                                75000
replay_pool/size                          75000
trainer/alpha                                 0.0362219
trainer/alpha_loss                            1.36607
trainer/entropy                              -6.41171
trainer/qf_loss                               3.95256
trainer/state_noise                           0.005
trainer/policy_loss                         -70.3267
trainer/policy_loss_without_entropy          71.2142
trainer/entropy_penalty                      -0.232244
trainer/entropy_percentage                   -0.00326121
trainer/Q1Pred Mean                          70.1285
trainer/Q1Pred Std                           31.7565
trainer/Q1Pred Max                          145.163
trainer/Q1Pred Min                          -13.935
trainer/Q2Pred Mean                          70.5002
trainer/Q2Pred Std                           31.7708
trainer/Q2Pred Max                          148.772
trainer/Q2Pred Min                           -9.38898
trainer/QTargetWithReg Mean                  70.7194
trainer/QTargetWithReg Std                   31.5214
trainer/QTargetWithReg Max                  148.973
trainer/QTargetWithReg Min                  -10.9105
trainer/PolicyLossWithoutReg Mean            71.2142
trainer/PolicyLossWithoutReg Std             31.0746
trainer/PolicyLossWithoutReg Max            146.679
trainer/PolicyLossWithoutReg Min             -9.94652
trainer/gradient_norm                       131.038
trainer/gradient_penalty                     -0.65519
trainer/gradient_percentage                  -0.00920028
exploration/num steps total               75000
exploration/num paths total                 791
exploration/path length this epoch Mean     139.143
exploration/path length this epoch Std       30.9489
exploration/path length this epoch Max      177
exploration/path length this epoch Min      107
exploration/Rewards Mean                      2.24522
exploration/Rewards Std                       1.15369
exploration/Rewards Max                       5.86201
exploration/Rewards Min                      -0.718456
exploration/Returns Mean                    312.407
exploration/Returns Std                      82.2373
exploration/Returns Max                     418.727
exploration/Returns Min                     194.041
exploration/Num Paths                         7
exploration/Average Returns                 312.407
evaluation_0/num steps total             553883
evaluation_0/num paths total               3755
evaluation_0/path length Mean               128.097
evaluation_0/path length Std                 26.4933
evaluation_0/path length Max                211
evaluation_0/path length Min                 92
evaluation_0/Rewards Mean                     2.31006
evaluation_0/Rewards Std                      1.35103
evaluation_0/Rewards Max                      6.37658
evaluation_0/Rewards Min                     -0.570543
evaluation_0/Returns Mean                   295.911
evaluation_0/Returns Std                     70.9771
evaluation_0/Returns Max                    449.751
evaluation_0/Returns Min                    170.452
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                295.911
time/epoch (s)                                0
time/total (s)                             1721.61
Epoch                                        70
---------------------------------------  ---------------
2022-11-16 11:14:45.352192 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 71 finished
---------------------------------------  ---------------
epoch                                        71
total_step                                76000
replay_pool/size                          76000
trainer/alpha                                 0.0354128
trainer/alpha_loss                           -1.61947
trainer/entropy                              -5.51522
trainer/qf_loss                               5.44769
trainer/state_noise                           0.005
trainer/policy_loss                         -76.3742
trainer/policy_loss_without_entropy          77.1982
trainer/entropy_penalty                      -0.195309
trainer/entropy_percentage                   -0.00252997
trainer/Q1Pred Mean                          76.1718
trainer/Q1Pred Std                           29.0042
trainer/Q1Pred Max                          130.6
trainer/Q1Pred Min                          -11.0955
trainer/Q2Pred Mean                          76.3603
trainer/Q2Pred Std                           29.0469
trainer/Q2Pred Max                          126.651
trainer/Q2Pred Min                          -11.1941
trainer/QTargetWithReg Mean                  76.8602
trainer/QTargetWithReg Std                   29.2467
trainer/QTargetWithReg Max                  128.969
trainer/QTargetWithReg Min                  -10.4287
trainer/PolicyLossWithoutReg Mean            77.1982
trainer/PolicyLossWithoutReg Std             28.2299
trainer/PolicyLossWithoutReg Max            129
trainer/PolicyLossWithoutReg Min             -8.74035
trainer/gradient_norm                       125.75
trainer/gradient_penalty                     -0.628752
trainer/gradient_percentage                  -0.00814464
exploration/num steps total               76000
exploration/num paths total                 798
exploration/path length this epoch Mean     127.286
exploration/path length this epoch Std       21.2718
exploration/path length this epoch Max      158
exploration/path length this epoch Min       93
exploration/Rewards Mean                      2.1301
exploration/Rewards Std                       1.42548
exploration/Rewards Max                       5.98268
exploration/Rewards Min                      -1.0105
exploration/Returns Mean                    271.131
exploration/Returns Std                      84.8173
exploration/Returns Max                     412.315
exploration/Returns Min                     182.745
exploration/Num Paths                         7
exploration/Average Returns                 271.131
evaluation_0/num steps total             561810
evaluation_0/num paths total               3803
evaluation_0/path length Mean               165.146
evaluation_0/path length Std                 82.6426
evaluation_0/path length Max                563
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     2.11257
evaluation_0/Rewards Std                      1.21006
evaluation_0/Rewards Max                      7.00274
evaluation_0/Rewards Min                     -1.40289
evaluation_0/Returns Mean                   348.883
evaluation_0/Returns Std                    128.233
evaluation_0/Returns Max                    727.438
evaluation_0/Returns Min                    211.372
evaluation_0/Num Paths                       48
evaluation_0/Average Returns                348.883
time/epoch (s)                                0
time/total (s)                             1739.32
Epoch                                        71
---------------------------------------  ---------------
2022-11-16 11:15:02.050293 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 72 finished
---------------------------------------  --------------
epoch                                        72
total_step                                77000
replay_pool/size                          77000
trainer/alpha                                 0.0360329
trainer/alpha_loss                            0.417056
trainer/entropy                              -6.12549
trainer/qf_loss                               5.05473
trainer/state_noise                           0.005
trainer/policy_loss                         -74.9846
trainer/policy_loss_without_entropy          75.8354
trainer/entropy_penalty                      -0.220719
trainer/entropy_percentage                   -0.0029105
trainer/Q1Pred Mean                          74.9546
trainer/Q1Pred Std                           28.9516
trainer/Q1Pred Max                          128.523
trainer/Q1Pred Min                          -19.8037
trainer/Q2Pred Mean                          75.1272
trainer/Q2Pred Std                           28.8811
trainer/Q2Pred Max                          128.204
trainer/Q2Pred Min                          -15.8438
trainer/QTargetWithReg Mean                  74.5885
trainer/QTargetWithReg Std                   28.7119
trainer/QTargetWithReg Max                  128.201
trainer/QTargetWithReg Min                  -13.3162
trainer/PolicyLossWithoutReg Mean            75.8354
trainer/PolicyLossWithoutReg Std             28.0381
trainer/PolicyLossWithoutReg Max            127.613
trainer/PolicyLossWithoutReg Min             -9.46804
trainer/gradient_norm                       126.023
trainer/gradient_penalty                     -0.630116
trainer/gradient_percentage                  -0.008309
exploration/num steps total               77000
exploration/num paths total                 805
exploration/path length this epoch Mean     127.857
exploration/path length this epoch Std       13.357
exploration/path length this epoch Max      145
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.2257
exploration/Rewards Std                       1.28803
exploration/Rewards Max                       6.01901
exploration/Rewards Min                      -0.645327
exploration/Returns Mean                    284.572
exploration/Returns Std                      25.3258
exploration/Returns Max                     312.154
exploration/Returns Min                     232.843
exploration/Num Paths                         7
exploration/Average Returns                 284.572
evaluation_0/num steps total             569745
evaluation_0/num paths total               3877
evaluation_0/path length Mean               107.23
evaluation_0/path length Std                 16.3852
evaluation_0/path length Max                144
evaluation_0/path length Min                 81
evaluation_0/Rewards Mean                     2.31558
evaluation_0/Rewards Std                      1.38955
evaluation_0/Rewards Max                      5.86535
evaluation_0/Rewards Min                     -0.697829
evaluation_0/Returns Mean                   248.299
evaluation_0/Returns Std                     44.6714
evaluation_0/Returns Max                    342.925
evaluation_0/Returns Min                    176.314
evaluation_0/Num Paths                       74
evaluation_0/Average Returns                248.299
time/epoch (s)                                0
time/total (s)                             1756.02
Epoch                                        72
---------------------------------------  --------------
2022-11-16 11:15:19.045157 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 73 finished
---------------------------------------  ---------------
epoch                                        73
total_step                                78000
replay_pool/size                          78000
trainer/alpha                                 0.0356559
trainer/alpha_loss                           -1.65639
trainer/entropy                              -5.50314
trainer/qf_loss                               4.89561
trainer/state_noise                           0.005
trainer/policy_loss                         -74.3934
trainer/policy_loss_without_entropy          75.1928
trainer/entropy_penalty                      -0.196219
trainer/entropy_percentage                   -0.00260955
trainer/Q1Pred Mean                          74.1915
trainer/Q1Pred Std                           30.1516
trainer/Q1Pred Max                          126.985
trainer/Q1Pred Min                          -29.1477
trainer/Q2Pred Mean                          74.2076
trainer/Q2Pred Std                           30.0207
trainer/Q2Pred Max                          127.547
trainer/Q2Pred Min                          -25.8051
trainer/QTargetWithReg Mean                  74.0725
trainer/QTargetWithReg Std                   29.8541
trainer/QTargetWithReg Max                  126.046
trainer/QTargetWithReg Min                  -32.4329
trainer/PolicyLossWithoutReg Mean            75.1928
trainer/PolicyLossWithoutReg Std             29.1831
trainer/PolicyLossWithoutReg Max            125.804
trainer/PolicyLossWithoutReg Min            -26.6369
trainer/gradient_norm                       120.633
trainer/gradient_penalty                     -0.603164
trainer/gradient_percentage                  -0.00802157
exploration/num steps total               78000
exploration/num paths total                 813
exploration/path length this epoch Mean     122.625
exploration/path length this epoch Std       32.303
exploration/path length this epoch Max      195
exploration/path length this epoch Min       92
exploration/Rewards Mean                      2.18657
exploration/Rewards Std                       1.35714
exploration/Rewards Max                       6.05705
exploration/Rewards Min                      -1.05257
exploration/Returns Mean                    268.128
exploration/Returns Std                      77.128
exploration/Returns Max                     425.523
exploration/Returns Min                     165.218
exploration/Num Paths                         8
exploration/Average Returns                 268.128
evaluation_0/num steps total             577730
evaluation_0/num paths total               3926
evaluation_0/path length Mean               162.959
evaluation_0/path length Std                 28.7813
evaluation_0/path length Max                289
evaluation_0/path length Min                116
evaluation_0/Rewards Mean                     2.24835
evaluation_0/Rewards Std                      1.3099
evaluation_0/Rewards Max                      7.45994
evaluation_0/Rewards Min                     -0.532998
evaluation_0/Returns Mean                   366.389
evaluation_0/Returns Std                     93.6312
evaluation_0/Returns Max                    646.303
evaluation_0/Returns Min                    204.166
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                366.389
time/epoch (s)                                0
time/total (s)                             1773.01
Epoch                                        73
---------------------------------------  ---------------
2022-11-16 11:15:36.182353 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 74 finished
---------------------------------------  ---------------
epoch                                        74
total_step                                79000
replay_pool/size                          79000
trainer/alpha                                 0.0364267
trainer/alpha_loss                           -0.106387
trainer/entropy                              -5.96788
trainer/qf_loss                               5.15357
trainer/state_noise                           0.005
trainer/policy_loss                         -76.4336
trainer/policy_loss_without_entropy          77.2427
trainer/entropy_penalty                      -0.21739
trainer/entropy_percentage                   -0.00281438
trainer/Q1Pred Mean                          76.0363
trainer/Q1Pred Std                           30.5813
trainer/Q1Pred Max                          129.927
trainer/Q1Pred Min                          -16.8733
trainer/Q2Pred Mean                          76.0179
trainer/Q2Pred Std                           30.6443
trainer/Q2Pred Max                          129.404
trainer/Q2Pred Min                          -15.982
trainer/QTargetWithReg Mean                  76.0089
trainer/QTargetWithReg Std                   30.6898
trainer/QTargetWithReg Max                  129.83
trainer/QTargetWithReg Min                  -12.0313
trainer/PolicyLossWithoutReg Mean            77.2427
trainer/PolicyLossWithoutReg Std             29.5282
trainer/PolicyLossWithoutReg Max            129.343
trainer/PolicyLossWithoutReg Min            -17.5655
trainer/gradient_norm                       118.353
trainer/gradient_penalty                     -0.591767
trainer/gradient_percentage                  -0.00766114
exploration/num steps total               79000
exploration/num paths total                 821
exploration/path length this epoch Mean     113.75
exploration/path length this epoch Std       28.1236
exploration/path length this epoch Max      157
exploration/path length this epoch Min       77
exploration/Rewards Mean                      2.29617
exploration/Rewards Std                       1.39404
exploration/Rewards Max                       6.1442
exploration/Rewards Min                      -0.792426
exploration/Returns Mean                    261.19
exploration/Returns Std                      57.4295
exploration/Returns Max                     341.536
exploration/Returns Min                     186.945
exploration/Num Paths                         8
exploration/Average Returns                 261.19
evaluation_0/num steps total             585638
evaluation_0/num paths total               3993
evaluation_0/path length Mean               118.03
evaluation_0/path length Std                 31.0459
evaluation_0/path length Max                270
evaluation_0/path length Min                 75
evaluation_0/Rewards Mean                     2.16793
evaluation_0/Rewards Std                      1.32545
evaluation_0/Rewards Max                      5.95493
evaluation_0/Rewards Min                     -0.757026
evaluation_0/Returns Mean                   255.88
evaluation_0/Returns Std                     69.7028
evaluation_0/Returns Max                    631.569
evaluation_0/Returns Min                    164.926
evaluation_0/Num Paths                       67
evaluation_0/Average Returns                255.88
time/epoch (s)                                0
time/total (s)                             1790.15
Epoch                                        74
---------------------------------------  ---------------
2022-11-16 11:15:52.762079 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 75 finished
---------------------------------------  ---------------
epoch                                        75
total_step                                80000
replay_pool/size                          80000
trainer/alpha                                 0.0363698
trainer/alpha_loss                           -2.43846
trainer/entropy                              -5.2642
trainer/qf_loss                               4.93727
trainer/state_noise                           0.005
trainer/policy_loss                         -78.8132
trainer/policy_loss_without_entropy          79.6232
trainer/entropy_penalty                      -0.191458
trainer/entropy_percentage                   -0.00240455
trainer/Q1Pred Mean                          79.1348
trainer/Q1Pred Std                           28.9298
trainer/Q1Pred Max                          145.884
trainer/Q1Pred Min                            0.816574
trainer/Q2Pred Mean                          78.8717
trainer/Q2Pred Std                           28.6347
trainer/Q2Pred Max                          144.124
trainer/Q2Pred Min                           -1.42392
trainer/QTargetWithReg Mean                  79.0502
trainer/QTargetWithReg Std                   28.8755
trainer/QTargetWithReg Max                  146.233
trainer/QTargetWithReg Min                    0.90488
trainer/PolicyLossWithoutReg Mean            79.6232
trainer/PolicyLossWithoutReg Std             28.699
trainer/PolicyLossWithoutReg Max            146.367
trainer/PolicyLossWithoutReg Min             -1.6312
trainer/gradient_norm                       123.71
trainer/gradient_penalty                     -0.618548
trainer/gradient_percentage                  -0.00776844
exploration/num steps total               80000
exploration/num paths total                 828
exploration/path length this epoch Mean     129.143
exploration/path length this epoch Std       12.911
exploration/path length this epoch Max      147
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.38496
exploration/Rewards Std                       1.29501
exploration/Rewards Max                       5.87447
exploration/Rewards Min                      -0.67227
exploration/Returns Mean                    308.001
exploration/Returns Std                      31.4281
exploration/Returns Max                     358.415
exploration/Returns Min                     258.625
exploration/Num Paths                         7
exploration/Average Returns                 308.001
evaluation_0/num steps total             593605
evaluation_0/num paths total               4045
evaluation_0/path length Mean               153.212
evaluation_0/path length Std                 28.7625
evaluation_0/path length Max                242
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     2.11391
evaluation_0/Rewards Std                      1.28939
evaluation_0/Rewards Max                      6.63824
evaluation_0/Rewards Min                     -1.01926
evaluation_0/Returns Mean                   323.875
evaluation_0/Returns Std                     77.8915
evaluation_0/Returns Max                    625.527
evaluation_0/Returns Min                    208.843
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                323.875
time/epoch (s)                                0
time/total (s)                             1806.73
Epoch                                        75
---------------------------------------  ---------------
2022-11-16 11:16:09.533132 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 76 finished
---------------------------------------  ---------------
epoch                                        76
total_step                                81000
replay_pool/size                          81000
trainer/alpha                                 0.0349086
trainer/alpha_loss                            0.447152
trainer/entropy                              -6.13328
trainer/qf_loss                               5.35905
trainer/state_noise                           0.005
trainer/policy_loss                         -79.058
trainer/policy_loss_without_entropy          79.878
trainer/entropy_penalty                      -0.214104
trainer/entropy_percentage                   -0.00268039
trainer/Q1Pred Mean                          79.1234
trainer/Q1Pred Std                           28.9262
trainer/Q1Pred Max                          126.377
trainer/Q1Pred Min                          -14.4723
trainer/Q2Pred Mean                          78.9869
trainer/Q2Pred Std                           28.9849
trainer/Q2Pred Max                          127.02
trainer/Q2Pred Min                          -12.6052
trainer/QTargetWithReg Mean                  79.4528
trainer/QTargetWithReg Std                   29.0946
trainer/QTargetWithReg Max                  125.536
trainer/QTargetWithReg Min                  -10.9871
trainer/PolicyLossWithoutReg Mean            79.878
trainer/PolicyLossWithoutReg Std             28.6188
trainer/PolicyLossWithoutReg Max            126.095
trainer/PolicyLossWithoutReg Min             -9.9528
trainer/gradient_norm                       121.177
trainer/gradient_penalty                     -0.605883
trainer/gradient_percentage                  -0.0075851
exploration/num steps total               81000
exploration/num paths total                 835
exploration/path length this epoch Mean     130
exploration/path length this epoch Std       17.6392
exploration/path length this epoch Max      168
exploration/path length this epoch Min      114
exploration/Rewards Mean                      2.34293
exploration/Rewards Std                       1.33671
exploration/Rewards Max                       6.11328
exploration/Rewards Min                      -0.532878
exploration/Returns Mean                    304.581
exploration/Returns Std                      43.7067
exploration/Returns Max                     397.919
exploration/Returns Min                     255.432
exploration/Num Paths                         7
exploration/Average Returns                 304.581
evaluation_0/num steps total             601557
evaluation_0/num paths total               4104
evaluation_0/path length Mean               134.78
evaluation_0/path length Std                 17.0155
evaluation_0/path length Max                175
evaluation_0/path length Min                109
evaluation_0/Rewards Mean                     2.40522
evaluation_0/Rewards Std                      1.27316
evaluation_0/Rewards Max                      5.87539
evaluation_0/Rewards Min                     -0.332859
evaluation_0/Returns Mean                   324.175
evaluation_0/Returns Std                     27.266
evaluation_0/Returns Max                    395.049
evaluation_0/Returns Min                    276.378
evaluation_0/Num Paths                       59
evaluation_0/Average Returns                324.175
time/epoch (s)                                0
time/total (s)                             1823.5
Epoch                                        76
---------------------------------------  ---------------
2022-11-16 11:16:25.290091 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 77 finished
---------------------------------------  ---------------
epoch                                        77
total_step                                82000
replay_pool/size                          82000
trainer/alpha                                 0.033789
trainer/alpha_loss                           -1.09612
trainer/entropy                              -5.67643
trainer/qf_loss                               3.61926
trainer/state_noise                           0.005
trainer/policy_loss                         -80.8025
trainer/policy_loss_without_entropy          81.583
trainer/entropy_penalty                      -0.191801
trainer/entropy_percentage                   -0.00235099
trainer/Q1Pred Mean                          81.3207
trainer/Q1Pred Std                           28.4346
trainer/Q1Pred Max                          131.826
trainer/Q1Pred Min                            3.02724
trainer/Q2Pred Mean                          81.361
trainer/Q2Pred Std                           28.6594
trainer/Q2Pred Max                          132.563
trainer/Q2Pred Min                            1.25107
trainer/QTargetWithReg Mean                  81.199
trainer/QTargetWithReg Std                   28.7674
trainer/QTargetWithReg Max                  133.99
trainer/QTargetWithReg Min                   -1.67737
trainer/PolicyLossWithoutReg Mean            81.583
trainer/PolicyLossWithoutReg Std             28.3947
trainer/PolicyLossWithoutReg Max            132.244
trainer/PolicyLossWithoutReg Min              1.34441
trainer/gradient_norm                       117.746
trainer/gradient_penalty                     -0.588731
trainer/gradient_percentage                  -0.00721635
exploration/num steps total               82000
exploration/num paths total                 842
exploration/path length this epoch Mean     120.143
exploration/path length this epoch Std       18.4579
exploration/path length this epoch Max      160
exploration/path length this epoch Min       97
exploration/Rewards Mean                      2.42115
exploration/Rewards Std                       1.3233
exploration/Rewards Max                       6.28911
exploration/Rewards Min                      -0.624569
exploration/Returns Mean                    290.884
exploration/Returns Std                      41.6144
exploration/Returns Max                     367.176
exploration/Returns Min                     216.233
exploration/Num Paths                         7
exploration/Average Returns                 290.884
evaluation_0/num steps total             609514
evaluation_0/num paths total               4158
evaluation_0/path length Mean               147.352
evaluation_0/path length Std                 15.1293
evaluation_0/path length Max                181
evaluation_0/path length Min                109
evaluation_0/Rewards Mean                     2.26558
evaluation_0/Rewards Std                      1.23983
evaluation_0/Rewards Max                      6.11945
evaluation_0/Rewards Min                     -0.74991
evaluation_0/Returns Mean                   333.837
evaluation_0/Returns Std                     34.246
evaluation_0/Returns Max                    388.201
evaluation_0/Returns Min                    246.947
evaluation_0/Num Paths                       54
evaluation_0/Average Returns                333.837
time/epoch (s)                                0
time/total (s)                             1839.25
Epoch                                        77
---------------------------------------  ---------------
2022-11-16 11:16:42.780546 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 78 finished
---------------------------------------  ---------------
epoch                                        78
total_step                                83000
replay_pool/size                          83000
trainer/alpha                                 0.0344459
trainer/alpha_loss                            0.709027
trainer/entropy                              -6.21049
trainer/qf_loss                               4.95315
trainer/state_noise                           0.005
trainer/policy_loss                         -77.7234
trainer/policy_loss_without_entropy          78.5626
trainer/entropy_penalty                      -0.213926
trainer/entropy_percentage                   -0.002723
trainer/Q1Pred Mean                          77.9329
trainer/Q1Pred Std                           27.4807
trainer/Q1Pred Max                          126.641
trainer/Q1Pred Min                          -16.7681
trainer/Q2Pred Mean                          77.7488
trainer/Q2Pred Std                           27.878
trainer/Q2Pred Max                          128.718
trainer/Q2Pred Min                          -19.4979
trainer/QTargetWithReg Mean                  78.1092
trainer/QTargetWithReg Std                   27.6667
trainer/QTargetWithReg Max                  128.146
trainer/QTargetWithReg Min                  -17.2348
trainer/PolicyLossWithoutReg Mean            78.5626
trainer/PolicyLossWithoutReg Std             27.5371
trainer/PolicyLossWithoutReg Max            126.691
trainer/PolicyLossWithoutReg Min            -13.4418
trainer/gradient_norm                       125.062
trainer/gradient_penalty                     -0.625309
trainer/gradient_percentage                  -0.00795938
exploration/num steps total               83000
exploration/num paths total                 849
exploration/path length this epoch Mean     134.429
exploration/path length this epoch Std       50.6919
exploration/path length this epoch Max      239
exploration/path length this epoch Min       71
exploration/Rewards Mean                      2.40838
exploration/Rewards Std                       1.3912
exploration/Rewards Max                       6.80146
exploration/Rewards Min                      -0.658357
exploration/Returns Mean                    323.755
exploration/Returns Std                     151.618
exploration/Returns Max                     645.643
exploration/Returns Min                     158.961
exploration/Num Paths                         7
exploration/Average Returns                 323.755
evaluation_0/num steps total             617469
evaluation_0/num paths total               4241
evaluation_0/path length Mean                95.8434
evaluation_0/path length Std                 45.305
evaluation_0/path length Max                323
evaluation_0/path length Min                 69
evaluation_0/Rewards Mean                     2.17772
evaluation_0/Rewards Std                      1.34258
evaluation_0/Rewards Max                      6.16303
evaluation_0/Rewards Min                     -0.433051
evaluation_0/Returns Mean                   208.72
evaluation_0/Returns Std                     88.7053
evaluation_0/Returns Max                    741
evaluation_0/Returns Min                    152.474
evaluation_0/Num Paths                       83
evaluation_0/Average Returns                208.72
time/epoch (s)                                0
time/total (s)                             1856.74
Epoch                                        78
---------------------------------------  ---------------
2022-11-16 11:16:59.161938 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 79 finished
---------------------------------------  ---------------
epoch                                        79
total_step                                84000
replay_pool/size                          84000
trainer/alpha                                 0.0337547
trainer/alpha_loss                           -0.547897
trainer/entropy                              -5.83832
trainer/qf_loss                               5.05128
trainer/state_noise                           0.005
trainer/policy_loss                         -80.4123
trainer/policy_loss_without_entropy          81.2119
trainer/entropy_penalty                      -0.197071
trainer/entropy_percentage                   -0.00242663
trainer/Q1Pred Mean                          80.4732
trainer/Q1Pred Std                           30.2073
trainer/Q1Pred Max                          137.967
trainer/Q1Pred Min                           -4.27105
trainer/Q2Pred Mean                          80.5581
trainer/Q2Pred Std                           30.0797
trainer/Q2Pred Max                          136.275
trainer/Q2Pred Min                           -1.06295
trainer/QTargetWithReg Mean                  79.9925
trainer/QTargetWithReg Std                   30.4696
trainer/QTargetWithReg Max                  137.769
trainer/QTargetWithReg Min                   -0.646502
trainer/PolicyLossWithoutReg Mean            81.2119
trainer/PolicyLossWithoutReg Std             29.4315
trainer/PolicyLossWithoutReg Max            136.368
trainer/PolicyLossWithoutReg Min              2.77801
trainer/gradient_norm                       120.498
trainer/gradient_penalty                     -0.602492
trainer/gradient_percentage                  -0.00741877
exploration/num steps total               84000
exploration/num paths total                 858
exploration/path length this epoch Mean     106.111
exploration/path length this epoch Std       20.9467
exploration/path length this epoch Max      138
exploration/path length this epoch Min       74
exploration/Rewards Mean                      2.41307
exploration/Rewards Std                       1.37535
exploration/Rewards Max                       6.19177
exploration/Rewards Min                      -0.545404
exploration/Returns Mean                    256.053
exploration/Returns Std                      40.1101
exploration/Returns Max                     326.704
exploration/Returns Min                     206.167
exploration/Num Paths                         9
exploration/Average Returns                 256.053
evaluation_0/num steps total             625406
evaluation_0/num paths total               4310
evaluation_0/path length Mean               115.029
evaluation_0/path length Std                 22.708
evaluation_0/path length Max                163
evaluation_0/path length Min                 75
evaluation_0/Rewards Mean                     2.6519
evaluation_0/Rewards Std                      1.3657
evaluation_0/Rewards Max                      6.40966
evaluation_0/Rewards Min                     -0.53884
evaluation_0/Returns Mean                   305.046
evaluation_0/Returns Std                     56.8971
evaluation_0/Returns Max                    395.367
evaluation_0/Returns Min                    195.839
evaluation_0/Num Paths                       69
evaluation_0/Average Returns                305.046
time/epoch (s)                                0
time/total (s)                             1873.13
Epoch                                        79
---------------------------------------  ---------------
2022-11-16 11:17:15.237853 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 80 finished
---------------------------------------  ---------------
epoch                                        80
total_step                                85000
replay_pool/size                          85000
trainer/alpha                                 0.0344155
trainer/alpha_loss                            0.70168
trainer/entropy                              -6.20825
trainer/qf_loss                               3.85874
trainer/state_noise                           0.005
trainer/policy_loss                         -78.4589
trainer/policy_loss_without_entropy          79.2769
trainer/entropy_penalty                      -0.21366
trainer/entropy_percentage                   -0.00269511
trainer/Q1Pred Mean                          78.4527
trainer/Q1Pred Std                           27.8994
trainer/Q1Pred Max                          129.411
trainer/Q1Pred Min                          -11.0905
trainer/Q2Pred Mean                          78.7196
trainer/Q2Pred Std                           27.7129
trainer/Q2Pred Max                          131.662
trainer/Q2Pred Min                           -9.40071
trainer/QTargetWithReg Mean                  78.5679
trainer/QTargetWithReg Std                   27.8102
trainer/QTargetWithReg Max                  129.883
trainer/QTargetWithReg Min                   -7.92417
trainer/PolicyLossWithoutReg Mean            79.2769
trainer/PolicyLossWithoutReg Std             27.6437
trainer/PolicyLossWithoutReg Max            129.717
trainer/PolicyLossWithoutReg Min             -8.33812
trainer/gradient_norm                       120.857
trainer/gradient_penalty                     -0.604284
trainer/gradient_percentage                  -0.00762245
exploration/num steps total               85000
exploration/num paths total                 866
exploration/path length this epoch Mean     115.75
exploration/path length this epoch Std       27.8018
exploration/path length this epoch Max      182
exploration/path length this epoch Min       88
exploration/Rewards Mean                      2.55466
exploration/Rewards Std                       1.41617
exploration/Rewards Max                       6.22784
exploration/Rewards Min                      -0.886857
exploration/Returns Mean                    295.702
exploration/Returns Std                      59.5132
exploration/Returns Max                     384.259
exploration/Returns Min                     202.116
exploration/Num Paths                         8
exploration/Average Returns                 295.702
evaluation_0/num steps total             633405
evaluation_0/num paths total               4386
evaluation_0/path length Mean               105.25
evaluation_0/path length Std                  6.27259
evaluation_0/path length Max                129
evaluation_0/path length Min                 95
evaluation_0/Rewards Mean                     2.65613
evaluation_0/Rewards Std                      1.44636
evaluation_0/Rewards Max                      7.08124
evaluation_0/Rewards Min                     -0.703553
evaluation_0/Returns Mean                   279.557
evaluation_0/Returns Std                     25.4513
evaluation_0/Returns Max                    372.325
evaluation_0/Returns Min                    237.888
evaluation_0/Num Paths                       76
evaluation_0/Average Returns                279.557
time/epoch (s)                                0
time/total (s)                             1889.2
Epoch                                        80
---------------------------------------  ---------------
2022-11-16 11:17:32.198479 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 81 finished
---------------------------------------  ---------------
epoch                                        81
total_step                                86000
replay_pool/size                          86000
trainer/alpha                                 0.0340851
trainer/alpha_loss                           -0.86701
trainer/entropy                              -5.7434
trainer/qf_loss                               5.54565
trainer/state_noise                           0.005
trainer/policy_loss                         -76.666
trainer/policy_loss_without_entropy          77.4804
trainer/entropy_penalty                      -0.195765
trainer/entropy_percentage                   -0.00252664
trainer/Q1Pred Mean                          76.935
trainer/Q1Pred Std                           28.091
trainer/Q1Pred Max                          128.027
trainer/Q1Pred Min                           -8.93676
trainer/Q2Pred Mean                          76.7338
trainer/Q2Pred Std                           28.1556
trainer/Q2Pred Max                          128.513
trainer/Q2Pred Min                          -15.1471
trainer/QTargetWithReg Mean                  76.5403
trainer/QTargetWithReg Std                   28.2448
trainer/QTargetWithReg Max                  128.524
trainer/QTargetWithReg Min                  -20.606
trainer/PolicyLossWithoutReg Mean            77.4804
trainer/PolicyLossWithoutReg Std             27.3992
trainer/PolicyLossWithoutReg Max            128.295
trainer/PolicyLossWithoutReg Min             -6.65758
trainer/gradient_norm                       123.718
trainer/gradient_penalty                     -0.618591
trainer/gradient_percentage                  -0.00798384
exploration/num steps total               86000
exploration/num paths total                 874
exploration/path length this epoch Mean     114.5
exploration/path length this epoch Std       22.0851
exploration/path length this epoch Max      139
exploration/path length this epoch Min       73
exploration/Rewards Mean                      2.69793
exploration/Rewards Std                       1.39692
exploration/Rewards Max                       6.19437
exploration/Rewards Min                      -1.01721
exploration/Returns Mean                    308.913
exploration/Returns Std                      65.7268
exploration/Returns Max                     382.97
exploration/Returns Min                     192.998
exploration/Num Paths                         8
exploration/Average Returns                 308.913
evaluation_0/num steps total             641386
evaluation_0/num paths total               4461
evaluation_0/path length Mean               106.413
evaluation_0/path length Std                 15.7244
evaluation_0/path length Max                144
evaluation_0/path length Min                 82
evaluation_0/Rewards Mean                     2.52962
evaluation_0/Rewards Std                      1.4328
evaluation_0/Rewards Max                      6.36762
evaluation_0/Rewards Min                     -0.718491
evaluation_0/Returns Mean                   269.186
evaluation_0/Returns Std                     54.7908
evaluation_0/Returns Max                    406.458
evaluation_0/Returns Min                    212.402
evaluation_0/Num Paths                       75
evaluation_0/Average Returns                269.186
time/epoch (s)                                0
time/total (s)                             1906.16
Epoch                                        81
---------------------------------------  ---------------
2022-11-16 11:17:48.242667 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 82 finished
---------------------------------------  ---------------
epoch                                        82
total_step                                87000
replay_pool/size                          87000
trainer/alpha                                 0.0342872
trainer/alpha_loss                            1.25531
trainer/entropy                              -6.37216
trainer/qf_loss                               4.37311
trainer/state_noise                           0.005
trainer/policy_loss                         -79.1791
trainer/policy_loss_without_entropy          80.0135
trainer/entropy_penalty                      -0.218483
trainer/entropy_percentage                   -0.00273058
trainer/Q1Pred Mean                          78.4034
trainer/Q1Pred Std                           30.8083
trainer/Q1Pred Max                          128.005
trainer/Q1Pred Min                           -3.34392
trainer/Q2Pred Mean                          78.2751
trainer/Q2Pred Std                           30.9751
trainer/Q2Pred Max                          127.222
trainer/Q2Pred Min                           -3.49666
trainer/QTargetWithReg Mean                  78.444
trainer/QTargetWithReg Std                   30.8975
trainer/QTargetWithReg Max                  126.666
trainer/QTargetWithReg Min                   -0.909409
trainer/PolicyLossWithoutReg Mean            80.0135
trainer/PolicyLossWithoutReg Std             29.7049
trainer/PolicyLossWithoutReg Max            126.852
trainer/PolicyLossWithoutReg Min              0.980279
trainer/gradient_norm                       123.187
trainer/gradient_penalty                     -0.615936
trainer/gradient_percentage                  -0.00769791
exploration/num steps total               87000
exploration/num paths total                 883
exploration/path length this epoch Mean      92.5556
exploration/path length this epoch Std       20.9556
exploration/path length this epoch Max      137
exploration/path length this epoch Min       69
exploration/Rewards Mean                      2.70601
exploration/Rewards Std                       1.47211
exploration/Rewards Max                       6.25883
exploration/Rewards Min                      -0.869104
exploration/Returns Mean                    250.457
exploration/Returns Std                      66.0604
exploration/Returns Max                     389.742
exploration/Returns Min                     186.815
exploration/Num Paths                         9
exploration/Average Returns                 250.457
evaluation_0/num steps total             649335
evaluation_0/num paths total               4553
evaluation_0/path length Mean                86.4022
evaluation_0/path length Std                  2.76256
evaluation_0/path length Max                100
evaluation_0/path length Min                 82
evaluation_0/Rewards Mean                     2.71529
evaluation_0/Rewards Std                      1.48411
evaluation_0/Rewards Max                      6.47171
evaluation_0/Rewards Min                     -0.605221
evaluation_0/Returns Mean                   234.607
evaluation_0/Returns Std                     11.4834
evaluation_0/Returns Max                    283.846
evaluation_0/Returns Min                    213.683
evaluation_0/Num Paths                       92
evaluation_0/Average Returns                234.607
time/epoch (s)                                0
time/total (s)                             1922.2
Epoch                                        82
---------------------------------------  ---------------
2022-11-16 11:18:05.773740 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 83 finished
---------------------------------------  ---------------
epoch                                        83
total_step                                88000
replay_pool/size                          88000
trainer/alpha                                 0.0325583
trainer/alpha_loss                           -1.18602
trainer/entropy                              -5.65367
trainer/qf_loss                               4.61942
trainer/state_noise                           0.005
trainer/policy_loss                         -77.7059
trainer/policy_loss_without_entropy          78.5152
trainer/entropy_penalty                      -0.184074
trainer/entropy_percentage                   -0.00234444
trainer/Q1Pred Mean                          77.9441
trainer/Q1Pred Std                           29.1968
trainer/Q1Pred Max                          128.286
trainer/Q1Pred Min                          -20.7051
trainer/Q2Pred Mean                          77.9389
trainer/Q2Pred Std                           29.2591
trainer/Q2Pred Max                          128.138
trainer/Q2Pred Min                          -20.5882
trainer/QTargetWithReg Mean                  77.8366
trainer/QTargetWithReg Std                   29.234
trainer/QTargetWithReg Max                  128.252
trainer/QTargetWithReg Min                  -15.4822
trainer/PolicyLossWithoutReg Mean            78.5152
trainer/PolicyLossWithoutReg Std             28.6258
trainer/PolicyLossWithoutReg Max            128.005
trainer/PolicyLossWithoutReg Min            -18.1652
trainer/gradient_norm                       125.045
trainer/gradient_penalty                     -0.625224
trainer/gradient_percentage                  -0.0079631
exploration/num steps total               88000
exploration/num paths total                 891
exploration/path length this epoch Mean     124
exploration/path length this epoch Std       15.5081
exploration/path length this epoch Max      155
exploration/path length this epoch Min       96
exploration/Rewards Mean                      2.83046
exploration/Rewards Std                       1.44083
exploration/Rewards Max                       6.49989
exploration/Rewards Min                      -0.675441
exploration/Returns Mean                    350.977
exploration/Returns Std                      45.0665
exploration/Returns Max                     439.648
exploration/Returns Min                     276.842
exploration/Num Paths                         8
exploration/Average Returns                 350.977
evaluation_0/num steps total             657242
evaluation_0/num paths total               4624
evaluation_0/path length Mean               111.366
evaluation_0/path length Std                 51.8723
evaluation_0/path length Max                481
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     2.77199
evaluation_0/Rewards Std                      1.48012
evaluation_0/Rewards Max                      7.04735
evaluation_0/Rewards Min                     -0.563243
evaluation_0/Returns Mean                   308.705
evaluation_0/Returns Std                     91.9537
evaluation_0/Returns Max                    795.945
evaluation_0/Returns Min                    195.392
evaluation_0/Num Paths                       71
evaluation_0/Average Returns                308.705
time/epoch (s)                                0
time/total (s)                             1939.74
Epoch                                        83
---------------------------------------  ---------------
2022-11-16 11:18:23.183162 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 84 finished
---------------------------------------  ---------------
epoch                                        84
total_step                                89000
replay_pool/size                          89000
trainer/alpha                                 0.0329483
trainer/alpha_loss                           -1.42278
trainer/entropy                              -5.58308
trainer/qf_loss                               3.37334
trainer/state_noise                           0.005
trainer/policy_loss                         -80.0306
trainer/policy_loss_without_entropy          80.8291
trainer/entropy_penalty                      -0.183953
trainer/entropy_percentage                   -0.00227582
trainer/Q1Pred Mean                          80.3102
trainer/Q1Pred Std                           29.4394
trainer/Q1Pred Max                          132.037
trainer/Q1Pred Min                           -7.24479
trainer/Q2Pred Mean                          80.3397
trainer/Q2Pred Std                           29.5278
trainer/Q2Pred Max                          131.626
trainer/Q2Pred Min                          -11.7454
trainer/QTargetWithReg Mean                  80.2384
trainer/QTargetWithReg Std                   29.2256
trainer/QTargetWithReg Max                  130.922
trainer/QTargetWithReg Min                   -2.46501
trainer/PolicyLossWithoutReg Mean            80.8291
trainer/PolicyLossWithoutReg Std             28.9936
trainer/PolicyLossWithoutReg Max            130.707
trainer/PolicyLossWithoutReg Min             -8.89634
trainer/gradient_norm                       122.894
trainer/gradient_penalty                     -0.614472
trainer/gradient_percentage                  -0.00760211
exploration/num steps total               89000
exploration/num paths total                 899
exploration/path length this epoch Mean     119.75
exploration/path length this epoch Std       26.8921
exploration/path length this epoch Max      164
exploration/path length this epoch Min       78
exploration/Rewards Mean                      2.47548
exploration/Rewards Std                       1.40081
exploration/Rewards Max                       5.76022
exploration/Rewards Min                      -0.65584
exploration/Returns Mean                    296.439
exploration/Returns Std                      57.6617
exploration/Returns Max                     354.595
exploration/Returns Min                     183.457
exploration/Num Paths                         8
exploration/Average Returns                 296.439
evaluation_0/num steps total             664959
evaluation_0/num paths total               4658
evaluation_0/path length Mean               226.971
evaluation_0/path length Std                 99.1352
evaluation_0/path length Max                703
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     1.65443
evaluation_0/Rewards Std                      1.35893
evaluation_0/Rewards Max                      5.89135
evaluation_0/Rewards Min                     -1.70791
evaluation_0/Returns Mean                   375.507
evaluation_0/Returns Std                    151.401
evaluation_0/Returns Max                    879.018
evaluation_0/Returns Min                    154.563
evaluation_0/Num Paths                       34
evaluation_0/Average Returns                375.507
time/epoch (s)                                0
time/total (s)                             1957.14
Epoch                                        84
---------------------------------------  ---------------
2022-11-16 11:18:39.889712 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 85 finished
---------------------------------------  ---------------
epoch                                        85
total_step                                90000
replay_pool/size                          90000
trainer/alpha                                 0.0330901
trainer/alpha_loss                            1.69602
trainer/entropy                              -6.49756
trainer/qf_loss                               4.55017
trainer/state_noise                           0.005
trainer/policy_loss                         -79.2431
trainer/policy_loss_without_entropy          80.0451
trainer/entropy_penalty                      -0.215005
trainer/entropy_percentage                   -0.00268605
trainer/Q1Pred Mean                          78.8228
trainer/Q1Pred Std                           30.5731
trainer/Q1Pred Max                          128.36
trainer/Q1Pred Min                          -14.1106
trainer/Q2Pred Mean                          78.6923
trainer/Q2Pred Std                           30.5923
trainer/Q2Pred Max                          128.394
trainer/Q2Pred Min                          -16.1253
trainer/QTargetWithReg Mean                  78.8638
trainer/QTargetWithReg Std                   30.6499
trainer/QTargetWithReg Max                  128.625
trainer/QTargetWithReg Min                  -11.8797
trainer/PolicyLossWithoutReg Mean            80.0451
trainer/PolicyLossWithoutReg Std             29.537
trainer/PolicyLossWithoutReg Max            128.152
trainer/PolicyLossWithoutReg Min            -15.7065
trainer/gradient_norm                       117.394
trainer/gradient_penalty                     -0.58697
trainer/gradient_percentage                  -0.00733299
exploration/num steps total               90000
exploration/num paths total                 907
exploration/path length this epoch Mean     111.75
exploration/path length this epoch Std       17.9774
exploration/path length this epoch Max      135
exploration/path length this epoch Min       86
exploration/Rewards Mean                      2.5625
exploration/Rewards Std                       1.53445
exploration/Rewards Max                       6.62295
exploration/Rewards Min                      -0.802885
exploration/Returns Mean                    286.36
exploration/Returns Std                      63.3229
exploration/Returns Max                     381.312
exploration/Returns Min                     191.747
exploration/Num Paths                         8
exploration/Average Returns                 286.36
evaluation_0/num steps total             672894
evaluation_0/num paths total               4720
evaluation_0/path length Mean               127.984
evaluation_0/path length Std                 21.9791
evaluation_0/path length Max                218
evaluation_0/path length Min                101
evaluation_0/Rewards Mean                     2.38112
evaluation_0/Rewards Std                      1.29008
evaluation_0/Rewards Max                      6.24766
evaluation_0/Rewards Min                     -0.92976
evaluation_0/Returns Mean                   304.744
evaluation_0/Returns Std                     69.1566
evaluation_0/Returns Max                    613.287
evaluation_0/Returns Min                    228.587
evaluation_0/Num Paths                       62
evaluation_0/Average Returns                304.744
time/epoch (s)                                0
time/total (s)                             1973.85
Epoch                                        85
---------------------------------------  ---------------
2022-11-16 11:18:56.206576 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 86 finished
---------------------------------------  ---------------
epoch                                        86
total_step                                91000
replay_pool/size                          91000
trainer/alpha                                 0.0330367
trainer/alpha_loss                           -1.73287
trainer/entropy                              -5.49183
trainer/qf_loss                               3.3431
trainer/state_noise                           0.005
trainer/policy_loss                         -80.6832
trainer/policy_loss_without_entropy          81.444
trainer/entropy_penalty                      -0.181432
trainer/entropy_percentage                   -0.00222769
trainer/Q1Pred Mean                          80.7127
trainer/Q1Pred Std                           30.7441
trainer/Q1Pred Max                          128.574
trainer/Q1Pred Min                           -0.00484473
trainer/Q2Pred Mean                          80.6936
trainer/Q2Pred Std                           30.8058
trainer/Q2Pred Max                          127.803
trainer/Q2Pred Min                           -5.23029
trainer/QTargetWithReg Mean                  80.9326
trainer/QTargetWithReg Std                   30.8489
trainer/QTargetWithReg Max                  127.582
trainer/QTargetWithReg Min                   -0.769
trainer/PolicyLossWithoutReg Mean            81.444
trainer/PolicyLossWithoutReg Std             30.5021
trainer/PolicyLossWithoutReg Max            127.652
trainer/PolicyLossWithoutReg Min             -0.749547
trainer/gradient_norm                       115.859
trainer/gradient_penalty                     -0.579293
trainer/gradient_percentage                  -0.00711278
exploration/num steps total               91000
exploration/num paths total                 914
exploration/path length this epoch Mean     134.857
exploration/path length this epoch Std       56.9321
exploration/path length this epoch Max      266
exploration/path length this epoch Min       88
exploration/Rewards Mean                      2.38895
exploration/Rewards Std                       1.27913
exploration/Rewards Max                       5.70437
exploration/Rewards Min                      -0.826331
exploration/Returns Mean                    322.166
exploration/Returns Std                      86.1485
exploration/Returns Max                     491.783
exploration/Returns Min                     228.885
exploration/Num Paths                         7
exploration/Average Returns                 322.166
evaluation_0/num steps total             680871
evaluation_0/num paths total               4790
evaluation_0/path length Mean               113.957
evaluation_0/path length Std                 14.0381
evaluation_0/path length Max                141
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     2.80446
evaluation_0/Rewards Std                      1.34378
evaluation_0/Rewards Max                      6.15521
evaluation_0/Rewards Min                     -0.509565
evaluation_0/Returns Mean                   319.588
evaluation_0/Returns Std                     34.3917
evaluation_0/Returns Max                    373.553
evaluation_0/Returns Min                    231.263
evaluation_0/Num Paths                       70
evaluation_0/Average Returns                319.588
time/epoch (s)                                0
time/total (s)                             1990.17
Epoch                                        86
---------------------------------------  ---------------
2022-11-16 11:19:12.877247 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 87 finished
---------------------------------------  ---------------
epoch                                        87
total_step                                92000
replay_pool/size                          92000
trainer/alpha                                 0.032955
trainer/alpha_loss                            0.939818
trainer/entropy                              -6.27539
trainer/qf_loss                               5.59873
trainer/state_noise                           0.005
trainer/policy_loss                         -78.2913
trainer/policy_loss_without_entropy          79.1086
trainer/entropy_penalty                      -0.206805
trainer/entropy_percentage                   -0.00261419
trainer/Q1Pred Mean                          78.4593
trainer/Q1Pred Std                           28.9635
trainer/Q1Pred Max                          128.115
trainer/Q1Pred Min                           -2.50492
trainer/Q2Pred Mean                          78.6054
trainer/Q2Pred Std                           29.1702
trainer/Q2Pred Max                          128.688
trainer/Q2Pred Min                           -3.34067
trainer/QTargetWithReg Mean                  78.3124
trainer/QTargetWithReg Std                   29.2094
trainer/QTargetWithReg Max                  128.19
trainer/QTargetWithReg Min                   -0.2569
trainer/PolicyLossWithoutReg Mean            79.1086
trainer/PolicyLossWithoutReg Std             28.5785
trainer/PolicyLossWithoutReg Max            128.29
trainer/PolicyLossWithoutReg Min             -1.81995
trainer/gradient_norm                       122.109
trainer/gradient_penalty                     -0.610543
trainer/gradient_percentage                  -0.00771778
exploration/num steps total               92000
exploration/num paths total                 921
exploration/path length this epoch Mean     136.571
exploration/path length this epoch Std        8.46602
exploration/path length this epoch Max      155
exploration/path length this epoch Min      129
exploration/Rewards Mean                      2.81571
exploration/Rewards Std                       1.39175
exploration/Rewards Max                       6.27367
exploration/Rewards Min                      -1.12007
exploration/Returns Mean                    384.546
exploration/Returns Std                      20.6765
exploration/Returns Max                     424.828
exploration/Returns Min                     353.326
exploration/Num Paths                         7
exploration/Average Returns                 384.546
evaluation_0/num steps total             688870
evaluation_0/num paths total               4849
evaluation_0/path length Mean               135.576
evaluation_0/path length Std                 12.5323
evaluation_0/path length Max                160
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.70374
evaluation_0/Rewards Std                      1.30461
evaluation_0/Rewards Max                      7.33494
evaluation_0/Rewards Min                     -0.520872
evaluation_0/Returns Mean                   366.563
evaluation_0/Returns Std                     50.1275
evaluation_0/Returns Max                    439.774
evaluation_0/Returns Min                    245.794
evaluation_0/Num Paths                       59
evaluation_0/Average Returns                366.563
time/epoch (s)                                0
time/total (s)                             2006.84
Epoch                                        87
---------------------------------------  ---------------
2022-11-16 11:19:29.284334 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 88 finished
---------------------------------------  ---------------
epoch                                        88
total_step                                93000
replay_pool/size                          93000
trainer/alpha                                 0.0340488
trainer/alpha_loss                            0.300464
trainer/entropy                              -6.08889
trainer/qf_loss                               4.9663
trainer/state_noise                           0.005
trainer/policy_loss                         -82.2773
trainer/policy_loss_without_entropy          83.0856
trainer/entropy_penalty                      -0.20732
trainer/entropy_percentage                   -0.00249525
trainer/Q1Pred Mean                          81.8367
trainer/Q1Pred Std                           28.0006
trainer/Q1Pred Max                          135.439
trainer/Q1Pred Min                           -4.92643
trainer/Q2Pred Mean                          81.8577
trainer/Q2Pred Std                           27.9437
trainer/Q2Pred Max                          134.753
trainer/Q2Pred Min                           -4.06739
trainer/QTargetWithReg Mean                  82.4149
trainer/QTargetWithReg Std                   27.8681
trainer/QTargetWithReg Max                  135.665
trainer/QTargetWithReg Min                   -0.371912
trainer/PolicyLossWithoutReg Mean            83.0856
trainer/PolicyLossWithoutReg Std             27.1508
trainer/PolicyLossWithoutReg Max            135.772
trainer/PolicyLossWithoutReg Min              1.17923
trainer/gradient_norm                       120.199
trainer/gradient_penalty                     -0.600993
trainer/gradient_percentage                  -0.00723342
exploration/num steps total               93000
exploration/num paths total                 928
exploration/path length this epoch Mean     141.429
exploration/path length this epoch Std       16.7916
exploration/path length this epoch Max      166
exploration/path length this epoch Min      115
exploration/Rewards Mean                      2.58975
exploration/Rewards Std                       1.30232
exploration/Rewards Max                       6.51922
exploration/Rewards Min                      -0.596303
exploration/Returns Mean                    366.265
exploration/Returns Std                      36.235
exploration/Returns Max                     429.258
exploration/Returns Min                     318.853
exploration/Num Paths                         7
exploration/Average Returns                 366.265
evaluation_0/num steps total             696746
evaluation_0/num paths total               4898
evaluation_0/path length Mean               160.735
evaluation_0/path length Std                 18.6709
evaluation_0/path length Max                183
evaluation_0/path length Min                107
evaluation_0/Rewards Mean                     2.64328
evaluation_0/Rewards Std                      1.23065
evaluation_0/Rewards Max                      5.91034
evaluation_0/Rewards Min                     -0.341803
evaluation_0/Returns Mean                   424.867
evaluation_0/Returns Std                     60.4951
evaluation_0/Returns Max                    478.832
evaluation_0/Returns Min                    229.329
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                424.867
time/epoch (s)                                0
time/total (s)                             2023.24
Epoch                                        88
---------------------------------------  ---------------
2022-11-16 11:19:45.663964 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 89 finished
---------------------------------------  ---------------
epoch                                        89
total_step                                94000
replay_pool/size                          94000
trainer/alpha                                 0.0326828
trainer/alpha_loss                            0.100826
trainer/entropy                              -6.02947
trainer/qf_loss                               4.21931
trainer/state_noise                           0.005
trainer/policy_loss                         -80.9377
trainer/policy_loss_without_entropy          81.7119
trainer/entropy_penalty                      -0.19706
trainer/entropy_percentage                   -0.00241165
trainer/Q1Pred Mean                          81.2993
trainer/Q1Pred Std                           30.8018
trainer/Q1Pred Max                          130.535
trainer/Q1Pred Min                           -1.46374
trainer/Q2Pred Mean                          81.4325
trainer/Q2Pred Std                           30.8449
trainer/Q2Pred Max                          130.804
trainer/Q2Pred Min                            0.476991
trainer/QTargetWithReg Mean                  81.2308
trainer/QTargetWithReg Std                   31.1671
trainer/QTargetWithReg Max                  131.432
trainer/QTargetWithReg Min                   -5.55933
trainer/PolicyLossWithoutReg Mean            81.7118
trainer/PolicyLossWithoutReg Std             30.6769
trainer/PolicyLossWithoutReg Max            130.13
trainer/PolicyLossWithoutReg Min             -2.3162
trainer/gradient_norm                       115.426
trainer/gradient_penalty                     -0.577132
trainer/gradient_percentage                  -0.00706301
exploration/num steps total               94000
exploration/num paths total                 935
exploration/path length this epoch Mean     140.714
exploration/path length this epoch Std       24.5457
exploration/path length this epoch Max      187
exploration/path length this epoch Min      117
exploration/Rewards Mean                      2.55657
exploration/Rewards Std                       1.30006
exploration/Rewards Max                       5.87853
exploration/Rewards Min                      -0.930964
exploration/Returns Mean                    359.746
exploration/Returns Std                      46.1953
exploration/Returns Max                     416.195
exploration/Returns Min                     281.31
exploration/Num Paths                         7
exploration/Average Returns                 359.746
evaluation_0/num steps total             704521
evaluation_0/num paths total               4943
evaluation_0/path length Mean               172.778
evaluation_0/path length Std                 18.8655
evaluation_0/path length Max                285
evaluation_0/path length Min                147
evaluation_0/Rewards Mean                     2.71085
evaluation_0/Rewards Std                      1.23999
evaluation_0/Rewards Max                      5.74724
evaluation_0/Rewards Min                     -0.672466
evaluation_0/Returns Mean                   468.375
evaluation_0/Returns Std                     60.9514
evaluation_0/Returns Max                    836.714
evaluation_0/Returns Min                    366.047
evaluation_0/Num Paths                       45
evaluation_0/Average Returns                468.375
time/epoch (s)                                0
time/total (s)                             2039.62
Epoch                                        89
---------------------------------------  ---------------
2022-11-16 11:20:02.600799 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 90 finished
---------------------------------------  ---------------
epoch                                        90
total_step                                95000
replay_pool/size                          95000
trainer/alpha                                 0.0330019
trainer/alpha_loss                           -0.919493
trainer/entropy                              -5.73046
trainer/qf_loss                               4.73409
trainer/state_noise                           0.005
trainer/policy_loss                         -85.3365
trainer/policy_loss_without_entropy          86.125
trainer/entropy_penalty                      -0.189116
trainer/entropy_percentage                   -0.00219583
trainer/Q1Pred Mean                          85.6705
trainer/Q1Pred Std                           29.1659
trainer/Q1Pred Max                          134.936
trainer/Q1Pred Min                          -31.8615
trainer/Q2Pred Mean                          85.4682
trainer/Q2Pred Std                           29.1394
trainer/Q2Pred Max                          133.137
trainer/Q2Pred Min                          -32.4015
trainer/QTargetWithReg Mean                  85.7458
trainer/QTargetWithReg Std                   29.4091
trainer/QTargetWithReg Max                  135.839
trainer/QTargetWithReg Min                  -34.718
trainer/PolicyLossWithoutReg Mean            86.125
trainer/PolicyLossWithoutReg Std             28.6999
trainer/PolicyLossWithoutReg Max            133.578
trainer/PolicyLossWithoutReg Min            -28.7965
trainer/gradient_norm                       119.887
trainer/gradient_penalty                     -0.599434
trainer/gradient_percentage                  -0.00696005
exploration/num steps total               95000
exploration/num paths total                 942
exploration/path length this epoch Mean     129.571
exploration/path length this epoch Std       33.5468
exploration/path length this epoch Max      170
exploration/path length this epoch Min       84
exploration/Rewards Mean                      2.79396
exploration/Rewards Std                       1.40064
exploration/Rewards Max                       5.95722
exploration/Rewards Min                      -0.927678
exploration/Returns Mean                    362.017
exploration/Returns Std                      80.8968
exploration/Returns Max                     466.73
exploration/Returns Min                     226.523
exploration/Num Paths                         7
exploration/Average Returns                 362.017
evaluation_0/num steps total             712416
evaluation_0/num paths total               5004
evaluation_0/path length Mean               129.426
evaluation_0/path length Std                 20.3796
evaluation_0/path length Max                181
evaluation_0/path length Min                 94
evaluation_0/Rewards Mean                     2.42262
evaluation_0/Rewards Std                      1.26404
evaluation_0/Rewards Max                      6.75166
evaluation_0/Rewards Min                     -0.808975
evaluation_0/Returns Mean                   313.551
evaluation_0/Returns Std                     65.7952
evaluation_0/Returns Max                    435.363
evaluation_0/Returns Min                    190.993
evaluation_0/Num Paths                       61
evaluation_0/Average Returns                313.551
time/epoch (s)                                0
time/total (s)                             2056.56
Epoch                                        90
---------------------------------------  ---------------
2022-11-16 11:20:18.651843 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 91 finished
---------------------------------------  ---------------
epoch                                        91
total_step                                96000
replay_pool/size                          96000
trainer/alpha                                 0.03412
trainer/alpha_loss                            0.172472
trainer/entropy                              -6.05106
trainer/qf_loss                               3.92576
trainer/state_noise                           0.005
trainer/policy_loss                         -85.3696
trainer/policy_loss_without_entropy          86.1628
trainer/entropy_penalty                      -0.206462
trainer/entropy_percentage                   -0.00239619
trainer/Q1Pred Mean                          85.0695
trainer/Q1Pred Std                           30.9803
trainer/Q1Pred Max                          137.633
trainer/Q1Pred Min                           -6.65597
trainer/Q2Pred Mean                          85.0012
trainer/Q2Pred Std                           30.8553
trainer/Q2Pred Max                          136.924
trainer/Q2Pred Min                           -5.74505
trainer/QTargetWithReg Mean                  85.145
trainer/QTargetWithReg Std                   30.8899
trainer/QTargetWithReg Max                  136.611
trainer/QTargetWithReg Min                   -3.01685
trainer/PolicyLossWithoutReg Mean            86.1628
trainer/PolicyLossWithoutReg Std             30.5748
trainer/PolicyLossWithoutReg Max            137.309
trainer/PolicyLossWithoutReg Min              0.396152
trainer/gradient_norm                       117.354
trainer/gradient_penalty                     -0.586768
trainer/gradient_percentage                  -0.00681
exploration/num steps total               96000
exploration/num paths total                 948
exploration/path length this epoch Mean     163.667
exploration/path length this epoch Std       27.9205
exploration/path length this epoch Max      223
exploration/path length this epoch Min      140
exploration/Rewards Mean                      2.73388
exploration/Rewards Std                       1.32191
exploration/Rewards Max                       7.46102
exploration/Rewards Min                      -0.904313
exploration/Returns Mean                    447.446
exploration/Returns Std                     128.124
exploration/Returns Max                     728.07
exploration/Returns Min                     344.831
exploration/Num Paths                         6
exploration/Average Returns                 447.446
evaluation_0/num steps total             720342
evaluation_0/num paths total               5062
evaluation_0/path length Mean               136.655
evaluation_0/path length Std                  4.29335
evaluation_0/path length Max                152
evaluation_0/path length Min                127
evaluation_0/Rewards Mean                     2.38449
evaluation_0/Rewards Std                      1.21541
evaluation_0/Rewards Max                      5.26741
evaluation_0/Rewards Min                     -0.68496
evaluation_0/Returns Mean                   325.853
evaluation_0/Returns Std                     15.8879
evaluation_0/Returns Max                    396.515
evaluation_0/Returns Min                    305.101
evaluation_0/Num Paths                       58
evaluation_0/Average Returns                325.853
time/epoch (s)                                0
time/total (s)                             2072.61
Epoch                                        91
---------------------------------------  ---------------
2022-11-16 11:20:36.430697 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 92 finished
---------------------------------------  ---------------
epoch                                        92
total_step                                97000
replay_pool/size                          97000
trainer/alpha                                 0.0342274
trainer/alpha_loss                            0.724185
trainer/entropy                              -6.21459
trainer/qf_loss                               4.58759
trainer/state_noise                           0.005
trainer/policy_loss                         -82.373
trainer/policy_loss_without_entropy          83.2108
trainer/entropy_penalty                      -0.21271
trainer/entropy_percentage                   -0.00255627
trainer/Q1Pred Mean                          82.0443
trainer/Q1Pred Std                           28.4865
trainer/Q1Pred Max                          132.796
trainer/Q1Pred Min                            3.77769
trainer/Q2Pred Mean                          82.3548
trainer/Q2Pred Std                           28.3118
trainer/Q2Pred Max                          131.246
trainer/Q2Pred Min                            4.68862
trainer/QTargetWithReg Mean                  82.1109
trainer/QTargetWithReg Std                   28.7364
trainer/QTargetWithReg Max                  132.003
trainer/QTargetWithReg Min                   -5.9415
trainer/PolicyLossWithoutReg Mean            83.2108
trainer/PolicyLossWithoutReg Std             27.8518
trainer/PolicyLossWithoutReg Max            131.965
trainer/PolicyLossWithoutReg Min              4.24025
trainer/gradient_norm                       125.022
trainer/gradient_penalty                     -0.625108
trainer/gradient_percentage                  -0.00751234
exploration/num steps total               97000
exploration/num paths total                 955
exploration/path length this epoch Mean     138.571
exploration/path length this epoch Std        6.25316
exploration/path length this epoch Max      146
exploration/path length this epoch Min      128
exploration/Rewards Mean                      2.52867
exploration/Rewards Std                       1.24972
exploration/Rewards Max                       5.60881
exploration/Rewards Min                      -1.0947
exploration/Returns Mean                    350.402
exploration/Returns Std                      23.9903
exploration/Returns Max                     381.958
exploration/Returns Min                     316.241
exploration/Num Paths                         7
exploration/Average Returns                 350.402
evaluation_0/num steps total             728310
evaluation_0/num paths total               5114
evaluation_0/path length Mean               153.231
evaluation_0/path length Std                 52.0553
evaluation_0/path length Max                321
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     2.49175
evaluation_0/Rewards Std                      1.15166
evaluation_0/Rewards Max                      6.213
evaluation_0/Rewards Min                     -0.559028
evaluation_0/Returns Mean                   381.812
evaluation_0/Returns Std                    163.895
evaluation_0/Returns Max                    872.88
evaluation_0/Returns Min                    219.488
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                381.812
time/epoch (s)                                0
time/total (s)                             2090.39
Epoch                                        92
---------------------------------------  ---------------
2022-11-16 11:20:54.327835 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 93 finished
---------------------------------------  ---------------
epoch                                        93
total_step                                98000
replay_pool/size                          98000
trainer/alpha                                 0.0342323
trainer/alpha_loss                           -0.061851
trainer/entropy                              -5.98167
trainer/qf_loss                               4.85837
trainer/state_noise                           0.005
trainer/policy_loss                         -83.0378
trainer/policy_loss_without_entropy          83.8623
trainer/entropy_penalty                      -0.204766
trainer/entropy_percentage                   -0.0024417
trainer/Q1Pred Mean                          83.1347
trainer/Q1Pred Std                           32.4817
trainer/Q1Pred Max                          134.901
trainer/Q1Pred Min                           -8.83977
trainer/Q2Pred Mean                          83.2865
trainer/Q2Pred Std                           32.4771
trainer/Q2Pred Max                          135.502
trainer/Q2Pred Min                           -7.84064
trainer/QTargetWithReg Mean                  82.8264
trainer/QTargetWithReg Std                   32.6567
trainer/QTargetWithReg Max                  134.86
trainer/QTargetWithReg Min                   -2.02687
trainer/PolicyLossWithoutReg Mean            83.8623
trainer/PolicyLossWithoutReg Std             31.7121
trainer/PolicyLossWithoutReg Max            134.228
trainer/PolicyLossWithoutReg Min            -12.0242
trainer/gradient_norm                       123.952
trainer/gradient_penalty                     -0.619758
trainer/gradient_percentage                  -0.00739019
exploration/num steps total               98000
exploration/num paths total                 961
exploration/path length this epoch Mean     166.167
exploration/path length this epoch Std       34.095
exploration/path length this epoch Max      221
exploration/path length this epoch Min      122
exploration/Rewards Mean                      2.61356
exploration/Rewards Std                       1.24641
exploration/Rewards Max                       7.42282
exploration/Rewards Min                      -0.838416
exploration/Returns Mean                    434.286
exploration/Returns Std                     123.813
exploration/Returns Max                     643.63
exploration/Returns Min                     280.98
exploration/Num Paths                         6
exploration/Average Returns                 434.286
evaluation_0/num steps total             735836
evaluation_0/num paths total               5153
evaluation_0/path length Mean               192.974
evaluation_0/path length Std                 61.7839
evaluation_0/path length Max                367
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     2.67557
evaluation_0/Rewards Std                      1.29286
evaluation_0/Rewards Max                      7.7359
evaluation_0/Rewards Min                     -0.821787
evaluation_0/Returns Mean                   516.317
evaluation_0/Returns Std                    157.364
evaluation_0/Returns Max                    823.941
evaluation_0/Returns Min                    293.167
evaluation_0/Num Paths                       39
evaluation_0/Average Returns                516.317
time/epoch (s)                                0
time/total (s)                             2108.29
Epoch                                        93
---------------------------------------  ---------------
2022-11-16 11:21:11.403774 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 94 finished
---------------------------------------  ---------------
epoch                                        94
total_step                                99000
replay_pool/size                          99000
trainer/alpha                                 0.0344027
trainer/alpha_loss                            0.0452809
trainer/entropy                              -6.01344
trainer/qf_loss                               4.08758
trainer/state_noise                           0.005
trainer/policy_loss                         -88.0396
trainer/policy_loss_without_entropy          88.832
trainer/entropy_penalty                      -0.206878
trainer/entropy_percentage                   -0.00232887
trainer/Q1Pred Mean                          87.9879
trainer/Q1Pred Std                           30.6313
trainer/Q1Pred Max                          137.925
trainer/Q1Pred Min                          -18.5639
trainer/Q2Pred Mean                          87.8745
trainer/Q2Pred Std                           30.9365
trainer/Q2Pred Max                          137.507
trainer/Q2Pred Min                          -21.0467
trainer/QTargetWithReg Mean                  88.1543
trainer/QTargetWithReg Std                   30.6858
trainer/QTargetWithReg Max                  136.331
trainer/QTargetWithReg Min                  -16.354
trainer/PolicyLossWithoutReg Mean            88.832
trainer/PolicyLossWithoutReg Std             30.4426
trainer/PolicyLossWithoutReg Max            137.798
trainer/PolicyLossWithoutReg Min            -20.9644
trainer/gradient_norm                       117.093
trainer/gradient_penalty                     -0.585467
trainer/gradient_percentage                  -0.00659072
exploration/num steps total               99000
exploration/num paths total                 966
exploration/path length this epoch Mean     163.4
exploration/path length this epoch Std       20.5971
exploration/path length this epoch Max      185
exploration/path length this epoch Min      126
exploration/Rewards Mean                      2.53684
exploration/Rewards Std                       1.18496
exploration/Rewards Max                       5.86979
exploration/Rewards Min                      -0.707427
exploration/Returns Mean                    414.52
exploration/Returns Std                      59.5836
exploration/Returns Max                     464.42
exploration/Returns Min                     301.263
exploration/Num Paths                         5
exploration/Average Returns                 414.52
evaluation_0/num steps total             743753
evaluation_0/num paths total               5201
evaluation_0/path length Mean               164.938
evaluation_0/path length Std                 19.8949
evaluation_0/path length Max                242
evaluation_0/path length Min                138
evaluation_0/Rewards Mean                     2.41245
evaluation_0/Rewards Std                      1.16337
evaluation_0/Rewards Max                      6.61373
evaluation_0/Rewards Min                     -0.694007
evaluation_0/Returns Mean                   397.903
evaluation_0/Returns Std                     76.0696
evaluation_0/Returns Max                    609.396
evaluation_0/Returns Min                    279.824
evaluation_0/Num Paths                       48
evaluation_0/Average Returns                397.903
time/epoch (s)                                0
time/total (s)                             2125.36
Epoch                                        94
---------------------------------------  ---------------
2022-11-16 11:21:28.287341 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 95 finished
---------------------------------------  ---------------
epoch                                        95
total_step                               100000
replay_pool/size                         100000
trainer/alpha                                 0.0345884
trainer/alpha_loss                            2.20101
trainer/entropy                              -6.65421
trainer/qf_loss                               3.94549
trainer/state_noise                           0.005
trainer/policy_loss                         -83.5688
trainer/policy_loss_without_entropy          84.438
trainer/entropy_penalty                      -0.230159
trainer/entropy_percentage                   -0.00272577
trainer/Q1Pred Mean                          83.3347
trainer/Q1Pred Std                           30.1845
trainer/Q1Pred Max                          135.803
trainer/Q1Pred Min                           -4.80182
trainer/Q2Pred Mean                          83.284
trainer/Q2Pred Std                           30.3508
trainer/Q2Pred Max                          135.835
trainer/Q2Pred Min                           -5.44099
trainer/QTargetWithReg Mean                  83.4172
trainer/QTargetWithReg Std                   30.1069
trainer/QTargetWithReg Max                  136.072
trainer/QTargetWithReg Min                   -2.14717
trainer/PolicyLossWithoutReg Mean            84.438
trainer/PolicyLossWithoutReg Std             29.6092
trainer/PolicyLossWithoutReg Max            135.665
trainer/PolicyLossWithoutReg Min             -3.39078
trainer/gradient_norm                       127.8
trainer/gradient_penalty                     -0.638998
trainer/gradient_percentage                  -0.00756766
exploration/num steps total              100000
exploration/num paths total                 970
exploration/path length this epoch Mean     234.25
exploration/path length this epoch Std       41.6976
exploration/path length this epoch Max      298
exploration/path length this epoch Min      181
exploration/Rewards Mean                      2.66412
exploration/Rewards Std                       1.27106
exploration/Rewards Max                       7.19858
exploration/Rewards Min                      -0.79371
exploration/Returns Mean                    624.07
exploration/Returns Std                     134.014
exploration/Returns Max                     840.487
exploration/Returns Min                     496.129
exploration/Num Paths                         4
exploration/Average Returns                 624.07
evaluation_0/num steps total             751691
evaluation_0/num paths total               5243
evaluation_0/path length Mean               189
evaluation_0/path length Std                 58.5589
evaluation_0/path length Max                336
evaluation_0/path length Min                132
evaluation_0/Rewards Mean                     2.69596
evaluation_0/Rewards Std                      1.32994
evaluation_0/Rewards Max                      7.44092
evaluation_0/Rewards Min                     -0.766758
evaluation_0/Returns Mean                   509.537
evaluation_0/Returns Std                    198.414
evaluation_0/Returns Max                    989.481
evaluation_0/Returns Min                    305.516
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                509.537
time/epoch (s)                                0
time/total (s)                             2142.25
Epoch                                        95
---------------------------------------  ---------------
2022-11-16 11:21:44.870831 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 96 finished
---------------------------------------  ---------------
epoch                                        96
total_step                               101000
replay_pool/size                         101000
trainer/alpha                                 0.0347559
trainer/alpha_loss                           -0.335932
trainer/entropy                              -5.90001
trainer/qf_loss                               8.32669
trainer/state_noise                           0.005
trainer/policy_loss                         -89.4186
trainer/policy_loss_without_entropy          90.2015
trainer/entropy_penalty                      -0.20506
trainer/entropy_percentage                   -0.00227335
trainer/Q1Pred Mean                          89.9851
trainer/Q1Pred Std                           30.2213
trainer/Q1Pred Max                          135.943
trainer/Q1Pred Min                          -13.6396
trainer/Q2Pred Mean                          89.9878
trainer/Q2Pred Std                           30.1041
trainer/Q2Pred Max                          135.187
trainer/Q2Pred Min                          -15.9881
trainer/QTargetWithReg Mean                  89.8506
trainer/QTargetWithReg Std                   30.4264
trainer/QTargetWithReg Max                  135.526
trainer/QTargetWithReg Min                  -17.4299
trainer/PolicyLossWithoutReg Mean            90.2015
trainer/PolicyLossWithoutReg Std             30.0779
trainer/PolicyLossWithoutReg Max            135.28
trainer/PolicyLossWithoutReg Min            -11.1214
trainer/gradient_norm                       115.581
trainer/gradient_penalty                     -0.577903
trainer/gradient_percentage                  -0.0064068
exploration/num steps total              101000
exploration/num paths total                 976
exploration/path length this epoch Mean     165.167
exploration/path length this epoch Std       44.2019
exploration/path length this epoch Max      229
exploration/path length this epoch Min      116
exploration/Rewards Mean                      2.82419
exploration/Rewards Std                       1.40443
exploration/Rewards Max                       5.96745
exploration/Rewards Min                      -0.80748
exploration/Returns Mean                    466.462
exploration/Returns Std                     140.727
exploration/Returns Max                     660.306
exploration/Returns Min                     320.943
exploration/Num Paths                         6
exploration/Average Returns                 466.462
evaluation_0/num steps total             759597
evaluation_0/num paths total               5302
evaluation_0/path length Mean               134
evaluation_0/path length Std                  9.18916
evaluation_0/path length Max                163
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     2.48924
evaluation_0/Rewards Std                      1.43205
evaluation_0/Rewards Max                      6.80046
evaluation_0/Rewards Min                     -0.516152
evaluation_0/Returns Mean                   333.557
evaluation_0/Returns Std                     21.3238
evaluation_0/Returns Max                    391.235
evaluation_0/Returns Min                    273.58
evaluation_0/Num Paths                       59
evaluation_0/Average Returns                333.557
time/epoch (s)                                0
time/total (s)                             2158.83
Epoch                                        96
---------------------------------------  ---------------
2022-11-16 11:22:01.156859 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 97 finished
---------------------------------------  ---------------
epoch                                        97
total_step                               102000
replay_pool/size                         102000
trainer/alpha                                 0.0348729
trainer/alpha_loss                           -0.271893
trainer/entropy                              -5.91898
trainer/qf_loss                               3.65909
trainer/state_noise                           0.005
trainer/policy_loss                         -87.3581
trainer/policy_loss_without_entropy          88.155
trainer/entropy_penalty                      -0.206412
trainer/entropy_percentage                   -0.00234147
trainer/Q1Pred Mean                          87.8951
trainer/Q1Pred Std                           29.9548
trainer/Q1Pred Max                          134.273
trainer/Q1Pred Min                           -9.71956
trainer/Q2Pred Mean                          87.7443
trainer/Q2Pred Std                           29.9387
trainer/Q2Pred Max                          133.321
trainer/Q2Pred Min                            1.66377
trainer/QTargetWithReg Mean                  87.9393
trainer/QTargetWithReg Std                   30.2326
trainer/QTargetWithReg Max                  133.669
trainer/QTargetWithReg Min                   -0.563669
trainer/PolicyLossWithoutReg Mean            88.155
trainer/PolicyLossWithoutReg Std             29.7554
trainer/PolicyLossWithoutReg Max            133.175
trainer/PolicyLossWithoutReg Min              5.98129
trainer/gradient_norm                       118.1
trainer/gradient_penalty                     -0.590502
trainer/gradient_percentage                  -0.00669845
exploration/num steps total              102000
exploration/num paths total                 981
exploration/path length this epoch Mean     183.4
exploration/path length this epoch Std       45.6798
exploration/path length this epoch Max      267
exploration/path length this epoch Min      135
exploration/Rewards Mean                      2.59622
exploration/Rewards Std                       1.33766
exploration/Rewards Max                       6.88465
exploration/Rewards Min                      -0.770453
exploration/Returns Mean                    476.146
exploration/Returns Std                     144.616
exploration/Returns Max                     745.117
exploration/Returns Min                     341.262
exploration/Num Paths                         5
exploration/Average Returns                 476.146
evaluation_0/num steps total             767470
evaluation_0/num paths total               5351
evaluation_0/path length Mean               160.673
evaluation_0/path length Std                 17.1243
evaluation_0/path length Max                204
evaluation_0/path length Min                138
evaluation_0/Rewards Mean                     2.59495
evaluation_0/Rewards Std                      1.38591
evaluation_0/Rewards Max                      6.64332
evaluation_0/Rewards Min                     -0.690567
evaluation_0/Returns Mean                   416.94
evaluation_0/Returns Std                     35.2475
evaluation_0/Returns Max                    526.606
evaluation_0/Returns Min                    353.689
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                416.94
time/epoch (s)                                0
time/total (s)                             2175.11
Epoch                                        97
---------------------------------------  ---------------
2022-11-16 11:22:18.365080 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 98 finished
---------------------------------------  ---------------
epoch                                        98
total_step                               103000
replay_pool/size                         103000
trainer/alpha                                 0.0347599
trainer/alpha_loss                            1.2399
trainer/entropy                              -6.3691
trainer/qf_loss                               5.11642
trainer/state_noise                           0.005
trainer/policy_loss                         -86.8384
trainer/policy_loss_without_entropy          87.6807
trainer/entropy_penalty                      -0.221389
trainer/entropy_percentage                   -0.00252495
trainer/Q1Pred Mean                          86.2755
trainer/Q1Pred Std                           31.6085
trainer/Q1Pred Max                          137.954
trainer/Q1Pred Min                          -15.0092
trainer/Q2Pred Mean                          86.5755
trainer/Q2Pred Std                           31.8159
trainer/Q2Pred Max                          138.907
trainer/Q2Pred Min                          -17.2578
trainer/QTargetWithReg Mean                  86.2948
trainer/QTargetWithReg Std                   31.8041
trainer/QTargetWithReg Max                  138.682
trainer/QTargetWithReg Min                  -11.8285
trainer/PolicyLossWithoutReg Mean            87.6807
trainer/PolicyLossWithoutReg Std             31.2261
trainer/PolicyLossWithoutReg Max            138.439
trainer/PolicyLossWithoutReg Min            -13.6095
trainer/gradient_norm                       124.175
trainer/gradient_penalty                     -0.620876
trainer/gradient_percentage                  -0.00708111
exploration/num steps total              103000
exploration/num paths total                 988
exploration/path length this epoch Mean     136.429
exploration/path length this epoch Std       22.0315
exploration/path length this epoch Max      174
exploration/path length this epoch Min      104
exploration/Rewards Mean                      2.63503
exploration/Rewards Std                       1.37922
exploration/Rewards Max                       6.05422
exploration/Rewards Min                      -0.879949
exploration/Returns Mean                    359.493
exploration/Returns Std                      69.6543
exploration/Returns Max                     483.638
exploration/Returns Min                     255.894
exploration/Num Paths                         7
exploration/Average Returns                 359.493
evaluation_0/num steps total             775367
evaluation_0/num paths total               5393
evaluation_0/path length Mean               188.024
evaluation_0/path length Std                 38.398
evaluation_0/path length Max                282
evaluation_0/path length Min                136
evaluation_0/Rewards Mean                     2.53761
evaluation_0/Rewards Std                      1.20875
evaluation_0/Rewards Max                      7.32313
evaluation_0/Rewards Min                     -0.570429
evaluation_0/Returns Mean                   477.131
evaluation_0/Returns Std                    141.789
evaluation_0/Returns Max                    859.043
evaluation_0/Returns Min                    324.797
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                477.131
time/epoch (s)                                0
time/total (s)                             2192.32
Epoch                                        98
---------------------------------------  ---------------
2022-11-16 11:22:35.013841 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 99 finished
---------------------------------------  ---------------
epoch                                        99
total_step                               104000
replay_pool/size                         104000
trainer/alpha                                 0.0352176
trainer/alpha_loss                           -1.79663
trainer/entropy                              -5.46308
trainer/qf_loss                               3.56621
trainer/state_noise                           0.005
trainer/policy_loss                         -87.2493
trainer/policy_loss_without_entropy          88.0691
trainer/entropy_penalty                      -0.192396
trainer/entropy_percentage                   -0.00218461
trainer/Q1Pred Mean                          86.6223
trainer/Q1Pred Std                           31.0443
trainer/Q1Pred Max                          138.209
trainer/Q1Pred Min                          -14.4958
trainer/Q2Pred Mean                          86.8696
trainer/Q2Pred Std                           31.0935
trainer/Q2Pred Max                          137.664
trainer/Q2Pred Min                           -5.94129
trainer/QTargetWithReg Mean                  86.7981
trainer/QTargetWithReg Std                   31.1076
trainer/QTargetWithReg Max                  138.368
trainer/QTargetWithReg Min                   -8.36331
trainer/PolicyLossWithoutReg Mean            88.0691
trainer/PolicyLossWithoutReg Std             30.1312
trainer/PolicyLossWithoutReg Max            138.063
trainer/PolicyLossWithoutReg Min             -1.64439
trainer/gradient_norm                       125.496
trainer/gradient_penalty                     -0.627482
trainer/gradient_percentage                  -0.00712488
exploration/num steps total              104000
exploration/num paths total                 995
exploration/path length this epoch Mean     139.714
exploration/path length this epoch Std       38.164
exploration/path length this epoch Max      212
exploration/path length this epoch Min      103
exploration/Rewards Mean                      2.7697
exploration/Rewards Std                       1.39704
exploration/Rewards Max                       6.8988
exploration/Rewards Min                      -0.782332
exploration/Returns Mean                    386.966
exploration/Returns Std                     139.985
exploration/Returns Max                     687.997
exploration/Returns Min                     261.632
exploration/Num Paths                         7
exploration/Average Returns                 386.966
evaluation_0/num steps total             783348
evaluation_0/num paths total               5442
evaluation_0/path length Mean               162.878
evaluation_0/path length Std                 37.1174
evaluation_0/path length Max                364
evaluation_0/path length Min                125
evaluation_0/Rewards Mean                     2.02033
evaluation_0/Rewards Std                      1.32761
evaluation_0/Rewards Max                      6.43694
evaluation_0/Rewards Min                     -0.67563
evaluation_0/Returns Mean                   329.066
evaluation_0/Returns Std                     53.1402
evaluation_0/Returns Max                    596.003
evaluation_0/Returns Min                    295.046
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                329.066
time/epoch (s)                                0
time/total (s)                             2208.97
Epoch                                        99
---------------------------------------  ---------------
2022-11-16 11:22:52.936222 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 100 finished
---------------------------------------  ---------------
epoch                                       100
total_step                               105000
replay_pool/size                         105000
trainer/alpha                                 0.0352185
trainer/alpha_loss                            1.77463
trainer/entropy                              -6.53029
trainer/qf_loss                               4.3618
trainer/state_noise                           0.005
trainer/policy_loss                         -92.9683
trainer/policy_loss_without_entropy          93.8135
trainer/entropy_penalty                      -0.229987
trainer/entropy_percentage                   -0.00245154
trainer/Q1Pred Mean                          92.1604
trainer/Q1Pred Std                           28.5795
trainer/Q1Pred Max                          137.227
trainer/Q1Pred Min                           -8.54126
trainer/Q2Pred Mean                          92.5636
trainer/Q2Pred Std                           28.5217
trainer/Q2Pred Max                          137.122
trainer/Q2Pred Min                           -5.47886
trainer/QTargetWithReg Mean                  92.0877
trainer/QTargetWithReg Std                   28.4697
trainer/QTargetWithReg Max                  136.421
trainer/QTargetWithReg Min                   -5.22745
trainer/PolicyLossWithoutReg Mean            93.8135
trainer/PolicyLossWithoutReg Std             27.8947
trainer/PolicyLossWithoutReg Max            137.258
trainer/PolicyLossWithoutReg Min             -2.52194
trainer/gradient_norm                       123.04
trainer/gradient_penalty                     -0.615198
trainer/gradient_percentage                  -0.00655768
exploration/num steps total              105000
exploration/num paths total                1001
exploration/path length this epoch Mean     163.667
exploration/path length this epoch Std       45.6241
exploration/path length this epoch Max      233
exploration/path length this epoch Min      122
exploration/Rewards Mean                      2.48058
exploration/Rewards Std                       1.35863
exploration/Rewards Max                       6.88319
exploration/Rewards Min                      -0.781568
exploration/Returns Mean                    405.988
exploration/Returns Std                     144.082
exploration/Returns Max                     655.772
exploration/Returns Min                     253.921
exploration/Num Paths                         6
exploration/Average Returns                 405.988
evaluation_0/num steps total             791084
evaluation_0/num paths total               5483
evaluation_0/path length Mean               188.683
evaluation_0/path length Std                 69.1818
evaluation_0/path length Max                543
evaluation_0/path length Min                129
evaluation_0/Rewards Mean                     2.13926
evaluation_0/Rewards Std                      1.2322
evaluation_0/Rewards Max                      7.51956
evaluation_0/Rewards Min                     -1.0429
evaluation_0/Returns Mean                   403.642
evaluation_0/Returns Std                    226.707
evaluation_0/Returns Max                   1532.92
evaluation_0/Returns Min                    202.65
evaluation_0/Num Paths                       41
evaluation_0/Average Returns                403.642
time/epoch (s)                                0
time/total (s)                             2226.89
Epoch                                       100
---------------------------------------  ---------------
2022-11-16 11:23:10.305043 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 101 finished
---------------------------------------  ---------------
epoch                                       101
total_step                               106000
replay_pool/size                         106000
trainer/alpha                                 0.0366584
trainer/alpha_loss                            0.600382
trainer/entropy                              -6.1816
trainer/qf_loss                               3.53685
trainer/state_noise                           0.005
trainer/policy_loss                         -89.3586
trainer/policy_loss_without_entropy          90.2084
trainer/entropy_penalty                      -0.226607
trainer/entropy_percentage                   -0.00251204
trainer/Q1Pred Mean                          88.6143
trainer/Q1Pred Std                           32.5601
trainer/Q1Pred Max                          139.649
trainer/Q1Pred Min                           -1.56242
trainer/Q2Pred Mean                          88.5886
trainer/Q2Pred Std                           32.799
trainer/Q2Pred Max                          137.852
trainer/Q2Pred Min                          -10.1137
trainer/QTargetWithReg Mean                  88.9736
trainer/QTargetWithReg Std                   32.649
trainer/QTargetWithReg Max                  139.468
trainer/QTargetWithReg Min                  -12.0503
trainer/PolicyLossWithoutReg Mean            90.2084
trainer/PolicyLossWithoutReg Std             31.1362
trainer/PolicyLossWithoutReg Max            138.582
trainer/PolicyLossWithoutReg Min             -1.17981
trainer/gradient_norm                       124.651
trainer/gradient_penalty                     -0.623257
trainer/gradient_percentage                  -0.00690908
exploration/num steps total              106000
exploration/num paths total                1005
exploration/path length this epoch Mean     225.25
exploration/path length this epoch Std       47.678
exploration/path length this epoch Max      291
exploration/path length this epoch Min      160
exploration/Rewards Mean                      2.94207
exploration/Rewards Std                       1.41252
exploration/Rewards Max                       6.92924
exploration/Rewards Min                      -0.63709
exploration/Returns Mean                    662.7
exploration/Returns Std                     175.468
exploration/Returns Max                     887.737
exploration/Returns Min                     395.399
exploration/Num Paths                         4
exploration/Average Returns                 662.7
evaluation_0/num steps total             799042
evaluation_0/num paths total               5523
evaluation_0/path length Mean               198.95
evaluation_0/path length Std                 67.8439
evaluation_0/path length Max                402
evaluation_0/path length Min                125
evaluation_0/Rewards Mean                     2.44302
evaluation_0/Rewards Std                      1.2314
evaluation_0/Rewards Max                      7.08215
evaluation_0/Rewards Min                     -0.669177
evaluation_0/Returns Mean                   486.04
evaluation_0/Returns Std                    244.499
evaluation_0/Returns Max                   1266.76
evaluation_0/Returns Min                    235.093
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                486.04
time/epoch (s)                                0
time/total (s)                             2244.26
Epoch                                       101
---------------------------------------  ---------------
2022-11-16 11:23:26.480054 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 102 finished
---------------------------------------  ---------------
epoch                                       102
total_step                               107000
replay_pool/size                         107000
trainer/alpha                                 0.036829
trainer/alpha_loss                           -0.150917
trainer/entropy                              -5.95429
trainer/qf_loss                               4.43091
trainer/state_noise                           0.005
trainer/policy_loss                         -89.1131
trainer/policy_loss_without_entropy          89.9437
trainer/entropy_penalty                      -0.21929
trainer/entropy_percentage                   -0.00243808
trainer/Q1Pred Mean                          89.2081
trainer/Q1Pred Std                           32.5795
trainer/Q1Pred Max                          135.394
trainer/Q1Pred Min                           -2.13573
trainer/Q2Pred Mean                          89.3287
trainer/Q2Pred Std                           32.7546
trainer/Q2Pred Max                          135.735
trainer/Q2Pred Min                           -2.31654
trainer/QTargetWithReg Mean                  89.3928
trainer/QTargetWithReg Std                   32.835
trainer/QTargetWithReg Max                  135.556
trainer/QTargetWithReg Min                    0.196671
trainer/PolicyLossWithoutReg Mean            89.9437
trainer/PolicyLossWithoutReg Std             32.2542
trainer/PolicyLossWithoutReg Max            135.136
trainer/PolicyLossWithoutReg Min             -0.863306
trainer/gradient_norm                       122.258
trainer/gradient_penalty                     -0.61129
trainer/gradient_percentage                  -0.00679636
exploration/num steps total              107000
exploration/num paths total                1009
exploration/path length this epoch Mean     194.25
exploration/path length this epoch Std       73.2099
exploration/path length this epoch Max      287
exploration/path length this epoch Min      101
exploration/Rewards Mean                      2.79956
exploration/Rewards Std                       1.36514
exploration/Rewards Max                       6.21083
exploration/Rewards Min                      -0.685196
exploration/Returns Mean                    543.815
exploration/Returns Std                     267.274
exploration/Returns Max                     824.921
exploration/Returns Min                     222.348
exploration/Num Paths                         4
exploration/Average Returns                 543.815
evaluation_0/num steps total             807003
evaluation_0/num paths total               5583
evaluation_0/path length Mean               132.683
evaluation_0/path length Std                  3.86217
evaluation_0/path length Max                148
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     3.05222
evaluation_0/Rewards Std                      1.46687
evaluation_0/Rewards Max                      5.97205
evaluation_0/Rewards Min                     -0.587196
evaluation_0/Returns Mean                   404.978
evaluation_0/Returns Std                     12.8076
evaluation_0/Returns Max                    446.08
evaluation_0/Returns Min                    366.714
evaluation_0/Num Paths                       60
evaluation_0/Average Returns                404.978
time/epoch (s)                                0
time/total (s)                             2260.44
Epoch                                       102
---------------------------------------  ---------------
2022-11-16 11:23:44.220104 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 103 finished
---------------------------------------  ---------------
epoch                                       103
total_step                               108000
replay_pool/size                         108000
trainer/alpha                                 0.0368086
trainer/alpha_loss                            0.490678
trainer/entropy                              -6.14861
trainer/qf_loss                               4.22794
trainer/state_noise                           0.005
trainer/policy_loss                         -91.3035
trainer/policy_loss_without_entropy          92.1591
trainer/entropy_penalty                      -0.226322
trainer/entropy_percentage                   -0.00245577
trainer/Q1Pred Mean                          90.9865
trainer/Q1Pred Std                           30.8823
trainer/Q1Pred Max                          137.137
trainer/Q1Pred Min                           -3.74217
trainer/Q2Pred Mean                          90.7982
trainer/Q2Pred Std                           30.8397
trainer/Q2Pred Max                          137.785
trainer/Q2Pred Min                           -0.73376
trainer/QTargetWithReg Mean                  90.9559
trainer/QTargetWithReg Std                   30.9203
trainer/QTargetWithReg Max                  137.458
trainer/QTargetWithReg Min                   -0.840771
trainer/PolicyLossWithoutReg Mean            92.1591
trainer/PolicyLossWithoutReg Std             29.515
trainer/PolicyLossWithoutReg Max            138.177
trainer/PolicyLossWithoutReg Min              3.42356
trainer/gradient_norm                       125.877
trainer/gradient_penalty                     -0.629385
trainer/gradient_percentage                  -0.00682933
exploration/num steps total              108000
exploration/num paths total                1014
exploration/path length this epoch Mean     194.2
exploration/path length this epoch Std       44.8883
exploration/path length this epoch Max      269
exploration/path length this epoch Min      143
exploration/Rewards Mean                      2.87081
exploration/Rewards Std                       1.3961
exploration/Rewards Max                       6.59134
exploration/Rewards Min                      -0.637277
exploration/Returns Mean                    557.512
exploration/Returns Std                     159.869
exploration/Returns Max                     788.662
exploration/Returns Min                     370.844
exploration/Num Paths                         5
exploration/Average Returns                 557.512
evaluation_0/num steps total             814747
evaluation_0/num paths total               5623
evaluation_0/path length Mean               193.6
evaluation_0/path length Std                 71.2523
evaluation_0/path length Max                450
evaluation_0/path length Min                128
evaluation_0/Rewards Mean                     2.2278
evaluation_0/Rewards Std                      1.3384
evaluation_0/Rewards Max                      6.87359
evaluation_0/Rewards Min                     -1.10422
evaluation_0/Returns Mean                   431.303
evaluation_0/Returns Std                    177.027
evaluation_0/Returns Max                   1006.41
evaluation_0/Returns Min                    242.978
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                431.303
time/epoch (s)                                0
time/total (s)                             2278.18
Epoch                                       103
---------------------------------------  ---------------
2022-11-16 11:24:01.718840 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 104 finished
---------------------------------------  ---------------
epoch                                       104
total_step                               109000
replay_pool/size                         109000
trainer/alpha                                 0.037288
trainer/alpha_loss                            1.70304
trainer/entropy                              -6.51778
trainer/qf_loss                               4.43664
trainer/state_noise                           0.005
trainer/policy_loss                         -85.7238
trainer/policy_loss_without_entropy          86.6452
trainer/entropy_penalty                      -0.243035
trainer/entropy_percentage                   -0.00280495
trainer/Q1Pred Mean                          85.4274
trainer/Q1Pred Std                           32.9722
trainer/Q1Pred Max                          138.495
trainer/Q1Pred Min                          -35.565
trainer/Q2Pred Mean                          85.4511
trainer/Q2Pred Std                           33.2599
trainer/Q2Pred Max                          138.837
trainer/Q2Pred Min                          -36.1303
trainer/QTargetWithReg Mean                  85.7429
trainer/QTargetWithReg Std                   33.2502
trainer/QTargetWithReg Max                  139.124
trainer/QTargetWithReg Min                  -36.6304
trainer/PolicyLossWithoutReg Mean            86.6452
trainer/PolicyLossWithoutReg Std             32.3377
trainer/PolicyLossWithoutReg Max            139.152
trainer/PolicyLossWithoutReg Min            -35.1463
trainer/gradient_norm                       135.675
trainer/gradient_penalty                     -0.678373
trainer/gradient_percentage                  -0.00782932
exploration/num steps total              109000
exploration/num paths total                1018
exploration/path length this epoch Mean     184.75
exploration/path length this epoch Std       58.3111
exploration/path length this epoch Max      285
exploration/path length this epoch Min      141
exploration/Rewards Mean                      2.52888
exploration/Rewards Std                       1.42543
exploration/Rewards Max                       6.49725
exploration/Rewards Min                      -0.835935
exploration/Returns Mean                    467.211
exploration/Returns Std                     255.606
exploration/Returns Max                     901.129
exploration/Returns Min                     280.228
exploration/Num Paths                         4
exploration/Average Returns                 467.211
evaluation_0/num steps total             822211
evaluation_0/num paths total               5656
evaluation_0/path length Mean               226.182
evaluation_0/path length Std                 79.8125
evaluation_0/path length Max                456
evaluation_0/path length Min                156
evaluation_0/Rewards Mean                     2.23115
evaluation_0/Rewards Std                      1.38693
evaluation_0/Rewards Max                      6.87899
evaluation_0/Rewards Min                     -2.52702
evaluation_0/Returns Mean                   504.646
evaluation_0/Returns Std                    254.489
evaluation_0/Returns Max                   1243.26
evaluation_0/Returns Min                    208.526
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                504.646
time/epoch (s)                                0
time/total (s)                             2295.67
Epoch                                       104
---------------------------------------  ---------------
2022-11-16 11:24:19.130045 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 105 finished
---------------------------------------  ---------------
epoch                                       105
total_step                               110000
replay_pool/size                         110000
trainer/alpha                                 0.0379179
trainer/alpha_loss                            0.220979
trainer/entropy                              -6.06753
trainer/qf_loss                               3.15618
trainer/state_noise                           0.005
trainer/policy_loss                         -88.516
trainer/policy_loss_without_entropy          89.3964
trainer/entropy_penalty                      -0.230068
trainer/entropy_percentage                   -0.00257357
trainer/Q1Pred Mean                          87.9532
trainer/Q1Pred Std                           35.3376
trainer/Q1Pred Max                          138.948
trainer/Q1Pred Min                           -8.60079
trainer/Q2Pred Mean                          87.9782
trainer/Q2Pred Std                           35.2276
trainer/Q2Pred Max                          137.664
trainer/Q2Pred Min                          -12.949
trainer/QTargetWithReg Mean                  88.2142
trainer/QTargetWithReg Std                   35.1715
trainer/QTargetWithReg Max                  138.33
trainer/QTargetWithReg Min                   -9.98691
trainer/PolicyLossWithoutReg Mean            89.3964
trainer/PolicyLossWithoutReg Std             34.4413
trainer/PolicyLossWithoutReg Max            137.654
trainer/PolicyLossWithoutReg Min             -3.52402
trainer/gradient_norm                       130.071
trainer/gradient_penalty                     -0.650357
trainer/gradient_percentage                  -0.00727498
exploration/num steps total              110000
exploration/num paths total                1022
exploration/path length this epoch Mean     207.5
exploration/path length this epoch Std       42.3173
exploration/path length this epoch Max      257
exploration/path length this epoch Min      145
exploration/Rewards Mean                      2.84743
exploration/Rewards Std                       1.42024
exploration/Rewards Max                       6.70968
exploration/Rewards Min                      -1.00673
exploration/Returns Mean                    590.841
exploration/Returns Std                     158.111
exploration/Returns Max                     729.576
exploration/Returns Min                     324.415
exploration/Num Paths                         4
exploration/Average Returns                 590.841
evaluation_0/num steps total             830102
evaluation_0/num paths total               5705
evaluation_0/path length Mean               161.041
evaluation_0/path length Std                 51.803
evaluation_0/path length Max                337
evaluation_0/path length Min                106
evaluation_0/Rewards Mean                     2.78724
evaluation_0/Rewards Std                      1.42742
evaluation_0/Rewards Max                      6.86865
evaluation_0/Rewards Min                     -1.73611
evaluation_0/Returns Mean                   448.86
evaluation_0/Returns Std                    150.258
evaluation_0/Returns Max                    912.312
evaluation_0/Returns Min                    236.059
evaluation_0/Num Paths                       49
evaluation_0/Average Returns                448.86
time/epoch (s)                                0
time/total (s)                             2313.09
Epoch                                       105
---------------------------------------  ---------------
2022-11-16 11:24:35.824274 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 106 finished
---------------------------------------  ---------------
epoch                                       106
total_step                               111000
replay_pool/size                         111000
trainer/alpha                                 0.0374765
trainer/alpha_loss                            0.770891
trainer/entropy                              -6.23472
trainer/qf_loss                               4.18316
trainer/state_noise                           0.005
trainer/policy_loss                         -91.9859
trainer/policy_loss_without_entropy          92.8643
trainer/entropy_penalty                      -0.233656
trainer/entropy_percentage                   -0.00251609
trainer/Q1Pred Mean                          91.6222
trainer/Q1Pred Std                           33.8986
trainer/Q1Pred Max                          152.448
trainer/Q1Pred Min                           -4.58292
trainer/Q2Pred Mean                          91.488
trainer/Q2Pred Std                           34.0367
trainer/Q2Pred Max                          153.769
trainer/Q2Pred Min                           -3.75807
trainer/QTargetWithReg Mean                  91.6889
trainer/QTargetWithReg Std                   34.0004
trainer/QTargetWithReg Max                  157.027
trainer/QTargetWithReg Min                   -6.165
trainer/PolicyLossWithoutReg Mean            92.8643
trainer/PolicyLossWithoutReg Std             33.4909
trainer/PolicyLossWithoutReg Max            155.302
trainer/PolicyLossWithoutReg Min             -4.38981
trainer/gradient_norm                       128.962
trainer/gradient_penalty                     -0.644811
trainer/gradient_percentage                  -0.00694358
exploration/num steps total              111000
exploration/num paths total                1026
exploration/path length this epoch Mean     214.75
exploration/path length this epoch Std       56.6011
exploration/path length this epoch Max      278
exploration/path length this epoch Min      128
exploration/Rewards Mean                      2.67716
exploration/Rewards Std                       1.60263
exploration/Rewards Max                       7.48744
exploration/Rewards Min                      -1.27209
exploration/Returns Mean                    574.921
exploration/Returns Std                     304.847
exploration/Returns Max                     938.637
exploration/Returns Min                     146.954
exploration/Num Paths                         4
exploration/Average Returns                 574.921
evaluation_0/num steps total             837828
evaluation_0/num paths total               5742
evaluation_0/path length Mean               208.811
evaluation_0/path length Std                 83.6401
evaluation_0/path length Max                380
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     1.87676
evaluation_0/Rewards Std                      1.67584
evaluation_0/Rewards Max                      6.80633
evaluation_0/Rewards Min                     -2.52827
evaluation_0/Returns Mean                   391.888
evaluation_0/Returns Std                    232.747
evaluation_0/Returns Max                   1020.26
evaluation_0/Returns Min                     66.2679
evaluation_0/Num Paths                       37
evaluation_0/Average Returns                391.888
time/epoch (s)                                0
time/total (s)                             2329.78
Epoch                                       106
---------------------------------------  ---------------
2022-11-16 11:24:53.225081 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 107 finished
---------------------------------------  ---------------
epoch                                       107
total_step                               112000
replay_pool/size                         112000
trainer/alpha                                 0.0377031
trainer/alpha_loss                           -0.558187
trainer/entropy                              -5.82971
trainer/qf_loss                               4.9754
trainer/state_noise                           0.005
trainer/policy_loss                         -92.6971
trainer/policy_loss_without_entropy          93.5848
trainer/entropy_penalty                      -0.219798
trainer/entropy_percentage                   -0.00234865
trainer/Q1Pred Mean                          92.6506
trainer/Q1Pred Std                           32.6733
trainer/Q1Pred Max                          142.831
trainer/Q1Pred Min                          -16.3209
trainer/Q2Pred Mean                          92.5474
trainer/Q2Pred Std                           32.5494
trainer/Q2Pred Max                          141.047
trainer/Q2Pred Min                          -17.9651
trainer/QTargetWithReg Mean                  91.8567
trainer/QTargetWithReg Std                   32.8554
trainer/QTargetWithReg Max                  141.715
trainer/QTargetWithReg Min                  -22.828
trainer/PolicyLossWithoutReg Mean            93.5848
trainer/PolicyLossWithoutReg Std             31.882
trainer/PolicyLossWithoutReg Max            140.515
trainer/PolicyLossWithoutReg Min            -10.3588
trainer/gradient_norm                       133.579
trainer/gradient_penalty                     -0.667896
trainer/gradient_percentage                  -0.0071368
exploration/num steps total              112000
exploration/num paths total                1031
exploration/path length this epoch Mean     177.2
exploration/path length this epoch Std       50.1693
exploration/path length this epoch Max      243
exploration/path length this epoch Min      115
exploration/Rewards Mean                      1.88916
exploration/Rewards Std                       1.18064
exploration/Rewards Max                       5.88466
exploration/Rewards Min                      -0.910218
exploration/Returns Mean                    334.76
exploration/Returns Std                      84.5242
exploration/Returns Max                     461.694
exploration/Returns Min                     216.528
exploration/Num Paths                         5
exploration/Average Returns                 334.76
evaluation_0/num steps total             845652
evaluation_0/num paths total               5773
evaluation_0/path length Mean               252.387
evaluation_0/path length Std                 91.8651
evaluation_0/path length Max                483
evaluation_0/path length Min                118
evaluation_0/Rewards Mean                     2.4173
evaluation_0/Rewards Std                      1.41412
evaluation_0/Rewards Max                      7.11367
evaluation_0/Rewards Min                     -1.64471
evaluation_0/Returns Mean                   610.095
evaluation_0/Returns Std                    297.429
evaluation_0/Returns Max                   1254.36
evaluation_0/Returns Min                    207.24
evaluation_0/Num Paths                       31
evaluation_0/Average Returns                610.095
time/epoch (s)                                0
time/total (s)                             2347.18
Epoch                                       107
---------------------------------------  ---------------
2022-11-16 11:25:10.539179 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 108 finished
---------------------------------------  ---------------
epoch                                       108
total_step                               113000
replay_pool/size                         113000
trainer/alpha                                 0.0385919
trainer/alpha_loss                            0.239033
trainer/entropy                              -6.07344
trainer/qf_loss                               5.00018
trainer/state_noise                           0.005
trainer/policy_loss                         -94.375
trainer/policy_loss_without_entropy          95.2704
trainer/entropy_penalty                      -0.234386
trainer/entropy_percentage                   -0.00246022
trainer/Q1Pred Mean                          93.6179
trainer/Q1Pred Std                           33.8986
trainer/Q1Pred Max                          139.797
trainer/Q1Pred Min                          -22.5352
trainer/Q2Pred Mean                          93.7955
trainer/Q2Pred Std                           33.7809
trainer/Q2Pred Max                          139.874
trainer/Q2Pred Min                          -26.6913
trainer/QTargetWithReg Mean                  93.6985
trainer/QTargetWithReg Std                   33.9847
trainer/QTargetWithReg Max                  139.919
trainer/QTargetWithReg Min                  -25.4285
trainer/PolicyLossWithoutReg Mean            95.2704
trainer/PolicyLossWithoutReg Std             32.4616
trainer/PolicyLossWithoutReg Max            139.99
trainer/PolicyLossWithoutReg Min            -22.2911
trainer/gradient_norm                       132.196
trainer/gradient_penalty                     -0.660978
trainer/gradient_percentage                  -0.00693792
exploration/num steps total              113000
exploration/num paths total                1036
exploration/path length this epoch Mean     186.8
exploration/path length this epoch Std       38.4312
exploration/path length this epoch Max      245
exploration/path length this epoch Min      131
exploration/Rewards Mean                      2.54098
exploration/Rewards Std                       1.37522
exploration/Rewards Max                       6.42648
exploration/Rewards Min                      -1.24193
exploration/Returns Mean                    474.654
exploration/Returns Std                     174.342
exploration/Returns Max                     786.372
exploration/Returns Min                     273.817
exploration/Num Paths                         5
exploration/Average Returns                 474.654
evaluation_0/num steps total             853521
evaluation_0/num paths total               5817
evaluation_0/path length Mean               178.841
evaluation_0/path length Std                 75.1659
evaluation_0/path length Max                415
evaluation_0/path length Min                 86
evaluation_0/Rewards Mean                     2.32097
evaluation_0/Rewards Std                      1.4379
evaluation_0/Rewards Max                      7.56198
evaluation_0/Rewards Min                     -0.864284
evaluation_0/Returns Mean                   415.085
evaluation_0/Returns Std                    232.457
evaluation_0/Returns Max                   1169.85
evaluation_0/Returns Min                    175.444
evaluation_0/Num Paths                       44
evaluation_0/Average Returns                415.085
time/epoch (s)                                0
time/total (s)                             2364.49
Epoch                                       108
---------------------------------------  ---------------
2022-11-16 11:25:28.461155 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 109 finished
---------------------------------------  ---------------
epoch                                       109
total_step                               114000
replay_pool/size                         114000
trainer/alpha                                 0.0385902
trainer/alpha_loss                           -1.1727
trainer/entropy                              -5.63969
trainer/qf_loss                               4.79574
trainer/state_noise                           0.005
trainer/policy_loss                         -90.0099
trainer/policy_loss_without_entropy          90.8954
trainer/entropy_penalty                      -0.217637
trainer/entropy_percentage                   -0.00239436
trainer/Q1Pred Mean                          90.3402
trainer/Q1Pred Std                           32.7084
trainer/Q1Pred Max                          144.893
trainer/Q1Pred Min                            2.37199
trainer/Q2Pred Mean                          90.6356
trainer/Q2Pred Std                           32.5787
trainer/Q2Pred Max                          144.028
trainer/Q2Pred Min                            2.1223
trainer/QTargetWithReg Mean                  90.3491
trainer/QTargetWithReg Std                   32.7804
trainer/QTargetWithReg Max                  143.16
trainer/QTargetWithReg Min                    2.53225
trainer/PolicyLossWithoutReg Mean            90.8954
trainer/PolicyLossWithoutReg Std             32.3757
trainer/PolicyLossWithoutReg Max            143.34
trainer/PolicyLossWithoutReg Min              3.40762
trainer/gradient_norm                       133.57
trainer/gradient_penalty                     -0.66785
trainer/gradient_percentage                  -0.00734746
exploration/num steps total              114000
exploration/num paths total                1040
exploration/path length this epoch Mean     229
exploration/path length this epoch Std      174.695
exploration/path length this epoch Max      518
exploration/path length this epoch Min       75
exploration/Rewards Mean                      1.96788
exploration/Rewards Std                       1.4944
exploration/Rewards Max                       5.86299
exploration/Rewards Min                      -1.88349
exploration/Returns Mean                    450.643
exploration/Returns Std                     355.723
exploration/Returns Max                     977.247
exploration/Returns Min                      34.8886
exploration/Num Paths                         4
exploration/Average Returns                 450.643
evaluation_0/num steps total             861288
evaluation_0/num paths total               5853
evaluation_0/path length Mean               215.75
evaluation_0/path length Std                112.407
evaluation_0/path length Max                496
evaluation_0/path length Min                115
evaluation_0/Rewards Mean                     1.625
evaluation_0/Rewards Std                      1.13374
evaluation_0/Rewards Max                      6.66654
evaluation_0/Rewards Min                     -1.13725
evaluation_0/Returns Mean                   350.593
evaluation_0/Returns Std                    177
evaluation_0/Returns Max                    691.012
evaluation_0/Returns Min                    138.984
evaluation_0/Num Paths                       36
evaluation_0/Average Returns                350.593
time/epoch (s)                                0
time/total (s)                             2382.42
Epoch                                       109
---------------------------------------  ---------------
2022-11-16 11:25:45.408551 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 110 finished
---------------------------------------  ---------------
epoch                                       110
total_step                               115000
replay_pool/size                         115000
trainer/alpha                                 0.0387979
trainer/alpha_loss                            1.1686
trainer/entropy                              -6.35961
trainer/qf_loss                               4.9985
trainer/state_noise                           0.005
trainer/policy_loss                         -89.8762
trainer/policy_loss_without_entropy          90.8496
trainer/entropy_penalty                      -0.246739
trainer/entropy_percentage                   -0.00271591
trainer/Q1Pred Mean                          89.8849
trainer/Q1Pred Std                           34.6653
trainer/Q1Pred Max                          146.862
trainer/Q1Pred Min                           -9.72269
trainer/Q2Pred Mean                          89.5488
trainer/Q2Pred Std                           34.4905
trainer/Q2Pred Max                          145.331
trainer/Q2Pred Min                          -16.674
trainer/QTargetWithReg Mean                  89.613
trainer/QTargetWithReg Std                   34.648
trainer/QTargetWithReg Max                  145.123
trainer/QTargetWithReg Min                   -5.61013
trainer/PolicyLossWithoutReg Mean            90.8496
trainer/PolicyLossWithoutReg Std             33.9971
trainer/PolicyLossWithoutReg Max            144.761
trainer/PolicyLossWithoutReg Min            -15.4978
trainer/gradient_norm                       145.326
trainer/gradient_penalty                     -0.726628
trainer/gradient_percentage                  -0.00799814
exploration/num steps total              115000
exploration/num paths total                1045
exploration/path length this epoch Mean     158
exploration/path length this epoch Std       40.1248
exploration/path length this epoch Max      206
exploration/path length this epoch Min      103
exploration/Rewards Mean                      2.68401
exploration/Rewards Std                       1.50374
exploration/Rewards Max                       6.22024
exploration/Rewards Min                      -0.799316
exploration/Returns Mean                    424.074
exploration/Returns Std                     140.751
exploration/Returns Max                     657.714
exploration/Returns Min                     293.873
exploration/Num Paths                         5
exploration/Average Returns                 424.074
evaluation_0/num steps total             869250
evaluation_0/num paths total               5910
evaluation_0/path length Mean               139.684
evaluation_0/path length Std                 44.3535
evaluation_0/path length Max                282
evaluation_0/path length Min                 94
evaluation_0/Rewards Mean                     2.82227
evaluation_0/Rewards Std                      1.47847
evaluation_0/Rewards Max                      7.75062
evaluation_0/Rewards Min                     -0.580598
evaluation_0/Returns Mean                   394.227
evaluation_0/Returns Std                    182.703
evaluation_0/Returns Max                   1020.67
evaluation_0/Returns Min                    230.51
evaluation_0/Num Paths                       57
evaluation_0/Average Returns                394.227
time/epoch (s)                                0
time/total (s)                             2399.36
Epoch                                       110
---------------------------------------  ---------------
2022-11-16 11:26:02.138406 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 111 finished
---------------------------------------  ---------------
epoch                                       111
total_step                               116000
replay_pool/size                         116000
trainer/alpha                                 0.0385099
trainer/alpha_loss                            0.399806
trainer/entropy                              -6.12276
trainer/qf_loss                               4.66569
trainer/state_noise                           0.005
trainer/policy_loss                         -92.3084
trainer/policy_loss_without_entropy          93.2443
trainer/entropy_penalty                      -0.235787
trainer/entropy_percentage                   -0.0025287
trainer/Q1Pred Mean                          92.3308
trainer/Q1Pred Std                           32.8425
trainer/Q1Pred Max                          147.445
trainer/Q1Pred Min                           -2.61899
trainer/Q2Pred Mean                          92.0849
trainer/Q2Pred Std                           32.9701
trainer/Q2Pred Max                          146.051
trainer/Q2Pred Min                           -5.5673
trainer/QTargetWithReg Mean                  92.2169
trainer/QTargetWithReg Std                   32.7996
trainer/QTargetWithReg Max                  146.426
trainer/QTargetWithReg Min                    0.867048
trainer/PolicyLossWithoutReg Mean            93.2443
trainer/PolicyLossWithoutReg Std             32.1182
trainer/PolicyLossWithoutReg Max            146.699
trainer/PolicyLossWithoutReg Min              5.56644
trainer/gradient_norm                       140.021
trainer/gradient_penalty                     -0.700103
trainer/gradient_percentage                  -0.00750827
exploration/num steps total              116000
exploration/num paths total                1050
exploration/path length this epoch Mean     192.2
exploration/path length this epoch Std       85.8217
exploration/path length this epoch Max      355
exploration/path length this epoch Min      112
exploration/Rewards Mean                      2.5999
exploration/Rewards Std                       1.41455
exploration/Rewards Max                       6.52224
exploration/Rewards Min                      -0.822531
exploration/Returns Mean                    499.701
exploration/Returns Std                     214.9
exploration/Returns Max                     916.213
exploration/Returns Min                     317.088
exploration/Num Paths                         5
exploration/Average Returns                 499.701
evaluation_0/num steps total             877111
evaluation_0/num paths total               5950
evaluation_0/path length Mean               196.525
evaluation_0/path length Std                 57.9534
evaluation_0/path length Max                270
evaluation_0/path length Min                119
evaluation_0/Rewards Mean                     2.96429
evaluation_0/Rewards Std                      1.42226
evaluation_0/Rewards Max                      6.60743
evaluation_0/Rewards Min                     -0.605838
evaluation_0/Returns Mean                   582.557
evaluation_0/Returns Std                    201.676
evaluation_0/Returns Max                    938.364
evaluation_0/Returns Min                    340.2
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                582.557
time/epoch (s)                                0
time/total (s)                             2416.09
Epoch                                       111
---------------------------------------  ---------------
2022-11-16 11:26:19.396265 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 112 finished
---------------------------------------  ---------------
epoch                                       112
total_step                               117000
replay_pool/size                         117000
trainer/alpha                                 0.0369948
trainer/alpha_loss                            0.189978
trainer/entropy                              -6.05762
trainer/qf_loss                               6.05197
trainer/state_noise                           0.005
trainer/policy_loss                         -89.3418
trainer/policy_loss_without_entropy          90.3199
trainer/entropy_penalty                      -0.224101
trainer/entropy_percentage                   -0.00248119
trainer/Q1Pred Mean                          89.6606
trainer/Q1Pred Std                           34.8914
trainer/Q1Pred Max                          146.297
trainer/Q1Pred Min                          -25.4474
trainer/Q2Pred Mean                          89.8401
trainer/Q2Pred Std                           34.8694
trainer/Q2Pred Max                          146.074
trainer/Q2Pred Min                          -19.9167
trainer/QTargetWithReg Mean                  89.1338
trainer/QTargetWithReg Std                   35.1133
trainer/QTargetWithReg Max                  145.598
trainer/QTargetWithReg Min                  -23.7404
trainer/PolicyLossWithoutReg Mean            90.3199
trainer/PolicyLossWithoutReg Std             34.3893
trainer/PolicyLossWithoutReg Max            146.587
trainer/PolicyLossWithoutReg Min            -25.224
trainer/gradient_norm                       150.791
trainer/gradient_penalty                     -0.753954
trainer/gradient_percentage                  -0.00834759
exploration/num steps total              117000
exploration/num paths total                1055
exploration/path length this epoch Mean     194.2
exploration/path length this epoch Std       71.0532
exploration/path length this epoch Max      311
exploration/path length this epoch Min      117
exploration/Rewards Mean                      2.39907
exploration/Rewards Std                       1.46797
exploration/Rewards Max                       6.17081
exploration/Rewards Min                      -0.796303
exploration/Returns Mean                    465.9
exploration/Returns Std                     132.671
exploration/Returns Max                     629.606
exploration/Returns Min                     277.937
exploration/Num Paths                         5
exploration/Average Returns                 465.9
evaluation_0/num steps total             885043
evaluation_0/num paths total               5983
evaluation_0/path length Mean               240.364
evaluation_0/path length Std                 64.1739
evaluation_0/path length Max                395
evaluation_0/path length Min                142
evaluation_0/Rewards Mean                     2.36778
evaluation_0/Rewards Std                      1.42016
evaluation_0/Rewards Max                      6.28526
evaluation_0/Rewards Min                     -1.49885
evaluation_0/Returns Mean                   569.129
evaluation_0/Returns Std                    166.49
evaluation_0/Returns Max                   1061.12
evaluation_0/Returns Min                    326.744
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                569.129
time/epoch (s)                                0
time/total (s)                             2433.35
Epoch                                       112
---------------------------------------  ---------------
2022-11-16 11:26:36.479131 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 113 finished
---------------------------------------  ---------------
epoch                                       113
total_step                               118000
replay_pool/size                         118000
trainer/alpha                                 0.0371672
trainer/alpha_loss                            0.851118
trainer/entropy                              -6.25851
trainer/qf_loss                               4.54014
trainer/state_noise                           0.005
trainer/policy_loss                         -90.2338
trainer/policy_loss_without_entropy          91.2144
trainer/entropy_penalty                      -0.232611
trainer/entropy_percentage                   -0.00255016
trainer/Q1Pred Mean                          89.8355
trainer/Q1Pred Std                           33.3509
trainer/Q1Pred Max                          147.428
trainer/Q1Pred Min                          -10.1668
trainer/Q2Pred Mean                          89.6513
trainer/Q2Pred Std                           33.1702
trainer/Q2Pred Max                          146.955
trainer/Q2Pred Min                           -6.44928
trainer/QTargetWithReg Mean                  89.9763
trainer/QTargetWithReg Std                   33.1154
trainer/QTargetWithReg Max                  145.839
trainer/QTargetWithReg Min                   -9.18679
trainer/PolicyLossWithoutReg Mean            91.2144
trainer/PolicyLossWithoutReg Std             31.6633
trainer/PolicyLossWithoutReg Max            147.637
trainer/PolicyLossWithoutReg Min              0.203349
trainer/gradient_norm                       149.604
trainer/gradient_penalty                     -0.748018
trainer/gradient_percentage                  -0.00820065
exploration/num steps total              118000
exploration/num paths total                1061
exploration/path length this epoch Mean     166.667
exploration/path length this epoch Std       26.3165
exploration/path length this epoch Max      200
exploration/path length this epoch Min      128
exploration/Rewards Mean                      2.60405
exploration/Rewards Std                       1.32833
exploration/Rewards Max                       5.74487
exploration/Rewards Min                      -0.611121
exploration/Returns Mean                    434.009
exploration/Returns Std                      50.5414
exploration/Returns Max                     496.743
exploration/Returns Min                     345.542
exploration/Num Paths                         6
exploration/Average Returns                 434.009
evaluation_0/num steps total             892915
evaluation_0/num paths total               6034
evaluation_0/path length Mean               154.353
evaluation_0/path length Std                 43.5196
evaluation_0/path length Max                301
evaluation_0/path length Min                116
evaluation_0/Rewards Mean                     3.04229
evaluation_0/Rewards Std                      1.43708
evaluation_0/Rewards Max                      6.61236
evaluation_0/Rewards Min                     -0.540094
evaluation_0/Returns Mean                   469.587
evaluation_0/Returns Std                    177.98
evaluation_0/Returns Max                   1084.64
evaluation_0/Returns Min                    324.255
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                469.587
time/epoch (s)                                0
time/total (s)                             2450.43
Epoch                                       113
---------------------------------------  ---------------
2022-11-16 11:26:53.889955 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 114 finished
---------------------------------------  ---------------
epoch                                       114
total_step                               119000
replay_pool/size                         119000
trainer/alpha                                 0.0369589
trainer/alpha_loss                            0.362407
trainer/entropy                              -6.10989
trainer/qf_loss                               4.84249
trainer/state_noise                           0.005
trainer/policy_loss                         -90.3517
trainer/policy_loss_without_entropy          91.3265
trainer/entropy_penalty                      -0.225814
trainer/entropy_percentage                   -0.00247261
trainer/Q1Pred Mean                          90.5866
trainer/Q1Pred Std                           36.7242
trainer/Q1Pred Max                          146.746
trainer/Q1Pred Min                          -13.1217
trainer/Q2Pred Mean                          90.5499
trainer/Q2Pred Std                           36.687
trainer/Q2Pred Max                          146.414
trainer/Q2Pred Min                          -12.6393
trainer/QTargetWithReg Mean                  90.8397
trainer/QTargetWithReg Std                   36.7783
trainer/QTargetWithReg Max                  147.466
trainer/QTargetWithReg Min                   -9.6245
trainer/PolicyLossWithoutReg Mean            91.3265
trainer/PolicyLossWithoutReg Std             36.3128
trainer/PolicyLossWithoutReg Max            146.982
trainer/PolicyLossWithoutReg Min             -6.87448
trainer/gradient_norm                       149.785
trainer/gradient_penalty                     -0.748923
trainer/gradient_percentage                  -0.00820051
exploration/num steps total              119000
exploration/num paths total                1067
exploration/path length this epoch Mean     166.667
exploration/path length this epoch Std       48.9274
exploration/path length this epoch Max      233
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.61732
exploration/Rewards Std                       1.44234
exploration/Rewards Max                       6.41115
exploration/Rewards Min                      -0.729435
exploration/Returns Mean                    436.22
exploration/Returns Std                     157.633
exploration/Returns Max                     702.057
exploration/Returns Min                     287.935
exploration/Num Paths                         6
exploration/Average Returns                 436.22
evaluation_0/num steps total             900832
evaluation_0/num paths total               6087
evaluation_0/path length Mean               149.377
evaluation_0/path length Std                 60.1486
evaluation_0/path length Max                384
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.88091
evaluation_0/Rewards Std                      1.33305
evaluation_0/Rewards Max                      6.86076
evaluation_0/Rewards Min                     -0.596663
evaluation_0/Returns Mean                   430.343
evaluation_0/Returns Std                    222.718
evaluation_0/Returns Max                   1307.84
evaluation_0/Returns Min                    285.871
evaluation_0/Num Paths                       53
evaluation_0/Average Returns                430.343
time/epoch (s)                                0
time/total (s)                             2467.84
Epoch                                       114
---------------------------------------  ---------------
2022-11-16 11:27:10.343714 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 115 finished
---------------------------------------  ---------------
epoch                                       115
total_step                               120000
replay_pool/size                         120000
trainer/alpha                                 0.037582
trainer/alpha_loss                            1.35709
trainer/entropy                              -6.41358
trainer/qf_loss                               5.22335
trainer/state_noise                           0.005
trainer/policy_loss                         -89.1391
trainer/policy_loss_without_entropy          90.1754
trainer/entropy_penalty                      -0.241035
trainer/entropy_percentage                   -0.00267296
trainer/Q1Pred Mean                          89.2703
trainer/Q1Pred Std                           34.577
trainer/Q1Pred Max                          154.542
trainer/Q1Pred Min                          -16.1262
trainer/Q2Pred Mean                          89.13
trainer/Q2Pred Std                           34.7936
trainer/Q2Pred Max                          151.705
trainer/Q2Pred Min                          -21.6416
trainer/QTargetWithReg Mean                  89.7153
trainer/QTargetWithReg Std                   35.1013
trainer/QTargetWithReg Max                  153.18
trainer/QTargetWithReg Min                  -20.2852
trainer/PolicyLossWithoutReg Mean            90.1754
trainer/PolicyLossWithoutReg Std             34.0271
trainer/PolicyLossWithoutReg Max            151.482
trainer/PolicyLossWithoutReg Min            -16.6145
trainer/gradient_norm                       159.048
trainer/gradient_penalty                     -0.795239
trainer/gradient_percentage                  -0.0088188
exploration/num steps total              120000
exploration/num paths total                1072
exploration/path length this epoch Mean     193.8
exploration/path length this epoch Std       70.0069
exploration/path length this epoch Max      278
exploration/path length this epoch Min       90
exploration/Rewards Mean                      3.0911
exploration/Rewards Std                       1.39724
exploration/Rewards Max                       6.33527
exploration/Rewards Min                      -0.828334
exploration/Returns Mean                    599.055
exploration/Returns Std                     267.671
exploration/Returns Max                     986.761
exploration/Returns Min                     218.896
exploration/Num Paths                         5
exploration/Average Returns                 599.055
evaluation_0/num steps total             908826
evaluation_0/num paths total               6120
evaluation_0/path length Mean               242.242
evaluation_0/path length Std                 40.0227
evaluation_0/path length Max                300
evaluation_0/path length Min                134
evaluation_0/Rewards Mean                     3.41079
evaluation_0/Rewards Std                      1.43744
evaluation_0/Rewards Max                      7.60663
evaluation_0/Rewards Min                     -0.420349
evaluation_0/Returns Mean                   826.238
evaluation_0/Returns Std                    161.957
evaluation_0/Returns Max                   1109.59
evaluation_0/Returns Min                    406.467
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                826.238
time/epoch (s)                                0
time/total (s)                             2484.3
Epoch                                       115
---------------------------------------  ---------------
2022-11-16 11:27:27.915717 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 116 finished
---------------------------------------  ---------------
epoch                                       116
total_step                               121000
replay_pool/size                         121000
trainer/alpha                                 0.0387674
trainer/alpha_loss                           -0.0772958
trainer/entropy                              -5.97622
trainer/qf_loss                               6.55799
trainer/state_noise                           0.005
trainer/policy_loss                         -92.1222
trainer/policy_loss_without_entropy          93.1275
trainer/entropy_penalty                      -0.231682
trainer/entropy_percentage                   -0.0024878
trainer/Q1Pred Mean                          91.6471
trainer/Q1Pred Std                           33.2885
trainer/Q1Pred Max                          144.007
trainer/Q1Pred Min                          -20.9661
trainer/Q2Pred Mean                          92.0327
trainer/Q2Pred Std                           33.2445
trainer/Q2Pred Max                          145.564
trainer/Q2Pred Min                          -22.4987
trainer/QTargetWithReg Mean                  91.9617
trainer/QTargetWithReg Std                   33.3941
trainer/QTargetWithReg Max                  146.055
trainer/QTargetWithReg Min                  -16.2375
trainer/PolicyLossWithoutReg Mean            93.1275
trainer/PolicyLossWithoutReg Std             32.0633
trainer/PolicyLossWithoutReg Max            145.023
trainer/PolicyLossWithoutReg Min            -24.1234
trainer/gradient_norm                       154.723
trainer/gradient_penalty                     -0.773614
trainer/gradient_percentage                  -0.00830704
exploration/num steps total              121000
exploration/num paths total                1079
exploration/path length this epoch Mean     125
exploration/path length this epoch Std       30.2135
exploration/path length this epoch Max      175
exploration/path length this epoch Min       91
exploration/Rewards Mean                      2.90105
exploration/Rewards Std                       1.41838
exploration/Rewards Max                       6.14987
exploration/Rewards Min                      -0.539656
exploration/Returns Mean                    362.631
exploration/Returns Std                     106.447
exploration/Returns Max                     539.045
exploration/Returns Min                     237.753
exploration/Num Paths                         7
exploration/Average Returns                 362.631
evaluation_0/num steps total             916740
evaluation_0/num paths total               6181
evaluation_0/path length Mean               129.738
evaluation_0/path length Std                 45.4554
evaluation_0/path length Max                305
evaluation_0/path length Min                 96
evaluation_0/Rewards Mean                     3.04581
evaluation_0/Rewards Std                      1.48696
evaluation_0/Rewards Max                      7.21557
evaluation_0/Rewards Min                     -0.509224
evaluation_0/Returns Mean                   395.156
evaluation_0/Returns Std                    174.409
evaluation_0/Returns Max                   1079.39
evaluation_0/Returns Min                    266.866
evaluation_0/Num Paths                       61
evaluation_0/Average Returns                395.156
time/epoch (s)                                0
time/total (s)                             2501.87
Epoch                                       116
---------------------------------------  ---------------
2022-11-16 11:27:43.956335 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 117 finished
---------------------------------------  ---------------
epoch                                       117
total_step                               122000
replay_pool/size                         122000
trainer/alpha                                 0.0391518
trainer/alpha_loss                            0.769395
trainer/entropy                              -6.23745
trainer/qf_loss                               4.82593
trainer/state_noise                           0.005
trainer/policy_loss                         -90.2452
trainer/policy_loss_without_entropy          91.2637
trainer/entropy_penalty                      -0.244207
trainer/entropy_percentage                   -0.00267584
trainer/Q1Pred Mean                          90.3293
trainer/Q1Pred Std                           35.4799
trainer/Q1Pred Max                          181.055
trainer/Q1Pred Min                          -11.6722
trainer/Q2Pred Mean                          90.341
trainer/Q2Pred Std                           35.5545
trainer/Q2Pred Max                          183.15
trainer/Q2Pred Min                          -17.5623
trainer/QTargetWithReg Mean                  90.1961
trainer/QTargetWithReg Std                   35.3711
trainer/QTargetWithReg Max                  183.231
trainer/QTargetWithReg Min                  -18.2407
trainer/PolicyLossWithoutReg Mean            91.2637
trainer/PolicyLossWithoutReg Std             34.95
trainer/PolicyLossWithoutReg Max            183.112
trainer/PolicyLossWithoutReg Min            -13.0804
trainer/gradient_norm                       154.865
trainer/gradient_penalty                     -0.774326
trainer/gradient_percentage                  -0.00848449
exploration/num steps total              122000
exploration/num paths total                1085
exploration/path length this epoch Mean     146.833
exploration/path length this epoch Std       65.0575
exploration/path length this epoch Max      240
exploration/path length this epoch Min       87
exploration/Rewards Mean                      3.07145
exploration/Rewards Std                       1.4822
exploration/Rewards Max                       7.48758
exploration/Rewards Min                      -0.479125
exploration/Returns Mean                    450.991
exploration/Returns Std                     243.6
exploration/Returns Max                     802.544
exploration/Returns Min                     226.303
exploration/Num Paths                         6
exploration/Average Returns                 450.991
evaluation_0/num steps total             924740
evaluation_0/num paths total               6267
evaluation_0/path length Mean                93.0233
evaluation_0/path length Std                 10.3418
evaluation_0/path length Max                145
evaluation_0/path length Min                 80
evaluation_0/Rewards Mean                     2.64456
evaluation_0/Rewards Std                      1.41574
evaluation_0/Rewards Max                      6.14692
evaluation_0/Rewards Min                     -0.446689
evaluation_0/Returns Mean                   246.006
evaluation_0/Returns Std                     35.1465
evaluation_0/Returns Max                    420.739
evaluation_0/Returns Min                    197.055
evaluation_0/Num Paths                       86
evaluation_0/Average Returns                246.006
time/epoch (s)                                0
time/total (s)                             2517.91
Epoch                                       117
---------------------------------------  ---------------
2022-11-16 11:28:01.105389 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 118 finished
---------------------------------------  ---------------
epoch                                       118
total_step                               123000
replay_pool/size                         123000
trainer/alpha                                 0.0394306
trainer/alpha_loss                           -0.0276351
trainer/entropy                              -5.99145
trainer/qf_loss                               4.95127
trainer/state_noise                           0.005
trainer/policy_loss                         -91.6512
trainer/policy_loss_without_entropy          92.6824
trainer/entropy_penalty                      -0.236247
trainer/entropy_percentage                   -0.00254899
trainer/Q1Pred Mean                          92.1919
trainer/Q1Pred Std                           33.0529
trainer/Q1Pred Max                          149.228
trainer/Q1Pred Min                          -21.3954
trainer/Q2Pred Mean                          92.0255
trainer/Q2Pred Std                           33.1053
trainer/Q2Pred Max                          148.701
trainer/Q2Pred Min                          -19.7256
trainer/QTargetWithReg Mean                  91.7434
trainer/QTargetWithReg Std                   32.907
trainer/QTargetWithReg Max                  148.364
trainer/QTargetWithReg Min                  -27.3211
trainer/PolicyLossWithoutReg Mean            92.6824
trainer/PolicyLossWithoutReg Std             32.406
trainer/PolicyLossWithoutReg Max            148.1
trainer/PolicyLossWithoutReg Min            -18.9746
trainer/gradient_norm                       158.992
trainer/gradient_penalty                     -0.79496
trainer/gradient_percentage                  -0.00857725
exploration/num steps total              123000
exploration/num paths total                1090
exploration/path length this epoch Mean     168.2
exploration/path length this epoch Std       45.0529
exploration/path length this epoch Max      240
exploration/path length this epoch Min      118
exploration/Rewards Mean                      3.00592
exploration/Rewards Std                       1.37554
exploration/Rewards Max                       7.35824
exploration/Rewards Min                      -0.731949
exploration/Returns Mean                    505.596
exploration/Returns Std                     170.776
exploration/Returns Max                     825.845
exploration/Returns Min                     354.623
exploration/Num Paths                         5
exploration/Average Returns                 505.596
evaluation_0/num steps total             932622
evaluation_0/num paths total               6304
evaluation_0/path length Mean               213.027
evaluation_0/path length Std                 61.4533
evaluation_0/path length Max                320
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     3.21002
evaluation_0/Rewards Std                      1.45196
evaluation_0/Rewards Max                      7.41401
evaluation_0/Rewards Min                     -0.537586
evaluation_0/Returns Mean                   683.821
evaluation_0/Returns Std                    243.51
evaluation_0/Returns Max                   1154.87
evaluation_0/Returns Min                    339.306
evaluation_0/Num Paths                       37
evaluation_0/Average Returns                683.821
time/epoch (s)                                0
time/total (s)                             2535.06
Epoch                                       118
---------------------------------------  ---------------
2022-11-16 11:28:18.013147 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 119 finished
---------------------------------------  ---------------
epoch                                       119
total_step                               124000
replay_pool/size                         124000
trainer/alpha                                 0.0391906
trainer/alpha_loss                           -0.889371
trainer/entropy                              -5.72543
trainer/qf_loss                               5.91317
trainer/state_noise                           0.005
trainer/policy_loss                         -93.3925
trainer/policy_loss_without_entropy          94.436
trainer/entropy_penalty                      -0.224383
trainer/entropy_percentage                   -0.00237603
trainer/Q1Pred Mean                          93.5598
trainer/Q1Pred Std                           31.7708
trainer/Q1Pred Max                          145.681
trainer/Q1Pred Min                            3.12949
trainer/Q2Pred Mean                          93.8132
trainer/Q2Pred Std                           31.5984
trainer/Q2Pred Max                          147.239
trainer/Q2Pred Min                            4.18039
trainer/QTargetWithReg Mean                  93.6601
trainer/QTargetWithReg Std                   32.293
trainer/QTargetWithReg Max                  145.911
trainer/QTargetWithReg Min                   -1.14008
trainer/PolicyLossWithoutReg Mean            94.436
trainer/PolicyLossWithoutReg Std             30.9197
trainer/PolicyLossWithoutReg Max            145.695
trainer/PolicyLossWithoutReg Min              4.73941
trainer/gradient_norm                       163.824
trainer/gradient_penalty                     -0.819118
trainer/gradient_percentage                  -0.00867379
exploration/num steps total              124000
exploration/num paths total                1096
exploration/path length this epoch Mean     158.667
exploration/path length this epoch Std       70.5612
exploration/path length this epoch Max      283
exploration/path length this epoch Min       84
exploration/Rewards Mean                      3.04506
exploration/Rewards Std                       1.40866
exploration/Rewards Max                       7.43596
exploration/Rewards Min                      -0.53637
exploration/Returns Mean                    483.15
exploration/Returns Std                     257.222
exploration/Returns Max                     956.866
exploration/Returns Min                     215.223
exploration/Num Paths                         6
exploration/Average Returns                 483.15
evaluation_0/num steps total             940608
evaluation_0/num paths total               6359
evaluation_0/path length Mean               145.2
evaluation_0/path length Std                 50.1497
evaluation_0/path length Max                317
evaluation_0/path length Min                 86
evaluation_0/Rewards Mean                     2.81857
evaluation_0/Rewards Std                      1.33351
evaluation_0/Rewards Max                      8.27154
evaluation_0/Rewards Min                     -0.334943
evaluation_0/Returns Mean                   409.256
evaluation_0/Returns Std                    182.203
evaluation_0/Returns Max                   1004.6
evaluation_0/Returns Min                    211.246
evaluation_0/Num Paths                       55
evaluation_0/Average Returns                409.256
time/epoch (s)                                0
time/total (s)                             2551.96
Epoch                                       119
---------------------------------------  ---------------
2022-11-16 11:28:35.810129 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 120 finished
---------------------------------------  ---------------
epoch                                       120
total_step                               125000
replay_pool/size                         125000
trainer/alpha                                 0.0393941
trainer/alpha_loss                            0.635439
trainer/entropy                              -6.19648
trainer/qf_loss                               4.15854
trainer/state_noise                           0.005
trainer/policy_loss                         -91.0241
trainer/policy_loss_without_entropy          92.049
trainer/entropy_penalty                      -0.244104
trainer/entropy_percentage                   -0.0026519
trainer/Q1Pred Mean                          91.5426
trainer/Q1Pred Std                           34.5358
trainer/Q1Pred Max                          145.738
trainer/Q1Pred Min                          -10.442
trainer/Q2Pred Mean                          91.3912
trainer/Q2Pred Std                           34.0615
trainer/Q2Pred Max                          145.719
trainer/Q2Pred Min                           -8.83417
trainer/QTargetWithReg Mean                  91.8281
trainer/QTargetWithReg Std                   34.2748
trainer/QTargetWithReg Max                  145.405
trainer/QTargetWithReg Min                   -9.88893
trainer/PolicyLossWithoutReg Mean            92.049
trainer/PolicyLossWithoutReg Std             33.9029
trainer/PolicyLossWithoutReg Max            145.073
trainer/PolicyLossWithoutReg Min             -4.65853
trainer/gradient_norm                       156.156
trainer/gradient_penalty                     -0.780782
trainer/gradient_percentage                  -0.00848224
exploration/num steps total              125000
exploration/num paths total                1103
exploration/path length this epoch Mean     132.714
exploration/path length this epoch Std       29.8985
exploration/path length this epoch Max      198
exploration/path length this epoch Min       96
exploration/Rewards Mean                      2.67516
exploration/Rewards Std                       1.27284
exploration/Rewards Max                       5.68928
exploration/Rewards Min                      -0.592236
exploration/Returns Mean                    355.032
exploration/Returns Std                      72.9465
exploration/Returns Max                     507.355
exploration/Returns Min                     248.542
exploration/Num Paths                         7
exploration/Average Returns                 355.032
evaluation_0/num steps total             948578
evaluation_0/num paths total               6411
evaluation_0/path length Mean               153.269
evaluation_0/path length Std                123.277
evaluation_0/path length Max               1000
evaluation_0/path length Min                113
evaluation_0/Rewards Mean                     2.67623
evaluation_0/Rewards Std                      1.42358
evaluation_0/Rewards Max                      7.01414
evaluation_0/Rewards Min                     -0.511878
evaluation_0/Returns Mean                   410.184
evaluation_0/Returns Std                    134.264
evaluation_0/Returns Max                   1063.25
evaluation_0/Returns Min                    316.335
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                410.184
time/epoch (s)                                0
time/total (s)                             2569.76
Epoch                                       120
---------------------------------------  ---------------
2022-11-16 11:28:54.330113 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 121 finished
---------------------------------------  ---------------
epoch                                       121
total_step                               126000
replay_pool/size                         126000
trainer/alpha                                 0.0401871
trainer/alpha_loss                            0.0705401
trainer/entropy                              -6.02195
trainer/qf_loss                               5.7713
trainer/state_noise                           0.005
trainer/policy_loss                         -90.5194
trainer/policy_loss_without_entropy          91.5728
trainer/entropy_penalty                      -0.242004
trainer/entropy_percentage                   -0.00264275
trainer/Q1Pred Mean                          90.3454
trainer/Q1Pred Std                           34.0706
trainer/Q1Pred Max                          145.816
trainer/Q1Pred Min                          -16.0169
trainer/Q2Pred Mean                          90.5146
trainer/Q2Pred Std                           34.1516
trainer/Q2Pred Max                          145.663
trainer/Q2Pred Min                          -11.9618
trainer/QTargetWithReg Mean                  90.6877
trainer/QTargetWithReg Std                   34.0725
trainer/QTargetWithReg Max                  146.812
trainer/QTargetWithReg Min                  -25.4421
trainer/PolicyLossWithoutReg Mean            91.5728
trainer/PolicyLossWithoutReg Std             33.5762
trainer/PolicyLossWithoutReg Max            145.919
trainer/PolicyLossWithoutReg Min             -7.28
trainer/gradient_norm                       162.278
trainer/gradient_penalty                     -0.81139
trainer/gradient_percentage                  -0.0088606
exploration/num steps total              126000
exploration/num paths total                1107
exploration/path length this epoch Mean     184.75
exploration/path length this epoch Std       85.5084
exploration/path length this epoch Max      271
exploration/path length this epoch Min       84
exploration/Rewards Mean                      3.25951
exploration/Rewards Std                       1.58834
exploration/Rewards Max                       7.49183
exploration/Rewards Min                      -0.577101
exploration/Returns Mean                    602.194
exploration/Returns Std                     337.578
exploration/Returns Max                     965.709
exploration/Returns Min                     193.45
exploration/Num Paths                         4
exploration/Average Returns                 602.194
evaluation_0/num steps total             956434
evaluation_0/num paths total               6444
evaluation_0/path length Mean               238.061
evaluation_0/path length Std                178.441
evaluation_0/path length Max               1000
evaluation_0/path length Min                 63
evaluation_0/Rewards Mean                     1.90835
evaluation_0/Rewards Std                      1.51163
evaluation_0/Rewards Max                      7.13701
evaluation_0/Rewards Min                     -2.1064
evaluation_0/Returns Mean                   454.302
evaluation_0/Returns Std                    391.655
evaluation_0/Returns Max                   1415.77
evaluation_0/Returns Min                     19.7738
evaluation_0/Num Paths                       33
evaluation_0/Average Returns                454.302
time/epoch (s)                                0
time/total (s)                             2588.28
Epoch                                       121
---------------------------------------  ---------------
2022-11-16 11:29:11.564371 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 122 finished
---------------------------------------  ---------------
epoch                                       122
total_step                               127000
replay_pool/size                         127000
trainer/alpha                                 0.0404084
trainer/alpha_loss                            0.0116803
trainer/entropy                              -6.00364
trainer/qf_loss                               6.96618
trainer/state_noise                           0.005
trainer/policy_loss                         -91.9589
trainer/policy_loss_without_entropy          92.9976
trainer/entropy_penalty                      -0.242597
trainer/entropy_percentage                   -0.00260864
trainer/Q1Pred Mean                          92.4502
trainer/Q1Pred Std                           33.7622
trainer/Q1Pred Max                          148.367
trainer/Q1Pred Min                          -19.4205
trainer/Q2Pred Mean                          92.1271
trainer/Q2Pred Std                           33.5779
trainer/Q2Pred Max                          147.816
trainer/Q2Pred Min                          -12.5102
trainer/QTargetWithReg Mean                  92.5042
trainer/QTargetWithReg Std                   33.781
trainer/QTargetWithReg Max                  148.015
trainer/QTargetWithReg Min                  -13.5369
trainer/PolicyLossWithoutReg Mean            92.9976
trainer/PolicyLossWithoutReg Std             33.5362
trainer/PolicyLossWithoutReg Max            147.928
trainer/PolicyLossWithoutReg Min            -13.8252
trainer/gradient_norm                       159.222
trainer/gradient_penalty                     -0.796111
trainer/gradient_percentage                  -0.00856056
exploration/num steps total              127000
exploration/num paths total                1111
exploration/path length this epoch Mean     236
exploration/path length this epoch Std       69.1195
exploration/path length this epoch Max      297
exploration/path length this epoch Min      120
exploration/Rewards Mean                      2.73341
exploration/Rewards Std                       1.44466
exploration/Rewards Max                       7.63419
exploration/Rewards Min                      -0.560646
exploration/Returns Mean                    645.085
exploration/Returns Std                     193.167
exploration/Returns Max                     840.565
exploration/Returns Min                     380.864
exploration/Num Paths                         4
exploration/Average Returns                 645.085
evaluation_0/num steps total             964328
evaluation_0/num paths total               6501
evaluation_0/path length Mean               138.491
evaluation_0/path length Std                 42.8859
evaluation_0/path length Max                309
evaluation_0/path length Min                105
evaluation_0/Rewards Mean                     2.98927
evaluation_0/Rewards Std                      1.35837
evaluation_0/Rewards Max                      7.74723
evaluation_0/Rewards Min                     -0.58864
evaluation_0/Returns Mean                   413.988
evaluation_0/Returns Std                    166.623
evaluation_0/Returns Max                    995.571
evaluation_0/Returns Min                    298.542
evaluation_0/Num Paths                       57
evaluation_0/Average Returns                413.988
time/epoch (s)                                0
time/total (s)                             2605.51
Epoch                                       122
---------------------------------------  ---------------
2022-11-16 11:29:28.436329 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 123 finished
---------------------------------------  ---------------
epoch                                       123
total_step                               128000
replay_pool/size                         128000
trainer/alpha                                 0.0410813
trainer/alpha_loss                            0.928979
trainer/entropy                              -6.29099
trainer/qf_loss                               5.13403
trainer/state_noise                           0.005
trainer/policy_loss                         -90.4319
trainer/policy_loss_without_entropy          91.5204
trainer/entropy_penalty                      -0.258442
trainer/entropy_percentage                   -0.00282388
trainer/Q1Pred Mean                          91.1772
trainer/Q1Pred Std                           35.5485
trainer/Q1Pred Max                          147.42
trainer/Q1Pred Min                          -24.3448
trainer/Q2Pred Mean                          91.0219
trainer/Q2Pred Std                           35.4883
trainer/Q2Pred Max                          148.115
trainer/Q2Pred Min                          -24.2342
trainer/QTargetWithReg Mean                  90.6154
trainer/QTargetWithReg Std                   35.4699
trainer/QTargetWithReg Max                  146.72
trainer/QTargetWithReg Min                  -24.2983
trainer/PolicyLossWithoutReg Mean            91.5204
trainer/PolicyLossWithoutReg Std             35.4466
trainer/PolicyLossWithoutReg Max            147.215
trainer/PolicyLossWithoutReg Min            -24.3017
trainer/gradient_norm                       166.014
trainer/gradient_penalty                     -0.830071
trainer/gradient_percentage                  -0.0090698
exploration/num steps total              128000
exploration/num paths total                1116
exploration/path length this epoch Mean     160.6
exploration/path length this epoch Std       81.1507
exploration/path length this epoch Max      312
exploration/path length this epoch Min       98
exploration/Rewards Mean                      2.88651
exploration/Rewards Std                       1.34341
exploration/Rewards Max                       6.34789
exploration/Rewards Min                      -0.613299
exploration/Returns Mean                    463.574
exploration/Returns Std                     247.331
exploration/Returns Max                     920.321
exploration/Returns Min                     259.511
exploration/Num Paths                         5
exploration/Average Returns                 463.574
evaluation_0/num steps total             972198
evaluation_0/num paths total               6547
evaluation_0/path length Mean               171.087
evaluation_0/path length Std                 47.7515
evaluation_0/path length Max                331
evaluation_0/path length Min                124
evaluation_0/Rewards Mean                     3.33392
evaluation_0/Rewards Std                      1.48207
evaluation_0/Rewards Max                      8.2202
evaluation_0/Rewards Min                     -0.643439
evaluation_0/Returns Mean                   570.39
evaluation_0/Returns Std                    193.832
evaluation_0/Returns Max                   1233.41
evaluation_0/Returns Min                    391.243
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                570.39
time/epoch (s)                                0
time/total (s)                             2622.39
Epoch                                       123
---------------------------------------  ---------------
2022-11-16 11:29:44.665773 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 124 finished
---------------------------------------  ---------------
epoch                                       124
total_step                               129000
replay_pool/size                         129000
trainer/alpha                                 0.0403729
trainer/alpha_loss                            0.636854
trainer/entropy                              -6.19841
trainer/qf_loss                               6.1322
trainer/state_noise                           0.005
trainer/policy_loss                         -91.0234
trainer/policy_loss_without_entropy          92.0813
trainer/entropy_penalty                      -0.250248
trainer/entropy_percentage                   -0.00271769
trainer/Q1Pred Mean                          91.211
trainer/Q1Pred Std                           34.3587
trainer/Q1Pred Max                          146.253
trainer/Q1Pred Min                           -7.9704
trainer/Q2Pred Mean                          90.965
trainer/Q2Pred Std                           34.3295
trainer/Q2Pred Max                          145.582
trainer/Q2Pred Min                          -14.5013
trainer/QTargetWithReg Mean                  91.2444
trainer/QTargetWithReg Std                   34.4535
trainer/QTargetWithReg Max                  145.343
trainer/QTargetWithReg Min                  -12.9219
trainer/PolicyLossWithoutReg Mean            92.0812
trainer/PolicyLossWithoutReg Std             33.7509
trainer/PolicyLossWithoutReg Max            145.121
trainer/PolicyLossWithoutReg Min            -13.5325
trainer/gradient_norm                       161.526
trainer/gradient_penalty                     -0.807632
trainer/gradient_percentage                  -0.00877086
exploration/num steps total              129000
exploration/num paths total                1122
exploration/path length this epoch Mean     121.333
exploration/path length this epoch Std       13.8764
exploration/path length this epoch Max      137
exploration/path length this epoch Min       96
exploration/Rewards Mean                      2.85008
exploration/Rewards Std                       1.50898
exploration/Rewards Max                       6.51448
exploration/Rewards Min                      -0.670901
exploration/Returns Mean                    345.81
exploration/Returns Std                      41.2961
exploration/Returns Max                     410.336
exploration/Returns Min                     272.946
exploration/Num Paths                         6
exploration/Average Returns                 345.81
evaluation_0/num steps total             980111
evaluation_0/num paths total               6629
evaluation_0/path length Mean                96.5
evaluation_0/path length Std                  9.87266
evaluation_0/path length Max                122
evaluation_0/path length Min                 82
evaluation_0/Rewards Mean                     2.77396
evaluation_0/Rewards Std                      1.48204
evaluation_0/Rewards Max                      5.75148
evaluation_0/Rewards Min                     -0.544031
evaluation_0/Returns Mean                   267.687
evaluation_0/Returns Std                     37.247
evaluation_0/Returns Max                    354.62
evaluation_0/Returns Min                    197.995
evaluation_0/Num Paths                       82
evaluation_0/Average Returns                267.687
time/epoch (s)                                0
time/total (s)                             2638.62
Epoch                                       124
---------------------------------------  ---------------
2022-11-16 11:30:02.727946 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 125 finished
---------------------------------------  ---------------
epoch                                       125
total_step                               130000
replay_pool/size                         130000
trainer/alpha                                 0.0410899
trainer/alpha_loss                           -0.374412
trainer/entropy                              -5.88271
trainer/qf_loss                               5.14538
trainer/state_noise                           0.005
trainer/policy_loss                         -95.0305
trainer/policy_loss_without_entropy          96.0654
trainer/entropy_penalty                      -0.24172
trainer/entropy_percentage                   -0.0025162
trainer/Q1Pred Mean                          95.6047
trainer/Q1Pred Std                           31.8072
trainer/Q1Pred Max                          144.521
trainer/Q1Pred Min                          -10.1816
trainer/Q2Pred Mean                          95.9886
trainer/Q2Pred Std                           31.9751
trainer/Q2Pred Max                          144.256
trainer/Q2Pred Min                           -8.23881
trainer/QTargetWithReg Mean                  95.6331
trainer/QTargetWithReg Std                   32.2993
trainer/QTargetWithReg Max                  144.602
trainer/QTargetWithReg Min                  -17.6284
trainer/PolicyLossWithoutReg Mean            96.0654
trainer/PolicyLossWithoutReg Std             31.8718
trainer/PolicyLossWithoutReg Max            144.057
trainer/PolicyLossWithoutReg Min            -12.7333
trainer/gradient_norm                       158.637
trainer/gradient_penalty                     -0.793187
trainer/gradient_percentage                  -0.00825674
exploration/num steps total              130000
exploration/num paths total                1127
exploration/path length this epoch Mean     178.2
exploration/path length this epoch Std       72.794
exploration/path length this epoch Max      309
exploration/path length this epoch Min       94
exploration/Rewards Mean                      3.19088
exploration/Rewards Std                       1.45396
exploration/Rewards Max                       7.69507
exploration/Rewards Min                      -0.610455
exploration/Returns Mean                    568.615
exploration/Returns Std                     300.393
exploration/Returns Max                    1115.61
exploration/Returns Min                     241.676
exploration/Num Paths                         5
exploration/Average Returns                 568.615
evaluation_0/num steps total             988089
evaluation_0/num paths total               6663
evaluation_0/path length Mean               234.647
evaluation_0/path length Std                110.27
evaluation_0/path length Max                661
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     3.39324
evaluation_0/Rewards Std                      1.41649
evaluation_0/Rewards Max                      8.59917
evaluation_0/Rewards Min                     -0.409067
evaluation_0/Returns Mean                   796.213
evaluation_0/Returns Std                    462.006
evaluation_0/Returns Max                   2571.12
evaluation_0/Returns Min                    313.674
evaluation_0/Num Paths                       34
evaluation_0/Average Returns                796.213
time/epoch (s)                                0
time/total (s)                             2656.68
Epoch                                       125
---------------------------------------  ---------------
2022-11-16 11:30:19.769157 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 126 finished
---------------------------------------  ---------------
epoch                                       126
total_step                               131000
replay_pool/size                         131000
trainer/alpha                                 0.0417018
trainer/alpha_loss                            0.476638
trainer/entropy                              -6.15002
trainer/qf_loss                               5.44896
trainer/state_noise                           0.005
trainer/policy_loss                         -90.5499
trainer/policy_loss_without_entropy          91.678
trainer/entropy_penalty                      -0.256467
trainer/entropy_percentage                   -0.00279748
trainer/Q1Pred Mean                          90.3577
trainer/Q1Pred Std                           34.9853
trainer/Q1Pred Max                          143.745
trainer/Q1Pred Min                           -8.86753
trainer/Q2Pred Mean                          90.6296
trainer/Q2Pred Std                           34.8563
trainer/Q2Pred Max                          143.306
trainer/Q2Pred Min                           -6.57401
trainer/QTargetWithReg Mean                  90.3513
trainer/QTargetWithReg Std                   34.9588
trainer/QTargetWithReg Max                  143.773
trainer/QTargetWithReg Min                  -14.0127
trainer/PolicyLossWithoutReg Mean            91.678
trainer/PolicyLossWithoutReg Std             34.3746
trainer/PolicyLossWithoutReg Max            143.497
trainer/PolicyLossWithoutReg Min             -6.37584
trainer/gradient_norm                       174.33
trainer/gradient_penalty                     -0.87165
trainer/gradient_percentage                  -0.00950774
exploration/num steps total              131000
exploration/num paths total                1132
exploration/path length this epoch Mean     197.6
exploration/path length this epoch Std       82.2669
exploration/path length this epoch Max      331
exploration/path length this epoch Min      111
exploration/Rewards Mean                      2.95345
exploration/Rewards Std                       1.48956
exploration/Rewards Max                       7.58023
exploration/Rewards Min                      -1.52396
exploration/Returns Mean                    583.601
exploration/Returns Std                     354.217
exploration/Returns Max                    1177.99
exploration/Returns Min                     127.097
exploration/Num Paths                         5
exploration/Average Returns                 583.601
evaluation_0/num steps total             996018
evaluation_0/num paths total               6701
evaluation_0/path length Mean               208.658
evaluation_0/path length Std                 88.8115
evaluation_0/path length Max                440
evaluation_0/path length Min                130
evaluation_0/Rewards Mean                     2.81969
evaluation_0/Rewards Std                      1.29495
evaluation_0/Rewards Max                      7.40832
evaluation_0/Rewards Min                     -0.671445
evaluation_0/Returns Mean                   588.351
evaluation_0/Returns Std                    301.588
evaluation_0/Returns Max                   1393.32
evaluation_0/Returns Min                    340.173
evaluation_0/Num Paths                       38
evaluation_0/Average Returns                588.351
time/epoch (s)                                0
time/total (s)                             2673.72
Epoch                                       126
---------------------------------------  ---------------
2022-11-16 11:30:39.449708 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 127 finished
---------------------------------------  ---------------
epoch                                       127
total_step                               132000
replay_pool/size                         132000
trainer/alpha                                 0.0410567
trainer/alpha_loss                           -0.465519
trainer/entropy                              -5.85419
trainer/qf_loss                               4.3449
trainer/state_noise                           0.005
trainer/policy_loss                         -91.3445
trainer/policy_loss_without_entropy          92.3956
trainer/entropy_penalty                      -0.240354
trainer/entropy_percentage                   -0.00260136
trainer/Q1Pred Mean                          91.6759
trainer/Q1Pred Std                           35.0773
trainer/Q1Pred Max                          175.275
trainer/Q1Pred Min                           -3.45179
trainer/Q2Pred Mean                          91.5959
trainer/Q2Pred Std                           35.4387
trainer/Q2Pred Max                          175.185
trainer/Q2Pred Min                           -9.20404
trainer/QTargetWithReg Mean                  91.7737
trainer/QTargetWithReg Std                   35.4263
trainer/QTargetWithReg Max                  176.747
trainer/QTargetWithReg Min                   -6.17461
trainer/PolicyLossWithoutReg Mean            92.3956
trainer/PolicyLossWithoutReg Std             35.0132
trainer/PolicyLossWithoutReg Max            175.416
trainer/PolicyLossWithoutReg Min             -0.463469
trainer/gradient_norm                       162.134
trainer/gradient_penalty                     -0.81067
trainer/gradient_percentage                  -0.0087739
exploration/num steps total              132000
exploration/num paths total                1137
exploration/path length this epoch Mean     173.2
exploration/path length this epoch Std       82.6666
exploration/path length this epoch Max      327
exploration/path length this epoch Min       87
exploration/Rewards Mean                      2.70848
exploration/Rewards Std                       1.49244
exploration/Rewards Max                       6.17309
exploration/Rewards Min                      -1.74337
exploration/Returns Mean                    469.109
exploration/Returns Std                     264.978
exploration/Returns Max                     880.65
exploration/Returns Min                      61.8755
exploration/Num Paths                         5
exploration/Average Returns                 469.109
evaluation_0/num steps total                  1.0039e+06
evaluation_0/num paths total               6722
evaluation_0/path length Mean               375.143
evaluation_0/path length Std                371.605
evaluation_0/path length Max               1000
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     1.48681
evaluation_0/Rewards Std                      1.13271
evaluation_0/Rewards Max                      7.41242
evaluation_0/Rewards Min                     -2.17215
evaluation_0/Returns Mean                   557.766
evaluation_0/Returns Std                    533.996
evaluation_0/Returns Max                   2084.02
evaluation_0/Returns Min                     92.9031
evaluation_0/Num Paths                       21
evaluation_0/Average Returns                557.766
time/epoch (s)                                0
time/total (s)                             2693.4
Epoch                                       127
---------------------------------------  ---------------
2022-11-16 11:30:57.421677 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 128 finished
---------------------------------------  ----------------
epoch                                       128
total_step                               133000
replay_pool/size                         133000
trainer/alpha                                 0.0417375
trainer/alpha_loss                            0.870635
trainer/entropy                              -6.27409
trainer/qf_loss                               8.23596
trainer/state_noise                           0.005
trainer/policy_loss                         -91.4739
trainer/policy_loss_without_entropy          92.5834
trainer/entropy_penalty                      -0.261865
trainer/entropy_percentage                   -0.00282842
trainer/Q1Pred Mean                          91.3699
trainer/Q1Pred Std                           35.4079
trainer/Q1Pred Max                          146.302
trainer/Q1Pred Min                          -35.3278
trainer/Q2Pred Mean                          91.3536
trainer/Q2Pred Std                           35.4993
trainer/Q2Pred Max                          145.987
trainer/Q2Pred Min                          -41.4014
trainer/QTargetWithReg Mean                  90.7586
trainer/QTargetWithReg Std                   35.791
trainer/QTargetWithReg Max                  145.749
trainer/QTargetWithReg Min                  -44.7756
trainer/PolicyLossWithoutReg Mean            92.5834
trainer/PolicyLossWithoutReg Std             34.8462
trainer/PolicyLossWithoutReg Max            145.807
trainer/PolicyLossWithoutReg Min            -42.7604
trainer/gradient_norm                       169.524
trainer/gradient_penalty                     -0.847622
trainer/gradient_percentage                  -0.00915523
exploration/num steps total              133000
exploration/num paths total                1138
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      1.00408
exploration/Rewards Std                       0.388297
exploration/Rewards Max                       3.57209
exploration/Rewards Min                      -0.751261
exploration/Returns Mean                   1004.08
exploration/Returns Std                       0
exploration/Returns Max                    1004.08
exploration/Returns Min                    1004.08
exploration/Num Paths                         1
exploration/Average Returns                1004.08
evaluation_0/num steps total                  1.01174e+06
evaluation_0/num paths total               6759
evaluation_0/path length Mean               211.946
evaluation_0/path length Std                131.655
evaluation_0/path length Max                542
evaluation_0/path length Min                 80
evaluation_0/Rewards Mean                     3.0094
evaluation_0/Rewards Std                      1.42532
evaluation_0/Rewards Max                      8.50845
evaluation_0/Rewards Min                     -0.370113
evaluation_0/Returns Mean                   637.831
evaluation_0/Returns Std                    455.994
evaluation_0/Returns Max                   1857.92
evaluation_0/Returns Min                    204.417
evaluation_0/Num Paths                       37
evaluation_0/Average Returns                637.831
time/epoch (s)                                0
time/total (s)                             2711.37
Epoch                                       128
---------------------------------------  ----------------
2022-11-16 11:31:15.412085 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 129 finished
---------------------------------------  ----------------
epoch                                       129
total_step                               134000
replay_pool/size                         134000
trainer/alpha                                 0.0418878
trainer/alpha_loss                            0.972849
trainer/entropy                              -6.30662
trainer/qf_loss                               7.60514
trainer/state_noise                           0.005
trainer/policy_loss                         -93.9684
trainer/policy_loss_without_entropy          95.0762
trainer/entropy_penalty                      -0.26417
trainer/entropy_percentage                   -0.00277851
trainer/Q1Pred Mean                          93.7357
trainer/Q1Pred Std                           33.9486
trainer/Q1Pred Max                          143.677
trainer/Q1Pred Min                          -15.2067
trainer/Q2Pred Mean                          93.9625
trainer/Q2Pred Std                           33.8925
trainer/Q2Pred Max                          143.77
trainer/Q2Pred Min                           -9.85278
trainer/QTargetWithReg Mean                  94.1428
trainer/QTargetWithReg Std                   34.0906
trainer/QTargetWithReg Max                  143.306
trainer/QTargetWithReg Min                  -20.2148
trainer/PolicyLossWithoutReg Mean            95.0762
trainer/PolicyLossWithoutReg Std             32.9286
trainer/PolicyLossWithoutReg Max            143.448
trainer/PolicyLossWithoutReg Min             -8.89753
trainer/gradient_norm                       168.713
trainer/gradient_penalty                     -0.843563
trainer/gradient_percentage                  -0.0088725
exploration/num steps total              134000
exploration/num paths total                1144
exploration/path length this epoch Mean     155
exploration/path length this epoch Std       88.3799
exploration/path length this epoch Max      351
exploration/path length this epoch Min       98
exploration/Rewards Mean                      2.35153
exploration/Rewards Std                       1.29015
exploration/Rewards Max                       5.89523
exploration/Rewards Min                      -1.58026
exploration/Returns Mean                    364.487
exploration/Returns Std                     260.975
exploration/Returns Max                     932.919
exploration/Returns Min                     133.338
exploration/Num Paths                         6
exploration/Average Returns                 364.487
evaluation_0/num steps total                  1.01965e+06
evaluation_0/num paths total               6774
evaluation_0/path length Mean               527.667
evaluation_0/path length Std                336.074
evaluation_0/path length Max               1000
evaluation_0/path length Min                146
evaluation_0/Rewards Mean                     2.24411
evaluation_0/Rewards Std                      1.28065
evaluation_0/Rewards Max                      7.62891
evaluation_0/Rewards Min                     -1.22981
evaluation_0/Returns Mean                  1184.14
evaluation_0/Returns Std                    854.452
evaluation_0/Returns Max                   2644.95
evaluation_0/Returns Min                    252.891
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1184.14
time/epoch (s)                                0
time/total (s)                             2729.36
Epoch                                       129
---------------------------------------  ----------------
2022-11-16 11:31:32.403215 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 130 finished
---------------------------------------  ----------------
epoch                                       130
total_step                               135000
replay_pool/size                         135000
trainer/alpha                                 0.0432012
trainer/alpha_loss                            0.125267
trainer/entropy                              -6.03987
trainer/qf_loss                               6.91436
trainer/state_noise                           0.005
trainer/policy_loss                         -90.9202
trainer/policy_loss_without_entropy          92.0124
trainer/entropy_penalty                      -0.26093
trainer/entropy_percentage                   -0.00283581
trainer/Q1Pred Mean                          90.6262
trainer/Q1Pred Std                           34.7236
trainer/Q1Pred Max                          143.931
trainer/Q1Pred Min                           -0.0251418
trainer/Q2Pred Mean                          90.5239
trainer/Q2Pred Std                           34.888
trainer/Q2Pred Max                          144.392
trainer/Q2Pred Min                           -2.528
trainer/QTargetWithReg Mean                  91.1494
trainer/QTargetWithReg Std                   34.72
trainer/QTargetWithReg Max                  144.823
trainer/QTargetWithReg Min                   -3.27589
trainer/PolicyLossWithoutReg Mean            92.0124
trainer/PolicyLossWithoutReg Std             34.231
trainer/PolicyLossWithoutReg Max            145.047
trainer/PolicyLossWithoutReg Min              0.293214
trainer/gradient_norm                       166.266
trainer/gradient_penalty                     -0.831329
trainer/gradient_percentage                  -0.00903497
exploration/num steps total              135000
exploration/num paths total                1145
exploration/path length this epoch Mean     865
exploration/path length this epoch Std        0
exploration/path length this epoch Max      865
exploration/path length this epoch Min      865
exploration/Rewards Mean                      2.00708
exploration/Rewards Std                       0.979662
exploration/Rewards Max                       5.43832
exploration/Rewards Min                      -0.701301
exploration/Returns Mean                   1736.12
exploration/Returns Std                       0
exploration/Returns Max                    1736.12
exploration/Returns Min                    1736.12
exploration/Num Paths                         1
exploration/Average Returns                1736.12
evaluation_0/num steps total                  1.02765e+06
evaluation_0/num paths total               6832
evaluation_0/path length Mean               137.879
evaluation_0/path length Std                 84.3975
evaluation_0/path length Max                764
evaluation_0/path length Min                117
evaluation_0/Rewards Mean                     2.57581
evaluation_0/Rewards Std                      1.452
evaluation_0/Rewards Max                      7.49428
evaluation_0/Rewards Min                     -1.42035
evaluation_0/Returns Mean                   355.152
evaluation_0/Returns Std                    271.112
evaluation_0/Returns Max                   2371.64
evaluation_0/Returns Min                    284.746
evaluation_0/Num Paths                       58
evaluation_0/Average Returns                355.152
time/epoch (s)                                0
time/total (s)                             2746.35
Epoch                                       130
---------------------------------------  ----------------
2022-11-16 11:31:50.569124 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 131 finished
---------------------------------------  ----------------
epoch                                       131
total_step                               136000
replay_pool/size                         136000
trainer/alpha                                 0.0430704
trainer/alpha_loss                           -0.223475
trainer/entropy                              -5.92894
trainer/qf_loss                               5.77353
trainer/state_noise                           0.005
trainer/policy_loss                         -91.7356
trainer/policy_loss_without_entropy          92.8178
trainer/entropy_penalty                      -0.255362
trainer/entropy_percentage                   -0.00275122
trainer/Q1Pred Mean                          91.7089
trainer/Q1Pred Std                           36.9285
trainer/Q1Pred Max                          147.466
trainer/Q1Pred Min                           -8.0401
trainer/Q2Pred Mean                          91.6112
trainer/Q2Pred Std                           36.767
trainer/Q2Pred Max                          145.963
trainer/Q2Pred Min                           -7.83716
trainer/QTargetWithReg Mean                  92.0132
trainer/QTargetWithReg Std                   36.5315
trainer/QTargetWithReg Max                  147.874
trainer/QTargetWithReg Min                  -11.43
trainer/PolicyLossWithoutReg Mean            92.8178
trainer/PolicyLossWithoutReg Std             36.096
trainer/PolicyLossWithoutReg Max            146.581
trainer/PolicyLossWithoutReg Min             -0.333894
trainer/gradient_norm                       165.359
trainer/gradient_penalty                     -0.826796
trainer/gradient_percentage                  -0.00890773
exploration/num steps total              136000
exploration/num paths total                1148
exploration/path length this epoch Mean     234.333
exploration/path length this epoch Std      109.962
exploration/path length this epoch Max      389
exploration/path length this epoch Min      143
exploration/Rewards Mean                      2.45118
exploration/Rewards Std                       1.2263
exploration/Rewards Max                       6.43138
exploration/Rewards Min                      -0.565436
exploration/Returns Mean                    574.393
exploration/Returns Std                     280.188
exploration/Returns Max                     964.052
exploration/Returns Min                     317.261
exploration/Num Paths                         3
exploration/Average Returns                 574.393
evaluation_0/num steps total                  1.03561e+06
evaluation_0/num paths total               6878
evaluation_0/path length Mean               172.978
evaluation_0/path length Std                112.814
evaluation_0/path length Max                554
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     2.75114
evaluation_0/Rewards Std                      1.41059
evaluation_0/Rewards Max                      7.55071
evaluation_0/Rewards Min                     -0.687731
evaluation_0/Returns Mean                   475.887
evaluation_0/Returns Std                    358.272
evaluation_0/Returns Max                   1659.1
evaluation_0/Returns Min                    230.919
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                475.887
time/epoch (s)                                0
time/total (s)                             2764.52
Epoch                                       131
---------------------------------------  ----------------
2022-11-16 11:32:07.963708 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 132 finished
---------------------------------------  ---------------
epoch                                       132
total_step                               137000
replay_pool/size                         137000
trainer/alpha                                 0.042883
trainer/alpha_loss                            0.214075
trainer/entropy                              -6.06797
trainer/qf_loss                               4.81137
trainer/state_noise                           0.005
trainer/policy_loss                         -93.3242
trainer/policy_loss_without_entropy          94.4185
trainer/entropy_penalty                      -0.260213
trainer/entropy_percentage                   -0.00275595
trainer/Q1Pred Mean                          93.5506
trainer/Q1Pred Std                           36.6132
trainer/Q1Pred Max                          151.491
trainer/Q1Pred Min                          -33.8244
trainer/Q2Pred Mean                          93.6904
trainer/Q2Pred Std                           36.473
trainer/Q2Pred Max                          152.287
trainer/Q2Pred Min                          -35.7746
trainer/QTargetWithReg Mean                  93.7192
trainer/QTargetWithReg Std                   36.6764
trainer/QTargetWithReg Max                  152.297
trainer/QTargetWithReg Min                  -32.1383
trainer/PolicyLossWithoutReg Mean            94.4185
trainer/PolicyLossWithoutReg Std             36.0242
trainer/PolicyLossWithoutReg Max            152.59
trainer/PolicyLossWithoutReg Min            -32.4402
trainer/gradient_norm                       166.816
trainer/gradient_penalty                     -0.834078
trainer/gradient_percentage                  -0.00883384
exploration/num steps total              137000
exploration/num paths total                1153
exploration/path length this epoch Mean     184.2
exploration/path length this epoch Std      121.797
exploration/path length this epoch Max      424
exploration/path length this epoch Min       90
exploration/Rewards Mean                      2.82621
exploration/Rewards Std                       1.40776
exploration/Rewards Max                       7.09506
exploration/Rewards Min                      -0.573197
exploration/Returns Mean                    520.588
exploration/Returns Std                     390.537
exploration/Returns Max                    1295.89
exploration/Returns Min                     239.233
exploration/Num Paths                         5
exploration/Average Returns                 520.588
evaluation_0/num steps total                  1.0431e+06
evaluation_0/num paths total               6892
evaluation_0/path length Mean               535.5
evaluation_0/path length Std                322.383
evaluation_0/path length Max               1000
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     2.45832
evaluation_0/Rewards Std                      1.19104
evaluation_0/Rewards Max                      7.84918
evaluation_0/Rewards Min                     -0.585955
evaluation_0/Returns Mean                  1316.43
evaluation_0/Returns Std                    798.464
evaluation_0/Returns Max                   2602
evaluation_0/Returns Min                    266.943
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               1316.43
time/epoch (s)                                0
time/total (s)                             2781.91
Epoch                                       132
---------------------------------------  ---------------
2022-11-16 11:32:26.035516 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 133 finished
---------------------------------------  ---------------
epoch                                       133
total_step                               138000
replay_pool/size                         138000
trainer/alpha                                 0.0418798
trainer/alpha_loss                            1.93441
trainer/entropy                              -6.60961
trainer/qf_loss                               5.30047
trainer/state_noise                           0.005
trainer/policy_loss                         -93.0146
trainer/policy_loss_without_entropy          94.1745
trainer/entropy_penalty                      -0.27681
trainer/entropy_percentage                   -0.00293933
trainer/Q1Pred Mean                          92.7328
trainer/Q1Pred Std                           34.7799
trainer/Q1Pred Max                          152.506
trainer/Q1Pred Min                           -6.08712
trainer/Q2Pred Mean                          92.7783
trainer/Q2Pred Std                           34.756
trainer/Q2Pred Max                          151.293
trainer/Q2Pred Min                           -4.82682
trainer/QTargetWithReg Mean                  92.8198
trainer/QTargetWithReg Std                   35.066
trainer/QTargetWithReg Max                  154.726
trainer/QTargetWithReg Min                  -12.6378
trainer/PolicyLossWithoutReg Mean            94.1745
trainer/PolicyLossWithoutReg Std             34.0346
trainer/PolicyLossWithoutReg Max            152.547
trainer/PolicyLossWithoutReg Min             -2.77837
trainer/gradient_norm                       176.611
trainer/gradient_penalty                     -0.883057
trainer/gradient_percentage                  -0.00937682
exploration/num steps total              138000
exploration/num paths total                1158
exploration/path length this epoch Mean     173.6
exploration/path length this epoch Std       79.8589
exploration/path length this epoch Max      315
exploration/path length this epoch Min      104
exploration/Rewards Mean                      2.46533
exploration/Rewards Std                       1.4269
exploration/Rewards Max                       6.46342
exploration/Rewards Min                      -0.597021
exploration/Returns Mean                    427.981
exploration/Returns Std                     195.744
exploration/Returns Max                     714.166
exploration/Returns Min                     246.762
exploration/Num Paths                         5
exploration/Average Returns                 427.981
evaluation_0/num steps total                  1.0511e+06
evaluation_0/num paths total               6911
evaluation_0/path length Mean               420.737
evaluation_0/path length Std                157.411
evaluation_0/path length Max                792
evaluation_0/path length Min                217
evaluation_0/Rewards Mean                     2.91334
evaluation_0/Rewards Std                      1.34226
evaluation_0/Rewards Max                      7.76456
evaluation_0/Rewards Min                     -0.578568
evaluation_0/Returns Mean                  1225.75
evaluation_0/Returns Std                    528.732
evaluation_0/Returns Max                   2606.04
evaluation_0/Returns Min                    610.122
evaluation_0/Num Paths                       19
evaluation_0/Average Returns               1225.75
time/epoch (s)                                0
time/total (s)                             2799.98
Epoch                                       133
---------------------------------------  ---------------
2022-11-16 11:32:43.884086 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 134 finished
---------------------------------------  ----------------
epoch                                       134
total_step                               139000
replay_pool/size                         139000
trainer/alpha                                 0.0419361
trainer/alpha_loss                            0.258134
trainer/entropy                              -6.08139
trainer/qf_loss                               5.18233
trainer/state_noise                           0.005
trainer/policy_loss                         -89.4904
trainer/policy_loss_without_entropy          90.5942
trainer/entropy_penalty                      -0.25503
trainer/entropy_percentage                   -0.00281508
trainer/Q1Pred Mean                          89.8898
trainer/Q1Pred Std                           36.3167
trainer/Q1Pred Max                          145.452
trainer/Q1Pred Min                          -17.2736
trainer/Q2Pred Mean                          90.0079
trainer/Q2Pred Std                           36.4082
trainer/Q2Pred Max                          147.061
trainer/Q2Pred Min                          -20.0765
trainer/QTargetWithReg Mean                  90.1534
trainer/QTargetWithReg Std                   36.6507
trainer/QTargetWithReg Max                  146.925
trainer/QTargetWithReg Min                  -23.0521
trainer/PolicyLossWithoutReg Mean            90.5942
trainer/PolicyLossWithoutReg Std             36.1449
trainer/PolicyLossWithoutReg Max            146.054
trainer/PolicyLossWithoutReg Min            -13.3931
trainer/gradient_norm                       169.756
trainer/gradient_penalty                     -0.848778
trainer/gradient_percentage                  -0.00936901
exploration/num steps total              139000
exploration/num paths total                1161
exploration/path length this epoch Mean     299.667
exploration/path length this epoch Std       82.762
exploration/path length this epoch Max      388
exploration/path length this epoch Min      189
exploration/Rewards Mean                      2.77967
exploration/Rewards Std                       1.28109
exploration/Rewards Max                       6.50701
exploration/Rewards Min                      -0.759296
exploration/Returns Mean                    832.973
exploration/Returns Std                     189.743
exploration/Returns Max                     983.74
exploration/Returns Min                     565.352
exploration/Num Paths                         3
exploration/Average Returns                 832.973
evaluation_0/num steps total                  1.05897e+06
evaluation_0/num paths total               6937
evaluation_0/path length Mean               302.885
evaluation_0/path length Std                194.136
evaluation_0/path length Max                855
evaluation_0/path length Min                133
evaluation_0/Rewards Mean                     3.25678
evaluation_0/Rewards Std                      1.33749
evaluation_0/Rewards Max                      8.37314
evaluation_0/Rewards Min                     -0.496718
evaluation_0/Returns Mean                   986.429
evaluation_0/Returns Std                    664.774
evaluation_0/Returns Max                   2657.32
evaluation_0/Returns Min                    373.783
evaluation_0/Num Paths                       26
evaluation_0/Average Returns                986.429
time/epoch (s)                                0
time/total (s)                             2817.83
Epoch                                       134
---------------------------------------  ----------------
2022-11-16 11:33:01.834662 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 135 finished
---------------------------------------  ----------------
epoch                                       135
total_step                               140000
replay_pool/size                         140000
trainer/alpha                                 0.0429584
trainer/alpha_loss                            0.571725
trainer/entropy                              -6.18163
trainer/qf_loss                               6.11621
trainer/state_noise                           0.005
trainer/policy_loss                         -95.3585
trainer/policy_loss_without_entropy          96.4803
trainer/entropy_penalty                      -0.265553
trainer/entropy_percentage                   -0.00275241
trainer/Q1Pred Mean                          95.366
trainer/Q1Pred Std                           33.3598
trainer/Q1Pred Max                          145.344
trainer/Q1Pred Min                          -19.5175
trainer/Q2Pred Mean                          95.2857
trainer/Q2Pred Std                           32.9457
trainer/Q2Pred Max                          143.947
trainer/Q2Pred Min                           -6.15053
trainer/QTargetWithReg Mean                  95.5919
trainer/QTargetWithReg Std                   32.9659
trainer/QTargetWithReg Max                  144.576
trainer/QTargetWithReg Min                   -0.789306
trainer/PolicyLossWithoutReg Mean            96.4803
trainer/PolicyLossWithoutReg Std             32.4569
trainer/PolicyLossWithoutReg Max            144.478
trainer/PolicyLossWithoutReg Min            -22.1554
trainer/gradient_norm                       171.241
trainer/gradient_penalty                     -0.856207
trainer/gradient_percentage                  -0.00887443
exploration/num steps total              140000
exploration/num paths total                1163
exploration/path length this epoch Mean     252
exploration/path length this epoch Std      156
exploration/path length this epoch Max      408
exploration/path length this epoch Min       96
exploration/Rewards Mean                      3.27684
exploration/Rewards Std                       1.36171
exploration/Rewards Max                       7.18406
exploration/Rewards Min                      -0.460737
exploration/Returns Mean                    825.763
exploration/Returns Std                     565.217
exploration/Returns Max                    1390.98
exploration/Returns Min                     260.546
exploration/Num Paths                         2
exploration/Average Returns                 825.763
evaluation_0/num steps total                  1.06696e+06
evaluation_0/num paths total               6949
evaluation_0/path length Mean               665.75
evaluation_0/path length Std                360.144
evaluation_0/path length Max               1000
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     1.78655
evaluation_0/Rewards Std                      1.20563
evaluation_0/Rewards Max                      8.542
evaluation_0/Rewards Min                     -1.36348
evaluation_0/Returns Mean                  1189.39
evaluation_0/Returns Std                    748.158
evaluation_0/Returns Max                   2550.26
evaluation_0/Returns Min                    225.464
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               1189.39
time/epoch (s)                                0
time/total (s)                             2835.78
Epoch                                       135
---------------------------------------  ----------------
2022-11-16 11:33:19.382982 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 136 finished
---------------------------------------  ----------------
epoch                                       136
total_step                               141000
replay_pool/size                         141000
trainer/alpha                                 0.0429567
trainer/alpha_loss                            1.5389
trainer/entropy                              -6.48889
trainer/qf_loss                               5.73345
trainer/state_noise                           0.005
trainer/policy_loss                         -90.2862
trainer/policy_loss_without_entropy          91.4609
trainer/entropy_penalty                      -0.278741
trainer/entropy_percentage                   -0.00304765
trainer/Q1Pred Mean                          90.2627
trainer/Q1Pred Std                           36.6315
trainer/Q1Pred Max                          146.11
trainer/Q1Pred Min                          -24.5222
trainer/Q2Pred Mean                          90.0476
trainer/Q2Pred Std                           36.318
trainer/Q2Pred Max                          146.733
trainer/Q2Pred Min                          -26.5773
trainer/QTargetWithReg Mean                  90.3238
trainer/QTargetWithReg Std                   36.6255
trainer/QTargetWithReg Max                  146.162
trainer/QTargetWithReg Min                  -27.7332
trainer/PolicyLossWithoutReg Mean            91.4609
trainer/PolicyLossWithoutReg Std             35.8851
trainer/PolicyLossWithoutReg Max            146.1
trainer/PolicyLossWithoutReg Min            -25.7369
trainer/gradient_norm                       179.193
trainer/gradient_penalty                     -0.895966
trainer/gradient_percentage                  -0.00979616
exploration/num steps total              141000
exploration/num paths total                1166
exploration/path length this epoch Mean     304.333
exploration/path length this epoch Std      140.117
exploration/path length this epoch Max      467
exploration/path length this epoch Min      125
exploration/Rewards Mean                      2.685
exploration/Rewards Std                       1.42603
exploration/Rewards Max                       6.88024
exploration/Rewards Min                      -0.43231
exploration/Returns Mean                    817.135
exploration/Returns Std                     359.327
exploration/Returns Max                    1190.49
exploration/Returns Min                     331.911
exploration/Num Paths                         3
exploration/Average Returns                 817.135
evaluation_0/num steps total                  1.07442e+06
evaluation_0/num paths total               6981
evaluation_0/path length Mean               232.938
evaluation_0/path length Std                 80.4829
evaluation_0/path length Max                458
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     2.59532
evaluation_0/Rewards Std                      1.23764
evaluation_0/Rewards Max                      6.50712
evaluation_0/Rewards Min                     -0.947164
evaluation_0/Returns Mean                   604.547
evaluation_0/Returns Std                    248.774
evaluation_0/Returns Max                   1475.24
evaluation_0/Returns Min                    250.431
evaluation_0/Num Paths                       32
evaluation_0/Average Returns                604.547
time/epoch (s)                                0
time/total (s)                             2853.33
Epoch                                       136
---------------------------------------  ----------------
2022-11-16 11:33:36.983771 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 137 finished
---------------------------------------  ----------------
epoch                                       137
total_step                               142000
replay_pool/size                         142000
trainer/alpha                                 0.0422972
trainer/alpha_loss                            0.0274878
trainer/entropy                              -6.00869
trainer/qf_loss                               5.24985
trainer/state_noise                           0.005
trainer/policy_loss                         -94.426
trainer/policy_loss_without_entropy          95.5772
trainer/entropy_penalty                      -0.254151
trainer/entropy_percentage                   -0.00265911
trainer/Q1Pred Mean                          94.7604
trainer/Q1Pred Std                           33.8721
trainer/Q1Pred Max                          148.884
trainer/Q1Pred Min                          -52.6861
trainer/Q2Pred Mean                          94.9299
trainer/Q2Pred Std                           33.5929
trainer/Q2Pred Max                          148.258
trainer/Q2Pred Min                          -50.3819
trainer/QTargetWithReg Mean                  94.612
trainer/QTargetWithReg Std                   33.94
trainer/QTargetWithReg Max                  148.454
trainer/QTargetWithReg Min                  -54.7567
trainer/PolicyLossWithoutReg Mean            95.5772
trainer/PolicyLossWithoutReg Std             33.3648
trainer/PolicyLossWithoutReg Max            149.35
trainer/PolicyLossWithoutReg Min            -50.6307
trainer/gradient_norm                       179.407
trainer/gradient_penalty                     -0.897034
trainer/gradient_percentage                  -0.00938544
exploration/num steps total              142000
exploration/num paths total                1170
exploration/path length this epoch Mean     248.5
exploration/path length this epoch Std       51.3882
exploration/path length this epoch Max      303
exploration/path length this epoch Min      165
exploration/Rewards Mean                      2.54781
exploration/Rewards Std                       1.32802
exploration/Rewards Max                       6.57852
exploration/Rewards Min                      -0.65395
exploration/Returns Mean                    633.131
exploration/Returns Std                     113.323
exploration/Returns Max                     732.761
exploration/Returns Min                     440.488
exploration/Num Paths                         4
exploration/Average Returns                 633.131
evaluation_0/num steps total                  1.08155e+06
evaluation_0/num paths total               6996
evaluation_0/path length Mean               475.6
evaluation_0/path length Std                314.5
evaluation_0/path length Max               1000
evaluation_0/path length Min                113
evaluation_0/Rewards Mean                     2.36284
evaluation_0/Rewards Std                      1.18332
evaluation_0/Rewards Max                      7.48705
evaluation_0/Rewards Min                     -0.637357
evaluation_0/Returns Mean                  1123.77
evaluation_0/Returns Std                    692.266
evaluation_0/Returns Max                   2238.15
evaluation_0/Returns Min                    227.984
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1123.77
time/epoch (s)                                0
time/total (s)                             2870.93
Epoch                                       137
---------------------------------------  ----------------
2022-11-16 11:33:54.824033 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 138 finished
---------------------------------------  ----------------
epoch                                       138
total_step                               143000
replay_pool/size                         143000
trainer/alpha                                 0.0429375
trainer/alpha_loss                            0.866404
trainer/entropy                              -6.27523
trainer/qf_loss                               4.97746
trainer/state_noise                           0.005
trainer/policy_loss                         -93.6992
trainer/policy_loss_without_entropy          94.8666
trainer/entropy_penalty                      -0.269443
trainer/entropy_percentage                   -0.00284023
trainer/Q1Pred Mean                          94.2261
trainer/Q1Pred Std                           35.8304
trainer/Q1Pred Max                          148.615
trainer/Q1Pred Min                          -22.1195
trainer/Q2Pred Mean                          93.6784
trainer/Q2Pred Std                           35.7646
trainer/Q2Pred Max                          147.52
trainer/Q2Pred Min                          -23.2821
trainer/QTargetWithReg Mean                  94.1321
trainer/QTargetWithReg Std                   35.6748
trainer/QTargetWithReg Max                  146.967
trainer/QTargetWithReg Min                  -24.358
trainer/PolicyLossWithoutReg Mean            94.8666
trainer/PolicyLossWithoutReg Std             34.9813
trainer/PolicyLossWithoutReg Max            148.509
trainer/PolicyLossWithoutReg Min            -20.6167
trainer/gradient_norm                       179.589
trainer/gradient_penalty                     -0.897945
trainer/gradient_percentage                  -0.00946535
exploration/num steps total              143000
exploration/num paths total                1172
exploration/path length this epoch Mean     359.5
exploration/path length this epoch Std      110.5
exploration/path length this epoch Max      470
exploration/path length this epoch Min      249
exploration/Rewards Mean                      2.62528
exploration/Rewards Std                       1.32529
exploration/Rewards Max                       6.92576
exploration/Rewards Min                      -0.635698
exploration/Returns Mean                    943.789
exploration/Returns Std                     297.954
exploration/Returns Max                    1241.74
exploration/Returns Min                     645.835
exploration/Num Paths                         2
exploration/Average Returns                 943.789
evaluation_0/num steps total                  1.08945e+06
evaluation_0/num paths total               7017
evaluation_0/path length Mean               376.19
evaluation_0/path length Std                219.538
evaluation_0/path length Max                832
evaluation_0/path length Min                126
evaluation_0/Rewards Mean                     2.62857
evaluation_0/Rewards Std                      1.16833
evaluation_0/Rewards Max                      7.21182
evaluation_0/Rewards Min                     -0.385478
evaluation_0/Returns Mean                   988.845
evaluation_0/Returns Std                    618.842
evaluation_0/Returns Max                   2265.14
evaluation_0/Returns Min                    287.837
evaluation_0/Num Paths                       21
evaluation_0/Average Returns                988.845
time/epoch (s)                                0
time/total (s)                             2888.77
Epoch                                       138
---------------------------------------  ----------------
2022-11-16 11:34:14.155585 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 139 finished
---------------------------------------  ----------------
epoch                                       139
total_step                               144000
replay_pool/size                         144000
trainer/alpha                                 0.0433565
trainer/alpha_loss                           -1.03571
trainer/entropy                              -5.66997
trainer/qf_loss                               5.25175
trainer/state_noise                           0.005
trainer/policy_loss                         -92.2397
trainer/policy_loss_without_entropy          93.3774
trainer/entropy_penalty                      -0.24583
trainer/entropy_percentage                   -0.00263265
trainer/Q1Pred Mean                          92.8524
trainer/Q1Pred Std                           36.4974
trainer/Q1Pred Max                          146.52
trainer/Q1Pred Min                          -38.6645
trainer/Q2Pred Mean                          92.7203
trainer/Q2Pred Std                           36.3423
trainer/Q2Pred Max                          145.862
trainer/Q2Pred Min                          -36.1408
trainer/QTargetWithReg Mean                  92.3462
trainer/QTargetWithReg Std                   36.473
trainer/QTargetWithReg Max                  145.88
trainer/QTargetWithReg Min                  -35.1929
trainer/PolicyLossWithoutReg Mean            93.3774
trainer/PolicyLossWithoutReg Std             35.9174
trainer/PolicyLossWithoutReg Max            145.855
trainer/PolicyLossWithoutReg Min            -33.7179
trainer/gradient_norm                       178.375
trainer/gradient_penalty                     -0.891876
trainer/gradient_percentage                  -0.00955131
exploration/num steps total              144000
exploration/num paths total                1175
exploration/path length this epoch Mean     294.667
exploration/path length this epoch Std      143.966
exploration/path length this epoch Max      498
exploration/path length this epoch Min      184
exploration/Rewards Mean                      2.39107
exploration/Rewards Std                       1.15047
exploration/Rewards Max                       6.6266
exploration/Rewards Min                      -0.492095
exploration/Returns Mean                    704.568
exploration/Returns Std                     399.452
exploration/Returns Max                    1262.64
exploration/Returns Min                     349.643
exploration/Num Paths                         3
exploration/Average Returns                 704.568
evaluation_0/num steps total                  1.09735e+06
evaluation_0/num paths total               7044
evaluation_0/path length Mean               292.704
evaluation_0/path length Std                171.636
evaluation_0/path length Max               1000
evaluation_0/path length Min                122
evaluation_0/Rewards Mean                     2.58674
evaluation_0/Rewards Std                      1.20802
evaluation_0/Rewards Max                      8.02404
evaluation_0/Rewards Min                     -0.742939
evaluation_0/Returns Mean                   757.15
evaluation_0/Returns Std                    499.935
evaluation_0/Returns Max                   2802.37
evaluation_0/Returns Min                    295.492
evaluation_0/Num Paths                       27
evaluation_0/Average Returns                757.15
time/epoch (s)                                0
time/total (s)                             2908.1
Epoch                                       139
---------------------------------------  ----------------
2022-11-16 11:34:31.962794 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 140 finished
---------------------------------------  ----------------
epoch                                       140
total_step                               145000
replay_pool/size                         145000
trainer/alpha                                 0.0430108
trainer/alpha_loss                           -0.0670414
trainer/entropy                              -5.97869
trainer/qf_loss                               6.29659
trainer/state_noise                           0.005
trainer/policy_loss                         -94.665
trainer/policy_loss_without_entropy          95.841
trainer/entropy_penalty                      -0.257148
trainer/entropy_percentage                   -0.00268307
trainer/Q1Pred Mean                          94.5523
trainer/Q1Pred Std                           33.3323
trainer/Q1Pred Max                          149.2
trainer/Q1Pred Min                           -5.90837
trainer/Q2Pred Mean                          94.3672
trainer/Q2Pred Std                           33.5037
trainer/Q2Pred Max                          147.383
trainer/Q2Pred Min                           -7.28966
trainer/QTargetWithReg Mean                  94.5871
trainer/QTargetWithReg Std                   33.7448
trainer/QTargetWithReg Max                  148.074
trainer/QTargetWithReg Min                   -9.89995
trainer/PolicyLossWithoutReg Mean            95.841
trainer/PolicyLossWithoutReg Std             32.7363
trainer/PolicyLossWithoutReg Max            148.461
trainer/PolicyLossWithoutReg Min             -7.43636
trainer/gradient_norm                       183.785
trainer/gradient_penalty                     -0.918925
trainer/gradient_percentage                  -0.00958801
exploration/num steps total              145000
exploration/num paths total                1180
exploration/path length this epoch Mean     191.6
exploration/path length this epoch Std      103.587
exploration/path length this epoch Max      381
exploration/path length this epoch Min      108
exploration/Rewards Mean                      2.40329
exploration/Rewards Std                       1.19535
exploration/Rewards Max                       6.1479
exploration/Rewards Min                      -0.618432
exploration/Returns Mean                    460.47
exploration/Returns Std                     238.17
exploration/Returns Max                     898.459
exploration/Returns Min                     248.182
exploration/Num Paths                         5
exploration/Average Returns                 460.47
evaluation_0/num steps total                  1.10535e+06
evaluation_0/num paths total               7066
evaluation_0/path length Mean               363.545
evaluation_0/path length Std                221.276
evaluation_0/path length Max               1000
evaluation_0/path length Min                125
evaluation_0/Rewards Mean                     2.68799
evaluation_0/Rewards Std                      1.30489
evaluation_0/Rewards Max                      7.19635
evaluation_0/Rewards Min                     -0.673444
evaluation_0/Returns Mean                   977.205
evaluation_0/Returns Std                    542.148
evaluation_0/Returns Max                   2112.65
evaluation_0/Returns Min                    328.83
evaluation_0/Num Paths                       22
evaluation_0/Average Returns                977.205
time/epoch (s)                                0
time/total (s)                             2925.91
Epoch                                       140
---------------------------------------  ----------------
2022-11-16 11:34:50.781906 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 141 finished
---------------------------------------  ----------------
epoch                                       141
total_step                               146000
replay_pool/size                         146000
trainer/alpha                                 0.0426645
trainer/alpha_loss                            0.305199
trainer/entropy                              -6.09676
trainer/qf_loss                               6.96736
trainer/state_noise                           0.005
trainer/policy_loss                         -93.31
trainer/policy_loss_without_entropy          94.4519
trainer/entropy_penalty                      -0.260115
trainer/entropy_percentage                   -0.00275394
trainer/Q1Pred Mean                          93.3758
trainer/Q1Pred Std                           34.3819
trainer/Q1Pred Max                          148.988
trainer/Q1Pred Min                           -3.7511
trainer/Q2Pred Mean                          93.4217
trainer/Q2Pred Std                           34.3632
trainer/Q2Pred Max                          150.007
trainer/Q2Pred Min                           -1.80647
trainer/QTargetWithReg Mean                  93.2938
trainer/QTargetWithReg Std                   34.53
trainer/QTargetWithReg Max                  148.913
trainer/QTargetWithReg Min                   -4.73477
trainer/PolicyLossWithoutReg Mean            94.4519
trainer/PolicyLossWithoutReg Std             33.6415
trainer/PolicyLossWithoutReg Max            149.699
trainer/PolicyLossWithoutReg Min             -0.701347
trainer/gradient_norm                       176.35
trainer/gradient_penalty                     -0.88175
trainer/gradient_percentage                  -0.00933544
exploration/num steps total              146000
exploration/num paths total                1183
exploration/path length this epoch Mean     289.333
exploration/path length this epoch Std      208.778
exploration/path length this epoch Max      583
exploration/path length this epoch Min      116
exploration/Rewards Mean                      3.3366
exploration/Rewards Std                       1.33554
exploration/Rewards Max                       6.84297
exploration/Rewards Min                      -0.648606
exploration/Returns Mean                    965.391
exploration/Returns Std                     826.497
exploration/Returns Max                    2130.27
exploration/Returns Min                     299.689
exploration/Num Paths                         3
exploration/Average Returns                 965.391
evaluation_0/num steps total                  1.11311e+06
evaluation_0/num paths total               7095
evaluation_0/path length Mean               267.483
evaluation_0/path length Std                196.85
evaluation_0/path length Max                772
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     3.21475
evaluation_0/Rewards Std                      1.34099
evaluation_0/Rewards Max                      7.31483
evaluation_0/Rewards Min                     -0.667752
evaluation_0/Returns Mean                   859.891
evaluation_0/Returns Std                    688.846
evaluation_0/Returns Max                   2594.99
evaluation_0/Returns Min                    233.45
evaluation_0/Num Paths                       29
evaluation_0/Average Returns                859.891
time/epoch (s)                                0
time/total (s)                             2944.73
Epoch                                       141
---------------------------------------  ----------------
2022-11-16 11:35:07.720666 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 142 finished
---------------------------------------  ---------------
epoch                                       142
total_step                               147000
replay_pool/size                         147000
trainer/alpha                                 0.043302
trainer/alpha_loss                            0.0761031
trainer/entropy                              -6.02424
trainer/qf_loss                               7.14613
trainer/state_noise                           0.005
trainer/policy_loss                         -93.6505
trainer/policy_loss_without_entropy          94.8021
trainer/entropy_penalty                      -0.260861
trainer/entropy_percentage                   -0.00275164
trainer/Q1Pred Mean                          93.6964
trainer/Q1Pred Std                           34.9034
trainer/Q1Pred Max                          150.019
trainer/Q1Pred Min                          -13.5927
trainer/Q2Pred Mean                          94.0787
trainer/Q2Pred Std                           34.7599
trainer/Q2Pred Max                          149.743
trainer/Q2Pred Min                          -12.8393
trainer/QTargetWithReg Mean                  93.8625
trainer/QTargetWithReg Std                   34.724
trainer/QTargetWithReg Max                  150.077
trainer/QTargetWithReg Min                  -11.3211
trainer/PolicyLossWithoutReg Mean            94.8021
trainer/PolicyLossWithoutReg Std             34.0813
trainer/PolicyLossWithoutReg Max            149.111
trainer/PolicyLossWithoutReg Min             -7.58109
trainer/gradient_norm                       178.16
trainer/gradient_penalty                     -0.890798
trainer/gradient_percentage                  -0.0093964
exploration/num steps total              147000
exploration/num paths total                1186
exploration/path length this epoch Mean     325
exploration/path length this epoch Std      222.972
exploration/path length this epoch Max      635
exploration/path length this epoch Min      120
exploration/Rewards Mean                      3.05879
exploration/Rewards Std                       1.28972
exploration/Rewards Max                       7.87781
exploration/Rewards Min                      -0.725595
exploration/Returns Mean                    994.107
exploration/Returns Std                     621.703
exploration/Returns Max                    1838.33
exploration/Returns Min                     359.311
exploration/Num Paths                         3
exploration/Average Returns                 994.107
evaluation_0/num steps total                  1.1209e+06
evaluation_0/num paths total               7116
evaluation_0/path length Mean               370.81
evaluation_0/path length Std                150.836
evaluation_0/path length Max                779
evaluation_0/path length Min                235
evaluation_0/Rewards Mean                     3.34687
evaluation_0/Rewards Std                      1.3874
evaluation_0/Rewards Max                      7.11335
evaluation_0/Rewards Min                     -0.624674
evaluation_0/Returns Mean                  1241.05
evaluation_0/Returns Std                    523.607
evaluation_0/Returns Max                   2388.3
evaluation_0/Returns Min                    742.319
evaluation_0/Num Paths                       21
evaluation_0/Average Returns               1241.05
time/epoch (s)                                0
time/total (s)                             2961.66
Epoch                                       142
---------------------------------------  ---------------
2022-11-16 11:35:24.718028 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 143 finished
---------------------------------------  ----------------
epoch                                       143
total_step                               148000
replay_pool/size                         148000
trainer/alpha                                 0.0425007
trainer/alpha_loss                           -0.0132193
trainer/entropy                              -5.99581
trainer/qf_loss                               6.44668
trainer/state_noise                           0.005
trainer/policy_loss                         -91.9335
trainer/policy_loss_without_entropy          93.045
trainer/entropy_penalty                      -0.254827
trainer/entropy_percentage                   -0.00273874
trainer/Q1Pred Mean                          92.8303
trainer/Q1Pred Std                           33.938
trainer/Q1Pred Max                          157.702
trainer/Q1Pred Min                           -6.74067
trainer/Q2Pred Mean                          92.2087
trainer/Q2Pred Std                           34.0558
trainer/Q2Pred Max                          151.497
trainer/Q2Pred Min                          -11.0783
trainer/QTargetWithReg Mean                  92.4818
trainer/QTargetWithReg Std                   34.1976
trainer/QTargetWithReg Max                  151.935
trainer/QTargetWithReg Min                   -8.15595
trainer/PolicyLossWithoutReg Mean            93.045
trainer/PolicyLossWithoutReg Std             33.4247
trainer/PolicyLossWithoutReg Max            151.639
trainer/PolicyLossWithoutReg Min             -5.03969
trainer/gradient_norm                       171.34
trainer/gradient_penalty                     -0.856701
trainer/gradient_percentage                  -0.00920738
exploration/num steps total              148000
exploration/num paths total                1188
exploration/path length this epoch Mean     252.5
exploration/path length this epoch Std      164.5
exploration/path length this epoch Max      417
exploration/path length this epoch Min       88
exploration/Rewards Mean                      3.47014
exploration/Rewards Std                       1.48784
exploration/Rewards Max                       7.41916
exploration/Rewards Min                      -0.568594
exploration/Returns Mean                    876.211
exploration/Returns Std                     636.759
exploration/Returns Max                    1512.97
exploration/Returns Min                     239.453
exploration/Num Paths                         2
exploration/Average Returns                 876.211
evaluation_0/num steps total                  1.12876e+06
evaluation_0/num paths total               7169
evaluation_0/path length Mean               148.377
evaluation_0/path length Std                 40.9483
evaluation_0/path length Max                405
evaluation_0/path length Min                114
evaluation_0/Rewards Mean                     3.21801
evaluation_0/Rewards Std                      1.42494
evaluation_0/Rewards Max                      7.62412
evaluation_0/Rewards Min                     -0.592405
evaluation_0/Returns Mean                   477.479
evaluation_0/Returns Std                    177.188
evaluation_0/Returns Max                   1610.43
evaluation_0/Returns Min                    350.047
evaluation_0/Num Paths                       53
evaluation_0/Average Returns                477.479
time/epoch (s)                                0
time/total (s)                             2978.66
Epoch                                       143
---------------------------------------  ----------------
2022-11-16 11:35:42.287197 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 144 finished
---------------------------------------  ----------------
epoch                                       144
total_step                               149000
replay_pool/size                         149000
trainer/alpha                                 0.0425877
trainer/alpha_loss                            1.57657
trainer/entropy                              -6.49948
trainer/qf_loss                               5.17463
trainer/state_noise                           0.005
trainer/policy_loss                         -93.379
trainer/policy_loss_without_entropy          94.5878
trainer/entropy_penalty                      -0.276798
trainer/entropy_percentage                   -0.00292636
trainer/Q1Pred Mean                          93.7151
trainer/Q1Pred Std                           33.476
trainer/Q1Pred Max                          147.129
trainer/Q1Pred Min                           -2.87502
trainer/Q2Pred Mean                          93.5789
trainer/Q2Pred Std                           33.7305
trainer/Q2Pred Max                          148.825
trainer/Q2Pred Min                           -7.47705
trainer/QTargetWithReg Mean                  93.5627
trainer/QTargetWithReg Std                   33.6648
trainer/QTargetWithReg Max                  148.446
trainer/QTargetWithReg Min                   -7.34672
trainer/PolicyLossWithoutReg Mean            94.5878
trainer/PolicyLossWithoutReg Std             32.6963
trainer/PolicyLossWithoutReg Max            147.647
trainer/PolicyLossWithoutReg Min             -4.62038
trainer/gradient_norm                       186.4
trainer/gradient_penalty                     -0.932001
trainer/gradient_percentage                  -0.00985328
exploration/num steps total              149000
exploration/num paths total                1192
exploration/path length this epoch Mean     222.75
exploration/path length this epoch Std      176.752
exploration/path length this epoch Max      528
exploration/path length this epoch Min      109
exploration/Rewards Mean                      2.91026
exploration/Rewards Std                       1.22244
exploration/Rewards Max                       6.5728
exploration/Rewards Min                      -0.780023
exploration/Returns Mean                    648.26
exploration/Returns Std                     509.515
exploration/Returns Max                    1527.71
exploration/Returns Min                     307.448
exploration/Num Paths                         4
exploration/Average Returns                 648.26
evaluation_0/num steps total                  1.13665e+06
evaluation_0/num paths total               7190
evaluation_0/path length Mean               375.571
evaluation_0/path length Std                197.587
evaluation_0/path length Max                915
evaluation_0/path length Min                148
evaluation_0/Rewards Mean                     3.40203
evaluation_0/Rewards Std                      1.37768
evaluation_0/Rewards Max                      8.501
evaluation_0/Rewards Min                     -0.638881
evaluation_0/Returns Mean                  1277.71
evaluation_0/Returns Std                    679.216
evaluation_0/Returns Max                   3390.03
evaluation_0/Returns Min                    477.65
evaluation_0/Num Paths                       21
evaluation_0/Average Returns               1277.71
time/epoch (s)                                0
time/total (s)                             2996.23
Epoch                                       144
---------------------------------------  ----------------
2022-11-16 11:35:59.281014 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 145 finished
---------------------------------------  ---------------
epoch                                       145
total_step                               150000
replay_pool/size                         150000
trainer/alpha                                 0.0443423
trainer/alpha_loss                           -0.869155
trainer/entropy                              -5.72104
trainer/qf_loss                               6.75793
trainer/state_noise                           0.005
trainer/policy_loss                         -97.4888
trainer/policy_loss_without_entropy          98.6708
trainer/entropy_penalty                      -0.253684
trainer/entropy_percentage                   -0.00257102
trainer/Q1Pred Mean                          98.1393
trainer/Q1Pred Std                           32.0744
trainer/Q1Pred Max                          147.94
trainer/Q1Pred Min                           10.7866
trainer/Q2Pred Mean                          98.0324
trainer/Q2Pred Std                           31.8454
trainer/Q2Pred Max                          149.399
trainer/Q2Pred Min                           10.9765
trainer/QTargetWithReg Mean                  98.4541
trainer/QTargetWithReg Std                   32.0322
trainer/QTargetWithReg Max                  149.424
trainer/QTargetWithReg Min                   11.669
trainer/PolicyLossWithoutReg Mean            98.6708
trainer/PolicyLossWithoutReg Std             31.8412
trainer/PolicyLossWithoutReg Max            147.609
trainer/PolicyLossWithoutReg Min             10.6375
trainer/gradient_norm                       185.679
trainer/gradient_penalty                     -0.928396
trainer/gradient_percentage                  -0.00940902
exploration/num steps total              150000
exploration/num paths total                1195
exploration/path length this epoch Mean     265.333
exploration/path length this epoch Std      156.726
exploration/path length this epoch Max      486
exploration/path length this epoch Min      137
exploration/Rewards Mean                      3.20791
exploration/Rewards Std                       1.36579
exploration/Rewards Max                       6.60553
exploration/Rewards Min                      -0.662301
exploration/Returns Mean                    851.166
exploration/Returns Std                     537.1
exploration/Returns Max                    1603.87
exploration/Returns Min                     386.534
exploration/Num Paths                         3
exploration/Average Returns                 851.166
evaluation_0/num steps total                  1.1441e+06
evaluation_0/num paths total               7204
evaluation_0/path length Mean               532.286
evaluation_0/path length Std                197.492
evaluation_0/path length Max               1000
evaluation_0/path length Min                325
evaluation_0/Rewards Mean                     3.29052
evaluation_0/Rewards Std                      1.24997
evaluation_0/Rewards Max                      7.94558
evaluation_0/Rewards Min                     -0.776628
evaluation_0/Returns Mean                  1751.49
evaluation_0/Returns Std                    691.002
evaluation_0/Returns Max                   3519.57
evaluation_0/Returns Min                    977.638
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               1751.49
time/epoch (s)                                0
time/total (s)                             3013.22
Epoch                                       145
---------------------------------------  ---------------
2022-11-16 11:36:17.005891 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 146 finished
---------------------------------------  ----------------
epoch                                       146
total_step                               151000
replay_pool/size                         151000
trainer/alpha                                 0.0442178
trainer/alpha_loss                           -0.00667822
trainer/entropy                              -5.99786
trainer/qf_loss                               6.99939
trainer/state_noise                           0.005
trainer/policy_loss                         -92.4052
trainer/policy_loss_without_entropy          93.6014
trainer/entropy_penalty                      -0.265212
trainer/entropy_percentage                   -0.00283342
trainer/Q1Pred Mean                          92.2346
trainer/Q1Pred Std                           34.3936
trainer/Q1Pred Max                          147.748
trainer/Q1Pred Min                           -0.726766
trainer/Q2Pred Mean                          92.2342
trainer/Q2Pred Std                           34.345
trainer/Q2Pred Max                          147.302
trainer/Q2Pred Min                           -7.89642
trainer/QTargetWithReg Mean                  91.7552
trainer/QTargetWithReg Std                   34.8733
trainer/QTargetWithReg Max                  147.713
trainer/QTargetWithReg Min                   -3.22246
trainer/PolicyLossWithoutReg Mean            93.6014
trainer/PolicyLossWithoutReg Std             33.1989
trainer/PolicyLossWithoutReg Max            147.888
trainer/PolicyLossWithoutReg Min             -2.4781
trainer/gradient_norm                       186.206
trainer/gradient_penalty                     -0.931029
trainer/gradient_percentage                  -0.00994675
exploration/num steps total              151000
exploration/num paths total                1196
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.82508
exploration/Rewards Std                       0.911729
exploration/Rewards Max                       5.97584
exploration/Rewards Min                      -0.672049
exploration/Returns Mean                   2825.08
exploration/Returns Std                       0
exploration/Returns Max                    2825.08
exploration/Returns Min                    2825.08
exploration/Num Paths                         1
exploration/Average Returns                2825.08
evaluation_0/num steps total                  1.15152e+06
evaluation_0/num paths total               7215
evaluation_0/path length Mean               674.909
evaluation_0/path length Std                268.353
evaluation_0/path length Max               1000
evaluation_0/path length Min                290
evaluation_0/Rewards Mean                     3.07127
evaluation_0/Rewards Std                      1.15457
evaluation_0/Rewards Max                      8.1979
evaluation_0/Rewards Min                     -0.864716
evaluation_0/Returns Mean                  2072.83
evaluation_0/Returns Std                    699.533
evaluation_0/Returns Max                   3167.99
evaluation_0/Returns Min                    978.008
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2072.83
time/epoch (s)                                0
time/total (s)                             3030.95
Epoch                                       146
---------------------------------------  ----------------
2022-11-16 11:36:33.265217 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 147 finished
---------------------------------------  ----------------
epoch                                       147
total_step                               152000
replay_pool/size                         152000
trainer/alpha                                 0.0434431
trainer/alpha_loss                           -0.171446
trainer/entropy                              -5.94534
trainer/qf_loss                               5.69841
trainer/state_noise                           0.005
trainer/policy_loss                         -94.8876
trainer/policy_loss_without_entropy          96.067
trainer/entropy_penalty                      -0.258284
trainer/entropy_percentage                   -0.00268858
trainer/Q1Pred Mean                          94.9361
trainer/Q1Pred Std                           33.4189
trainer/Q1Pred Max                          146.854
trainer/Q1Pred Min                          -12.1502
trainer/Q2Pred Mean                          94.8857
trainer/Q2Pred Std                           33.3612
trainer/Q2Pred Max                          146.93
trainer/Q2Pred Min                          -11.92
trainer/QTargetWithReg Mean                  95.192
trainer/QTargetWithReg Std                   33.5066
trainer/QTargetWithReg Max                  146.131
trainer/QTargetWithReg Min                  -12.2677
trainer/PolicyLossWithoutReg Mean            96.067
trainer/PolicyLossWithoutReg Std             32.2785
trainer/PolicyLossWithoutReg Max            147.057
trainer/PolicyLossWithoutReg Min             -9.84646
trainer/gradient_norm                       184.234
trainer/gradient_penalty                     -0.921171
trainer/gradient_percentage                  -0.00958884
exploration/num steps total              152000
exploration/num paths total                1197
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      1.80635
exploration/Rewards Std                       1.21067
exploration/Rewards Max                       6.63306
exploration/Rewards Min                      -0.808918
exploration/Returns Mean                   1806.35
exploration/Returns Std                       0
exploration/Returns Max                    1806.35
exploration/Returns Min                    1806.35
exploration/Num Paths                         1
exploration/Average Returns                1806.35
evaluation_0/num steps total                  1.15951e+06
evaluation_0/num paths total               7295
evaluation_0/path length Mean                99.8625
evaluation_0/path length Std                 11.2791
evaluation_0/path length Max                130
evaluation_0/path length Min                 88
evaluation_0/Rewards Mean                     2.71635
evaluation_0/Rewards Std                      1.496
evaluation_0/Rewards Max                      6.55233
evaluation_0/Rewards Min                     -0.45027
evaluation_0/Returns Mean                   271.262
evaluation_0/Returns Std                     23.4647
evaluation_0/Returns Max                    349.24
evaluation_0/Returns Min                    245.006
evaluation_0/Num Paths                       80
evaluation_0/Average Returns                271.262
time/epoch (s)                                0
time/total (s)                             3047.21
Epoch                                       147
---------------------------------------  ----------------
2022-11-16 11:36:51.120719 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 148 finished
---------------------------------------  ----------------
epoch                                       148
total_step                               153000
replay_pool/size                         153000
trainer/alpha                                 0.0423158
trainer/alpha_loss                            0.290773
trainer/entropy                              -6.09194
trainer/qf_loss                               5.53655
trainer/state_noise                           0.005
trainer/policy_loss                         -94.5742
trainer/policy_loss_without_entropy          95.7176
trainer/entropy_penalty                      -0.257785
trainer/entropy_percentage                   -0.00269319
trainer/Q1Pred Mean                          94.6679
trainer/Q1Pred Std                           33.8264
trainer/Q1Pred Max                          155.313
trainer/Q1Pred Min                          -13.7847
trainer/Q2Pred Mean                          94.7882
trainer/Q2Pred Std                           33.4427
trainer/Q2Pred Max                          154.672
trainer/Q2Pred Min                           -5.78596
trainer/QTargetWithReg Mean                  94.4421
trainer/QTargetWithReg Std                   33.9405
trainer/QTargetWithReg Max                  155.495
trainer/QTargetWithReg Min                   -7.06033
trainer/PolicyLossWithoutReg Mean            95.7176
trainer/PolicyLossWithoutReg Std             32.8741
trainer/PolicyLossWithoutReg Max            155.276
trainer/PolicyLossWithoutReg Min             -0.01751
trainer/gradient_norm                       177.136
trainer/gradient_penalty                     -0.885678
trainer/gradient_percentage                  -0.00925303
exploration/num steps total              153000
exploration/num paths total                1202
exploration/path length this epoch Mean     193.4
exploration/path length this epoch Std      167.828
exploration/path length this epoch Max      528
exploration/path length this epoch Min       91
exploration/Rewards Mean                      2.97912
exploration/Rewards Std                       1.44835
exploration/Rewards Max                       6.56916
exploration/Rewards Min                      -0.78229
exploration/Returns Mean                    576.162
exploration/Returns Std                     570.813
exploration/Returns Max                    1712.03
exploration/Returns Min                     225.27
exploration/Num Paths                         5
exploration/Average Returns                 576.162
evaluation_0/num steps total                  1.16749e+06
evaluation_0/num paths total               7306
evaluation_0/path length Mean               725.545
evaluation_0/path length Std                343.225
evaluation_0/path length Max               1000
evaluation_0/path length Min                156
evaluation_0/Rewards Mean                     1.79112
evaluation_0/Rewards Std                      1.1372
evaluation_0/Rewards Max                      7.55375
evaluation_0/Rewards Min                     -0.713599
evaluation_0/Returns Mean                  1299.54
evaluation_0/Returns Std                    567.587
evaluation_0/Returns Max                   2568.85
evaluation_0/Returns Min                    333.041
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               1299.54
time/epoch (s)                                0
time/total (s)                             3065.06
Epoch                                       148
---------------------------------------  ----------------
2022-11-16 11:37:08.801849 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 149 finished
---------------------------------------  ----------------
epoch                                       149
total_step                               154000
replay_pool/size                         154000
trainer/alpha                                 0.044454
trainer/alpha_loss                            0.769306
trainer/entropy                              -6.24711
trainer/qf_loss                               5.93968
trainer/state_noise                           0.005
trainer/policy_loss                         -94.056
trainer/policy_loss_without_entropy          95.2418
trainer/entropy_penalty                      -0.277709
trainer/entropy_percentage                   -0.00291583
trainer/Q1Pred Mean                          94.0821
trainer/Q1Pred Std                           35.2798
trainer/Q1Pred Max                          147.158
trainer/Q1Pred Min                            3.03976
trainer/Q2Pred Mean                          94.0878
trainer/Q2Pred Std                           35.0686
trainer/Q2Pred Max                          147.336
trainer/Q2Pred Min                           -3.79117
trainer/QTargetWithReg Mean                  94.1648
trainer/QTargetWithReg Std                   35.3702
trainer/QTargetWithReg Max                  148.382
trainer/QTargetWithReg Min                   -0.291876
trainer/PolicyLossWithoutReg Mean            95.2418
trainer/PolicyLossWithoutReg Std             34.0068
trainer/PolicyLossWithoutReg Max            146.973
trainer/PolicyLossWithoutReg Min             -1.93541
trainer/gradient_norm                       181.603
trainer/gradient_penalty                     -0.908017
trainer/gradient_percentage                  -0.0095338
exploration/num steps total              154000
exploration/num paths total                1204
exploration/path length this epoch Mean     225
exploration/path length this epoch Std        3
exploration/path length this epoch Max      228
exploration/path length this epoch Min      222
exploration/Rewards Mean                      3.16696
exploration/Rewards Std                       1.41436
exploration/Rewards Max                       6.32981
exploration/Rewards Min                      -0.628384
exploration/Returns Mean                    712.565
exploration/Returns Std                       2.5568
exploration/Returns Max                     715.122
exploration/Returns Min                     710.008
exploration/Num Paths                         2
exploration/Average Returns                 712.565
evaluation_0/num steps total                  1.17545e+06
evaluation_0/num paths total               7323
evaluation_0/path length Mean               467.941
evaluation_0/path length Std                304.486
evaluation_0/path length Max               1000
evaluation_0/path length Min                 93
evaluation_0/Rewards Mean                     3.11319
evaluation_0/Rewards Std                      1.22549
evaluation_0/Rewards Max                      7.97949
evaluation_0/Rewards Min                     -0.638351
evaluation_0/Returns Mean                  1456.79
evaluation_0/Returns Std                    954.093
evaluation_0/Returns Max                   2988.97
evaluation_0/Returns Min                    227.557
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1456.79
time/epoch (s)                                0
time/total (s)                             3082.74
Epoch                                       149
---------------------------------------  ----------------
2022-11-16 11:37:28.252484 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 150 finished
---------------------------------------  ---------------
epoch                                       150
total_step                               155000
replay_pool/size                         155000
trainer/alpha                                 0.0435452
trainer/alpha_loss                            1.41336
trainer/entropy                              -6.45098
trainer/qf_loss                               8.18592
trainer/state_noise                           0.005
trainer/policy_loss                         -93.7176
trainer/policy_loss_without_entropy          94.9578
trainer/entropy_penalty                      -0.280909
trainer/entropy_percentage                   -0.00295825
trainer/Q1Pred Mean                          94.1463
trainer/Q1Pred Std                           38.354
trainer/Q1Pred Max                          157.586
trainer/Q1Pred Min                          -12.0226
trainer/Q2Pred Mean                          93.6833
trainer/Q2Pred Std                           38.3926
trainer/Q2Pred Max                          157.937
trainer/Q2Pred Min                          -13.2802
trainer/QTargetWithReg Mean                  93.8518
trainer/QTargetWithReg Std                   38.374
trainer/QTargetWithReg Max                  159.572
trainer/QTargetWithReg Min                   -9.14032
trainer/PolicyLossWithoutReg Mean            94.9578
trainer/PolicyLossWithoutReg Std             36.8098
trainer/PolicyLossWithoutReg Max            157.767
trainer/PolicyLossWithoutReg Min            -11.5724
trainer/gradient_norm                       191.852
trainer/gradient_penalty                     -0.959259
trainer/gradient_percentage                  -0.010102
exploration/num steps total              155000
exploration/num paths total                1205
exploration/path length this epoch Mean     940
exploration/path length this epoch Std        0
exploration/path length this epoch Max      940
exploration/path length this epoch Min      940
exploration/Rewards Mean                      3.02376
exploration/Rewards Std                       1.1025
exploration/Rewards Max                       7.47194
exploration/Rewards Min                      -0.495647
exploration/Returns Mean                   2842.34
exploration/Returns Std                       0
exploration/Returns Max                    2842.34
exploration/Returns Min                    2842.34
exploration/Num Paths                         1
exploration/Average Returns                2842.34
evaluation_0/num steps total                  1.1834e+06
evaluation_0/num paths total               7365
evaluation_0/path length Mean               189.429
evaluation_0/path length Std                120.301
evaluation_0/path length Max                583
evaluation_0/path length Min                102
evaluation_0/Rewards Mean                     3.10276
evaluation_0/Rewards Std                      1.34886
evaluation_0/Rewards Max                      7.72055
evaluation_0/Rewards Min                     -0.67728
evaluation_0/Returns Mean                   587.752
evaluation_0/Returns Std                    405.824
evaluation_0/Returns Max                   1856.66
evaluation_0/Returns Min                    273.406
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                587.752
time/epoch (s)                                0
time/total (s)                             3102.19
Epoch                                       150
---------------------------------------  ---------------
2022-11-16 11:37:45.112593 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 151 finished
---------------------------------------  ----------------
epoch                                       151
total_step                               156000
replay_pool/size                         156000
trainer/alpha                                 0.044631
trainer/alpha_loss                           -1.82107
trainer/entropy                              -5.41429
trainer/qf_loss                               6.2294
trainer/state_noise                           0.005
trainer/policy_loss                         -97.3896
trainer/policy_loss_without_entropy          98.5326
trainer/entropy_penalty                      -0.241645
trainer/entropy_percentage                   -0.00245244
trainer/Q1Pred Mean                          97.7323
trainer/Q1Pred Std                           32.9928
trainer/Q1Pred Max                          149.981
trainer/Q1Pred Min                            3.87286
trainer/Q2Pred Mean                          98.0402
trainer/Q2Pred Std                           32.8983
trainer/Q2Pred Max                          149.144
trainer/Q2Pred Min                           -1.36952
trainer/QTargetWithReg Mean                  97.6738
trainer/QTargetWithReg Std                   33.0656
trainer/QTargetWithReg Max                  151.843
trainer/QTargetWithReg Min                    3.48498
trainer/PolicyLossWithoutReg Mean            98.5326
trainer/PolicyLossWithoutReg Std             32.9833
trainer/PolicyLossWithoutReg Max            149.976
trainer/PolicyLossWithoutReg Min              0.828836
trainer/gradient_norm                       180.272
trainer/gradient_penalty                     -0.901359
trainer/gradient_percentage                  -0.00914782
exploration/num steps total              156000
exploration/num paths total                1209
exploration/path length this epoch Mean     233.25
exploration/path length this epoch Std      215.754
exploration/path length this epoch Max      606
exploration/path length this epoch Min       95
exploration/Rewards Mean                      3.11258
exploration/Rewards Std                       1.30812
exploration/Rewards Max                       7.03137
exploration/Rewards Min                      -0.70088
exploration/Returns Mean                    726.01
exploration/Returns Std                     767.117
exploration/Returns Max                    2050
exploration/Returns Min                     222.353
exploration/Num Paths                         4
exploration/Average Returns                 726.01
evaluation_0/num steps total                  1.19132e+06
evaluation_0/num paths total               7436
evaluation_0/path length Mean               111.549
evaluation_0/path length Std                 76.1151
evaluation_0/path length Max                738
evaluation_0/path length Min                 90
evaluation_0/Rewards Mean                     2.55632
evaluation_0/Rewards Std                      1.52016
evaluation_0/Rewards Max                      7.32871
evaluation_0/Rewards Min                     -0.61833
evaluation_0/Returns Mean                   285.155
evaluation_0/Returns Std                    241.211
evaluation_0/Returns Max                   2281.05
evaluation_0/Returns Min                    223.665
evaluation_0/Num Paths                       71
evaluation_0/Average Returns                285.155
time/epoch (s)                                0
time/total (s)                             3119.05
Epoch                                       151
---------------------------------------  ----------------
2022-11-16 11:38:02.839144 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 152 finished
---------------------------------------  ----------------
epoch                                       152
total_step                               157000
replay_pool/size                         157000
trainer/alpha                                 0.0446283
trainer/alpha_loss                            2.28305
trainer/entropy                              -6.73422
trainer/qf_loss                               6.31474
trainer/state_noise                           0.005
trainer/policy_loss                         -95.1794
trainer/policy_loss_without_entropy          96.3563
trainer/entropy_penalty                      -0.300537
trainer/entropy_percentage                   -0.00311902
trainer/Q1Pred Mean                          95.8833
trainer/Q1Pred Std                           35.579
trainer/Q1Pred Max                          153.259
trainer/Q1Pred Min                            2.24894
trainer/Q2Pred Mean                          95.6625
trainer/Q2Pred Std                           35.3259
trainer/Q2Pred Max                          153.172
trainer/Q2Pred Min                            5.9209
trainer/QTargetWithReg Mean                  94.761
trainer/QTargetWithReg Std                   35.8601
trainer/QTargetWithReg Max                  151.493
trainer/QTargetWithReg Min                   -2.46548
trainer/PolicyLossWithoutReg Mean            96.3563
trainer/PolicyLossWithoutReg Std             34.8122
trainer/PolicyLossWithoutReg Max            151.714
trainer/PolicyLossWithoutReg Min              4.62179
trainer/gradient_norm                       175.262
trainer/gradient_penalty                     -0.87631
trainer/gradient_percentage                  -0.00909448
exploration/num steps total              157000
exploration/num paths total                1216
exploration/path length this epoch Mean     135.143
exploration/path length this epoch Std       67.6449
exploration/path length this epoch Max      291
exploration/path length this epoch Min       79
exploration/Rewards Mean                      2.81157
exploration/Rewards Std                       1.51087
exploration/Rewards Max                       6.92999
exploration/Rewards Min                      -0.918446
exploration/Returns Mean                    379.963
exploration/Returns Std                     246.081
exploration/Returns Max                     962.614
exploration/Returns Min                     203.405
exploration/Num Paths                         7
exploration/Average Returns                 379.963
evaluation_0/num steps total                  1.19909e+06
evaluation_0/num paths total               7451
evaluation_0/path length Mean               517.667
evaluation_0/path length Std                280.688
evaluation_0/path length Max               1000
evaluation_0/path length Min                109
evaluation_0/Rewards Mean                     3.00795
evaluation_0/Rewards Std                      1.21842
evaluation_0/Rewards Max                      7.73005
evaluation_0/Rewards Min                     -0.674406
evaluation_0/Returns Mean                  1557.12
evaluation_0/Returns Std                    886.816
evaluation_0/Returns Max                   3008.96
evaluation_0/Returns Min                    278.243
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1557.12
time/epoch (s)                                0
time/total (s)                             3136.78
Epoch                                       152
---------------------------------------  ----------------
2022-11-16 11:38:21.109445 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 153 finished
---------------------------------------  ----------------
epoch                                       153
total_step                               158000
replay_pool/size                         158000
trainer/alpha                                 0.0447866
trainer/alpha_loss                            0.184768
trainer/entropy                              -6.05949
trainer/qf_loss                               5.53002
trainer/state_noise                           0.005
trainer/policy_loss                         -98.0714
trainer/policy_loss_without_entropy          99.265
trainer/entropy_penalty                      -0.271384
trainer/entropy_percentage                   -0.00273393
trainer/Q1Pred Mean                          98.0183
trainer/Q1Pred Std                           34.5204
trainer/Q1Pred Max                          149.7
trainer/Q1Pred Min                            0.274115
trainer/Q2Pred Mean                          98.451
trainer/Q2Pred Std                           34.5497
trainer/Q2Pred Max                          150.333
trainer/Q2Pred Min                            0.65691
trainer/QTargetWithReg Mean                  98.3324
trainer/QTargetWithReg Std                   34.4292
trainer/QTargetWithReg Max                  149.91
trainer/QTargetWithReg Min                   -0.236059
trainer/PolicyLossWithoutReg Mean            99.2651
trainer/PolicyLossWithoutReg Std             33.6388
trainer/PolicyLossWithoutReg Max            149.828
trainer/PolicyLossWithoutReg Min              6.95539
trainer/gradient_norm                       184.457
trainer/gradient_penalty                     -0.922285
trainer/gradient_percentage                  -0.00929113
exploration/num steps total              158000
exploration/num paths total                1219
exploration/path length this epoch Mean     320.667
exploration/path length this epoch Std      147.947
exploration/path length this epoch Max      464
exploration/path length this epoch Min      117
exploration/Rewards Mean                      3.30269
exploration/Rewards Std                       1.49788
exploration/Rewards Max                       6.92482
exploration/Rewards Min                      -0.938916
exploration/Returns Mean                   1059.06
exploration/Returns Std                     547.556
exploration/Returns Max                    1646.14
exploration/Returns Min                     328.223
exploration/Num Paths                         3
exploration/Average Returns                1059.06
evaluation_0/num steps total                  1.20707e+06
evaluation_0/num paths total               7469
evaluation_0/path length Mean               443.278
evaluation_0/path length Std                261.91
evaluation_0/path length Max               1000
evaluation_0/path length Min                187
evaluation_0/Rewards Mean                     3.3118
evaluation_0/Rewards Std                      1.26979
evaluation_0/Rewards Max                      7.5676
evaluation_0/Rewards Min                     -0.637011
evaluation_0/Returns Mean                  1468.05
evaluation_0/Returns Std                    754.544
evaluation_0/Returns Max                   2898.84
evaluation_0/Returns Min                    663.445
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1468.05
time/epoch (s)                                0
time/total (s)                             3155.05
Epoch                                       153
---------------------------------------  ----------------
2022-11-16 11:38:37.605308 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 154 finished
---------------------------------------  ----------------
epoch                                       154
total_step                               159000
replay_pool/size                         159000
trainer/alpha                                 0.0460547
trainer/alpha_loss                           -0.599363
trainer/entropy                              -5.80528
trainer/qf_loss                               5.40475
trainer/state_noise                           0.005
trainer/policy_loss                         -96.887
trainer/policy_loss_without_entropy          98.038
trainer/entropy_penalty                      -0.26736
trainer/entropy_percentage                   -0.00272711
trainer/Q1Pred Mean                          96.8658
trainer/Q1Pred Std                           35.0843
trainer/Q1Pred Max                          163.956
trainer/Q1Pred Min                           -2.34356
trainer/Q2Pred Mean                          96.9679
trainer/Q2Pred Std                           35.0452
trainer/Q2Pred Max                          165.67
trainer/Q2Pred Min                           -3.86202
trainer/QTargetWithReg Mean                  96.9954
trainer/QTargetWithReg Std                   34.8521
trainer/QTargetWithReg Max                  162.343
trainer/QTargetWithReg Min                   -1.16841
trainer/PolicyLossWithoutReg Mean            98.038
trainer/PolicyLossWithoutReg Std             34.8372
trainer/PolicyLossWithoutReg Max            163.823
trainer/PolicyLossWithoutReg Min              0.152581
trainer/gradient_norm                       176.717
trainer/gradient_penalty                     -0.883586
trainer/gradient_percentage                  -0.00901269
exploration/num steps total              159000
exploration/num paths total                1223
exploration/path length this epoch Mean     226.25
exploration/path length this epoch Std      209.684
exploration/path length this epoch Max      589
exploration/path length this epoch Min       96
exploration/Rewards Mean                      2.90515
exploration/Rewards Std                       1.27494
exploration/Rewards Max                       6.18898
exploration/Rewards Min                      -0.780402
exploration/Returns Mean                    657.289
exploration/Returns Std                     651.082
exploration/Returns Max                    1783.85
exploration/Returns Min                     239.22
exploration/Num Paths                         4
exploration/Average Returns                 657.289
evaluation_0/num steps total                  1.21504e+06
evaluation_0/num paths total               7547
evaluation_0/path length Mean               102.218
evaluation_0/path length Std                  1.75154
evaluation_0/path length Max                112
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     2.68661
evaluation_0/Rewards Std                      1.48694
evaluation_0/Rewards Max                      6.47278
evaluation_0/Rewards Min                     -1.77854
evaluation_0/Returns Mean                   274.619
evaluation_0/Returns Std                     10.1886
evaluation_0/Returns Max                    303.028
evaluation_0/Returns Min                    246.493
evaluation_0/Num Paths                       78
evaluation_0/Average Returns                274.619
time/epoch (s)                                0
time/total (s)                             3171.55
Epoch                                       154
---------------------------------------  ----------------
2022-11-16 11:38:56.489321 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 155 finished
---------------------------------------  ----------------
epoch                                       155
total_step                               160000
replay_pool/size                         160000
trainer/alpha                                 0.0473634
trainer/alpha_loss                           -1.41859
trainer/entropy                              -5.53487
trainer/qf_loss                               7.63256
trainer/state_noise                           0.005
trainer/policy_loss                         -93.6861
trainer/policy_loss_without_entropy          94.8423
trainer/entropy_penalty                      -0.26215
trainer/entropy_percentage                   -0.00276406
trainer/Q1Pred Mean                          94.0852
trainer/Q1Pred Std                           39.1945
trainer/Q1Pred Max                          155.439
trainer/Q1Pred Min                          -16.5626
trainer/Q2Pred Mean                          94.2687
trainer/Q2Pred Std                           39.1472
trainer/Q2Pred Max                          154.261
trainer/Q2Pred Min                          -19.5341
trainer/QTargetWithReg Mean                  94.0353
trainer/QTargetWithReg Std                   39.0647
trainer/QTargetWithReg Max                  156.783
trainer/QTargetWithReg Min                  -20.9426
trainer/PolicyLossWithoutReg Mean            94.8423
trainer/PolicyLossWithoutReg Std             38.8346
trainer/PolicyLossWithoutReg Max            154.489
trainer/PolicyLossWithoutReg Min             -8.34737
trainer/gradient_norm                       178.815
trainer/gradient_penalty                     -0.894077
trainer/gradient_percentage                  -0.00942698
exploration/num steps total              160000
exploration/num paths total                1228
exploration/path length this epoch Mean     173.2
exploration/path length this epoch Std       86.363
exploration/path length this epoch Max      313
exploration/path length this epoch Min       93
exploration/Rewards Mean                      2.77643
exploration/Rewards Std                       1.432
exploration/Rewards Max                       6.20475
exploration/Rewards Min                      -0.945381
exploration/Returns Mean                    480.878
exploration/Returns Std                     293.365
exploration/Returns Max                    1026.21
exploration/Returns Min                     230.356
exploration/Num Paths                         5
exploration/Average Returns                 480.878
evaluation_0/num steps total                  1.22224e+06
evaluation_0/num paths total               7593
evaluation_0/path length Mean               156.5
evaluation_0/path length Std                118.092
evaluation_0/path length Max                759
evaluation_0/path length Min                104
evaluation_0/Rewards Mean                     2.77525
evaluation_0/Rewards Std                      1.55054
evaluation_0/Rewards Max                      7.05122
evaluation_0/Rewards Min                     -0.908503
evaluation_0/Returns Mean                   434.327
evaluation_0/Returns Std                    434.168
evaluation_0/Returns Max                   2600.83
evaluation_0/Returns Min                    217.48
evaluation_0/Num Paths                       46
evaluation_0/Average Returns                434.327
time/epoch (s)                                0
time/total (s)                             3190.43
Epoch                                       155
---------------------------------------  ----------------
2022-11-16 11:39:14.227658 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 156 finished
---------------------------------------  ---------------
epoch                                       156
total_step                               161000
replay_pool/size                         161000
trainer/alpha                                 0.0464565
trainer/alpha_loss                            0.102681
trainer/entropy                              -6.03345
trainer/qf_loss                               6.02835
trainer/state_noise                           0.005
trainer/policy_loss                         -97.493
trainer/policy_loss_without_entropy          98.7232
trainer/entropy_penalty                      -0.280293
trainer/entropy_percentage                   -0.00283918
trainer/Q1Pred Mean                          97.5728
trainer/Q1Pred Std                           33.9047
trainer/Q1Pred Max                          153.869
trainer/Q1Pred Min                            2.37098
trainer/Q2Pred Mean                          98.3425
trainer/Q2Pred Std                           33.7954
trainer/Q2Pred Max                          154.751
trainer/Q2Pred Min                            4.35117
trainer/QTargetWithReg Mean                  97.3664
trainer/QTargetWithReg Std                   33.9378
trainer/QTargetWithReg Max                  153.521
trainer/QTargetWithReg Min                    1.35812
trainer/PolicyLossWithoutReg Mean            98.7232
trainer/PolicyLossWithoutReg Std             33.4043
trainer/PolicyLossWithoutReg Max            154.381
trainer/PolicyLossWithoutReg Min              4.82436
trainer/gradient_norm                       189.988
trainer/gradient_penalty                     -0.949942
trainer/gradient_percentage                  -0.00962228
exploration/num steps total              161000
exploration/num paths total                1235
exploration/path length this epoch Mean     141.571
exploration/path length this epoch Std       47.2376
exploration/path length this epoch Max      244
exploration/path length this epoch Min       99
exploration/Rewards Mean                      2.94083
exploration/Rewards Std                       1.61866
exploration/Rewards Max                       6.75604
exploration/Rewards Min                      -0.888222
exploration/Returns Mean                    416.337
exploration/Returns Std                     205.39
exploration/Returns Max                     883.199
exploration/Returns Min                     275.281
exploration/Num Paths                         7
exploration/Average Returns                 416.337
evaluation_0/num steps total                  1.2302e+06
evaluation_0/num paths total               7645
evaluation_0/path length Mean               153.058
evaluation_0/path length Std                 92.1106
evaluation_0/path length Max                525
evaluation_0/path length Min                 95
evaluation_0/Rewards Mean                     2.88479
evaluation_0/Rewards Std                      1.53336
evaluation_0/Rewards Max                      7.19726
evaluation_0/Rewards Min                     -0.827945
evaluation_0/Returns Mean                   441.54
evaluation_0/Returns Std                    354.21
evaluation_0/Returns Max                   1773.33
evaluation_0/Returns Min                    257.116
evaluation_0/Num Paths                       52
evaluation_0/Average Returns                441.54
time/epoch (s)                                0
time/total (s)                             3208.17
Epoch                                       156
---------------------------------------  ---------------
2022-11-16 11:39:30.654581 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 157 finished
---------------------------------------  ----------------
epoch                                       157
total_step                               162000
replay_pool/size                         162000
trainer/alpha                                 0.0457935
trainer/alpha_loss                            0.395593
trainer/entropy                              -6.12829
trainer/qf_loss                               6.06566
trainer/state_noise                           0.005
trainer/policy_loss                         -94.3705
trainer/policy_loss_without_entropy          95.542
trainer/entropy_penalty                      -0.280636
trainer/entropy_percentage                   -0.0029373
trainer/Q1Pred Mean                          94.5253
trainer/Q1Pred Std                           37.5049
trainer/Q1Pred Max                          150.362
trainer/Q1Pred Min                          -23.8442
trainer/Q2Pred Mean                          94.3984
trainer/Q2Pred Std                           37.619
trainer/Q2Pred Max                          150.07
trainer/Q2Pred Min                          -21.7828
trainer/QTargetWithReg Mean                  94.6779
trainer/QTargetWithReg Std                   37.3599
trainer/QTargetWithReg Max                  151.525
trainer/QTargetWithReg Min                  -16.3918
trainer/PolicyLossWithoutReg Mean            95.542
trainer/PolicyLossWithoutReg Std             36.9467
trainer/PolicyLossWithoutReg Max            150.881
trainer/PolicyLossWithoutReg Min            -18.0481
trainer/gradient_norm                       178.176
trainer/gradient_penalty                     -0.890881
trainer/gradient_percentage                  -0.0093245
exploration/num steps total              162000
exploration/num paths total                1237
exploration/path length this epoch Mean     120.5
exploration/path length this epoch Std        2.5
exploration/path length this epoch Max      123
exploration/path length this epoch Min      118
exploration/Rewards Mean                      2.44167
exploration/Rewards Std                       1.35503
exploration/Rewards Max                       6.12794
exploration/Rewards Min                      -0.948858
exploration/Returns Mean                    294.222
exploration/Returns Std                       4.10675
exploration/Returns Max                     298.328
exploration/Returns Min                     290.115
exploration/Num Paths                         2
exploration/Average Returns                 294.222
evaluation_0/num steps total                  1.23815e+06
evaluation_0/num paths total               7737
evaluation_0/path length Mean                86.4565
evaluation_0/path length Std                 15.1933
evaluation_0/path length Max                126
evaluation_0/path length Min                 75
evaluation_0/Rewards Mean                     2.7962
evaluation_0/Rewards Std                      1.54196
evaluation_0/Rewards Max                      5.83919
evaluation_0/Rewards Min                     -0.88723
evaluation_0/Returns Mean                   241.75
evaluation_0/Returns Std                     41.5036
evaluation_0/Returns Max                    354.827
evaluation_0/Returns Min                    207.6
evaluation_0/Num Paths                       92
evaluation_0/Average Returns                241.75
time/epoch (s)                                0
time/total (s)                             3224.59
Epoch                                       157
---------------------------------------  ----------------
2022-11-16 11:39:47.109391 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 158 finished
---------------------------------------  ----------------
epoch                                       158
total_step                               163000
replay_pool/size                         163000
trainer/alpha                                 0.0468629
trainer/alpha_loss                           -0.381898
trainer/entropy                              -5.87522
trainer/qf_loss                               6.86854
trainer/state_noise                           0.005
trainer/policy_loss                        -102.661
trainer/policy_loss_without_entropy         103.857
trainer/entropy_penalty                      -0.27533
trainer/entropy_percentage                   -0.00265104
trainer/Q1Pred Mean                         102.765
trainer/Q1Pred Std                           33.6927
trainer/Q1Pred Max                          153.596
trainer/Q1Pred Min                            4.11842
trainer/Q2Pred Mean                         102.371
trainer/Q2Pred Std                           33.7208
trainer/Q2Pred Max                          156.373
trainer/Q2Pred Min                           -1.279
trainer/QTargetWithReg Mean                 102.655
trainer/QTargetWithReg Std                   33.6958
trainer/QTargetWithReg Max                  154.538
trainer/QTargetWithReg Min                   -0.517032
trainer/PolicyLossWithoutReg Mean           103.857
trainer/PolicyLossWithoutReg Std             32.5831
trainer/PolicyLossWithoutReg Max            153.112
trainer/PolicyLossWithoutReg Min              3.4717
trainer/gradient_norm                       184.184
trainer/gradient_penalty                     -0.920921
trainer/gradient_percentage                  -0.00886717
exploration/num steps total              163000
exploration/num paths total                1247
exploration/path length this epoch Mean      93
exploration/path length this epoch Std       14.3038
exploration/path length this epoch Max      119
exploration/path length this epoch Min       70
exploration/Rewards Mean                      2.76659
exploration/Rewards Std                       1.5163
exploration/Rewards Max                       5.76604
exploration/Rewards Min                      -0.966464
exploration/Returns Mean                    257.293
exploration/Returns Std                      48.0533
exploration/Returns Max                     344.007
exploration/Returns Min                     192.03
exploration/Num Paths                        10
exploration/Average Returns                 257.293
evaluation_0/num steps total                  1.24611e+06
evaluation_0/num paths total               7826
evaluation_0/path length Mean                89.3933
evaluation_0/path length Std                  2.47513
evaluation_0/path length Max                 95
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     2.87721
evaluation_0/Rewards Std                      1.56377
evaluation_0/Rewards Max                      5.36849
evaluation_0/Rewards Min                     -0.546702
evaluation_0/Returns Mean                   257.204
evaluation_0/Returns Std                      6.28961
evaluation_0/Returns Max                    274.792
evaluation_0/Returns Min                    232.389
evaluation_0/Num Paths                       89
evaluation_0/Average Returns                257.204
time/epoch (s)                                0
time/total (s)                             3241.05
Epoch                                       158
---------------------------------------  ----------------
2022-11-16 11:40:04.136981 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 159 finished
---------------------------------------  ----------------
epoch                                       159
total_step                               164000
replay_pool/size                         164000
trainer/alpha                                 0.0465673
trainer/alpha_loss                            1.20845
trainer/entropy                              -6.39403
trainer/qf_loss                               5.68044
trainer/state_noise                           0.005
trainer/policy_loss                         -96.9565
trainer/policy_loss_without_entropy          98.1825
trainer/entropy_penalty                      -0.297753
trainer/entropy_percentage                   -0.00303264
trainer/Q1Pred Mean                          97.9832
trainer/Q1Pred Std                           37.0433
trainer/Q1Pred Max                          161.638
trainer/Q1Pred Min                            1.40531
trainer/Q2Pred Mean                          97.91
trainer/Q2Pred Std                           36.8482
trainer/Q2Pred Max                          167.276
trainer/Q2Pred Min                           -1.81535
trainer/QTargetWithReg Mean                  97.7756
trainer/QTargetWithReg Std                   37.1693
trainer/QTargetWithReg Max                  163.23
trainer/QTargetWithReg Min                   -4.23487
trainer/PolicyLossWithoutReg Mean            98.1825
trainer/PolicyLossWithoutReg Std             36.7494
trainer/PolicyLossWithoutReg Max            161.123
trainer/PolicyLossWithoutReg Min              2.34678
trainer/gradient_norm                       185.66
trainer/gradient_penalty                     -0.9283
trainer/gradient_percentage                  -0.00945484
exploration/num steps total              164000
exploration/num paths total                1252
exploration/path length this epoch Mean     186.2
exploration/path length this epoch Std      180.806
exploration/path length this epoch Max      547
exploration/path length this epoch Min       80
exploration/Rewards Mean                      3.00168
exploration/Rewards Std                       1.30047
exploration/Rewards Max                       6.68077
exploration/Rewards Min                      -0.95064
exploration/Returns Mean                    558.913
exploration/Returns Std                     576.232
exploration/Returns Max                    1707.85
exploration/Returns Min                     211.198
exploration/Num Paths                         5
exploration/Average Returns                 558.913
evaluation_0/num steps total                  1.25371e+06
evaluation_0/num paths total               7849
evaluation_0/path length Mean               330.522
evaluation_0/path length Std                149.98
evaluation_0/path length Max                765
evaluation_0/path length Min                201
evaluation_0/Rewards Mean                     2.68368
evaluation_0/Rewards Std                      1.25776
evaluation_0/Rewards Max                      7.22658
evaluation_0/Rewards Min                     -0.946816
evaluation_0/Returns Mean                   887.016
evaluation_0/Returns Std                    510.939
evaluation_0/Returns Max                   2589.18
evaluation_0/Returns Min                    440.31
evaluation_0/Num Paths                       23
evaluation_0/Average Returns                887.016
time/epoch (s)                                0
time/total (s)                             3258.08
Epoch                                       159
---------------------------------------  ----------------
2022-11-16 11:40:21.656347 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 160 finished
---------------------------------------  ----------------
epoch                                       160
total_step                               165000
replay_pool/size                         165000
trainer/alpha                                 0.0461038
trainer/alpha_loss                            1.09989
trainer/entropy                              -6.35745
trainer/qf_loss                               7.0215
trainer/state_noise                           0.005
trainer/policy_loss                         -96.3886
trainer/policy_loss_without_entropy          97.6368
trainer/entropy_penalty                      -0.293103
trainer/entropy_percentage                   -0.00300197
trainer/Q1Pred Mean                          96.285
trainer/Q1Pred Std                           36.6148
trainer/Q1Pred Max                          157.16
trainer/Q1Pred Min                           -7.85153
trainer/Q2Pred Mean                          96.4506
trainer/Q2Pred Std                           36.784
trainer/Q2Pred Max                          156.721
trainer/Q2Pred Min                           -5.13301
trainer/QTargetWithReg Mean                  97.253
trainer/QTargetWithReg Std                   36.6937
trainer/QTargetWithReg Max                  159.505
trainer/QTargetWithReg Min                   -0.00121415
trainer/PolicyLossWithoutReg Mean            97.6368
trainer/PolicyLossWithoutReg Std             35.9996
trainer/PolicyLossWithoutReg Max            157.18
trainer/PolicyLossWithoutReg Min             -1.57815
trainer/gradient_norm                       191.028
trainer/gradient_penalty                     -0.955142
trainer/gradient_percentage                  -0.0097826
exploration/num steps total              165000
exploration/num paths total                1260
exploration/path length this epoch Mean     115
exploration/path length this epoch Std       10.7587
exploration/path length this epoch Max      129
exploration/path length this epoch Min       97
exploration/Rewards Mean                      2.75566
exploration/Rewards Std                       1.42187
exploration/Rewards Max                       6.49153
exploration/Rewards Min                      -0.959324
exploration/Returns Mean                    316.901
exploration/Returns Std                      44.8388
exploration/Returns Max                     394.264
exploration/Returns Min                     250.978
exploration/Num Paths                         8
exploration/Average Returns                 316.901
evaluation_0/num steps total                  1.26134e+06
evaluation_0/num paths total               7864
evaluation_0/path length Mean               508.867
evaluation_0/path length Std                231.597
evaluation_0/path length Max               1000
evaluation_0/path length Min                222
evaluation_0/Rewards Mean                     2.75946
evaluation_0/Rewards Std                      1.24996
evaluation_0/Rewards Max                      7.66198
evaluation_0/Rewards Min                     -0.885199
evaluation_0/Returns Mean                  1404.2
evaluation_0/Returns Std                    727.569
evaluation_0/Returns Max                   2720.43
evaluation_0/Returns Min                    513.721
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1404.2
time/epoch (s)                                0
time/total (s)                             3275.6
Epoch                                       160
---------------------------------------  ----------------
2022-11-16 11:40:41.072886 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 161 finished
---------------------------------------  ----------------
epoch                                       161
total_step                               166000
replay_pool/size                         166000
trainer/alpha                                 0.0470831
trainer/alpha_loss                            0.293497
trainer/entropy                              -6.09605
trainer/qf_loss                               6.69459
trainer/state_noise                           0.005
trainer/policy_loss                         -96.5569
trainer/policy_loss_without_entropy          97.8011
trainer/entropy_penalty                      -0.287021
trainer/entropy_percentage                   -0.00293474
trainer/Q1Pred Mean                          96.4283
trainer/Q1Pred Std                           39.9616
trainer/Q1Pred Max                          157.316
trainer/Q1Pred Min                          -35.4157
trainer/Q2Pred Mean                          96.2273
trainer/Q2Pred Std                           40.0984
trainer/Q2Pred Max                          157.199
trainer/Q2Pred Min                          -39.5761
trainer/QTargetWithReg Mean                  96.1661
trainer/QTargetWithReg Std                   40.1547
trainer/QTargetWithReg Max                  156.799
trainer/QTargetWithReg Min                  -36.2755
trainer/PolicyLossWithoutReg Mean            97.8012
trainer/PolicyLossWithoutReg Std             39.1833
trainer/PolicyLossWithoutReg Max            155.077
trainer/PolicyLossWithoutReg Min            -33.2996
trainer/gradient_norm                       191.439
trainer/gradient_penalty                     -0.957196
trainer/gradient_percentage                  -0.00978716
exploration/num steps total              166000
exploration/num paths total                1266
exploration/path length this epoch Mean     162.5
exploration/path length this epoch Std       56.7854
exploration/path length this epoch Max      284
exploration/path length this epoch Min      114
exploration/Rewards Mean                      2.96735
exploration/Rewards Std                       1.36619
exploration/Rewards Max                       6.75023
exploration/Rewards Min                      -0.970936
exploration/Returns Mean                    482.195
exploration/Returns Std                     200.25
exploration/Returns Max                     907.583
exploration/Returns Min                     312.91
exploration/Num Paths                         6
exploration/Average Returns                 482.195
evaluation_0/num steps total                  1.26926e+06
evaluation_0/num paths total               7901
evaluation_0/path length Mean               213.865
evaluation_0/path length Std                234.164
evaluation_0/path length Max               1000
evaluation_0/path length Min                 85
evaluation_0/Rewards Mean                     3.15964
evaluation_0/Rewards Std                      1.34692
evaluation_0/Rewards Max                      7.55224
evaluation_0/Rewards Min                     -0.687483
evaluation_0/Returns Mean                   675.736
evaluation_0/Returns Std                    768.976
evaluation_0/Returns Max                   3172.29
evaluation_0/Returns Min                    241.962
evaluation_0/Num Paths                       37
evaluation_0/Average Returns                675.736
time/epoch (s)                                0
time/total (s)                             3295.01
Epoch                                       161
---------------------------------------  ----------------
2022-11-16 11:40:58.970149 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 162 finished
---------------------------------------  ----------------
epoch                                       162
total_step                               167000
replay_pool/size                         167000
trainer/alpha                                 0.0471459
trainer/alpha_loss                           -0.848583
trainer/entropy                              -5.72219
trainer/qf_loss                               7.04701
trainer/state_noise                           0.005
trainer/policy_loss                         -98.2085
trainer/policy_loss_without_entropy          99.4123
trainer/entropy_penalty                      -0.269778
trainer/entropy_percentage                   -0.00271372
trainer/Q1Pred Mean                          98.2479
trainer/Q1Pred Std                           38.0215
trainer/Q1Pred Max                          156.597
trainer/Q1Pred Min                           -5.37274
trainer/Q2Pred Mean                          99.24
trainer/Q2Pred Std                           37.8626
trainer/Q2Pred Max                          157.009
trainer/Q2Pred Min                           -7.06047
trainer/QTargetWithReg Mean                  98.3254
trainer/QTargetWithReg Std                   38.3641
trainer/QTargetWithReg Max                  157.596
trainer/QTargetWithReg Min                   -7.26947
trainer/PolicyLossWithoutReg Mean            99.4123
trainer/PolicyLossWithoutReg Std             37.1512
trainer/PolicyLossWithoutReg Max            156.411
trainer/PolicyLossWithoutReg Min             -2.57165
trainer/gradient_norm                       186.813
trainer/gradient_penalty                     -0.934064
trainer/gradient_percentage                  -0.00939586
exploration/num steps total              167000
exploration/num paths total                1270
exploration/path length this epoch Mean     244.75
exploration/path length this epoch Std      212.642
exploration/path length this epoch Max      613
exploration/path length this epoch Min      116
exploration/Rewards Mean                      3.17979
exploration/Rewards Std                       1.22676
exploration/Rewards Max                       7.92036
exploration/Rewards Min                      -0.819377
exploration/Returns Mean                    778.253
exploration/Returns Std                     737.655
exploration/Returns Max                    2055.72
exploration/Returns Min                     338.728
exploration/Num Paths                         4
exploration/Average Returns                 778.253
evaluation_0/num steps total                  1.27716e+06
evaluation_0/num paths total               7952
evaluation_0/path length Mean               154.902
evaluation_0/path length Std                 76.7157
evaluation_0/path length Max                520
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     3.07353
evaluation_0/Rewards Std                      1.36975
evaluation_0/Rewards Max                      7.3817
evaluation_0/Rewards Min                     -0.78645
evaluation_0/Returns Mean                   476.097
evaluation_0/Returns Std                    315.513
evaluation_0/Returns Max                   2022.92
evaluation_0/Returns Min                    298.981
evaluation_0/Num Paths                       51
evaluation_0/Average Returns                476.097
time/epoch (s)                                0
time/total (s)                             3312.91
Epoch                                       162
---------------------------------------  ----------------
2022-11-16 11:41:17.713983 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 163 finished
---------------------------------------  ----------------
epoch                                       163
total_step                               168000
replay_pool/size                         168000
trainer/alpha                                 0.0467438
trainer/alpha_loss                            0.0212495
trainer/entropy                              -6.00694
trainer/qf_loss                               8.74233
trainer/state_noise                           0.005
trainer/policy_loss                         -97.1191
trainer/policy_loss_without_entropy          98.3869
trainer/entropy_penalty                      -0.280787
trainer/entropy_percentage                   -0.00285391
trainer/Q1Pred Mean                          97.4439
trainer/Q1Pred Std                           39.6683
trainer/Q1Pred Max                          161.196
trainer/Q1Pred Min                          -30.514
trainer/Q2Pred Mean                          97.2797
trainer/Q2Pred Std                           39.5615
trainer/Q2Pred Max                          162.055
trainer/Q2Pred Min                          -32.2137
trainer/QTargetWithReg Mean                  96.9632
trainer/QTargetWithReg Std                   39.3171
trainer/QTargetWithReg Max                  154.684
trainer/QTargetWithReg Min                  -33.1981
trainer/PolicyLossWithoutReg Mean            98.3869
trainer/PolicyLossWithoutReg Std             38.4963
trainer/PolicyLossWithoutReg Max            160.699
trainer/PolicyLossWithoutReg Min            -32.518
trainer/gradient_norm                       197.392
trainer/gradient_penalty                     -0.986961
trainer/gradient_percentage                  -0.0100314
exploration/num steps total              168000
exploration/num paths total                1277
exploration/path length this epoch Mean     137.286
exploration/path length this epoch Std       28.8826
exploration/path length this epoch Max      200
exploration/path length this epoch Min      106
exploration/Rewards Mean                      2.77165
exploration/Rewards Std                       1.28426
exploration/Rewards Max                       6.21818
exploration/Rewards Min                      -0.862488
exploration/Returns Mean                    380.509
exploration/Returns Std                      70.2701
exploration/Returns Max                     492.43
exploration/Returns Min                     285.602
exploration/Num Paths                         7
exploration/Average Returns                 380.509
evaluation_0/num steps total                  1.28488e+06
evaluation_0/num paths total               7976
evaluation_0/path length Mean               322.042
evaluation_0/path length Std                206.355
evaluation_0/path length Max                822
evaluation_0/path length Min                138
evaluation_0/Rewards Mean                     3.38395
evaluation_0/Rewards Std                      1.3455
evaluation_0/Rewards Max                      7.41412
evaluation_0/Rewards Min                     -0.707063
evaluation_0/Returns Mean                  1089.77
evaluation_0/Returns Std                    732.538
evaluation_0/Returns Max                   2615.63
evaluation_0/Returns Min                    369.852
evaluation_0/Num Paths                       24
evaluation_0/Average Returns               1089.77
time/epoch (s)                                0
time/total (s)                             3331.65
Epoch                                       163
---------------------------------------  ----------------
2022-11-16 11:41:35.263742 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 164 finished
---------------------------------------  ----------------
epoch                                       164
total_step                               169000
replay_pool/size                         169000
trainer/alpha                                 0.0470325
trainer/alpha_loss                            1.34209
trainer/entropy                              -6.43901
trainer/qf_loss                               6.29092
trainer/state_noise                           0.005
trainer/policy_loss                         -99.8925
trainer/policy_loss_without_entropy         101.15
trainer/entropy_penalty                      -0.302843
trainer/entropy_percentage                   -0.002994
trainer/Q1Pred Mean                         100.282
trainer/Q1Pred Std                           33.613
trainer/Q1Pred Max                          153.965
trainer/Q1Pred Min                           -2.06953
trainer/Q2Pred Mean                         100.64
trainer/Q2Pred Std                           33.475
trainer/Q2Pred Max                          155.903
trainer/Q2Pred Min                           -1.90052
trainer/QTargetWithReg Mean                 100.235
trainer/QTargetWithReg Std                   33.8482
trainer/QTargetWithReg Max                  155.123
trainer/QTargetWithReg Min                   -6.31709
trainer/PolicyLossWithoutReg Mean           101.15
trainer/PolicyLossWithoutReg Std             32.682
trainer/PolicyLossWithoutReg Max            154.778
trainer/PolicyLossWithoutReg Min              1.08735
trainer/gradient_norm                       190.934
trainer/gradient_penalty                     -0.954671
trainer/gradient_percentage                  -0.00943817
exploration/num steps total              169000
exploration/num paths total                1282
exploration/path length this epoch Mean     144.6
exploration/path length this epoch Std       26.9191
exploration/path length this epoch Max      198
exploration/path length this epoch Min      127
exploration/Rewards Mean                      3.00182
exploration/Rewards Std                       1.41472
exploration/Rewards Max                       6.59346
exploration/Rewards Min                      -0.833814
exploration/Returns Mean                    434.063
exploration/Returns Std                     120.037
exploration/Returns Max                     670.346
exploration/Returns Min                     350.176
exploration/Num Paths                         5
exploration/Average Returns                 434.063
evaluation_0/num steps total                  1.29275e+06
evaluation_0/num paths total               8010
evaluation_0/path length Mean               231.441
evaluation_0/path length Std                134.491
evaluation_0/path length Max               1000
evaluation_0/path length Min                193
evaluation_0/Rewards Mean                     2.381
evaluation_0/Rewards Std                      1.09444
evaluation_0/Rewards Max                      6.5754
evaluation_0/Rewards Min                     -0.767846
evaluation_0/Returns Mean                   551.062
evaluation_0/Returns Std                    367.387
evaluation_0/Returns Max                   2642.32
evaluation_0/Returns Min                    407.628
evaluation_0/Num Paths                       34
evaluation_0/Average Returns                551.062
time/epoch (s)                                0
time/total (s)                             3349.2
Epoch                                       164
---------------------------------------  ----------------
2022-11-16 11:41:52.488590 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 165 finished
---------------------------------------  ----------------
epoch                                       165
total_step                               170000
replay_pool/size                         170000
trainer/alpha                                 0.0475635
trainer/alpha_loss                            0.721679
trainer/entropy                              -6.23693
trainer/qf_loss                               6.36179
trainer/state_noise                           0.005
trainer/policy_loss                        -100.762
trainer/policy_loss_without_entropy         101.999
trainer/entropy_penalty                      -0.29665
trainer/entropy_percentage                   -0.00290836
trainer/Q1Pred Mean                         100.483
trainer/Q1Pred Std                           38.0721
trainer/Q1Pred Max                          162.179
trainer/Q1Pred Min                          -10.3188
trainer/Q2Pred Mean                         100.768
trainer/Q2Pred Std                           38.1032
trainer/Q2Pred Max                          163.682
trainer/Q2Pred Min                          -10.2139
trainer/QTargetWithReg Mean                 100.878
trainer/QTargetWithReg Std                   38.2017
trainer/QTargetWithReg Max                  163.918
trainer/QTargetWithReg Min                  -16.0998
trainer/PolicyLossWithoutReg Mean           101.999
trainer/PolicyLossWithoutReg Std             37.3942
trainer/PolicyLossWithoutReg Max            161.71
trainer/PolicyLossWithoutReg Min             -9.86642
trainer/gradient_norm                       188.194
trainer/gradient_penalty                     -0.940969
trainer/gradient_percentage                  -0.00922525
exploration/num steps total              170000
exploration/num paths total                1283
exploration/path length this epoch Mean     939
exploration/path length this epoch Std        0
exploration/path length this epoch Max      939
exploration/path length this epoch Min      939
exploration/Rewards Mean                      3.10477
exploration/Rewards Std                       1.12686
exploration/Rewards Max                       6.9177
exploration/Rewards Min                      -0.746621
exploration/Returns Mean                   2915.38
exploration/Returns Std                       0
exploration/Returns Max                    2915.38
exploration/Returns Min                    2915.38
exploration/Num Paths                         1
exploration/Average Returns                2915.38
evaluation_0/num steps total                  1.30061e+06
evaluation_0/num paths total               8053
evaluation_0/path length Mean               182.605
evaluation_0/path length Std                 61.3041
evaluation_0/path length Max                438
evaluation_0/path length Min                126
evaluation_0/Rewards Mean                     3.21527
evaluation_0/Rewards Std                      1.50504
evaluation_0/Rewards Max                      7.06622
evaluation_0/Rewards Min                     -0.644902
evaluation_0/Returns Mean                   587.124
evaluation_0/Returns Std                    261.311
evaluation_0/Returns Max                   1678.65
evaluation_0/Returns Min                    349.863
evaluation_0/Num Paths                       43
evaluation_0/Average Returns                587.124
time/epoch (s)                                0
time/total (s)                             3366.43
Epoch                                       165
---------------------------------------  ----------------
2022-11-16 11:42:11.209381 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 166 finished
---------------------------------------  ----------------
epoch                                       166
total_step                               171000
replay_pool/size                         171000
trainer/alpha                                 0.0455867
trainer/alpha_loss                           -0.612149
trainer/entropy                              -5.80177
trainer/qf_loss                               8.16683
trainer/state_noise                           0.005
trainer/policy_loss                        -101.221
trainer/policy_loss_without_entropy         102.441
trainer/entropy_penalty                      -0.264484
trainer/entropy_percentage                   -0.00258181
trainer/Q1Pred Mean                         101.889
trainer/Q1Pred Std                           36.6661
trainer/Q1Pred Max                          158.883
trainer/Q1Pred Min                           -0.876871
trainer/Q2Pred Mean                         101.725
trainer/Q2Pred Std                           36.755
trainer/Q2Pred Max                          160.088
trainer/Q2Pred Min                            0.0476892
trainer/QTargetWithReg Mean                 101.599
trainer/QTargetWithReg Std                   36.8675
trainer/QTargetWithReg Max                  160.664
trainer/QTargetWithReg Min                   -0.325618
trainer/PolicyLossWithoutReg Mean           102.441
trainer/PolicyLossWithoutReg Std             36.3954
trainer/PolicyLossWithoutReg Max            158.973
trainer/PolicyLossWithoutReg Min              2.81566
trainer/gradient_norm                       191.068
trainer/gradient_penalty                     -0.95534
trainer/gradient_percentage                  -0.00932575
exploration/num steps total              171000
exploration/num paths total                1284
exploration/path length this epoch Mean     325
exploration/path length this epoch Std        0
exploration/path length this epoch Max      325
exploration/path length this epoch Min      325
exploration/Rewards Mean                      3.53387
exploration/Rewards Std                       1.41824
exploration/Rewards Max                       6.53986
exploration/Rewards Min                      -0.627906
exploration/Returns Mean                   1148.51
exploration/Returns Std                       0
exploration/Returns Max                    1148.51
exploration/Returns Min                    1148.51
exploration/Num Paths                         1
exploration/Average Returns                1148.51
evaluation_0/num steps total                  1.30780e+06
evaluation_0/num paths total               8083
evaluation_0/path length Mean               239.967
evaluation_0/path length Std                157.347
evaluation_0/path length Max               1000
evaluation_0/path length Min                173
evaluation_0/Rewards Mean                     2.54667
evaluation_0/Rewards Std                      1.18431
evaluation_0/Rewards Max                      6.36057
evaluation_0/Rewards Min                     -1.58979
evaluation_0/Returns Mean                   611.115
evaluation_0/Returns Std                    529.087
evaluation_0/Returns Max                   3148.45
evaluation_0/Returns Min                    364.937
evaluation_0/Num Paths                       30
evaluation_0/Average Returns                611.115
time/epoch (s)                                0
time/total (s)                             3385.15
Epoch                                       166
---------------------------------------  ----------------
2022-11-16 11:42:28.448056 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 167 finished
---------------------------------------  ----------------
epoch                                       167
total_step                               172000
replay_pool/size                         172000
trainer/alpha                                 0.047056
trainer/alpha_loss                           -1.04588
trainer/entropy                              -5.65782
trainer/qf_loss                               6.5832
trainer/state_noise                           0.005
trainer/policy_loss                         -98.547
trainer/policy_loss_without_entropy          99.758
trainer/entropy_penalty                      -0.266234
trainer/entropy_percentage                   -0.0026688
trainer/Q1Pred Mean                          99.7301
trainer/Q1Pred Std                           36.4859
trainer/Q1Pred Max                          163.967
trainer/Q1Pred Min                            1.28597
trainer/Q2Pred Mean                          99.4014
trainer/Q2Pred Std                           36.2508
trainer/Q2Pred Max                          164.017
trainer/Q2Pred Min                            0.797059
trainer/QTargetWithReg Mean                  99.0774
trainer/QTargetWithReg Std                   36.7248
trainer/QTargetWithReg Max                  163.664
trainer/QTargetWithReg Min                   -1.59879
trainer/PolicyLossWithoutReg Mean            99.758
trainer/PolicyLossWithoutReg Std             35.868
trainer/PolicyLossWithoutReg Max            163.683
trainer/PolicyLossWithoutReg Min              1.78872
trainer/gradient_norm                       188.96
trainer/gradient_penalty                     -0.944798
trainer/gradient_percentage                  -0.0094709
exploration/num steps total              172000
exploration/num paths total                1287
exploration/path length this epoch Mean     106.333
exploration/path length this epoch Std       19.1543
exploration/path length this epoch Max      125
exploration/path length this epoch Min       80
exploration/Rewards Mean                      2.79432
exploration/Rewards Std                       1.33329
exploration/Rewards Max                       5.37617
exploration/Rewards Min                      -0.735716
exploration/Returns Mean                    297.13
exploration/Returns Std                      55.5798
exploration/Returns Max                     342.124
exploration/Returns Min                     218.818
exploration/Num Paths                         3
exploration/Average Returns                 297.13
evaluation_0/num steps total                  1.31577e+06
evaluation_0/num paths total               8098
evaluation_0/path length Mean               530.867
evaluation_0/path length Std                268.716
evaluation_0/path length Max               1000
evaluation_0/path length Min                178
evaluation_0/Rewards Mean                     3.33844
evaluation_0/Rewards Std                      1.29471
evaluation_0/Rewards Max                      7.96909
evaluation_0/Rewards Min                     -0.866327
evaluation_0/Returns Mean                  1772.27
evaluation_0/Returns Std                    938.683
evaluation_0/Returns Max                   3585.59
evaluation_0/Returns Min                    462.354
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1772.27
time/epoch (s)                                0
time/total (s)                             3402.39
Epoch                                       167
---------------------------------------  ----------------
2022-11-16 11:42:48.034292 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 168 finished
---------------------------------------  ----------------
epoch                                       168
total_step                               173000
replay_pool/size                         173000
trainer/alpha                                 0.0484033
trainer/alpha_loss                           -1.07694
trainer/entropy                              -5.64434
trainer/qf_loss                               7.65446
trainer/state_noise                           0.005
trainer/policy_loss                         -98.7224
trainer/policy_loss_without_entropy          99.9895
trainer/entropy_penalty                      -0.273205
trainer/entropy_percentage                   -0.00273233
trainer/Q1Pred Mean                          99.2203
trainer/Q1Pred Std                           38.4816
trainer/Q1Pred Max                          158.739
trainer/Q1Pred Min                          -20.0121
trainer/Q2Pred Mean                          98.642
trainer/Q2Pred Std                           38.4511
trainer/Q2Pred Max                          156.753
trainer/Q2Pred Min                          -24.4853
trainer/QTargetWithReg Mean                  98.5134
trainer/QTargetWithReg Std                   38.358
trainer/QTargetWithReg Max                  158.886
trainer/QTargetWithReg Min                  -20.3964
trainer/PolicyLossWithoutReg Mean            99.9895
trainer/PolicyLossWithoutReg Std             37.5695
trainer/PolicyLossWithoutReg Max            157.742
trainer/PolicyLossWithoutReg Min            -19.7328
trainer/gradient_norm                       198.779
trainer/gradient_penalty                     -0.993894
trainer/gradient_percentage                  -0.00993998
exploration/num steps total              173000
exploration/num paths total                1292
exploration/path length this epoch Mean     158.6
exploration/path length this epoch Std       41.548
exploration/path length this epoch Max      221
exploration/path length this epoch Min      110
exploration/Rewards Mean                      2.81989
exploration/Rewards Std                       1.40116
exploration/Rewards Max                       6.29105
exploration/Rewards Min                      -0.72312
exploration/Returns Mean                    447.234
exploration/Returns Std                     113.941
exploration/Returns Max                     577.468
exploration/Returns Min                     289.563
exploration/Num Paths                         5
exploration/Average Returns                 447.234
evaluation_0/num steps total                  1.32344e+06
evaluation_0/num paths total               8116
evaluation_0/path length Mean               426.389
evaluation_0/path length Std                268.995
evaluation_0/path length Max               1000
evaluation_0/path length Min                167
evaluation_0/Rewards Mean                     2.68038
evaluation_0/Rewards Std                      1.2234
evaluation_0/Rewards Max                      7.12863
evaluation_0/Rewards Min                     -0.752801
evaluation_0/Returns Mean                  1142.88
evaluation_0/Returns Std                    671.16
evaluation_0/Returns Max                   2978.79
evaluation_0/Returns Min                    403.583
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1142.88
time/epoch (s)                                0
time/total (s)                             3421.97
Epoch                                       168
---------------------------------------  ----------------
2022-11-16 11:43:05.920436 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 169 finished
---------------------------------------  ----------------
epoch                                       169
total_step                               174000
replay_pool/size                         174000
trainer/alpha                                 0.0453565
trainer/alpha_loss                            1.72153
trainer/entropy                              -6.55653
trainer/qf_loss                               7.06743
trainer/state_noise                           0.005
trainer/policy_loss                         -98.7631
trainer/policy_loss_without_entropy         100.033
trainer/entropy_penalty                      -0.297382
trainer/entropy_percentage                   -0.00297282
trainer/Q1Pred Mean                          99.1041
trainer/Q1Pred Std                           36.9348
trainer/Q1Pred Max                          158.831
trainer/Q1Pred Min                          -15.4948
trainer/Q2Pred Mean                          99.1278
trainer/Q2Pred Std                           36.4795
trainer/Q2Pred Max                          161.313
trainer/Q2Pred Min                          -11.9032
trainer/QTargetWithReg Mean                  99.304
trainer/QTargetWithReg Std                   36.4993
trainer/QTargetWithReg Max                  160.504
trainer/QTargetWithReg Min                   -5.49626
trainer/PolicyLossWithoutReg Mean           100.034
trainer/PolicyLossWithoutReg Std             35.4937
trainer/PolicyLossWithoutReg Max            159.199
trainer/PolicyLossWithoutReg Min             -3.45643
trainer/gradient_norm                       194.611
trainer/gradient_penalty                     -0.973056
trainer/gradient_percentage                  -0.0097273
exploration/num steps total              174000
exploration/num paths total                1294
exploration/path length this epoch Mean     442
exploration/path length this epoch Std      327
exploration/path length this epoch Max      769
exploration/path length this epoch Min      115
exploration/Rewards Mean                      3.32405
exploration/Rewards Std                       1.2303
exploration/Rewards Max                       6.58129
exploration/Rewards Min                      -0.589852
exploration/Returns Mean                   1469.23
exploration/Returns Std                    1123.29
exploration/Returns Max                    2592.52
exploration/Returns Min                     345.936
exploration/Num Paths                         2
exploration/Average Returns                1469.23
evaluation_0/num steps total                  1.33121e+06
evaluation_0/num paths total               8139
evaluation_0/path length Mean               337.87
evaluation_0/path length Std                331.525
evaluation_0/path length Max               1000
evaluation_0/path length Min                 79
evaluation_0/Rewards Mean                     2.97494
evaluation_0/Rewards Std                      1.23963
evaluation_0/Rewards Max                      7.20269
evaluation_0/Rewards Min                     -0.570145
evaluation_0/Returns Mean                  1005.14
evaluation_0/Returns Std                   1039.94
evaluation_0/Returns Max                   3069.15
evaluation_0/Returns Min                    212.708
evaluation_0/Num Paths                       23
evaluation_0/Average Returns               1005.14
time/epoch (s)                                0
time/total (s)                             3439.86
Epoch                                       169
---------------------------------------  ----------------
2022-11-16 11:43:24.650262 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 170 finished
---------------------------------------  ----------------
epoch                                       170
total_step                               175000
replay_pool/size                         175000
trainer/alpha                                 0.0474467
trainer/alpha_loss                            0.283273
trainer/entropy                              -6.09293
trainer/qf_loss                               5.98061
trainer/state_noise                           0.005
trainer/policy_loss                         -96.7936
trainer/policy_loss_without_entropy          98.0257
trainer/entropy_penalty                      -0.289089
trainer/entropy_percentage                   -0.00294912
trainer/Q1Pred Mean                          97.62
trainer/Q1Pred Std                           38.8854
trainer/Q1Pred Max                          152.423
trainer/Q1Pred Min                            1.54272
trainer/Q2Pred Mean                          97.5698
trainer/Q2Pred Std                           38.8829
trainer/Q2Pred Max                          153.023
trainer/Q2Pred Min                            4.00956
trainer/QTargetWithReg Mean                  97.2291
trainer/QTargetWithReg Std                   39.0492
trainer/QTargetWithReg Max                  155.906
trainer/QTargetWithReg Min                    3.5989
trainer/PolicyLossWithoutReg Mean            98.0257
trainer/PolicyLossWithoutReg Std             38.7084
trainer/PolicyLossWithoutReg Max            152.25
trainer/PolicyLossWithoutReg Min              3.32838
trainer/gradient_norm                       188.594
trainer/gradient_penalty                     -0.942971
trainer/gradient_percentage                  -0.00961963
exploration/num steps total              175000
exploration/num paths total                1295
exploration/path length this epoch Mean     149
exploration/path length this epoch Std        0
exploration/path length this epoch Max      149
exploration/path length this epoch Min      149
exploration/Rewards Mean                      2.60659
exploration/Rewards Std                       1.2297
exploration/Rewards Max                       5.81046
exploration/Rewards Min                      -0.73912
exploration/Returns Mean                    388.382
exploration/Returns Std                       0
exploration/Returns Max                     388.382
exploration/Returns Min                     388.382
exploration/Num Paths                         1
exploration/Average Returns                 388.382
evaluation_0/num steps total                  1.33874e+06
evaluation_0/num paths total               8159
evaluation_0/path length Mean               376.5
evaluation_0/path length Std                332.296
evaluation_0/path length Max               1000
evaluation_0/path length Min                120
evaluation_0/Rewards Mean                     2.78864
evaluation_0/Rewards Std                      1.15889
evaluation_0/Rewards Max                      7.0807
evaluation_0/Rewards Min                     -0.618376
evaluation_0/Returns Mean                  1049.92
evaluation_0/Returns Std                    927.96
evaluation_0/Returns Max                   2978.61
evaluation_0/Returns Min                    328.821
evaluation_0/Num Paths                       20
evaluation_0/Average Returns               1049.92
time/epoch (s)                                0
time/total (s)                             3458.59
Epoch                                       170
---------------------------------------  ----------------
2022-11-16 11:43:43.620715 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 171 finished
---------------------------------------  ----------------
epoch                                       171
total_step                               176000
replay_pool/size                         176000
trainer/alpha                                 0.0463904
trainer/alpha_loss                            0.666165
trainer/entropy                              -6.21695
trainer/qf_loss                               8.4349
trainer/state_noise                           0.005
trainer/policy_loss                         -98.4089
trainer/policy_loss_without_entropy          99.6643
trainer/entropy_penalty                      -0.288407
trainer/entropy_percentage                   -0.00289378
trainer/Q1Pred Mean                          98.4095
trainer/Q1Pred Std                           38.0441
trainer/Q1Pred Max                          157.949
trainer/Q1Pred Min                           -4.23902
trainer/Q2Pred Mean                          98.3702
trainer/Q2Pred Std                           38.369
trainer/Q2Pred Max                          160.17
trainer/Q2Pred Min                          -12.2639
trainer/QTargetWithReg Mean                  98.3863
trainer/QTargetWithReg Std                   38.549
trainer/QTargetWithReg Max                  162.886
trainer/QTargetWithReg Min                   -4.75614
trainer/PolicyLossWithoutReg Mean            99.6643
trainer/PolicyLossWithoutReg Std             37.5214
trainer/PolicyLossWithoutReg Max            158.308
trainer/PolicyLossWithoutReg Min             -0.863702
trainer/gradient_norm                       193.397
trainer/gradient_penalty                     -0.966984
trainer/gradient_percentage                  -0.00970241
exploration/num steps total              176000
exploration/num paths total                1297
exploration/path length this epoch Mean     277
exploration/path length this epoch Std      126
exploration/path length this epoch Max      403
exploration/path length this epoch Min      151
exploration/Rewards Mean                      3.41052
exploration/Rewards Std                       1.38711
exploration/Rewards Max                       6.6353
exploration/Rewards Min                      -0.65568
exploration/Returns Mean                    944.715
exploration/Returns Std                     467.23
exploration/Returns Max                    1411.95
exploration/Returns Min                     477.485
exploration/Num Paths                         2
exploration/Average Returns                 944.715
evaluation_0/num steps total                  1.34601e+06
evaluation_0/num paths total               8176
evaluation_0/path length Mean               427.471
evaluation_0/path length Std                397.303
evaluation_0/path length Max               1000
evaluation_0/path length Min                 90
evaluation_0/Rewards Mean                     2.91732
evaluation_0/Rewards Std                      1.03131
evaluation_0/Rewards Max                      7.23197
evaluation_0/Rewards Min                     -0.761082
evaluation_0/Returns Mean                  1247.07
evaluation_0/Returns Std                   1162.44
evaluation_0/Returns Max                   3029.8
evaluation_0/Returns Min                    231.329
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1247.07
time/epoch (s)                                0
time/total (s)                             3477.56
Epoch                                       171
---------------------------------------  ----------------
2022-11-16 11:44:01.387762 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 172 finished
---------------------------------------  ----------------
epoch                                       172
total_step                               177000
replay_pool/size                         177000
trainer/alpha                                 0.0470795
trainer/alpha_loss                            0.377629
trainer/entropy                              -6.12357
trainer/qf_loss                               6.03945
trainer/state_noise                           0.005
trainer/policy_loss                         -98.9648
trainer/policy_loss_without_entropy         100.181
trainer/entropy_penalty                      -0.288295
trainer/entropy_percentage                   -0.00287775
trainer/Q1Pred Mean                          99.3724
trainer/Q1Pred Std                           39.2566
trainer/Q1Pred Max                          179.026
trainer/Q1Pred Min                          -53.6744
trainer/Q2Pred Mean                          99.7898
trainer/Q2Pred Std                           39.1035
trainer/Q2Pred Max                          178.931
trainer/Q2Pred Min                          -48.4975
trainer/QTargetWithReg Mean                  99.5618
trainer/QTargetWithReg Std                   39.7652
trainer/QTargetWithReg Max                  183.574
trainer/QTargetWithReg Min                  -51.7823
trainer/PolicyLossWithoutReg Mean           100.181
trainer/PolicyLossWithoutReg Std             39.1066
trainer/PolicyLossWithoutReg Max            181.292
trainer/PolicyLossWithoutReg Min            -51.3708
trainer/gradient_norm                       185.543
trainer/gradient_penalty                     -0.927716
trainer/gradient_percentage                  -0.00926042
exploration/num steps total              177000
exploration/num paths total                1299
exploration/path length this epoch Mean      98
exploration/path length this epoch Std        8
exploration/path length this epoch Max      106
exploration/path length this epoch Min       90
exploration/Rewards Mean                      2.66442
exploration/Rewards Std                       1.41416
exploration/Rewards Max                       6.22022
exploration/Rewards Min                      -0.791141
exploration/Returns Mean                    261.113
exploration/Returns Std                      28.7716
exploration/Returns Max                     289.885
exploration/Returns Min                     232.341
exploration/Num Paths                         2
exploration/Average Returns                 261.113
evaluation_0/num steps total                  1.35388e+06
evaluation_0/num paths total               8189
evaluation_0/path length Mean               605.077
evaluation_0/path length Std                260.692
evaluation_0/path length Max               1000
evaluation_0/path length Min                216
evaluation_0/Rewards Mean                     3.14205
evaluation_0/Rewards Std                      1.09172
evaluation_0/Rewards Max                      7.67062
evaluation_0/Rewards Min                     -0.523182
evaluation_0/Returns Mean                  1901.18
evaluation_0/Returns Std                    827.409
evaluation_0/Returns Max                   3041
evaluation_0/Returns Min                    575.495
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               1901.18
time/epoch (s)                                0
time/total (s)                             3495.32
Epoch                                       172
---------------------------------------  ----------------
2022-11-16 11:44:18.750001 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 173 finished
---------------------------------------  ----------------
epoch                                       173
total_step                               178000
replay_pool/size                         178000
trainer/alpha                                 0.0470344
trainer/alpha_loss                            0.495248
trainer/entropy                              -6.162
trainer/qf_loss                               7.24375
trainer/state_noise                           0.005
trainer/policy_loss                         -98.1186
trainer/policy_loss_without_entropy          99.4232
trainer/entropy_penalty                      -0.289826
trainer/entropy_percentage                   -0.00291507
trainer/Q1Pred Mean                          98.694
trainer/Q1Pred Std                           38.4326
trainer/Q1Pred Max                          163.135
trainer/Q1Pred Min                           -2.8727
trainer/Q2Pred Mean                          98.8431
trainer/Q2Pred Std                           38.4726
trainer/Q2Pred Max                          162.771
trainer/Q2Pred Min                           -0.125157
trainer/QTargetWithReg Mean                  98.5499
trainer/QTargetWithReg Std                   38.6881
trainer/QTargetWithReg Max                  163.898
trainer/QTargetWithReg Min                   -4.49006
trainer/PolicyLossWithoutReg Mean            99.4232
trainer/PolicyLossWithoutReg Std             38.3587
trainer/PolicyLossWithoutReg Max            162.704
trainer/PolicyLossWithoutReg Min              0.343224
trainer/gradient_norm                       202.959
trainer/gradient_penalty                     -1.01479
trainer/gradient_percentage                  -0.0102068
exploration/num steps total              178000
exploration/num paths total                1301
exploration/path length this epoch Mean     133.5
exploration/path length this epoch Std        8.5
exploration/path length this epoch Max      142
exploration/path length this epoch Min      125
exploration/Rewards Mean                      2.92642
exploration/Rewards Std                       1.55108
exploration/Rewards Max                       6.05636
exploration/Rewards Min                      -0.50227
exploration/Returns Mean                    390.678
exploration/Returns Std                      25.9106
exploration/Returns Max                     416.588
exploration/Returns Min                     364.767
exploration/Num Paths                         2
exploration/Average Returns                 390.678
evaluation_0/num steps total                  1.36169e+06
evaluation_0/num paths total               8203
evaluation_0/path length Mean               558.357
evaluation_0/path length Std                419.773
evaluation_0/path length Max               1000
evaluation_0/path length Min                 93
evaluation_0/Rewards Mean                     2.84898
evaluation_0/Rewards Std                      0.872042
evaluation_0/Rewards Max                      7.1278
evaluation_0/Rewards Min                     -0.609039
evaluation_0/Returns Mean                  1590.75
evaluation_0/Returns Std                   1202.53
evaluation_0/Returns Max                   2950.72
evaluation_0/Returns Min                    235.195
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               1590.75
time/epoch (s)                                0
time/total (s)                             3512.68
Epoch                                       173
---------------------------------------  ----------------
2022-11-16 11:44:36.372969 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 174 finished
---------------------------------------  ----------------
epoch                                       174
total_step                               179000
replay_pool/size                         179000
trainer/alpha                                 0.0474569
trainer/alpha_loss                           -0.959416
trainer/entropy                              -5.68522
trainer/qf_loss                               6.56644
trainer/state_noise                           0.005
trainer/policy_loss                         -97.9337
trainer/policy_loss_without_entropy          99.12
trainer/entropy_penalty                      -0.269803
trainer/entropy_percentage                   -0.00272198
trainer/Q1Pred Mean                          98.4929
trainer/Q1Pred Std                           38.6835
trainer/Q1Pred Max                          152.71
trainer/Q1Pred Min                          -15.6457
trainer/Q2Pred Mean                          98.502
trainer/Q2Pred Std                           38.6352
trainer/Q2Pred Max                          151.96
trainer/Q2Pred Min                          -12.9001
trainer/QTargetWithReg Mean                  98.6121
trainer/QTargetWithReg Std                   38.6891
trainer/QTargetWithReg Max                  151.877
trainer/QTargetWithReg Min                  -13.8099
trainer/PolicyLossWithoutReg Mean            99.1201
trainer/PolicyLossWithoutReg Std             38.2032
trainer/PolicyLossWithoutReg Max            152.215
trainer/PolicyLossWithoutReg Min            -14.5897
trainer/gradient_norm                       183.301
trainer/gradient_penalty                     -0.916504
trainer/gradient_percentage                  -0.0092464
exploration/num steps total              179000
exploration/num paths total                1305
exploration/path length this epoch Mean     106.75
exploration/path length this epoch Std        9.44391
exploration/path length this epoch Max      121
exploration/path length this epoch Min       96
exploration/Rewards Mean                      2.68148
exploration/Rewards Std                       1.39087
exploration/Rewards Max                       6.26622
exploration/Rewards Min                      -0.78356
exploration/Returns Mean                    286.248
exploration/Returns Std                      41.1586
exploration/Returns Max                     350.004
exploration/Returns Min                     237.965
exploration/Num Paths                         4
exploration/Average Returns                 286.248
evaluation_0/num steps total                  1.36897e+06
evaluation_0/num paths total               8215
evaluation_0/path length Mean               606.167
evaluation_0/path length Std                314.989
evaluation_0/path length Max               1000
evaluation_0/path length Min                132
evaluation_0/Rewards Mean                     3.12503
evaluation_0/Rewards Std                      1.1683
evaluation_0/Rewards Max                      7.94285
evaluation_0/Rewards Min                     -0.610888
evaluation_0/Returns Mean                  1894.29
evaluation_0/Returns Std                    900.783
evaluation_0/Returns Max                   3062.8
evaluation_0/Returns Min                    351.083
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               1894.29
time/epoch (s)                                0
time/total (s)                             3530.31
Epoch                                       174
---------------------------------------  ----------------
2022-11-16 11:44:53.937741 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 175 finished
---------------------------------------  ----------------
epoch                                       175
total_step                               180000
replay_pool/size                         180000
trainer/alpha                                 0.0474146
trainer/alpha_loss                           -1.62389
trainer/entropy                              -5.46737
trainer/qf_loss                               7.49663
trainer/state_noise                           0.005
trainer/policy_loss                         -98.1826
trainer/policy_loss_without_entropy          99.3935
trainer/entropy_penalty                      -0.259233
trainer/entropy_percentage                   -0.00260815
trainer/Q1Pred Mean                          98.7265
trainer/Q1Pred Std                           39.6894
trainer/Q1Pred Max                          162.947
trainer/Q1Pred Min                          -21.005
trainer/Q2Pred Mean                          99.0181
trainer/Q2Pred Std                           39.7101
trainer/Q2Pred Max                          162.597
trainer/Q2Pred Min                          -15.6849
trainer/QTargetWithReg Mean                  98.772
trainer/QTargetWithReg Std                   39.5433
trainer/QTargetWithReg Max                  162.58
trainer/QTargetWithReg Min                  -16.1531
trainer/PolicyLossWithoutReg Mean            99.3936
trainer/PolicyLossWithoutReg Std             39.3172
trainer/PolicyLossWithoutReg Max            161.727
trainer/PolicyLossWithoutReg Min            -12.9321
trainer/gradient_norm                       190.342
trainer/gradient_penalty                     -0.95171
trainer/gradient_percentage                  -0.00957517
exploration/num steps total              180000
exploration/num paths total                1306
exploration/path length this epoch Mean     100
exploration/path length this epoch Std        0
exploration/path length this epoch Max      100
exploration/path length this epoch Min      100
exploration/Rewards Mean                      2.69625
exploration/Rewards Std                       1.37192
exploration/Rewards Max                       4.43726
exploration/Rewards Min                      -0.548993
exploration/Returns Mean                    269.625
exploration/Returns Std                       0
exploration/Returns Max                     269.625
exploration/Returns Min                     269.625
exploration/Num Paths                         1
exploration/Average Returns                 269.625
evaluation_0/num steps total                  1.37653e+06
evaluation_0/num paths total               8224
evaluation_0/path length Mean               840.222
evaluation_0/path length Std                311.116
evaluation_0/path length Max               1000
evaluation_0/path length Min                 98
evaluation_0/Rewards Mean                     2.89685
evaluation_0/Rewards Std                      0.799104
evaluation_0/Rewards Max                      7.4299
evaluation_0/Rewards Min                     -0.51539
evaluation_0/Returns Mean                  2433.99
evaluation_0/Returns Std                    871.864
evaluation_0/Returns Max                   3012.54
evaluation_0/Returns Min                    251.284
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2433.99
time/epoch (s)                                0
time/total (s)                             3547.87
Epoch                                       175
---------------------------------------  ----------------
2022-11-16 11:45:14.304090 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 176 finished
---------------------------------------  ----------------
epoch                                       176
total_step                               181000
replay_pool/size                         181000
trainer/alpha                                 0.0473224
trainer/alpha_loss                           -0.829551
trainer/entropy                              -5.72808
trainer/qf_loss                               7.38898
trainer/state_noise                           0.005
trainer/policy_loss                         -99.786
trainer/policy_loss_without_entropy         101.014
trainer/entropy_penalty                      -0.271067
trainer/entropy_percentage                   -0.00268345
trainer/Q1Pred Mean                         100.605
trainer/Q1Pred Std                           38.7141
trainer/Q1Pred Max                          170.179
trainer/Q1Pred Min                          -14.2669
trainer/Q2Pred Mean                         100.326
trainer/Q2Pred Std                           38.4091
trainer/Q2Pred Max                          170.596
trainer/Q2Pred Min                          -11.571
trainer/QTargetWithReg Mean                 100.569
trainer/QTargetWithReg Std                   38.1785
trainer/QTargetWithReg Max                  171.857
trainer/QTargetWithReg Min                   -0.773806
trainer/PolicyLossWithoutReg Mean           101.014
trainer/PolicyLossWithoutReg Std             38.2471
trainer/PolicyLossWithoutReg Max            170.439
trainer/PolicyLossWithoutReg Min             -5.43008
trainer/gradient_norm                       191.389
trainer/gradient_penalty                     -0.956946
trainer/gradient_percentage                  -0.0094734
exploration/num steps total              181000
exploration/num paths total                1308
exploration/path length this epoch Mean     371
exploration/path length this epoch Std      225
exploration/path length this epoch Max      596
exploration/path length this epoch Min      146
exploration/Rewards Mean                      3.16689
exploration/Rewards Std                       1.35824
exploration/Rewards Max                       8.12476
exploration/Rewards Min                      -0.59019
exploration/Returns Mean                   1174.91
exploration/Returns Std                     780.21
exploration/Returns Max                    1955.12
exploration/Returns Min                     394.705
exploration/Num Paths                         2
exploration/Average Returns                1174.91
evaluation_0/num steps total                  1.38449e+06
evaluation_0/num paths total               8248
evaluation_0/path length Mean               331.625
evaluation_0/path length Std                349.2
evaluation_0/path length Max               1000
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     2.83958
evaluation_0/Rewards Std                      1.04275
evaluation_0/Rewards Max                      6.99269
evaluation_0/Rewards Min                     -0.74558
evaluation_0/Returns Mean                   941.675
evaluation_0/Returns Std                   1010.69
evaluation_0/Returns Max                   2851.8
evaluation_0/Returns Min                    205.028
evaluation_0/Num Paths                       24
evaluation_0/Average Returns                941.675
time/epoch (s)                                0
time/total (s)                             3568.24
Epoch                                       176
---------------------------------------  ----------------
2022-11-16 11:45:33.654567 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 177 finished
---------------------------------------  ----------------
epoch                                       177
total_step                               182000
replay_pool/size                         182000
trainer/alpha                                 0.0478642
trainer/alpha_loss                           -1.26899
trainer/entropy                              -5.58247
trainer/qf_loss                               7.19483
trainer/state_noise                           0.005
trainer/policy_loss                        -103.008
trainer/policy_loss_without_entropy         104.219
trainer/entropy_penalty                      -0.267201
trainer/entropy_percentage                   -0.00256382
trainer/Q1Pred Mean                         103.061
trainer/Q1Pred Std                           35.8323
trainer/Q1Pred Max                          179.677
trainer/Q1Pred Min                            3.60971
trainer/Q2Pred Mean                         102.96
trainer/Q2Pred Std                           35.8175
trainer/Q2Pred Max                          181.701
trainer/Q2Pred Min                            3.64306
trainer/QTargetWithReg Mean                 103.742
trainer/QTargetWithReg Std                   35.7104
trainer/QTargetWithReg Max                  184.365
trainer/QTargetWithReg Min                    2.56356
trainer/PolicyLossWithoutReg Mean           104.219
trainer/PolicyLossWithoutReg Std             35.2657
trainer/PolicyLossWithoutReg Max            180.583
trainer/PolicyLossWithoutReg Min              4.28745
trainer/gradient_norm                       188.892
trainer/gradient_penalty                     -0.94446
trainer/gradient_percentage                  -0.00906222
exploration/num steps total              182000
exploration/num paths total                1309
exploration/path length this epoch Mean     474
exploration/path length this epoch Std        0
exploration/path length this epoch Max      474
exploration/path length this epoch Min      474
exploration/Rewards Mean                      2.71511
exploration/Rewards Std                       1.11954
exploration/Rewards Max                       6.01872
exploration/Rewards Min                      -0.54696
exploration/Returns Mean                   1286.96
exploration/Returns Std                       0
exploration/Returns Max                    1286.96
exploration/Returns Min                    1286.96
exploration/Num Paths                         1
exploration/Average Returns                1286.96
evaluation_0/num steps total                  1.39203e+06
evaluation_0/num paths total               8267
evaluation_0/path length Mean               396.684
evaluation_0/path length Std                411.476
evaluation_0/path length Max               1000
evaluation_0/path length Min                 78
evaluation_0/Rewards Mean                     2.78375
evaluation_0/Rewards Std                      0.907294
evaluation_0/Rewards Max                      7.04368
evaluation_0/Rewards Min                     -0.501252
evaluation_0/Returns Mean                  1104.27
evaluation_0/Returns Std                   1167.25
evaluation_0/Returns Max                   3068.82
evaluation_0/Returns Min                    189.998
evaluation_0/Num Paths                       19
evaluation_0/Average Returns               1104.27
time/epoch (s)                                0
time/total (s)                             3587.59
Epoch                                       177
---------------------------------------  ----------------
2022-11-16 11:45:53.801133 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 178 finished
---------------------------------------  ----------------
epoch                                       178
total_step                               183000
replay_pool/size                         183000
trainer/alpha                                 0.0462425
trainer/alpha_loss                           -0.495477
trainer/entropy                              -5.83881
trainer/qf_loss                               6.72101
trainer/state_noise                           0.005
trainer/policy_loss                        -100.957
trainer/policy_loss_without_entropy         102.174
trainer/entropy_penalty                      -0.270001
trainer/entropy_percentage                   -0.00264255
trainer/Q1Pred Mean                         101.478
trainer/Q1Pred Std                           36.6232
trainer/Q1Pred Max                          152.973
trainer/Q1Pred Min                           -8.89682
trainer/Q2Pred Mean                         101.405
trainer/Q2Pred Std                           36.7332
trainer/Q2Pred Max                          151.901
trainer/Q2Pred Min                           -7.32294
trainer/QTargetWithReg Mean                 101.569
trainer/QTargetWithReg Std                   36.3266
trainer/QTargetWithReg Max                  153.059
trainer/QTargetWithReg Min                   -5.68137
trainer/PolicyLossWithoutReg Mean           102.174
trainer/PolicyLossWithoutReg Std             36.3103
trainer/PolicyLossWithoutReg Max            152.829
trainer/PolicyLossWithoutReg Min             -8.00325
trainer/gradient_norm                       189.505
trainer/gradient_penalty                     -0.947524
trainer/gradient_percentage                  -0.0092736
exploration/num steps total              183000
exploration/num paths total                1310
exploration/path length this epoch Mean     141
exploration/path length this epoch Std        0
exploration/path length this epoch Max      141
exploration/path length this epoch Min      141
exploration/Rewards Mean                      3.14445
exploration/Rewards Std                       1.60631
exploration/Rewards Max                       7.5196
exploration/Rewards Min                      -0.505853
exploration/Returns Mean                    443.368
exploration/Returns Std                       0
exploration/Returns Max                     443.368
exploration/Returns Min                     443.368
exploration/Num Paths                         1
exploration/Average Returns                 443.368
evaluation_0/num steps total                  1.39903e+06
evaluation_0/num paths total               8309
evaluation_0/path length Mean               166.786
evaluation_0/path length Std                193.308
evaluation_0/path length Max               1000
evaluation_0/path length Min                 85
evaluation_0/Rewards Mean                     2.75356
evaluation_0/Rewards Std                      1.20584
evaluation_0/Rewards Max                      8.41068
evaluation_0/Rewards Min                     -0.511623
evaluation_0/Returns Mean                   459.254
evaluation_0/Returns Std                    544.997
evaluation_0/Returns Max                   2836.64
evaluation_0/Returns Min                    196.911
evaluation_0/Num Paths                       42
evaluation_0/Average Returns                459.254
time/epoch (s)                                0
time/total (s)                             3607.73
Epoch                                       178
---------------------------------------  ----------------
2022-11-16 11:46:13.059359 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 179 finished
---------------------------------------  ----------------
epoch                                       179
total_step                               184000
replay_pool/size                         184000
trainer/alpha                                 0.0469208
trainer/alpha_loss                           -0.947464
trainer/entropy                              -5.69029
trainer/qf_loss                               6.36435
trainer/state_noise                           0.005
trainer/policy_loss                        -102.495
trainer/policy_loss_without_entropy         103.745
trainer/entropy_penalty                      -0.266993
trainer/entropy_percentage                   -0.00257356
trainer/Q1Pred Mean                         103.096
trainer/Q1Pred Std                           38.029
trainer/Q1Pred Max                          156.157
trainer/Q1Pred Min                           -1.89495
trainer/Q2Pred Mean                         102.995
trainer/Q2Pred Std                           38.1687
trainer/Q2Pred Max                          159.048
trainer/Q2Pred Min                           -4.71852
trainer/QTargetWithReg Mean                 102.832
trainer/QTargetWithReg Std                   38.2162
trainer/QTargetWithReg Max                  158.459
trainer/QTargetWithReg Min                   -3.31213
trainer/PolicyLossWithoutReg Mean           103.745
trainer/PolicyLossWithoutReg Std             38.0195
trainer/PolicyLossWithoutReg Max            159.057
trainer/PolicyLossWithoutReg Min             -2.48941
trainer/gradient_norm                       196.482
trainer/gradient_penalty                     -0.982408
trainer/gradient_percentage                  -0.00946947
exploration/num steps total              184000
exploration/num paths total                1311
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.71842
exploration/Rewards Std                       0.819535
exploration/Rewards Max                       5.48664
exploration/Rewards Min                      -0.691237
exploration/Returns Mean                   2718.42
exploration/Returns Std                       0
exploration/Returns Max                    2718.42
exploration/Returns Min                    2718.42
exploration/Num Paths                         1
exploration/Average Returns                2718.42
evaluation_0/num steps total                  1.40675e+06
evaluation_0/num paths total               8335
evaluation_0/path length Mean               296.808
evaluation_0/path length Std                337.322
evaluation_0/path length Max               1000
evaluation_0/path length Min                 87
evaluation_0/Rewards Mean                     2.71758
evaluation_0/Rewards Std                      1.02283
evaluation_0/Rewards Max                      7.74144
evaluation_0/Rewards Min                     -0.520337
evaluation_0/Returns Mean                   806.6
evaluation_0/Returns Std                    913.374
evaluation_0/Returns Max                   2656.07
evaluation_0/Returns Min                    215.342
evaluation_0/Num Paths                       26
evaluation_0/Average Returns                806.6
time/epoch (s)                                0
time/total (s)                             3626.99
Epoch                                       179
---------------------------------------  ----------------
2022-11-16 11:46:30.790998 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 180 finished
---------------------------------------  ----------------
epoch                                       180
total_step                               185000
replay_pool/size                         185000
trainer/alpha                                 0.046852
trainer/alpha_loss                            0.155678
trainer/entropy                              -6.05086
trainer/qf_loss                               7.20067
trainer/state_noise                           0.005
trainer/policy_loss                        -100.918
trainer/policy_loss_without_entropy         102.166
trainer/entropy_penalty                      -0.283495
trainer/entropy_percentage                   -0.00277486
trainer/Q1Pred Mean                         100.687
trainer/Q1Pred Std                           38.081
trainer/Q1Pred Max                          166.13
trainer/Q1Pred Min                           -5.28627
trainer/Q2Pred Mean                         100.449
trainer/Q2Pred Std                           38.0135
trainer/Q2Pred Max                          167.495
trainer/Q2Pred Min                           -7.81899
trainer/QTargetWithReg Mean                 101.259
trainer/QTargetWithReg Std                   38.1415
trainer/QTargetWithReg Max                  169.012
trainer/QTargetWithReg Min                   -7.27897
trainer/PolicyLossWithoutReg Mean           102.166
trainer/PolicyLossWithoutReg Std             36.94
trainer/PolicyLossWithoutReg Max            166.697
trainer/PolicyLossWithoutReg Min             -4.27748
trainer/gradient_norm                       192.931
trainer/gradient_penalty                     -0.964655
trainer/gradient_percentage                  -0.00944206
exploration/num steps total              185000
exploration/num paths total                1313
exploration/path length this epoch Mean     206
exploration/path length this epoch Std       87
exploration/path length this epoch Max      293
exploration/path length this epoch Min      119
exploration/Rewards Mean                      2.76847
exploration/Rewards Std                       1.3462
exploration/Rewards Max                       5.74007
exploration/Rewards Min                      -0.618024
exploration/Returns Mean                    570.305
exploration/Returns Std                     255.104
exploration/Returns Max                     825.408
exploration/Returns Min                     315.201
exploration/Num Paths                         2
exploration/Average Returns                 570.305
evaluation_0/num steps total                  1.41403e+06
evaluation_0/num paths total               8343
evaluation_0/path length Mean               910.75
evaluation_0/path length Std                177.631
evaluation_0/path length Max               1000
evaluation_0/path length Min                468
evaluation_0/Rewards Mean                     2.92416
evaluation_0/Rewards Std                      0.958128
evaluation_0/Rewards Max                      8.14025
evaluation_0/Rewards Min                     -0.331232
evaluation_0/Returns Mean                  2663.18
evaluation_0/Returns Std                    446.196
evaluation_0/Returns Max                   3226.12
evaluation_0/Returns Min                   1586.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2663.18
time/epoch (s)                                0
time/total (s)                             3644.73
Epoch                                       180
---------------------------------------  ----------------
2022-11-16 11:46:48.324979 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 181 finished
---------------------------------------  ----------------
epoch                                       181
total_step                               186000
replay_pool/size                         186000
trainer/alpha                                 0.0467033
trainer/alpha_loss                            0.307947
trainer/entropy                              -6.10051
trainer/qf_loss                               5.85004
trainer/state_noise                           0.005
trainer/policy_loss                        -100.409
trainer/policy_loss_without_entropy         101.635
trainer/entropy_penalty                      -0.284914
trainer/entropy_percentage                   -0.00280331
trainer/Q1Pred Mean                         100.772
trainer/Q1Pred Std                           37.5487
trainer/Q1Pred Max                          160.781
trainer/Q1Pred Min                            2.78167
trainer/Q2Pred Mean                         101.26
trainer/Q2Pred Std                           37.4027
trainer/Q2Pred Max                          159.251
trainer/Q2Pred Min                            3.57816
trainer/QTargetWithReg Mean                 100.902
trainer/QTargetWithReg Std                   37.4824
trainer/QTargetWithReg Max                  160.593
trainer/QTargetWithReg Min                   -0.126675
trainer/PolicyLossWithoutReg Mean           101.635
trainer/PolicyLossWithoutReg Std             36.6439
trainer/PolicyLossWithoutReg Max            157.616
trainer/PolicyLossWithoutReg Min              4.45664
trainer/gradient_norm                       188.304
trainer/gradient_penalty                     -0.941522
trainer/gradient_percentage                  -0.00926376
exploration/num steps total              186000
exploration/num paths total                1314
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.17559
exploration/Rewards Std                       1.01916
exploration/Rewards Max                       6.84107
exploration/Rewards Min                      -0.335955
exploration/Returns Mean                   3175.59
exploration/Returns Std                       0
exploration/Returns Max                    3175.59
exploration/Returns Min                    3175.59
exploration/Num Paths                         1
exploration/Average Returns                3175.59
evaluation_0/num steps total                  1.42118e+06
evaluation_0/num paths total               8353
evaluation_0/path length Mean               714.1
evaluation_0/path length Std                374.825
evaluation_0/path length Max               1000
evaluation_0/path length Min                102
evaluation_0/Rewards Mean                     2.67685
evaluation_0/Rewards Std                      0.906807
evaluation_0/Rewards Max                      7.26271
evaluation_0/Rewards Min                     -0.576037
evaluation_0/Returns Mean                  1911.54
evaluation_0/Returns Std                    977.876
evaluation_0/Returns Max                   2714.46
evaluation_0/Returns Min                    252.964
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               1911.54
time/epoch (s)                                0
time/total (s)                             3662.26
Epoch                                       181
---------------------------------------  ----------------
2022-11-16 11:47:06.145310 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 182 finished
---------------------------------------  ----------------
epoch                                       182
total_step                               187000
replay_pool/size                         187000
trainer/alpha                                 0.0473
trainer/alpha_loss                            0.632383
trainer/entropy                              -6.20724
trainer/qf_loss                               8.25767
trainer/state_noise                           0.005
trainer/policy_loss                        -102.574
trainer/policy_loss_without_entropy         103.822
trainer/entropy_penalty                      -0.293603
trainer/entropy_percentage                   -0.00282794
trainer/Q1Pred Mean                         102.724
trainer/Q1Pred Std                           37.58
trainer/Q1Pred Max                          178.135
trainer/Q1Pred Min                           -8.23005
trainer/Q2Pred Mean                         101.892
trainer/Q2Pred Std                           37.6025
trainer/Q2Pred Max                          173.551
trainer/Q2Pred Min                           -7.75506
trainer/QTargetWithReg Mean                 102.08
trainer/QTargetWithReg Std                   37.9312
trainer/QTargetWithReg Max                  182.297
trainer/QTargetWithReg Min                   -4.06024
trainer/PolicyLossWithoutReg Mean           103.822
trainer/PolicyLossWithoutReg Std             36.6593
trainer/PolicyLossWithoutReg Max            177.344
trainer/PolicyLossWithoutReg Min             -6.86841
trainer/gradient_norm                       190.863
trainer/gradient_penalty                     -0.954317
trainer/gradient_percentage                  -0.00919184
exploration/num steps total              187000
exploration/num paths total                1315
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.56069
exploration/Rewards Std                       0.735302
exploration/Rewards Max                       5.5673
exploration/Rewards Min                      -0.551758
exploration/Returns Mean                   2560.69
exploration/Returns Std                       0
exploration/Returns Max                    2560.69
exploration/Returns Min                    2560.69
exploration/Num Paths                         1
exploration/Average Returns                2560.69
evaluation_0/num steps total                  1.42873e+06
evaluation_0/num paths total               8365
evaluation_0/path length Mean               629.583
evaluation_0/path length Std                391.853
evaluation_0/path length Max               1000
evaluation_0/path length Min                121
evaluation_0/Rewards Mean                     2.56294
evaluation_0/Rewards Std                      0.868203
evaluation_0/Rewards Max                      6.51437
evaluation_0/Rewards Min                     -0.729083
evaluation_0/Returns Mean                  1613.58
evaluation_0/Returns Std                   1000.09
evaluation_0/Returns Max                   2641.6
evaluation_0/Returns Min                    273.815
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               1613.58
time/epoch (s)                                0
time/total (s)                             3680.08
Epoch                                       182
---------------------------------------  ----------------
2022-11-16 11:47:25.136591 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 183 finished
---------------------------------------  ----------------
epoch                                       183
total_step                               188000
replay_pool/size                         188000
trainer/alpha                                 0.0473504
trainer/alpha_loss                            1.13357
trainer/entropy                              -6.37162
trainer/qf_loss                               6.81696
trainer/state_noise                           0.005
trainer/policy_loss                        -102.748
trainer/policy_loss_without_entropy         104.037
trainer/entropy_penalty                      -0.301699
trainer/entropy_percentage                   -0.00289991
trainer/Q1Pred Mean                         102.753
trainer/Q1Pred Std                           38.0887
trainer/Q1Pred Max                          163.743
trainer/Q1Pred Min                          -16.5751
trainer/Q2Pred Mean                         102.516
trainer/Q2Pred Std                           38.2043
trainer/Q2Pred Max                          162.552
trainer/Q2Pred Min                          -11.5415
trainer/QTargetWithReg Mean                 103.458
trainer/QTargetWithReg Std                   38.2027
trainer/QTargetWithReg Max                  164.888
trainer/QTargetWithReg Min                   -0.615303
trainer/PolicyLossWithoutReg Mean           104.037
trainer/PolicyLossWithoutReg Std             38.1085
trainer/PolicyLossWithoutReg Max            164.25
trainer/PolicyLossWithoutReg Min            -11.4419
trainer/gradient_norm                       197.525
trainer/gradient_penalty                     -0.987626
trainer/gradient_percentage                  -0.00949301
exploration/num steps total              188000
exploration/num paths total                1316
exploration/path length this epoch Mean     144
exploration/path length this epoch Std        0
exploration/path length this epoch Max      144
exploration/path length this epoch Min      144
exploration/Rewards Mean                      2.79535
exploration/Rewards Std                       1.84759
exploration/Rewards Max                       7.17594
exploration/Rewards Min                      -0.734899
exploration/Returns Mean                    402.53
exploration/Returns Std                       0
exploration/Returns Max                     402.53
exploration/Returns Min                     402.53
exploration/Num Paths                         1
exploration/Average Returns                 402.53
evaluation_0/num steps total                  1.43655e+06
evaluation_0/num paths total               8384
evaluation_0/path length Mean               411.526
evaluation_0/path length Std                368.763
evaluation_0/path length Max               1000
evaluation_0/path length Min                111
evaluation_0/Rewards Mean                     2.41112
evaluation_0/Rewards Std                      0.954254
evaluation_0/Rewards Max                      7.79461
evaluation_0/Rewards Min                     -0.668444
evaluation_0/Returns Mean                   992.241
evaluation_0/Returns Std                    884.028
evaluation_0/Returns Max                   2754.22
evaluation_0/Returns Min                    243.99
evaluation_0/Num Paths                       19
evaluation_0/Average Returns                992.241
time/epoch (s)                                0
time/total (s)                             3699.07
Epoch                                       183
---------------------------------------  ----------------
2022-11-16 11:47:42.986065 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 184 finished
---------------------------------------  ----------------
epoch                                       184
total_step                               189000
replay_pool/size                         189000
trainer/alpha                                 0.0473601
trainer/alpha_loss                            1.9172
trainer/entropy                              -6.62856
trainer/qf_loss                               6.47571
trainer/state_noise                           0.005
trainer/policy_loss                         -99.7616
trainer/policy_loss_without_entropy         101.037
trainer/entropy_penalty                      -0.313929
trainer/entropy_percentage                   -0.00310708
trainer/Q1Pred Mean                          99.7107
trainer/Q1Pred Std                           40.375
trainer/Q1Pred Max                          154.291
trainer/Q1Pred Min                           -5.12667
trainer/Q2Pred Mean                          99.7825
trainer/Q2Pred Std                           40.5384
trainer/Q2Pred Max                          154.493
trainer/Q2Pred Min                          -12.1988
trainer/QTargetWithReg Mean                  99.6462
trainer/QTargetWithReg Std                   40.4527
trainer/QTargetWithReg Max                  155.022
trainer/QTargetWithReg Min                   -7.70194
trainer/PolicyLossWithoutReg Mean           101.037
trainer/PolicyLossWithoutReg Std             39.1733
trainer/PolicyLossWithoutReg Max            154.36
trainer/PolicyLossWithoutReg Min            -12.5581
trainer/gradient_norm                       192.257
trainer/gradient_penalty                     -0.961283
trainer/gradient_percentage                  -0.00951419
exploration/num steps total              189000
exploration/num paths total                1319
exploration/path length this epoch Mean     300.333
exploration/path length this epoch Std      141.085
exploration/path length this epoch Max      457
exploration/path length this epoch Min      115
exploration/Rewards Mean                      2.67809
exploration/Rewards Std                       1.42983
exploration/Rewards Max                       8.08459
exploration/Rewards Min                      -0.911423
exploration/Returns Mean                    804.32
exploration/Returns Std                     446.116
exploration/Returns Max                    1359.36
exploration/Returns Min                     267.036
exploration/Num Paths                         3
exploration/Average Returns                 804.32
evaluation_0/num steps total                  1.44388e+06
evaluation_0/num paths total               8393
evaluation_0/path length Mean               814.667
evaluation_0/path length Std                347.119
evaluation_0/path length Max               1000
evaluation_0/path length Min                131
evaluation_0/Rewards Mean                     2.48932
evaluation_0/Rewards Std                      0.744346
evaluation_0/Rewards Max                      5.96355
evaluation_0/Rewards Min                     -0.6328
evaluation_0/Returns Mean                  2027.96
evaluation_0/Returns Std                    877.978
evaluation_0/Returns Max                   2637.74
evaluation_0/Returns Min                    322.808
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2027.96
time/epoch (s)                                0
time/total (s)                             3716.92
Epoch                                       184
---------------------------------------  ----------------
2022-11-16 11:48:00.448587 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 185 finished
---------------------------------------  ----------------
epoch                                       185
total_step                               190000
replay_pool/size                         190000
trainer/alpha                                 0.0474443
trainer/alpha_loss                            0.00873771
trainer/entropy                              -6.00287
trainer/qf_loss                               7.32705
trainer/state_noise                           0.005
trainer/policy_loss                        -102.991
trainer/policy_loss_without_entropy         104.234
trainer/entropy_penalty                      -0.284802
trainer/entropy_percentage                   -0.00273233
trainer/Q1Pred Mean                         102.752
trainer/Q1Pred Std                           39.014
trainer/Q1Pred Max                          157.548
trainer/Q1Pred Min                           -6.73308
trainer/Q2Pred Mean                         103.001
trainer/Q2Pred Std                           39.2704
trainer/Q2Pred Max                          157.071
trainer/Q2Pred Min                           -9.74651
trainer/QTargetWithReg Mean                 102.342
trainer/QTargetWithReg Std                   39.086
trainer/QTargetWithReg Max                  156.434
trainer/QTargetWithReg Min                   -7.03395
trainer/PolicyLossWithoutReg Mean           104.234
trainer/PolicyLossWithoutReg Std             37.6958
trainer/PolicyLossWithoutReg Max            156.155
trainer/PolicyLossWithoutReg Min             -0.171527
trainer/gradient_norm                       191.56
trainer/gradient_penalty                     -0.957802
trainer/gradient_percentage                  -0.00918897
exploration/num steps total              190000
exploration/num paths total                1320
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.41358
exploration/Rewards Std                       0.724664
exploration/Rewards Max                       4.92374
exploration/Rewards Min                      -0.519047
exploration/Returns Mean                   2413.58
exploration/Returns Std                       0
exploration/Returns Max                    2413.58
exploration/Returns Min                    2413.58
exploration/Num Paths                         1
exploration/Average Returns                2413.58
evaluation_0/num steps total                  1.45139e+06
evaluation_0/num paths total               8401
evaluation_0/path length Mean               939
evaluation_0/path length Std                161.391
evaluation_0/path length Max               1000
evaluation_0/path length Min                512
evaluation_0/Rewards Mean                     2.67777
evaluation_0/Rewards Std                      0.827812
evaluation_0/Rewards Max                      7.35513
evaluation_0/Rewards Min                     -0.4907
evaluation_0/Returns Mean                  2514.43
evaluation_0/Returns Std                    267.867
evaluation_0/Returns Max                   2718.62
evaluation_0/Returns Min                   1830.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2514.43
time/epoch (s)                                0
time/total (s)                             3734.38
Epoch                                       185
---------------------------------------  ----------------
2022-11-16 11:48:16.517426 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 186 finished
---------------------------------------  ----------------
epoch                                       186
total_step                               191000
replay_pool/size                         191000
trainer/alpha                                 0.0475621
trainer/alpha_loss                            0.653005
trainer/entropy                              -6.21439
trainer/qf_loss                               6.70675
trainer/state_noise                           0.005
trainer/policy_loss                         -99.6667
trainer/policy_loss_without_entropy         100.909
trainer/entropy_penalty                      -0.29557
trainer/entropy_percentage                   -0.00292908
trainer/Q1Pred Mean                          99.7911
trainer/Q1Pred Std                           39.8454
trainer/Q1Pred Max                          164.292
trainer/Q1Pred Min                           -8.55101
trainer/Q2Pred Mean                          99.7003
trainer/Q2Pred Std                           39.4984
trainer/Q2Pred Max                          163.937
trainer/Q2Pred Min                          -11.0389
trainer/QTargetWithReg Mean                  99.8873
trainer/QTargetWithReg Std                   39.5445
trainer/QTargetWithReg Max                  163.648
trainer/QTargetWithReg Min                  -10.8874
trainer/PolicyLossWithoutReg Mean           100.909
trainer/PolicyLossWithoutReg Std             39.1492
trainer/PolicyLossWithoutReg Max            163.964
trainer/PolicyLossWithoutReg Min            -10.2458
trainer/gradient_norm                       189.312
trainer/gradient_penalty                     -0.946562
trainer/gradient_percentage                  -0.00938037
exploration/num steps total              191000
exploration/num paths total                1321
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.4649
exploration/Rewards Std                       0.632031
exploration/Rewards Max                       4.67441
exploration/Rewards Min                      -0.580117
exploration/Returns Mean                   2464.9
exploration/Returns Std                       0
exploration/Returns Max                    2464.9
exploration/Returns Min                    2464.9
exploration/Num Paths                         1
exploration/Average Returns                2464.9
evaluation_0/num steps total                  1.45939e+06
evaluation_0/num paths total               8409
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.70049
evaluation_0/Rewards Std                      0.696809
evaluation_0/Rewards Max                      6.09789
evaluation_0/Rewards Min                     -0.596204
evaluation_0/Returns Mean                  2700.49
evaluation_0/Returns Std                     58.8063
evaluation_0/Returns Max                   2810.72
evaluation_0/Returns Min                   2639.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2700.49
time/epoch (s)                                0
time/total (s)                             3750.45
Epoch                                       186
---------------------------------------  ----------------
2022-11-16 11:48:35.050801 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 187 finished
---------------------------------------  ----------------
epoch                                       187
total_step                               192000
replay_pool/size                         192000
trainer/alpha                                 0.046707
trainer/alpha_loss                            0.563623
trainer/entropy                              -6.18395
trainer/qf_loss                               6.71326
trainer/state_noise                           0.005
trainer/policy_loss                        -101.685
trainer/policy_loss_without_entropy         102.899
trainer/entropy_penalty                      -0.288834
trainer/entropy_percentage                   -0.00280696
trainer/Q1Pred Mean                         102.08
trainer/Q1Pred Std                           40.8701
trainer/Q1Pred Max                          188.619
trainer/Q1Pred Min                          -19.714
trainer/Q2Pred Mean                         102.348
trainer/Q2Pred Std                           40.7586
trainer/Q2Pred Max                          191.899
trainer/Q2Pred Min                          -17.3136
trainer/QTargetWithReg Mean                 102.034
trainer/QTargetWithReg Std                   40.6207
trainer/QTargetWithReg Max                  190.409
trainer/QTargetWithReg Min                  -19.2176
trainer/PolicyLossWithoutReg Mean           102.899
trainer/PolicyLossWithoutReg Std             39.7642
trainer/PolicyLossWithoutReg Max            188.19
trainer/PolicyLossWithoutReg Min            -10.2447
trainer/gradient_norm                       185.178
trainer/gradient_penalty                     -0.925892
trainer/gradient_percentage                  -0.00899804
exploration/num steps total              192000
exploration/num paths total                1322
exploration/path length this epoch Mean     173
exploration/path length this epoch Std        0
exploration/path length this epoch Max      173
exploration/path length this epoch Min      173
exploration/Rewards Mean                      3.46051
exploration/Rewards Std                       1.71463
exploration/Rewards Max                       7.87083
exploration/Rewards Min                      -0.634329
exploration/Returns Mean                    598.668
exploration/Returns Std                       0
exploration/Returns Max                     598.668
exploration/Returns Min                     598.668
exploration/Num Paths                         1
exploration/Average Returns                 598.668
evaluation_0/num steps total                  1.46665e+06
evaluation_0/num paths total               8470
evaluation_0/path length Mean               118.902
evaluation_0/path length Std                 55.3504
evaluation_0/path length Max                386
evaluation_0/path length Min                 88
evaluation_0/Rewards Mean                     2.52093
evaluation_0/Rewards Std                      1.41333
evaluation_0/Rewards Max                      8.08812
evaluation_0/Rewards Min                     -0.374437
evaluation_0/Returns Mean                   299.743
evaluation_0/Returns Std                    196.683
evaluation_0/Returns Max                   1327.66
evaluation_0/Returns Min                    197.786
evaluation_0/Num Paths                       61
evaluation_0/Average Returns                299.743
time/epoch (s)                                0
time/total (s)                             3768.98
Epoch                                       187
---------------------------------------  ----------------
2022-11-16 11:48:52.524718 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 188 finished
---------------------------------------  ----------------
epoch                                       188
total_step                               193000
replay_pool/size                         193000
trainer/alpha                                 0.0478289
trainer/alpha_loss                           -0.387431
trainer/entropy                              -5.87257
trainer/qf_loss                               6.50307
trainer/state_noise                           0.005
trainer/policy_loss                        -102.792
trainer/policy_loss_without_entropy         104.025
trainer/entropy_penalty                      -0.280879
trainer/entropy_percentage                   -0.00270011
trainer/Q1Pred Mean                         103.744
trainer/Q1Pred Std                           38.9292
trainer/Q1Pred Max                          165.985
trainer/Q1Pred Min                          -10.2253
trainer/Q2Pred Mean                         103.352
trainer/Q2Pred Std                           38.6665
trainer/Q2Pred Max                          165.038
trainer/Q2Pred Min                          -15.9533
trainer/QTargetWithReg Mean                 103.318
trainer/QTargetWithReg Std                   39.0136
trainer/QTargetWithReg Max                  164.855
trainer/QTargetWithReg Min                   -7.94143
trainer/PolicyLossWithoutReg Mean           104.025
trainer/PolicyLossWithoutReg Std             38.3379
trainer/PolicyLossWithoutReg Max            165.393
trainer/PolicyLossWithoutReg Min             -7.65566
trainer/gradient_norm                       190.299
trainer/gradient_penalty                     -0.951496
trainer/gradient_percentage                  -0.00914683
exploration/num steps total              193000
exploration/num paths total                1324
exploration/path length this epoch Mean     398.5
exploration/path length this epoch Std      290.5
exploration/path length this epoch Max      689
exploration/path length this epoch Min      108
exploration/Rewards Mean                      3.43165
exploration/Rewards Std                       1.27794
exploration/Rewards Max                       6.60299
exploration/Rewards Min                      -0.618743
exploration/Returns Mean                   1367.51
exploration/Returns Std                    1086.15
exploration/Returns Max                    2453.66
exploration/Returns Min                     281.361
exploration/Num Paths                         2
exploration/Average Returns                1367.51
evaluation_0/num steps total                  1.47435e+06
evaluation_0/num paths total               8482
evaluation_0/path length Mean               641.833
evaluation_0/path length Std                272.418
evaluation_0/path length Max               1000
evaluation_0/path length Min                276
evaluation_0/Rewards Mean                     2.92376
evaluation_0/Rewards Std                      1.13596
evaluation_0/Rewards Max                      7.59114
evaluation_0/Rewards Min                     -0.458465
evaluation_0/Returns Mean                  1876.56
evaluation_0/Returns Std                    646.035
evaluation_0/Returns Max                   2907.51
evaluation_0/Returns Min                    869.852
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               1876.56
time/epoch (s)                                0
time/total (s)                             3786.45
Epoch                                       188
---------------------------------------  ----------------
2022-11-16 11:49:09.916130 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 189 finished
---------------------------------------  ----------------
epoch                                       189
total_step                               194000
replay_pool/size                         194000
trainer/alpha                                 0.0457973
trainer/alpha_loss                            0.00814869
trainer/entropy                              -6.00264
trainer/qf_loss                               7.49918
trainer/state_noise                           0.005
trainer/policy_loss                         -99.8364
trainer/policy_loss_without_entropy         101.023
trainer/entropy_penalty                      -0.274905
trainer/entropy_percentage                   -0.00272121
trainer/Q1Pred Mean                         100.651
trainer/Q1Pred Std                           41.3032
trainer/Q1Pred Max                          172.489
trainer/Q1Pred Min                          -21.8204
trainer/Q2Pred Mean                          99.7788
trainer/Q2Pred Std                           41.3768
trainer/Q2Pred Max                          168.931
trainer/Q2Pred Min                          -20.3449
trainer/QTargetWithReg Mean                 100.406
trainer/QTargetWithReg Std                   41.435
trainer/QTargetWithReg Max                  171.014
trainer/QTargetWithReg Min                  -16.6137
trainer/PolicyLossWithoutReg Mean           101.023
trainer/PolicyLossWithoutReg Std             40.7188
trainer/PolicyLossWithoutReg Max            168.682
trainer/PolicyLossWithoutReg Min            -20.4062
trainer/gradient_norm                       182.321
trainer/gradient_penalty                     -0.911605
trainer/gradient_percentage                  -0.00902375
exploration/num steps total              194000
exploration/num paths total                1325
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.64837
exploration/Rewards Std                       0.728964
exploration/Rewards Max                       6.08422
exploration/Rewards Min                      -0.383546
exploration/Returns Mean                   2648.37
exploration/Returns Std                       0
exploration/Returns Max                    2648.37
exploration/Returns Min                    2648.37
exploration/Num Paths                         1
exploration/Average Returns                2648.37
evaluation_0/num steps total                  1.48142e+06
evaluation_0/num paths total               8490
evaluation_0/path length Mean               883.875
evaluation_0/path length Std                234.735
evaluation_0/path length Max               1000
evaluation_0/path length Min                290
evaluation_0/Rewards Mean                     2.51327
evaluation_0/Rewards Std                      1.00343
evaluation_0/Rewards Max                      7.96622
evaluation_0/Rewards Min                     -0.569314
evaluation_0/Returns Mean                  2221.42
evaluation_0/Returns Std                    673.317
evaluation_0/Returns Max                   3380.55
evaluation_0/Returns Min                    753.476
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2221.42
time/epoch (s)                                0
time/total (s)                             3803.85
Epoch                                       189
---------------------------------------  ----------------
2022-11-16 11:49:27.307442 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 190 finished
---------------------------------------  ----------------
epoch                                       190
total_step                               195000
replay_pool/size                         195000
trainer/alpha                                 0.0464491
trainer/alpha_loss                           -0.74067
trainer/entropy                              -5.75869
trainer/qf_loss                               6.92009
trainer/state_noise                           0.005
trainer/policy_loss                        -107.815
trainer/policy_loss_without_entropy         109.037
trainer/entropy_penalty                      -0.267486
trainer/entropy_percentage                   -0.00245316
trainer/Q1Pred Mean                         107.748
trainer/Q1Pred Std                           36.5185
trainer/Q1Pred Max                          163.244
trainer/Q1Pred Min                           -0.37536
trainer/Q2Pred Mean                         107.761
trainer/Q2Pred Std                           36.4547
trainer/Q2Pred Max                          160.751
trainer/Q2Pred Min                           -1.9755
trainer/QTargetWithReg Mean                 107.293
trainer/QTargetWithReg Std                   36.5895
trainer/QTargetWithReg Max                  161.808
trainer/QTargetWithReg Min                   -0.261219
trainer/PolicyLossWithoutReg Mean           109.037
trainer/PolicyLossWithoutReg Std             34.9031
trainer/PolicyLossWithoutReg Max            160.792
trainer/PolicyLossWithoutReg Min              3.33747
trainer/gradient_norm                       190.9
trainer/gradient_penalty                     -0.954501
trainer/gradient_percentage                  -0.00875388
exploration/num steps total              195000
exploration/num paths total                1326
exploration/path length this epoch Mean     938
exploration/path length this epoch Std        0
exploration/path length this epoch Max      938
exploration/path length this epoch Min      938
exploration/Rewards Mean                      3.72989
exploration/Rewards Std                       1.24944
exploration/Rewards Max                       8.32092
exploration/Rewards Min                      -0.629716
exploration/Returns Mean                   3498.64
exploration/Returns Std                       0
exploration/Returns Max                    3498.64
exploration/Returns Min                    3498.64
exploration/Num Paths                         1
exploration/Average Returns                3498.64
evaluation_0/num steps total                  1.48884e+06
evaluation_0/num paths total               8500
evaluation_0/path length Mean               742
evaluation_0/path length Std                395.192
evaluation_0/path length Max               1000
evaluation_0/path length Min                 86
evaluation_0/Rewards Mean                     2.44407
evaluation_0/Rewards Std                      0.81586
evaluation_0/Rewards Max                      5.87911
evaluation_0/Rewards Min                     -0.592902
evaluation_0/Returns Mean                  1813.5
evaluation_0/Returns Std                    980.152
evaluation_0/Returns Max                   2540.45
evaluation_0/Returns Min                    178.814
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               1813.5
time/epoch (s)                                0
time/total (s)                             3821.24
Epoch                                       190
---------------------------------------  ----------------
2022-11-16 11:49:45.346522 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 191 finished
---------------------------------------  ---------------
epoch                                       191
total_step                               196000
replay_pool/size                         196000
trainer/alpha                                 0.046705
trainer/alpha_loss                            1.33576
trainer/entropy                              -6.43596
trainer/qf_loss                               5.01416
trainer/state_noise                           0.005
trainer/policy_loss                        -105.138
trainer/policy_loss_without_entropy         106.369
trainer/entropy_penalty                      -0.300591
trainer/entropy_percentage                   -0.00282593
trainer/Q1Pred Mean                         104.794
trainer/Q1Pred Std                           38.5371
trainer/Q1Pred Max                          193.733
trainer/Q1Pred Min                           -0.227787
trainer/Q2Pred Mean                         104.981
trainer/Q2Pred Std                           38.8591
trainer/Q2Pred Max                          186.997
trainer/Q2Pred Min                          -10.7718
trainer/QTargetWithReg Mean                 105.13
trainer/QTargetWithReg Std                   38.959
trainer/QTargetWithReg Max                  186.26
trainer/QTargetWithReg Min                   -0.72851
trainer/PolicyLossWithoutReg Mean           106.369
trainer/PolicyLossWithoutReg Std             36.7906
trainer/PolicyLossWithoutReg Max            186.545
trainer/PolicyLossWithoutReg Min              5.57255
trainer/gradient_norm                       186.014
trainer/gradient_penalty                     -0.930068
trainer/gradient_percentage                  -0.00874378
exploration/num steps total              196000
exploration/num paths total                1328
exploration/path length this epoch Mean     222
exploration/path length this epoch Std      107
exploration/path length this epoch Max      329
exploration/path length this epoch Min      115
exploration/Rewards Mean                      3.19446
exploration/Rewards Std                       1.33806
exploration/Rewards Max                       6.85749
exploration/Rewards Min                      -0.63047
exploration/Returns Mean                    709.17
exploration/Returns Std                     412.743
exploration/Returns Max                    1121.91
exploration/Returns Min                     296.427
exploration/Num Paths                         2
exploration/Average Returns                 709.17
evaluation_0/num steps total                  1.496e+06
evaluation_0/num paths total               8508
evaluation_0/path length Mean               894.5
evaluation_0/path length Std                279.127
evaluation_0/path length Max               1000
evaluation_0/path length Min                156
evaluation_0/Rewards Mean                     2.4311
evaluation_0/Rewards Std                      0.808704
evaluation_0/Rewards Max                      5.45489
evaluation_0/Rewards Min                     -0.490562
evaluation_0/Returns Mean                  2174.62
evaluation_0/Returns Std                    685.324
evaluation_0/Returns Max                   2509.89
evaluation_0/Returns Min                    369.639
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2174.62
time/epoch (s)                                0
time/total (s)                             3839.27
Epoch                                       191
---------------------------------------  ---------------
2022-11-16 11:50:02.619322 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 192 finished
---------------------------------------  ----------------
epoch                                       192
total_step                               197000
replay_pool/size                         197000
trainer/alpha                                 0.0458634
trainer/alpha_loss                            1.61294
trainer/entropy                              -6.52333
trainer/qf_loss                               4.733
trainer/state_noise                           0.005
trainer/policy_loss                        -102.043
trainer/policy_loss_without_entropy         103.237
trainer/entropy_penalty                      -0.299182
trainer/entropy_percentage                   -0.00289801
trainer/Q1Pred Mean                         102.643
trainer/Q1Pred Std                           40.9334
trainer/Q1Pred Max                          164.416
trainer/Q1Pred Min                          -22.854
trainer/Q2Pred Mean                         102.481
trainer/Q2Pred Std                           41.0878
trainer/Q2Pred Max                          163.672
trainer/Q2Pred Min                          -22.566
trainer/QTargetWithReg Mean                 102.69
trainer/QTargetWithReg Std                   41.2734
trainer/QTargetWithReg Max                  163.534
trainer/QTargetWithReg Min                  -18.4125
trainer/PolicyLossWithoutReg Mean           103.237
trainer/PolicyLossWithoutReg Std             40.1718
trainer/PolicyLossWithoutReg Max            164.199
trainer/PolicyLossWithoutReg Min            -17.8734
trainer/gradient_norm                       179.095
trainer/gradient_penalty                     -0.895475
trainer/gradient_percentage                  -0.00867396
exploration/num steps total              197000
exploration/num paths total                1330
exploration/path length this epoch Mean     274.5
exploration/path length this epoch Std      206.5
exploration/path length this epoch Max      481
exploration/path length this epoch Min       68
exploration/Rewards Mean                      3.26625
exploration/Rewards Std                       1.40642
exploration/Rewards Max                       6.6447
exploration/Rewards Min                      -0.556018
exploration/Returns Mean                    896.586
exploration/Returns Std                     722.263
exploration/Returns Max                    1618.85
exploration/Returns Min                     174.323
exploration/Num Paths                         2
exploration/Average Returns                 896.586
evaluation_0/num steps total                  1.50315e+06
evaluation_0/num paths total               8517
evaluation_0/path length Mean               795
evaluation_0/path length Std                143.399
evaluation_0/path length Max               1000
evaluation_0/path length Min                591
evaluation_0/Rewards Mean                     3.00588
evaluation_0/Rewards Std                      1.25765
evaluation_0/Rewards Max                      7.81293
evaluation_0/Rewards Min                     -0.49793
evaluation_0/Returns Mean                  2389.68
evaluation_0/Returns Std                    348.496
evaluation_0/Returns Max                   2911.93
evaluation_0/Returns Min                   1867.33
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2389.68
time/epoch (s)                                0
time/total (s)                             3856.55
Epoch                                       192
---------------------------------------  ----------------
2022-11-16 11:50:22.190330 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 193 finished
---------------------------------------  ----------------
epoch                                       193
total_step                               198000
replay_pool/size                         198000
trainer/alpha                                 0.0469728
trainer/alpha_loss                           -1.09575
trainer/entropy                              -5.6417
trainer/qf_loss                               6.0109
trainer/state_noise                           0.005
trainer/policy_loss                        -100.944
trainer/policy_loss_without_entropy         102.15
trainer/entropy_penalty                      -0.265006
trainer/entropy_percentage                   -0.00259428
trainer/Q1Pred Mean                         101.153
trainer/Q1Pred Std                           41.8325
trainer/Q1Pred Max                          160.569
trainer/Q1Pred Min                           -4.89071
trainer/Q2Pred Mean                         101.419
trainer/Q2Pred Std                           41.9507
trainer/Q2Pred Max                          164.955
trainer/Q2Pred Min                           -8.49892
trainer/QTargetWithReg Mean                 101.164
trainer/QTargetWithReg Std                   42.1453
trainer/QTargetWithReg Max                  160.921
trainer/QTargetWithReg Min                   -2.66875
trainer/PolicyLossWithoutReg Mean           102.15
trainer/PolicyLossWithoutReg Std             41.3309
trainer/PolicyLossWithoutReg Max            161.37
trainer/PolicyLossWithoutReg Min             -1.54511
trainer/gradient_norm                       188.292
trainer/gradient_penalty                     -0.941459
trainer/gradient_percentage                  -0.00921639
exploration/num steps total              198000
exploration/num paths total                1331
exploration/path length this epoch Mean     793
exploration/path length this epoch Std        0
exploration/path length this epoch Max      793
exploration/path length this epoch Min      793
exploration/Rewards Mean                      3.16237
exploration/Rewards Std                       1.26885
exploration/Rewards Max                       7.87327
exploration/Rewards Min                      -0.501824
exploration/Returns Mean                   2507.76
exploration/Returns Std                       0
exploration/Returns Max                    2507.76
exploration/Returns Min                    2507.76
exploration/Num Paths                         1
exploration/Average Returns                2507.76
evaluation_0/num steps total                  1.51103e+06
evaluation_0/num paths total               8547
evaluation_0/path length Mean               262.733
evaluation_0/path length Std                254.776
evaluation_0/path length Max               1000
evaluation_0/path length Min                103
evaluation_0/Rewards Mean                     2.70681
evaluation_0/Rewards Std                      1.32319
evaluation_0/Rewards Max                      7.9715
evaluation_0/Rewards Min                     -0.545321
evaluation_0/Returns Mean                   711.17
evaluation_0/Returns Std                    771.678
evaluation_0/Returns Max                   2893.16
evaluation_0/Returns Min                    236.456
evaluation_0/Num Paths                       30
evaluation_0/Average Returns                711.17
time/epoch (s)                                0
time/total (s)                             3876.12
Epoch                                       193
---------------------------------------  ----------------
2022-11-16 11:50:39.565834 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 194 finished
---------------------------------------  ----------------
epoch                                       194
total_step                               199000
replay_pool/size                         199000
trainer/alpha                                 0.0469051
trainer/alpha_loss                           -0.691024
trainer/entropy                              -5.77414
trainer/qf_loss                               6.19958
trainer/state_noise                           0.005
trainer/policy_loss                        -110.232
trainer/policy_loss_without_entropy         111.442
trainer/entropy_penalty                      -0.270837
trainer/entropy_percentage                   -0.0024303
trainer/Q1Pred Mean                         110.305
trainer/Q1Pred Std                           35.3778
trainer/Q1Pred Max                          201.516
trainer/Q1Pred Min                            0.429597
trainer/Q2Pred Mean                         110.324
trainer/Q2Pred Std                           35.2445
trainer/Q2Pred Max                          205.834
trainer/Q2Pred Min                           -0.193916
trainer/QTargetWithReg Mean                 110.205
trainer/QTargetWithReg Std                   35.5355
trainer/QTargetWithReg Max                  204.033
trainer/QTargetWithReg Min                   -2.55316
trainer/PolicyLossWithoutReg Mean           111.442
trainer/PolicyLossWithoutReg Std             34.3645
trainer/PolicyLossWithoutReg Max            202.205
trainer/PolicyLossWithoutReg Min              1.44419
trainer/gradient_norm                       187.881
trainer/gradient_penalty                     -0.939403
trainer/gradient_percentage                  -0.00842954
exploration/num steps total              199000
exploration/num paths total                1333
exploration/path length this epoch Mean     118.5
exploration/path length this epoch Std       10.5
exploration/path length this epoch Max      129
exploration/path length this epoch Min      108
exploration/Rewards Mean                      2.34692
exploration/Rewards Std                       1.23657
exploration/Rewards Max                       5.56564
exploration/Rewards Min                      -0.564146
exploration/Returns Mean                    278.11
exploration/Returns Std                      29.5318
exploration/Returns Max                     307.642
exploration/Returns Min                     248.578
exploration/Num Paths                         2
exploration/Average Returns                 278.11
evaluation_0/num steps total                  1.51843e+06
evaluation_0/num paths total               8556
evaluation_0/path length Mean               821.889
evaluation_0/path length Std                110.91
evaluation_0/path length Max               1000
evaluation_0/path length Min                661
evaluation_0/Rewards Mean                     3.01849
evaluation_0/Rewards Std                      1.15951
evaluation_0/Rewards Max                      7.75348
evaluation_0/Rewards Min                     -0.578624
evaluation_0/Returns Mean                  2480.86
evaluation_0/Returns Std                    238.658
evaluation_0/Returns Max                   2758.77
evaluation_0/Returns Min                   2045.71
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2480.86
time/epoch (s)                                0
time/total (s)                             3893.49
Epoch                                       194
---------------------------------------  ----------------
2022-11-16 11:50:56.030986 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 195 finished
---------------------------------------  ----------------
epoch                                       195
total_step                               200000
replay_pool/size                         200000
trainer/alpha                                 0.0460626
trainer/alpha_loss                            0.14799
trainer/entropy                              -6.04808
trainer/qf_loss                               7.69296
trainer/state_noise                           0.005
trainer/policy_loss                        -103.642
trainer/policy_loss_without_entropy         104.883
trainer/entropy_penalty                      -0.27859
trainer/entropy_percentage                   -0.00265619
trainer/Q1Pred Mean                         103.802
trainer/Q1Pred Std                           39.6342
trainer/Q1Pred Max                          161.071
trainer/Q1Pred Min                           -2.66513
trainer/Q2Pred Mean                         103.862
trainer/Q2Pred Std                           39.6112
trainer/Q2Pred Max                          160.045
trainer/Q2Pred Min                           -3.87413
trainer/QTargetWithReg Mean                 102.925
trainer/QTargetWithReg Std                   39.3554
trainer/QTargetWithReg Max                  161.652
trainer/QTargetWithReg Min                   -0.372902
trainer/PolicyLossWithoutReg Mean           104.883
trainer/PolicyLossWithoutReg Std             38.2947
trainer/PolicyLossWithoutReg Max            159.696
trainer/PolicyLossWithoutReg Min             -4.89099
trainer/gradient_norm                       192.483
trainer/gradient_penalty                     -0.962414
trainer/gradient_percentage                  -0.00917604
exploration/num steps total              200000
exploration/num paths total                1335
exploration/path length this epoch Mean     425.5
exploration/path length this epoch Std      114.5
exploration/path length this epoch Max      540
exploration/path length this epoch Min      311
exploration/Rewards Mean                      3.16583
exploration/Rewards Std                       1.33807
exploration/Rewards Max                       7.67854
exploration/Rewards Min                      -0.608936
exploration/Returns Mean                   1347.06
exploration/Returns Std                     230.217
exploration/Returns Max                    1577.28
exploration/Returns Min                    1116.84
exploration/Num Paths                         2
exploration/Average Returns                1347.06
evaluation_0/num steps total                  1.52643e+06
evaluation_0/num paths total               8564
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.59258
evaluation_0/Rewards Std                      0.925591
evaluation_0/Rewards Max                      6.74501
evaluation_0/Rewards Min                     -0.34439
evaluation_0/Returns Mean                  2592.58
evaluation_0/Returns Std                     75.3829
evaluation_0/Returns Max                   2698.62
evaluation_0/Returns Min                   2467.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2592.58
time/epoch (s)                                0
time/total (s)                             3909.96
Epoch                                       195
---------------------------------------  ----------------
2022-11-16 11:51:13.270821 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 196 finished
---------------------------------------  ----------------
epoch                                       196
total_step                               201000
replay_pool/size                         201000
trainer/alpha                                 0.0459263
trainer/alpha_loss                           -0.571814
trainer/entropy                              -5.81438
trainer/qf_loss                               5.48714
trainer/state_noise                           0.005
trainer/policy_loss                        -102.663
trainer/policy_loss_without_entropy         103.895
trainer/entropy_penalty                      -0.267033
trainer/entropy_percentage                   -0.00257021
trainer/Q1Pred Mean                         102.472
trainer/Q1Pred Std                           38.6501
trainer/Q1Pred Max                          177.058
trainer/Q1Pred Min                          -10.1509
trainer/Q2Pred Mean                         102.475
trainer/Q2Pred Std                           38.8811
trainer/Q2Pred Max                          174.224
trainer/Q2Pred Min                          -11.4898
trainer/QTargetWithReg Mean                 102.92
trainer/QTargetWithReg Std                   38.701
trainer/QTargetWithReg Max                  180.643
trainer/QTargetWithReg Min                   -9.32228
trainer/PolicyLossWithoutReg Mean           103.895
trainer/PolicyLossWithoutReg Std             36.8358
trainer/PolicyLossWithoutReg Max            175.014
trainer/PolicyLossWithoutReg Min             -7.44542
trainer/gradient_norm                       192.992
trainer/gradient_penalty                     -0.96496
trainer/gradient_percentage                  -0.0092878
exploration/num steps total              201000
exploration/num paths total                1337
exploration/path length this epoch Mean     447.5
exploration/path length this epoch Std      182.5
exploration/path length this epoch Max      630
exploration/path length this epoch Min      265
exploration/Rewards Mean                      3.03552
exploration/Rewards Std                       1.24721
exploration/Rewards Max                       6.77839
exploration/Rewards Min                      -0.579184
exploration/Returns Mean                   1358.39
exploration/Returns Std                     496.597
exploration/Returns Max                    1854.99
exploration/Returns Min                     861.796
exploration/Num Paths                         2
exploration/Average Returns                1358.39
evaluation_0/num steps total                  1.53408e+06
evaluation_0/num paths total               8573
evaluation_0/path length Mean               849.889
evaluation_0/path length Std                247.245
evaluation_0/path length Max               1000
evaluation_0/path length Min                191
evaluation_0/Rewards Mean                     2.96766
evaluation_0/Rewards Std                      1.23834
evaluation_0/Rewards Max                      7.80475
evaluation_0/Rewards Min                     -2.09551
evaluation_0/Returns Mean                  2522.18
evaluation_0/Returns Std                    834.327
evaluation_0/Returns Max                   3306.72
evaluation_0/Returns Min                    515.306
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2522.18
time/epoch (s)                                0
time/total (s)                             3927.2
Epoch                                       196
---------------------------------------  ----------------
2022-11-16 11:51:32.721914 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 197 finished
---------------------------------------  ----------------
epoch                                       197
total_step                               202000
replay_pool/size                         202000
trainer/alpha                                 0.0461801
trainer/alpha_loss                            1.11071
trainer/entropy                              -6.36113
trainer/qf_loss                               5.45624
trainer/state_noise                           0.005
trainer/policy_loss                        -105.546
trainer/policy_loss_without_entropy         106.741
trainer/entropy_penalty                      -0.293758
trainer/entropy_percentage                   -0.00275206
trainer/Q1Pred Mean                         105.599
trainer/Q1Pred Std                           36.5853
trainer/Q1Pred Max                          195.039
trainer/Q1Pred Min                          -25.9124
trainer/Q2Pred Mean                         105.826
trainer/Q2Pred Std                           36.4891
trainer/Q2Pred Max                          194.543
trainer/Q2Pred Min                          -23.7721
trainer/QTargetWithReg Mean                 106.157
trainer/QTargetWithReg Std                   36.6056
trainer/QTargetWithReg Max                  199.147
trainer/QTargetWithReg Min                  -20.4198
trainer/PolicyLossWithoutReg Mean           106.741
trainer/PolicyLossWithoutReg Std             35.8688
trainer/PolicyLossWithoutReg Max            195.378
trainer/PolicyLossWithoutReg Min            -19.3901
trainer/gradient_norm                       180.233
trainer/gradient_penalty                     -0.901164
trainer/gradient_percentage                  -0.00844253
exploration/num steps total              202000
exploration/num paths total                1339
exploration/path length this epoch Mean     427
exploration/path length this epoch Std      353
exploration/path length this epoch Max      780
exploration/path length this epoch Min       74
exploration/Rewards Mean                      3.16953
exploration/Rewards Std                       1.29505
exploration/Rewards Max                       7.61592
exploration/Rewards Min                      -0.647832
exploration/Returns Mean                   1353.39
exploration/Returns Std                    1155.52
exploration/Returns Max                    2508.91
exploration/Returns Min                     197.874
exploration/Num Paths                         2
exploration/Average Returns                1353.39
evaluation_0/num steps total                  1.54159e+06
evaluation_0/num paths total               8591
evaluation_0/path length Mean               417.278
evaluation_0/path length Std                394.293
evaluation_0/path length Max               1000
evaluation_0/path length Min                 69
evaluation_0/Rewards Mean                     2.89867
evaluation_0/Rewards Std                      1.25029
evaluation_0/Rewards Max                      8.03155
evaluation_0/Rewards Min                     -1.1698
evaluation_0/Returns Mean                  1209.55
evaluation_0/Returns Std                   1199.23
evaluation_0/Returns Max                   3478.6
evaluation_0/Returns Min                    187.025
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1209.55
time/epoch (s)                                0
time/total (s)                             3946.65
Epoch                                       197
---------------------------------------  ----------------
2022-11-16 11:51:48.599915 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 198 finished
---------------------------------------  ----------------
epoch                                       198
total_step                               203000
replay_pool/size                         203000
trainer/alpha                                 0.0462648
trainer/alpha_loss                           -1.43508
trainer/entropy                              -5.53304
trainer/qf_loss                               4.42921
trainer/state_noise                           0.005
trainer/policy_loss                        -105.662
trainer/policy_loss_without_entropy         106.878
trainer/entropy_penalty                      -0.255985
trainer/entropy_percentage                   -0.00239513
trainer/Q1Pred Mean                         106.085
trainer/Q1Pred Std                           36.6531
trainer/Q1Pred Max                          162.888
trainer/Q1Pred Min                           -2.87572
trainer/Q2Pred Mean                         106.377
trainer/Q2Pred Std                           36.7083
trainer/Q2Pred Max                          163.292
trainer/Q2Pred Min                           -5.91693
trainer/QTargetWithReg Mean                 106.425
trainer/QTargetWithReg Std                   36.2699
trainer/QTargetWithReg Max                  162.77
trainer/QTargetWithReg Min                   -0.326387
trainer/PolicyLossWithoutReg Mean           106.878
trainer/PolicyLossWithoutReg Std             35.8614
trainer/PolicyLossWithoutReg Max            163.279
trainer/PolicyLossWithoutReg Min              3.43967
trainer/gradient_norm                       191.844
trainer/gradient_penalty                     -0.959218
trainer/gradient_percentage                  -0.00897492
exploration/num steps total              203000
exploration/num paths total                1340
exploration/path length this epoch Mean     554
exploration/path length this epoch Std        0
exploration/path length this epoch Max      554
exploration/path length this epoch Min      554
exploration/Rewards Mean                      3.2289
exploration/Rewards Std                       1.31764
exploration/Rewards Max                       6.78799
exploration/Rewards Min                      -0.350409
exploration/Returns Mean                   1788.81
exploration/Returns Std                       0
exploration/Returns Max                    1788.81
exploration/Returns Min                    1788.81
exploration/Num Paths                         1
exploration/Average Returns                1788.81
evaluation_0/num steps total                  1.54952e+06
evaluation_0/num paths total               8667
evaluation_0/path length Mean               104.421
evaluation_0/path length Std                  2.44014
evaluation_0/path length Max                111
evaluation_0/path length Min                100
evaluation_0/Rewards Mean                     2.55835
evaluation_0/Rewards Std                      1.32524
evaluation_0/Rewards Max                      6.346
evaluation_0/Rewards Min                     -0.586606
evaluation_0/Returns Mean                   267.146
evaluation_0/Returns Std                     13.1126
evaluation_0/Returns Max                    304.465
evaluation_0/Returns Min                    247.352
evaluation_0/Num Paths                       76
evaluation_0/Average Returns                267.146
time/epoch (s)                                0
time/total (s)                             3962.53
Epoch                                       198
---------------------------------------  ----------------
2022-11-16 11:52:06.482650 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 199 finished
---------------------------------------  ----------------
epoch                                       199
total_step                               204000
replay_pool/size                         204000
trainer/alpha                                 0.0459824
trainer/alpha_loss                           -0.400061
trainer/entropy                              -5.87009
trainer/qf_loss                               7.67233
trainer/state_noise                           0.005
trainer/policy_loss                        -109.439
trainer/policy_loss_without_entropy         110.65
trainer/entropy_penalty                      -0.269921
trainer/entropy_percentage                   -0.0024394
trainer/Q1Pred Mean                         109.825
trainer/Q1Pred Std                           34.9838
trainer/Q1Pred Max                          173.917
trainer/Q1Pred Min                           -3.33759
trainer/Q2Pred Mean                         109.505
trainer/Q2Pred Std                           34.951
trainer/Q2Pred Max                          174.013
trainer/Q2Pred Min                          -10.1924
trainer/QTargetWithReg Mean                 109.985
trainer/QTargetWithReg Std                   35.0759
trainer/QTargetWithReg Max                  174.607
trainer/QTargetWithReg Min                   -9.50173
trainer/PolicyLossWithoutReg Mean           110.65
trainer/PolicyLossWithoutReg Std             34.7615
trainer/PolicyLossWithoutReg Max            174.01
trainer/PolicyLossWithoutReg Min             -7.41794
trainer/gradient_norm                       188.326
trainer/gradient_penalty                     -0.941628
trainer/gradient_percentage                  -0.00850994
exploration/num steps total              204000
exploration/num paths total                1341
exploration/path length this epoch Mean     615
exploration/path length this epoch Std        0
exploration/path length this epoch Max      615
exploration/path length this epoch Min      615
exploration/Rewards Mean                      3.43651
exploration/Rewards Std                       1.31333
exploration/Rewards Max                       7.49443
exploration/Rewards Min                      -0.602944
exploration/Returns Mean                   2113.45
exploration/Returns Std                       0
exploration/Returns Max                    2113.45
exploration/Returns Min                    2113.45
exploration/Num Paths                         1
exploration/Average Returns                2113.45
evaluation_0/num steps total                  1.55731e+06
evaluation_0/num paths total               8690
evaluation_0/path length Mean               338.348
evaluation_0/path length Std                136.705
evaluation_0/path length Max                795
evaluation_0/path length Min                266
evaluation_0/Rewards Mean                     3.50451
evaluation_0/Rewards Std                      1.43401
evaluation_0/Rewards Max                      8.29848
evaluation_0/Rewards Min                     -0.380889
evaluation_0/Returns Mean                  1185.74
evaluation_0/Returns Std                    468.82
evaluation_0/Returns Max                   2554.47
evaluation_0/Returns Min                    918.154
evaluation_0/Num Paths                       23
evaluation_0/Average Returns               1185.74
time/epoch (s)                                0
time/total (s)                             3980.41
Epoch                                       199
---------------------------------------  ----------------
2022-11-16 11:52:23.887893 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 200 finished
---------------------------------------  ----------------
epoch                                       200
total_step                               205000
replay_pool/size                         205000
trainer/alpha                                 0.0459877
trainer/alpha_loss                           -0.903664
trainer/entropy                              -5.70653
trainer/qf_loss                               4.93211
trainer/state_noise                           0.005
trainer/policy_loss                        -105.628
trainer/policy_loss_without_entropy         106.836
trainer/entropy_penalty                      -0.26243
trainer/entropy_percentage                   -0.00245637
trainer/Q1Pred Mean                         106.54
trainer/Q1Pred Std                           37.1329
trainer/Q1Pred Max                          198.927
trainer/Q1Pred Min                           -6.28563
trainer/Q2Pred Mean                         106.093
trainer/Q2Pred Std                           37.2555
trainer/Q2Pred Max                          192.261
trainer/Q2Pred Min                           -5.41171
trainer/QTargetWithReg Mean                 106.04
trainer/QTargetWithReg Std                   37.3689
trainer/QTargetWithReg Max                  197.359
trainer/QTargetWithReg Min                   -6.16667
trainer/PolicyLossWithoutReg Mean           106.836
trainer/PolicyLossWithoutReg Std             36.8785
trainer/PolicyLossWithoutReg Max            193.923
trainer/PolicyLossWithoutReg Min             -4.09297
trainer/gradient_norm                       189.239
trainer/gradient_penalty                     -0.946193
trainer/gradient_percentage                  -0.00885647
exploration/num steps total              205000
exploration/num paths total                1342
exploration/path length this epoch Mean     413
exploration/path length this epoch Std        0
exploration/path length this epoch Max      413
exploration/path length this epoch Min      413
exploration/Rewards Mean                      3.06403
exploration/Rewards Std                       1.35803
exploration/Rewards Max                       6.87654
exploration/Rewards Min                      -0.362376
exploration/Returns Mean                   1265.45
exploration/Returns Std                       0
exploration/Returns Max                    1265.45
exploration/Returns Min                    1265.45
exploration/Num Paths                         1
exploration/Average Returns                1265.45
evaluation_0/num steps total                  1.56452e+06
evaluation_0/num paths total               8698
evaluation_0/path length Mean               901.75
evaluation_0/path length Std                128.594
evaluation_0/path length Max               1000
evaluation_0/path length Min                706
evaluation_0/Rewards Mean                     3.40153
evaluation_0/Rewards Std                      1.14234
evaluation_0/Rewards Max                      8.127
evaluation_0/Rewards Min                     -0.34837
evaluation_0/Returns Mean                  3067.33
evaluation_0/Returns Std                    353.209
evaluation_0/Returns Max                   3529.14
evaluation_0/Returns Min                   2476.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3067.33
time/epoch (s)                                0
time/total (s)                             3997.81
Epoch                                       200
---------------------------------------  ----------------
2022-11-16 11:52:41.987328 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 201 finished
---------------------------------------  ----------------
epoch                                       201
total_step                               206000
replay_pool/size                         206000
trainer/alpha                                 0.047021
trainer/alpha_loss                            0.583263
trainer/entropy                              -6.19077
trainer/qf_loss                               5.4769
trainer/state_noise                           0.005
trainer/policy_loss                        -106.506
trainer/policy_loss_without_entropy         107.73
trainer/entropy_penalty                      -0.291097
trainer/entropy_percentage                   -0.0027021
trainer/Q1Pred Mean                         107.234
trainer/Q1Pred Std                           36.0916
trainer/Q1Pred Max                          161.493
trainer/Q1Pred Min                           -2.15494
trainer/Q2Pred Mean                         106.882
trainer/Q2Pred Std                           36.1584
trainer/Q2Pred Max                          161.715
trainer/Q2Pred Min                           -5.11623
trainer/QTargetWithReg Mean                 107.619
trainer/QTargetWithReg Std                   36.1495
trainer/QTargetWithReg Max                  161.329
trainer/QTargetWithReg Min                   -1.43304
trainer/PolicyLossWithoutReg Mean           107.73
trainer/PolicyLossWithoutReg Std             35.4559
trainer/PolicyLossWithoutReg Max            161.007
trainer/PolicyLossWithoutReg Min             -7.75148
trainer/gradient_norm                       186.604
trainer/gradient_penalty                     -0.933019
trainer/gradient_percentage                  -0.00866073
exploration/num steps total              206000
exploration/num paths total                1343
exploration/path length this epoch Mean     534
exploration/path length this epoch Std        0
exploration/path length this epoch Max      534
exploration/path length this epoch Min      534
exploration/Rewards Mean                      3.08267
exploration/Rewards Std                       1.19745
exploration/Rewards Max                       6.88176
exploration/Rewards Min                      -0.24411
exploration/Returns Mean                   1646.14
exploration/Returns Std                       0
exploration/Returns Max                    1646.14
exploration/Returns Min                    1646.14
exploration/Num Paths                         1
exploration/Average Returns                1646.14
evaluation_0/num steps total                  1.57225e+06
evaluation_0/num paths total               8707
evaluation_0/path length Mean               859.111
evaluation_0/path length Std                195.705
evaluation_0/path length Max               1000
evaluation_0/path length Min                501
evaluation_0/Rewards Mean                     3.17387
evaluation_0/Rewards Std                      1.14192
evaluation_0/Rewards Max                      7.67895
evaluation_0/Rewards Min                     -0.407524
evaluation_0/Returns Mean                  2726.7
evaluation_0/Returns Std                    584.261
evaluation_0/Returns Max                   3511.18
evaluation_0/Returns Min                   1650.73
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2726.7
time/epoch (s)                                0
time/total (s)                             4015.91
Epoch                                       201
---------------------------------------  ----------------
2022-11-16 11:52:57.760737 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 202 finished
---------------------------------------  ----------------
epoch                                       202
total_step                               207000
replay_pool/size                         207000
trainer/alpha                                 0.0477158
trainer/alpha_loss                            2.01629
trainer/entropy                              -6.66265
trainer/qf_loss                               5.141
trainer/state_noise                           0.005
trainer/policy_loss                        -104.08
trainer/policy_loss_without_entropy         105.374
trainer/entropy_penalty                      -0.317914
trainer/entropy_percentage                   -0.00301702
trainer/Q1Pred Mean                         104.497
trainer/Q1Pred Std                           39.0028
trainer/Q1Pred Max                          166.636
trainer/Q1Pred Min                           -3.00387
trainer/Q2Pred Mean                         104.489
trainer/Q2Pred Std                           38.8468
trainer/Q2Pred Max                          165.9
trainer/Q2Pred Min                            0.201093
trainer/QTargetWithReg Mean                 104.61
trainer/QTargetWithReg Std                   39.2651
trainer/QTargetWithReg Max                  165.748
trainer/QTargetWithReg Min                   -3.59008
trainer/PolicyLossWithoutReg Mean           105.374
trainer/PolicyLossWithoutReg Std             38.4872
trainer/PolicyLossWithoutReg Max            166.104
trainer/PolicyLossWithoutReg Min              0.630082
trainer/gradient_norm                       195.066
trainer/gradient_penalty                     -0.975332
trainer/gradient_percentage                  -0.00925595
exploration/num steps total              207000
exploration/num paths total                1344
exploration/path length this epoch Mean     924
exploration/path length this epoch Std        0
exploration/path length this epoch Max      924
exploration/path length this epoch Min      924
exploration/Rewards Mean                      3.53963
exploration/Rewards Std                       1.28618
exploration/Rewards Max                       7.61643
exploration/Rewards Min                      -0.41245
exploration/Returns Mean                   3270.61
exploration/Returns Std                       0
exploration/Returns Max                    3270.61
exploration/Returns Min                    3270.61
exploration/Num Paths                         1
exploration/Average Returns                3270.61
evaluation_0/num steps total                  1.58025e+06
evaluation_0/num paths total               8715
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.78202
evaluation_0/Rewards Std                      1.0309
evaluation_0/Rewards Max                      7.54783
evaluation_0/Rewards Min                     -0.363361
evaluation_0/Returns Mean                  2782.02
evaluation_0/Returns Std                    376.125
evaluation_0/Returns Max                   3349.08
evaluation_0/Returns Min                   2315.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2782.02
time/epoch (s)                                0
time/total (s)                             4031.69
Epoch                                       202
---------------------------------------  ----------------
2022-11-16 11:53:15.733701 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 203 finished
---------------------------------------  ----------------
epoch                                       203
total_step                               208000
replay_pool/size                         208000
trainer/alpha                                 0.0470548
trainer/alpha_loss                            0.0711732
trainer/entropy                              -6.02329
trainer/qf_loss                               6.0077
trainer/state_noise                           0.005
trainer/policy_loss                        -107.498
trainer/policy_loss_without_entropy         108.73
trainer/entropy_penalty                      -0.283425
trainer/entropy_percentage                   -0.00260668
trainer/Q1Pred Mean                         107.628
trainer/Q1Pred Std                           38.4995
trainer/Q1Pred Max                          168.452
trainer/Q1Pred Min                          -24.5158
trainer/Q2Pred Mean                         107.423
trainer/Q2Pred Std                           38.5546
trainer/Q2Pred Max                          167.038
trainer/Q2Pred Min                          -25.5199
trainer/QTargetWithReg Mean                 107.638
trainer/QTargetWithReg Std                   38.0437
trainer/QTargetWithReg Max                  166.621
trainer/QTargetWithReg Min                  -21.5315
trainer/PolicyLossWithoutReg Mean           108.73
trainer/PolicyLossWithoutReg Std             37.8298
trainer/PolicyLossWithoutReg Max            167.104
trainer/PolicyLossWithoutReg Min            -22.1147
trainer/gradient_norm                       189.664
trainer/gradient_penalty                     -0.948321
trainer/gradient_percentage                  -0.00872179
exploration/num steps total              208000
exploration/num paths total                1345
exploration/path length this epoch Mean     207
exploration/path length this epoch Std        0
exploration/path length this epoch Max      207
exploration/path length this epoch Min      207
exploration/Rewards Mean                      2.79573
exploration/Rewards Std                       1.8313
exploration/Rewards Max                       6.82457
exploration/Rewards Min                      -1.85031
exploration/Returns Mean                    578.716
exploration/Returns Std                       0
exploration/Returns Max                     578.716
exploration/Returns Min                     578.716
exploration/Num Paths                         1
exploration/Average Returns                 578.716
evaluation_0/num steps total                  1.58778e+06
evaluation_0/num paths total               8723
evaluation_0/path length Mean               941.375
evaluation_0/path length Std                 99.9599
evaluation_0/path length Max               1000
evaluation_0/path length Min                758
evaluation_0/Rewards Mean                     3.19284
evaluation_0/Rewards Std                      1.22475
evaluation_0/Rewards Max                      8.62436
evaluation_0/Rewards Min                     -0.318625
evaluation_0/Returns Mean                  3005.66
evaluation_0/Returns Std                    392.95
evaluation_0/Returns Max                   3828.56
evaluation_0/Returns Min                   2479.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3005.66
time/epoch (s)                                0
time/total (s)                             4049.66
Epoch                                       203
---------------------------------------  ----------------
2022-11-16 11:53:32.985354 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 204 finished
---------------------------------------  ----------------
epoch                                       204
total_step                               209000
replay_pool/size                         209000
trainer/alpha                                 0.0468586
trainer/alpha_loss                            1.11495
trainer/entropy                              -6.36429
trainer/qf_loss                               7.65043
trainer/state_noise                           0.005
trainer/policy_loss                        -105.836
trainer/policy_loss_without_entropy         107.104
trainer/entropy_penalty                      -0.298222
trainer/entropy_percentage                   -0.00278441
trainer/Q1Pred Mean                         106.269
trainer/Q1Pred Std                           36.4411
trainer/Q1Pred Max                          188.001
trainer/Q1Pred Min                            5.59108
trainer/Q2Pred Mean                         106.074
trainer/Q2Pred Std                           36.6239
trainer/Q2Pred Max                          187.765
trainer/Q2Pred Min                           -3.20422
trainer/QTargetWithReg Mean                 106.209
trainer/QTargetWithReg Std                   36.7018
trainer/QTargetWithReg Max                  189.713
trainer/QTargetWithReg Min                   -0.0699258
trainer/PolicyLossWithoutReg Mean           107.104
trainer/PolicyLossWithoutReg Std             35.5425
trainer/PolicyLossWithoutReg Max            187.907
trainer/PolicyLossWithoutReg Min             10.7313
trainer/gradient_norm                       193.838
trainer/gradient_penalty                     -0.969189
trainer/gradient_percentage                  -0.00904905
exploration/num steps total              209000
exploration/num paths total                1346
exploration/path length this epoch Mean     991
exploration/path length this epoch Std        0
exploration/path length this epoch Max      991
exploration/path length this epoch Min      991
exploration/Rewards Mean                      3.1981
exploration/Rewards Std                       1.10588
exploration/Rewards Max                       7.89927
exploration/Rewards Min                      -0.418259
exploration/Returns Mean                   3169.32
exploration/Returns Std                       0
exploration/Returns Max                    3169.32
exploration/Returns Min                    3169.32
exploration/Num Paths                         1
exploration/Average Returns                3169.32
evaluation_0/num steps total                  1.59515e+06
evaluation_0/num paths total               8731
evaluation_0/path length Mean               920.625
evaluation_0/path length Std                210.007
evaluation_0/path length Max               1000
evaluation_0/path length Min                365
evaluation_0/Rewards Mean                     2.64976
evaluation_0/Rewards Std                      0.851162
evaluation_0/Rewards Max                      7.42495
evaluation_0/Rewards Min                     -2.55195
evaluation_0/Returns Mean                  2439.44
evaluation_0/Returns Std                    611.925
evaluation_0/Returns Max                   2791.81
evaluation_0/Returns Min                    829.872
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2439.44
time/epoch (s)                                0
time/total (s)                             4066.91
Epoch                                       204
---------------------------------------  ----------------
2022-11-16 11:53:50.722827 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 205 finished
---------------------------------------  ----------------
epoch                                       205
total_step                               210000
replay_pool/size                         210000
trainer/alpha                                 0.0463865
trainer/alpha_loss                           -0.300343
trainer/entropy                              -5.90219
trainer/qf_loss                               5.62202
trainer/state_noise                           0.005
trainer/policy_loss                        -107.302
trainer/policy_loss_without_entropy         108.573
trainer/entropy_penalty                      -0.273782
trainer/entropy_percentage                   -0.00252164
trainer/Q1Pred Mean                         107.761
trainer/Q1Pred Std                           35.8496
trainer/Q1Pred Max                          172.451
trainer/Q1Pred Min                           -1.85025
trainer/Q2Pred Mean                         107.76
trainer/Q2Pred Std                           35.7996
trainer/Q2Pred Max                          172.335
trainer/Q2Pred Min                           -3.59641
trainer/QTargetWithReg Mean                 108.094
trainer/QTargetWithReg Std                   35.8195
trainer/QTargetWithReg Max                  173.462
trainer/QTargetWithReg Min                   -0.249502
trainer/PolicyLossWithoutReg Mean           108.573
trainer/PolicyLossWithoutReg Std             35.4865
trainer/PolicyLossWithoutReg Max            173.042
trainer/PolicyLossWithoutReg Min              4.6604
trainer/gradient_norm                       199.442
trainer/gradient_penalty                     -0.997211
trainer/gradient_percentage                  -0.0091847
exploration/num steps total              210000
exploration/num paths total                1348
exploration/path length this epoch Mean     227
exploration/path length this epoch Std      109
exploration/path length this epoch Max      336
exploration/path length this epoch Min      118
exploration/Rewards Mean                      3.43349
exploration/Rewards Std                       1.46098
exploration/Rewards Max                       7.83759
exploration/Rewards Min                      -0.526477
exploration/Returns Mean                    779.401
exploration/Returns Std                     464.389
exploration/Returns Max                    1243.79
exploration/Returns Min                     315.012
exploration/Num Paths                         2
exploration/Average Returns                 779.401
evaluation_0/num steps total                  1.60274e+06
evaluation_0/num paths total               8744
evaluation_0/path length Mean               584.077
evaluation_0/path length Std                170.735
evaluation_0/path length Max               1000
evaluation_0/path length Min                301
evaluation_0/Rewards Mean                     3.4568
evaluation_0/Rewards Std                      1.33213
evaluation_0/Rewards Max                      8.46883
evaluation_0/Rewards Min                     -0.474259
evaluation_0/Returns Mean                  2019.04
evaluation_0/Returns Std                    576.747
evaluation_0/Returns Max                   3423.76
evaluation_0/Returns Min                   1131.08
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2019.04
time/epoch (s)                                0
time/total (s)                             4084.65
Epoch                                       205
---------------------------------------  ----------------
2022-11-16 11:54:08.093038 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 206 finished
---------------------------------------  ----------------
epoch                                       206
total_step                               211000
replay_pool/size                         211000
trainer/alpha                                 0.0459032
trainer/alpha_loss                            0.0984415
trainer/entropy                              -6.03195
trainer/qf_loss                               6.57596
trainer/state_noise                           0.005
trainer/policy_loss                        -113.003
trainer/policy_loss_without_entropy         114.269
trainer/entropy_penalty                      -0.276886
trainer/entropy_percentage                   -0.00242309
trainer/Q1Pred Mean                         113.835
trainer/Q1Pred Std                           35.0849
trainer/Q1Pred Max                          195.115
trainer/Q1Pred Min                           -1.70538
trainer/Q2Pred Mean                         113.927
trainer/Q2Pred Std                           35.2017
trainer/Q2Pred Max                          196.882
trainer/Q2Pred Min                           -2.30429
trainer/QTargetWithReg Mean                 113.837
trainer/QTargetWithReg Std                   35.0496
trainer/QTargetWithReg Max                  196.268
trainer/QTargetWithReg Min                   -2.39533
trainer/PolicyLossWithoutReg Mean           114.269
trainer/PolicyLossWithoutReg Std             34.6762
trainer/PolicyLossWithoutReg Max            195.31
trainer/PolicyLossWithoutReg Min             -1.76978
trainer/gradient_norm                       197.857
trainer/gradient_penalty                     -0.989283
trainer/gradient_percentage                  -0.00865746
exploration/num steps total              211000
exploration/num paths total                1351
exploration/path length this epoch Mean     323.333
exploration/path length this epoch Std      162.309
exploration/path length this epoch Max      528
exploration/path length this epoch Min      131
exploration/Rewards Mean                      3.31575
exploration/Rewards Std                       1.43213
exploration/Rewards Max                       8.35475
exploration/Rewards Min                      -0.668965
exploration/Returns Mean                   1072.09
exploration/Returns Std                     647.87
exploration/Returns Max                    1843.01
exploration/Returns Min                     257.836
exploration/Num Paths                         3
exploration/Average Returns                1072.09
evaluation_0/num steps total                  1.61057e+06
evaluation_0/num paths total               8755
evaluation_0/path length Mean               711.455
evaluation_0/path length Std                220.101
evaluation_0/path length Max               1000
evaluation_0/path length Min                388
evaluation_0/Rewards Mean                     3.3174
evaluation_0/Rewards Std                      1.30345
evaluation_0/Rewards Max                      8.45718
evaluation_0/Rewards Min                     -0.629311
evaluation_0/Returns Mean                  2360.18
evaluation_0/Returns Std                    703.701
evaluation_0/Returns Max                   3454.14
evaluation_0/Returns Min                   1510.45
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2360.18
time/epoch (s)                                0
time/total (s)                             4102.02
Epoch                                       206
---------------------------------------  ----------------
2022-11-16 11:54:25.540817 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 207 finished
---------------------------------------  ----------------
epoch                                       207
total_step                               212000
replay_pool/size                         212000
trainer/alpha                                 0.0463959
trainer/alpha_loss                            1.29396
trainer/entropy                              -6.42142
trainer/qf_loss                              11.4206
trainer/state_noise                           0.005
trainer/policy_loss                        -107.443
trainer/policy_loss_without_entropy         108.731
trainer/entropy_penalty                      -0.297927
trainer/entropy_percentage                   -0.00274005
trainer/Q1Pred Mean                         107.31
trainer/Q1Pred Std                           36.5167
trainer/Q1Pred Max                          168.489
trainer/Q1Pred Min                           -3.13924
trainer/Q2Pred Mean                         107.28
trainer/Q2Pred Std                           36.5848
trainer/Q2Pred Max                          170.726
trainer/Q2Pred Min                           -2.92176
trainer/QTargetWithReg Mean                 108.113
trainer/QTargetWithReg Std                   36.7033
trainer/QTargetWithReg Max                  169.736
trainer/QTargetWithReg Min                   -0.462485
trainer/PolicyLossWithoutReg Mean           108.731
trainer/PolicyLossWithoutReg Std             36.2444
trainer/PolicyLossWithoutReg Max            169.05
trainer/PolicyLossWithoutReg Min              1.0384
trainer/gradient_norm                       198.015
trainer/gradient_penalty                     -0.990077
trainer/gradient_percentage                  -0.00910577
exploration/num steps total              212000
exploration/num paths total                1352
exploration/path length this epoch Mean     645
exploration/path length this epoch Std        0
exploration/path length this epoch Max      645
exploration/path length this epoch Min      645
exploration/Rewards Mean                      3.395
exploration/Rewards Std                       1.28964
exploration/Rewards Max                       7.48051
exploration/Rewards Min                      -0.564151
exploration/Returns Mean                   2189.77
exploration/Returns Std                       0
exploration/Returns Max                    2189.77
exploration/Returns Min                    2189.77
exploration/Num Paths                         1
exploration/Average Returns                2189.77
evaluation_0/num steps total                  1.61817e+06
evaluation_0/num paths total               8767
evaluation_0/path length Mean               633.333
evaluation_0/path length Std                152.629
evaluation_0/path length Max                923
evaluation_0/path length Min                390
evaluation_0/Rewards Mean                     3.38735
evaluation_0/Rewards Std                      1.41623
evaluation_0/Rewards Max                      9.08719
evaluation_0/Rewards Min                     -0.366053
evaluation_0/Returns Mean                  2145.32
evaluation_0/Returns Std                    634.757
evaluation_0/Returns Max                   3418.61
evaluation_0/Returns Min                   1021.72
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2145.32
time/epoch (s)                                0
time/total (s)                             4119.47
Epoch                                       207
---------------------------------------  ----------------
2022-11-16 11:54:42.928773 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 208 finished
---------------------------------------  ----------------
epoch                                       208
total_step                               213000
replay_pool/size                         213000
trainer/alpha                                 0.0468774
trainer/alpha_loss                            1.27698
trainer/entropy                              -6.41728
trainer/qf_loss                               5.68693
trainer/state_noise                           0.005
trainer/policy_loss                        -107.628
trainer/policy_loss_without_entropy         108.9
trainer/entropy_penalty                      -0.300826
trainer/entropy_percentage                   -0.00276239
trainer/Q1Pred Mean                         107.992
trainer/Q1Pred Std                           38.3424
trainer/Q1Pred Max                          177.751
trainer/Q1Pred Min                          -36.4653
trainer/Q2Pred Mean                         108.211
trainer/Q2Pred Std                           38.4202
trainer/Q2Pred Max                          178.407
trainer/Q2Pred Min                          -35.8403
trainer/QTargetWithReg Mean                 108.564
trainer/QTargetWithReg Std                   38.2539
trainer/QTargetWithReg Max                  177.487
trainer/QTargetWithReg Min                  -21.3645
trainer/PolicyLossWithoutReg Mean           108.9
trainer/PolicyLossWithoutReg Std             38.1683
trainer/PolicyLossWithoutReg Max            177.905
trainer/PolicyLossWithoutReg Min            -30.8334
trainer/gradient_norm                       194.278
trainer/gradient_penalty                     -0.971389
trainer/gradient_percentage                  -0.00891997
exploration/num steps total              213000
exploration/num paths total                1353
exploration/path length this epoch Mean     705
exploration/path length this epoch Std        0
exploration/path length this epoch Max      705
exploration/path length this epoch Min      705
exploration/Rewards Mean                      3.60158
exploration/Rewards Std                       1.23221
exploration/Rewards Max                       7.58204
exploration/Rewards Min                      -0.402376
exploration/Returns Mean                   2539.12
exploration/Returns Std                       0
exploration/Returns Max                    2539.12
exploration/Returns Min                    2539.12
exploration/Num Paths                         1
exploration/Average Returns                2539.12
evaluation_0/num steps total                  1.62531e+06
evaluation_0/num paths total               8775
evaluation_0/path length Mean               892.25
evaluation_0/path length Std                156.766
evaluation_0/path length Max               1000
evaluation_0/path length Min                549
evaluation_0/Rewards Mean                     3.30915
evaluation_0/Rewards Std                      1.28464
evaluation_0/Rewards Max                      8.9774
evaluation_0/Rewards Min                     -0.790932
evaluation_0/Returns Mean                  2952.59
evaluation_0/Returns Std                    478.886
evaluation_0/Returns Max                   3442.9
evaluation_0/Returns Min                   1881.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2952.59
time/epoch (s)                                0
time/total (s)                             4136.85
Epoch                                       208
---------------------------------------  ----------------
2022-11-16 11:55:00.729386 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 209 finished
---------------------------------------  ----------------
epoch                                       209
total_step                               214000
replay_pool/size                         214000
trainer/alpha                                 0.0470902
trainer/alpha_loss                           -1.24156
trainer/entropy                              -5.59366
trainer/qf_loss                               6.443
trainer/state_noise                           0.005
trainer/policy_loss                        -106.686
trainer/policy_loss_without_entropy         107.921
trainer/entropy_penalty                      -0.263406
trainer/entropy_percentage                   -0.00244074
trainer/Q1Pred Mean                         106.888
trainer/Q1Pred Std                           38.7946
trainer/Q1Pred Max                          183.004
trainer/Q1Pred Min                          -10.3778
trainer/Q2Pred Mean                         106.855
trainer/Q2Pred Std                           38.5435
trainer/Q2Pred Max                          178.382
trainer/Q2Pred Min                           -7.36376
trainer/QTargetWithReg Mean                 106.578
trainer/QTargetWithReg Std                   38.9727
trainer/QTargetWithReg Max                  183.125
trainer/QTargetWithReg Min                   -3.94849
trainer/PolicyLossWithoutReg Mean           107.921
trainer/PolicyLossWithoutReg Std             37.558
trainer/PolicyLossWithoutReg Max            178.508
trainer/PolicyLossWithoutReg Min             -7.05042
trainer/gradient_norm                       194.206
trainer/gradient_penalty                     -0.971031
trainer/gradient_percentage                  -0.00899763
exploration/num steps total              214000
exploration/num paths total                1354
exploration/path length this epoch Mean     615
exploration/path length this epoch Std        0
exploration/path length this epoch Max      615
exploration/path length this epoch Min      615
exploration/Rewards Mean                      3.90886
exploration/Rewards Std                       1.55444
exploration/Rewards Max                       8.45894
exploration/Rewards Min                      -0.601346
exploration/Returns Mean                   2403.95
exploration/Returns Std                       0
exploration/Returns Max                    2403.95
exploration/Returns Min                    2403.95
exploration/Num Paths                         1
exploration/Average Returns                2403.95
evaluation_0/num steps total                  1.63296e+06
evaluation_0/num paths total               8784
evaluation_0/path length Mean               850.222
evaluation_0/path length Std                241.056
evaluation_0/path length Max               1000
evaluation_0/path length Min                283
evaluation_0/Rewards Mean                     3.03034
evaluation_0/Rewards Std                      1.34213
evaluation_0/Rewards Max                      8.87734
evaluation_0/Rewards Min                     -0.455944
evaluation_0/Returns Mean                  2576.46
evaluation_0/Returns Std                    792.765
evaluation_0/Returns Max                   3569.74
evaluation_0/Returns Min                    865.138
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2576.46
time/epoch (s)                                0
time/total (s)                             4154.65
Epoch                                       209
---------------------------------------  ----------------
2022-11-16 11:55:17.397155 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 210 finished
---------------------------------------  ----------------
epoch                                       210
total_step                               215000
replay_pool/size                         215000
trainer/alpha                                 0.0476608
trainer/alpha_loss                           -2.22757
trainer/entropy                              -5.26811
trainer/qf_loss                               7.06573
trainer/state_noise                           0.005
trainer/policy_loss                        -110.279
trainer/policy_loss_without_entropy         111.476
trainer/entropy_penalty                      -0.251082
trainer/entropy_percentage                   -0.00225234
trainer/Q1Pred Mean                         110.297
trainer/Q1Pred Std                           35.8346
trainer/Q1Pred Max                          163.54
trainer/Q1Pred Min                           -3.31406
trainer/Q2Pred Mean                         109.908
trainer/Q2Pred Std                           36.1347
trainer/Q2Pred Max                          163.143
trainer/Q2Pred Min                          -21.8968
trainer/QTargetWithReg Mean                 110.674
trainer/QTargetWithReg Std                   35.8176
trainer/QTargetWithReg Max                  164.222
trainer/QTargetWithReg Min                    0.0472331
trainer/PolicyLossWithoutReg Mean           111.476
trainer/PolicyLossWithoutReg Std             35.0235
trainer/PolicyLossWithoutReg Max            164.302
trainer/PolicyLossWithoutReg Min             11.6733
trainer/gradient_norm                       189.13
trainer/gradient_penalty                     -0.945652
trainer/gradient_percentage                  -0.00848299
exploration/num steps total              215000
exploration/num paths total                1355
exploration/path length this epoch Mean     658
exploration/path length this epoch Std        0
exploration/path length this epoch Max      658
exploration/path length this epoch Min      658
exploration/Rewards Mean                      2.6906
exploration/Rewards Std                       1.35925
exploration/Rewards Max                       6.73325
exploration/Rewards Min                      -0.902454
exploration/Returns Mean                   1770.41
exploration/Returns Std                       0
exploration/Returns Max                    1770.41
exploration/Returns Min                    1770.41
exploration/Num Paths                         1
exploration/Average Returns                1770.41
evaluation_0/num steps total                  1.64048e+06
evaluation_0/num paths total               8797
evaluation_0/path length Mean               578.385
evaluation_0/path length Std                172.835
evaluation_0/path length Max                863
evaluation_0/path length Min                121
evaluation_0/Rewards Mean                     3.36514
evaluation_0/Rewards Std                      1.4823
evaluation_0/Rewards Max                      9.03364
evaluation_0/Rewards Min                     -0.461599
evaluation_0/Returns Mean                  1946.35
evaluation_0/Returns Std                    676.131
evaluation_0/Returns Max                   2882.45
evaluation_0/Returns Min                    282.388
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               1946.35
time/epoch (s)                                0
time/total (s)                             4171.32
Epoch                                       210
---------------------------------------  ----------------
2022-11-16 11:55:34.679951 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 211 finished
---------------------------------------  ---------------
epoch                                       211
total_step                               216000
replay_pool/size                         216000
trainer/alpha                                 0.0456113
trainer/alpha_loss                            0.568316
trainer/entropy                              -6.18405
trainer/qf_loss                               6.35842
trainer/state_noise                           0.005
trainer/policy_loss                        -106.979
trainer/policy_loss_without_entropy         108.188
trainer/entropy_penalty                      -0.282063
trainer/entropy_percentage                   -0.00260715
trainer/Q1Pred Mean                         107.775
trainer/Q1Pred Std                           39.3637
trainer/Q1Pred Max                          176.247
trainer/Q1Pred Min                           -3.47251
trainer/Q2Pred Mean                         108.138
trainer/Q2Pred Std                           39.476
trainer/Q2Pred Max                          179.877
trainer/Q2Pred Min                           -8.32162
trainer/QTargetWithReg Mean                 107.69
trainer/QTargetWithReg Std                   39.5116
trainer/QTargetWithReg Max                  178.081
trainer/QTargetWithReg Min                    0.167506
trainer/PolicyLossWithoutReg Mean           108.188
trainer/PolicyLossWithoutReg Std             38.8957
trainer/PolicyLossWithoutReg Max            175.481
trainer/PolicyLossWithoutReg Min              4.11652
trainer/gradient_norm                       185.475
trainer/gradient_penalty                     -0.927373
trainer/gradient_percentage                  -0.00857186
exploration/num steps total              216000
exploration/num paths total                1356
exploration/path length this epoch Mean     517
exploration/path length this epoch Std        0
exploration/path length this epoch Max      517
exploration/path length this epoch Min      517
exploration/Rewards Mean                      2.94347
exploration/Rewards Std                       1.60235
exploration/Rewards Max                       7.88412
exploration/Rewards Min                      -0.205353
exploration/Returns Mean                   1521.78
exploration/Returns Std                       0
exploration/Returns Max                    1521.78
exploration/Returns Min                    1521.78
exploration/Num Paths                         1
exploration/Average Returns                1521.78
evaluation_0/num steps total                  1.6484e+06
evaluation_0/num paths total               8807
evaluation_0/path length Mean               791.9
evaluation_0/path length Std                147.148
evaluation_0/path length Max               1000
evaluation_0/path length Min                576
evaluation_0/Rewards Mean                     3.39031
evaluation_0/Rewards Std                      1.511
evaluation_0/Rewards Max                      9.02559
evaluation_0/Rewards Min                     -0.565698
evaluation_0/Returns Mean                  2684.79
evaluation_0/Returns Std                    488.783
evaluation_0/Returns Max                   3504.07
evaluation_0/Returns Min                   1818.35
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2684.79
time/epoch (s)                                0
time/total (s)                             4188.6
Epoch                                       211
---------------------------------------  ---------------
2022-11-16 11:55:54.941769 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 212 finished
---------------------------------------  ----------------
epoch                                       212
total_step                               217000
replay_pool/size                         217000
trainer/alpha                                 0.0454881
trainer/alpha_loss                            0.888093
trainer/entropy                              -6.28738
trainer/qf_loss                               7.16861
trainer/state_noise                           0.005
trainer/policy_loss                        -105.24
trainer/policy_loss_without_entropy         106.529
trainer/entropy_penalty                      -0.286001
trainer/entropy_percentage                   -0.00268472
trainer/Q1Pred Mean                         105.726
trainer/Q1Pred Std                           37.2647
trainer/Q1Pred Max                          167.582
trainer/Q1Pred Min                          -19.532
trainer/Q2Pred Mean                         105.826
trainer/Q2Pred Std                           37.1626
trainer/Q2Pred Max                          167.346
trainer/Q2Pred Min                          -20.0976
trainer/QTargetWithReg Mean                 105.744
trainer/QTargetWithReg Std                   37.4596
trainer/QTargetWithReg Max                  167.643
trainer/QTargetWithReg Min                  -16.9618
trainer/PolicyLossWithoutReg Mean           106.529
trainer/PolicyLossWithoutReg Std             36.4943
trainer/PolicyLossWithoutReg Max            167.081
trainer/PolicyLossWithoutReg Min            -14.1453
trainer/gradient_norm                       200.664
trainer/gradient_penalty                     -1.00332
trainer/gradient_percentage                  -0.00941828
exploration/num steps total              217000
exploration/num paths total                1358
exploration/path length this epoch Mean     383.5
exploration/path length this epoch Std      234.5
exploration/path length this epoch Max      618
exploration/path length this epoch Min      149
exploration/Rewards Mean                      3.63986
exploration/Rewards Std                       1.51309
exploration/Rewards Max                       8.61433
exploration/Rewards Min                      -0.575883
exploration/Returns Mean                   1395.89
exploration/Returns Std                    1002.57
exploration/Returns Max                    2398.46
exploration/Returns Min                     393.314
exploration/Num Paths                         2
exploration/Average Returns                1395.89
evaluation_0/num steps total                  1.65601e+06
evaluation_0/num paths total               8839
evaluation_0/path length Mean               237.844
evaluation_0/path length Std                200.484
evaluation_0/path length Max                984
evaluation_0/path length Min                114
evaluation_0/Rewards Mean                     2.71748
evaluation_0/Rewards Std                      1.66767
evaluation_0/Rewards Max                      8.74572
evaluation_0/Rewards Min                     -1.43533
evaluation_0/Returns Mean                   646.335
evaluation_0/Returns Std                    839.379
evaluation_0/Returns Max                   3935.79
evaluation_0/Returns Min                    195.185
evaluation_0/Num Paths                       32
evaluation_0/Average Returns                646.335
time/epoch (s)                                0
time/total (s)                             4208.87
Epoch                                       212
---------------------------------------  ----------------
2022-11-16 11:56:12.967239 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 213 finished
---------------------------------------  ----------------
epoch                                       213
total_step                               218000
replay_pool/size                         218000
trainer/alpha                                 0.0457761
trainer/alpha_loss                            0.444453
trainer/entropy                              -6.14412
trainer/qf_loss                               5.72584
trainer/state_noise                           0.005
trainer/policy_loss                        -110.753
trainer/policy_loss_without_entropy         111.999
trainer/entropy_penalty                      -0.281254
trainer/entropy_percentage                   -0.00251121
trainer/Q1Pred Mean                         111.172
trainer/Q1Pred Std                           38.3711
trainer/Q1Pred Max                          201.621
trainer/Q1Pred Min                          -17.4709
trainer/Q2Pred Mean                         111.294
trainer/Q2Pred Std                           38.5483
trainer/Q2Pred Max                          202.946
trainer/Q2Pred Min                          -18.2429
trainer/QTargetWithReg Mean                 110.935
trainer/QTargetWithReg Std                   38.6493
trainer/QTargetWithReg Max                  201.994
trainer/QTargetWithReg Min                  -18.4212
trainer/PolicyLossWithoutReg Mean           111.999
trainer/PolicyLossWithoutReg Std             37.8499
trainer/PolicyLossWithoutReg Max            201.414
trainer/PolicyLossWithoutReg Min            -14.1762
trainer/gradient_norm                       192.919
trainer/gradient_penalty                     -0.964595
trainer/gradient_percentage                  -0.00861253
exploration/num steps total              218000
exploration/num paths total                1359
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.87099
exploration/Rewards Std                       1.42286
exploration/Rewards Max                       8.48549
exploration/Rewards Min                      -0.460668
exploration/Returns Mean                   3870.99
exploration/Returns Std                       0
exploration/Returns Max                    3870.99
exploration/Returns Min                    3870.99
exploration/Num Paths                         1
exploration/Average Returns                3870.99
evaluation_0/num steps total                  1.66367e+06
evaluation_0/num paths total               8856
evaluation_0/path length Mean               450.824
evaluation_0/path length Std                252.713
evaluation_0/path length Max               1000
evaluation_0/path length Min                182
evaluation_0/Rewards Mean                     2.76231
evaluation_0/Rewards Std                      1.38424
evaluation_0/Rewards Max                      9.12233
evaluation_0/Rewards Min                     -0.502232
evaluation_0/Returns Mean                  1245.31
evaluation_0/Returns Std                    786.563
evaluation_0/Returns Max                   3626.51
evaluation_0/Returns Min                    451.318
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               1245.31
time/epoch (s)                                0
time/total (s)                             4226.89
Epoch                                       213
---------------------------------------  ----------------
2022-11-16 11:56:30.720551 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 214 finished
---------------------------------------  ----------------
epoch                                       214
total_step                               219000
replay_pool/size                         219000
trainer/alpha                                 0.0476512
trainer/alpha_loss                           -0.697445
trainer/entropy                              -5.77086
trainer/qf_loss                               4.58857
trainer/state_noise                           0.005
trainer/policy_loss                        -109.881
trainer/policy_loss_without_entropy         111.112
trainer/entropy_penalty                      -0.274988
trainer/entropy_percentage                   -0.00247486
trainer/Q1Pred Mean                         110.789
trainer/Q1Pred Std                           38.3426
trainer/Q1Pred Max                          180.285
trainer/Q1Pred Min                          -23.5289
trainer/Q2Pred Mean                         110.691
trainer/Q2Pred Std                           38.4219
trainer/Q2Pred Max                          181.632
trainer/Q2Pred Min                          -20.3694
trainer/QTargetWithReg Mean                 110.261
trainer/QTargetWithReg Std                   38.2231
trainer/QTargetWithReg Max                  180.962
trainer/QTargetWithReg Min                  -23.8932
trainer/PolicyLossWithoutReg Mean           111.112
trainer/PolicyLossWithoutReg Std             38.0687
trainer/PolicyLossWithoutReg Max            179.946
trainer/PolicyLossWithoutReg Min            -18.2751
trainer/gradient_norm                       191.243
trainer/gradient_penalty                     -0.956213
trainer/gradient_percentage                  -0.00860581
exploration/num steps total              219000
exploration/num paths total                1360
exploration/path length this epoch Mean     638
exploration/path length this epoch Std        0
exploration/path length this epoch Max      638
exploration/path length this epoch Min      638
exploration/Rewards Mean                      3.68481
exploration/Rewards Std                       1.39021
exploration/Rewards Max                       7.4894
exploration/Rewards Min                      -0.497697
exploration/Returns Mean                   2350.91
exploration/Returns Std                       0
exploration/Returns Max                    2350.91
exploration/Returns Min                    2350.91
exploration/Num Paths                         1
exploration/Average Returns                2350.91
evaluation_0/num steps total                  1.67159e+06
evaluation_0/num paths total               8869
evaluation_0/path length Mean               609.231
evaluation_0/path length Std                216.504
evaluation_0/path length Max               1000
evaluation_0/path length Min                232
evaluation_0/Rewards Mean                     3.56327
evaluation_0/Rewards Std                      1.34222
evaluation_0/Rewards Max                      8.41893
evaluation_0/Rewards Min                     -0.468539
evaluation_0/Returns Mean                  2170.85
evaluation_0/Returns Std                    822.848
evaluation_0/Returns Max                   3680.36
evaluation_0/Returns Min                    687.112
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2170.85
time/epoch (s)                                0
time/total (s)                             4244.64
Epoch                                       214
---------------------------------------  ----------------
2022-11-16 11:56:48.191673 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 215 finished
---------------------------------------  ----------------
epoch                                       215
total_step                               220000
replay_pool/size                         220000
trainer/alpha                                 0.0480256
trainer/alpha_loss                           -0.212025
trainer/entropy                              -5.93016
trainer/qf_loss                               4.8115
trainer/state_noise                           0.005
trainer/policy_loss                        -107.679
trainer/policy_loss_without_entropy         108.91
trainer/entropy_penalty                      -0.2848
trainer/entropy_percentage                   -0.00261499
trainer/Q1Pred Mean                         108.748
trainer/Q1Pred Std                           38.8897
trainer/Q1Pred Max                          171.136
trainer/Q1Pred Min                           -5.9822
trainer/Q2Pred Mean                         108.497
trainer/Q2Pred Std                           38.8228
trainer/Q2Pred Max                          173.405
trainer/Q2Pred Min                           -4.66456
trainer/QTargetWithReg Mean                 108.346
trainer/QTargetWithReg Std                   38.5828
trainer/QTargetWithReg Max                  171.81
trainer/QTargetWithReg Min                   -8.44084
trainer/PolicyLossWithoutReg Mean           108.91
trainer/PolicyLossWithoutReg Std             38.2938
trainer/PolicyLossWithoutReg Max            170.337
trainer/PolicyLossWithoutReg Min             -3.45683
trainer/gradient_norm                       189.391
trainer/gradient_penalty                     -0.946956
trainer/gradient_percentage                  -0.00869481
exploration/num steps total              220000
exploration/num paths total                1363
exploration/path length this epoch Mean     320.667
exploration/path length this epoch Std       76.9949
exploration/path length this epoch Max      399
exploration/path length this epoch Min      216
exploration/Rewards Mean                      3.30384
exploration/Rewards Std                       1.388
exploration/Rewards Max                       8.55655
exploration/Rewards Min                      -0.563256
exploration/Returns Mean                   1059.43
exploration/Returns Std                     307.827
exploration/Returns Max                    1324.02
exploration/Returns Min                     627.753
exploration/Num Paths                         3
exploration/Average Returns                1059.43
evaluation_0/num steps total                  1.67878e+06
evaluation_0/num paths total               8880
evaluation_0/path length Mean               653.273
evaluation_0/path length Std                344.837
evaluation_0/path length Max               1000
evaluation_0/path length Min                185
evaluation_0/Rewards Mean                     2.96799
evaluation_0/Rewards Std                      1.21489
evaluation_0/Rewards Max                      8.18583
evaluation_0/Rewards Min                     -0.616987
evaluation_0/Returns Mean                  1938.9
evaluation_0/Returns Std                   1087.91
evaluation_0/Returns Max                   3268.29
evaluation_0/Returns Min                    335.429
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               1938.9
time/epoch (s)                                0
time/total (s)                             4262.11
Epoch                                       215
---------------------------------------  ----------------
2022-11-16 11:57:06.639175 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 216 finished
---------------------------------------  ----------------
epoch                                       216
total_step                               221000
replay_pool/size                         221000
trainer/alpha                                 0.0487551
trainer/alpha_loss                           -0.707323
trainer/entropy                              -5.76586
trainer/qf_loss                               7.34241
trainer/state_noise                           0.005
trainer/policy_loss                        -109.919
trainer/policy_loss_without_entropy         111.125
trainer/entropy_penalty                      -0.281115
trainer/entropy_percentage                   -0.00252971
trainer/Q1Pred Mean                         110.58
trainer/Q1Pred Std                           39.0904
trainer/Q1Pred Max                          177.439
trainer/Q1Pred Min                           -3.7337
trainer/Q2Pred Mean                         110.601
trainer/Q2Pred Std                           38.9534
trainer/Q2Pred Max                          180.659
trainer/Q2Pred Min                          -12.1866
trainer/QTargetWithReg Mean                 110.457
trainer/QTargetWithReg Std                   38.9298
trainer/QTargetWithReg Max                  180.938
trainer/QTargetWithReg Min                   -5.64995
trainer/PolicyLossWithoutReg Mean           111.125
trainer/PolicyLossWithoutReg Std             38.4687
trainer/PolicyLossWithoutReg Max            179.466
trainer/PolicyLossWithoutReg Min             -2.90154
trainer/gradient_norm                       184.979
trainer/gradient_penalty                     -0.924896
trainer/gradient_percentage                  -0.00832299
exploration/num steps total              221000
exploration/num paths total                1365
exploration/path length this epoch Mean     444.5
exploration/path length this epoch Std       23.5
exploration/path length this epoch Max      468
exploration/path length this epoch Min      421
exploration/Rewards Mean                      3.13431
exploration/Rewards Std                       1.32748
exploration/Rewards Max                       7.07302
exploration/Rewards Min                      -0.528155
exploration/Returns Mean                   1393.2
exploration/Returns Std                      81.4128
exploration/Returns Max                    1474.61
exploration/Returns Min                    1311.79
exploration/Num Paths                         2
exploration/Average Returns                1393.2
evaluation_0/num steps total                  1.68672e+06
evaluation_0/num paths total               8899
evaluation_0/path length Mean               418.053
evaluation_0/path length Std                253.642
evaluation_0/path length Max               1000
evaluation_0/path length Min                128
evaluation_0/Rewards Mean                     2.89931
evaluation_0/Rewards Std                      1.35379
evaluation_0/Rewards Max                      8.64781
evaluation_0/Rewards Min                     -0.728804
evaluation_0/Returns Mean                  1212.06
evaluation_0/Returns Std                    878.206
evaluation_0/Returns Max                   3571.41
evaluation_0/Returns Min                    273.199
evaluation_0/Num Paths                       19
evaluation_0/Average Returns               1212.06
time/epoch (s)                                0
time/total (s)                             4280.56
Epoch                                       216
---------------------------------------  ----------------
2022-11-16 11:57:24.052802 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 217 finished
---------------------------------------  ----------------
epoch                                       217
total_step                               222000
replay_pool/size                         222000
trainer/alpha                                 0.0487712
trainer/alpha_loss                            0.594762
trainer/entropy                              -6.1969
trainer/qf_loss                               5.32366
trainer/state_noise                           0.005
trainer/policy_loss                        -111.798
trainer/policy_loss_without_entropy         113.129
trainer/entropy_penalty                      -0.30223
trainer/entropy_percentage                   -0.00267155
trainer/Q1Pred Mean                         111.719
trainer/Q1Pred Std                           38.687
trainer/Q1Pred Max                          175.199
trainer/Q1Pred Min                          -18.0026
trainer/Q2Pred Mean                         112.188
trainer/Q2Pred Std                           38.4121
trainer/Q2Pred Max                          174.562
trainer/Q2Pred Min                          -19.4253
trainer/QTargetWithReg Mean                 111.906
trainer/QTargetWithReg Std                   38.8036
trainer/QTargetWithReg Max                  175.618
trainer/QTargetWithReg Min                  -21.8087
trainer/PolicyLossWithoutReg Mean           113.129
trainer/PolicyLossWithoutReg Std             38.0971
trainer/PolicyLossWithoutReg Max            175.57
trainer/PolicyLossWithoutReg Min            -17.8979
trainer/gradient_norm                       205.827
trainer/gradient_penalty                     -1.02914
trainer/gradient_percentage                  -0.00909701
exploration/num steps total              222000
exploration/num paths total                1366
exploration/path length this epoch Mean     386
exploration/path length this epoch Std        0
exploration/path length this epoch Max      386
exploration/path length this epoch Min      386
exploration/Rewards Mean                      3.2335
exploration/Rewards Std                       1.1954
exploration/Rewards Max                       6.45376
exploration/Rewards Min                      -0.554214
exploration/Returns Mean                   1248.13
exploration/Returns Std                       0
exploration/Returns Max                    1248.13
exploration/Returns Min                    1248.13
exploration/Num Paths                         1
exploration/Average Returns                1248.13
evaluation_0/num steps total                  1.69451e+06
evaluation_0/num paths total               8921
evaluation_0/path length Mean               354.182
evaluation_0/path length Std                138.785
evaluation_0/path length Max                796
evaluation_0/path length Min                204
evaluation_0/Rewards Mean                     3.44462
evaluation_0/Rewards Std                      1.33256
evaluation_0/Rewards Max                      8.4436
evaluation_0/Rewards Min                     -0.37602
evaluation_0/Returns Mean                  1220.02
evaluation_0/Returns Std                    545.938
evaluation_0/Returns Max                   3059.97
evaluation_0/Returns Min                    665.458
evaluation_0/Num Paths                       22
evaluation_0/Average Returns               1220.02
time/epoch (s)                                0
time/total (s)                             4297.97
Epoch                                       217
---------------------------------------  ----------------
2022-11-16 11:57:41.714641 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 218 finished
---------------------------------------  ----------------
epoch                                       218
total_step                               223000
replay_pool/size                         223000
trainer/alpha                                 0.0484321
trainer/alpha_loss                            0.915348
trainer/entropy                              -6.30232
trainer/qf_loss                               5.72983
trainer/state_noise                           0.005
trainer/policy_loss                        -107.751
trainer/policy_loss_without_entropy         109.068
trainer/entropy_penalty                      -0.305235
trainer/entropy_percentage                   -0.00279857
trainer/Q1Pred Mean                         108.113
trainer/Q1Pred Std                           41.4576
trainer/Q1Pred Max                          175.216
trainer/Q1Pred Min                           -5.24875
trainer/Q2Pred Mean                         107.748
trainer/Q2Pred Std                           41.4483
trainer/Q2Pred Max                          174.786
trainer/Q2Pred Min                           -4.39852
trainer/QTargetWithReg Mean                 108.142
trainer/QTargetWithReg Std                   41.4113
trainer/QTargetWithReg Max                  175.125
trainer/QTargetWithReg Min                   -4.31479
trainer/PolicyLossWithoutReg Mean           109.068
trainer/PolicyLossWithoutReg Std             41.0754
trainer/PolicyLossWithoutReg Max            174.348
trainer/PolicyLossWithoutReg Min              0.605666
trainer/gradient_norm                       202.322
trainer/gradient_penalty                     -1.01161
trainer/gradient_percentage                  -0.00927502
exploration/num steps total              223000
exploration/num paths total                1367
exploration/path length this epoch Mean     512
exploration/path length this epoch Std        0
exploration/path length this epoch Max      512
exploration/path length this epoch Min      512
exploration/Rewards Mean                      3.65584
exploration/Rewards Std                       1.24225
exploration/Rewards Max                       7.22305
exploration/Rewards Min                      -0.290723
exploration/Returns Mean                   1871.79
exploration/Returns Std                       0
exploration/Returns Max                    1871.79
exploration/Returns Min                    1871.79
exploration/Num Paths                         1
exploration/Average Returns                1871.79
evaluation_0/num steps total                  1.70249e+06
evaluation_0/num paths total               8933
evaluation_0/path length Mean               664.583
evaluation_0/path length Std                351.666
evaluation_0/path length Max               1000
evaluation_0/path length Min                240
evaluation_0/Rewards Mean                     3.44699
evaluation_0/Rewards Std                      1.04065
evaluation_0/Rewards Max                      7.68594
evaluation_0/Rewards Min                     -0.371181
evaluation_0/Returns Mean                  2290.81
evaluation_0/Returns Std                   1233.86
evaluation_0/Returns Max                   3531.45
evaluation_0/Returns Min                    779.801
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2290.81
time/epoch (s)                                0
time/total (s)                             4315.64
Epoch                                       218
---------------------------------------  ----------------
2022-11-16 11:57:57.527653 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 219 finished
---------------------------------------  ----------------
epoch                                       219
total_step                               224000
replay_pool/size                         224000
trainer/alpha                                 0.0494279
trainer/alpha_loss                           -0.576995
trainer/entropy                              -5.80812
trainer/qf_loss                               8.51186
trainer/state_noise                           0.005
trainer/policy_loss                        -103.994
trainer/policy_loss_without_entropy         105.276
trainer/entropy_penalty                      -0.287083
trainer/entropy_percentage                   -0.00272695
trainer/Q1Pred Mean                         105.271
trainer/Q1Pred Std                           42.101
trainer/Q1Pred Max                          185.507
trainer/Q1Pred Min                            5.17538
trainer/Q2Pred Mean                         104.7
trainer/Q2Pred Std                           42.0025
trainer/Q2Pred Max                          185.322
trainer/Q2Pred Min                            4.36667
trainer/QTargetWithReg Mean                 104.448
trainer/QTargetWithReg Std                   42.0302
trainer/QTargetWithReg Max                  184.721
trainer/QTargetWithReg Min                    3.71241
trainer/PolicyLossWithoutReg Mean           105.276
trainer/PolicyLossWithoutReg Std             41.4278
trainer/PolicyLossWithoutReg Max            184.193
trainer/PolicyLossWithoutReg Min              4.99402
trainer/gradient_norm                       199.146
trainer/gradient_penalty                     -0.995732
trainer/gradient_percentage                  -0.00945827
exploration/num steps total              224000
exploration/num paths total                1368
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.66649
exploration/Rewards Std                       1.3928
exploration/Rewards Max                       8.51686
exploration/Rewards Min                      -0.529269
exploration/Returns Mean                   3666.49
exploration/Returns Std                       0
exploration/Returns Max                    3666.49
exploration/Returns Min                    3666.49
exploration/Num Paths                         1
exploration/Average Returns                3666.49
evaluation_0/num steps total                  1.71049e+06
evaluation_0/num paths total               8941
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.68492
evaluation_0/Rewards Std                      1.00632
evaluation_0/Rewards Max                      8.4824
evaluation_0/Rewards Min                     -0.554915
evaluation_0/Returns Mean                  3684.92
evaluation_0/Returns Std                     87.8066
evaluation_0/Returns Max                   3899.95
evaluation_0/Returns Min                   3623.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3684.92
time/epoch (s)                                0
time/total (s)                             4331.45
Epoch                                       219
---------------------------------------  ----------------
2022-11-16 11:58:15.465621 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 220 finished
---------------------------------------  ----------------
epoch                                       220
total_step                               225000
replay_pool/size                         225000
trainer/alpha                                 0.048371
trainer/alpha_loss                            0.392324
trainer/entropy                              -6.12953
trainer/qf_loss                               6.4065
trainer/state_noise                           0.005
trainer/policy_loss                        -112.875
trainer/policy_loss_without_entropy         114.194
trainer/entropy_penalty                      -0.296492
trainer/entropy_percentage                   -0.0025964
trainer/Q1Pred Mean                         113.208
trainer/Q1Pred Std                           38.1172
trainer/Q1Pred Max                          183.743
trainer/Q1Pred Min                            2.24113
trainer/Q2Pred Mean                         113
trainer/Q2Pred Std                           37.7626
trainer/Q2Pred Max                          184.078
trainer/Q2Pred Min                           -2.39261
trainer/QTargetWithReg Mean                 113.542
trainer/QTargetWithReg Std                   38.1922
trainer/QTargetWithReg Max                  183.748
trainer/QTargetWithReg Min                    0.000628684
trainer/PolicyLossWithoutReg Mean           114.194
trainer/PolicyLossWithoutReg Std             36.9605
trainer/PolicyLossWithoutReg Max            184.795
trainer/PolicyLossWithoutReg Min              0.480788
trainer/gradient_norm                       204.312
trainer/gradient_penalty                     -1.02156
trainer/gradient_percentage                  -0.00894588
exploration/num steps total              225000
exploration/num paths total                1370
exploration/path length this epoch Mean     467
exploration/path length this epoch Std      191
exploration/path length this epoch Max      658
exploration/path length this epoch Min      276
exploration/Rewards Mean                      3.60358
exploration/Rewards Std                       1.30536
exploration/Rewards Max                       8.07777
exploration/Rewards Min                      -0.384952
exploration/Returns Mean                   1682.87
exploration/Returns Std                     706.496
exploration/Returns Max                    2389.37
exploration/Returns Min                     976.376
exploration/Num Paths                         2
exploration/Average Returns                1682.87
evaluation_0/num steps total                  1.71836e+06
evaluation_0/num paths total               8949
evaluation_0/path length Mean               983.5
evaluation_0/path length Std                 43.6549
evaluation_0/path length Max               1000
evaluation_0/path length Min                868
evaluation_0/Rewards Mean                     3.49838
evaluation_0/Rewards Std                      1.12231
evaluation_0/Rewards Max                      9.24879
evaluation_0/Rewards Min                     -0.345639
evaluation_0/Returns Mean                  3440.66
evaluation_0/Returns Std                    333.98
evaluation_0/Returns Max                   4052.54
evaluation_0/Returns Min                   3024.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3440.66
time/epoch (s)                                0
time/total (s)                             4349.39
Epoch                                       220
---------------------------------------  ----------------
2022-11-16 11:58:33.852054 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 221 finished
---------------------------------------  ----------------
epoch                                       221
total_step                               226000
replay_pool/size                         226000
trainer/alpha                                 0.0493129
trainer/alpha_loss                            0.979376
trainer/entropy                              -6.32539
trainer/qf_loss                               6.47872
trainer/state_noise                           0.005
trainer/policy_loss                        -111.239
trainer/policy_loss_without_entropy         112.518
trainer/entropy_penalty                      -0.311924
trainer/entropy_percentage                   -0.00277222
trainer/Q1Pred Mean                         111.839
trainer/Q1Pred Std                           38.2562
trainer/Q1Pred Max                          186.857
trainer/Q1Pred Min                           -0.304046
trainer/Q2Pred Mean                         111.844
trainer/Q2Pred Std                           38.5628
trainer/Q2Pred Max                          185.684
trainer/Q2Pred Min                           -1.3505
trainer/QTargetWithReg Mean                 111.704
trainer/QTargetWithReg Std                   38.7908
trainer/QTargetWithReg Max                  185.003
trainer/QTargetWithReg Min                   -2.62702
trainer/PolicyLossWithoutReg Mean           112.518
trainer/PolicyLossWithoutReg Std             37.6945
trainer/PolicyLossWithoutReg Max            185.729
trainer/PolicyLossWithoutReg Min             -2.33926
trainer/gradient_norm                       193.306
trainer/gradient_penalty                     -0.966528
trainer/gradient_percentage                  -0.00859002
exploration/num steps total              226000
exploration/num paths total                1371
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.4592
exploration/Rewards Std                       1.16683
exploration/Rewards Max                       8.07979
exploration/Rewards Min                      -0.301469
exploration/Returns Mean                   3459.2
exploration/Returns Std                       0
exploration/Returns Max                    3459.2
exploration/Returns Min                    3459.2
exploration/Num Paths                         1
exploration/Average Returns                3459.2
evaluation_0/num steps total                  1.72597e+06
evaluation_0/num paths total               8965
evaluation_0/path length Mean               476.062
evaluation_0/path length Std                157.997
evaluation_0/path length Max                818
evaluation_0/path length Min                298
evaluation_0/Rewards Mean                     3.9372
evaluation_0/Rewards Std                      1.43671
evaluation_0/Rewards Max                      9.15799
evaluation_0/Rewards Min                     -0.579794
evaluation_0/Returns Mean                  1874.35
evaluation_0/Returns Std                    689.962
evaluation_0/Returns Max                   3488.17
evaluation_0/Returns Min                   1067.66
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               1874.35
time/epoch (s)                                0
time/total (s)                             4367.77
Epoch                                       221
---------------------------------------  ----------------
2022-11-16 11:58:50.151209 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 222 finished
---------------------------------------  ----------------
epoch                                       222
total_step                               227000
replay_pool/size                         227000
trainer/alpha                                 0.0500071
trainer/alpha_loss                           -0.03028
trainer/entropy                              -5.98989
trainer/qf_loss                               7.08849
trainer/state_noise                           0.005
trainer/policy_loss                        -111.022
trainer/policy_loss_without_entropy         112.27
trainer/entropy_penalty                      -0.299537
trainer/entropy_percentage                   -0.00266801
trainer/Q1Pred Mean                         111.308
trainer/Q1Pred Std                           40.2493
trainer/Q1Pred Max                          193.108
trainer/Q1Pred Min                          -21.7973
trainer/Q2Pred Mean                         112.085
trainer/Q2Pred Std                           39.9934
trainer/Q2Pred Max                          191.943
trainer/Q2Pred Min                          -17.2717
trainer/QTargetWithReg Mean                 112.002
trainer/QTargetWithReg Std                   40.083
trainer/QTargetWithReg Max                  193.336
trainer/QTargetWithReg Min                  -22.8945
trainer/PolicyLossWithoutReg Mean           112.27
trainer/PolicyLossWithoutReg Std             39.9062
trainer/PolicyLossWithoutReg Max            195.142
trainer/PolicyLossWithoutReg Min            -20.4773
trainer/gradient_norm                       189.6
trainer/gradient_penalty                     -0.947998
trainer/gradient_percentage                  -0.00844393
exploration/num steps total              227000
exploration/num paths total                1372
exploration/path length this epoch Mean     967
exploration/path length this epoch Std        0
exploration/path length this epoch Max      967
exploration/path length this epoch Min      967
exploration/Rewards Mean                      3.85762
exploration/Rewards Std                       1.15448
exploration/Rewards Max                       7.82971
exploration/Rewards Min                      -0.478896
exploration/Returns Mean                   3730.32
exploration/Returns Std                       0
exploration/Returns Max                    3730.32
exploration/Returns Min                    3730.32
exploration/Num Paths                         1
exploration/Average Returns                3730.32
evaluation_0/num steps total                  1.73397e+06
evaluation_0/num paths total               8973
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.53411
evaluation_0/Rewards Std                      1.02
evaluation_0/Rewards Max                      7.45694
evaluation_0/Rewards Min                     -0.478212
evaluation_0/Returns Mean                  3534.11
evaluation_0/Returns Std                     59.8738
evaluation_0/Returns Max                   3604.94
evaluation_0/Returns Min                   3434.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3534.11
time/epoch (s)                                0
time/total (s)                             4384.07
Epoch                                       222
---------------------------------------  ----------------
2022-11-16 11:59:07.505490 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 223 finished
---------------------------------------  ----------------
epoch                                       223
total_step                               228000
replay_pool/size                         228000
trainer/alpha                                 0.0488478
trainer/alpha_loss                            0.072762
trainer/entropy                              -6.0241
trainer/qf_loss                              10.573
trainer/state_noise                           0.005
trainer/policy_loss                        -115.815
trainer/policy_loss_without_entropy         117.134
trainer/entropy_penalty                      -0.294264
trainer/entropy_percentage                   -0.00251219
trainer/Q1Pred Mean                         116.589
trainer/Q1Pred Std                           34.6903
trainer/Q1Pred Max                          192.37
trainer/Q1Pred Min                            7.11615
trainer/Q2Pred Mean                         116.807
trainer/Q2Pred Std                           34.9276
trainer/Q2Pred Max                          192.319
trainer/Q2Pred Min                            7.95991
trainer/QTargetWithReg Mean                 116.89
trainer/QTargetWithReg Std                   34.6811
trainer/QTargetWithReg Max                  192.259
trainer/QTargetWithReg Min                    8.04363
trainer/PolicyLossWithoutReg Mean           117.134
trainer/PolicyLossWithoutReg Std             34.278
trainer/PolicyLossWithoutReg Max            191.129
trainer/PolicyLossWithoutReg Min              8.19914
trainer/gradient_norm                       205.02
trainer/gradient_penalty                     -1.0251
trainer/gradient_percentage                  -0.0087515
exploration/num steps total              228000
exploration/num paths total                1373
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.42731
exploration/Rewards Std                       1.02037
exploration/Rewards Max                       8.10401
exploration/Rewards Min                      -0.423828
exploration/Returns Mean                   3427.31
exploration/Returns Std                       0
exploration/Returns Max                    3427.31
exploration/Returns Min                    3427.31
exploration/Num Paths                         1
exploration/Average Returns                3427.31
evaluation_0/num steps total                  1.74148e+06
evaluation_0/num paths total               8981
evaluation_0/path length Mean               938.875
evaluation_0/path length Std                106.367
evaluation_0/path length Max               1000
evaluation_0/path length Min                735
evaluation_0/Rewards Mean                     3.69162
evaluation_0/Rewards Std                      1.1315
evaluation_0/Rewards Max                      8.77109
evaluation_0/Rewards Min                     -0.649084
evaluation_0/Returns Mean                  3465.97
evaluation_0/Returns Std                    297.815
evaluation_0/Returns Max                   3767.52
evaluation_0/Returns Min                   2958.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3465.97
time/epoch (s)                                0
time/total (s)                             4401.42
Epoch                                       223
---------------------------------------  ----------------
2022-11-16 11:59:25.685371 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 224 finished
---------------------------------------  ----------------
epoch                                       224
total_step                               229000
replay_pool/size                         229000
trainer/alpha                                 0.0492158
trainer/alpha_loss                            1.0847
trainer/entropy                              -6.36018
trainer/qf_loss                               6.43801
trainer/state_noise                           0.005
trainer/policy_loss                        -108.346
trainer/policy_loss_without_entropy         109.651
trainer/entropy_penalty                      -0.313021
trainer/entropy_percentage                   -0.0028547
trainer/Q1Pred Mean                         108.472
trainer/Q1Pred Std                           39.9448
trainer/Q1Pred Max                          172.44
trainer/Q1Pred Min                            1.9006
trainer/Q2Pred Mean                         107.984
trainer/Q2Pred Std                           40.2418
trainer/Q2Pred Max                          172.322
trainer/Q2Pred Min                            0.86012
trainer/QTargetWithReg Mean                 108.418
trainer/QTargetWithReg Std                   40.4254
trainer/QTargetWithReg Max                  172.645
trainer/QTargetWithReg Min                    1.60211
trainer/PolicyLossWithoutReg Mean           109.651
trainer/PolicyLossWithoutReg Std             39.4729
trainer/PolicyLossWithoutReg Max            172.45
trainer/PolicyLossWithoutReg Min              1.24473
trainer/gradient_norm                       198.446
trainer/gradient_penalty                     -0.992229
trainer/gradient_percentage                  -0.00904897
exploration/num steps total              229000
exploration/num paths total                1374
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.37248
exploration/Rewards Std                       0.919152
exploration/Rewards Max                       7.09958
exploration/Rewards Min                      -0.52066
exploration/Returns Mean                   3372.48
exploration/Returns Std                       0
exploration/Returns Max                    3372.48
exploration/Returns Min                    3372.48
exploration/Num Paths                         1
exploration/Average Returns                3372.48
evaluation_0/num steps total                  1.74908e+06
evaluation_0/num paths total               8991
evaluation_0/path length Mean               759.5
evaluation_0/path length Std                367.922
evaluation_0/path length Max               1000
evaluation_0/path length Min                152
evaluation_0/Rewards Mean                     3.40411
evaluation_0/Rewards Std                      1.02782
evaluation_0/Rewards Max                      7.41565
evaluation_0/Rewards Min                     -0.612759
evaluation_0/Returns Mean                  2585.42
evaluation_0/Returns Std                   1247.24
evaluation_0/Returns Max                   3635.24
evaluation_0/Returns Min                    499.373
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2585.42
time/epoch (s)                                0
time/total (s)                             4419.61
Epoch                                       224
---------------------------------------  ----------------
2022-11-16 11:59:43.041016 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 225 finished
---------------------------------------  ----------------
epoch                                       225
total_step                               230000
replay_pool/size                         230000
trainer/alpha                                 0.0491411
trainer/alpha_loss                            2.62145
trainer/entropy                              -6.87
trainer/qf_loss                               9.49321
trainer/state_noise                           0.005
trainer/policy_loss                        -112.532
trainer/policy_loss_without_entropy         113.887
trainer/entropy_penalty                      -0.3376
trainer/entropy_percentage                   -0.00296433
trainer/Q1Pred Mean                         111.892
trainer/Q1Pred Std                           39.564
trainer/Q1Pred Max                          180.398
trainer/Q1Pred Min                          -14.2213
trainer/Q2Pred Mean                         112.624
trainer/Q2Pred Std                           39.688
trainer/Q2Pred Max                          182.143
trainer/Q2Pred Min                          -13.343
trainer/QTargetWithReg Mean                 112.63
trainer/QTargetWithReg Std                   39.584
trainer/QTargetWithReg Max                  181.855
trainer/QTargetWithReg Min                  -10.4663
trainer/PolicyLossWithoutReg Mean           113.887
trainer/PolicyLossWithoutReg Std             37.677
trainer/PolicyLossWithoutReg Max            179.687
trainer/PolicyLossWithoutReg Min             -9.3528
trainer/gradient_norm                       203.472
trainer/gradient_penalty                     -1.01736
trainer/gradient_percentage                  -0.00893304
exploration/num steps total              230000
exploration/num paths total                1377
exploration/path length this epoch Mean     115.333
exploration/path length this epoch Std        7.93025
exploration/path length this epoch Max      126
exploration/path length this epoch Min      107
exploration/Rewards Mean                      2.91993
exploration/Rewards Std                       1.50273
exploration/Rewards Max                       6.93098
exploration/Rewards Min                      -0.590257
exploration/Returns Mean                    336.765
exploration/Returns Std                       8.05055
exploration/Returns Max                     348.129
exploration/Returns Min                     330.483
exploration/Num Paths                         3
exploration/Average Returns                 336.765
evaluation_0/num steps total                  1.75645e+06
evaluation_0/num paths total               9000
evaluation_0/path length Mean               819
evaluation_0/path length Std                339.269
evaluation_0/path length Max               1000
evaluation_0/path length Min                141
evaluation_0/Rewards Mean                     3.47186
evaluation_0/Rewards Std                      1.0101
evaluation_0/Rewards Max                      7.19286
evaluation_0/Rewards Min                     -0.644222
evaluation_0/Returns Mean                  2843.45
evaluation_0/Returns Std                   1203.81
evaluation_0/Returns Max                   3585.68
evaluation_0/Returns Min                    416.1
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               2843.45
time/epoch (s)                                0
time/total (s)                             4436.96
Epoch                                       225
---------------------------------------  ----------------
2022-11-16 11:59:59.918284 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 226 finished
---------------------------------------  ---------------
epoch                                       226
total_step                               231000
replay_pool/size                         231000
trainer/alpha                                 0.048916
trainer/alpha_loss                            0.20463
trainer/entropy                              -6.06781
trainer/qf_loss                               4.75191
trainer/state_noise                           0.005
trainer/policy_loss                        -108.426
trainer/policy_loss_without_entropy         109.691
trainer/entropy_penalty                      -0.296813
trainer/entropy_percentage                   -0.0027059
trainer/Q1Pred Mean                         108.877
trainer/Q1Pred Std                           38.8448
trainer/Q1Pred Max                          183.655
trainer/Q1Pred Min                           -1.84242
trainer/Q2Pred Mean                         108.832
trainer/Q2Pred Std                           38.7149
trainer/Q2Pred Max                          184.27
trainer/Q2Pred Min                            0.774392
trainer/QTargetWithReg Mean                 108.76
trainer/QTargetWithReg Std                   38.9409
trainer/QTargetWithReg Max                  183.152
trainer/QTargetWithReg Min                    1.02873
trainer/PolicyLossWithoutReg Mean           109.691
trainer/PolicyLossWithoutReg Std             38.4376
trainer/PolicyLossWithoutReg Max            183.808
trainer/PolicyLossWithoutReg Min              7.49612
trainer/gradient_norm                       193.647
trainer/gradient_penalty                     -0.968235
trainer/gradient_percentage                  -0.00882693
exploration/num steps total              231000
exploration/num paths total                1378
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.39513
exploration/Rewards Std                       0.928018
exploration/Rewards Max                       6.69153
exploration/Rewards Min                      -0.5969
exploration/Returns Mean                   3395.13
exploration/Returns Std                       0
exploration/Returns Max                    3395.13
exploration/Returns Min                    3395.13
exploration/Num Paths                         1
exploration/Average Returns                3395.13
evaluation_0/num steps total                  1.7644e+06
evaluation_0/num paths total               9070
evaluation_0/path length Mean               113.557
evaluation_0/path length Std                 25.0044
evaluation_0/path length Max                297
evaluation_0/path length Min                106
evaluation_0/Rewards Mean                     3.21182
evaluation_0/Rewards Std                      1.53755
evaluation_0/Rewards Max                      7.34498
evaluation_0/Rewards Min                     -0.631203
evaluation_0/Returns Mean                   364.725
evaluation_0/Returns Std                     83.0974
evaluation_0/Returns Max                    916.585
evaluation_0/Returns Min                    334.974
evaluation_0/Num Paths                       70
evaluation_0/Average Returns                364.725
time/epoch (s)                                0
time/total (s)                             4453.84
Epoch                                       226
---------------------------------------  ---------------
2022-11-16 12:00:15.708893 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 227 finished
---------------------------------------  ----------------
epoch                                       227
total_step                               232000
replay_pool/size                         232000
trainer/alpha                                 0.0492236
trainer/alpha_loss                            0.268519
trainer/entropy                              -6.08917
trainer/qf_loss                              50.1313
trainer/state_noise                           0.005
trainer/policy_loss                        -112.664
trainer/policy_loss_without_entropy         113.985
trainer/entropy_penalty                      -0.299731
trainer/entropy_percentage                   -0.00262956
trainer/Q1Pred Mean                         113.441
trainer/Q1Pred Std                           39.3209
trainer/Q1Pred Max                          179.491
trainer/Q1Pred Min                           -9.55331
trainer/Q2Pred Mean                         113.335
trainer/Q2Pred Std                           39.2623
trainer/Q2Pred Max                          178.646
trainer/Q2Pred Min                           -6.68948
trainer/QTargetWithReg Mean                 113.533
trainer/QTargetWithReg Std                   39.8356
trainer/QTargetWithReg Max                  181.752
trainer/QTargetWithReg Min                   -0.000737987
trainer/PolicyLossWithoutReg Mean           113.985
trainer/PolicyLossWithoutReg Std             38.316
trainer/PolicyLossWithoutReg Max            177.976
trainer/PolicyLossWithoutReg Min              4.39548
trainer/gradient_norm                       204.225
trainer/gradient_penalty                     -1.02112
trainer/gradient_percentage                  -0.00895842
exploration/num steps total              232000
exploration/num paths total                1379
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.22059
exploration/Rewards Std                       0.876064
exploration/Rewards Max                       7.14699
exploration/Rewards Min                      -0.701658
exploration/Returns Mean                   3220.59
exploration/Returns Std                       0
exploration/Returns Max                    3220.59
exploration/Returns Min                    3220.59
exploration/Num Paths                         1
exploration/Average Returns                3220.59
evaluation_0/num steps total                  1.7724e+06
evaluation_0/num paths total               9078
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.25459
evaluation_0/Rewards Std                      0.943037
evaluation_0/Rewards Max                      6.75686
evaluation_0/Rewards Min                     -0.412848
evaluation_0/Returns Mean                  3254.59
evaluation_0/Returns Std                     50.3222
evaluation_0/Returns Max                   3301.02
evaluation_0/Returns Min                   3167.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3254.59
time/epoch (s)                                0
time/total (s)                             4469.63
Epoch                                       227
---------------------------------------  ----------------
2022-11-16 12:00:32.022059 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 228 finished
---------------------------------------  ---------------
epoch                                       228
total_step                               233000
replay_pool/size                         233000
trainer/alpha                                 0.0491198
trainer/alpha_loss                            0.0898521
trainer/entropy                              -6.02982
trainer/qf_loss                               8.8459
trainer/state_noise                           0.005
trainer/policy_loss                        -105.462
trainer/policy_loss_without_entropy         106.765
trainer/entropy_penalty                      -0.296183
trainer/entropy_percentage                   -0.00277416
trainer/Q1Pred Mean                         106.322
trainer/Q1Pred Std                           43.3318
trainer/Q1Pred Max                          193.154
trainer/Q1Pred Min                           -0.286426
trainer/Q2Pred Mean                         106.546
trainer/Q2Pred Std                           43.1261
trainer/Q2Pred Max                          195.054
trainer/Q2Pred Min                            1.83111
trainer/QTargetWithReg Mean                 106.501
trainer/QTargetWithReg Std                   43.0556
trainer/QTargetWithReg Max                  194.011
trainer/QTargetWithReg Min                   -0.0729068
trainer/PolicyLossWithoutReg Mean           106.765
trainer/PolicyLossWithoutReg Std             42.3791
trainer/PolicyLossWithoutReg Max            192.563
trainer/PolicyLossWithoutReg Min              0.452362
trainer/gradient_norm                       201.373
trainer/gradient_penalty                     -1.00687
trainer/gradient_percentage                  -0.00943069
exploration/num steps total              233000
exploration/num paths total                1382
exploration/path length this epoch Mean     251
exploration/path length this epoch Std      149.053
exploration/path length this epoch Max      456
exploration/path length this epoch Min      106
exploration/Rewards Mean                      3.10469
exploration/Rewards Std                       1.42619
exploration/Rewards Max                       7.27071
exploration/Rewards Min                      -0.470065
exploration/Returns Mean                    779.277
exploration/Returns Std                     433.218
exploration/Returns Max                    1363.23
exploration/Returns Min                     326.785
exploration/Num Paths                         3
exploration/Average Returns                 779.277
evaluation_0/num steps total                  1.7804e+06
evaluation_0/num paths total               9086
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     2.9757
evaluation_0/Rewards Std                      0.791383
evaluation_0/Rewards Max                      7.24582
evaluation_0/Rewards Min                     -0.349164
evaluation_0/Returns Mean                  2975.7
evaluation_0/Returns Std                     22.1339
evaluation_0/Returns Max                   3003.67
evaluation_0/Returns Min                   2923.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2975.7
time/epoch (s)                                0
time/total (s)                             4485.94
Epoch                                       228
---------------------------------------  ---------------
2022-11-16 12:00:51.675843 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 229 finished
---------------------------------------  ----------------
epoch                                       229
total_step                               234000
replay_pool/size                         234000
trainer/alpha                                 0.0488776
trainer/alpha_loss                           -0.315466
trainer/entropy                              -5.89549
trainer/qf_loss                               6.44725
trainer/state_noise                           0.005
trainer/policy_loss                        -114.191
trainer/policy_loss_without_entropy         115.487
trainer/entropy_penalty                      -0.288157
trainer/entropy_percentage                   -0.00249515
trainer/Q1Pred Mean                         114.805
trainer/Q1Pred Std                           36.7219
trainer/Q1Pred Max                          192.933
trainer/Q1Pred Min                            1.57648
trainer/Q2Pred Mean                         114.459
trainer/Q2Pred Std                           36.5453
trainer/Q2Pred Max                          189.258
trainer/Q2Pred Min                            2.27536
trainer/QTargetWithReg Mean                 114.267
trainer/QTargetWithReg Std                   36.7511
trainer/QTargetWithReg Max                  193.759
trainer/QTargetWithReg Min                    2.62489
trainer/PolicyLossWithoutReg Mean           115.487
trainer/PolicyLossWithoutReg Std             36.0173
trainer/PolicyLossWithoutReg Max            189.856
trainer/PolicyLossWithoutReg Min              1.30487
trainer/gradient_norm                       201.574
trainer/gradient_penalty                     -1.00787
trainer/gradient_percentage                  -0.00872713
exploration/num steps total              234000
exploration/num paths total                1383
exploration/path length this epoch Mean     102
exploration/path length this epoch Std        0
exploration/path length this epoch Max      102
exploration/path length this epoch Min      102
exploration/Rewards Mean                      3.1498
exploration/Rewards Std                       1.5295
exploration/Rewards Max                       5.63621
exploration/Rewards Min                      -0.274787
exploration/Returns Mean                    321.28
exploration/Returns Std                       0
exploration/Returns Max                     321.28
exploration/Returns Min                     321.28
exploration/Num Paths                         1
exploration/Average Returns                 321.28
evaluation_0/num steps total                  1.78837e+06
evaluation_0/num paths total               9126
evaluation_0/path length Mean               199.225
evaluation_0/path length Std                228.784
evaluation_0/path length Max               1000
evaluation_0/path length Min                110
evaluation_0/Rewards Mean                     3.19016
evaluation_0/Rewards Std                      1.30331
evaluation_0/Rewards Max                      6.97966
evaluation_0/Rewards Min                     -0.427591
evaluation_0/Returns Mean                   635.559
evaluation_0/Returns Std                    752.71
evaluation_0/Returns Max                   3331.09
evaluation_0/Returns Min                    334.084
evaluation_0/Num Paths                       40
evaluation_0/Average Returns                635.559
time/epoch (s)                                0
time/total (s)                             4505.59
Epoch                                       229
---------------------------------------  ----------------
2022-11-16 12:01:09.639927 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 230 finished
---------------------------------------  ----------------
epoch                                       230
total_step                               235000
replay_pool/size                         235000
trainer/alpha                                 0.0481448
trainer/alpha_loss                           -1.44284
trainer/entropy                              -5.52434
trainer/qf_loss                               6.35954
trainer/state_noise                           0.005
trainer/policy_loss                        -113.247
trainer/policy_loss_without_entropy         114.488
trainer/entropy_penalty                      -0.265968
trainer/entropy_percentage                   -0.00232312
trainer/Q1Pred Mean                         114.482
trainer/Q1Pred Std                           37.0266
trainer/Q1Pred Max                          194.282
trainer/Q1Pred Min                            2.73726
trainer/Q2Pred Mean                         114.231
trainer/Q2Pred Std                           36.8079
trainer/Q2Pred Max                          191.635
trainer/Q2Pred Min                            1.53745
trainer/QTargetWithReg Mean                 114.034
trainer/QTargetWithReg Std                   36.9912
trainer/QTargetWithReg Max                  190.448
trainer/QTargetWithReg Min                   -1.29384
trainer/PolicyLossWithoutReg Mean           114.488
trainer/PolicyLossWithoutReg Std             36.394
trainer/PolicyLossWithoutReg Max            191.117
trainer/PolicyLossWithoutReg Min              5.23398
trainer/gradient_norm                       194.847
trainer/gradient_penalty                     -0.974237
trainer/gradient_percentage                  -0.00850955
exploration/num steps total              235000
exploration/num paths total                1384
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.25281
exploration/Rewards Std                       0.89549
exploration/Rewards Max                       6.65874
exploration/Rewards Min                      -0.356366
exploration/Returns Mean                   3252.81
exploration/Returns Std                       0
exploration/Returns Max                    3252.81
exploration/Returns Min                    3252.81
exploration/Num Paths                         1
exploration/Average Returns                3252.81
evaluation_0/num steps total                  1.79611e+06
evaluation_0/num paths total               9138
evaluation_0/path length Mean               645.583
evaluation_0/path length Std                421.685
evaluation_0/path length Max               1000
evaluation_0/path length Min                108
evaluation_0/Rewards Mean                     3.10666
evaluation_0/Rewards Std                      0.997771
evaluation_0/Rewards Max                      8.15547
evaluation_0/Rewards Min                     -0.453916
evaluation_0/Returns Mean                  2005.61
evaluation_0/Returns Std                   1311.31
evaluation_0/Returns Max                   3216.18
evaluation_0/Returns Min                    326.939
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2005.61
time/epoch (s)                                0
time/total (s)                             4523.56
Epoch                                       230
---------------------------------------  ----------------
2022-11-16 12:01:27.062063 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 231 finished
---------------------------------------  ----------------
epoch                                       231
total_step                               236000
replay_pool/size                         236000
trainer/alpha                                 0.0480397
trainer/alpha_loss                           -1.03318
trainer/entropy                              -5.65965
trainer/qf_loss                               5.5792
trainer/state_noise                           0.005
trainer/policy_loss                        -113.068
trainer/policy_loss_without_entropy         114.369
trainer/entropy_penalty                      -0.271888
trainer/entropy_percentage                   -0.0023773
trainer/Q1Pred Mean                         113.591
trainer/Q1Pred Std                           39.0154
trainer/Q1Pred Max                          190.332
trainer/Q1Pred Min                            6.23494
trainer/Q2Pred Mean                         113.338
trainer/Q2Pred Std                           39.0146
trainer/Q2Pred Max                          194.713
trainer/Q2Pred Min                            5.91007
trainer/QTargetWithReg Mean                 113.71
trainer/QTargetWithReg Std                   38.988
trainer/QTargetWithReg Max                  193.245
trainer/QTargetWithReg Min                    0.0049116
trainer/PolicyLossWithoutReg Mean           114.369
trainer/PolicyLossWithoutReg Std             38.176
trainer/PolicyLossWithoutReg Max            192.973
trainer/PolicyLossWithoutReg Min             11.4712
trainer/gradient_norm                       205.658
trainer/gradient_penalty                     -1.02829
trainer/gradient_percentage                  -0.00899103
exploration/num steps total              236000
exploration/num paths total                1385
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.23655
exploration/Rewards Std                       0.960541
exploration/Rewards Max                       7.18763
exploration/Rewards Min                      -0.417165
exploration/Returns Mean                   3236.55
exploration/Returns Std                       0
exploration/Returns Max                    3236.55
exploration/Returns Min                    3236.55
exploration/Num Paths                         1
exploration/Average Returns                3236.55
evaluation_0/num steps total                  1.80337e+06
evaluation_0/num paths total               9153
evaluation_0/path length Mean               483.6
evaluation_0/path length Std                422.246
evaluation_0/path length Max               1000
evaluation_0/path length Min                108
evaluation_0/Rewards Mean                     3.49176
evaluation_0/Rewards Std                      1.16327
evaluation_0/Rewards Max                      8.52155
evaluation_0/Rewards Min                     -0.467252
evaluation_0/Returns Mean                  1688.62
evaluation_0/Returns Std                   1511.95
evaluation_0/Returns Max                   3665.8
evaluation_0/Returns Min                    341.747
evaluation_0/Num Paths                       15
evaluation_0/Average Returns               1688.62
time/epoch (s)                                0
time/total (s)                             4540.98
Epoch                                       231
---------------------------------------  ----------------
2022-11-16 12:01:45.029314 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 232 finished
---------------------------------------  ----------------
epoch                                       232
total_step                               237000
replay_pool/size                         237000
trainer/alpha                                 0.0481344
trainer/alpha_loss                            1.01481
trainer/entropy                              -6.33449
trainer/qf_loss                               6.26308
trainer/state_noise                           0.005
trainer/policy_loss                        -113.925
trainer/policy_loss_without_entropy         115.261
trainer/entropy_penalty                      -0.304907
trainer/entropy_percentage                   -0.00264536
trainer/Q1Pred Mean                         114.962
trainer/Q1Pred Std                           37.2035
trainer/Q1Pred Max                          182.653
trainer/Q1Pred Min                           -2.46646
trainer/Q2Pred Mean                         114.947
trainer/Q2Pred Std                           37.2749
trainer/Q2Pred Max                          181.927
trainer/Q2Pred Min                           -3.6335
trainer/QTargetWithReg Mean                 115.224
trainer/QTargetWithReg Std                   37.3903
trainer/QTargetWithReg Max                  181.909
trainer/QTargetWithReg Min                   -0.0441943
trainer/PolicyLossWithoutReg Mean           115.261
trainer/PolicyLossWithoutReg Std             36.7556
trainer/PolicyLossWithoutReg Max            181.761
trainer/PolicyLossWithoutReg Min             -3.26542
trainer/gradient_norm                       206.235
trainer/gradient_penalty                     -1.03117
trainer/gradient_percentage                  -0.00894642
exploration/num steps total              237000
exploration/num paths total                1386
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.41145
exploration/Rewards Std                       1.07267
exploration/Rewards Max                       7.91765
exploration/Rewards Min                      -0.429133
exploration/Returns Mean                   3411.45
exploration/Returns Std                       0
exploration/Returns Max                    3411.45
exploration/Returns Min                    3411.45
exploration/Num Paths                         1
exploration/Average Returns                3411.45
evaluation_0/num steps total                  1.81134e+06
evaluation_0/num paths total               9164
evaluation_0/path length Mean               724.545
evaluation_0/path length Std                364.791
evaluation_0/path length Max               1000
evaluation_0/path length Min                220
evaluation_0/Rewards Mean                     3.22161
evaluation_0/Rewards Std                      1.07829
evaluation_0/Rewards Max                      8.20263
evaluation_0/Rewards Min                     -0.591956
evaluation_0/Returns Mean                  2334.2
evaluation_0/Returns Std                   1106.82
evaluation_0/Returns Max                   3281.26
evaluation_0/Returns Min                    809.231
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2334.2
time/epoch (s)                                0
time/total (s)                             4558.95
Epoch                                       232
---------------------------------------  ----------------
2022-11-16 12:02:02.413934 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 233 finished
---------------------------------------  ----------------
epoch                                       233
total_step                               238000
replay_pool/size                         238000
trainer/alpha                                 0.0484034
trainer/alpha_loss                            0.243039
trainer/entropy                              -6.08026
trainer/qf_loss                               6.35446
trainer/state_noise                           0.005
trainer/policy_loss                        -113.605
trainer/policy_loss_without_entropy         114.922
trainer/entropy_penalty                      -0.294305
trainer/entropy_percentage                   -0.00256091
trainer/Q1Pred Mean                         114.094
trainer/Q1Pred Std                           40.6357
trainer/Q1Pred Max                          209.451
trainer/Q1Pred Min                           -4.38288
trainer/Q2Pred Mean                         113.819
trainer/Q2Pred Std                           40.6406
trainer/Q2Pred Max                          209.316
trainer/Q2Pred Min                          -13.3437
trainer/QTargetWithReg Mean                 114.364
trainer/QTargetWithReg Std                   40.3492
trainer/QTargetWithReg Max                  210.136
trainer/QTargetWithReg Min                   -9.09082
trainer/PolicyLossWithoutReg Mean           114.922
trainer/PolicyLossWithoutReg Std             39.9555
trainer/PolicyLossWithoutReg Max            209.133
trainer/PolicyLossWithoutReg Min             -4.25952
trainer/gradient_norm                       204.655
trainer/gradient_penalty                     -1.02327
trainer/gradient_percentage                  -0.00890407
exploration/num steps total              238000
exploration/num paths total                1387
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.1227
exploration/Rewards Std                       0.861821
exploration/Rewards Max                       7.65254
exploration/Rewards Min                      -0.529239
exploration/Returns Mean                   3122.7
exploration/Returns Std                       0
exploration/Returns Max                    3122.7
exploration/Returns Min                    3122.7
exploration/Num Paths                         1
exploration/Average Returns                3122.7
evaluation_0/num steps total                  1.81841e+06
evaluation_0/num paths total               9177
evaluation_0/path length Mean               543.692
evaluation_0/path length Std                367.029
evaluation_0/path length Max               1000
evaluation_0/path length Min                193
evaluation_0/Rewards Mean                     3.24784
evaluation_0/Rewards Std                      1.15676
evaluation_0/Rewards Max                      8.85998
evaluation_0/Rewards Min                     -0.496033
evaluation_0/Returns Mean                  1765.82
evaluation_0/Returns Std                   1135.4
evaluation_0/Returns Max                   3281.29
evaluation_0/Returns Min                    642.315
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               1765.82
time/epoch (s)                                0
time/total (s)                             4576.33
Epoch                                       233
---------------------------------------  ----------------
2022-11-16 12:02:18.839402 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 234 finished
---------------------------------------  ----------------
epoch                                       234
total_step                               239000
replay_pool/size                         239000
trainer/alpha                                 0.0501639
trainer/alpha_loss                           -0.232223
trainer/entropy                              -5.92239
trainer/qf_loss                               7.41997
trainer/state_noise                           0.005
trainer/policy_loss                        -116.209
trainer/policy_loss_without_entropy         117.503
trainer/entropy_penalty                      -0.297091
trainer/entropy_percentage                   -0.00252836
trainer/Q1Pred Mean                         116.336
trainer/Q1Pred Std                           37.933
trainer/Q1Pred Max                          190.264
trainer/Q1Pred Min                          -12.4011
trainer/Q2Pred Mean                         116.336
trainer/Q2Pred Std                           37.7388
trainer/Q2Pred Max                          188.529
trainer/Q2Pred Min                          -11.9385
trainer/QTargetWithReg Mean                 115.801
trainer/QTargetWithReg Std                   38.2463
trainer/QTargetWithReg Max                  191.152
trainer/QTargetWithReg Min                  -18.4264
trainer/PolicyLossWithoutReg Mean           117.503
trainer/PolicyLossWithoutReg Std             36.6602
trainer/PolicyLossWithoutReg Max            188.642
trainer/PolicyLossWithoutReg Min              0.0634295
trainer/gradient_norm                       199.357
trainer/gradient_penalty                     -0.996787
trainer/gradient_percentage                  -0.00848305
exploration/num steps total              239000
exploration/num paths total                1388
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.00653
exploration/Rewards Std                       0.97073
exploration/Rewards Max                       7.79225
exploration/Rewards Min                      -0.247343
exploration/Returns Mean                   3006.53
exploration/Returns Std                       0
exploration/Returns Max                    3006.53
exploration/Returns Min                    3006.53
exploration/Num Paths                         1
exploration/Average Returns                3006.53
evaluation_0/num steps total                  1.82641e+06
evaluation_0/num paths total               9185
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.46439
evaluation_0/Rewards Std                      0.971031
evaluation_0/Rewards Max                      8.53441
evaluation_0/Rewards Min                     -0.518995
evaluation_0/Returns Mean                  3464.39
evaluation_0/Returns Std                    111.283
evaluation_0/Returns Max                   3622.94
evaluation_0/Returns Min                   3267.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3464.39
time/epoch (s)                                0
time/total (s)                             4592.76
Epoch                                       234
---------------------------------------  ----------------
2022-11-16 12:02:34.583433 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 235 finished
---------------------------------------  ----------------
epoch                                       235
total_step                               240000
replay_pool/size                         240000
trainer/alpha                                 0.050917
trainer/alpha_loss                           -0.537325
trainer/entropy                              -5.81955
trainer/qf_loss                               7.89333
trainer/state_noise                           0.005
trainer/policy_loss                        -117.182
trainer/policy_loss_without_entropy         118.47
trainer/entropy_penalty                      -0.296314
trainer/entropy_percentage                   -0.00250116
trainer/Q1Pred Mean                         118.035
trainer/Q1Pred Std                           38.8253
trainer/Q1Pred Max                          192.028
trainer/Q1Pred Min                           11.1908
trainer/Q2Pred Mean                         117.632
trainer/Q2Pred Std                           38.8267
trainer/Q2Pred Max                          188.696
trainer/Q2Pred Min                            9.3412
trainer/QTargetWithReg Mean                 117.777
trainer/QTargetWithReg Std                   39.2355
trainer/QTargetWithReg Max                  191.068
trainer/QTargetWithReg Min                    9.36283
trainer/PolicyLossWithoutReg Mean           118.47
trainer/PolicyLossWithoutReg Std             38.6417
trainer/PolicyLossWithoutReg Max            191.059
trainer/PolicyLossWithoutReg Min             10.5816
trainer/gradient_norm                       198.373
trainer/gradient_penalty                     -0.991866
trainer/gradient_percentage                  -0.00837226
exploration/num steps total              240000
exploration/num paths total                1389
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.8117
exploration/Rewards Std                       0.759023
exploration/Rewards Max                       6.75411
exploration/Rewards Min                      -0.48082
exploration/Returns Mean                   2811.7
exploration/Returns Std                       0
exploration/Returns Max                    2811.7
exploration/Returns Min                    2811.7
exploration/Num Paths                         1
exploration/Average Returns                2811.7
evaluation_0/num steps total                  1.83441e+06
evaluation_0/num paths total               9193
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.10786
evaluation_0/Rewards Std                      0.900505
evaluation_0/Rewards Max                      7.41267
evaluation_0/Rewards Min                     -0.524003
evaluation_0/Returns Mean                  3107.86
evaluation_0/Returns Std                    242.794
evaluation_0/Returns Max                   3521.86
evaluation_0/Returns Min                   2740.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3107.86
time/epoch (s)                                0
time/total (s)                             4608.5
Epoch                                       235
---------------------------------------  ----------------
2022-11-16 12:02:54.151714 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 236 finished
---------------------------------------  ----------------
epoch                                       236
total_step                               241000
replay_pool/size                         241000
trainer/alpha                                 0.0504338
trainer/alpha_loss                           -1.67616
trainer/entropy                              -5.43887
trainer/qf_loss                               6.29103
trainer/state_noise                           0.005
trainer/policy_loss                        -116.873
trainer/policy_loss_without_entropy         118.12
trainer/entropy_penalty                      -0.274303
trainer/entropy_percentage                   -0.00232225
trainer/Q1Pred Mean                         118.048
trainer/Q1Pred Std                           38.9486
trainer/Q1Pred Max                          196.595
trainer/Q1Pred Min                            0.527944
trainer/Q2Pred Mean                         117.85
trainer/Q2Pred Std                           38.7953
trainer/Q2Pred Max                          197.542
trainer/Q2Pred Min                            6.09842
trainer/QTargetWithReg Mean                 117.546
trainer/QTargetWithReg Std                   39.103
trainer/QTargetWithReg Max                  196.163
trainer/QTargetWithReg Min                   -5.10895
trainer/PolicyLossWithoutReg Mean           118.12
trainer/PolicyLossWithoutReg Std             38.6675
trainer/PolicyLossWithoutReg Max            196.441
trainer/PolicyLossWithoutReg Min              0.60055
trainer/gradient_norm                       194.567
trainer/gradient_penalty                     -0.972837
trainer/gradient_percentage                  -0.00823603
exploration/num steps total              241000
exploration/num paths total                1390
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.16143
exploration/Rewards Std                       0.839526
exploration/Rewards Max                       7.01394
exploration/Rewards Min                      -0.402846
exploration/Returns Mean                   3161.43
exploration/Returns Std                       0
exploration/Returns Max                    3161.43
exploration/Returns Min                    3161.43
exploration/Num Paths                         1
exploration/Average Returns                3161.43
evaluation_0/num steps total                  1.84213e+06
evaluation_0/num paths total               9211
evaluation_0/path length Mean               429.333
evaluation_0/path length Std                406.605
evaluation_0/path length Max               1000
evaluation_0/path length Min                101
evaluation_0/Rewards Mean                     3.05207
evaluation_0/Rewards Std                      1.14862
evaluation_0/Rewards Max                      8.30699
evaluation_0/Rewards Min                     -0.451352
evaluation_0/Returns Mean                  1310.36
evaluation_0/Returns Std                   1182.17
evaluation_0/Returns Max                   3171.48
evaluation_0/Returns Min                    305.389
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1310.36
time/epoch (s)                                0
time/total (s)                             4628.07
Epoch                                       236
---------------------------------------  ----------------
2022-11-16 12:03:09.940346 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 237 finished
---------------------------------------  ----------------
epoch                                       237
total_step                               242000
replay_pool/size                         242000
trainer/alpha                                 0.050705
trainer/alpha_loss                           -0.587453
trainer/entropy                              -5.80298
trainer/qf_loss                               7.45138
trainer/state_noise                           0.005
trainer/policy_loss                        -114.516
trainer/policy_loss_without_entropy         115.843
trainer/entropy_penalty                      -0.29424
trainer/entropy_percentage                   -0.00253998
trainer/Q1Pred Mean                         115.479
trainer/Q1Pred Std                           38.8806
trainer/Q1Pred Max                          193.429
trainer/Q1Pred Min                           -0.237359
trainer/Q2Pred Mean                         115.386
trainer/Q2Pred Std                           38.9633
trainer/Q2Pred Max                          194.062
trainer/Q2Pred Min                           -2.52186
trainer/QTargetWithReg Mean                 115.454
trainer/QTargetWithReg Std                   38.9016
trainer/QTargetWithReg Max                  193.877
trainer/QTargetWithReg Min                    2.96012
trainer/PolicyLossWithoutReg Mean           115.843
trainer/PolicyLossWithoutReg Std             38.6886
trainer/PolicyLossWithoutReg Max            192.347
trainer/PolicyLossWithoutReg Min             -0.497165
trainer/gradient_norm                       206.556
trainer/gradient_penalty                     -1.03278
trainer/gradient_percentage                  -0.00891533
exploration/num steps total              242000
exploration/num paths total                1391
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.79127
exploration/Rewards Std                       0.876944
exploration/Rewards Max                       7.61872
exploration/Rewards Min                      -0.430151
exploration/Returns Mean                   2791.27
exploration/Returns Std                       0
exploration/Returns Max                    2791.27
exploration/Returns Min                    2791.27
exploration/Num Paths                         1
exploration/Average Returns                2791.27
evaluation_0/num steps total                  1.85013e+06
evaluation_0/num paths total               9219
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.10565
evaluation_0/Rewards Std                      0.833988
evaluation_0/Rewards Max                      7.43787
evaluation_0/Rewards Min                     -0.524798
evaluation_0/Returns Mean                  3105.65
evaluation_0/Returns Std                     38.9901
evaluation_0/Returns Max                   3155.92
evaluation_0/Returns Min                   3038.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3105.65
time/epoch (s)                                0
time/total (s)                             4643.86
Epoch                                       237
---------------------------------------  ----------------
2022-11-16 12:03:26.428986 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 238 finished
---------------------------------------  ----------------
epoch                                       238
total_step                               243000
replay_pool/size                         243000
trainer/alpha                                 0.0509446
trainer/alpha_loss                            0.483826
trainer/entropy                              -6.16252
trainer/qf_loss                               6.49009
trainer/state_noise                           0.005
trainer/policy_loss                        -114.25
trainer/policy_loss_without_entropy         115.615
trainer/entropy_penalty                      -0.313947
trainer/entropy_percentage                   -0.00271546
trainer/Q1Pred Mean                         114.35
trainer/Q1Pred Std                           40.4844
trainer/Q1Pred Max                          192.782
trainer/Q1Pred Min                           -5.19067
trainer/Q2Pred Mean                         114.367
trainer/Q2Pred Std                           40.6891
trainer/Q2Pred Max                          194.28
trainer/Q2Pred Min                           -5.88307
trainer/QTargetWithReg Mean                 114.704
trainer/QTargetWithReg Std                   40.2667
trainer/QTargetWithReg Max                  194.214
trainer/QTargetWithReg Min                   -0.645184
trainer/PolicyLossWithoutReg Mean           115.615
trainer/PolicyLossWithoutReg Std             38.7198
trainer/PolicyLossWithoutReg Max            194.713
trainer/PolicyLossWithoutReg Min              8.73649
trainer/gradient_norm                       210.145
trainer/gradient_penalty                     -1.05072
trainer/gradient_percentage                  -0.00908816
exploration/num steps total              243000
exploration/num paths total                1392
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.97494
exploration/Rewards Std                       1.07123
exploration/Rewards Max                       7.90488
exploration/Rewards Min                      -0.522125
exploration/Returns Mean                   2974.94
exploration/Returns Std                       0
exploration/Returns Max                    2974.94
exploration/Returns Min                    2974.94
exploration/Num Paths                         1
exploration/Average Returns                2974.94
evaluation_0/num steps total                  1.85813e+06
evaluation_0/num paths total               9227
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.17172
evaluation_0/Rewards Std                      0.85979
evaluation_0/Rewards Max                      7.20083
evaluation_0/Rewards Min                     -0.555391
evaluation_0/Returns Mean                  3171.72
evaluation_0/Returns Std                     71.002
evaluation_0/Returns Max                   3294.88
evaluation_0/Returns Min                   3090.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3171.72
time/epoch (s)                                0
time/total (s)                             4660.34
Epoch                                       238
---------------------------------------  ----------------
2022-11-16 12:03:44.824909 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 239 finished
---------------------------------------  ----------------
epoch                                       239
total_step                               244000
replay_pool/size                         244000
trainer/alpha                                 0.050633
trainer/alpha_loss                            1.21325
trainer/entropy                              -6.40667
trainer/qf_loss                               6.42589
trainer/state_noise                           0.005
trainer/policy_loss                        -114.543
trainer/policy_loss_without_entropy         115.875
trainer/entropy_penalty                      -0.324389
trainer/entropy_percentage                   -0.00279948
trainer/Q1Pred Mean                         115.215
trainer/Q1Pred Std                           39.7675
trainer/Q1Pred Max                          214.905
trainer/Q1Pred Min                            0.0596172
trainer/Q2Pred Mean                         114.89
trainer/Q2Pred Std                           39.8808
trainer/Q2Pred Max                          211.516
trainer/Q2Pred Min                           -2.53791
trainer/QTargetWithReg Mean                 115.137
trainer/QTargetWithReg Std                   39.9746
trainer/QTargetWithReg Max                  215.177
trainer/QTargetWithReg Min                   -0.179047
trainer/PolicyLossWithoutReg Mean           115.875
trainer/PolicyLossWithoutReg Std             39.5655
trainer/PolicyLossWithoutReg Max            211.635
trainer/PolicyLossWithoutReg Min             -1.62053
trainer/gradient_norm                       201.422
trainer/gradient_penalty                     -1.00711
trainer/gradient_percentage                  -0.00869134
exploration/num steps total              244000
exploration/num paths total                1393
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.96772
exploration/Rewards Std                       0.988534
exploration/Rewards Max                       8.14508
exploration/Rewards Min                      -0.467842
exploration/Returns Mean                   2967.72
exploration/Returns Std                       0
exploration/Returns Max                    2967.72
exploration/Returns Min                    2967.72
exploration/Num Paths                         1
exploration/Average Returns                2967.72
evaluation_0/num steps total                  1.86605e+06
evaluation_0/num paths total               9266
evaluation_0/path length Mean               203
evaluation_0/path length Std                231.8
evaluation_0/path length Max               1000
evaluation_0/path length Min                109
evaluation_0/Rewards Mean                     3.23751
evaluation_0/Rewards Std                      1.44192
evaluation_0/Rewards Max                      8.89977
evaluation_0/Rewards Min                     -0.439211
evaluation_0/Returns Mean                   657.215
evaluation_0/Returns Std                    686.748
evaluation_0/Returns Max                   3050.18
evaluation_0/Returns Min                    336.535
evaluation_0/Num Paths                       39
evaluation_0/Average Returns                657.215
time/epoch (s)                                0
time/total (s)                             4678.74
Epoch                                       239
---------------------------------------  ----------------
2022-11-16 12:04:02.437415 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 240 finished
---------------------------------------  ----------------
epoch                                       240
total_step                               245000
replay_pool/size                         245000
trainer/alpha                                 0.0504727
trainer/alpha_loss                           -2.19442
trainer/entropy                              -5.26517
trainer/qf_loss                               5.66022
trainer/state_noise                           0.005
trainer/policy_loss                        -113.554
trainer/policy_loss_without_entropy         114.831
trainer/entropy_penalty                      -0.265748
trainer/entropy_percentage                   -0.00231425
trainer/Q1Pred Mean                         114.109
trainer/Q1Pred Std                           37.4717
trainer/Q1Pred Max                          193.357
trainer/Q1Pred Min                          -14.5199
trainer/Q2Pred Mean                         114.365
trainer/Q2Pred Std                           37.6071
trainer/Q2Pred Max                          197.281
trainer/Q2Pred Min                          -11.1192
trainer/QTargetWithReg Mean                 113.971
trainer/QTargetWithReg Std                   37.559
trainer/QTargetWithReg Max                  192.762
trainer/QTargetWithReg Min                  -12.9369
trainer/PolicyLossWithoutReg Mean           114.831
trainer/PolicyLossWithoutReg Std             36.9668
trainer/PolicyLossWithoutReg Max            192.859
trainer/PolicyLossWithoutReg Min             -9.58444
trainer/gradient_norm                       202.161
trainer/gradient_penalty                     -1.01081
trainer/gradient_percentage                  -0.00880256
exploration/num steps total              245000
exploration/num paths total                1394
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.922
exploration/Rewards Std                       0.848921
exploration/Rewards Max                       7.01844
exploration/Rewards Min                      -0.284147
exploration/Returns Mean                   2922
exploration/Returns Std                       0
exploration/Returns Max                    2922
exploration/Returns Min                    2922
exploration/Num Paths                         1
exploration/Average Returns                2922
evaluation_0/num steps total                  1.87325e+06
evaluation_0/num paths total               9274
evaluation_0/path length Mean               899.75
evaluation_0/path length Std                265.237
evaluation_0/path length Max               1000
evaluation_0/path length Min                198
evaluation_0/Rewards Mean                     2.87204
evaluation_0/Rewards Std                      0.903716
evaluation_0/Rewards Max                      7.655
evaluation_0/Rewards Min                     -0.667493
evaluation_0/Returns Mean                  2584.12
evaluation_0/Returns Std                    734.626
evaluation_0/Returns Max                   3059.14
evaluation_0/Returns Min                    652.628
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               2584.12
time/epoch (s)                                0
time/total (s)                             4696.35
Epoch                                       240
---------------------------------------  ----------------
2022-11-16 12:04:32.868576 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 241 finished
---------------------------------------  ----------------
epoch                                       241
total_step                               246000
replay_pool/size                         246000
trainer/alpha                                 0.0514471
trainer/alpha_loss                           -0.778051
trainer/entropy                              -5.73778
trainer/qf_loss                               4.71384
trainer/state_noise                           0.005
trainer/policy_loss                        -114.658
trainer/policy_loss_without_entropy         115.982
trainer/entropy_penalty                      -0.295192
trainer/entropy_percentage                   -0.00254515
trainer/Q1Pred Mean                         115.496
trainer/Q1Pred Std                           42.2371
trainer/Q1Pred Max                          200.574
trainer/Q1Pred Min                          -14.215
trainer/Q2Pred Mean                         115.1
trainer/Q2Pred Std                           42.2144
trainer/Q2Pred Max                          198.482
trainer/Q2Pred Min                          -16.7854
trainer/QTargetWithReg Mean                 115.164
trainer/QTargetWithReg Std                   41.9582
trainer/QTargetWithReg Max                  193.065
trainer/QTargetWithReg Min                  -19.1672
trainer/PolicyLossWithoutReg Mean           115.982
trainer/PolicyLossWithoutReg Std             41.7281
trainer/PolicyLossWithoutReg Max            197.428
trainer/PolicyLossWithoutReg Min            -15.0768
trainer/gradient_norm                       205.761
trainer/gradient_penalty                     -1.02881
trainer/gradient_percentage                  -0.0088704
exploration/num steps total              246000
exploration/num paths total                1398
exploration/path length this epoch Mean     185.25
exploration/path length this epoch Std       96.2558
exploration/path length this epoch Max      349
exploration/path length this epoch Min      104
exploration/Rewards Mean                      3.06147
exploration/Rewards Std                       1.5548
exploration/Rewards Max                       7.35456
exploration/Rewards Min                      -0.633974
exploration/Returns Mean                    567.138
exploration/Returns Std                     252.126
exploration/Returns Max                     981.743
exploration/Returns Min                     338.651
exploration/Num Paths                         4
exploration/Average Returns                 567.138
evaluation_0/num steps total                  1.88125e+06
evaluation_0/num paths total               9282
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.01519
evaluation_0/Rewards Std                      0.888372
evaluation_0/Rewards Max                      7.05965
evaluation_0/Rewards Min                     -0.425503
evaluation_0/Returns Mean                  3015.19
evaluation_0/Returns Std                     99.9263
evaluation_0/Returns Max                   3172.4
evaluation_0/Returns Min                   2909.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3015.19
time/epoch (s)                                0
time/total (s)                             4726.78
Epoch                                       241
---------------------------------------  ----------------
2022-11-16 12:05:29.333649 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 242 finished
---------------------------------------  ----------------
epoch                                       242
total_step                               247000
replay_pool/size                         247000
trainer/alpha                                 0.05082
trainer/alpha_loss                           -0.25439
trainer/entropy                              -5.91462
trainer/qf_loss                               5.48076
trainer/state_noise                           0.005
trainer/policy_loss                        -116.224
trainer/policy_loss_without_entropy         117.513
trainer/entropy_penalty                      -0.300581
trainer/entropy_percentage                   -0.00255784
trainer/Q1Pred Mean                         117.087
trainer/Q1Pred Std                           40.6161
trainer/Q1Pred Max                          189.382
trainer/Q1Pred Min                           -3.07924
trainer/Q2Pred Mean                         116.995
trainer/Q2Pred Std                           40.5814
trainer/Q2Pred Max                          186.722
trainer/Q2Pred Min                           -0.459079
trainer/QTargetWithReg Mean                 117.078
trainer/QTargetWithReg Std                   40.8245
trainer/QTargetWithReg Max                  188.088
trainer/QTargetWithReg Min                    1.74357
trainer/PolicyLossWithoutReg Mean           117.513
trainer/PolicyLossWithoutReg Std             40.3461
trainer/PolicyLossWithoutReg Max            188.303
trainer/PolicyLossWithoutReg Min             -3.93322
trainer/gradient_norm                       197.875
trainer/gradient_penalty                     -0.989377
trainer/gradient_percentage                  -0.00841926
exploration/num steps total              247000
exploration/num paths total                1399
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.97816
exploration/Rewards Std                       0.885657
exploration/Rewards Max                       6.67196
exploration/Rewards Min                      -0.418859
exploration/Returns Mean                   2978.16
exploration/Returns Std                       0
exploration/Returns Max                    2978.16
exploration/Returns Min                    2978.16
exploration/Num Paths                         1
exploration/Average Returns                2978.16
evaluation_0/num steps total                  1.88878e+06
evaluation_0/num paths total               9290
evaluation_0/path length Mean               941.5
evaluation_0/path length Std                154.776
evaluation_0/path length Max               1000
evaluation_0/path length Min                532
evaluation_0/Rewards Mean                     3.32013
evaluation_0/Rewards Std                      0.981435
evaluation_0/Rewards Max                      8.76704
evaluation_0/Rewards Min                     -0.512116
evaluation_0/Returns Mean                  3125.9
evaluation_0/Returns Std                    385.174
evaluation_0/Returns Max                   3710.04
evaluation_0/Returns Min                   2220.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3125.9
time/epoch (s)                                0
time/total (s)                             4783.25
Epoch                                       242
---------------------------------------  ----------------
2022-11-16 12:05:57.591596 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 243 finished
---------------------------------------  ----------------
epoch                                       243
total_step                               248000
replay_pool/size                         248000
trainer/alpha                                 0.0506387
trainer/alpha_loss                            1.1637
trainer/entropy                              -6.39012
trainer/qf_loss                               8.41654
trainer/state_noise                           0.005
trainer/policy_loss                        -116.604
trainer/policy_loss_without_entropy         117.993
trainer/entropy_penalty                      -0.323587
trainer/entropy_percentage                   -0.00274244
trainer/Q1Pred Mean                         116.789
trainer/Q1Pred Std                           40.3269
trainer/Q1Pred Max                          199.958
trainer/Q1Pred Min                           -8.92042
trainer/Q2Pred Mean                         116.691
trainer/Q2Pred Std                           40.2025
trainer/Q2Pred Max                          201.149
trainer/Q2Pred Min                           -5.89574
trainer/QTargetWithReg Mean                 116.992
trainer/QTargetWithReg Std                   40.6762
trainer/QTargetWithReg Max                  200.148
trainer/QTargetWithReg Min                   -0.20564
trainer/PolicyLossWithoutReg Mean           117.993
trainer/PolicyLossWithoutReg Std             38.9953
trainer/PolicyLossWithoutReg Max            200.077
trainer/PolicyLossWithoutReg Min              0.934497
trainer/gradient_norm                       213.043
trainer/gradient_penalty                     -1.06521
trainer/gradient_percentage                  -0.00902779
exploration/num steps total              248000
exploration/num paths total                1400
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.272
exploration/Rewards Std                       0.976746
exploration/Rewards Max                       8.12202
exploration/Rewards Min                      -0.458138
exploration/Returns Mean                   3272
exploration/Returns Std                       0
exploration/Returns Max                    3272
exploration/Returns Min                    3272
exploration/Num Paths                         1
exploration/Average Returns                3272
evaluation_0/num steps total                  1.89678e+06
evaluation_0/num paths total               9298
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.14843
evaluation_0/Rewards Std                      0.90772
evaluation_0/Rewards Max                      7.99345
evaluation_0/Rewards Min                     -0.421982
evaluation_0/Returns Mean                  3148.43
evaluation_0/Returns Std                     46.4844
evaluation_0/Returns Max                   3255.14
evaluation_0/Returns Min                   3088.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3148.43
time/epoch (s)                                0
time/total (s)                             4811.51
Epoch                                       243
---------------------------------------  ----------------
2022-11-16 12:06:31.875795 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 244 finished
---------------------------------------  ----------------
epoch                                       244
total_step                               249000
replay_pool/size                         249000
trainer/alpha                                 0.049977
trainer/alpha_loss                            0.213355
trainer/entropy                              -6.07121
trainer/qf_loss                               5.90968
trainer/state_noise                           0.005
trainer/policy_loss                        -119.637
trainer/policy_loss_without_entropy         120.935
trainer/entropy_penalty                      -0.303421
trainer/entropy_percentage                   -0.00250896
trainer/Q1Pred Mean                         120.177
trainer/Q1Pred Std                           38.9204
trainer/Q1Pred Max                          188.721
trainer/Q1Pred Min                            4.21972
trainer/Q2Pred Mean                         119.985
trainer/Q2Pred Std                           38.6391
trainer/Q2Pred Max                          188.584
trainer/Q2Pred Min                            3.01814
trainer/QTargetWithReg Mean                 120.212
trainer/QTargetWithReg Std                   38.639
trainer/QTargetWithReg Max                  193.893
trainer/QTargetWithReg Min                    3.40289
trainer/PolicyLossWithoutReg Mean           120.935
trainer/PolicyLossWithoutReg Std             38.261
trainer/PolicyLossWithoutReg Max            188.782
trainer/PolicyLossWithoutReg Min              3.6695
trainer/gradient_norm                       199.014
trainer/gradient_penalty                     -0.995071
trainer/gradient_percentage                  -0.00822815
exploration/num steps total              249000
exploration/num paths total                1401
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.25732
exploration/Rewards Std                       0.935056
exploration/Rewards Max                       7.81166
exploration/Rewards Min                      -0.477128
exploration/Returns Mean                   3257.32
exploration/Returns Std                       0
exploration/Returns Max                    3257.32
exploration/Returns Min                    3257.32
exploration/Num Paths                         1
exploration/Average Returns                3257.32
evaluation_0/num steps total                  1.90478e+06
evaluation_0/num paths total               9306
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.55079
evaluation_0/Rewards Std                      0.94392
evaluation_0/Rewards Max                      8.66575
evaluation_0/Rewards Min                     -0.306381
evaluation_0/Returns Mean                  3550.79
evaluation_0/Returns Std                     96.0994
evaluation_0/Returns Max                   3730.14
evaluation_0/Returns Min                   3476.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3550.79
time/epoch (s)                                0
time/total (s)                             4845.79
Epoch                                       244
---------------------------------------  ----------------
2022-11-16 12:07:50.698969 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 245 finished
---------------------------------------  ----------------
epoch                                       245
total_step                               250000
replay_pool/size                         250000
trainer/alpha                                 0.0518473
trainer/alpha_loss                           -0.2588
trainer/entropy                              -5.91256
trainer/qf_loss                               6.90336
trainer/state_noise                           0.005
trainer/policy_loss                        -119.37
trainer/policy_loss_without_entropy         120.701
trainer/entropy_penalty                      -0.30655
trainer/entropy_percentage                   -0.00253976
trainer/Q1Pred Mean                         119.749
trainer/Q1Pred Std                           39.2238
trainer/Q1Pred Max                          184.529
trainer/Q1Pred Min                           -4.88911
trainer/Q2Pred Mean                         119.973
trainer/Q2Pred Std                           39.0988
trainer/Q2Pred Max                          185.893
trainer/Q2Pred Min                           -0.803836
trainer/QTargetWithReg Mean                 119.989
trainer/QTargetWithReg Std                   39.42
trainer/QTargetWithReg Max                  185.934
trainer/QTargetWithReg Min                   -2.75716
trainer/PolicyLossWithoutReg Mean           120.701
trainer/PolicyLossWithoutReg Std             38.3765
trainer/PolicyLossWithoutReg Max            185.121
trainer/PolicyLossWithoutReg Min             -0.747731
trainer/gradient_norm                       204.721
trainer/gradient_penalty                     -1.02361
trainer/gradient_percentage                  -0.00848053
exploration/num steps total              250000
exploration/num paths total                1402
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      2.88914
exploration/Rewards Std                       0.773597
exploration/Rewards Max                       6.28165
exploration/Rewards Min                      -0.411909
exploration/Returns Mean                   2889.14
exploration/Returns Std                       0
exploration/Returns Max                    2889.14
exploration/Returns Min                    2889.14
exploration/Num Paths                         1
exploration/Average Returns                2889.14
evaluation_0/num steps total                  1.91278e+06
evaluation_0/num paths total               9314
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.18788
evaluation_0/Rewards Std                      0.850007
evaluation_0/Rewards Max                      7.24101
evaluation_0/Rewards Min                     -0.496431
evaluation_0/Returns Mean                  3187.88
evaluation_0/Returns Std                     46.3834
evaluation_0/Returns Max                   3255.04
evaluation_0/Returns Min                   3108.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3187.88
time/epoch (s)                                0
time/total (s)                             4924.63
Epoch                                       245
---------------------------------------  ----------------
2022-11-16 12:09:06.830265 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 246 finished
---------------------------------------  ----------------
epoch                                       246
total_step                               251000
replay_pool/size                         251000
trainer/alpha                                 0.050534
trainer/alpha_loss                            0.00240267
trainer/entropy                              -6.0008
trainer/qf_loss                               8.65509
trainer/state_noise                           0.005
trainer/policy_loss                        -119.256
trainer/policy_loss_without_entropy         120.622
trainer/entropy_penalty                      -0.303245
trainer/entropy_percentage                   -0.00251401
trainer/Q1Pred Mean                         119.693
trainer/Q1Pred Std                           37.8939
trainer/Q1Pred Max                          195.69
trainer/Q1Pred Min                            1.46026
trainer/Q2Pred Mean                         119.915
trainer/Q2Pred Std                           37.8199
trainer/Q2Pred Max                          194.369
trainer/Q2Pred Min                            0.328255
trainer/QTargetWithReg Mean                 120.703
trainer/QTargetWithReg Std                   38.0996
trainer/QTargetWithReg Max                  195.337
trainer/QTargetWithReg Min                    2.77399
trainer/PolicyLossWithoutReg Mean           120.622
trainer/PolicyLossWithoutReg Std             37.3721
trainer/PolicyLossWithoutReg Max            195.528
trainer/PolicyLossWithoutReg Min              3.58553
trainer/gradient_norm                       212.485
trainer/gradient_penalty                     -1.06243
trainer/gradient_percentage                  -0.00880793
exploration/num steps total              251000
exploration/num paths total                1403
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.35293
exploration/Rewards Std                       0.894633
exploration/Rewards Max                       6.81765
exploration/Rewards Min                      -0.429131
exploration/Returns Mean                   3352.93
exploration/Returns Std                       0
exploration/Returns Max                    3352.93
exploration/Returns Min                    3352.93
exploration/Num Paths                         1
exploration/Average Returns                3352.93
evaluation_0/num steps total                  1.92078e+06
evaluation_0/num paths total               9322
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.01745
evaluation_0/Rewards Std                      0.876132
evaluation_0/Rewards Max                      7.69827
evaluation_0/Rewards Min                     -0.522574
evaluation_0/Returns Mean                  3017.45
evaluation_0/Returns Std                     59.6504
evaluation_0/Returns Max                   3109.02
evaluation_0/Returns Min                   2919.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3017.45
time/epoch (s)                                0
time/total (s)                             5000.75
Epoch                                       246
---------------------------------------  ----------------
2022-11-16 12:09:54.591913 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 247 finished
---------------------------------------  ---------------
epoch                                       247
total_step                               252000
replay_pool/size                         252000
trainer/alpha                                 0.0521406
trainer/alpha_loss                           -0.940871
trainer/entropy                              -5.68145
trainer/qf_loss                               5.8677
trainer/state_noise                           0.005
trainer/policy_loss                        -112.223
trainer/policy_loss_without_entropy         113.528
trainer/entropy_penalty                      -0.296234
trainer/entropy_percentage                   -0.00260935
trainer/Q1Pred Mean                         112.963
trainer/Q1Pred Std                           43.4395
trainer/Q1Pred Max                          185.359
trainer/Q1Pred Min                            2.32785
trainer/Q2Pred Mean                         112.845
trainer/Q2Pred Std                           43.1158
trainer/Q2Pred Max                          185.837
trainer/Q2Pred Min                            2.96786
trainer/QTargetWithReg Mean                 113.423
trainer/QTargetWithReg Std                   43.518
trainer/QTargetWithReg Max                  187.329
trainer/QTargetWithReg Min                    1.33813
trainer/PolicyLossWithoutReg Mean           113.528
trainer/PolicyLossWithoutReg Std             42.3097
trainer/PolicyLossWithoutReg Max            185.444
trainer/PolicyLossWithoutReg Min              2.27765
trainer/gradient_norm                       201.721
trainer/gradient_penalty                     -1.0086
trainer/gradient_percentage                  -0.00888421
exploration/num steps total              252000
exploration/num paths total                1404
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.17602
exploration/Rewards Std                       0.86475
exploration/Rewards Max                       6.49691
exploration/Rewards Min                      -0.595836
exploration/Returns Mean                   3176.02
exploration/Returns Std                       0
exploration/Returns Max                    3176.02
exploration/Returns Min                    3176.02
exploration/Num Paths                         1
exploration/Average Returns                3176.02
evaluation_0/num steps total                  1.9284e+06
evaluation_0/num paths total               9330
evaluation_0/path length Mean               952.625
evaluation_0/path length Std                125.342
evaluation_0/path length Max               1000
evaluation_0/path length Min                621
evaluation_0/Rewards Mean                     3.42342
evaluation_0/Rewards Std                      0.948188
evaluation_0/Rewards Max                      9.35312
evaluation_0/Rewards Min                     -0.495681
evaluation_0/Returns Mean                  3261.23
evaluation_0/Returns Std                    240.402
evaluation_0/Returns Max                   3388.28
evaluation_0/Returns Min                   2627.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3261.23
time/epoch (s)                                0
time/total (s)                             5048.5
Epoch                                       247
---------------------------------------  ---------------
2022-11-16 12:10:07.764135 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 248 finished
---------------------------------------  ---------------
epoch                                       248
total_step                               253000
replay_pool/size                         253000
trainer/alpha                                 0.0521593
trainer/alpha_loss                            0.737441
trainer/entropy                              -6.24968
trainer/qf_loss                              11.8594
trainer/state_noise                           0.005
trainer/policy_loss                        -120.498
trainer/policy_loss_without_entropy         121.865
trainer/entropy_penalty                      -0.325979
trainer/entropy_percentage                   -0.00267492
trainer/Q1Pred Mean                         121.421
trainer/Q1Pred Std                           42.3855
trainer/Q1Pred Max                          204.844
trainer/Q1Pred Min                          -16.575
trainer/Q2Pred Mean                         121.343
trainer/Q2Pred Std                           42.416
trainer/Q2Pred Max                          204.244
trainer/Q2Pred Min                          -11.4299
trainer/QTargetWithReg Mean                 121.959
trainer/QTargetWithReg Std                   42.8451
trainer/QTargetWithReg Max                  205.282
trainer/QTargetWithReg Min                  -16.1007
trainer/PolicyLossWithoutReg Mean           121.865
trainer/PolicyLossWithoutReg Std             41.9946
trainer/PolicyLossWithoutReg Max            204.509
trainer/PolicyLossWithoutReg Min            -14.2047
trainer/gradient_norm                       208.129
trainer/gradient_penalty                     -1.04065
trainer/gradient_percentage                  -0.00853936
exploration/num steps total              253000
exploration/num paths total                1405
exploration/path length this epoch Mean     480
exploration/path length this epoch Std        0
exploration/path length this epoch Max      480
exploration/path length this epoch Min      480
exploration/Rewards Mean                      3.81722
exploration/Rewards Std                       1.45572
exploration/Rewards Max                       9.2808
exploration/Rewards Min                      -0.468959
exploration/Returns Mean                   1832.27
exploration/Returns Std                       0
exploration/Returns Max                    1832.27
exploration/Returns Min                    1832.27
exploration/Num Paths                         1
exploration/Average Returns                1832.27
evaluation_0/num steps total                  1.9364e+06
evaluation_0/num paths total               9338
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.59862
evaluation_0/Rewards Std                      0.953783
evaluation_0/Rewards Max                      7.83619
evaluation_0/Rewards Min                     -0.501573
evaluation_0/Returns Mean                  3598.62
evaluation_0/Returns Std                     85.3866
evaluation_0/Returns Max                   3741.77
evaluation_0/Returns Min                   3481.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3598.62
time/epoch (s)                                0
time/total (s)                             5061.67
Epoch                                       248
---------------------------------------  ---------------
2022-11-16 12:10:23.610142 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 249 finished
---------------------------------------  ---------------
epoch                                       249
total_step                               254000
replay_pool/size                         254000
trainer/alpha                                 0.0518906
trainer/alpha_loss                            0.0200945
trainer/entropy                              -6.00679
trainer/qf_loss                               8.02466
trainer/state_noise                           0.005
trainer/policy_loss                        -111.437
trainer/policy_loss_without_entropy         112.804
trainer/entropy_penalty                      -0.311696
trainer/entropy_percentage                   -0.00276317
trainer/Q1Pred Mean                         112.332
trainer/Q1Pred Std                           41.5856
trainer/Q1Pred Max                          200.242
trainer/Q1Pred Min                            0.468456
trainer/Q2Pred Mean                         112.389
trainer/Q2Pred Std                           41.5177
trainer/Q2Pred Max                          198.246
trainer/Q2Pred Min                            0.441484
trainer/QTargetWithReg Mean                 112.806
trainer/QTargetWithReg Std                   41.6398
trainer/QTargetWithReg Max                  200.721
trainer/QTargetWithReg Min                    3.19899
trainer/PolicyLossWithoutReg Mean           112.804
trainer/PolicyLossWithoutReg Std             41.1866
trainer/PolicyLossWithoutReg Max            197.914
trainer/PolicyLossWithoutReg Min              3.32793
trainer/gradient_norm                       210.949
trainer/gradient_penalty                     -1.05475
trainer/gradient_percentage                  -0.00935026
exploration/num steps total              254000
exploration/num paths total                1406
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.37688
exploration/Rewards Std                       0.897558
exploration/Rewards Max                       6.72147
exploration/Rewards Min                      -0.51068
exploration/Returns Mean                   3376.88
exploration/Returns Std                       0
exploration/Returns Max                    3376.88
exploration/Returns Min                    3376.88
exploration/Num Paths                         1
exploration/Average Returns                3376.88
evaluation_0/num steps total                  1.9444e+06
evaluation_0/num paths total               9346
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.04255
evaluation_0/Rewards Std                      0.731589
evaluation_0/Rewards Max                      6.27436
evaluation_0/Rewards Min                     -0.382774
evaluation_0/Returns Mean                  3042.55
evaluation_0/Returns Std                    134.176
evaluation_0/Returns Max                   3191.82
evaluation_0/Returns Min                   2906.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3042.55
time/epoch (s)                                0
time/total (s)                             5077.52
Epoch                                       249
---------------------------------------  ---------------
2022-11-16 12:10:39.477122 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 250 finished
---------------------------------------  ---------------
epoch                                       250
total_step                               255000
replay_pool/size                         255000
trainer/alpha                                 0.0519756
trainer/alpha_loss                            1.26023
trainer/entropy                              -6.42619
trainer/qf_loss                              10.4049
trainer/state_noise                           0.005
trainer/policy_loss                        -120.989
trainer/policy_loss_without_entropy         122.413
trainer/entropy_penalty                      -0.334005
trainer/entropy_percentage                   -0.00272851
trainer/Q1Pred Mean                         121.025
trainer/Q1Pred Std                           40.8617
trainer/Q1Pred Max                          198.686
trainer/Q1Pred Min                          -21.3263
trainer/Q2Pred Mean                         121.372
trainer/Q2Pred Std                           40.6882
trainer/Q2Pred Max                          199.17
trainer/Q2Pred Min                          -16.2251
trainer/QTargetWithReg Mean                 121.142
trainer/QTargetWithReg Std                   40.8922
trainer/QTargetWithReg Max                  200.163
trainer/QTargetWithReg Min                    0.821023
trainer/PolicyLossWithoutReg Mean           122.413
trainer/PolicyLossWithoutReg Std             39.4893
trainer/PolicyLossWithoutReg Max            198.982
trainer/PolicyLossWithoutReg Min              6.57152
trainer/gradient_norm                       217.951
trainer/gradient_penalty                     -1.08976
trainer/gradient_percentage                  -0.00890232
exploration/num steps total              255000
exploration/num paths total                1407
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.10476
exploration/Rewards Std                       0.840592
exploration/Rewards Max                       6.54838
exploration/Rewards Min                      -0.358374
exploration/Returns Mean                   3104.76
exploration/Returns Std                       0
exploration/Returns Max                    3104.76
exploration/Returns Min                    3104.76
exploration/Num Paths                         1
exploration/Average Returns                3104.76
evaluation_0/num steps total                  1.9524e+06
evaluation_0/num paths total               9354
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.14104
evaluation_0/Rewards Std                      0.778584
evaluation_0/Rewards Max                      7.56543
evaluation_0/Rewards Min                     -0.534314
evaluation_0/Returns Mean                  3141.04
evaluation_0/Returns Std                     17.5224
evaluation_0/Returns Max                   3169.36
evaluation_0/Returns Min                   3116.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3141.04
time/epoch (s)                                0
time/total (s)                             5093.39
Epoch                                       250
---------------------------------------  ---------------
2022-11-16 12:11:17.146763 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 251 finished
---------------------------------------  ---------------
epoch                                       251
total_step                               256000
replay_pool/size                         256000
trainer/alpha                                 0.0518585
trainer/alpha_loss                            0.911931
trainer/entropy                              -6.30816
trainer/qf_loss                               6.45821
trainer/state_noise                           0.005
trainer/policy_loss                        -117.812
trainer/policy_loss_without_entropy         119.216
trainer/entropy_penalty                      -0.327131
trainer/entropy_percentage                   -0.00274402
trainer/Q1Pred Mean                         118.46
trainer/Q1Pred Std                           40.6157
trainer/Q1Pred Max                          203.444
trainer/Q1Pred Min                            1.07668
trainer/Q2Pred Mean                         118.608
trainer/Q2Pred Std                           40.6056
trainer/Q2Pred Max                          205.748
trainer/Q2Pred Min                            1.05162
trainer/QTargetWithReg Mean                 118.241
trainer/QTargetWithReg Std                   40.5902
trainer/QTargetWithReg Max                  203.975
trainer/QTargetWithReg Min                    2.58716
trainer/PolicyLossWithoutReg Mean           119.216
trainer/PolicyLossWithoutReg Std             40.2593
trainer/PolicyLossWithoutReg Max            203.542
trainer/PolicyLossWithoutReg Min             -0.129818
trainer/gradient_norm                       215.364
trainer/gradient_penalty                     -1.07682
trainer/gradient_percentage                  -0.0090325
exploration/num steps total              256000
exploration/num paths total                1408
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.13486
exploration/Rewards Std                       0.846292
exploration/Rewards Max                       6.95733
exploration/Rewards Min                      -0.516259
exploration/Returns Mean                   3134.86
exploration/Returns Std                       0
exploration/Returns Max                    3134.86
exploration/Returns Min                    3134.86
exploration/Num Paths                         1
exploration/Average Returns                3134.86
evaluation_0/num steps total                  1.9604e+06
evaluation_0/num paths total               9362
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.45396
evaluation_0/Rewards Std                      0.901607
evaluation_0/Rewards Max                      8.39375
evaluation_0/Rewards Min                     -0.473372
evaluation_0/Returns Mean                  3453.96
evaluation_0/Returns Std                     50.3694
evaluation_0/Returns Max                   3525.47
evaluation_0/Returns Min                   3381.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3453.96
time/epoch (s)                                0
time/total (s)                             5131.07
Epoch                                       251
---------------------------------------  ---------------
2022-11-16 12:12:31.306805 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 252 finished
---------------------------------------  ---------------
epoch                                       252
total_step                               257000
replay_pool/size                         257000
trainer/alpha                                 0.052784
trainer/alpha_loss                           -0.520377
trainer/entropy                              -5.8231
trainer/qf_loss                               5.54287
trainer/state_noise                           0.005
trainer/policy_loss                        -121.584
trainer/policy_loss_without_entropy         122.904
trainer/entropy_penalty                      -0.307366
trainer/entropy_percentage                   -0.00250087
trainer/Q1Pred Mean                         122.061
trainer/Q1Pred Std                           37.0416
trainer/Q1Pred Max                          191.201
trainer/Q1Pred Min                          -17.77
trainer/Q2Pred Mean                         122.058
trainer/Q2Pred Std                           37.0682
trainer/Q2Pred Max                          192.822
trainer/Q2Pred Min                          -12.2843
trainer/QTargetWithReg Mean                 122.155
trainer/QTargetWithReg Std                   36.6437
trainer/QTargetWithReg Max                  190.414
trainer/QTargetWithReg Min                  -15.5908
trainer/PolicyLossWithoutReg Mean           122.904
trainer/PolicyLossWithoutReg Std             36.57
trainer/PolicyLossWithoutReg Max            191.582
trainer/PolicyLossWithoutReg Min            -11.8086
trainer/gradient_norm                       202.43
trainer/gradient_penalty                     -1.01215
trainer/gradient_percentage                  -0.0082353
exploration/num steps total              257000
exploration/num paths total                1409
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.42125
exploration/Rewards Std                       0.876877
exploration/Rewards Max                       7.17346
exploration/Rewards Min                      -0.471468
exploration/Returns Mean                   3421.25
exploration/Returns Std                       0
exploration/Returns Max                    3421.25
exploration/Returns Min                    3421.25
exploration/Num Paths                         1
exploration/Average Returns                3421.25
evaluation_0/num steps total                  1.9684e+06
evaluation_0/num paths total               9370
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.63253
evaluation_0/Rewards Std                      0.944871
evaluation_0/Rewards Max                      8.54184
evaluation_0/Rewards Min                     -0.485605
evaluation_0/Returns Mean                  3632.53
evaluation_0/Returns Std                     50.1665
evaluation_0/Returns Max                   3727.48
evaluation_0/Returns Min                   3553.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3632.53
time/epoch (s)                                0
time/total (s)                             5205.23
Epoch                                       252
---------------------------------------  ---------------
2022-11-16 12:13:59.032867 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 253 finished
---------------------------------------  ---------------
epoch                                       253
total_step                               258000
replay_pool/size                         258000
trainer/alpha                                 0.0523479
trainer/alpha_loss                            0.228803
trainer/entropy                              -6.07756
trainer/qf_loss                               5.46355
trainer/state_noise                           0.005
trainer/policy_loss                        -126.102
trainer/policy_loss_without_entropy         127.438
trainer/entropy_penalty                      -0.318147
trainer/entropy_percentage                   -0.00249649
trainer/Q1Pred Mean                         126.472
trainer/Q1Pred Std                           38.167
trainer/Q1Pred Max                          204.583
trainer/Q1Pred Min                            6.36536
trainer/Q2Pred Mean                         126.743
trainer/Q2Pred Std                           38.0659
trainer/Q2Pred Max                          201.336
trainer/Q2Pred Min                            6.2386
trainer/QTargetWithReg Mean                 126.544
trainer/QTargetWithReg Std                   38.092
trainer/QTargetWithReg Max                  203.638
trainer/QTargetWithReg Min                    8.43025
trainer/PolicyLossWithoutReg Mean           127.438
trainer/PolicyLossWithoutReg Std             37.7562
trainer/PolicyLossWithoutReg Max            201.654
trainer/PolicyLossWithoutReg Min             10.8258
trainer/gradient_norm                       203.605
trainer/gradient_penalty                     -1.01802
trainer/gradient_percentage                  -0.00798838
exploration/num steps total              258000
exploration/num paths total                1410
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.56304
exploration/Rewards Std                       0.922709
exploration/Rewards Max                       7.33285
exploration/Rewards Min                      -0.526005
exploration/Returns Mean                   3563.04
exploration/Returns Std                       0
exploration/Returns Max                    3563.04
exploration/Returns Min                    3563.04
exploration/Num Paths                         1
exploration/Average Returns                3563.04
evaluation_0/num steps total                  1.9764e+06
evaluation_0/num paths total               9378
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.38794
evaluation_0/Rewards Std                      0.887911
evaluation_0/Rewards Max                      6.88979
evaluation_0/Rewards Min                     -0.391906
evaluation_0/Returns Mean                  3387.94
evaluation_0/Returns Std                    126.8
evaluation_0/Returns Max                   3592.78
evaluation_0/Returns Min                   3247.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3387.94
time/epoch (s)                                0
time/total (s)                             5292.95
Epoch                                       253
---------------------------------------  ---------------
2022-11-16 12:15:27.347114 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 254 finished
---------------------------------------  ---------------
epoch                                       254
total_step                               259000
replay_pool/size                         259000
trainer/alpha                                 0.0530153
trainer/alpha_loss                            1.1383
trainer/entropy                              -6.38755
trainer/qf_loss                               7.24668
trainer/state_noise                           0.005
trainer/policy_loss                        -118.877
trainer/policy_loss_without_entropy         120.293
trainer/entropy_penalty                      -0.338638
trainer/entropy_percentage                   -0.0028151
trainer/Q1Pred Mean                         119.307
trainer/Q1Pred Std                           43.2096
trainer/Q1Pred Max                          196.556
trainer/Q1Pred Min                           -2.88286
trainer/Q2Pred Mean                         119.415
trainer/Q2Pred Std                           43.1896
trainer/Q2Pred Max                          193.486
trainer/Q2Pred Min                           -0.445889
trainer/QTargetWithReg Mean                 120.058
trainer/QTargetWithReg Std                   43.1466
trainer/QTargetWithReg Max                  198.025
trainer/QTargetWithReg Min                    0.140218
trainer/PolicyLossWithoutReg Mean           120.293
trainer/PolicyLossWithoutReg Std             41.9609
trainer/PolicyLossWithoutReg Max            193.798
trainer/PolicyLossWithoutReg Min              3.14763
trainer/gradient_norm                       215.527
trainer/gradient_penalty                     -1.07763
trainer/gradient_percentage                  -0.00895838
exploration/num steps total              259000
exploration/num paths total                1411
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.41328
exploration/Rewards Std                       0.897276
exploration/Rewards Max                       6.98584
exploration/Rewards Min                      -0.448317
exploration/Returns Mean                   3413.28
exploration/Returns Std                       0
exploration/Returns Max                    3413.28
exploration/Returns Min                    3413.28
exploration/Num Paths                         1
exploration/Average Returns                3413.28
evaluation_0/num steps total                  1.9844e+06
evaluation_0/num paths total               9386
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.83989
evaluation_0/Rewards Std                      1.03557
evaluation_0/Rewards Max                      7.52891
evaluation_0/Rewards Min                     -0.621517
evaluation_0/Returns Mean                  3839.89
evaluation_0/Returns Std                     99.5801
evaluation_0/Returns Max                   4049.07
evaluation_0/Returns Min                   3721.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3839.89
time/epoch (s)                                0
time/total (s)                             5381.27
Epoch                                       254
---------------------------------------  ---------------
2022-11-16 12:16:45.908617 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 255 finished
---------------------------------------  ----------------
epoch                                       255
total_step                               260000
replay_pool/size                         260000
trainer/alpha                                 0.0529195
trainer/alpha_loss                            0.0892458
trainer/entropy                              -6.03037
trainer/qf_loss                               6.91875
trainer/state_noise                           0.005
trainer/policy_loss                        -119.184
trainer/policy_loss_without_entropy         120.559
trainer/entropy_penalty                      -0.319124
trainer/entropy_percentage                   -0.00264703
trainer/Q1Pred Mean                         119.527
trainer/Q1Pred Std                           43.9165
trainer/Q1Pred Max                          204.822
trainer/Q1Pred Min                          -28.2282
trainer/Q2Pred Mean                         118.622
trainer/Q2Pred Std                           44.2304
trainer/Q2Pred Max                          206.994
trainer/Q2Pred Min                          -25.4914
trainer/QTargetWithReg Mean                 119.82
trainer/QTargetWithReg Std                   44.3582
trainer/QTargetWithReg Max                  205.175
trainer/QTargetWithReg Min                  -30.2844
trainer/PolicyLossWithoutReg Mean           120.559
trainer/PolicyLossWithoutReg Std             43.2874
trainer/PolicyLossWithoutReg Max            205.691
trainer/PolicyLossWithoutReg Min            -26.8668
trainer/gradient_norm                       211.268
trainer/gradient_penalty                     -1.05634
trainer/gradient_percentage                  -0.00876199
exploration/num steps total              260000
exploration/num paths total                1412
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.73763
exploration/Rewards Std                       0.970232
exploration/Rewards Max                       7.16934
exploration/Rewards Min                      -0.590189
exploration/Returns Mean                   3737.63
exploration/Returns Std                       0
exploration/Returns Max                    3737.63
exploration/Returns Min                    3737.63
exploration/Num Paths                         1
exploration/Average Returns                3737.63
evaluation_0/num steps total                  1.99174e+06
evaluation_0/num paths total               9394
evaluation_0/path length Mean               917.125
evaluation_0/path length Std                219.267
evaluation_0/path length Max               1000
evaluation_0/path length Min                337
evaluation_0/Rewards Mean                     3.6723
evaluation_0/Rewards Std                      1.04487
evaluation_0/Rewards Max                      8.99119
evaluation_0/Rewards Min                     -0.468588
evaluation_0/Returns Mean                  3367.96
evaluation_0/Returns Std                    770.372
evaluation_0/Returns Max                   4027.55
evaluation_0/Returns Min                   1398.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3367.96
time/epoch (s)                                0
time/total (s)                             5459.81
Epoch                                       255
---------------------------------------  ----------------
2022-11-16 12:16:59.861237 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 256 finished
---------------------------------------  ----------------
epoch                                       256
total_step                               261000
replay_pool/size                         261000
trainer/alpha                                 0.0523067
trainer/alpha_loss                            0.482792
trainer/entropy                              -6.16362
trainer/qf_loss                               5.80625
trainer/state_noise                           0.005
trainer/policy_loss                        -121.756
trainer/policy_loss_without_entropy         123.105
trainer/entropy_penalty                      -0.322399
trainer/entropy_percentage                   -0.00261889
trainer/Q1Pred Mean                         122.646
trainer/Q1Pred Std                           41.2887
trainer/Q1Pred Max                          202.18
trainer/Q1Pred Min                            3.8077
trainer/Q2Pred Mean                         122.601
trainer/Q2Pred Std                           41.0905
trainer/Q2Pred Max                          202.24
trainer/Q2Pred Min                            2.98918
trainer/QTargetWithReg Mean                 122.429
trainer/QTargetWithReg Std                   41.3957
trainer/QTargetWithReg Max                  201.987
trainer/QTargetWithReg Min                    3.6883
trainer/PolicyLossWithoutReg Mean           123.105
trainer/PolicyLossWithoutReg Std             40.8198
trainer/PolicyLossWithoutReg Max            202.075
trainer/PolicyLossWithoutReg Min              4.08482
trainer/gradient_norm                       205.344
trainer/gradient_penalty                     -1.02672
trainer/gradient_percentage                  -0.00834022
exploration/num steps total              261000
exploration/num paths total                1413
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.74802
exploration/Rewards Std                       0.973194
exploration/Rewards Max                       7.57777
exploration/Rewards Min                      -0.528586
exploration/Returns Mean                   3748.02
exploration/Returns Std                       0
exploration/Returns Max                    3748.02
exploration/Returns Min                    3748.02
exploration/Num Paths                         1
exploration/Average Returns                3748.02
evaluation_0/num steps total                  1.99928e+06
evaluation_0/num paths total               9402
evaluation_0/path length Mean               942.5
evaluation_0/path length Std                152.131
evaluation_0/path length Max               1000
evaluation_0/path length Min                540
evaluation_0/Rewards Mean                     3.82495
evaluation_0/Rewards Std                      1.01525
evaluation_0/Rewards Max                      7.99818
evaluation_0/Rewards Min                     -0.486677
evaluation_0/Returns Mean                  3605.02
evaluation_0/Returns Std                    541.189
evaluation_0/Returns Max                   3891.36
evaluation_0/Returns Min                   2178.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3605.02
time/epoch (s)                                0
time/total (s)                             5473.77
Epoch                                       256
---------------------------------------  ----------------
2022-11-16 12:17:15.754802 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 257 finished
---------------------------------------  ----------------
epoch                                       257
total_step                               262000
replay_pool/size                         262000
trainer/alpha                                 0.0532768
trainer/alpha_loss                           -1.83194
trainer/entropy                              -5.37519
trainer/qf_loss                               5.43426
trainer/state_noise                           0.005
trainer/policy_loss                        -120.328
trainer/policy_loss_without_entropy         121.626
trainer/entropy_penalty                      -0.286373
trainer/entropy_percentage                   -0.00235453
trainer/Q1Pred Mean                         120.763
trainer/Q1Pred Std                           42.1004
trainer/Q1Pred Max                          189.262
trainer/Q1Pred Min                            0.902994
trainer/Q2Pred Mean                         120.729
trainer/Q2Pred Std                           42.0315
trainer/Q2Pred Max                          187.953
trainer/Q2Pred Min                            0.801405
trainer/QTargetWithReg Mean                 120.84
trainer/QTargetWithReg Std                   42.4026
trainer/QTargetWithReg Max                  187.811
trainer/QTargetWithReg Min                   -4.79391
trainer/PolicyLossWithoutReg Mean           121.626
trainer/PolicyLossWithoutReg Std             41.7907
trainer/PolicyLossWithoutReg Max            187.819
trainer/PolicyLossWithoutReg Min              0.016579
trainer/gradient_norm                       202.267
trainer/gradient_penalty                     -1.01134
trainer/gradient_percentage                  -0.00831513
exploration/num steps total              262000
exploration/num paths total                1414
exploration/path length this epoch Mean     438
exploration/path length this epoch Std        0
exploration/path length this epoch Max      438
exploration/path length this epoch Min      438
exploration/Rewards Mean                      3.82744
exploration/Rewards Std                       1.27783
exploration/Rewards Max                       7.94186
exploration/Rewards Min                      -0.46978
exploration/Returns Mean                   1676.42
exploration/Returns Std                       0
exploration/Returns Max                    1676.42
exploration/Returns Min                    1676.42
exploration/Num Paths                         1
exploration/Average Returns                1676.42
evaluation_0/num steps total                  2.00728e+06
evaluation_0/num paths total               9410
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.83422
evaluation_0/Rewards Std                      1.00408
evaluation_0/Rewards Max                      8.88574
evaluation_0/Rewards Min                     -0.533729
evaluation_0/Returns Mean                  3834.22
evaluation_0/Returns Std                    100.428
evaluation_0/Returns Max                   4040.48
evaluation_0/Returns Min                   3713.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3834.22
time/epoch (s)                                0
time/total (s)                             5489.66
Epoch                                       257
---------------------------------------  ----------------
2022-11-16 12:17:32.037383 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 258 finished
---------------------------------------  ----------------
epoch                                       258
total_step                               263000
replay_pool/size                         263000
trainer/alpha                                 0.0516178
trainer/alpha_loss                            0.172288
trainer/entropy                              -6.05813
trainer/qf_loss                               6.23746
trainer/state_noise                           0.005
trainer/policy_loss                        -117.577
trainer/policy_loss_without_entropy         118.896
trainer/entropy_penalty                      -0.312708
trainer/entropy_percentage                   -0.0026301
trainer/Q1Pred Mean                         118.444
trainer/Q1Pred Std                           45.5215
trainer/Q1Pred Max                          190.131
trainer/Q1Pred Min                          -10.1882
trainer/Q2Pred Mean                         118.064
trainer/Q2Pred Std                           45.5561
trainer/Q2Pred Max                          190.758
trainer/Q2Pred Min                          -11.0548
trainer/QTargetWithReg Mean                 118.254
trainer/QTargetWithReg Std                   45.9673
trainer/QTargetWithReg Max                  191.385
trainer/QTargetWithReg Min                  -13.9733
trainer/PolicyLossWithoutReg Mean           118.896
trainer/PolicyLossWithoutReg Std             45.0197
trainer/PolicyLossWithoutReg Max            191.176
trainer/PolicyLossWithoutReg Min             -8.92305
trainer/gradient_norm                       201.331
trainer/gradient_penalty                     -1.00665
trainer/gradient_percentage                  -0.00846669
exploration/num steps total              263000
exploration/num paths total                1415
exploration/path length this epoch Mean     544
exploration/path length this epoch Std        0
exploration/path length this epoch Max      544
exploration/path length this epoch Min      544
exploration/Rewards Mean                      4.22103
exploration/Rewards Std                       1.43603
exploration/Rewards Max                       8.63962
exploration/Rewards Min                      -0.352437
exploration/Returns Mean                   2296.24
exploration/Returns Std                       0
exploration/Returns Max                    2296.24
exploration/Returns Min                    2296.24
exploration/Num Paths                         1
exploration/Average Returns                2296.24
evaluation_0/num steps total                  2.01528e+06
evaluation_0/num paths total               9418
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.64208
evaluation_0/Rewards Std                      0.965706
evaluation_0/Rewards Max                      7.3464
evaluation_0/Rewards Min                     -0.649643
evaluation_0/Returns Mean                  3642.08
evaluation_0/Returns Std                     20.2206
evaluation_0/Returns Max                   3669.78
evaluation_0/Returns Min                   3605.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3642.08
time/epoch (s)                                0
time/total (s)                             5505.94
Epoch                                       258
---------------------------------------  ----------------
2022-11-16 12:17:49.349756 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 259 finished
---------------------------------------  ----------------
epoch                                       259
total_step                               264000
replay_pool/size                         264000
trainer/alpha                                 0.0529021
trainer/alpha_loss                           -0.865627
trainer/entropy                              -5.7055
trainer/qf_loss                               6.06216
trainer/state_noise                           0.005
trainer/policy_loss                        -123.404
trainer/policy_loss_without_entropy         124.741
trainer/entropy_penalty                      -0.301833
trainer/entropy_percentage                   -0.00241967
trainer/Q1Pred Mean                         123.944
trainer/Q1Pred Std                           42.3142
trainer/Q1Pred Max                          187.15
trainer/Q1Pred Min                           11.4515
trainer/Q2Pred Mean                         123.931
trainer/Q2Pred Std                           42.4338
trainer/Q2Pred Max                          186.793
trainer/Q2Pred Min                           10.6522
trainer/QTargetWithReg Mean                 123.878
trainer/QTargetWithReg Std                   42.6108
trainer/QTargetWithReg Max                  188.339
trainer/QTargetWithReg Min                   10.4097
trainer/PolicyLossWithoutReg Mean           124.741
trainer/PolicyLossWithoutReg Std             41.8426
trainer/PolicyLossWithoutReg Max            187.918
trainer/PolicyLossWithoutReg Min             10.3958
trainer/gradient_norm                       207.028
trainer/gradient_penalty                     -1.03514
trainer/gradient_percentage                  -0.00829829
exploration/num steps total              264000
exploration/num paths total                1416
exploration/path length this epoch Mean     296
exploration/path length this epoch Std        0
exploration/path length this epoch Max      296
exploration/path length this epoch Min      296
exploration/Rewards Mean                      3.18006
exploration/Rewards Std                       1.20061
exploration/Rewards Max                       7.33976
exploration/Rewards Min                      -0.605923
exploration/Returns Mean                    941.298
exploration/Returns Std                       0
exploration/Returns Max                     941.298
exploration/Returns Min                     941.298
exploration/Num Paths                         1
exploration/Average Returns                 941.298
evaluation_0/num steps total                  2.02312e+06
evaluation_0/num paths total               9430
evaluation_0/path length Mean               653.25
evaluation_0/path length Std                282.238
evaluation_0/path length Max               1000
evaluation_0/path length Min                311
evaluation_0/Rewards Mean                     4.38015
evaluation_0/Rewards Std                      1.40939
evaluation_0/Rewards Max                      9.8289
evaluation_0/Rewards Min                     -0.589297
evaluation_0/Returns Mean                  2861.33
evaluation_0/Returns Std                   1210.48
evaluation_0/Returns Max                   4447.5
evaluation_0/Returns Min                   1357.29
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2861.33
time/epoch (s)                                0
time/total (s)                             5523.25
Epoch                                       259
---------------------------------------  ----------------
2022-11-16 12:18:07.385609 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 260 finished
---------------------------------------  ---------------
epoch                                       260
total_step                               265000
replay_pool/size                         265000
trainer/alpha                                 0.0533251
trainer/alpha_loss                           -0.705031
trainer/entropy                              -5.75949
trainer/qf_loss                               4.88235
trainer/state_noise                           0.005
trainer/policy_loss                        -121.731
trainer/policy_loss_without_entropy         123.083
trainer/entropy_penalty                      -0.307125
trainer/entropy_percentage                   -0.00249526
trainer/Q1Pred Mean                         122.282
trainer/Q1Pred Std                           43.184
trainer/Q1Pred Max                          197.986
trainer/Q1Pred Min                            2.95715
trainer/Q2Pred Mean                         122.472
trainer/Q2Pred Std                           43.1748
trainer/Q2Pred Max                          197.624
trainer/Q2Pred Min                           -2.99785
trainer/QTargetWithReg Mean                 121.957
trainer/QTargetWithReg Std                   43.7193
trainer/QTargetWithReg Max                  198.766
trainer/QTargetWithReg Min                    0.0251065
trainer/PolicyLossWithoutReg Mean           123.083
trainer/PolicyLossWithoutReg Std             42.5837
trainer/PolicyLossWithoutReg Max            197.744
trainer/PolicyLossWithoutReg Min              1.74151
trainer/gradient_norm                       208.978
trainer/gradient_penalty                     -1.04489
trainer/gradient_percentage                  -0.00848929
exploration/num steps total              265000
exploration/num paths total                1417
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.70551
exploration/Rewards Std                       0.972793
exploration/Rewards Max                       7.24613
exploration/Rewards Min                      -0.524108
exploration/Returns Mean                   3705.51
exploration/Returns Std                       0
exploration/Returns Max                    3705.51
exploration/Returns Min                    3705.51
exploration/Num Paths                         1
exploration/Average Returns                3705.51
evaluation_0/num steps total                  2.0306e+06
evaluation_0/num paths total               9439
evaluation_0/path length Mean               831.222
evaluation_0/path length Std                256.905
evaluation_0/path length Max               1000
evaluation_0/path length Min                295
evaluation_0/Rewards Mean                     3.76993
evaluation_0/Rewards Std                      1.1232
evaluation_0/Rewards Max                      9.74568
evaluation_0/Rewards Min                     -0.558143
evaluation_0/Returns Mean                  3133.65
evaluation_0/Returns Std                    887.656
evaluation_0/Returns Max                   3849.9
evaluation_0/Returns Min                   1225.79
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3133.65
time/epoch (s)                                0
time/total (s)                             5541.29
Epoch                                       260
---------------------------------------  ---------------
2022-11-16 12:18:24.714710 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 261 finished
---------------------------------------  ----------------
epoch                                       261
total_step                               266000
replay_pool/size                         266000
trainer/alpha                                 0.0533763
trainer/alpha_loss                            0.542
trainer/entropy                              -6.18497
trainer/qf_loss                               7.2687
trainer/state_noise                           0.005
trainer/policy_loss                        -118.677
trainer/policy_loss_without_entropy         120.06
trainer/entropy_penalty                      -0.33013
trainer/entropy_percentage                   -0.00274971
trainer/Q1Pred Mean                         118.793
trainer/Q1Pred Std                           46.0356
trainer/Q1Pred Max                          210.801
trainer/Q1Pred Min                            4.75586
trainer/Q2Pred Mean                         119.087
trainer/Q2Pred Std                           46.0184
trainer/Q2Pred Max                          211.969
trainer/Q2Pred Min                            0.0775487
trainer/QTargetWithReg Mean                 118.716
trainer/QTargetWithReg Std                   46.2641
trainer/QTargetWithReg Max                  210.007
trainer/QTargetWithReg Min                   -0.429158
trainer/PolicyLossWithoutReg Mean           120.06
trainer/PolicyLossWithoutReg Std             44.8039
trainer/PolicyLossWithoutReg Max            211.408
trainer/PolicyLossWithoutReg Min              5.26705
trainer/gradient_norm                       210.528
trainer/gradient_penalty                     -1.05264
trainer/gradient_percentage                  -0.00876762
exploration/num steps total              266000
exploration/num paths total                1418
exploration/path length this epoch Mean     402
exploration/path length this epoch Std        0
exploration/path length this epoch Max      402
exploration/path length this epoch Min      402
exploration/Rewards Mean                      4.41329
exploration/Rewards Std                       1.61592
exploration/Rewards Max                       9.39456
exploration/Rewards Min                      -0.513591
exploration/Returns Mean                   1774.14
exploration/Returns Std                       0
exploration/Returns Max                    1774.14
exploration/Returns Min                    1774.14
exploration/Num Paths                         1
exploration/Average Returns                1774.14
evaluation_0/num steps total                  2.03853e+06
evaluation_0/num paths total               9447
evaluation_0/path length Mean               991
evaluation_0/path length Std                 23.8118
evaluation_0/path length Max               1000
evaluation_0/path length Min                928
evaluation_0/Rewards Mean                     3.97178
evaluation_0/Rewards Std                      1.20602
evaluation_0/Rewards Max                      9.4435
evaluation_0/Rewards Min                     -0.492123
evaluation_0/Returns Mean                  3936.04
evaluation_0/Returns Std                    108.212
evaluation_0/Returns Max                   4092.38
evaluation_0/Returns Min                   3718.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3936.04
time/epoch (s)                                0
time/total (s)                             5558.62
Epoch                                       261
---------------------------------------  ----------------
2022-11-16 12:18:42.687165 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 262 finished
---------------------------------------  ----------------
epoch                                       262
total_step                               267000
replay_pool/size                         267000
trainer/alpha                                 0.0530367
trainer/alpha_loss                            0.350951
trainer/entropy                              -6.1195
trainer/qf_loss                               6.38555
trainer/state_noise                           0.005
trainer/policy_loss                        -124.128
trainer/policy_loss_without_entropy         125.518
trainer/entropy_penalty                      -0.324558
trainer/entropy_percentage                   -0.00258576
trainer/Q1Pred Mean                         124.069
trainer/Q1Pred Std                           41.1608
trainer/Q1Pred Max                          198.378
trainer/Q1Pred Min                            8.45463
trainer/Q2Pred Mean                         124.371
trainer/Q2Pred Std                           40.9492
trainer/Q2Pred Max                          196.851
trainer/Q2Pred Min                            5.31149
trainer/QTargetWithReg Mean                 123.952
trainer/QTargetWithReg Std                   41.1027
trainer/QTargetWithReg Max                  197.303
trainer/QTargetWithReg Min                    6.79326
trainer/PolicyLossWithoutReg Mean           125.518
trainer/PolicyLossWithoutReg Std             39.7882
trainer/PolicyLossWithoutReg Max            197.345
trainer/PolicyLossWithoutReg Min              9.62671
trainer/gradient_norm                       212.954
trainer/gradient_penalty                     -1.06477
trainer/gradient_percentage                  -0.00848304
exploration/num steps total              267000
exploration/num paths total                1419
exploration/path length this epoch Mean     902
exploration/path length this epoch Std        0
exploration/path length this epoch Max      902
exploration/path length this epoch Min      902
exploration/Rewards Mean                      4.12317
exploration/Rewards Std                       1.26789
exploration/Rewards Max                       8.9226
exploration/Rewards Min                      -0.3298
exploration/Returns Mean                   3719.1
exploration/Returns Std                       0
exploration/Returns Max                    3719.1
exploration/Returns Min                    3719.1
exploration/Num Paths                         1
exploration/Average Returns                3719.1
evaluation_0/num steps total                  2.04636e+06
evaluation_0/num paths total               9455
evaluation_0/path length Mean               978.625
evaluation_0/path length Std                 42.441
evaluation_0/path length Max               1000
evaluation_0/path length Min                873
evaluation_0/Rewards Mean                     4.10655
evaluation_0/Rewards Std                      1.21087
evaluation_0/Rewards Max                      9.51404
evaluation_0/Rewards Min                     -0.544815
evaluation_0/Returns Mean                  4018.77
evaluation_0/Returns Std                    155.982
evaluation_0/Returns Max                   4133.13
evaluation_0/Returns Min                   3616.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4018.77
time/epoch (s)                                0
time/total (s)                             5576.59
Epoch                                       262
---------------------------------------  ----------------
2022-11-16 12:19:00.685208 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 263 finished
---------------------------------------  ----------------
epoch                                       263
total_step                               268000
replay_pool/size                         268000
trainer/alpha                                 0.0536039
trainer/alpha_loss                           -0.493471
trainer/entropy                              -5.83137
trainer/qf_loss                               9.10238
trainer/state_noise                           0.005
trainer/policy_loss                        -129.733
trainer/policy_loss_without_entropy         131.108
trainer/entropy_penalty                      -0.312584
trainer/entropy_percentage                   -0.00238417
trainer/Q1Pred Mean                         130.994
trainer/Q1Pred Std                           43.8271
trainer/Q1Pred Max                          204.541
trainer/Q1Pred Min                            3.58487
trainer/Q2Pred Mean                         130.939
trainer/Q2Pred Std                           43.8617
trainer/Q2Pred Max                          205.42
trainer/Q2Pred Min                            1.83916
trainer/QTargetWithReg Mean                 130.567
trainer/QTargetWithReg Std                   44.0648
trainer/QTargetWithReg Max                  205.285
trainer/QTargetWithReg Min                    4.44186
trainer/PolicyLossWithoutReg Mean           131.108
trainer/PolicyLossWithoutReg Std             43.4067
trainer/PolicyLossWithoutReg Max            203.896
trainer/PolicyLossWithoutReg Min              3.67246
trainer/gradient_norm                       212.472
trainer/gradient_penalty                     -1.06236
trainer/gradient_percentage                  -0.00810293
exploration/num steps total              268000
exploration/num paths total                1420
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.9184
exploration/Rewards Std                       1.19955
exploration/Rewards Max                       8.59822
exploration/Rewards Min                      -0.578301
exploration/Returns Mean                   3918.4
exploration/Returns Std                       0
exploration/Returns Max                    3918.4
exploration/Returns Min                    3918.4
exploration/Num Paths                         1
exploration/Average Returns                3918.4
evaluation_0/num steps total                  2.05424e+06
evaluation_0/num paths total               9473
evaluation_0/path length Mean               438.167
evaluation_0/path length Std                255.857
evaluation_0/path length Max               1000
evaluation_0/path length Min                279
evaluation_0/Rewards Mean                     4.27022
evaluation_0/Rewards Std                      1.57737
evaluation_0/Rewards Max                      9.90913
evaluation_0/Rewards Min                     -0.585743
evaluation_0/Returns Mean                  1871.07
evaluation_0/Returns Std                   1139.59
evaluation_0/Returns Max                   4442.01
evaluation_0/Returns Min                   1141.6
evaluation_0/Num Paths                       18
evaluation_0/Average Returns               1871.07
time/epoch (s)                                0
time/total (s)                             5594.59
Epoch                                       263
---------------------------------------  ----------------
2022-11-16 12:19:18.973377 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 264 finished
---------------------------------------  ----------------
epoch                                       264
total_step                               269000
replay_pool/size                         269000
trainer/alpha                                 0.0535102
trainer/alpha_loss                            1.36537
trainer/entropy                              -6.4663
trainer/qf_loss                               6.63094
trainer/state_noise                           0.005
trainer/policy_loss                        -125.193
trainer/policy_loss_without_entropy         126.6
trainer/entropy_penalty                      -0.346013
trainer/entropy_percentage                   -0.00273311
trainer/Q1Pred Mean                         125.988
trainer/Q1Pred Std                           42.0314
trainer/Q1Pred Max                          206.475
trainer/Q1Pred Min                          -16.662
trainer/Q2Pred Mean                         125.517
trainer/Q2Pred Std                           41.6366
trainer/Q2Pred Max                          206.35
trainer/Q2Pred Min                          -13.6486
trainer/QTargetWithReg Mean                 126.158
trainer/QTargetWithReg Std                   41.7103
trainer/QTargetWithReg Max                  206.684
trainer/QTargetWithReg Min                  -15.0919
trainer/PolicyLossWithoutReg Mean           126.6
trainer/PolicyLossWithoutReg Std             41.2084
trainer/PolicyLossWithoutReg Max            205.86
trainer/PolicyLossWithoutReg Min            -10.9381
trainer/gradient_norm                       212.185
trainer/gradient_penalty                     -1.06093
trainer/gradient_percentage                  -0.00838013
exploration/num steps total              269000
exploration/num paths total                1421
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.17161
exploration/Rewards Std                       1.27943
exploration/Rewards Max                       9.11425
exploration/Rewards Min                      -0.611139
exploration/Returns Mean                   4171.61
exploration/Returns Std                       0
exploration/Returns Max                    4171.61
exploration/Returns Min                    4171.61
exploration/Num Paths                         1
exploration/Average Returns                4171.61
evaluation_0/num steps total                  2.06218e+06
evaluation_0/num paths total               9489
evaluation_0/path length Mean               496.312
evaluation_0/path length Std                234.516
evaluation_0/path length Max               1000
evaluation_0/path length Min                284
evaluation_0/Rewards Mean                     4.24617
evaluation_0/Rewards Std                      1.47317
evaluation_0/Rewards Max                     10.1069
evaluation_0/Rewards Min                     -0.603997
evaluation_0/Returns Mean                  2107.43
evaluation_0/Returns Std                   1037.39
evaluation_0/Returns Max                   4424.49
evaluation_0/Returns Min                   1157.19
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               2107.43
time/epoch (s)                                0
time/total (s)                             5612.88
Epoch                                       264
---------------------------------------  ----------------
2022-11-16 12:19:36.193813 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 265 finished
---------------------------------------  ----------------
epoch                                       265
total_step                               270000
replay_pool/size                         270000
trainer/alpha                                 0.0538048
trainer/alpha_loss                           -0.540482
trainer/entropy                              -5.81505
trainer/qf_loss                               6.42833
trainer/state_noise                           0.005
trainer/policy_loss                        -128.551
trainer/policy_loss_without_entropy         129.944
trainer/entropy_penalty                      -0.312878
trainer/entropy_percentage                   -0.00240779
trainer/Q1Pred Mean                         128.886
trainer/Q1Pred Std                           42.1535
trainer/Q1Pred Max                          203.182
trainer/Q1Pred Min                            1.4652
trainer/Q2Pred Mean                         128.842
trainer/Q2Pred Std                           42.0141
trainer/Q2Pred Max                          201.389
trainer/Q2Pred Min                            2.22099
trainer/QTargetWithReg Mean                 129.142
trainer/QTargetWithReg Std                   41.8625
trainer/QTargetWithReg Max                  204.704
trainer/QTargetWithReg Min                    0.165413
trainer/PolicyLossWithoutReg Mean           129.944
trainer/PolicyLossWithoutReg Std             40.8889
trainer/PolicyLossWithoutReg Max            199.517
trainer/PolicyLossWithoutReg Min              4.51262
trainer/gradient_norm                       215.901
trainer/gradient_penalty                     -1.07951
trainer/gradient_percentage                  -0.00830748
exploration/num steps total              270000
exploration/num paths total                1422
exploration/path length this epoch Mean     347
exploration/path length this epoch Std        0
exploration/path length this epoch Max      347
exploration/path length this epoch Min      347
exploration/Rewards Mean                      3.91879
exploration/Rewards Std                       1.49384
exploration/Rewards Max                       8.7719
exploration/Rewards Min                      -0.605584
exploration/Returns Mean                   1359.82
exploration/Returns Std                       0
exploration/Returns Max                    1359.82
exploration/Returns Min                    1359.82
exploration/Num Paths                         1
exploration/Average Returns                1359.82
evaluation_0/num steps total                  2.06937e+06
evaluation_0/num paths total               9498
evaluation_0/path length Mean               798.778
evaluation_0/path length Std                184.315
evaluation_0/path length Max               1000
evaluation_0/path length Min                551
evaluation_0/Rewards Mean                     4.20563
evaluation_0/Rewards Std                      1.28701
evaluation_0/Rewards Max                      9.85985
evaluation_0/Rewards Min                     -0.615744
evaluation_0/Returns Mean                  3359.36
evaluation_0/Returns Std                    746.328
evaluation_0/Returns Max                   4181.72
evaluation_0/Returns Min                   2332.15
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3359.36
time/epoch (s)                                0
time/total (s)                             5630.09
Epoch                                       265
---------------------------------------  ----------------
2022-11-16 12:19:53.822480 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 266 finished
---------------------------------------  ---------------
epoch                                       266
total_step                               271000
replay_pool/size                         271000
trainer/alpha                                 0.0518702
trainer/alpha_loss                            1.1267
trainer/entropy                              -6.38077
trainer/qf_loss                               7.65052
trainer/state_noise                           0.005
trainer/policy_loss                        -127.896
trainer/policy_loss_without_entropy         129.302
trainer/entropy_penalty                      -0.330972
trainer/entropy_percentage                   -0.00255967
trainer/Q1Pred Mean                         128.448
trainer/Q1Pred Std                           39.4119
trainer/Q1Pred Max                          200.446
trainer/Q1Pred Min                            0.0378194
trainer/Q2Pred Mean                         128.439
trainer/Q2Pred Std                           39.4975
trainer/Q2Pred Max                          200.204
trainer/Q2Pred Min                            1.02509
trainer/QTargetWithReg Mean                 128.514
trainer/QTargetWithReg Std                   39.479
trainer/QTargetWithReg Max                  201.003
trainer/QTargetWithReg Min                   -0.625859
trainer/PolicyLossWithoutReg Mean           129.302
trainer/PolicyLossWithoutReg Std             38.8059
trainer/PolicyLossWithoutReg Max            200.067
trainer/PolicyLossWithoutReg Min              0.909525
trainer/gradient_norm                       215.08
trainer/gradient_penalty                     -1.0754
trainer/gradient_percentage                  -0.00831693
exploration/num steps total              271000
exploration/num paths total                1423
exploration/path length this epoch Mean     684
exploration/path length this epoch Std        0
exploration/path length this epoch Max      684
exploration/path length this epoch Min      684
exploration/Rewards Mean                      4.31323
exploration/Rewards Std                       1.4357
exploration/Rewards Max                       9.82613
exploration/Rewards Min                      -0.495207
exploration/Returns Mean                   2950.25
exploration/Returns Std                       0
exploration/Returns Max                    2950.25
exploration/Returns Min                    2950.25
exploration/Num Paths                         1
exploration/Average Returns                2950.25
evaluation_0/num steps total                  2.0772e+06
evaluation_0/num paths total               9510
evaluation_0/path length Mean               652
evaluation_0/path length Std                187.708
evaluation_0/path length Max                965
evaluation_0/path length Min                420
evaluation_0/Rewards Mean                     3.85122
evaluation_0/Rewards Std                      1.40412
evaluation_0/Rewards Max                      9.51231
evaluation_0/Rewards Min                     -0.609913
evaluation_0/Returns Mean                  2510.99
evaluation_0/Returns Std                    690.027
evaluation_0/Returns Max                   3668.09
evaluation_0/Returns Min                   1679.97
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2510.99
time/epoch (s)                                0
time/total (s)                             5647.72
Epoch                                       266
---------------------------------------  ---------------
2022-11-16 12:20:09.963722 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 267 finished
---------------------------------------  ----------------
epoch                                       267
total_step                               272000
replay_pool/size                         272000
trainer/alpha                                 0.0533398
trainer/alpha_loss                            0.717349
trainer/entropy                              -6.24473
trainer/qf_loss                               7.58143
trainer/state_noise                           0.005
trainer/policy_loss                        -125.938
trainer/policy_loss_without_entropy         127.375
trainer/entropy_penalty                      -0.333092
trainer/entropy_percentage                   -0.00261506
trainer/Q1Pred Mean                         126.084
trainer/Q1Pred Std                           44.5226
trainer/Q1Pred Max                          199.77
trainer/Q1Pred Min                            0.566662
trainer/Q2Pred Mean                         125.953
trainer/Q2Pred Std                           44.708
trainer/Q2Pred Max                          198.334
trainer/Q2Pred Min                           -5.84561
trainer/QTargetWithReg Mean                 126.701
trainer/QTargetWithReg Std                   44.6483
trainer/QTargetWithReg Max                  197.794
trainer/QTargetWithReg Min                    1.77873
trainer/PolicyLossWithoutReg Mean           127.375
trainer/PolicyLossWithoutReg Std             44.2698
trainer/PolicyLossWithoutReg Max            198.252
trainer/PolicyLossWithoutReg Min             -5.6702
trainer/gradient_norm                       220.697
trainer/gradient_penalty                     -1.10349
trainer/gradient_percentage                  -0.0086633
exploration/num steps total              272000
exploration/num paths total                1424
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.06972
exploration/Rewards Std                       1.23363
exploration/Rewards Max                       8.8639
exploration/Rewards Min                      -0.560899
exploration/Returns Mean                   4069.72
exploration/Returns Std                       0
exploration/Returns Max                    4069.72
exploration/Returns Min                    4069.72
exploration/Num Paths                         1
exploration/Average Returns                4069.72
evaluation_0/num steps total                  2.08493e+06
evaluation_0/num paths total               9521
evaluation_0/path length Mean               703.364
evaluation_0/path length Std                251.253
evaluation_0/path length Max               1000
evaluation_0/path length Min                386
evaluation_0/Rewards Mean                     4.02953
evaluation_0/Rewards Std                      1.34028
evaluation_0/Rewards Max                      9.87042
evaluation_0/Rewards Min                     -0.589606
evaluation_0/Returns Mean                  2834.22
evaluation_0/Returns Std                   1082.13
evaluation_0/Returns Max                   4221.6
evaluation_0/Returns Min                   1458.69
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2834.22
time/epoch (s)                                0
time/total (s)                             5663.86
Epoch                                       267
---------------------------------------  ----------------
2022-11-16 12:20:27.412791 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 268 finished
---------------------------------------  ----------------
epoch                                       268
total_step                               273000
replay_pool/size                         273000
trainer/alpha                                 0.0531142
trainer/alpha_loss                            0.547028
trainer/entropy                              -6.18636
trainer/qf_loss                               6.83515
trainer/state_noise                           0.005
trainer/policy_loss                        -130.013
trainer/policy_loss_without_entropy         131.421
trainer/entropy_penalty                      -0.328583
trainer/entropy_percentage                   -0.00250024
trainer/Q1Pred Mean                         129.962
trainer/Q1Pred Std                           41.3802
trainer/Q1Pred Max                          198.843
trainer/Q1Pred Min                           -0.550712
trainer/Q2Pred Mean                         130.07
trainer/Q2Pred Std                           41.6022
trainer/Q2Pred Max                          199.163
trainer/Q2Pred Min                           -9.53873
trainer/QTargetWithReg Mean                 130.609
trainer/QTargetWithReg Std                   41.8216
trainer/QTargetWithReg Max                  199.616
trainer/QTargetWithReg Min                   -3.54366
trainer/PolicyLossWithoutReg Mean           131.421
trainer/PolicyLossWithoutReg Std             39.8662
trainer/PolicyLossWithoutReg Max            199.517
trainer/PolicyLossWithoutReg Min             -0.583194
trainer/gradient_norm                       215.864
trainer/gradient_penalty                     -1.07932
trainer/gradient_percentage                  -0.00821269
exploration/num steps total              273000
exploration/num paths total                1425
exploration/path length this epoch Mean     621
exploration/path length this epoch Std        0
exploration/path length this epoch Max      621
exploration/path length this epoch Min      621
exploration/Rewards Mean                      4.05239
exploration/Rewards Std                       1.317
exploration/Rewards Max                       9.70621
exploration/Rewards Min                      -0.583979
exploration/Returns Mean                   2516.53
exploration/Returns Std                       0
exploration/Returns Max                    2516.53
exploration/Returns Min                    2516.53
exploration/Num Paths                         1
exploration/Average Returns                2516.53
evaluation_0/num steps total                  2.09281e+06
evaluation_0/num paths total               9533
evaluation_0/path length Mean               656.667
evaluation_0/path length Std                113.557
evaluation_0/path length Max                909
evaluation_0/path length Min                527
evaluation_0/Rewards Mean                     4.07057
evaluation_0/Rewards Std                      1.34686
evaluation_0/Rewards Max                      9.83819
evaluation_0/Rewards Min                     -0.561622
evaluation_0/Returns Mean                  2673.01
evaluation_0/Returns Std                    497.032
evaluation_0/Returns Max                   3737.24
evaluation_0/Returns Min                   2084.75
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2673.01
time/epoch (s)                                0
time/total (s)                             5681.31
Epoch                                       268
---------------------------------------  ----------------
2022-11-16 12:20:45.657787 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 269 finished
---------------------------------------  ----------------
epoch                                       269
total_step                               274000
replay_pool/size                         274000
trainer/alpha                                 0.0527294
trainer/alpha_loss                           -0.544947
trainer/entropy                              -5.8148
trainer/qf_loss                               9.15119
trainer/state_noise                           0.005
trainer/policy_loss                        -125.286
trainer/policy_loss_without_entropy         126.689
trainer/entropy_penalty                      -0.306611
trainer/entropy_percentage                   -0.00242019
trainer/Q1Pred Mean                         126.39
trainer/Q1Pred Std                           44.8074
trainer/Q1Pred Max                          207.702
trainer/Q1Pred Min                           -4.33876
trainer/Q2Pred Mean                         126.286
trainer/Q2Pred Std                           44.9296
trainer/Q2Pred Max                          207.416
trainer/Q2Pred Min                           -7.94224
trainer/QTargetWithReg Mean                 126.085
trainer/QTargetWithReg Std                   44.7721
trainer/QTargetWithReg Max                  207.689
trainer/QTargetWithReg Min                   -6.00381
trainer/PolicyLossWithoutReg Mean           126.689
trainer/PolicyLossWithoutReg Std             43.8814
trainer/PolicyLossWithoutReg Max            207.113
trainer/PolicyLossWithoutReg Min             -2.4044
trainer/gradient_norm                       219.339
trainer/gradient_penalty                     -1.09669
trainer/gradient_percentage                  -0.00865659
exploration/num steps total              274000
exploration/num paths total                1426
exploration/path length this epoch Mean     279
exploration/path length this epoch Std        0
exploration/path length this epoch Max      279
exploration/path length this epoch Min      279
exploration/Rewards Mean                      4.11469
exploration/Rewards Std                       1.66896
exploration/Rewards Max                       9.62789
exploration/Rewards Min                      -0.513189
exploration/Returns Mean                   1148
exploration/Returns Std                       0
exploration/Returns Max                    1148
exploration/Returns Min                    1148
exploration/Num Paths                         1
exploration/Average Returns                1148
evaluation_0/num steps total                  2.10075e+06
evaluation_0/num paths total               9549
evaluation_0/path length Mean               495.75
evaluation_0/path length Std                207.652
evaluation_0/path length Max               1000
evaluation_0/path length Min                282
evaluation_0/Rewards Mean                     4.24269
evaluation_0/Rewards Std                      1.49919
evaluation_0/Rewards Max                      9.75101
evaluation_0/Rewards Min                     -0.556686
evaluation_0/Returns Mean                  2103.31
evaluation_0/Returns Std                    867.73
evaluation_0/Returns Max                   4092.85
evaluation_0/Returns Min                   1162.25
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               2103.31
time/epoch (s)                                0
time/total (s)                             5699.56
Epoch                                       269
---------------------------------------  ----------------
2022-11-16 12:21:03.203834 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 270 finished
---------------------------------------  ----------------
epoch                                       270
total_step                               275000
replay_pool/size                         275000
trainer/alpha                                 0.0535227
trainer/alpha_loss                           -1.17465
trainer/entropy                              -5.59875
trainer/qf_loss                               6.64926
trainer/state_noise                           0.005
trainer/policy_loss                        -129.468
trainer/policy_loss_without_entropy         130.868
trainer/entropy_penalty                      -0.29966
trainer/entropy_percentage                   -0.00228979
trainer/Q1Pred Mean                         130.358
trainer/Q1Pred Std                           41.5959
trainer/Q1Pred Max                          204.443
trainer/Q1Pred Min                           -0.887124
trainer/Q2Pred Mean                         130.383
trainer/Q2Pred Std                           41.3798
trainer/Q2Pred Max                          205.4
trainer/Q2Pred Min                            0.407032
trainer/QTargetWithReg Mean                 129.984
trainer/QTargetWithReg Std                   41.6153
trainer/QTargetWithReg Max                  204.767
trainer/QTargetWithReg Min                    1.37834
trainer/PolicyLossWithoutReg Mean           130.868
trainer/PolicyLossWithoutReg Std             41.0346
trainer/PolicyLossWithoutReg Max            205.737
trainer/PolicyLossWithoutReg Min             -2.03816
trainer/gradient_norm                       220.016
trainer/gradient_penalty                     -1.10008
trainer/gradient_percentage                  -0.00840604
exploration/num steps total              275000
exploration/num paths total                1428
exploration/path length this epoch Mean     384.5
exploration/path length this epoch Std       53.5
exploration/path length this epoch Max      438
exploration/path length this epoch Min      331
exploration/Rewards Mean                      4.15445
exploration/Rewards Std                       1.56471
exploration/Rewards Max                       9.82428
exploration/Rewards Min                      -0.541933
exploration/Returns Mean                   1597.39
exploration/Returns Std                     178.148
exploration/Returns Max                    1775.53
exploration/Returns Min                    1419.24
exploration/Num Paths                         2
exploration/Average Returns                1597.39
evaluation_0/num steps total                  2.10796e+06
evaluation_0/num paths total               9561
evaluation_0/path length Mean               600.833
evaluation_0/path length Std                180.692
evaluation_0/path length Max               1000
evaluation_0/path length Min                356
evaluation_0/Rewards Mean                     4.10204
evaluation_0/Rewards Std                      1.43828
evaluation_0/Rewards Max                      9.87151
evaluation_0/Rewards Min                     -0.600835
evaluation_0/Returns Mean                  2464.64
evaluation_0/Returns Std                    788.79
evaluation_0/Returns Max                   4156.33
evaluation_0/Returns Min                   1407.78
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2464.64
time/epoch (s)                                0
time/total (s)                             5717.1
Epoch                                       270
---------------------------------------  ----------------
2022-11-16 12:21:19.068143 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 271 finished
---------------------------------------  ----------------
epoch                                       271
total_step                               276000
replay_pool/size                         276000
trainer/alpha                                 0.0543234
trainer/alpha_loss                            0.547443
trainer/entropy                              -6.18794
trainer/qf_loss                               5.85201
trainer/state_noise                           0.005
trainer/policy_loss                        -122.019
trainer/policy_loss_without_entropy         123.455
trainer/entropy_penalty                      -0.33615
trainer/entropy_percentage                   -0.00272285
trainer/Q1Pred Mean                         122.137
trainer/Q1Pred Std                           47.7035
trainer/Q1Pred Max                          204.749
trainer/Q1Pred Min                           -9.66336
trainer/Q2Pred Mean                         122.374
trainer/Q2Pred Std                           47.7927
trainer/Q2Pred Max                          206.484
trainer/Q2Pred Min                          -12.9898
trainer/QTargetWithReg Mean                 122.491
trainer/QTargetWithReg Std                   47.8728
trainer/QTargetWithReg Max                  205.262
trainer/QTargetWithReg Min                   -3.69941
trainer/PolicyLossWithoutReg Mean           123.455
trainer/PolicyLossWithoutReg Std             46.7152
trainer/PolicyLossWithoutReg Max            206.152
trainer/PolicyLossWithoutReg Min             -2.76546
trainer/gradient_norm                       219.905
trainer/gradient_penalty                     -1.09953
trainer/gradient_percentage                  -0.00890628
exploration/num steps total              276000
exploration/num paths total                1429
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15851
exploration/Rewards Std                       1.24682
exploration/Rewards Max                       9.449
exploration/Rewards Min                      -0.622965
exploration/Returns Mean                   4158.51
exploration/Returns Std                       0
exploration/Returns Max                    4158.51
exploration/Returns Min                    4158.51
exploration/Num Paths                         1
exploration/Average Returns                4158.51
evaluation_0/num steps total                  2.11596e+06
evaluation_0/num paths total               9569
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.60788
evaluation_0/Rewards Std                      0.993648
evaluation_0/Rewards Max                      9.02497
evaluation_0/Rewards Min                     -0.630844
evaluation_0/Returns Mean                  3607.88
evaluation_0/Returns Std                    194.258
evaluation_0/Returns Max                   4084.92
evaluation_0/Returns Min                   3454.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3607.88
time/epoch (s)                                0
time/total (s)                             5732.97
Epoch                                       271
---------------------------------------  ----------------
2022-11-16 12:21:36.853466 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 272 finished
---------------------------------------  ----------------
epoch                                       272
total_step                               277000
replay_pool/size                         277000
trainer/alpha                                 0.0526241
trainer/alpha_loss                           -0.122246
trainer/entropy                              -5.95848
trainer/qf_loss                               7.17078
trainer/state_noise                           0.005
trainer/policy_loss                        -125.158
trainer/policy_loss_without_entropy         126.49
trainer/entropy_penalty                      -0.31356
trainer/entropy_percentage                   -0.00247893
trainer/Q1Pred Mean                         126.1
trainer/Q1Pred Std                           45.0548
trainer/Q1Pred Max                          205.201
trainer/Q1Pred Min                           -1.42107
trainer/Q2Pred Mean                         125.832
trainer/Q2Pred Std                           44.7199
trainer/Q2Pred Max                          206.086
trainer/Q2Pred Min                            1.78173
trainer/QTargetWithReg Mean                 125.679
trainer/QTargetWithReg Std                   45.0891
trainer/QTargetWithReg Max                  205.355
trainer/QTargetWithReg Min                   -7.4199
trainer/PolicyLossWithoutReg Mean           126.49
trainer/PolicyLossWithoutReg Std             44.28
trainer/PolicyLossWithoutReg Max            205.123
trainer/PolicyLossWithoutReg Min              0.850308
trainer/gradient_norm                       203.564
trainer/gradient_penalty                     -1.01782
trainer/gradient_percentage                  -0.00804665
exploration/num steps total              277000
exploration/num paths total                1430
exploration/path length this epoch Mean     345
exploration/path length this epoch Std        0
exploration/path length this epoch Max      345
exploration/path length this epoch Min      345
exploration/Rewards Mean                      3.42751
exploration/Rewards Std                       1.32971
exploration/Rewards Max                       6.9142
exploration/Rewards Min                      -0.60879
exploration/Returns Mean                   1182.49
exploration/Returns Std                       0
exploration/Returns Max                    1182.49
exploration/Returns Min                    1182.49
exploration/Num Paths                         1
exploration/Average Returns                1182.49
evaluation_0/num steps total                  2.12393e+06
evaluation_0/num paths total               9583
evaluation_0/path length Mean               569.5
evaluation_0/path length Std                284.496
evaluation_0/path length Max               1000
evaluation_0/path length Min                285
evaluation_0/Rewards Mean                     4.17585
evaluation_0/Rewards Std                      1.38785
evaluation_0/Rewards Max                      9.31134
evaluation_0/Rewards Min                     -0.558895
evaluation_0/Returns Mean                  2378.15
evaluation_0/Returns Std                   1154.44
evaluation_0/Returns Max                   4081.66
evaluation_0/Returns Min                   1189.81
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2378.15
time/epoch (s)                                0
time/total (s)                             5750.75
Epoch                                       272
---------------------------------------  ----------------
2022-11-16 12:21:54.371003 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 273 finished
---------------------------------------  ----------------
epoch                                       273
total_step                               278000
replay_pool/size                         278000
trainer/alpha                                 0.0549917
trainer/alpha_loss                            0.642224
trainer/entropy                              -6.22142
trainer/qf_loss                               6.95017
trainer/state_noise                           0.005
trainer/policy_loss                        -129.125
trainer/policy_loss_without_entropy         130.572
trainer/entropy_penalty                      -0.342126
trainer/entropy_percentage                   -0.00262021
trainer/Q1Pred Mean                         129.787
trainer/Q1Pred Std                           43.8488
trainer/Q1Pred Max                          213.138
trainer/Q1Pred Min                            2.04251
trainer/Q2Pred Mean                         129.993
trainer/Q2Pred Std                           44.1032
trainer/Q2Pred Max                          213.873
trainer/Q2Pred Min                           -0.640044
trainer/QTargetWithReg Mean                 130.136
trainer/QTargetWithReg Std                   43.9361
trainer/QTargetWithReg Max                  213.069
trainer/QTargetWithReg Min                    3.29388
trainer/PolicyLossWithoutReg Mean           130.572
trainer/PolicyLossWithoutReg Std             43.4693
trainer/PolicyLossWithoutReg Max            213.151
trainer/PolicyLossWithoutReg Min              2.13117
trainer/gradient_norm                       220.996
trainer/gradient_penalty                     -1.10498
trainer/gradient_percentage                  -0.00846261
exploration/num steps total              278000
exploration/num paths total                1431
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.20431
exploration/Rewards Std                       1.24617
exploration/Rewards Max                       9.63471
exploration/Rewards Min                      -0.471779
exploration/Returns Mean                   4204.31
exploration/Returns Std                       0
exploration/Returns Max                    4204.31
exploration/Returns Min                    4204.31
exploration/Num Paths                         1
exploration/Average Returns                4204.31
evaluation_0/num steps total                  2.13169e+06
evaluation_0/num paths total               9592
evaluation_0/path length Mean               862.111
evaluation_0/path length Std                231.568
evaluation_0/path length Max               1000
evaluation_0/path length Min                410
evaluation_0/Rewards Mean                     3.95981
evaluation_0/Rewards Std                      1.1899
evaluation_0/Rewards Max                      9.85567
evaluation_0/Rewards Min                     -0.604244
evaluation_0/Returns Mean                  3413.8
evaluation_0/Returns Std                    859.531
evaluation_0/Returns Max                   4182.3
evaluation_0/Returns Min                   1737.12
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3413.8
time/epoch (s)                                0
time/total (s)                             5768.27
Epoch                                       273
---------------------------------------  ----------------
2022-11-16 12:22:11.623439 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 274 finished
---------------------------------------  ----------------
epoch                                       274
total_step                               279000
replay_pool/size                         279000
trainer/alpha                                 0.0528623
trainer/alpha_loss                           -1.40668
trainer/entropy                              -5.5215
trainer/qf_loss                               5.9611
trainer/state_noise                           0.005
trainer/policy_loss                        -128.493
trainer/policy_loss_without_entropy         129.855
trainer/entropy_penalty                      -0.291879
trainer/entropy_percentage                   -0.00224774
trainer/Q1Pred Mean                         129.57
trainer/Q1Pred Std                           46.1488
trainer/Q1Pred Max                          212.08
trainer/Q1Pred Min                            1.98865
trainer/Q2Pred Mean                         129.107
trainer/Q2Pred Std                           46.3764
trainer/Q2Pred Max                          212.095
trainer/Q2Pred Min                           -3.99493
trainer/QTargetWithReg Mean                 129.591
trainer/QTargetWithReg Std                   46.2241
trainer/QTargetWithReg Max                  212.226
trainer/QTargetWithReg Min                   -2.6996
trainer/PolicyLossWithoutReg Mean           129.855
trainer/PolicyLossWithoutReg Std             45.7129
trainer/PolicyLossWithoutReg Max            210.928
trainer/PolicyLossWithoutReg Min              0.316072
trainer/gradient_norm                       213.949
trainer/gradient_penalty                     -1.06974
trainer/gradient_percentage                  -0.008238
exploration/num steps total              279000
exploration/num paths total                1432
exploration/path length this epoch Mean     799
exploration/path length this epoch Std        0
exploration/path length this epoch Max      799
exploration/path length this epoch Min      799
exploration/Rewards Mean                      4.28302
exploration/Rewards Std                       1.32187
exploration/Rewards Max                       9.85012
exploration/Rewards Min                      -0.552863
exploration/Returns Mean                   3422.13
exploration/Returns Std                       0
exploration/Returns Max                    3422.13
exploration/Returns Min                    3422.13
exploration/Num Paths                         1
exploration/Average Returns                3422.13
evaluation_0/num steps total                  2.13932e+06
evaluation_0/num paths total               9606
evaluation_0/path length Mean               545.5
evaluation_0/path length Std                212.02
evaluation_0/path length Max               1000
evaluation_0/path length Min                328
evaluation_0/Rewards Mean                     4.39014
evaluation_0/Rewards Std                      1.50072
evaluation_0/Rewards Max                      9.83384
evaluation_0/Rewards Min                     -0.571006
evaluation_0/Returns Mean                  2394.82
evaluation_0/Returns Std                    977.73
evaluation_0/Returns Max                   4462.17
evaluation_0/Returns Min                   1381.72
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2394.82
time/epoch (s)                                0
time/total (s)                             5785.52
Epoch                                       274
---------------------------------------  ----------------
2022-11-16 12:22:29.376830 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 275 finished
---------------------------------------  ----------------
epoch                                       275
total_step                               280000
replay_pool/size                         280000
trainer/alpha                                 0.0534342
trainer/alpha_loss                           -0.214296
trainer/entropy                              -5.92685
trainer/qf_loss                               6.85786
trainer/state_noise                           0.005
trainer/policy_loss                        -128.779
trainer/policy_loss_without_entropy         130.199
trainer/entropy_penalty                      -0.316696
trainer/entropy_percentage                   -0.00243239
trainer/Q1Pred Mean                         129.746
trainer/Q1Pred Std                           42.3914
trainer/Q1Pred Max                          206.211
trainer/Q1Pred Min                          -15.7027
trainer/Q2Pred Mean                         130.37
trainer/Q2Pred Std                           42.638
trainer/Q2Pred Max                          209.312
trainer/Q2Pred Min                          -14.1814
trainer/QTargetWithReg Mean                 129.714
trainer/QTargetWithReg Std                   42.3687
trainer/QTargetWithReg Max                  205.968
trainer/QTargetWithReg Min                  -10.6957
trainer/PolicyLossWithoutReg Mean           130.2
trainer/PolicyLossWithoutReg Std             42.1434
trainer/PolicyLossWithoutReg Max            205.27
trainer/PolicyLossWithoutReg Min            -11.6488
trainer/gradient_norm                       220.676
trainer/gradient_penalty                     -1.10338
trainer/gradient_percentage                  -0.00847452
exploration/num steps total              280000
exploration/num paths total                1433
exploration/path length this epoch Mean     594
exploration/path length this epoch Std        0
exploration/path length this epoch Max      594
exploration/path length this epoch Min      594
exploration/Rewards Mean                      3.94652
exploration/Rewards Std                       1.3929
exploration/Rewards Max                       9.19078
exploration/Rewards Min                      -0.587198
exploration/Returns Mean                   2344.23
exploration/Returns Std                       0
exploration/Returns Max                    2344.23
exploration/Returns Min                    2344.23
exploration/Num Paths                         1
exploration/Average Returns                2344.23
evaluation_0/num steps total                  2.14686e+06
evaluation_0/num paths total               9617
evaluation_0/path length Mean               684.909
evaluation_0/path length Std                298.862
evaluation_0/path length Max               1000
evaluation_0/path length Min                283
evaluation_0/Rewards Mean                     4.14949
evaluation_0/Rewards Std                      1.30658
evaluation_0/Rewards Max                      9.94524
evaluation_0/Rewards Min                     -0.576043
evaluation_0/Returns Mean                  2842.03
evaluation_0/Returns Std                   1175.98
evaluation_0/Returns Max                   4118.88
evaluation_0/Returns Min                   1194.87
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2842.03
time/epoch (s)                                0
time/total (s)                             5803.28
Epoch                                       275
---------------------------------------  ----------------
2022-11-16 12:22:46.809327 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 276 finished
---------------------------------------  ----------------
epoch                                       276
total_step                               281000
replay_pool/size                         281000
trainer/alpha                                 0.0538056
trainer/alpha_loss                            1.07227
trainer/entropy                              -6.36691
trainer/qf_loss                               7.75176
trainer/state_noise                           0.005
trainer/policy_loss                        -127.968
trainer/policy_loss_without_entropy         129.411
trainer/entropy_penalty                      -0.342575
trainer/entropy_percentage                   -0.00264718
trainer/Q1Pred Mean                         128.681
trainer/Q1Pred Std                           43.4379
trainer/Q1Pred Max                          216.537
trainer/Q1Pred Min                            5.13067
trainer/Q2Pred Mean                         128.692
trainer/Q2Pred Std                           43.4354
trainer/Q2Pred Max                          215.992
trainer/Q2Pred Min                            6.82495
trainer/QTargetWithReg Mean                 128.275
trainer/QTargetWithReg Std                   44.029
trainer/QTargetWithReg Max                  216.088
trainer/QTargetWithReg Min                    1.87917
trainer/PolicyLossWithoutReg Mean           129.411
trainer/PolicyLossWithoutReg Std             43.1035
trainer/PolicyLossWithoutReg Max            216.187
trainer/PolicyLossWithoutReg Min              5.45957
trainer/gradient_norm                       220.165
trainer/gradient_penalty                     -1.10083
trainer/gradient_percentage                  -0.00850641
exploration/num steps total              281000
exploration/num paths total                1434
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37778
exploration/Rewards Std                       1.33265
exploration/Rewards Max                      10.0907
exploration/Rewards Min                      -0.515241
exploration/Returns Mean                   4377.78
exploration/Returns Std                       0
exploration/Returns Max                    4377.78
exploration/Returns Min                    4377.78
exploration/Num Paths                         1
exploration/Average Returns                4377.78
evaluation_0/num steps total                  2.15419e+06
evaluation_0/num paths total               9627
evaluation_0/path length Mean               733.5
evaluation_0/path length Std                214.337
evaluation_0/path length Max               1000
evaluation_0/path length Min                373
evaluation_0/Rewards Mean                     4.26079
evaluation_0/Rewards Std                      1.38166
evaluation_0/Rewards Max                     10.0403
evaluation_0/Rewards Min                     -0.694498
evaluation_0/Returns Mean                  3125.29
evaluation_0/Returns Std                    907.003
evaluation_0/Returns Max                   4312.59
evaluation_0/Returns Min                   1589.15
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3125.29
time/epoch (s)                                0
time/total (s)                             5820.71
Epoch                                       276
---------------------------------------  ----------------
2022-11-16 12:23:04.890944 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 277 finished
---------------------------------------  ----------------
epoch                                       277
total_step                               282000
replay_pool/size                         282000
trainer/alpha                                 0.0544767
trainer/alpha_loss                            1.61458
trainer/entropy                              -6.55484
trainer/qf_loss                               7.73127
trainer/state_noise                           0.005
trainer/policy_loss                        -130.969
trainer/policy_loss_without_entropy         132.423
trainer/entropy_penalty                      -0.357086
trainer/entropy_percentage                   -0.00269655
trainer/Q1Pred Mean                         131.576
trainer/Q1Pred Std                           45.0268
trainer/Q1Pred Max                          213.274
trainer/Q1Pred Min                            7.68351
trainer/Q2Pred Mean                         131.859
trainer/Q2Pred Std                           45.0191
trainer/Q2Pred Max                          211.205
trainer/Q2Pred Min                            5.62641
trainer/QTargetWithReg Mean                 131.543
trainer/QTargetWithReg Std                   45.2306
trainer/QTargetWithReg Max                  213.556
trainer/QTargetWithReg Min                   -0.537562
trainer/PolicyLossWithoutReg Mean           132.423
trainer/PolicyLossWithoutReg Std             44.5256
trainer/PolicyLossWithoutReg Max            211.023
trainer/PolicyLossWithoutReg Min              8.54364
trainer/gradient_norm                       219.537
trainer/gradient_penalty                     -1.09769
trainer/gradient_percentage                  -0.00828922
exploration/num steps total              282000
exploration/num paths total                1435
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.97083
exploration/Rewards Std                       1.24606
exploration/Rewards Max                       9.34843
exploration/Rewards Min                      -0.714941
exploration/Returns Mean                   3970.83
exploration/Returns Std                       0
exploration/Returns Max                    3970.83
exploration/Returns Min                    3970.83
exploration/Num Paths                         1
exploration/Average Returns                3970.83
evaluation_0/num steps total                  2.16198e+06
evaluation_0/num paths total               9637
evaluation_0/path length Mean               778.3
evaluation_0/path length Std                282.783
evaluation_0/path length Max               1000
evaluation_0/path length Min                237
evaluation_0/Rewards Mean                     4.0598
evaluation_0/Rewards Std                      1.3256
evaluation_0/Rewards Max                     10.0821
evaluation_0/Rewards Min                     -0.510875
evaluation_0/Returns Mean                  3159.74
evaluation_0/Returns Std                   1114.62
evaluation_0/Returns Max                   4328.48
evaluation_0/Returns Min                    860.752
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3159.74
time/epoch (s)                                0
time/total (s)                             5838.79
Epoch                                       277
---------------------------------------  ----------------
2022-11-16 12:23:22.223760 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 278 finished
---------------------------------------  ----------------
epoch                                       278
total_step                               283000
replay_pool/size                         283000
trainer/alpha                                 0.0574501
trainer/alpha_loss                           -0.475949
trainer/entropy                              -5.8334
trainer/qf_loss                               6.41307
trainer/state_noise                           0.005
trainer/policy_loss                        -132.147
trainer/policy_loss_without_entropy         133.557
trainer/entropy_penalty                      -0.33513
trainer/entropy_percentage                   -0.00250926
trainer/Q1Pred Mean                         132.912
trainer/Q1Pred Std                           43.4283
trainer/Q1Pred Max                          216.116
trainer/Q1Pred Min                            1.52225
trainer/Q2Pred Mean                         132.694
trainer/Q2Pred Std                           43.656
trainer/Q2Pred Max                          216.256
trainer/Q2Pred Min                           -1.92719
trainer/QTargetWithReg Mean                 132.926
trainer/QTargetWithReg Std                   43.539
trainer/QTargetWithReg Max                  218.133
trainer/QTargetWithReg Min                    2.34654
trainer/PolicyLossWithoutReg Mean           133.557
trainer/PolicyLossWithoutReg Std             43.1738
trainer/PolicyLossWithoutReg Max            216.234
trainer/PolicyLossWithoutReg Min             -1.11109
trainer/gradient_norm                       214.945
trainer/gradient_penalty                     -1.07472
trainer/gradient_percentage                  -0.00804692
exploration/num steps total              283000
exploration/num paths total                1436
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.87822
exploration/Rewards Std                       1.24262
exploration/Rewards Max                       8.7114
exploration/Rewards Min                      -0.626499
exploration/Returns Mean                   3878.22
exploration/Returns Std                       0
exploration/Returns Max                    3878.22
exploration/Returns Min                    3878.22
exploration/Num Paths                         1
exploration/Average Returns                3878.22
evaluation_0/num steps total                  2.16940e+06
evaluation_0/num paths total               9646
evaluation_0/path length Mean               825.333
evaluation_0/path length Std                210.434
evaluation_0/path length Max               1000
evaluation_0/path length Min                432
evaluation_0/Rewards Mean                     3.92204
evaluation_0/Rewards Std                      1.24037
evaluation_0/Rewards Max                      9.25292
evaluation_0/Rewards Min                     -0.69045
evaluation_0/Returns Mean                  3236.99
evaluation_0/Returns Std                    691.98
evaluation_0/Returns Max                   3892.81
evaluation_0/Returns Min                   1867.09
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3236.99
time/epoch (s)                                0
time/total (s)                             5856.12
Epoch                                       278
---------------------------------------  ----------------
2022-11-16 12:23:38.694241 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 279 finished
---------------------------------------  ----------------
epoch                                       279
total_step                               284000
replay_pool/size                         284000
trainer/alpha                                 0.0552062
trainer/alpha_loss                            0.115536
trainer/entropy                              -6.03988
trainer/qf_loss                               8.16265
trainer/state_noise                           0.005
trainer/policy_loss                        -134.511
trainer/policy_loss_without_entropy         135.929
trainer/entropy_penalty                      -0.333439
trainer/entropy_percentage                   -0.00245303
trainer/Q1Pred Mean                         135.174
trainer/Q1Pred Std                           39.2115
trainer/Q1Pred Max                          211.965
trainer/Q1Pred Min                            7.0826
trainer/Q2Pred Mean                         135.335
trainer/Q2Pred Std                           39.2889
trainer/Q2Pred Max                          210.966
trainer/Q2Pred Min                            3.90405
trainer/QTargetWithReg Mean                 134.835
trainer/QTargetWithReg Std                   39.0093
trainer/QTargetWithReg Max                  208.541
trainer/QTargetWithReg Min                    3.34685
trainer/PolicyLossWithoutReg Mean           135.929
trainer/PolicyLossWithoutReg Std             38.3997
trainer/PolicyLossWithoutReg Max            211.622
trainer/PolicyLossWithoutReg Min              4.51869
trainer/gradient_norm                       216.913
trainer/gradient_penalty                     -1.08457
trainer/gradient_percentage                  -0.00797889
exploration/num steps total              284000
exploration/num paths total                1437
exploration/path length this epoch Mean     617
exploration/path length this epoch Std        0
exploration/path length this epoch Max      617
exploration/path length this epoch Min      617
exploration/Rewards Mean                      4.14052
exploration/Rewards Std                       1.45342
exploration/Rewards Max                       9.49512
exploration/Rewards Min                      -0.731727
exploration/Returns Mean                   2554.7
exploration/Returns Std                       0
exploration/Returns Max                    2554.7
exploration/Returns Min                    2554.7
exploration/Num Paths                         1
exploration/Average Returns                2554.7
evaluation_0/num steps total                  2.17740e+06
evaluation_0/num paths total               9654
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.65248
evaluation_0/Rewards Std                      0.979069
evaluation_0/Rewards Max                      8.04008
evaluation_0/Rewards Min                     -0.550744
evaluation_0/Returns Mean                  3652.48
evaluation_0/Returns Std                     46.2524
evaluation_0/Returns Max                   3755.25
evaluation_0/Returns Min                   3602.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3652.48
time/epoch (s)                                0
time/total (s)                             5872.59
Epoch                                       279
---------------------------------------  ----------------
2022-11-16 12:23:55.828273 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 280 finished
---------------------------------------  ----------------
epoch                                       280
total_step                               285000
replay_pool/size                         285000
trainer/alpha                                 0.0553667
trainer/alpha_loss                           -0.415648
trainer/entropy                              -5.85636
trainer/qf_loss                               8.36991
trainer/state_noise                           0.005
trainer/policy_loss                        -131.35
trainer/policy_loss_without_entropy         132.832
trainer/entropy_penalty                      -0.324248
trainer/entropy_percentage                   -0.00244104
trainer/Q1Pred Mean                         132.017
trainer/Q1Pred Std                           45.2008
trainer/Q1Pred Max                          216.818
trainer/Q1Pred Min                            1.54641
trainer/Q2Pred Mean                         131.984
trainer/Q2Pred Std                           45.3368
trainer/Q2Pred Max                          217.348
trainer/Q2Pred Min                            0.921737
trainer/QTargetWithReg Mean                 131.958
trainer/QTargetWithReg Std                   45.4055
trainer/QTargetWithReg Max                  216.951
trainer/QTargetWithReg Min                   -0.287351
trainer/PolicyLossWithoutReg Mean           132.832
trainer/PolicyLossWithoutReg Std             44.8819
trainer/PolicyLossWithoutReg Max            216.667
trainer/PolicyLossWithoutReg Min             10.4391
trainer/gradient_norm                       231.495
trainer/gradient_penalty                     -1.15747
trainer/gradient_percentage                  -0.00871383
exploration/num steps total              285000
exploration/num paths total                1438
exploration/path length this epoch Mean     665
exploration/path length this epoch Std        0
exploration/path length this epoch Max      665
exploration/path length this epoch Min      665
exploration/Rewards Mean                      4.3346
exploration/Rewards Std                       1.49579
exploration/Rewards Max                      10.1701
exploration/Rewards Min                      -0.459628
exploration/Returns Mean                   2882.51
exploration/Returns Std                       0
exploration/Returns Max                    2882.51
exploration/Returns Min                    2882.51
exploration/Num Paths                         1
exploration/Average Returns                2882.51
evaluation_0/num steps total                  2.18505e+06
evaluation_0/num paths total               9664
evaluation_0/path length Mean               764.9
evaluation_0/path length Std                261.328
evaluation_0/path length Max               1000
evaluation_0/path length Min                275
evaluation_0/Rewards Mean                     4.24429
evaluation_0/Rewards Std                      1.37582
evaluation_0/Rewards Max                      9.92995
evaluation_0/Rewards Min                     -0.547708
evaluation_0/Returns Mean                  3246.46
evaluation_0/Returns Std                   1039.55
evaluation_0/Returns Max                   4435.5
evaluation_0/Returns Min                   1225.89
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3246.46
time/epoch (s)                                0
time/total (s)                             5889.73
Epoch                                       280
---------------------------------------  ----------------
2022-11-16 12:24:13.747691 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 281 finished
---------------------------------------  ---------------
epoch                                       281
total_step                               286000
replay_pool/size                         286000
trainer/alpha                                 0.0554745
trainer/alpha_loss                           -0.070122
trainer/entropy                              -5.97575
trainer/qf_loss                               5.83192
trainer/state_noise                           0.005
trainer/policy_loss                        -131.259
trainer/policy_loss_without_entropy         132.679
trainer/entropy_penalty                      -0.331502
trainer/entropy_percentage                   -0.00249853
trainer/Q1Pred Mean                         131.698
trainer/Q1Pred Std                           47.7004
trainer/Q1Pred Max                          221.653
trainer/Q1Pred Min                            1.25098
trainer/Q2Pred Mean                         132.345
trainer/Q2Pred Std                           47.6874
trainer/Q2Pred Max                          219.559
trainer/Q2Pred Min                            2.45626
trainer/QTargetWithReg Mean                 131.728
trainer/QTargetWithReg Std                   47.7659
trainer/QTargetWithReg Max                  219.564
trainer/QTargetWithReg Min                    4.5659
trainer/PolicyLossWithoutReg Mean           132.679
trainer/PolicyLossWithoutReg Std             47.3051
trainer/PolicyLossWithoutReg Max            220.569
trainer/PolicyLossWithoutReg Min              1.73206
trainer/gradient_norm                       217.634
trainer/gradient_penalty                     -1.08817
trainer/gradient_percentage                  -0.00820156
exploration/num steps total              286000
exploration/num paths total                1439
exploration/path length this epoch Mean     988
exploration/path length this epoch Std        0
exploration/path length this epoch Max      988
exploration/path length this epoch Min      988
exploration/Rewards Mean                      3.97708
exploration/Rewards Std                       1.32055
exploration/Rewards Max                       9.5087
exploration/Rewards Min                      -0.467392
exploration/Returns Mean                   3929.36
exploration/Returns Std                       0
exploration/Returns Max                    3929.36
exploration/Returns Min                    3929.36
exploration/Num Paths                         1
exploration/Average Returns                3929.36
evaluation_0/num steps total                  2.1922e+06
evaluation_0/num paths total               9674
evaluation_0/path length Mean               714.5
evaluation_0/path length Std                284.977
evaluation_0/path length Max               1000
evaluation_0/path length Min                311
evaluation_0/Rewards Mean                     4.26029
evaluation_0/Rewards Std                      1.35395
evaluation_0/Rewards Max                     10.0948
evaluation_0/Rewards Min                     -0.548284
evaluation_0/Returns Mean                  3043.97
evaluation_0/Returns Std                   1107.44
evaluation_0/Returns Max                   4396.9
evaluation_0/Returns Min                   1380.39
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3043.97
time/epoch (s)                                0
time/total (s)                             5907.64
Epoch                                       281
---------------------------------------  ---------------
2022-11-16 12:24:31.169588 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 282 finished
---------------------------------------  ----------------
epoch                                       282
total_step                               287000
replay_pool/size                         287000
trainer/alpha                                 0.0561807
trainer/alpha_loss                           -0.0437079
trainer/entropy                              -5.98482
trainer/qf_loss                               5.76858
trainer/state_noise                           0.005
trainer/policy_loss                        -133.264
trainer/policy_loss_without_entropy         134.693
trainer/entropy_penalty                      -0.336231
trainer/entropy_percentage                   -0.00249627
trainer/Q1Pred Mean                         134.274
trainer/Q1Pred Std                           43.1369
trainer/Q1Pred Max                          209.063
trainer/Q1Pred Min                            1.59716
trainer/Q2Pred Mean                         133.764
trainer/Q2Pred Std                           43.0604
trainer/Q2Pred Max                          209.989
trainer/Q2Pred Min                            3.49893
trainer/QTargetWithReg Mean                 134.105
trainer/QTargetWithReg Std                   42.8585
trainer/QTargetWithReg Max                  209.336
trainer/QTargetWithReg Min                    3.85445
trainer/PolicyLossWithoutReg Mean           134.693
trainer/PolicyLossWithoutReg Std             42.5921
trainer/PolicyLossWithoutReg Max            209.727
trainer/PolicyLossWithoutReg Min              2.5806
trainer/gradient_norm                       218.694
trainer/gradient_penalty                     -1.09347
trainer/gradient_percentage                  -0.00811822
exploration/num steps total              287000
exploration/num paths total                1440
exploration/path length this epoch Mean     373
exploration/path length this epoch Std        0
exploration/path length this epoch Max      373
exploration/path length this epoch Min      373
exploration/Rewards Mean                      4.22398
exploration/Rewards Std                       1.57971
exploration/Rewards Max                       9.2394
exploration/Rewards Min                      -0.3837
exploration/Returns Mean                   1575.54
exploration/Returns Std                       0
exploration/Returns Max                    1575.54
exploration/Returns Min                    1575.54
exploration/Num Paths                         1
exploration/Average Returns                1575.54
evaluation_0/num steps total                  2.19999e+06
evaluation_0/num paths total               9683
evaluation_0/path length Mean               865.222
evaluation_0/path length Std                220.932
evaluation_0/path length Max               1000
evaluation_0/path length Min                415
evaluation_0/Rewards Mean                     3.97787
evaluation_0/Rewards Std                      1.27635
evaluation_0/Rewards Max                      9.7055
evaluation_0/Rewards Min                     -0.552638
evaluation_0/Returns Mean                  3441.74
evaluation_0/Returns Std                    820.213
evaluation_0/Returns Max                   3972.32
evaluation_0/Returns Min                   1724.44
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3441.74
time/epoch (s)                                0
time/total (s)                             5925.07
Epoch                                       282
---------------------------------------  ----------------
2022-11-16 12:24:48.989639 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 283 finished
---------------------------------------  ----------------
epoch                                       283
total_step                               288000
replay_pool/size                         288000
trainer/alpha                                 0.0565962
trainer/alpha_loss                           -1.23269
trainer/entropy                              -5.57074
trainer/qf_loss                               5.94111
trainer/state_noise                           0.005
trainer/policy_loss                        -133.102
trainer/policy_loss_without_entropy         134.556
trainer/entropy_penalty                      -0.315283
trainer/entropy_percentage                   -0.00234314
trainer/Q1Pred Mean                         134.022
trainer/Q1Pred Std                           46.6863
trainer/Q1Pred Max                          219.066
trainer/Q1Pred Min                           -2.08236
trainer/Q2Pred Mean                         134.492
trainer/Q2Pred Std                           46.8607
trainer/Q2Pred Max                          219.139
trainer/Q2Pred Min                           -0.975838
trainer/QTargetWithReg Mean                 133.731
trainer/QTargetWithReg Std                   46.8036
trainer/QTargetWithReg Max                  219.915
trainer/QTargetWithReg Min                   -5.78352
trainer/PolicyLossWithoutReg Mean           134.556
trainer/PolicyLossWithoutReg Std             46.236
trainer/PolicyLossWithoutReg Max            218.181
trainer/PolicyLossWithoutReg Min             -1.3363
trainer/gradient_norm                       227.665
trainer/gradient_penalty                     -1.13833
trainer/gradient_percentage                  -0.00845989
exploration/num steps total              288000
exploration/num paths total                1441
exploration/path length this epoch Mean     229
exploration/path length this epoch Std        0
exploration/path length this epoch Max      229
exploration/path length this epoch Min      229
exploration/Rewards Mean                      4.11302
exploration/Rewards Std                       1.75812
exploration/Rewards Max                       9.46764
exploration/Rewards Min                      -0.61712
exploration/Returns Mean                    941.882
exploration/Returns Std                       0
exploration/Returns Max                     941.882
exploration/Returns Min                     941.882
exploration/Num Paths                         1
exploration/Average Returns                 941.882
evaluation_0/num steps total                  2.20704e+06
evaluation_0/num paths total               9691
evaluation_0/path length Mean               882
evaluation_0/path length Std                237.006
evaluation_0/path length Max               1000
evaluation_0/path length Min                288
evaluation_0/Rewards Mean                     3.88376
evaluation_0/Rewards Std                      1.20596
evaluation_0/Rewards Max                      9.09883
evaluation_0/Rewards Min                     -0.549832
evaluation_0/Returns Mean                  3425.47
evaluation_0/Returns Std                   1020.99
evaluation_0/Returns Max                   4238.96
evaluation_0/Returns Min                   1058.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3425.47
time/epoch (s)                                0
time/total (s)                             5942.89
Epoch                                       283
---------------------------------------  ----------------
2022-11-16 12:25:04.495344 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 284 finished
---------------------------------------  ----------------
epoch                                       284
total_step                               289000
replay_pool/size                         289000
trainer/alpha                                 0.0574976
trainer/alpha_loss                            0.398931
trainer/entropy                              -6.13968
trainer/qf_loss                               5.64149
trainer/state_noise                           0.005
trainer/policy_loss                        -132.752
trainer/policy_loss_without_entropy         134.227
trainer/entropy_penalty                      -0.353017
trainer/entropy_percentage                   -0.00263001
trainer/Q1Pred Mean                         133.646
trainer/Q1Pred Std                           43.9519
trainer/Q1Pred Max                          218.273
trainer/Q1Pred Min                            0.0629156
trainer/Q2Pred Mean                         133.223
trainer/Q2Pred Std                           43.9129
trainer/Q2Pred Max                          218.569
trainer/Q2Pred Min                           -0.229811
trainer/QTargetWithReg Mean                 133.182
trainer/QTargetWithReg Std                   44.1374
trainer/QTargetWithReg Max                  218.516
trainer/QTargetWithReg Min                    1.66739
trainer/PolicyLossWithoutReg Mean           134.227
trainer/PolicyLossWithoutReg Std             43.7084
trainer/PolicyLossWithoutReg Max            218.049
trainer/PolicyLossWithoutReg Min              3.29374
trainer/gradient_norm                       224.276
trainer/gradient_penalty                     -1.12138
trainer/gradient_percentage                  -0.00835438
exploration/num steps total              289000
exploration/num paths total                1442
exploration/path length this epoch Mean      68
exploration/path length this epoch Std        0
exploration/path length this epoch Max       68
exploration/path length this epoch Min       68
exploration/Rewards Mean                      3.42592
exploration/Rewards Std                       2.37463
exploration/Rewards Max                       8.7147
exploration/Rewards Min                      -0.637152
exploration/Returns Mean                    232.963
exploration/Returns Std                       0
exploration/Returns Max                     232.963
exploration/Returns Min                     232.963
exploration/Num Paths                         1
exploration/Average Returns                 232.963
evaluation_0/num steps total                  2.21504e+06
evaluation_0/num paths total               9699
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.56687
evaluation_0/Rewards Std                      1.07197
evaluation_0/Rewards Max                      9.15253
evaluation_0/Rewards Min                     -0.579255
evaluation_0/Returns Mean                  3566.87
evaluation_0/Returns Std                     94.0064
evaluation_0/Returns Max                   3768.57
evaluation_0/Returns Min                   3463.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3566.87
time/epoch (s)                                0
time/total (s)                             5958.39
Epoch                                       284
---------------------------------------  ----------------
2022-11-16 12:25:21.945511 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 285 finished
---------------------------------------  ----------------
epoch                                       285
total_step                               290000
replay_pool/size                         290000
trainer/alpha                                 0.0564632
trainer/alpha_loss                           -0.80736
trainer/entropy                              -5.7191
trainer/qf_loss                               8.02886
trainer/state_noise                           0.005
trainer/policy_loss                        -127.737
trainer/policy_loss_without_entropy         129.19
trainer/entropy_penalty                      -0.322919
trainer/entropy_percentage                   -0.00249957
trainer/Q1Pred Mean                         128.17
trainer/Q1Pred Std                           53.2279
trainer/Q1Pred Max                          219.071
trainer/Q1Pred Min                           -3.05565
trainer/Q2Pred Mean                         128.149
trainer/Q2Pred Std                           53.2803
trainer/Q2Pred Max                          220.529
trainer/Q2Pred Min                          -15.5403
trainer/QTargetWithReg Mean                 128.235
trainer/QTargetWithReg Std                   53.0821
trainer/QTargetWithReg Max                  220.576
trainer/QTargetWithReg Min                   -1.71937
trainer/PolicyLossWithoutReg Mean           129.19
trainer/PolicyLossWithoutReg Std             52.2905
trainer/PolicyLossWithoutReg Max            219.298
trainer/PolicyLossWithoutReg Min             -3.27977
trainer/gradient_norm                       226.056
trainer/gradient_penalty                     -1.13028
trainer/gradient_percentage                  -0.008749
exploration/num steps total              290000
exploration/num paths total                1443
exploration/path length this epoch Mean     959
exploration/path length this epoch Std        0
exploration/path length this epoch Max      959
exploration/path length this epoch Min      959
exploration/Rewards Mean                      4.38452
exploration/Rewards Std                       1.35899
exploration/Rewards Max                       9.94508
exploration/Rewards Min                      -0.581025
exploration/Returns Mean                   4204.75
exploration/Returns Std                       0
exploration/Returns Max                    4204.75
exploration/Returns Min                    4204.75
exploration/Num Paths                         1
exploration/Average Returns                4204.75
evaluation_0/num steps total                  2.22274e+06
evaluation_0/num paths total               9709
evaluation_0/path length Mean               770.1
evaluation_0/path length Std                252.873
evaluation_0/path length Max               1000
evaluation_0/path length Min                427
evaluation_0/Rewards Mean                     4.25588
evaluation_0/Rewards Std                      1.28191
evaluation_0/Rewards Max                      9.60316
evaluation_0/Rewards Min                     -0.633002
evaluation_0/Returns Mean                  3277.45
evaluation_0/Returns Std                   1045.63
evaluation_0/Returns Max                   4401.51
evaluation_0/Returns Min                   1806.15
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3277.45
time/epoch (s)                                0
time/total (s)                             5975.84
Epoch                                       285
---------------------------------------  ----------------
2022-11-16 12:25:39.812489 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 286 finished
---------------------------------------  ----------------
epoch                                       286
total_step                               291000
replay_pool/size                         291000
trainer/alpha                                 0.0562646
trainer/alpha_loss                           -1.54232
trainer/entropy                              -5.46403
trainer/qf_loss                               7.45289
trainer/state_noise                           0.005
trainer/policy_loss                        -130.703
trainer/policy_loss_without_entropy         132.173
trainer/entropy_penalty                      -0.307431
trainer/entropy_percentage                   -0.00232597
trainer/Q1Pred Mean                         131.524
trainer/Q1Pred Std                           46.7861
trainer/Q1Pred Max                          214.912
trainer/Q1Pred Min                            2.53642
trainer/Q2Pred Mean                         131.267
trainer/Q2Pred Std                           46.9814
trainer/Q2Pred Max                          215.26
trainer/Q2Pred Min                           -3.60557
trainer/QTargetWithReg Mean                 131.357
trainer/QTargetWithReg Std                   46.9628
trainer/QTargetWithReg Max                  217.051
trainer/QTargetWithReg Min                   -1.10389
trainer/PolicyLossWithoutReg Mean           132.173
trainer/PolicyLossWithoutReg Std             45.878
trainer/PolicyLossWithoutReg Max            215.121
trainer/PolicyLossWithoutReg Min              3.23821
trainer/gradient_norm                       232.486
trainer/gradient_penalty                     -1.16243
trainer/gradient_percentage                  -0.00879474
exploration/num steps total              291000
exploration/num paths total                1444
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.56615
exploration/Rewards Std                       0.984919
exploration/Rewards Max                       7.54875
exploration/Rewards Min                      -0.725823
exploration/Returns Mean                   3566.15
exploration/Returns Std                       0
exploration/Returns Max                    3566.15
exploration/Returns Min                    3566.15
exploration/Num Paths                         1
exploration/Average Returns                3566.15
evaluation_0/num steps total                  2.23060e+06
evaluation_0/num paths total               9717
evaluation_0/path length Mean               982.75
evaluation_0/path length Std                 45.6392
evaluation_0/path length Max               1000
evaluation_0/path length Min                862
evaluation_0/Rewards Mean                     3.82972
evaluation_0/Rewards Std                      1.2385
evaluation_0/Rewards Max                      9.48972
evaluation_0/Rewards Min                     -0.552952
evaluation_0/Returns Mean                  3763.66
evaluation_0/Returns Std                    283.656
evaluation_0/Returns Max                   4062.49
evaluation_0/Returns Min                   3130.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3763.66
time/epoch (s)                                0
time/total (s)                             5993.71
Epoch                                       286
---------------------------------------  ----------------
2022-11-16 12:25:57.429805 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 287 finished
---------------------------------------  ---------------
epoch                                       287
total_step                               292000
replay_pool/size                         292000
trainer/alpha                                 0.0563209
trainer/alpha_loss                            0.120511
trainer/entropy                              -6.04189
trainer/qf_loss                               6.76567
trainer/state_noise                           0.005
trainer/policy_loss                        -134.992
trainer/policy_loss_without_entropy         136.518
trainer/entropy_penalty                      -0.340285
trainer/entropy_percentage                   -0.0024926
trainer/Q1Pred Mean                         135.823
trainer/Q1Pred Std                           46.6306
trainer/Q1Pred Max                          219.059
trainer/Q1Pred Min                           -6.64999
trainer/Q2Pred Mean                         136.139
trainer/Q2Pred Std                           46.7728
trainer/Q2Pred Max                          220.071
trainer/Q2Pred Min                          -11.1685
trainer/QTargetWithReg Mean                 136.069
trainer/QTargetWithReg Std                   46.482
trainer/QTargetWithReg Max                  218.721
trainer/QTargetWithReg Min                   -2.63934
trainer/PolicyLossWithoutReg Mean           136.518
trainer/PolicyLossWithoutReg Std             46.1652
trainer/PolicyLossWithoutReg Max            218.938
trainer/PolicyLossWithoutReg Min            -12.2285
trainer/gradient_norm                       237.123
trainer/gradient_penalty                     -1.18561
trainer/gradient_percentage                  -0.00868468
exploration/num steps total              292000
exploration/num paths total                1445
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.5525
exploration/Rewards Std                       1.13235
exploration/Rewards Max                       8.85313
exploration/Rewards Min                      -0.660959
exploration/Returns Mean                   3552.5
exploration/Returns Std                       0
exploration/Returns Max                    3552.5
exploration/Returns Min                    3552.5
exploration/Num Paths                         1
exploration/Average Returns                3552.5
evaluation_0/num steps total                  2.2385e+06
evaluation_0/num paths total               9731
evaluation_0/path length Mean               564.214
evaluation_0/path length Std                185.622
evaluation_0/path length Max                994
evaluation_0/path length Min                339
evaluation_0/Rewards Mean                     4.38052
evaluation_0/Rewards Std                      1.40679
evaluation_0/Rewards Max                      9.97311
evaluation_0/Rewards Min                     -0.668488
evaluation_0/Returns Mean                  2471.55
evaluation_0/Returns Std                    817.877
evaluation_0/Returns Max                   4230.94
evaluation_0/Returns Min                   1454.43
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2471.55
time/epoch (s)                                0
time/total (s)                             6011.33
Epoch                                       287
---------------------------------------  ---------------
2022-11-16 12:26:15.466976 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 288 finished
---------------------------------------  ----------------
epoch                                       288
total_step                               293000
replay_pool/size                         293000
trainer/alpha                                 0.0576008
trainer/alpha_loss                            0.275728
trainer/entropy                              -6.09661
trainer/qf_loss                               6.85426
trainer/state_noise                           0.005
trainer/policy_loss                        -129.359
trainer/policy_loss_without_entropy         130.883
trainer/entropy_penalty                      -0.35117
trainer/entropy_percentage                   -0.00268308
trainer/Q1Pred Mean                         128.984
trainer/Q1Pred Std                           47.3487
trainer/Q1Pred Max                          217.217
trainer/Q1Pred Min                          -24.2815
trainer/Q2Pred Mean                         129.552
trainer/Q2Pred Std                           47.4445
trainer/Q2Pred Max                          216.645
trainer/Q2Pred Min                          -16.919
trainer/QTargetWithReg Mean                 129.516
trainer/QTargetWithReg Std                   47.2476
trainer/QTargetWithReg Max                  218.299
trainer/QTargetWithReg Min                  -16.9965
trainer/PolicyLossWithoutReg Mean           130.883
trainer/PolicyLossWithoutReg Std             46.2865
trainer/PolicyLossWithoutReg Max            216.843
trainer/PolicyLossWithoutReg Min            -30.3828
trainer/gradient_norm                       234.476
trainer/gradient_penalty                     -1.17238
trainer/gradient_percentage                  -0.00895746
exploration/num steps total              293000
exploration/num paths total                1446
exploration/path length this epoch Mean     451
exploration/path length this epoch Std        0
exploration/path length this epoch Max      451
exploration/path length this epoch Min      451
exploration/Rewards Mean                      4.28263
exploration/Rewards Std                       1.49133
exploration/Rewards Max                       9.7615
exploration/Rewards Min                      -0.623913
exploration/Returns Mean                   1931.47
exploration/Returns Std                       0
exploration/Returns Max                    1931.47
exploration/Returns Min                    1931.47
exploration/Num Paths                         1
exploration/Average Returns                1931.47
evaluation_0/num steps total                  2.24553e+06
evaluation_0/num paths total               9739
evaluation_0/path length Mean               878.25
evaluation_0/path length Std                226.992
evaluation_0/path length Max               1000
evaluation_0/path length Min                345
evaluation_0/Rewards Mean                     4.04529
evaluation_0/Rewards Std                      1.34668
evaluation_0/Rewards Max                      9.87267
evaluation_0/Rewards Min                     -0.613181
evaluation_0/Returns Mean                  3552.77
evaluation_0/Returns Std                    854.824
evaluation_0/Returns Max                   4308.27
evaluation_0/Returns Min                   1473.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3552.77
time/epoch (s)                                0
time/total (s)                             6029.36
Epoch                                       288
---------------------------------------  ----------------
2022-11-16 12:26:33.198330 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 289 finished
---------------------------------------  ----------------
epoch                                       289
total_step                               294000
replay_pool/size                         294000
trainer/alpha                                 0.0566912
trainer/alpha_loss                           -0.0750145
trainer/entropy                              -5.97386
trainer/qf_loss                               8.11405
trainer/state_noise                           0.005
trainer/policy_loss                        -134.961
trainer/policy_loss_without_entropy         136.454
trainer/entropy_penalty                      -0.338665
trainer/entropy_percentage                   -0.0024819
trainer/Q1Pred Mean                         134.468
trainer/Q1Pred Std                           48.6485
trainer/Q1Pred Max                          224.092
trainer/Q1Pred Min                           -1.18633
trainer/Q2Pred Mean                         135.191
trainer/Q2Pred Std                           48.6103
trainer/Q2Pred Max                          224.666
trainer/Q2Pred Min                          -10.0363
trainer/QTargetWithReg Mean                 135.066
trainer/QTargetWithReg Std                   49.0146
trainer/QTargetWithReg Max                  225.144
trainer/QTargetWithReg Min                   -0.346058
trainer/PolicyLossWithoutReg Mean           136.454
trainer/PolicyLossWithoutReg Std             46.9494
trainer/PolicyLossWithoutReg Max            224.386
trainer/PolicyLossWithoutReg Min             -9.07211
trainer/gradient_norm                       230.92
trainer/gradient_penalty                     -1.1546
trainer/gradient_percentage                  -0.00846148
exploration/num steps total              294000
exploration/num paths total                1447
exploration/path length this epoch Mean     684
exploration/path length this epoch Std        0
exploration/path length this epoch Max      684
exploration/path length this epoch Min      684
exploration/Rewards Mean                      4.52484
exploration/Rewards Std                       1.43899
exploration/Rewards Max                       9.2098
exploration/Rewards Min                      -0.677325
exploration/Returns Mean                   3094.99
exploration/Returns Std                       0
exploration/Returns Max                    3094.99
exploration/Returns Min                    3094.99
exploration/Num Paths                         1
exploration/Average Returns                3094.99
evaluation_0/num steps total                  2.25254e+06
evaluation_0/num paths total               9747
evaluation_0/path length Mean               876.625
evaluation_0/path length Std                214.953
evaluation_0/path length Max               1000
evaluation_0/path length Min                460
evaluation_0/Rewards Mean                     4.03659
evaluation_0/Rewards Std                      1.17911
evaluation_0/Rewards Max                      9.69033
evaluation_0/Rewards Min                     -0.598334
evaluation_0/Returns Mean                  3538.57
evaluation_0/Returns Std                    801.137
evaluation_0/Returns Max                   4105.07
evaluation_0/Returns Min                   1982.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3538.57
time/epoch (s)                                0
time/total (s)                             6047.09
Epoch                                       289
---------------------------------------  ----------------
2022-11-16 12:26:51.977389 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 290 finished
---------------------------------------  ----------------
epoch                                       290
total_step                               295000
replay_pool/size                         295000
trainer/alpha                                 0.0564245
trainer/alpha_loss                           -0.363942
trainer/entropy                              -5.87341
trainer/qf_loss                               4.85195
trainer/state_noise                           0.005
trainer/policy_loss                        -138.66
trainer/policy_loss_without_entropy         140.125
trainer/entropy_penalty                      -0.331404
trainer/entropy_percentage                   -0.00236507
trainer/Q1Pred Mean                         139.502
trainer/Q1Pred Std                           45.8622
trainer/Q1Pred Max                          224.12
trainer/Q1Pred Min                            5.43686
trainer/Q2Pred Mean                         139.239
trainer/Q2Pred Std                           45.9741
trainer/Q2Pred Max                          224.637
trainer/Q2Pred Min                            5.17427
trainer/QTargetWithReg Mean                 139.279
trainer/QTargetWithReg Std                   46.0194
trainer/QTargetWithReg Max                  223.739
trainer/QTargetWithReg Min                    3.42558
trainer/PolicyLossWithoutReg Mean           140.125
trainer/PolicyLossWithoutReg Std             45.7538
trainer/PolicyLossWithoutReg Max            223.72
trainer/PolicyLossWithoutReg Min              4.80767
trainer/gradient_norm                       226.727
trainer/gradient_penalty                     -1.13363
trainer/gradient_percentage                  -0.00809019
exploration/num steps total              295000
exploration/num paths total                1448
exploration/path length this epoch Mean     506
exploration/path length this epoch Std        0
exploration/path length this epoch Max      506
exploration/path length this epoch Min      506
exploration/Rewards Mean                      4.25333
exploration/Rewards Std                       1.54544
exploration/Rewards Max                       9.93619
exploration/Rewards Min                      -0.52991
exploration/Returns Mean                   2152.19
exploration/Returns Std                       0
exploration/Returns Max                    2152.19
exploration/Returns Min                    2152.19
exploration/Num Paths                         1
exploration/Average Returns                2152.19
evaluation_0/num steps total                  2.26048e+06
evaluation_0/num paths total               9763
evaluation_0/path length Mean               496
evaluation_0/path length Std                271.232
evaluation_0/path length Max               1000
evaluation_0/path length Min                231
evaluation_0/Rewards Mean                     4.38214
evaluation_0/Rewards Std                      1.49746
evaluation_0/Rewards Max                      9.73782
evaluation_0/Rewards Min                     -0.577921
evaluation_0/Returns Mean                  2173.54
evaluation_0/Returns Std                   1186.19
evaluation_0/Returns Max                   4304.94
evaluation_0/Returns Min                    979.699
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               2173.54
time/epoch (s)                                0
time/total (s)                             6065.87
Epoch                                       290
---------------------------------------  ----------------
2022-11-16 12:27:09.819997 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 291 finished
---------------------------------------  ---------------
epoch                                       291
total_step                               296000
replay_pool/size                         296000
trainer/alpha                                 0.0567806
trainer/alpha_loss                           -0.806826
trainer/entropy                              -5.71873
trainer/qf_loss                               9.48441
trainer/state_noise                           0.005
trainer/policy_loss                        -133.99
trainer/policy_loss_without_entropy         135.414
trainer/entropy_penalty                      -0.324713
trainer/entropy_percentage                   -0.00239792
trainer/Q1Pred Mean                         134.697
trainer/Q1Pred Std                           45.5827
trainer/Q1Pred Max                          222.229
trainer/Q1Pred Min                            1.14822
trainer/Q2Pred Mean                         135.387
trainer/Q2Pred Std                           45.529
trainer/Q2Pred Max                          219.974
trainer/Q2Pred Min                            1.16158
trainer/QTargetWithReg Mean                 134.177
trainer/QTargetWithReg Std                   45.5477
trainer/QTargetWithReg Max                  219.917
trainer/QTargetWithReg Min                    2.62489
trainer/PolicyLossWithoutReg Mean           135.414
trainer/PolicyLossWithoutReg Std             45.0304
trainer/PolicyLossWithoutReg Max            218.789
trainer/PolicyLossWithoutReg Min              2.00314
trainer/gradient_norm                       219.814
trainer/gradient_penalty                     -1.09907
trainer/gradient_percentage                  -0.00811634
exploration/num steps total              296000
exploration/num paths total                1450
exploration/path length this epoch Mean     404.5
exploration/path length this epoch Std       36.5
exploration/path length this epoch Max      441
exploration/path length this epoch Min      368
exploration/Rewards Mean                      4.3918
exploration/Rewards Std                       1.59905
exploration/Rewards Max                       9.69742
exploration/Rewards Min                      -0.597143
exploration/Returns Mean                   1776.48
exploration/Returns Std                     142.155
exploration/Returns Max                    1918.64
exploration/Returns Min                    1634.33
exploration/Num Paths                         2
exploration/Average Returns                1776.48
evaluation_0/num steps total                  2.2682e+06
evaluation_0/num paths total               9773
evaluation_0/path length Mean               771.9
evaluation_0/path length Std                224.979
evaluation_0/path length Max               1000
evaluation_0/path length Min                373
evaluation_0/Rewards Mean                     4.39057
evaluation_0/Rewards Std                      1.3697
evaluation_0/Rewards Max                      9.67116
evaluation_0/Rewards Min                     -0.474681
evaluation_0/Returns Mean                  3389.08
evaluation_0/Returns Std                    985.778
evaluation_0/Returns Max                   4429.28
evaluation_0/Returns Min                   1670.25
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3389.08
time/epoch (s)                                0
time/total (s)                             6083.71
Epoch                                       291
---------------------------------------  ---------------
2022-11-16 12:27:27.435664 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 292 finished
---------------------------------------  ----------------
epoch                                       292
total_step                               297000
replay_pool/size                         297000
trainer/alpha                                 0.0577641
trainer/alpha_loss                            0.818119
trainer/entropy                              -6.28691
trainer/qf_loss                               5.01041
trainer/state_noise                           0.005
trainer/policy_loss                        -138.838
trainer/policy_loss_without_entropy         140.372
trainer/entropy_penalty                      -0.363158
trainer/entropy_percentage                   -0.00258711
trainer/Q1Pred Mean                         139.854
trainer/Q1Pred Std                           46.6183
trainer/Q1Pred Max                          226.744
trainer/Q1Pred Min                          -11.0517
trainer/Q2Pred Mean                         139.591
trainer/Q2Pred Std                           46.2956
trainer/Q2Pred Max                          224.609
trainer/Q2Pred Min                          -10.349
trainer/QTargetWithReg Mean                 139.741
trainer/QTargetWithReg Std                   46.4411
trainer/QTargetWithReg Max                  224.246
trainer/QTargetWithReg Min                  -10.7801
trainer/PolicyLossWithoutReg Mean           140.372
trainer/PolicyLossWithoutReg Std             45.9862
trainer/PolicyLossWithoutReg Max            224.446
trainer/PolicyLossWithoutReg Min             -3.3005
trainer/gradient_norm                       234.214
trainer/gradient_penalty                     -1.17107
trainer/gradient_percentage                  -0.00834262
exploration/num steps total              297000
exploration/num paths total                1451
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.92708
exploration/Rewards Std                       1.04953
exploration/Rewards Max                       8.0096
exploration/Rewards Min                      -0.439489
exploration/Returns Mean                   3927.08
exploration/Returns Std                       0
exploration/Returns Max                    3927.08
exploration/Returns Min                    3927.08
exploration/Num Paths                         1
exploration/Average Returns                3927.08
evaluation_0/num steps total                  2.27596e+06
evaluation_0/num paths total               9784
evaluation_0/path length Mean               706.091
evaluation_0/path length Std                217.98
evaluation_0/path length Max               1000
evaluation_0/path length Min                462
evaluation_0/Rewards Mean                     4.12739
evaluation_0/Rewards Std                      1.44024
evaluation_0/Rewards Max                      9.88835
evaluation_0/Rewards Min                     -0.529515
evaluation_0/Returns Mean                  2914.32
evaluation_0/Returns Std                    908.382
evaluation_0/Returns Max                   4143.35
evaluation_0/Returns Min                   1860.36
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2914.32
time/epoch (s)                                0
time/total (s)                             6101.33
Epoch                                       292
---------------------------------------  ----------------
2022-11-16 12:27:45.089604 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 293 finished
---------------------------------------  ----------------
epoch                                       293
total_step                               298000
replay_pool/size                         298000
trainer/alpha                                 0.0590428
trainer/alpha_loss                            0.286651
trainer/entropy                              -6.10131
trainer/qf_loss                               7.77166
trainer/state_noise                           0.005
trainer/policy_loss                        -134.149
trainer/policy_loss_without_entropy         135.633
trainer/entropy_penalty                      -0.360238
trainer/entropy_percentage                   -0.00265597
trainer/Q1Pred Mean                         134.793
trainer/Q1Pred Std                           46.8437
trainer/Q1Pred Max                          225.319
trainer/Q1Pred Min                           -3.72164
trainer/Q2Pred Mean                         135.379
trainer/Q2Pred Std                           47.0425
trainer/Q2Pred Max                          222.974
trainer/Q2Pred Min                           -2.635
trainer/QTargetWithReg Mean                 135.084
trainer/QTargetWithReg Std                   47.007
trainer/QTargetWithReg Max                  227.266
trainer/QTargetWithReg Min                    1.70217
trainer/PolicyLossWithoutReg Mean           135.633
trainer/PolicyLossWithoutReg Std             46.3528
trainer/PolicyLossWithoutReg Max            223.52
trainer/PolicyLossWithoutReg Min              1.14924
trainer/gradient_norm                       224.884
trainer/gradient_penalty                     -1.12442
trainer/gradient_percentage                  -0.00829013
exploration/num steps total              298000
exploration/num paths total                1452
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.09429
exploration/Rewards Std                       1.27985
exploration/Rewards Max                       9.19979
exploration/Rewards Min                      -0.451552
exploration/Returns Mean                   4094.29
exploration/Returns Std                       0
exploration/Returns Max                    4094.29
exploration/Returns Min                    4094.29
exploration/Num Paths                         1
exploration/Average Returns                4094.29
evaluation_0/num steps total                  2.28364e+06
evaluation_0/num paths total               9794
evaluation_0/path length Mean               767.7
evaluation_0/path length Std                224.713
evaluation_0/path length Max               1000
evaluation_0/path length Min                355
evaluation_0/Rewards Mean                     4.33145
evaluation_0/Rewards Std                      1.3403
evaluation_0/Rewards Max                      9.84504
evaluation_0/Rewards Min                     -0.579336
evaluation_0/Returns Mean                  3325.25
evaluation_0/Returns Std                    929.615
evaluation_0/Returns Max                   4516.58
evaluation_0/Returns Min                   1621.91
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3325.25
time/epoch (s)                                0
time/total (s)                             6118.98
Epoch                                       293
---------------------------------------  ----------------
2022-11-16 12:28:02.428214 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 294 finished
---------------------------------------  ----------------
epoch                                       294
total_step                               299000
replay_pool/size                         299000
trainer/alpha                                 0.0586067
trainer/alpha_loss                           -0.323514
trainer/entropy                              -5.88596
trainer/qf_loss                               6.76223
trainer/state_noise                           0.005
trainer/policy_loss                        -136.206
trainer/policy_loss_without_entropy         137.677
trainer/entropy_penalty                      -0.344957
trainer/entropy_percentage                   -0.00250555
trainer/Q1Pred Mean                         137.106
trainer/Q1Pred Std                           48.9662
trainer/Q1Pred Max                          230.778
trainer/Q1Pred Min                           -2.61636
trainer/Q2Pred Mean                         137.151
trainer/Q2Pred Std                           48.86
trainer/Q2Pred Max                          229.823
trainer/Q2Pred Min                            6.84684
trainer/QTargetWithReg Mean                 137.25
trainer/QTargetWithReg Std                   49.2155
trainer/QTargetWithReg Max                  230.961
trainer/QTargetWithReg Min                   -0.418537
trainer/PolicyLossWithoutReg Mean           137.677
trainer/PolicyLossWithoutReg Std             48.6457
trainer/PolicyLossWithoutReg Max            230.124
trainer/PolicyLossWithoutReg Min            -16.3428
trainer/gradient_norm                       225.316
trainer/gradient_penalty                     -1.12658
trainer/gradient_percentage                  -0.00818277
exploration/num steps total              299000
exploration/num paths total                1453
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.82133
exploration/Rewards Std                       1.08908
exploration/Rewards Max                       9.25492
exploration/Rewards Min                      -0.553145
exploration/Returns Mean                   3821.33
exploration/Returns Std                       0
exploration/Returns Max                    3821.33
exploration/Returns Min                    3821.33
exploration/Num Paths                         1
exploration/Average Returns                3821.33
evaluation_0/num steps total                  2.29157e+06
evaluation_0/num paths total               9814
evaluation_0/path length Mean               396.3
evaluation_0/path length Std                159.288
evaluation_0/path length Max               1000
evaluation_0/path length Min                331
evaluation_0/Rewards Mean                     4.27902
evaluation_0/Rewards Std                      1.63445
evaluation_0/Rewards Max                      9.94836
evaluation_0/Rewards Min                     -0.518364
evaluation_0/Returns Mean                  1695.77
evaluation_0/Returns Std                    701.535
evaluation_0/Returns Max                   4284.49
evaluation_0/Returns Min                   1384.22
evaluation_0/Num Paths                       20
evaluation_0/Average Returns               1695.77
time/epoch (s)                                0
time/total (s)                             6136.32
Epoch                                       294
---------------------------------------  ----------------
2022-11-16 12:28:20.148348 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 295 finished
---------------------------------------  ----------------
epoch                                       295
total_step                               300000
replay_pool/size                         300000
trainer/alpha                                 0.0580781
trainer/alpha_loss                           -0.474033
trainer/entropy                              -5.83343
trainer/qf_loss                               6.37168
trainer/state_noise                           0.005
trainer/policy_loss                        -135.739
trainer/policy_loss_without_entropy         137.195
trainer/entropy_penalty                      -0.338794
trainer/entropy_percentage                   -0.00246943
trainer/Q1Pred Mean                         136.5
trainer/Q1Pred Std                           49.2872
trainer/Q1Pred Max                          230.196
trainer/Q1Pred Min                           -4.76771
trainer/Q2Pred Mean                         136.242
trainer/Q2Pred Std                           49.1288
trainer/Q2Pred Max                          230.309
trainer/Q2Pred Min                          -10.1572
trainer/QTargetWithReg Mean                 136.342
trainer/QTargetWithReg Std                   49.1333
trainer/QTargetWithReg Max                  229.102
trainer/QTargetWithReg Min                  -10.4567
trainer/PolicyLossWithoutReg Mean           137.195
trainer/PolicyLossWithoutReg Std             48.306
trainer/PolicyLossWithoutReg Max            231.015
trainer/PolicyLossWithoutReg Min             -5.673
trainer/gradient_norm                       223.524
trainer/gradient_penalty                     -1.11762
trainer/gradient_percentage                  -0.00814622
exploration/num steps total              300000
exploration/num paths total                1454
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.70929
exploration/Rewards Std                       1.23395
exploration/Rewards Max                       9.76002
exploration/Rewards Min                      -0.563493
exploration/Returns Mean                   3709.29
exploration/Returns Std                       0
exploration/Returns Max                    3709.29
exploration/Returns Min                    3709.29
exploration/Num Paths                         1
exploration/Average Returns                3709.29
evaluation_0/num steps total                  2.29936e+06
evaluation_0/num paths total               9826
evaluation_0/path length Mean               649.75
evaluation_0/path length Std                223.133
evaluation_0/path length Max               1000
evaluation_0/path length Min                392
evaluation_0/Rewards Mean                     4.15085
evaluation_0/Rewards Std                      1.4043
evaluation_0/Rewards Max                      9.80538
evaluation_0/Rewards Min                     -0.646561
evaluation_0/Returns Mean                  2697.02
evaluation_0/Returns Std                    793.436
evaluation_0/Returns Max                   4022.96
evaluation_0/Returns Min                   1606.86
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2697.02
time/epoch (s)                                0
time/total (s)                             6154.04
Epoch                                       295
---------------------------------------  ----------------
2022-11-16 12:28:35.755300 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 296 finished
---------------------------------------  ----------------
epoch                                       296
total_step                               301000
replay_pool/size                         301000
trainer/alpha                                 0.058464
trainer/alpha_loss                           -0.495306
trainer/entropy                              -5.82556
trainer/qf_loss                               7.17063
trainer/state_noise                           0.005
trainer/policy_loss                        -134.386
trainer/policy_loss_without_entropy         135.865
trainer/entropy_penalty                      -0.340586
trainer/entropy_percentage                   -0.0025068
trainer/Q1Pred Mean                         135.453
trainer/Q1Pred Std                           50.4282
trainer/Q1Pred Max                          220.821
trainer/Q1Pred Min                          -22.548
trainer/Q2Pred Mean                         135.348
trainer/Q2Pred Std                           50.2588
trainer/Q2Pred Max                          222.074
trainer/Q2Pred Min                          -24.3956
trainer/QTargetWithReg Mean                 135.106
trainer/QTargetWithReg Std                   50.4576
trainer/QTargetWithReg Max                  220.362
trainer/QTargetWithReg Min                  -14.4972
trainer/PolicyLossWithoutReg Mean           135.865
trainer/PolicyLossWithoutReg Std             49.3721
trainer/PolicyLossWithoutReg Max            222.667
trainer/PolicyLossWithoutReg Min            -18.7008
trainer/gradient_norm                       227.652
trainer/gradient_penalty                     -1.13826
trainer/gradient_percentage                  -0.00837791
exploration/num steps total              301000
exploration/num paths total                1455
exploration/path length this epoch Mean     963
exploration/path length this epoch Std        0
exploration/path length this epoch Max      963
exploration/path length this epoch Min      963
exploration/Rewards Mean                      4.40963
exploration/Rewards Std                       1.35125
exploration/Rewards Max                       9.33096
exploration/Rewards Min                      -0.563701
exploration/Returns Mean                   4246.47
exploration/Returns Std                       0
exploration/Returns Max                    4246.47
exploration/Returns Min                    4246.47
exploration/Num Paths                         1
exploration/Average Returns                4246.47
evaluation_0/num steps total                  2.30736e+06
evaluation_0/num paths total               9834
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.72601
evaluation_0/Rewards Std                      1.0483
evaluation_0/Rewards Max                      9.23276
evaluation_0/Rewards Min                     -0.502687
evaluation_0/Returns Mean                  3726.01
evaluation_0/Returns Std                    158.157
evaluation_0/Returns Max                   4056.89
evaluation_0/Returns Min                   3518.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3726.01
time/epoch (s)                                0
time/total (s)                             6169.65
Epoch                                       296
---------------------------------------  ----------------
2022-11-16 12:28:53.116488 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 297 finished
---------------------------------------  ----------------
epoch                                       297
total_step                               302000
replay_pool/size                         302000
trainer/alpha                                 0.0586089
trainer/alpha_loss                            0.775438
trainer/entropy                              -6.27334
trainer/qf_loss                               5.04241
trainer/state_noise                           0.005
trainer/policy_loss                        -142.436
trainer/policy_loss_without_entropy         144.002
trainer/entropy_penalty                      -0.367673
trainer/entropy_percentage                   -0.00255325
trainer/Q1Pred Mean                         143.144
trainer/Q1Pred Std                           48.8508
trainer/Q1Pred Max                          228.745
trainer/Q1Pred Min                           -0.695641
trainer/Q2Pred Mean                         142.799
trainer/Q2Pred Std                           48.6562
trainer/Q2Pred Max                          227.462
trainer/Q2Pred Min                           -1.56743
trainer/QTargetWithReg Mean                 143.027
trainer/QTargetWithReg Std                   48.5198
trainer/QTargetWithReg Max                  227.604
trainer/QTargetWithReg Min                   -0.268182
trainer/PolicyLossWithoutReg Mean           144.002
trainer/PolicyLossWithoutReg Std             47.4676
trainer/PolicyLossWithoutReg Max            227.678
trainer/PolicyLossWithoutReg Min              2.88286
trainer/gradient_norm                       239.733
trainer/gradient_penalty                     -1.19867
trainer/gradient_percentage                  -0.00832396
exploration/num steps total              302000
exploration/num paths total                1456
exploration/path length this epoch Mean     374
exploration/path length this epoch Std        0
exploration/path length this epoch Max      374
exploration/path length this epoch Min      374
exploration/Rewards Mean                      4.00842
exploration/Rewards Std                       1.53873
exploration/Rewards Max                       9.63578
exploration/Rewards Min                      -0.519713
exploration/Returns Mean                   1499.15
exploration/Returns Std                       0
exploration/Returns Max                    1499.15
exploration/Returns Min                    1499.15
exploration/Num Paths                         1
exploration/Average Returns                1499.15
evaluation_0/num steps total                  2.31525e+06
evaluation_0/num paths total               9843
evaluation_0/path length Mean               875.667
evaluation_0/path length Std                188.581
evaluation_0/path length Max               1000
evaluation_0/path length Min                393
evaluation_0/Rewards Mean                     4.20917
evaluation_0/Rewards Std                      1.20298
evaluation_0/Rewards Max                      9.57949
evaluation_0/Rewards Min                     -0.606156
evaluation_0/Returns Mean                  3685.83
evaluation_0/Returns Std                    718.131
evaluation_0/Returns Max                   4186.57
evaluation_0/Returns Min                   1781.57
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3685.83
time/epoch (s)                                0
time/total (s)                             6187.01
Epoch                                       297
---------------------------------------  ----------------
2022-11-16 12:29:11.142505 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 298 finished
---------------------------------------  ----------------
epoch                                       298
total_step                               303000
replay_pool/size                         303000
trainer/alpha                                 0.0596223
trainer/alpha_loss                           -0.193298
trainer/entropy                              -5.93145
trainer/qf_loss                               5.34524
trainer/state_noise                           0.005
trainer/policy_loss                        -137.756
trainer/policy_loss_without_entropy         139.295
trainer/entropy_penalty                      -0.353647
trainer/entropy_percentage                   -0.00253884
trainer/Q1Pred Mean                         138.439
trainer/Q1Pred Std                           45.1775
trainer/Q1Pred Max                          222.461
trainer/Q1Pred Min                            4.29639
trainer/Q2Pred Mean                         138.542
trainer/Q2Pred Std                           44.8959
trainer/Q2Pred Max                          221.872
trainer/Q2Pred Min                            7.50085
trainer/QTargetWithReg Mean                 138.552
trainer/QTargetWithReg Std                   45.2251
trainer/QTargetWithReg Max                  221.33
trainer/QTargetWithReg Min                    4.94623
trainer/PolicyLossWithoutReg Mean           139.295
trainer/PolicyLossWithoutReg Std             44.6968
trainer/PolicyLossWithoutReg Max            220.643
trainer/PolicyLossWithoutReg Min              6.56558
trainer/gradient_norm                       237.065
trainer/gradient_penalty                     -1.18532
trainer/gradient_percentage                  -0.00850947
exploration/num steps total              303000
exploration/num paths total                1457
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.0705
exploration/Rewards Std                       1.24817
exploration/Rewards Max                       9.76812
exploration/Rewards Min                      -0.581208
exploration/Returns Mean                   4070.5
exploration/Returns Std                       0
exploration/Returns Max                    4070.5
exploration/Returns Min                    4070.5
exploration/Num Paths                         1
exploration/Average Returns                4070.5
evaluation_0/num steps total                  2.32273e+06
evaluation_0/num paths total               9853
evaluation_0/path length Mean               748.1
evaluation_0/path length Std                310.975
evaluation_0/path length Max               1000
evaluation_0/path length Min                320
evaluation_0/Rewards Mean                     3.94509
evaluation_0/Rewards Std                      1.22126
evaluation_0/Rewards Max                      9.51746
evaluation_0/Rewards Min                     -0.530907
evaluation_0/Returns Mean                  2951.32
evaluation_0/Returns Std                   1111.56
evaluation_0/Returns Max                   3868.3
evaluation_0/Returns Min                   1382.18
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               2951.32
time/epoch (s)                                0
time/total (s)                             6205.03
Epoch                                       298
---------------------------------------  ----------------
2022-11-16 12:29:28.529637 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 299 finished
---------------------------------------  ---------------
epoch                                       299
total_step                               304000
replay_pool/size                         304000
trainer/alpha                                 0.0594601
trainer/alpha_loss                           -0.653725
trainer/entropy                              -5.76838
trainer/qf_loss                               5.55678
trainer/state_noise                           0.005
trainer/policy_loss                        -136.917
trainer/policy_loss_without_entropy         138.436
trainer/entropy_penalty                      -0.342988
trainer/entropy_percentage                   -0.0024776
trainer/Q1Pred Mean                         137.965
trainer/Q1Pred Std                           47.7407
trainer/Q1Pred Max                          221.106
trainer/Q1Pred Min                            4.99208
trainer/Q2Pred Mean                         137.444
trainer/Q2Pred Std                           47.5665
trainer/Q2Pred Max                          223.689
trainer/Q2Pred Min                            4.99412
trainer/QTargetWithReg Mean                 138.045
trainer/QTargetWithReg Std                   47.7426
trainer/QTargetWithReg Max                  222.049
trainer/QTargetWithReg Min                    5.61716
trainer/PolicyLossWithoutReg Mean           138.436
trainer/PolicyLossWithoutReg Std             47.5423
trainer/PolicyLossWithoutReg Max            222.448
trainer/PolicyLossWithoutReg Min              4.89557
trainer/gradient_norm                       235.18
trainer/gradient_penalty                     -1.1759
trainer/gradient_percentage                  -0.0084942
exploration/num steps total              304000
exploration/num paths total                1458
exploration/path length this epoch Mean     322
exploration/path length this epoch Std        0
exploration/path length this epoch Max      322
exploration/path length this epoch Min      322
exploration/Rewards Mean                      4.42831
exploration/Rewards Std                       1.6418
exploration/Rewards Max                       9.45016
exploration/Rewards Min                      -0.486206
exploration/Returns Mean                   1425.92
exploration/Returns Std                       0
exploration/Returns Max                    1425.92
exploration/Returns Min                    1425.92
exploration/Num Paths                         1
exploration/Average Returns                1425.92
evaluation_0/num steps total                  2.3307e+06
evaluation_0/num paths total               9862
evaluation_0/path length Mean               885.889
evaluation_0/path length Std                224.375
evaluation_0/path length Max               1000
evaluation_0/path length Min                340
evaluation_0/Rewards Mean                     4.14781
evaluation_0/Rewards Std                      1.28539
evaluation_0/Rewards Max                      9.94564
evaluation_0/Rewards Min                     -0.610103
evaluation_0/Returns Mean                  3674.5
evaluation_0/Returns Std                    915.75
evaluation_0/Returns Max                   4587.31
evaluation_0/Returns Min                   1471.18
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3674.5
time/epoch (s)                                0
time/total (s)                             6222.42
Epoch                                       299
---------------------------------------  ---------------
2022-11-16 12:29:46.532398 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 300 finished
---------------------------------------  ----------------
epoch                                       300
total_step                               305000
replay_pool/size                         305000
trainer/alpha                                 0.0586125
trainer/alpha_loss                           -0.969718
trainer/entropy                              -5.65815
trainer/qf_loss                               6.33061
trainer/state_noise                           0.005
trainer/policy_loss                        -136.701
trainer/policy_loss_without_entropy         138.206
trainer/entropy_penalty                      -0.331639
trainer/entropy_percentage                   -0.0023996
trainer/Q1Pred Mean                         137.053
trainer/Q1Pred Std                           51.8189
trainer/Q1Pred Max                          230.813
trainer/Q1Pred Min                          -16.1141
trainer/Q2Pred Mean                         137.4
trainer/Q2Pred Std                           51.9633
trainer/Q2Pred Max                          229.462
trainer/Q2Pred Min                          -19.93
trainer/QTargetWithReg Mean                 137.515
trainer/QTargetWithReg Std                   51.9501
trainer/QTargetWithReg Max                  231.038
trainer/QTargetWithReg Min                  -16.5171
trainer/PolicyLossWithoutReg Mean           138.206
trainer/PolicyLossWithoutReg Std             51.2891
trainer/PolicyLossWithoutReg Max            231.358
trainer/PolicyLossWithoutReg Min            -12.5929
trainer/gradient_norm                       234.736
trainer/gradient_penalty                     -1.17368
trainer/gradient_percentage                  -0.00849227
exploration/num steps total              305000
exploration/num paths total                1459
exploration/path length this epoch Mean     671
exploration/path length this epoch Std        0
exploration/path length this epoch Max      671
exploration/path length this epoch Min      671
exploration/Rewards Mean                      4.06417
exploration/Rewards Std                       1.41608
exploration/Rewards Max                      10.0442
exploration/Rewards Min                      -0.488873
exploration/Returns Mean                   2727.06
exploration/Returns Std                       0
exploration/Returns Max                    2727.06
exploration/Returns Min                    2727.06
exploration/Num Paths                         1
exploration/Average Returns                2727.06
evaluation_0/num steps total                  2.33858e+06
evaluation_0/num paths total               9870
evaluation_0/path length Mean               984.875
evaluation_0/path length Std                 28.1311
evaluation_0/path length Max               1000
evaluation_0/path length Min                919
evaluation_0/Rewards Mean                     4.11682
evaluation_0/Rewards Std                      1.21934
evaluation_0/Rewards Max                     10.0218
evaluation_0/Rewards Min                     -0.760537
evaluation_0/Returns Mean                  4054.56
evaluation_0/Returns Std                     77.1374
evaluation_0/Returns Max                   4169.48
evaluation_0/Returns Min                   3947.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4054.56
time/epoch (s)                                0
time/total (s)                             6240.42
Epoch                                       300
---------------------------------------  ----------------
2022-11-16 12:30:03.921250 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 301 finished
---------------------------------------  ----------------
epoch                                       301
total_step                               306000
replay_pool/size                         306000
trainer/alpha                                 0.0596557
trainer/alpha_loss                           -0.068941
trainer/entropy                              -5.97555
trainer/qf_loss                               6.86645
trainer/state_noise                           0.005
trainer/policy_loss                        -140.293
trainer/policy_loss_without_entropy         141.834
trainer/entropy_penalty                      -0.356475
trainer/entropy_percentage                   -0.00251333
trainer/Q1Pred Mean                         140.804
trainer/Q1Pred Std                           48.0932
trainer/Q1Pred Max                          228.447
trainer/Q1Pred Min                           -0.72608
trainer/Q2Pred Mean                         140.632
trainer/Q2Pred Std                           48.2448
trainer/Q2Pred Max                          228.345
trainer/Q2Pred Min                           -2.80772
trainer/QTargetWithReg Mean                 140.567
trainer/QTargetWithReg Std                   48.312
trainer/QTargetWithReg Max                  227.919
trainer/QTargetWithReg Min                    1.02719
trainer/PolicyLossWithoutReg Mean           141.834
trainer/PolicyLossWithoutReg Std             47.812
trainer/PolicyLossWithoutReg Max            228.157
trainer/PolicyLossWithoutReg Min             -1.1446
trainer/gradient_norm                       236.983
trainer/gradient_penalty                     -1.18492
trainer/gradient_percentage                  -0.00835425
exploration/num steps total              306000
exploration/num paths total                1460
exploration/path length this epoch Mean     658
exploration/path length this epoch Std        0
exploration/path length this epoch Max      658
exploration/path length this epoch Min      658
exploration/Rewards Mean                      4.61625
exploration/Rewards Std                       1.5546
exploration/Rewards Max                       9.98843
exploration/Rewards Min                      -0.68597
exploration/Returns Mean                   3037.49
exploration/Returns Std                       0
exploration/Returns Max                    3037.49
exploration/Returns Min                    3037.49
exploration/Num Paths                         1
exploration/Average Returns                3037.49
evaluation_0/num steps total                  2.34606e+06
evaluation_0/num paths total               9878
evaluation_0/path length Mean               934.875
evaluation_0/path length Std                172.305
evaluation_0/path length Max               1000
evaluation_0/path length Min                479
evaluation_0/Rewards Mean                     3.68522
evaluation_0/Rewards Std                      1.12909
evaluation_0/Rewards Max                      9.6753
evaluation_0/Rewards Min                     -0.657662
evaluation_0/Returns Mean                  3445.22
evaluation_0/Returns Std                    514.344
evaluation_0/Returns Max                   3920.58
evaluation_0/Returns Min                   2136.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3445.22
time/epoch (s)                                0
time/total (s)                             6257.81
Epoch                                       301
---------------------------------------  ----------------
2022-11-16 12:30:21.994230 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 302 finished
---------------------------------------  ----------------
epoch                                       302
total_step                               307000
replay_pool/size                         307000
trainer/alpha                                 0.0594408
trainer/alpha_loss                           -2.93259
trainer/entropy                              -4.96104
trainer/qf_loss                               5.46342
trainer/state_noise                           0.005
trainer/policy_loss                        -141.935
trainer/policy_loss_without_entropy         143.417
trainer/entropy_penalty                      -0.294888
trainer/entropy_percentage                   -0.00205616
trainer/Q1Pred Mean                         143.024
trainer/Q1Pred Std                           47.4079
trainer/Q1Pred Max                          229.467
trainer/Q1Pred Min                           -6.32168
trainer/Q2Pred Mean                         142.825
trainer/Q2Pred Std                           47.3529
trainer/Q2Pred Max                          227.413
trainer/Q2Pred Min                           -7.82196
trainer/QTargetWithReg Mean                 143.053
trainer/QTargetWithReg Std                   47.7649
trainer/QTargetWithReg Max                  230.306
trainer/QTargetWithReg Min                  -12.0081
trainer/PolicyLossWithoutReg Mean           143.417
trainer/PolicyLossWithoutReg Std             46.9266
trainer/PolicyLossWithoutReg Max            228.386
trainer/PolicyLossWithoutReg Min             -4.11425
trainer/gradient_norm                       237.341
trainer/gradient_penalty                     -1.1867
trainer/gradient_percentage                  -0.00827451
exploration/num steps total              307000
exploration/num paths total                1461
exploration/path length this epoch Mean     907
exploration/path length this epoch Std        0
exploration/path length this epoch Max      907
exploration/path length this epoch Min      907
exploration/Rewards Mean                      4.43183
exploration/Rewards Std                       1.41957
exploration/Rewards Max                      10.4232
exploration/Rewards Min                      -0.708356
exploration/Returns Mean                   4019.67
exploration/Returns Std                       0
exploration/Returns Max                    4019.67
exploration/Returns Min                    4019.67
exploration/Num Paths                         1
exploration/Average Returns                4019.67
evaluation_0/num steps total                  2.35386e+06
evaluation_0/num paths total               9889
evaluation_0/path length Mean               709.636
evaluation_0/path length Std                255.748
evaluation_0/path length Max               1000
evaluation_0/path length Min                357
evaluation_0/Rewards Mean                     4.49425
evaluation_0/Rewards Std                      1.45547
evaluation_0/Rewards Max                     10.6295
evaluation_0/Rewards Min                     -0.585347
evaluation_0/Returns Mean                  3189.28
evaluation_0/Returns Std                   1130.85
evaluation_0/Returns Max                   4569.11
evaluation_0/Returns Min                   1613.84
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3189.28
time/epoch (s)                                0
time/total (s)                             6275.88
Epoch                                       302
---------------------------------------  ----------------
2022-11-16 12:30:39.351645 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 303 finished
---------------------------------------  ----------------
epoch                                       303
total_step                               308000
replay_pool/size                         308000
trainer/alpha                                 0.0606823
trainer/alpha_loss                            0.492996
trainer/entropy                              -6.17594
trainer/qf_loss                               9.56605
trainer/state_noise                           0.005
trainer/policy_loss                        -130.912
trainer/policy_loss_without_entropy         132.455
trainer/entropy_penalty                      -0.37477
trainer/entropy_percentage                   -0.00282942
trainer/Q1Pred Mean                         131.254
trainer/Q1Pred Std                           50.293
trainer/Q1Pred Max                          226.096
trainer/Q1Pred Min                          -20.772
trainer/Q2Pred Mean                         131.711
trainer/Q2Pred Std                           50.4326
trainer/Q2Pred Max                          225.377
trainer/Q2Pred Min                          -20.3079
trainer/QTargetWithReg Mean                 131.878
trainer/QTargetWithReg Std                   49.985
trainer/QTargetWithReg Max                  227.117
trainer/QTargetWithReg Min                   -9.0053
trainer/PolicyLossWithoutReg Mean           132.455
trainer/PolicyLossWithoutReg Std             49.9349
trainer/PolicyLossWithoutReg Max            225.247
trainer/PolicyLossWithoutReg Min            -20.6378
trainer/gradient_norm                       233.638
trainer/gradient_penalty                     -1.16819
trainer/gradient_percentage                  -0.00881952
exploration/num steps total              308000
exploration/num paths total                1462
exploration/path length this epoch Mean     783
exploration/path length this epoch Std        0
exploration/path length this epoch Max      783
exploration/path length this epoch Min      783
exploration/Rewards Mean                      4.31529
exploration/Rewards Std                       1.38124
exploration/Rewards Max                       9.81841
exploration/Rewards Min                      -0.509188
exploration/Returns Mean                   3378.87
exploration/Returns Std                       0
exploration/Returns Max                    3378.87
exploration/Returns Min                    3378.87
exploration/Num Paths                         1
exploration/Average Returns                3378.87
evaluation_0/num steps total                  2.36172e+06
evaluation_0/num paths total               9901
evaluation_0/path length Mean               654.583
evaluation_0/path length Std                295.427
evaluation_0/path length Max               1000
evaluation_0/path length Min                250
evaluation_0/Rewards Mean                     4.25032
evaluation_0/Rewards Std                      1.41676
evaluation_0/Rewards Max                     10.2116
evaluation_0/Rewards Min                     -0.593515
evaluation_0/Returns Mean                  2782.19
evaluation_0/Returns Std                   1169.35
evaluation_0/Returns Max                   4241.78
evaluation_0/Returns Min                   1086.32
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2782.19
time/epoch (s)                                0
time/total (s)                             6293.24
Epoch                                       303
---------------------------------------  ----------------
2022-11-16 12:30:55.671562 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 304 finished
---------------------------------------  ----------------
epoch                                       304
total_step                               309000
replay_pool/size                         309000
trainer/alpha                                 0.0604979
trainer/alpha_loss                            0.0386282
trainer/entropy                              -6.01377
trainer/qf_loss                               7.44961
trainer/state_noise                           0.005
trainer/policy_loss                        -141.736
trainer/policy_loss_without_entropy         143.36
trainer/entropy_penalty                      -0.36382
trainer/entropy_percentage                   -0.00253781
trainer/Q1Pred Mean                         142.787
trainer/Q1Pred Std                           48.5792
trainer/Q1Pred Max                          230.73
trainer/Q1Pred Min                           -6.88092
trainer/Q2Pred Mean                         142.95
trainer/Q2Pred Std                           48.5553
trainer/Q2Pred Max                          231.26
trainer/Q2Pred Min                           -1.56007
trainer/QTargetWithReg Mean                 143.088
trainer/QTargetWithReg Std                   48.65
trainer/QTargetWithReg Max                  231.361
trainer/QTargetWithReg Min                  -12.9548
trainer/PolicyLossWithoutReg Mean           143.36
trainer/PolicyLossWithoutReg Std             48.0213
trainer/PolicyLossWithoutReg Max            230.632
trainer/PolicyLossWithoutReg Min             -4.05519
trainer/gradient_norm                       251.992
trainer/gradient_penalty                     -1.25996
trainer/gradient_percentage                  -0.00878878
exploration/num steps total              309000
exploration/num paths total                1463
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.26668
exploration/Rewards Std                       1.26776
exploration/Rewards Max                       9.69183
exploration/Rewards Min                      -0.766322
exploration/Returns Mean                   4266.68
exploration/Returns Std                       0
exploration/Returns Max                    4266.68
exploration/Returns Min                    4266.68
exploration/Num Paths                         1
exploration/Average Returns                4266.68
evaluation_0/num steps total                  2.36972e+06
evaluation_0/num paths total               9909
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.95685
evaluation_0/Rewards Std                      1.21185
evaluation_0/Rewards Max                      9.97621
evaluation_0/Rewards Min                     -0.623415
evaluation_0/Returns Mean                  3956.85
evaluation_0/Returns Std                    151.43
evaluation_0/Returns Max                   4213.62
evaluation_0/Returns Min                   3769.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3956.85
time/epoch (s)                                0
time/total (s)                             6309.56
Epoch                                       304
---------------------------------------  ----------------
2022-11-16 12:31:13.203379 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 305 finished
---------------------------------------  ----------------
epoch                                       305
total_step                               310000
replay_pool/size                         310000
trainer/alpha                                 0.0602995
trainer/alpha_loss                           -1.48158
trainer/entropy                              -5.47241
trainer/qf_loss                               5.7917
trainer/state_noise                           0.005
trainer/policy_loss                        -139.452
trainer/policy_loss_without_entropy         140.967
trainer/entropy_penalty                      -0.329984
trainer/entropy_percentage                   -0.00234085
trainer/Q1Pred Mean                         140.212
trainer/Q1Pred Std                           49.0093
trainer/Q1Pred Max                          229.87
trainer/Q1Pred Min                           -1.68482
trainer/Q2Pred Mean                         140.011
trainer/Q2Pred Std                           48.9061
trainer/Q2Pred Max                          229.347
trainer/Q2Pred Min                           -4.25822
trainer/QTargetWithReg Mean                 140.424
trainer/QTargetWithReg Std                   49.1859
trainer/QTargetWithReg Max                  230.92
trainer/QTargetWithReg Min                   -1.18967
trainer/PolicyLossWithoutReg Mean           140.967
trainer/PolicyLossWithoutReg Std             48.9612
trainer/PolicyLossWithoutReg Max            229.837
trainer/PolicyLossWithoutReg Min             -1.95292
trainer/gradient_norm                       237.032
trainer/gradient_penalty                     -1.18516
trainer/gradient_percentage                  -0.00840734
exploration/num steps total              310000
exploration/num paths total                1464
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.09576
exploration/Rewards Std                       1.21446
exploration/Rewards Max                       9.5154
exploration/Rewards Min                      -0.751815
exploration/Returns Mean                   4095.76
exploration/Returns Std                       0
exploration/Returns Max                    4095.76
exploration/Returns Min                    4095.76
exploration/Num Paths                         1
exploration/Average Returns                4095.76
evaluation_0/num steps total                  2.37693e+06
evaluation_0/num paths total               9923
evaluation_0/path length Mean               515.357
evaluation_0/path length Std                263.702
evaluation_0/path length Max               1000
evaluation_0/path length Min                333
evaluation_0/Rewards Mean                     4.29479
evaluation_0/Rewards Std                      1.49396
evaluation_0/Rewards Max                     10.0683
evaluation_0/Rewards Min                     -0.553812
evaluation_0/Returns Mean                  2213.35
evaluation_0/Returns Std                   1085.78
evaluation_0/Returns Max                   4382.85
evaluation_0/Returns Min                   1420.16
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2213.35
time/epoch (s)                                0
time/total (s)                             6327.09
Epoch                                       305
---------------------------------------  ----------------
2022-11-16 12:31:30.376534 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 306 finished
---------------------------------------  ----------------
epoch                                       306
total_step                               311000
replay_pool/size                         311000
trainer/alpha                                 0.0612566
trainer/alpha_loss                            0.720629
trainer/entropy                              -6.25803
trainer/qf_loss                               8.20479
trainer/state_noise                           0.005
trainer/policy_loss                        -139.946
trainer/policy_loss_without_entropy         141.525
trainer/entropy_penalty                      -0.383345
trainer/entropy_percentage                   -0.00270868
trainer/Q1Pred Mean                         140.831
trainer/Q1Pred Std                           44.6289
trainer/Q1Pred Max                          223.696
trainer/Q1Pred Min                            0.456596
trainer/Q2Pred Mean                         140.673
trainer/Q2Pred Std                           44.6058
trainer/Q2Pred Max                          223.112
trainer/Q2Pred Min                            3.69461
trainer/QTargetWithReg Mean                 140.714
trainer/QTargetWithReg Std                   44.5757
trainer/QTargetWithReg Max                  222.39
trainer/QTargetWithReg Min                   -1.31952
trainer/PolicyLossWithoutReg Mean           141.525
trainer/PolicyLossWithoutReg Std             44.2777
trainer/PolicyLossWithoutReg Max            222.072
trainer/PolicyLossWithoutReg Min              0.943706
trainer/gradient_norm                       239.035
trainer/gradient_penalty                     -1.19517
trainer/gradient_percentage                  -0.00844498
exploration/num steps total              311000
exploration/num paths total                1465
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.98166
exploration/Rewards Std                       1.08176
exploration/Rewards Max                       8.55701
exploration/Rewards Min                      -0.466735
exploration/Returns Mean                   3981.66
exploration/Returns Std                       0
exploration/Returns Max                    3981.66
exploration/Returns Min                    3981.66
exploration/Num Paths                         1
exploration/Average Returns                3981.66
evaluation_0/num steps total                  2.38459e+06
evaluation_0/num paths total               9937
evaluation_0/path length Mean               547
evaluation_0/path length Std                261.712
evaluation_0/path length Max               1000
evaluation_0/path length Min                329
evaluation_0/Rewards Mean                     4.35892
evaluation_0/Rewards Std                      1.48176
evaluation_0/Rewards Max                     10.0887
evaluation_0/Rewards Min                     -0.704632
evaluation_0/Returns Mean                  2384.33
evaluation_0/Returns Std                   1098.22
evaluation_0/Returns Max                   4454.96
evaluation_0/Returns Min                   1429.24
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2384.33
time/epoch (s)                                0
time/total (s)                             6344.27
Epoch                                       306
---------------------------------------  ----------------
2022-11-16 12:31:48.108707 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 307 finished
---------------------------------------  ----------------
epoch                                       307
total_step                               312000
replay_pool/size                         312000
trainer/alpha                                 0.0602191
trainer/alpha_loss                           -1.4294
trainer/entropy                              -5.49124
trainer/qf_loss                               7.94658
trainer/state_noise                           0.005
trainer/policy_loss                        -139.602
trainer/policy_loss_without_entropy         141.109
trainer/entropy_penalty                      -0.330677
trainer/entropy_percentage                   -0.00234342
trainer/Q1Pred Mean                         140.393
trainer/Q1Pred Std                           52.8248
trainer/Q1Pred Max                          239.311
trainer/Q1Pred Min                            6.10278
trainer/Q2Pred Mean                         140.361
trainer/Q2Pred Std                           52.8994
trainer/Q2Pred Max                          238.6
trainer/Q2Pred Min                            2.10206
trainer/QTargetWithReg Mean                 140.789
trainer/QTargetWithReg Std                   53.1474
trainer/QTargetWithReg Max                  239.945
trainer/QTargetWithReg Min                   -1.10389
trainer/PolicyLossWithoutReg Mean           141.109
trainer/PolicyLossWithoutReg Std             52.0839
trainer/PolicyLossWithoutReg Max            238.487
trainer/PolicyLossWithoutReg Min              5.75058
trainer/gradient_norm                       235.229
trainer/gradient_penalty                     -1.17614
trainer/gradient_percentage                  -0.00833501
exploration/num steps total              312000
exploration/num paths total                1466
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.29643
exploration/Rewards Std                       1.28212
exploration/Rewards Max                      10.4325
exploration/Rewards Min                      -0.629579
exploration/Returns Mean                   4296.43
exploration/Returns Std                       0
exploration/Returns Max                    4296.43
exploration/Returns Min                    4296.43
exploration/Num Paths                         1
exploration/Average Returns                4296.43
evaluation_0/num steps total                  2.39195e+06
evaluation_0/num paths total               9949
evaluation_0/path length Mean               613.5
evaluation_0/path length Std                326.693
evaluation_0/path length Max               1000
evaluation_0/path length Min                329
evaluation_0/Rewards Mean                     4.08801
evaluation_0/Rewards Std                      1.29646
evaluation_0/Rewards Max                      9.55926
evaluation_0/Rewards Min                     -0.648261
evaluation_0/Returns Mean                  2507.99
evaluation_0/Returns Std                   1248.57
evaluation_0/Returns Max                   3993.4
evaluation_0/Returns Min                   1399.92
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2507.99
time/epoch (s)                                0
time/total (s)                             6362
Epoch                                       307
---------------------------------------  ----------------
2022-11-16 12:32:06.088805 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 308 finished
---------------------------------------  ----------------
epoch                                       308
total_step                               313000
replay_pool/size                         313000
trainer/alpha                                 0.060637
trainer/alpha_loss                           -0.715451
trainer/entropy                              -5.74473
trainer/qf_loss                               7.21586
trainer/state_noise                           0.005
trainer/policy_loss                        -145.491
trainer/policy_loss_without_entropy         147.099
trainer/entropy_penalty                      -0.348343
trainer/entropy_percentage                   -0.00236809
trainer/Q1Pred Mean                         145.935
trainer/Q1Pred Std                           45.383
trainer/Q1Pred Max                          221.439
trainer/Q1Pred Min                            5.14166
trainer/Q2Pred Mean                         146.289
trainer/Q2Pred Std                           45.5325
trainer/Q2Pred Max                          224.662
trainer/Q2Pred Min                            5.23358
trainer/QTargetWithReg Mean                 146.003
trainer/QTargetWithReg Std                   45.485
trainer/QTargetWithReg Max                  222.031
trainer/QTargetWithReg Min                    3.8187
trainer/PolicyLossWithoutReg Mean           147.099
trainer/PolicyLossWithoutReg Std             44.8107
trainer/PolicyLossWithoutReg Max            221.676
trainer/PolicyLossWithoutReg Min              4.50201
trainer/gradient_norm                       251.919
trainer/gradient_penalty                     -1.2596
trainer/gradient_percentage                  -0.00856293
exploration/num steps total              313000
exploration/num paths total                1467
exploration/path length this epoch Mean     594
exploration/path length this epoch Std        0
exploration/path length this epoch Max      594
exploration/path length this epoch Min      594
exploration/Rewards Mean                      4.59917
exploration/Rewards Std                       1.49398
exploration/Rewards Max                       9.98067
exploration/Rewards Min                      -0.647636
exploration/Returns Mean                   2731.9
exploration/Returns Std                       0
exploration/Returns Max                    2731.9
exploration/Returns Min                    2731.9
exploration/Num Paths                         1
exploration/Average Returns                2731.9
evaluation_0/num steps total                  2.39914e+06
evaluation_0/num paths total               9958
evaluation_0/path length Mean               799
evaluation_0/path length Std                293.012
evaluation_0/path length Max               1000
evaluation_0/path length Min                304
evaluation_0/Rewards Mean                     4.28403
evaluation_0/Rewards Std                      1.28419
evaluation_0/Rewards Max                     10.0852
evaluation_0/Rewards Min                     -0.549173
evaluation_0/Returns Mean                  3422.94
evaluation_0/Returns Std                   1190.84
evaluation_0/Returns Max                   4315.25
evaluation_0/Returns Min                   1369.2
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3422.94
time/epoch (s)                                0
time/total (s)                             6379.98
Epoch                                       308
---------------------------------------  ----------------
2022-11-16 12:32:23.497690 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 309 finished
---------------------------------------  ----------------
epoch                                       309
total_step                               314000
replay_pool/size                         314000
trainer/alpha                                 0.0613736
trainer/alpha_loss                           -1.11677
trainer/entropy                              -5.59983
trainer/qf_loss                               8.72156
trainer/state_noise                           0.005
trainer/policy_loss                        -141.306
trainer/policy_loss_without_entropy         142.828
trainer/entropy_penalty                      -0.343682
trainer/entropy_percentage                   -0.00240627
trainer/Q1Pred Mean                         142.369
trainer/Q1Pred Std                           46.9073
trainer/Q1Pred Max                          222.121
trainer/Q1Pred Min                           -8.37102
trainer/Q2Pred Mean                         142.209
trainer/Q2Pred Std                           46.8729
trainer/Q2Pred Max                          222.118
trainer/Q2Pred Min                           -6.40214
trainer/QTargetWithReg Mean                 142.293
trainer/QTargetWithReg Std                   46.755
trainer/QTargetWithReg Max                  223.095
trainer/QTargetWithReg Min                   -3.48372
trainer/PolicyLossWithoutReg Mean           142.828
trainer/PolicyLossWithoutReg Std             46.4696
trainer/PolicyLossWithoutReg Max            223.392
trainer/PolicyLossWithoutReg Min             -6.97042
trainer/gradient_norm                       235.653
trainer/gradient_penalty                     -1.17826
trainer/gradient_percentage                  -0.00824956
exploration/num steps total              314000
exploration/num paths total                1468
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.0528
exploration/Rewards Std                       1.13015
exploration/Rewards Max                       8.77709
exploration/Rewards Min                      -0.451041
exploration/Returns Mean                   4052.8
exploration/Returns Std                       0
exploration/Returns Max                    4052.8
exploration/Returns Min                    4052.8
exploration/Num Paths                         1
exploration/Average Returns                4052.8
evaluation_0/num steps total                  2.40705e+06
evaluation_0/num paths total               9966
evaluation_0/path length Mean               987.625
evaluation_0/path length Std                 32.7412
evaluation_0/path length Max               1000
evaluation_0/path length Min                901
evaluation_0/Rewards Mean                     4.15314
evaluation_0/Rewards Std                      1.25074
evaluation_0/Rewards Max                     10.2483
evaluation_0/Rewards Min                     -0.583081
evaluation_0/Returns Mean                  4101.75
evaluation_0/Returns Std                    211.973
evaluation_0/Returns Max                   4483.98
evaluation_0/Returns Min                   3899.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4101.75
time/epoch (s)                                0
time/total (s)                             6397.39
Epoch                                       309
---------------------------------------  ----------------
2022-11-16 12:32:41.136850 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 310 finished
---------------------------------------  ----------------
epoch                                       310
total_step                               315000
replay_pool/size                         315000
trainer/alpha                                 0.0600864
trainer/alpha_loss                           -0.149729
trainer/entropy                              -5.94675
trainer/qf_loss                               6.88374
trainer/state_noise                           0.005
trainer/policy_loss                        -139.439
trainer/policy_loss_without_entropy         141.005
trainer/entropy_penalty                      -0.357319
trainer/entropy_percentage                   -0.00253409
trainer/Q1Pred Mean                         140.432
trainer/Q1Pred Std                           51.0763
trainer/Q1Pred Max                          239.586
trainer/Q1Pred Min                           -1.99169
trainer/Q2Pred Mean                         139.376
trainer/Q2Pred Std                           50.8033
trainer/Q2Pred Max                          239.135
trainer/Q2Pred Min                           -1.35385
trainer/QTargetWithReg Mean                 139.613
trainer/QTargetWithReg Std                   50.9825
trainer/QTargetWithReg Max                  239.049
trainer/QTargetWithReg Min                   -2.87496
trainer/PolicyLossWithoutReg Mean           141.005
trainer/PolicyLossWithoutReg Std             49.208
trainer/PolicyLossWithoutReg Max            238.621
trainer/PolicyLossWithoutReg Min              4.0878
trainer/gradient_norm                       241.771
trainer/gradient_penalty                     -1.20886
trainer/gradient_percentage                  -0.00857316
exploration/num steps total              315000
exploration/num paths total                1469
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.03083
exploration/Rewards Std                       1.11193
exploration/Rewards Max                       8.73899
exploration/Rewards Min                      -0.648612
exploration/Returns Mean                   4030.83
exploration/Returns Std                       0
exploration/Returns Max                    4030.83
exploration/Returns Min                    4030.83
exploration/Num Paths                         1
exploration/Average Returns                4030.83
evaluation_0/num steps total                  2.41464e+06
evaluation_0/num paths total               9978
evaluation_0/path length Mean               632.5
evaluation_0/path length Std                219.438
evaluation_0/path length Max               1000
evaluation_0/path length Min                333
evaluation_0/Rewards Mean                     4.2339
evaluation_0/Rewards Std                      1.45307
evaluation_0/Rewards Max                      9.88506
evaluation_0/Rewards Min                     -0.523587
evaluation_0/Returns Mean                  2677.94
evaluation_0/Returns Std                    853.037
evaluation_0/Returns Max                   4222.06
evaluation_0/Returns Min                   1436.41
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2677.94
time/epoch (s)                                0
time/total (s)                             6415.02
Epoch                                       310
---------------------------------------  ----------------
2022-11-16 12:32:58.835872 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 311 finished
---------------------------------------  ----------------
epoch                                       311
total_step                               316000
replay_pool/size                         316000
trainer/alpha                                 0.059682
trainer/alpha_loss                           -0.271648
trainer/entropy                              -5.90363
trainer/qf_loss                               7.07133
trainer/state_noise                           0.005
trainer/policy_loss                        -140.527
trainer/policy_loss_without_entropy         142.094
trainer/entropy_penalty                      -0.35234
trainer/entropy_percentage                   -0.00247963
trainer/Q1Pred Mean                         140.792
trainer/Q1Pred Std                           50.6894
trainer/Q1Pred Max                          231.102
trainer/Q1Pred Min                           -6.15033
trainer/Q2Pred Mean                         140.528
trainer/Q2Pred Std                           50.767
trainer/Q2Pred Max                          230.665
trainer/Q2Pred Min                           -1.1858
trainer/QTargetWithReg Mean                 140.952
trainer/QTargetWithReg Std                   50.7466
trainer/QTargetWithReg Max                  230.894
trainer/QTargetWithReg Min                   -0.420475
trainer/PolicyLossWithoutReg Mean           142.094
trainer/PolicyLossWithoutReg Std             50.1544
trainer/PolicyLossWithoutReg Max            231.568
trainer/PolicyLossWithoutReg Min             -1.3533
trainer/gradient_norm                       242.97
trainer/gradient_penalty                     -1.21485
trainer/gradient_percentage                  -0.00854964
exploration/num steps total              316000
exploration/num paths total                1470
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48052
exploration/Rewards Std                       1.33039
exploration/Rewards Max                       9.69421
exploration/Rewards Min                      -0.556819
exploration/Returns Mean                   4480.52
exploration/Returns Std                       0
exploration/Returns Max                    4480.52
exploration/Returns Min                    4480.52
exploration/Num Paths                         1
exploration/Average Returns                4480.52
evaluation_0/num steps total                  2.42204e+06
evaluation_0/num paths total               9989
evaluation_0/path length Mean               672.909
evaluation_0/path length Std                291.216
evaluation_0/path length Max               1000
evaluation_0/path length Min                335
evaluation_0/Rewards Mean                     4.35189
evaluation_0/Rewards Std                      1.48005
evaluation_0/Rewards Max                     10.3289
evaluation_0/Rewards Min                     -0.59717
evaluation_0/Returns Mean                  2928.43
evaluation_0/Returns Std                   1258.13
evaluation_0/Returns Max                   4623.95
evaluation_0/Returns Min                   1439.56
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               2928.43
time/epoch (s)                                0
time/total (s)                             6432.72
Epoch                                       311
---------------------------------------  ----------------
2022-11-16 12:33:14.931040 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 312 finished
---------------------------------------  ----------------
epoch                                       312
total_step                               317000
replay_pool/size                         317000
trainer/alpha                                 0.061319
trainer/alpha_loss                           -0.142817
trainer/entropy                              -5.94884
trainer/qf_loss                               6.12473
trainer/state_noise                           0.005
trainer/policy_loss                        -143.476
trainer/policy_loss_without_entropy         145.097
trainer/entropy_penalty                      -0.364777
trainer/entropy_percentage                   -0.00251402
trainer/Q1Pred Mean                         144.831
trainer/Q1Pred Std                           48.5209
trainer/Q1Pred Max                          231.658
trainer/Q1Pred Min                           19.4733
trainer/Q2Pred Mean                         144.675
trainer/Q2Pred Std                           48.1078
trainer/Q2Pred Max                          231.237
trainer/Q2Pred Min                           18.4105
trainer/QTargetWithReg Mean                 144.691
trainer/QTargetWithReg Std                   48.5793
trainer/QTargetWithReg Max                  230.824
trainer/QTargetWithReg Min                   18.9774
trainer/PolicyLossWithoutReg Mean           145.097
trainer/PolicyLossWithoutReg Std             47.8913
trainer/PolicyLossWithoutReg Max            230.645
trainer/PolicyLossWithoutReg Min             18.2985
trainer/gradient_norm                       251.356
trainer/gradient_penalty                     -1.25678
trainer/gradient_percentage                  -0.00866165
exploration/num steps total              317000
exploration/num paths total                1471
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.03946
exploration/Rewards Std                       1.15618
exploration/Rewards Max                       9.07081
exploration/Rewards Min                      -0.604894
exploration/Returns Mean                   4039.46
exploration/Returns Std                       0
exploration/Returns Max                    4039.46
exploration/Returns Min                    4039.46
exploration/Num Paths                         1
exploration/Average Returns                4039.46
evaluation_0/num steps total                  2.43004e+06
evaluation_0/num paths total               9997
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.23488
evaluation_0/Rewards Std                      1.18678
evaluation_0/Rewards Max                      9.49106
evaluation_0/Rewards Min                     -0.726684
evaluation_0/Returns Mean                  4234.88
evaluation_0/Returns Std                    215.317
evaluation_0/Returns Max                   4469.89
evaluation_0/Returns Min                   4005.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4234.88
time/epoch (s)                                0
time/total (s)                             6448.82
Epoch                                       312
---------------------------------------  ----------------
2022-11-16 12:33:32.661964 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 313 finished
---------------------------------------  ----------------
epoch                                       313
total_step                               318000
replay_pool/size                         318000
trainer/alpha                                 0.0621647
trainer/alpha_loss                            0.397226
trainer/entropy                              -6.14299
trainer/qf_loss                               5.74666
trainer/state_noise                           0.005
trainer/policy_loss                        -139.665
trainer/policy_loss_without_entropy         141.246
trainer/entropy_penalty                      -0.381877
trainer/entropy_percentage                   -0.00270362
trainer/Q1Pred Mean                         139.658
trainer/Q1Pred Std                           46.5408
trainer/Q1Pred Max                          220.049
trainer/Q1Pred Min                           -3.74367
trainer/Q2Pred Mean                         139.911
trainer/Q2Pred Std                           46.716
trainer/Q2Pred Max                          222.277
trainer/Q2Pred Min                           -9.25025
trainer/QTargetWithReg Mean                 140.103
trainer/QTargetWithReg Std                   46.7221
trainer/QTargetWithReg Max                  220.515
trainer/QTargetWithReg Min                   -0.110743
trainer/PolicyLossWithoutReg Mean           141.246
trainer/PolicyLossWithoutReg Std             46.133
trainer/PolicyLossWithoutReg Max            221.644
trainer/PolicyLossWithoutReg Min             15.0012
trainer/gradient_norm                       239.912
trainer/gradient_penalty                     -1.19956
trainer/gradient_percentage                  -0.00849269
exploration/num steps total              318000
exploration/num paths total                1472
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.83136
exploration/Rewards Std                       1.15594
exploration/Rewards Max                       9.35889
exploration/Rewards Min                      -0.67043
exploration/Returns Mean                   3831.36
exploration/Returns Std                       0
exploration/Returns Max                    3831.36
exploration/Returns Min                    3831.36
exploration/Num Paths                         1
exploration/Average Returns                3831.36
evaluation_0/num steps total                  2.43797e+06
evaluation_0/num paths total              10005
evaluation_0/path length Mean               991.75
evaluation_0/path length Std                 21.8274
evaluation_0/path length Max               1000
evaluation_0/path length Min                934
evaluation_0/Rewards Mean                     4.30638
evaluation_0/Rewards Std                      1.19663
evaluation_0/Rewards Max                      9.46731
evaluation_0/Rewards Min                     -0.526885
evaluation_0/Returns Mean                  4270.85
evaluation_0/Returns Std                    162.103
evaluation_0/Returns Max                   4500.06
evaluation_0/Returns Min                   3988.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4270.85
time/epoch (s)                                0
time/total (s)                             6466.55
Epoch                                       313
---------------------------------------  ----------------
2022-11-16 12:33:49.712822 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 314 finished
---------------------------------------  ----------------
epoch                                       314
total_step                               319000
replay_pool/size                         319000
trainer/alpha                                 0.0607629
trainer/alpha_loss                           -0.7753
trainer/entropy                              -5.72316
trainer/qf_loss                               6.83393
trainer/state_noise                           0.005
trainer/policy_loss                        -143.259
trainer/policy_loss_without_entropy         144.846
trainer/entropy_penalty                      -0.347756
trainer/entropy_percentage                   -0.00240086
trainer/Q1Pred Mean                         144.204
trainer/Q1Pred Std                           46.0252
trainer/Q1Pred Max                          238.949
trainer/Q1Pred Min                           -4.9181
trainer/Q2Pred Mean                         144.081
trainer/Q2Pred Std                           46.2208
trainer/Q2Pred Max                          238.059
trainer/Q2Pred Min                           -6.74242
trainer/QTargetWithReg Mean                 144.466
trainer/QTargetWithReg Std                   46.4018
trainer/QTargetWithReg Max                  240.115
trainer/QTargetWithReg Min                   -0.110743
trainer/PolicyLossWithoutReg Mean           144.846
trainer/PolicyLossWithoutReg Std             45.5495
trainer/PolicyLossWithoutReg Max            238.288
trainer/PolicyLossWithoutReg Min              3.01692
trainer/gradient_norm                       247.896
trainer/gradient_penalty                     -1.23948
trainer/gradient_percentage                  -0.00855722
exploration/num steps total              319000
exploration/num paths total                1473
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53238
exploration/Rewards Std                       1.33301
exploration/Rewards Max                       9.69634
exploration/Rewards Min                      -0.52626
exploration/Returns Mean                   4532.38
exploration/Returns Std                       0
exploration/Returns Max                    4532.38
exploration/Returns Min                    4532.38
exploration/Num Paths                         1
exploration/Average Returns                4532.38
evaluation_0/num steps total                  2.44552e+06
evaluation_0/num paths total              10017
evaluation_0/path length Mean               629.333
evaluation_0/path length Std                168.841
evaluation_0/path length Max               1000
evaluation_0/path length Min                421
evaluation_0/Rewards Mean                     4.60281
evaluation_0/Rewards Std                      1.48146
evaluation_0/Rewards Max                     10.5379
evaluation_0/Rewards Min                     -0.436209
evaluation_0/Returns Mean                  2896.7
evaluation_0/Returns Std                    753.81
evaluation_0/Returns Max                   4371.11
evaluation_0/Returns Min                   1891.27
evaluation_0/Num Paths                       12
evaluation_0/Average Returns               2896.7
time/epoch (s)                                0
time/total (s)                             6483.6
Epoch                                       314
---------------------------------------  ----------------
2022-11-16 12:34:07.746072 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 315 finished
---------------------------------------  ----------------
epoch                                       315
total_step                               320000
replay_pool/size                         320000
trainer/alpha                                 0.0614152
trainer/alpha_loss                            0.894003
trainer/entropy                              -6.32041
trainer/qf_loss                               6.67965
trainer/state_noise                           0.005
trainer/policy_loss                        -137.525
trainer/policy_loss_without_entropy         139.111
trainer/entropy_penalty                      -0.388169
trainer/entropy_percentage                   -0.00279035
trainer/Q1Pred Mean                         138.333
trainer/Q1Pred Std                           50.751
trainer/Q1Pred Max                          219.907
trainer/Q1Pred Min                            0.00879446
trainer/Q2Pred Mean                         137.677
trainer/Q2Pred Std                           50.8439
trainer/Q2Pred Max                          221.028
trainer/Q2Pred Min                            2.29075
trainer/QTargetWithReg Mean                 137.893
trainer/QTargetWithReg Std                   50.8919
trainer/QTargetWithReg Max                  219.815
trainer/QTargetWithReg Min                    2.12431
trainer/PolicyLossWithoutReg Mean           139.111
trainer/PolicyLossWithoutReg Std             50.4116
trainer/PolicyLossWithoutReg Max            220.273
trainer/PolicyLossWithoutReg Min              3.36086
trainer/gradient_norm                       239.682
trainer/gradient_penalty                     -1.19841
trainer/gradient_percentage                  -0.00861478
exploration/num steps total              320000
exploration/num paths total                1474
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.28542
exploration/Rewards Std                       1.31423
exploration/Rewards Max                       9.87224
exploration/Rewards Min                      -0.40171
exploration/Returns Mean                   4285.42
exploration/Returns Std                       0
exploration/Returns Max                    4285.42
exploration/Returns Min                    4285.42
exploration/Num Paths                         1
exploration/Average Returns                4285.42
evaluation_0/num steps total                  2.45285e+06
evaluation_0/num paths total              10027
evaluation_0/path length Mean               732.6
evaluation_0/path length Std                215.687
evaluation_0/path length Max               1000
evaluation_0/path length Min                431
evaluation_0/Rewards Mean                     4.37845
evaluation_0/Rewards Std                      1.4133
evaluation_0/Rewards Max                     10.0502
evaluation_0/Rewards Min                     -0.56257
evaluation_0/Returns Mean                  3207.65
evaluation_0/Returns Std                    871.201
evaluation_0/Returns Max                   4439.08
evaluation_0/Returns Min                   1903.27
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3207.65
time/epoch (s)                                0
time/total (s)                             6501.63
Epoch                                       315
---------------------------------------  ----------------
2022-11-16 12:34:23.611296 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 316 finished
---------------------------------------  ----------------
epoch                                       316
total_step                               321000
replay_pool/size                         321000
trainer/alpha                                 0.0615174
trainer/alpha_loss                            0.768959
trainer/entropy                              -6.27576
trainer/qf_loss                               8.79291
trainer/state_noise                           0.005
trainer/policy_loss                        -139.857
trainer/policy_loss_without_entropy         141.475
trainer/entropy_penalty                      -0.386068
trainer/entropy_percentage                   -0.00272888
trainer/Q1Pred Mean                         140.446
trainer/Q1Pred Std                           47.6532
trainer/Q1Pred Max                          231.381
trainer/Q1Pred Min                            8.95533
trainer/Q2Pred Mean                         140.303
trainer/Q2Pred Std                           47.6495
trainer/Q2Pred Max                          231.634
trainer/Q2Pred Min                           10.1261
trainer/QTargetWithReg Mean                 140.641
trainer/QTargetWithReg Std                   47.7169
trainer/QTargetWithReg Max                  231.777
trainer/QTargetWithReg Min                    9.33035
trainer/PolicyLossWithoutReg Mean           141.475
trainer/PolicyLossWithoutReg Std             47.1211
trainer/PolicyLossWithoutReg Max            231.578
trainer/PolicyLossWithoutReg Min              9.10764
trainer/gradient_norm                       246.496
trainer/gradient_penalty                     -1.23248
trainer/gradient_percentage                  -0.00871164
exploration/num steps total              321000
exploration/num paths total                1475
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.21237
exploration/Rewards Std                       1.16421
exploration/Rewards Max                       9.66425
exploration/Rewards Min                      -0.500893
exploration/Returns Mean                   4212.37
exploration/Returns Std                       0
exploration/Returns Max                    4212.37
exploration/Returns Min                    4212.37
exploration/Num Paths                         1
exploration/Average Returns                4212.37
evaluation_0/num steps total                  2.46085e+06
evaluation_0/num paths total              10035
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.4082
evaluation_0/Rewards Std                      1.25288
evaluation_0/Rewards Max                     10.2083
evaluation_0/Rewards Min                     -0.640205
evaluation_0/Returns Mean                  4408.2
evaluation_0/Returns Std                    149.967
evaluation_0/Returns Max                   4537.1
evaluation_0/Returns Min                   4032.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4408.2
time/epoch (s)                                0
time/total (s)                             6517.5
Epoch                                       316
---------------------------------------  ----------------
2022-11-16 12:34:40.103164 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 317 finished
---------------------------------------  ----------------
epoch                                       317
total_step                               322000
replay_pool/size                         322000
trainer/alpha                                 0.0612457
trainer/alpha_loss                           -0.382083
trainer/entropy                              -5.8632
trainer/qf_loss                              10.1649
trainer/state_noise                           0.005
trainer/policy_loss                        -142.58
trainer/policy_loss_without_entropy         144.199
trainer/entropy_penalty                      -0.359096
trainer/entropy_percentage                   -0.00249028
trainer/Q1Pred Mean                         143.811
trainer/Q1Pred Std                           51.3684
trainer/Q1Pred Max                          233.382
trainer/Q1Pred Min                          -17.2744
trainer/Q2Pred Mean                         143.926
trainer/Q2Pred Std                           51.0571
trainer/Q2Pred Max                          232.255
trainer/Q2Pred Min                          -16.2282
trainer/QTargetWithReg Mean                 143.718
trainer/QTargetWithReg Std                   51.3815
trainer/QTargetWithReg Max                  230.309
trainer/QTargetWithReg Min                  -15.67
trainer/PolicyLossWithoutReg Mean           144.199
trainer/PolicyLossWithoutReg Std             50.8517
trainer/PolicyLossWithoutReg Max            231.74
trainer/PolicyLossWithoutReg Min            -12.9048
trainer/gradient_norm                       252.017
trainer/gradient_penalty                     -1.26008
trainer/gradient_percentage                  -0.00873849
exploration/num steps total              322000
exploration/num paths total                1476
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      3.96526
exploration/Rewards Std                       1.09702
exploration/Rewards Max                       8.18148
exploration/Rewards Min                      -0.64463
exploration/Returns Mean                   3965.26
exploration/Returns Std                       0
exploration/Returns Max                    3965.26
exploration/Returns Min                    3965.26
exploration/Num Paths                         1
exploration/Average Returns                3965.26
evaluation_0/num steps total                  2.46885e+06
evaluation_0/num paths total              10043
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.9112
evaluation_0/Rewards Std                      1.05934
evaluation_0/Rewards Max                      8.29969
evaluation_0/Rewards Min                     -0.611042
evaluation_0/Returns Mean                  3911.2
evaluation_0/Returns Std                     75.7917
evaluation_0/Returns Max                   4043.04
evaluation_0/Returns Min                   3774.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3911.2
time/epoch (s)                                0
time/total (s)                             6533.99
Epoch                                       317
---------------------------------------  ----------------
2022-11-16 12:34:56.017241 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 318 finished
---------------------------------------  ----------------
epoch                                       318
total_step                               323000
replay_pool/size                         323000
trainer/alpha                                 0.0632107
trainer/alpha_loss                            0.739511
trainer/entropy                              -6.26784
trainer/qf_loss                               8.2246
trainer/state_noise                           0.005
trainer/policy_loss                        -142.862
trainer/policy_loss_without_entropy         144.493
trainer/entropy_penalty                      -0.396194
trainer/entropy_percentage                   -0.00274195
trainer/Q1Pred Mean                         143.192
trainer/Q1Pred Std                           51.7665
trainer/Q1Pred Max                          222.927
trainer/Q1Pred Min                            2.4761
trainer/Q2Pred Mean                         143.324
trainer/Q2Pred Std                           51.7286
trainer/Q2Pred Max                          225.035
trainer/Q2Pred Min                            6.04985
trainer/QTargetWithReg Mean                 142.854
trainer/QTargetWithReg Std                   51.6872
trainer/QTargetWithReg Max                  225.084
trainer/QTargetWithReg Min                    5.62551
trainer/PolicyLossWithoutReg Mean           144.493
trainer/PolicyLossWithoutReg Std             51.2335
trainer/PolicyLossWithoutReg Max            223.411
trainer/PolicyLossWithoutReg Min              4.90442
trainer/gradient_norm                       247.116
trainer/gradient_penalty                     -1.23558
trainer/gradient_percentage                  -0.00855111
exploration/num steps total              323000
exploration/num paths total                1477
exploration/path length this epoch Mean     540
exploration/path length this epoch Std        0
exploration/path length this epoch Max      540
exploration/path length this epoch Min      540
exploration/Rewards Mean                      4.43979
exploration/Rewards Std                       1.52511
exploration/Rewards Max                       9.58492
exploration/Rewards Min                      -0.576618
exploration/Returns Mean                   2397.49
exploration/Returns Std                       0
exploration/Returns Max                    2397.49
exploration/Returns Min                    2397.49
exploration/Num Paths                         1
exploration/Average Returns                2397.49
evaluation_0/num steps total                  2.47685e+06
evaluation_0/num paths total              10051
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.49319
evaluation_0/Rewards Std                      1.25933
evaluation_0/Rewards Max                      9.28829
evaluation_0/Rewards Min                     -0.564167
evaluation_0/Returns Mean                  4493.19
evaluation_0/Returns Std                     17.7191
evaluation_0/Returns Max                   4524.21
evaluation_0/Returns Min                   4469.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4493.19
time/epoch (s)                                0
time/total (s)                             6549.9
Epoch                                       318
---------------------------------------  ----------------
2022-11-16 12:35:12.400813 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 319 finished
---------------------------------------  ----------------
epoch                                       319
total_step                               324000
replay_pool/size                         324000
trainer/alpha                                 0.0623155
trainer/alpha_loss                            0.210788
trainer/entropy                              -6.07595
trainer/qf_loss                               6.8067
trainer/state_noise                           0.005
trainer/policy_loss                        -143.919
trainer/policy_loss_without_entropy         145.55
trainer/entropy_penalty                      -0.378626
trainer/entropy_percentage                   -0.00260134
trainer/Q1Pred Mean                         144.766
trainer/Q1Pred Std                           49.7195
trainer/Q1Pred Max                          228.413
trainer/Q1Pred Min                           -2.75785
trainer/Q2Pred Mean                         144.651
trainer/Q2Pred Std                           49.861
trainer/Q2Pred Max                          231.028
trainer/Q2Pred Min                           -4.83818
trainer/QTargetWithReg Mean                 144.78
trainer/QTargetWithReg Std                   49.802
trainer/QTargetWithReg Max                  229.098
trainer/QTargetWithReg Min                   -1.87955
trainer/PolicyLossWithoutReg Mean           145.55
trainer/PolicyLossWithoutReg Std             49.2257
trainer/PolicyLossWithoutReg Max            228.541
trainer/PolicyLossWithoutReg Min             -4.13661
trainer/gradient_norm                       250.61
trainer/gradient_penalty                     -1.25305
trainer/gradient_percentage                  -0.00860903
exploration/num steps total              324000
exploration/num paths total                1478
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.36084
exploration/Rewards Std                       1.2616
exploration/Rewards Max                      10.0962
exploration/Rewards Min                      -0.538308
exploration/Returns Mean                   4360.84
exploration/Returns Std                       0
exploration/Returns Max                    4360.84
exploration/Returns Min                    4360.84
exploration/Num Paths                         1
exploration/Average Returns                4360.84
evaluation_0/num steps total                  2.48485e+06
evaluation_0/num paths total              10059
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58497
evaluation_0/Rewards Std                      1.30425
evaluation_0/Rewards Max                     10.5653
evaluation_0/Rewards Min                     -0.550219
evaluation_0/Returns Mean                  4584.97
evaluation_0/Returns Std                     21.8013
evaluation_0/Returns Max                   4630.47
evaluation_0/Returns Min                   4562.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4584.97
time/epoch (s)                                0
time/total (s)                             6566.29
Epoch                                       319
---------------------------------------  ----------------
2022-11-16 12:35:28.241874 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 320 finished
---------------------------------------  ----------------
epoch                                       320
total_step                               325000
replay_pool/size                         325000
trainer/alpha                                 0.0629183
trainer/alpha_loss                            0.709048
trainer/entropy                              -6.25635
trainer/qf_loss                               6.98261
trainer/state_noise                           0.005
trainer/policy_loss                        -146.229
trainer/policy_loss_without_entropy         147.831
trainer/entropy_penalty                      -0.393639
trainer/entropy_percentage                   -0.00266276
trainer/Q1Pred Mean                         147.077
trainer/Q1Pred Std                           47.7118
trainer/Q1Pred Max                          236.829
trainer/Q1Pred Min                            0.385306
trainer/Q2Pred Mean                         146.74
trainer/Q2Pred Std                           47.6498
trainer/Q2Pred Max                          236.229
trainer/Q2Pred Min                            1.56039
trainer/QTargetWithReg Mean                 147.275
trainer/QTargetWithReg Std                   47.3275
trainer/QTargetWithReg Max                  235.191
trainer/QTargetWithReg Min                    3.41884
trainer/PolicyLossWithoutReg Mean           147.831
trainer/PolicyLossWithoutReg Std             47.0318
trainer/PolicyLossWithoutReg Max            235.616
trainer/PolicyLossWithoutReg Min              2.17383
trainer/gradient_norm                       241.572
trainer/gradient_penalty                     -1.20786
trainer/gradient_percentage                  -0.00817054
exploration/num steps total              325000
exploration/num paths total                1479
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.46145
exploration/Rewards Std                       1.27956
exploration/Rewards Max                       9.59769
exploration/Rewards Min                      -0.527152
exploration/Returns Mean                   4461.45
exploration/Returns Std                       0
exploration/Returns Max                    4461.45
exploration/Returns Min                    4461.45
exploration/Num Paths                         1
exploration/Average Returns                4461.45
evaluation_0/num steps total                  2.49285e+06
evaluation_0/num paths total              10067
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.40072
evaluation_0/Rewards Std                      1.28327
evaluation_0/Rewards Max                      9.76001
evaluation_0/Rewards Min                     -0.541457
evaluation_0/Returns Mean                  4400.72
evaluation_0/Returns Std                     14.7451
evaluation_0/Returns Max                   4418.75
evaluation_0/Returns Min                   4371.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4400.72
time/epoch (s)                                0
time/total (s)                             6582.13
Epoch                                       320
---------------------------------------  ----------------
2022-11-16 12:35:46.319215 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 321 finished
---------------------------------------  ----------------
epoch                                       321
total_step                               326000
replay_pool/size                         326000
trainer/alpha                                 0.0625957
trainer/alpha_loss                            1.34735
trainer/entropy                              -6.48619
trainer/qf_loss                               8.81569
trainer/state_noise                           0.005
trainer/policy_loss                        -142.571
trainer/policy_loss_without_entropy         144.258
trainer/entropy_penalty                      -0.406008
trainer/entropy_percentage                   -0.00281445
trainer/Q1Pred Mean                         144.068
trainer/Q1Pred Std                           48.0733
trainer/Q1Pred Max                          229.639
trainer/Q1Pred Min                            2.54022
trainer/Q2Pred Mean                         143.633
trainer/Q2Pred Std                           47.9481
trainer/Q2Pred Max                          230.297
trainer/Q2Pred Min                            2.19688
trainer/QTargetWithReg Mean                 143.688
trainer/QTargetWithReg Std                   48.022
trainer/QTargetWithReg Max                  229.472
trainer/QTargetWithReg Min                    4.94285
trainer/PolicyLossWithoutReg Mean           144.258
trainer/PolicyLossWithoutReg Std             47.4209
trainer/PolicyLossWithoutReg Max            228.715
trainer/PolicyLossWithoutReg Min              2.97408
trainer/gradient_norm                       256.23
trainer/gradient_penalty                     -1.28115
trainer/gradient_percentage                  -0.00888096
exploration/num steps total              326000
exploration/num paths total                1480
exploration/path length this epoch Mean     622
exploration/path length this epoch Std        0
exploration/path length this epoch Max      622
exploration/path length this epoch Min      622
exploration/Rewards Mean                      4.60593
exploration/Rewards Std                       1.47981
exploration/Rewards Max                       9.66443
exploration/Rewards Min                      -0.590656
exploration/Returns Mean                   2864.89
exploration/Returns Std                       0
exploration/Returns Max                    2864.89
exploration/Returns Min                    2864.89
exploration/Num Paths                         1
exploration/Average Returns                2864.89
evaluation_0/num steps total                  2.50074e+06
evaluation_0/num paths total              10075
evaluation_0/path length Mean               985.625
evaluation_0/path length Std                 38.0327
evaluation_0/path length Max               1000
evaluation_0/path length Min                885
evaluation_0/Rewards Mean                     4.32374
evaluation_0/Rewards Std                      1.35454
evaluation_0/Rewards Max                     10.1721
evaluation_0/Rewards Min                     -0.626783
evaluation_0/Returns Mean                  4261.59
evaluation_0/Returns Std                    134.215
evaluation_0/Returns Max                   4481.31
evaluation_0/Returns Min                   3975.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4261.59
time/epoch (s)                                0
time/total (s)                             6600.2
Epoch                                       321
---------------------------------------  ----------------
2022-11-16 12:36:02.233366 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 322 finished
---------------------------------------  ----------------
epoch                                       322
total_step                               327000
replay_pool/size                         327000
trainer/alpha                                 0.0614124
trainer/alpha_loss                           -0.455183
trainer/entropy                              -5.83686
trainer/qf_loss                              12.8896
trainer/state_noise                           0.005
trainer/policy_loss                        -133.601
trainer/policy_loss_without_entropy         135.239
trainer/entropy_penalty                      -0.358456
trainer/entropy_percentage                   -0.00265053
trainer/Q1Pred Mean                         133.669
trainer/Q1Pred Std                           50.493
trainer/Q1Pred Max                          228.234
trainer/Q1Pred Min                          -23.6476
trainer/Q2Pred Mean                         133.669
trainer/Q2Pred Std                           50.5433
trainer/Q2Pred Max                          228.755
trainer/Q2Pred Min                           -7.76746
trainer/QTargetWithReg Mean                 133.27
trainer/QTargetWithReg Std                   50.4813
trainer/QTargetWithReg Max                  228.619
trainer/QTargetWithReg Min                   -0.579259
trainer/PolicyLossWithoutReg Mean           135.239
trainer/PolicyLossWithoutReg Std             48.9271
trainer/PolicyLossWithoutReg Max            227.752
trainer/PolicyLossWithoutReg Min            -16.5302
trainer/gradient_norm                       255.961
trainer/gradient_penalty                     -1.2798
trainer/gradient_percentage                  -0.00946324
exploration/num steps total              327000
exploration/num paths total                1482
exploration/path length this epoch Mean     252.5
exploration/path length this epoch Std      213.5
exploration/path length this epoch Max      466
exploration/path length this epoch Min       39
exploration/Rewards Mean                      4.24468
exploration/Rewards Std                       1.66716
exploration/Rewards Max                       9.18955
exploration/Rewards Min                      -0.717557
exploration/Returns Mean                   1071.78
exploration/Returns Std                     997.193
exploration/Returns Max                    2068.97
exploration/Returns Min                      74.5885
exploration/Num Paths                         2
exploration/Average Returns                1071.78
evaluation_0/num steps total                  2.50874e+06
evaluation_0/num paths total              10083
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.38907
evaluation_0/Rewards Std                      1.26959
evaluation_0/Rewards Max                     10.108
evaluation_0/Rewards Min                     -0.487002
evaluation_0/Returns Mean                  4389.07
evaluation_0/Returns Std                    139.562
evaluation_0/Returns Max                   4561.28
evaluation_0/Returns Min                   4126.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4389.07
time/epoch (s)                                0
time/total (s)                             6616.12
Epoch                                       322
---------------------------------------  ----------------
2022-11-16 12:36:18.802145 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 323 finished
---------------------------------------  ----------------
epoch                                       323
total_step                               328000
replay_pool/size                         328000
trainer/alpha                                 0.0629098
trainer/alpha_loss                           -0.680829
trainer/entropy                              -5.75386
trainer/qf_loss                               6.06618
trainer/state_noise                           0.005
trainer/policy_loss                        -143.994
trainer/policy_loss_without_entropy         145.633
trainer/entropy_penalty                      -0.361974
trainer/entropy_percentage                   -0.00248552
trainer/Q1Pred Mean                         145.138
trainer/Q1Pred Std                           51.8763
trainer/Q1Pred Max                          248.745
trainer/Q1Pred Min                            2.0513
trainer/Q2Pred Mean                         145.267
trainer/Q2Pred Std                           51.959
trainer/Q2Pred Max                          247.886
trainer/Q2Pred Min                           -0.846786
trainer/QTargetWithReg Mean                 145.111
trainer/QTargetWithReg Std                   52.1809
trainer/QTargetWithReg Max                  248.22
trainer/QTargetWithReg Min                    0.991994
trainer/PolicyLossWithoutReg Mean           145.633
trainer/PolicyLossWithoutReg Std             51.4261
trainer/PolicyLossWithoutReg Max            247.743
trainer/PolicyLossWithoutReg Min              2.92206
trainer/gradient_norm                       255.374
trainer/gradient_penalty                     -1.27687
trainer/gradient_percentage                  -0.00876774
exploration/num steps total              328000
exploration/num paths total                1483
exploration/path length this epoch Mean     513
exploration/path length this epoch Std        0
exploration/path length this epoch Max      513
exploration/path length this epoch Min      513
exploration/Rewards Mean                      4.58613
exploration/Rewards Std                       1.61026
exploration/Rewards Max                      10.0458
exploration/Rewards Min                      -0.528847
exploration/Returns Mean                   2352.69
exploration/Returns Std                       0
exploration/Returns Max                    2352.69
exploration/Returns Min                    2352.69
exploration/Num Paths                         1
exploration/Average Returns                2352.69
evaluation_0/num steps total                  2.51674e+06
evaluation_0/num paths total              10091
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.39126
evaluation_0/Rewards Std                      1.27425
evaluation_0/Rewards Max                     10.1771
evaluation_0/Rewards Min                     -0.585856
evaluation_0/Returns Mean                  4391.26
evaluation_0/Returns Std                    184.157
evaluation_0/Returns Max                   4508.72
evaluation_0/Returns Min                   3911.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4391.26
time/epoch (s)                                0
time/total (s)                             6632.68
Epoch                                       323
---------------------------------------  ----------------
2022-11-16 12:36:34.664754 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 324 finished
---------------------------------------  ----------------
epoch                                       324
total_step                               329000
replay_pool/size                         329000
trainer/alpha                                 0.0621441
trainer/alpha_loss                           -0.964065
trainer/entropy                              -5.65298
trainer/qf_loss                               6.7923
trainer/state_noise                           0.005
trainer/policy_loss                        -143.388
trainer/policy_loss_without_entropy         145.007
trainer/entropy_penalty                      -0.351299
trainer/entropy_percentage                   -0.00242264
trainer/Q1Pred Mean                         143.774
trainer/Q1Pred Std                           54.0325
trainer/Q1Pred Max                          238.538
trainer/Q1Pred Min                           -4.15567
trainer/Q2Pred Mean                         144.135
trainer/Q2Pred Std                           54.2069
trainer/Q2Pred Max                          239.671
trainer/Q2Pred Min                           -5.71815
trainer/QTargetWithReg Mean                 144.125
trainer/QTargetWithReg Std                   54.3729
trainer/QTargetWithReg Max                  238.971
trainer/QTargetWithReg Min                   -0.419796
trainer/PolicyLossWithoutReg Mean           145.007
trainer/PolicyLossWithoutReg Std             53.5376
trainer/PolicyLossWithoutReg Max            238.097
trainer/PolicyLossWithoutReg Min              0.739751
trainer/gradient_norm                       253.522
trainer/gradient_penalty                     -1.26761
trainer/gradient_percentage                  -0.00874174
exploration/num steps total              329000
exploration/num paths total                1484
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.40826
exploration/Rewards Std                       1.28261
exploration/Rewards Max                       9.87359
exploration/Rewards Min                      -0.405944
exploration/Returns Mean                   4408.26
exploration/Returns Std                       0
exploration/Returns Max                    4408.26
exploration/Returns Min                    4408.26
exploration/Num Paths                         1
exploration/Average Returns                4408.26
evaluation_0/num steps total                  2.52474e+06
evaluation_0/num paths total              10099
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.33991
evaluation_0/Rewards Std                      1.27235
evaluation_0/Rewards Max                     10.3441
evaluation_0/Rewards Min                     -0.635258
evaluation_0/Returns Mean                  4339.91
evaluation_0/Returns Std                    111.476
evaluation_0/Returns Max                   4476.85
evaluation_0/Returns Min                   4089.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4339.91
time/epoch (s)                                0
time/total (s)                             6648.55
Epoch                                       324
---------------------------------------  ----------------
2022-11-16 12:36:50.971592 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 325 finished
---------------------------------------  ----------------
epoch                                       325
total_step                               330000
replay_pool/size                         330000
trainer/alpha                                 0.0624279
trainer/alpha_loss                            0.56671
trainer/entropy                              -6.20431
trainer/qf_loss                               6.94331
trainer/state_noise                           0.005
trainer/policy_loss                        -144.209
trainer/policy_loss_without_entropy         145.887
trainer/entropy_penalty                      -0.387322
trainer/entropy_percentage                   -0.00265494
trainer/Q1Pred Mean                         145.25
trainer/Q1Pred Std                           49.9773
trainer/Q1Pred Max                          234.972
trainer/Q1Pred Min                            6.90425
trainer/Q2Pred Mean                         145.276
trainer/Q2Pred Std                           49.8434
trainer/Q2Pred Max                          233.094
trainer/Q2Pred Min                            4.85494
trainer/QTargetWithReg Mean                 145.012
trainer/QTargetWithReg Std                   49.9995
trainer/QTargetWithReg Max                  234.282
trainer/QTargetWithReg Min                   -0.435001
trainer/PolicyLossWithoutReg Mean           145.887
trainer/PolicyLossWithoutReg Std             49.4074
trainer/PolicyLossWithoutReg Max            232.872
trainer/PolicyLossWithoutReg Min              7.5213
trainer/gradient_norm                       258.224
trainer/gradient_penalty                     -1.29112
trainer/gradient_percentage                  -0.00885015
exploration/num steps total              330000
exploration/num paths total                1486
exploration/path length this epoch Mean     407.5
exploration/path length this epoch Std       63.5
exploration/path length this epoch Max      471
exploration/path length this epoch Min      344
exploration/Rewards Mean                      4.50222
exploration/Rewards Std                       1.63768
exploration/Rewards Max                      10.0426
exploration/Rewards Min                      -0.754072
exploration/Returns Mean                   1834.65
exploration/Returns Std                     291.557
exploration/Returns Max                    2126.21
exploration/Returns Min                    1543.1
exploration/Num Paths                         2
exploration/Average Returns                1834.65
evaluation_0/num steps total                  2.53274e+06
evaluation_0/num paths total              10107
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.19695
evaluation_0/Rewards Std                      1.16057
evaluation_0/Rewards Max                      9.33813
evaluation_0/Rewards Min                     -0.625414
evaluation_0/Returns Mean                  4196.95
evaluation_0/Returns Std                     67.9804
evaluation_0/Returns Max                   4327.32
evaluation_0/Returns Min                   4136.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4196.95
time/epoch (s)                                0
time/total (s)                             6664.85
Epoch                                       325
---------------------------------------  ----------------
2022-11-16 12:37:08.442652 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 326 finished
---------------------------------------  ---------------
epoch                                       326
total_step                               331000
replay_pool/size                         331000
trainer/alpha                                 0.0639914
trainer/alpha_loss                            0.306143
trainer/entropy                              -6.11137
trainer/qf_loss                              12.5371
trainer/state_noise                           0.005
trainer/policy_loss                        -144.806
trainer/policy_loss_without_entropy         146.476
trainer/entropy_penalty                      -0.391075
trainer/entropy_percentage                   -0.0026699
trainer/Q1Pred Mean                         145.294
trainer/Q1Pred Std                           50.3123
trainer/Q1Pred Max                          232.287
trainer/Q1Pred Min                          -11.4423
trainer/Q2Pred Mean                         144.928
trainer/Q2Pred Std                           50.215
trainer/Q2Pred Max                          232.099
trainer/Q2Pred Min                           -9.98038
trainer/QTargetWithReg Mean                 145.847
trainer/QTargetWithReg Std                   51.06
trainer/QTargetWithReg Max                  232.003
trainer/QTargetWithReg Min                   -7.55567
trainer/PolicyLossWithoutReg Mean           146.476
trainer/PolicyLossWithoutReg Std             49.4158
trainer/PolicyLossWithoutReg Max            232.448
trainer/PolicyLossWithoutReg Min             -2.37214
trainer/gradient_norm                       255.712
trainer/gradient_penalty                     -1.27856
trainer/gradient_percentage                  -0.00872882
exploration/num steps total              331000
exploration/num paths total                1487
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.23107
exploration/Rewards Std                       1.33071
exploration/Rewards Max                      10.4872
exploration/Rewards Min                      -0.519715
exploration/Returns Mean                   4231.07
exploration/Returns Std                       0
exploration/Returns Max                    4231.07
exploration/Returns Min                    4231.07
exploration/Num Paths                         1
exploration/Average Returns                4231.07
evaluation_0/num steps total                  2.5407e+06
evaluation_0/num paths total              10117
evaluation_0/path length Mean               796.8
evaluation_0/path length Std                217.917
evaluation_0/path length Max               1000
evaluation_0/path length Min                370
evaluation_0/Rewards Mean                     4.51949
evaluation_0/Rewards Std                      1.41604
evaluation_0/Rewards Max                     10.2963
evaluation_0/Rewards Min                     -0.585483
evaluation_0/Returns Mean                  3601.13
evaluation_0/Returns Std                    943.372
evaluation_0/Returns Max                   4714.2
evaluation_0/Returns Min                   1684.57
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3601.13
time/epoch (s)                                0
time/total (s)                             6682.32
Epoch                                       326
---------------------------------------  ---------------
2022-11-16 12:37:26.292920 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 327 finished
---------------------------------------  ----------------
epoch                                       327
total_step                               332000
replay_pool/size                         332000
trainer/alpha                                 0.0620986
trainer/alpha_loss                           -0.514726
trainer/entropy                              -5.81478
trainer/qf_loss                               5.85696
trainer/state_noise                           0.005
trainer/policy_loss                        -146.587
trainer/policy_loss_without_entropy         148.157
trainer/entropy_penalty                      -0.36109
trainer/entropy_percentage                   -0.00243721
trainer/Q1Pred Mean                         147.815
trainer/Q1Pred Std                           48.6769
trainer/Q1Pred Max                          242.374
trainer/Q1Pred Min                            0.332129
trainer/Q2Pred Mean                         147.211
trainer/Q2Pred Std                           48.931
trainer/Q2Pred Max                          240.93
trainer/Q2Pred Min                           -1.84995
trainer/QTargetWithReg Mean                 147.475
trainer/QTargetWithReg Std                   48.9156
trainer/QTargetWithReg Max                  241.506
trainer/QTargetWithReg Min                    0.0438341
trainer/PolicyLossWithoutReg Mean           148.157
trainer/PolicyLossWithoutReg Std             48.3129
trainer/PolicyLossWithoutReg Max            239.264
trainer/PolicyLossWithoutReg Min              0.0179803
trainer/gradient_norm                       241.825
trainer/gradient_penalty                     -1.20913
trainer/gradient_percentage                  -0.0081611
exploration/num steps total              332000
exploration/num paths total                1488
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.35977
exploration/Rewards Std                       1.36114
exploration/Rewards Max                      10.1698
exploration/Rewards Min                      -0.534082
exploration/Returns Mean                   4359.77
exploration/Returns Std                       0
exploration/Returns Max                    4359.77
exploration/Returns Min                    4359.77
exploration/Num Paths                         1
exploration/Average Returns                4359.77
evaluation_0/num steps total                  2.54868e+06
evaluation_0/num paths total              10127
evaluation_0/path length Mean               797.8
evaluation_0/path length Std                253.5
evaluation_0/path length Max               1000
evaluation_0/path length Min                414
evaluation_0/Rewards Mean                     4.54236
evaluation_0/Rewards Std                      1.44709
evaluation_0/Rewards Max                     10.7586
evaluation_0/Rewards Min                     -0.566528
evaluation_0/Returns Mean                  3623.89
evaluation_0/Returns Std                   1167.87
evaluation_0/Returns Max                   4722.38
evaluation_0/Returns Min                   1847.3
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3623.89
time/epoch (s)                                0
time/total (s)                             6700.17
Epoch                                       327
---------------------------------------  ----------------
2022-11-16 12:37:43.821013 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 328 finished
---------------------------------------  ----------------
epoch                                       328
total_step                               333000
replay_pool/size                         333000
trainer/alpha                                 0.063117
trainer/alpha_loss                           -2.19194
trainer/entropy                              -5.20654
trainer/qf_loss                               6.44582
trainer/state_noise                           0.005
trainer/policy_loss                        -153.09
trainer/policy_loss_without_entropy         154.718
trainer/entropy_penalty                      -0.328621
trainer/entropy_percentage                   -0.002124
trainer/Q1Pred Mean                         154.642
trainer/Q1Pred Std                           49.5273
trainer/Q1Pred Max                          229.771
trainer/Q1Pred Min                          -15.9959
trainer/Q2Pred Mean                         154.466
trainer/Q2Pred Std                           49.2698
trainer/Q2Pred Max                          227.976
trainer/Q2Pred Min                           -1.10526
trainer/QTargetWithReg Mean                 154.296
trainer/QTargetWithReg Std                   49.1883
trainer/QTargetWithReg Max                  228.32
trainer/QTargetWithReg Min                   -0.150345
trainer/PolicyLossWithoutReg Mean           154.718
trainer/PolicyLossWithoutReg Std             48.0619
trainer/PolicyLossWithoutReg Max            227.76
trainer/PolicyLossWithoutReg Min             15.5347
trainer/gradient_norm                       259.902
trainer/gradient_penalty                     -1.29951
trainer/gradient_percentage                  -0.00839921
exploration/num steps total              333000
exploration/num paths total                1489
exploration/path length this epoch Mean     493
exploration/path length this epoch Std        0
exploration/path length this epoch Max      493
exploration/path length this epoch Min      493
exploration/Rewards Mean                      4.53189
exploration/Rewards Std                       1.57086
exploration/Rewards Max                      10.343
exploration/Rewards Min                      -0.41866
exploration/Returns Mean                   2234.22
exploration/Returns Std                       0
exploration/Returns Max                    2234.22
exploration/Returns Min                    2234.22
exploration/Num Paths                         1
exploration/Average Returns                2234.22
evaluation_0/num steps total                  2.55603e+06
evaluation_0/num paths total              10137
evaluation_0/path length Mean               734.7
evaluation_0/path length Std                220.966
evaluation_0/path length Max               1000
evaluation_0/path length Min                417
evaluation_0/Rewards Mean                     4.51025
evaluation_0/Rewards Std                      1.43148
evaluation_0/Rewards Max                     10.5788
evaluation_0/Rewards Min                     -0.540605
evaluation_0/Returns Mean                  3313.68
evaluation_0/Returns Std                    986.916
evaluation_0/Returns Max                   4748.08
evaluation_0/Returns Min                   1903.86
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3313.68
time/epoch (s)                                0
time/total (s)                             6717.7
Epoch                                       328
---------------------------------------  ----------------
2022-11-16 12:38:00.012006 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 329 finished
---------------------------------------  ----------------
epoch                                       329
total_step                               334000
replay_pool/size                         334000
trainer/alpha                                 0.06208
trainer/alpha_loss                            1.35245
trainer/entropy                              -6.4866
trainer/qf_loss                               9.26923
trainer/state_noise                           0.005
trainer/policy_loss                        -147.167
trainer/policy_loss_without_entropy         148.835
trainer/entropy_penalty                      -0.402689
trainer/entropy_percentage                   -0.0027056
trainer/Q1Pred Mean                         147.976
trainer/Q1Pred Std                           48.2806
trainer/Q1Pred Max                          241.613
trainer/Q1Pred Min                            4.73378
trainer/Q2Pred Mean                         147.17
trainer/Q2Pred Std                           48.2955
trainer/Q2Pred Max                          239.341
trainer/Q2Pred Min                           -3.42315
trainer/QTargetWithReg Mean                 147.779
trainer/QTargetWithReg Std                   48.6928
trainer/QTargetWithReg Max                  241.493
trainer/QTargetWithReg Min                   -8.92332
trainer/PolicyLossWithoutReg Mean           148.835
trainer/PolicyLossWithoutReg Std             47.6592
trainer/PolicyLossWithoutReg Max            240.885
trainer/PolicyLossWithoutReg Min             11.9699
trainer/gradient_norm                       253.061
trainer/gradient_penalty                     -1.26531
trainer/gradient_percentage                  -0.00850139
exploration/num steps total              334000
exploration/num paths total                1490
exploration/path length this epoch Mean     494
exploration/path length this epoch Std        0
exploration/path length this epoch Max      494
exploration/path length this epoch Min      494
exploration/Rewards Mean                      4.67979
exploration/Rewards Std                       1.57238
exploration/Rewards Max                       9.93842
exploration/Rewards Min                      -0.520781
exploration/Returns Mean                   2311.82
exploration/Returns Std                       0
exploration/Returns Max                    2311.82
exploration/Returns Min                    2311.82
exploration/Num Paths                         1
exploration/Average Returns                2311.82
evaluation_0/num steps total                  2.56403e+06
evaluation_0/num paths total              10145
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.05775
evaluation_0/Rewards Std                      1.2026
evaluation_0/Rewards Max                     11.118
evaluation_0/Rewards Min                     -0.537638
evaluation_0/Returns Mean                  4057.75
evaluation_0/Returns Std                    222.233
evaluation_0/Returns Max                   4405.47
evaluation_0/Returns Min                   3744.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4057.75
time/epoch (s)                                0
time/total (s)                             6733.89
Epoch                                       329
---------------------------------------  ----------------
2022-11-16 12:38:17.779878 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 330 finished
---------------------------------------  ----------------
epoch                                       330
total_step                               335000
replay_pool/size                         335000
trainer/alpha                                 0.0629712
trainer/alpha_loss                           -1.1749
trainer/entropy                              -5.57508
trainer/qf_loss                               8.18109
trainer/state_noise                           0.005
trainer/policy_loss                        -142.327
trainer/policy_loss_without_entropy         143.985
trainer/entropy_penalty                      -0.35107
trainer/entropy_percentage                   -0.00243824
trainer/Q1Pred Mean                         143.885
trainer/Q1Pred Std                           53.2261
trainer/Q1Pred Max                          232.176
trainer/Q1Pred Min                          -41.8069
trainer/Q2Pred Mean                         143.287
trainer/Q2Pred Std                           53.1165
trainer/Q2Pred Max                          231.692
trainer/Q2Pred Min                          -41.8872
trainer/QTargetWithReg Mean                 143.243
trainer/QTargetWithReg Std                   53.193
trainer/QTargetWithReg Max                  231.915
trainer/QTargetWithReg Min                  -52.0612
trainer/PolicyLossWithoutReg Mean           143.985
trainer/PolicyLossWithoutReg Std             52.538
trainer/PolicyLossWithoutReg Max            231.04
trainer/PolicyLossWithoutReg Min            -39.7313
trainer/gradient_norm                       261.297
trainer/gradient_penalty                     -1.30648
trainer/gradient_percentage                  -0.00907378
exploration/num steps total              335000
exploration/num paths total                1491
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58929
exploration/Rewards Std                       1.36572
exploration/Rewards Max                      10.516
exploration/Rewards Min                      -0.490302
exploration/Returns Mean                   4589.29
exploration/Returns Std                       0
exploration/Returns Max                    4589.29
exploration/Returns Min                    4589.29
exploration/Num Paths                         1
exploration/Average Returns                4589.29
evaluation_0/num steps total                  2.57165e+06
evaluation_0/num paths total              10154
evaluation_0/path length Mean               847.111
evaluation_0/path length Std                174.032
evaluation_0/path length Max               1000
evaluation_0/path length Min                614
evaluation_0/Rewards Mean                     4.56306
evaluation_0/Rewards Std                      1.48038
evaluation_0/Rewards Max                     10.4227
evaluation_0/Rewards Min                     -0.548661
evaluation_0/Returns Mean                  3865.42
evaluation_0/Returns Std                    673.681
evaluation_0/Returns Max                   4692.98
evaluation_0/Returns Min                   2919.92
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3865.42
time/epoch (s)                                0
time/total (s)                             6751.66
Epoch                                       330
---------------------------------------  ----------------
2022-11-16 12:38:33.646206 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 331 finished
---------------------------------------  ----------------
epoch                                       331
total_step                               336000
replay_pool/size                         336000
trainer/alpha                                 0.061806
trainer/alpha_loss                           -0.831352
trainer/entropy                              -5.70138
trainer/qf_loss                               7.52545
trainer/state_noise                           0.005
trainer/policy_loss                        -146.404
trainer/policy_loss_without_entropy         148.008
trainer/entropy_penalty                      -0.352379
trainer/entropy_percentage                   -0.00238082
trainer/Q1Pred Mean                         147.43
trainer/Q1Pred Std                           53.0297
trainer/Q1Pred Max                          240.593
trainer/Q1Pred Min                          -33.7115
trainer/Q2Pred Mean                         147.222
trainer/Q2Pred Std                           52.8675
trainer/Q2Pred Max                          241.263
trainer/Q2Pred Min                          -29.3033
trainer/QTargetWithReg Mean                 146.496
trainer/QTargetWithReg Std                   52.6759
trainer/QTargetWithReg Max                  239.716
trainer/QTargetWithReg Min                  -37.6941
trainer/PolicyLossWithoutReg Mean           148.008
trainer/PolicyLossWithoutReg Std             52.3567
trainer/PolicyLossWithoutReg Max            240.6
trainer/PolicyLossWithoutReg Min            -30.719
trainer/gradient_norm                       250.334
trainer/gradient_penalty                     -1.25167
trainer/gradient_percentage                  -0.00845678
exploration/num steps total              336000
exploration/num paths total                1492
exploration/path length this epoch Mean     532
exploration/path length this epoch Std        0
exploration/path length this epoch Max      532
exploration/path length this epoch Min      532
exploration/Rewards Mean                      4.66613
exploration/Rewards Std                       1.52381
exploration/Rewards Max                       9.99616
exploration/Rewards Min                      -0.615516
exploration/Returns Mean                   2482.38
exploration/Returns Std                       0
exploration/Returns Max                    2482.38
exploration/Returns Min                    2482.38
exploration/Num Paths                         1
exploration/Average Returns                2482.38
evaluation_0/num steps total                  2.57965e+06
evaluation_0/num paths total              10162
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     3.52156
evaluation_0/Rewards Std                      1.17451
evaluation_0/Rewards Max                      8.38668
evaluation_0/Rewards Min                     -0.633684
evaluation_0/Returns Mean                  3521.56
evaluation_0/Returns Std                    195.675
evaluation_0/Returns Max                   3843.75
evaluation_0/Returns Min                   3280.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               3521.56
time/epoch (s)                                0
time/total (s)                             6767.53
Epoch                                       331
---------------------------------------  ----------------
2022-11-16 12:38:50.172877 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 332 finished
---------------------------------------  ----------------
epoch                                       332
total_step                               337000
replay_pool/size                         337000
trainer/alpha                                 0.0616313
trainer/alpha_loss                            0.0823141
trainer/entropy                              -6.02954
trainer/qf_loss                               8.63583
trainer/state_noise                           0.005
trainer/policy_loss                        -148.046
trainer/policy_loss_without_entropy         149.696
trainer/entropy_penalty                      -0.371608
trainer/entropy_percentage                   -0.00248241
trainer/Q1Pred Mean                         149.266
trainer/Q1Pred Std                           50.8611
trainer/Q1Pred Max                          227.669
trainer/Q1Pred Min                            3.52138
trainer/Q2Pred Mean                         148.828
trainer/Q2Pred Std                           50.8993
trainer/Q2Pred Max                          226.032
trainer/Q2Pred Min                            1.87225
trainer/QTargetWithReg Mean                 148.939
trainer/QTargetWithReg Std                   50.7095
trainer/QTargetWithReg Max                  225.574
trainer/QTargetWithReg Min                    1.75767
trainer/PolicyLossWithoutReg Mean           149.696
trainer/PolicyLossWithoutReg Std             50.378
trainer/PolicyLossWithoutReg Max            226.535
trainer/PolicyLossWithoutReg Min              5.76882
trainer/gradient_norm                       255.762
trainer/gradient_penalty                     -1.27881
trainer/gradient_percentage                  -0.00854268
exploration/num steps total              337000
exploration/num paths total                1493
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60155
exploration/Rewards Std                       1.33963
exploration/Rewards Max                      10.3087
exploration/Rewards Min                      -0.598731
exploration/Returns Mean                   4601.55
exploration/Returns Std                       0
exploration/Returns Max                    4601.55
exploration/Returns Min                    4601.55
exploration/Num Paths                         1
exploration/Average Returns                4601.55
evaluation_0/num steps total                  2.58765e+06
evaluation_0/num paths total              10170
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.28794
evaluation_0/Rewards Std                      1.28518
evaluation_0/Rewards Max                     10.8694
evaluation_0/Rewards Min                     -0.60244
evaluation_0/Returns Mean                  4287.94
evaluation_0/Returns Std                    211.797
evaluation_0/Returns Max                   4579.21
evaluation_0/Returns Min                   3962.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4287.94
time/epoch (s)                                0
time/total (s)                             6784.05
Epoch                                       332
---------------------------------------  ----------------
2022-11-16 12:39:06.045433 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 333 finished
---------------------------------------  ----------------
epoch                                       333
total_step                               338000
replay_pool/size                         338000
trainer/alpha                                 0.0622759
trainer/alpha_loss                           -0.175311
trainer/entropy                              -5.93685
trainer/qf_loss                               8.3796
trainer/state_noise                           0.005
trainer/policy_loss                        -141.561
trainer/policy_loss_without_entropy         143.223
trainer/entropy_penalty                      -0.369723
trainer/entropy_percentage                   -0.00258144
trainer/Q1Pred Mean                         143.041
trainer/Q1Pred Std                           53.8457
trainer/Q1Pred Max                          242.077
trainer/Q1Pred Min                          -15.1071
trainer/Q2Pred Mean                         143.281
trainer/Q2Pred Std                           53.581
trainer/Q2Pred Max                          243.38
trainer/Q2Pred Min                          -14.6296
trainer/QTargetWithReg Mean                 143.071
trainer/QTargetWithReg Std                   53.9937
trainer/QTargetWithReg Max                  244.055
trainer/QTargetWithReg Min                   -9.78087
trainer/PolicyLossWithoutReg Mean           143.223
trainer/PolicyLossWithoutReg Std             52.998
trainer/PolicyLossWithoutReg Max            242.141
trainer/PolicyLossWithoutReg Min            -18.0842
trainer/gradient_norm                       258.566
trainer/gradient_penalty                     -1.29283
trainer/gradient_percentage                  -0.00902665
exploration/num steps total              338000
exploration/num paths total                1494
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5199
exploration/Rewards Std                       1.33918
exploration/Rewards Max                      10.5716
exploration/Rewards Min                      -0.555835
exploration/Returns Mean                   4519.9
exploration/Returns Std                       0
exploration/Returns Max                    4519.9
exploration/Returns Min                    4519.9
exploration/Num Paths                         1
exploration/Average Returns                4519.9
evaluation_0/num steps total                  2.59565e+06
evaluation_0/num paths total              10178
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.11542
evaluation_0/Rewards Std                      1.08765
evaluation_0/Rewards Max                      8.97506
evaluation_0/Rewards Min                     -0.481322
evaluation_0/Returns Mean                  4115.42
evaluation_0/Returns Std                     26.803
evaluation_0/Returns Max                   4155.51
evaluation_0/Returns Min                   4064.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4115.42
time/epoch (s)                                0
time/total (s)                             6799.92
Epoch                                       333
---------------------------------------  ----------------
2022-11-16 12:39:22.715651 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 334 finished
---------------------------------------  ----------------
epoch                                       334
total_step                               339000
replay_pool/size                         339000
trainer/alpha                                 0.0645138
trainer/alpha_loss                           -3.79016e-05
trainer/entropy                              -5.99999
trainer/qf_loss                               7.80412
trainer/state_noise                           0.005
trainer/policy_loss                        -149.936
trainer/policy_loss_without_entropy         151.607
trainer/entropy_penalty                      -0.387082
trainer/entropy_percentage                   -0.00255319
trainer/Q1Pred Mean                         150.489
trainer/Q1Pred Std                           47.2825
trainer/Q1Pred Max                          232.439
trainer/Q1Pred Min                            6.34391
trainer/Q2Pred Mean                         150.22
trainer/Q2Pred Std                           47.2554
trainer/Q2Pred Max                          231.924
trainer/Q2Pred Min                           12.1447
trainer/QTargetWithReg Mean                 150.351
trainer/QTargetWithReg Std                   47.6201
trainer/QTargetWithReg Max                  231.233
trainer/QTargetWithReg Min                    0.249717
trainer/PolicyLossWithoutReg Mean           151.607
trainer/PolicyLossWithoutReg Std             46.1218
trainer/PolicyLossWithoutReg Max            231.709
trainer/PolicyLossWithoutReg Min             13.0862
trainer/gradient_norm                       256.849
trainer/gradient_penalty                     -1.28425
trainer/gradient_percentage                  -0.0084709
exploration/num steps total              339000
exploration/num paths total                1495
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.27183
exploration/Rewards Std                       1.20284
exploration/Rewards Max                       9.57569
exploration/Rewards Min                      -0.469035
exploration/Returns Mean                   4271.83
exploration/Returns Std                       0
exploration/Returns Max                    4271.83
exploration/Returns Min                    4271.83
exploration/Num Paths                         1
exploration/Average Returns                4271.83
evaluation_0/num steps total                  2.60365e+06
evaluation_0/num paths total              10186
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.4776
evaluation_0/Rewards Std                      1.29793
evaluation_0/Rewards Max                     10.3216
evaluation_0/Rewards Min                     -0.521149
evaluation_0/Returns Mean                  4477.6
evaluation_0/Returns Std                     27.0678
evaluation_0/Returns Max                   4529
evaluation_0/Returns Min                   4426.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4477.6
time/epoch (s)                                0
time/total (s)                             6816.59
Epoch                                       334
---------------------------------------  ----------------
2022-11-16 12:39:40.116274 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 335 finished
---------------------------------------  ----------------
epoch                                       335
total_step                               340000
replay_pool/size                         340000
trainer/alpha                                 0.0626915
trainer/alpha_loss                           -0.902528
trainer/entropy                              -5.6741
trainer/qf_loss                               5.53193
trainer/state_noise                           0.005
trainer/policy_loss                        -147.839
trainer/policy_loss_without_entropy         149.506
trainer/entropy_penalty                      -0.355718
trainer/entropy_percentage                   -0.00237928
trainer/Q1Pred Mean                         148.775
trainer/Q1Pred Std                           51.3641
trainer/Q1Pred Max                          236.681
trainer/Q1Pred Min                          -12.1583
trainer/Q2Pred Mean                         148.316
trainer/Q2Pred Std                           51.5549
trainer/Q2Pred Max                          236.257
trainer/Q2Pred Min                          -15.6927
trainer/QTargetWithReg Mean                 148.916
trainer/QTargetWithReg Std                   51.3577
trainer/QTargetWithReg Max                  237.638
trainer/QTargetWithReg Min                  -14.031
trainer/PolicyLossWithoutReg Mean           149.506
trainer/PolicyLossWithoutReg Std             50.6111
trainer/PolicyLossWithoutReg Max            237.426
trainer/PolicyLossWithoutReg Min            -11.699
trainer/gradient_norm                       262.401
trainer/gradient_penalty                     -1.31201
trainer/gradient_percentage                  -0.00877558
exploration/num steps total              340000
exploration/num paths total                1496
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75869
exploration/Rewards Std                       1.42163
exploration/Rewards Max                      10.8438
exploration/Rewards Min                      -0.546997
exploration/Returns Mean                   4758.69
exploration/Returns Std                       0
exploration/Returns Max                    4758.69
exploration/Returns Min                    4758.69
exploration/Num Paths                         1
exploration/Average Returns                4758.69
evaluation_0/num steps total                  2.61159e+06
evaluation_0/num paths total              10195
evaluation_0/path length Mean               881.778
evaluation_0/path length Std                227.609
evaluation_0/path length Max               1000
evaluation_0/path length Min                354
evaluation_0/Rewards Mean                     4.48574
evaluation_0/Rewards Std                      1.39793
evaluation_0/Rewards Max                     10.7662
evaluation_0/Rewards Min                     -0.564823
evaluation_0/Returns Mean                  3955.43
evaluation_0/Returns Std                   1039.72
evaluation_0/Returns Max                   4679.23
evaluation_0/Returns Min                   1544.12
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3955.43
time/epoch (s)                                0
time/total (s)                             6834
Epoch                                       335
---------------------------------------  ----------------
2022-11-16 12:39:58.246200 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 336 finished
---------------------------------------  ----------------
epoch                                       336
total_step                               341000
replay_pool/size                         341000
trainer/alpha                                 0.0632522
trainer/alpha_loss                            0.422662
trainer/entropy                              -6.1531
trainer/qf_loss                              14.2055
trainer/state_noise                           0.005
trainer/policy_loss                        -142.997
trainer/policy_loss_without_entropy         144.691
trainer/entropy_penalty                      -0.389197
trainer/entropy_percentage                   -0.00268985
trainer/Q1Pred Mean                         143.613
trainer/Q1Pred Std                           55.0741
trainer/Q1Pred Max                          244.767
trainer/Q1Pred Min                          -25.6271
trainer/Q2Pred Mean                         144.29
trainer/Q2Pred Std                           54.9063
trainer/Q2Pred Max                          242.385
trainer/Q2Pred Min                          -21.2334
trainer/QTargetWithReg Mean                 144.503
trainer/QTargetWithReg Std                   54.5734
trainer/QTargetWithReg Max                  241.474
trainer/QTargetWithReg Min                  -22.257
trainer/PolicyLossWithoutReg Mean           144.691
trainer/PolicyLossWithoutReg Std             53.97
trainer/PolicyLossWithoutReg Max            241.773
trainer/PolicyLossWithoutReg Min            -24.3704
trainer/gradient_norm                       260.955
trainer/gradient_penalty                     -1.30477
trainer/gradient_percentage                  -0.00901768
exploration/num steps total              341000
exploration/num paths total                1497
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.34284
exploration/Rewards Std                       1.3964
exploration/Rewards Max                      10.7121
exploration/Rewards Min                      -0.547296
exploration/Returns Mean                   4342.84
exploration/Returns Std                       0
exploration/Returns Max                    4342.84
exploration/Returns Min                    4342.84
exploration/Num Paths                         1
exploration/Average Returns                4342.84
evaluation_0/num steps total                  2.61944e+06
evaluation_0/num paths total              10206
evaluation_0/path length Mean               713.909
evaluation_0/path length Std                241.36
evaluation_0/path length Max               1000
evaluation_0/path length Min                427
evaluation_0/Rewards Mean                     4.5481
evaluation_0/Rewards Std                      1.46612
evaluation_0/Rewards Max                     10.589
evaluation_0/Rewards Min                     -0.50731
evaluation_0/Returns Mean                  3246.93
evaluation_0/Returns Std                   1034.61
evaluation_0/Returns Max                   4569.32
evaluation_0/Returns Min                   1942.13
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3246.93
time/epoch (s)                                0
time/total (s)                             6852.12
Epoch                                       336
---------------------------------------  ----------------
2022-11-16 12:40:14.099737 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 337 finished
---------------------------------------  ----------------
epoch                                       337
total_step                               342000
replay_pool/size                         342000
trainer/alpha                                 0.063647
trainer/alpha_loss                            0.00877655
trainer/entropy                              -6.00319
trainer/qf_loss                               6.24506
trainer/state_noise                           0.005
trainer/policy_loss                        -145.336
trainer/policy_loss_without_entropy         147.012
trainer/entropy_penalty                      -0.382085
trainer/entropy_percentage                   -0.002599
trainer/Q1Pred Mean                         145.889
trainer/Q1Pred Std                           53.3864
trainer/Q1Pred Max                          249.593
trainer/Q1Pred Min                          -14.1396
trainer/Q2Pred Mean                         146.663
trainer/Q2Pred Std                           53.6066
trainer/Q2Pred Max                          250.596
trainer/Q2Pred Min                           -7.5576
trainer/QTargetWithReg Mean                 146.056
trainer/QTargetWithReg Std                   53.6732
trainer/QTargetWithReg Max                  251.595
trainer/QTargetWithReg Min                   -0.991925
trainer/PolicyLossWithoutReg Mean           147.012
trainer/PolicyLossWithoutReg Std             53.1874
trainer/PolicyLossWithoutReg Max            249.228
trainer/PolicyLossWithoutReg Min            -21.3879
trainer/gradient_norm                       258.882
trainer/gradient_penalty                     -1.29441
trainer/gradient_percentage                  -0.00880479
exploration/num steps total              342000
exploration/num paths total                1498
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59981
exploration/Rewards Std                       1.32069
exploration/Rewards Max                      10.195
exploration/Rewards Min                      -0.725011
exploration/Returns Mean                   4599.81
exploration/Returns Std                       0
exploration/Returns Max                    4599.81
exploration/Returns Min                    4599.81
exploration/Num Paths                         1
exploration/Average Returns                4599.81
evaluation_0/num steps total                  2.62744e+06
evaluation_0/num paths total              10214
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.32996
evaluation_0/Rewards Std                      1.37787
evaluation_0/Rewards Max                     10.962
evaluation_0/Rewards Min                     -0.477773
evaluation_0/Returns Mean                  4329.96
evaluation_0/Returns Std                    370.786
evaluation_0/Returns Max                   4627.61
evaluation_0/Returns Min                   3591.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4329.96
time/epoch (s)                                0
time/total (s)                             6867.98
Epoch                                       337
---------------------------------------  ----------------
2022-11-16 12:40:30.577189 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 338 finished
---------------------------------------  ----------------
epoch                                       338
total_step                               343000
replay_pool/size                         343000
trainer/alpha                                 0.0624283
trainer/alpha_loss                            0.430943
trainer/entropy                              -6.15537
trainer/qf_loss                               5.73042
trainer/state_noise                           0.005
trainer/policy_loss                        -150.5
trainer/policy_loss_without_entropy         152.14
trainer/entropy_penalty                      -0.384269
trainer/entropy_percentage                   -0.00252576
trainer/Q1Pred Mean                         151.168
trainer/Q1Pred Std                           51.2081
trainer/Q1Pred Max                          243.781
trainer/Q1Pred Min                          -33.3985
trainer/Q2Pred Mean                         151.281
trainer/Q2Pred Std                           50.9692
trainer/Q2Pred Max                          242.425
trainer/Q2Pred Min                          -35.8773
trainer/QTargetWithReg Mean                 151.174
trainer/QTargetWithReg Std                   50.7204
trainer/QTargetWithReg Max                  242.727
trainer/QTargetWithReg Min                  -28.9342
trainer/PolicyLossWithoutReg Mean           152.14
trainer/PolicyLossWithoutReg Std             50.3863
trainer/PolicyLossWithoutReg Max            242.494
trainer/PolicyLossWithoutReg Min            -22.2272
trainer/gradient_norm                       251.228
trainer/gradient_penalty                     -1.25614
trainer/gradient_percentage                  -0.00825647
exploration/num steps total              343000
exploration/num paths total                1499
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.18515
exploration/Rewards Std                       1.34211
exploration/Rewards Max                      10.4762
exploration/Rewards Min                      -0.523249
exploration/Returns Mean                   4185.15
exploration/Returns Std                       0
exploration/Returns Max                    4185.15
exploration/Returns Min                    4185.15
exploration/Num Paths                         1
exploration/Average Returns                4185.15
evaluation_0/num steps total                  2.63544e+06
evaluation_0/num paths total              10222
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.52483
evaluation_0/Rewards Std                      1.39457
evaluation_0/Rewards Max                     10.835
evaluation_0/Rewards Min                     -0.514899
evaluation_0/Returns Mean                  4524.83
evaluation_0/Returns Std                    211.349
evaluation_0/Returns Max                   4728.88
evaluation_0/Returns Min                   4180.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4524.83
time/epoch (s)                                0
time/total (s)                             6884.46
Epoch                                       338
---------------------------------------  ----------------
2022-11-16 12:40:46.517333 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 339 finished
---------------------------------------  ----------------
epoch                                       339
total_step                               344000
replay_pool/size                         344000
trainer/alpha                                 0.0613058
trainer/alpha_loss                           -1.32912
trainer/entropy                              -5.52392
trainer/qf_loss                               7.95256
trainer/state_noise                           0.005
trainer/policy_loss                        -150.364
trainer/policy_loss_without_entropy         152.075
trainer/entropy_penalty                      -0.338648
trainer/entropy_percentage                   -0.00222685
trainer/Q1Pred Mean                         151.21
trainer/Q1Pred Std                           47.6156
trainer/Q1Pred Max                          236.973
trainer/Q1Pred Min                            8.85152
trainer/Q2Pred Mean                         151.209
trainer/Q2Pred Std                           47.616
trainer/Q2Pred Max                          237.093
trainer/Q2Pred Min                            6.26347
trainer/QTargetWithReg Mean                 151.506
trainer/QTargetWithReg Std                   47.7744
trainer/QTargetWithReg Max                  238.584
trainer/QTargetWithReg Min                    6.55088
trainer/PolicyLossWithoutReg Mean           152.075
trainer/PolicyLossWithoutReg Std             46.6036
trainer/PolicyLossWithoutReg Max            237.114
trainer/PolicyLossWithoutReg Min              6.82303
trainer/gradient_norm                       274.415
trainer/gradient_penalty                     -1.37207
trainer/gradient_percentage                  -0.00902235
exploration/num steps total              344000
exploration/num paths total                1500
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61006
exploration/Rewards Std                       1.3734
exploration/Rewards Max                      11.0925
exploration/Rewards Min                      -0.524891
exploration/Returns Mean                   4610.06
exploration/Returns Std                       0
exploration/Returns Max                    4610.06
exploration/Returns Min                    4610.06
exploration/Num Paths                         1
exploration/Average Returns                4610.06
evaluation_0/num steps total                  2.64344e+06
evaluation_0/num paths total              10230
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.00698
evaluation_0/Rewards Std                      1.35128
evaluation_0/Rewards Max                     10.5407
evaluation_0/Rewards Min                     -0.656961
evaluation_0/Returns Mean                  4006.98
evaluation_0/Returns Std                    491.192
evaluation_0/Returns Max                   4517.07
evaluation_0/Returns Min                   3374.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4006.98
time/epoch (s)                                0
time/total (s)                             6900.4
Epoch                                       339
---------------------------------------  ----------------
2022-11-16 12:41:02.550017 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 340 finished
---------------------------------------  ----------------
epoch                                       340
total_step                               345000
replay_pool/size                         345000
trainer/alpha                                 0.0623448
trainer/alpha_loss                           -0.144738
trainer/entropy                              -5.94784
trainer/qf_loss                              16.2168
trainer/state_noise                           0.005
trainer/policy_loss                        -147.746
trainer/policy_loss_without_entropy         149.445
trainer/entropy_penalty                      -0.370817
trainer/entropy_percentage                   -0.0024813
trainer/Q1Pred Mean                         148.821
trainer/Q1Pred Std                           48.889
trainer/Q1Pred Max                          246.77
trainer/Q1Pred Min                           10.628
trainer/Q2Pred Mean                         148.568
trainer/Q2Pred Std                           49.2829
trainer/Q2Pred Max                          245.699
trainer/Q2Pred Min                           14.2507
trainer/QTargetWithReg Mean                 148.953
trainer/QTargetWithReg Std                   49.5629
trainer/QTargetWithReg Max                  246.871
trainer/QTargetWithReg Min                    4.04947
trainer/PolicyLossWithoutReg Mean           149.445
trainer/PolicyLossWithoutReg Std             48.7492
trainer/PolicyLossWithoutReg Max            245.903
trainer/PolicyLossWithoutReg Min             16.1593
trainer/gradient_norm                       265.514
trainer/gradient_penalty                     -1.32757
trainer/gradient_percentage                  -0.00888335
exploration/num steps total              345000
exploration/num paths total                1501
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.62167
exploration/Rewards Std                       1.30794
exploration/Rewards Max                      10.1935
exploration/Rewards Min                      -0.61752
exploration/Returns Mean                   4621.67
exploration/Returns Std                       0
exploration/Returns Max                    4621.67
exploration/Returns Min                    4621.67
exploration/Num Paths                         1
exploration/Average Returns                4621.67
evaluation_0/num steps total                  2.65144e+06
evaluation_0/num paths total              10238
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.37987
evaluation_0/Rewards Std                      1.19209
evaluation_0/Rewards Max                     10.3047
evaluation_0/Rewards Min                     -0.598115
evaluation_0/Returns Mean                  4379.87
evaluation_0/Returns Std                     55.6973
evaluation_0/Returns Max                   4467.85
evaluation_0/Returns Min                   4316.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4379.87
time/epoch (s)                                0
time/total (s)                             6916.43
Epoch                                       340
---------------------------------------  ----------------
2022-11-16 12:41:18.700278 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 341 finished
---------------------------------------  ----------------
epoch                                       341
total_step                               346000
replay_pool/size                         346000
trainer/alpha                                 0.0635744
trainer/alpha_loss                            0.218097
trainer/entropy                              -6.07915
trainer/qf_loss                              10.0841
trainer/state_noise                           0.005
trainer/policy_loss                        -147.948
trainer/policy_loss_without_entropy         149.678
trainer/entropy_penalty                      -0.386478
trainer/entropy_percentage                   -0.00258207
trainer/Q1Pred Mean                         149.451
trainer/Q1Pred Std                           54.5879
trainer/Q1Pred Max                          239.428
trainer/Q1Pred Min                           -7.29358
trainer/Q2Pred Mean                         148.718
trainer/Q2Pred Std                           54.6042
trainer/Q2Pred Max                          235.005
trainer/Q2Pred Min                           -9.54096
trainer/QTargetWithReg Mean                 148.283
trainer/QTargetWithReg Std                   54.9567
trainer/QTargetWithReg Max                  237.199
trainer/QTargetWithReg Min                   -9.83235
trainer/PolicyLossWithoutReg Mean           149.678
trainer/PolicyLossWithoutReg Std             53.673
trainer/PolicyLossWithoutReg Max            235.864
trainer/PolicyLossWithoutReg Min             -5.81802
trainer/gradient_norm                       268.61
trainer/gradient_penalty                     -1.34305
trainer/gradient_percentage                  -0.00897295
exploration/num steps total              346000
exploration/num paths total                1502
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58708
exploration/Rewards Std                       1.32505
exploration/Rewards Max                      10.3007
exploration/Rewards Min                      -0.635377
exploration/Returns Mean                   4587.08
exploration/Returns Std                       0
exploration/Returns Max                    4587.08
exploration/Returns Min                    4587.08
exploration/Num Paths                         1
exploration/Average Returns                4587.08
evaluation_0/num steps total                  2.65944e+06
evaluation_0/num paths total              10246
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.5724
evaluation_0/Rewards Std                      1.2835
evaluation_0/Rewards Max                     10.4586
evaluation_0/Rewards Min                     -0.534016
evaluation_0/Returns Mean                  4572.4
evaluation_0/Returns Std                     30.2335
evaluation_0/Returns Max                   4606.85
evaluation_0/Returns Min                   4516.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4572.4
time/epoch (s)                                0
time/total (s)                             6932.58
Epoch                                       341
---------------------------------------  ----------------
2022-11-16 12:41:34.445165 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 342 finished
---------------------------------------  ----------------
epoch                                       342
total_step                               347000
replay_pool/size                         347000
trainer/alpha                                 0.0629081
trainer/alpha_loss                            0.721232
trainer/entropy                              -6.26074
trainer/qf_loss                               9.08107
trainer/state_noise                           0.005
trainer/policy_loss                        -153.454
trainer/policy_loss_without_entropy         155.195
trainer/entropy_penalty                      -0.393851
trainer/entropy_percentage                   -0.00253779
trainer/Q1Pred Mean                         154.85
trainer/Q1Pred Std                           50.6732
trainer/Q1Pred Max                          243.318
trainer/Q1Pred Min                          -33.5198
trainer/Q2Pred Mean                         154.783
trainer/Q2Pred Std                           50.7066
trainer/Q2Pred Max                          242.567
trainer/Q2Pred Min                          -31.1061
trainer/QTargetWithReg Mean                 154.359
trainer/QTargetWithReg Std                   50.4088
trainer/QTargetWithReg Max                  242.157
trainer/QTargetWithReg Min                  -42.0947
trainer/PolicyLossWithoutReg Mean           155.195
trainer/PolicyLossWithoutReg Std             50.031
trainer/PolicyLossWithoutReg Max            242.586
trainer/PolicyLossWithoutReg Min            -30.9385
trainer/gradient_norm                       269.396
trainer/gradient_penalty                     -1.34698
trainer/gradient_percentage                  -0.00867928
exploration/num steps total              347000
exploration/num paths total                1503
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.4681
exploration/Rewards Std                       1.27318
exploration/Rewards Max                      10.1094
exploration/Rewards Min                      -0.595929
exploration/Returns Mean                   4468.1
exploration/Returns Std                       0
exploration/Returns Max                    4468.1
exploration/Returns Min                    4468.1
exploration/Num Paths                         1
exploration/Average Returns                4468.1
evaluation_0/num steps total                  2.66744e+06
evaluation_0/num paths total              10254
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77209
evaluation_0/Rewards Std                      1.40274
evaluation_0/Rewards Max                     11.1936
evaluation_0/Rewards Min                     -0.45876
evaluation_0/Returns Mean                  4772.09
evaluation_0/Returns Std                     48.1461
evaluation_0/Returns Max                   4858.52
evaluation_0/Returns Min                   4692.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4772.09
time/epoch (s)                                0
time/total (s)                             6948.32
Epoch                                       342
---------------------------------------  ----------------
2022-11-16 12:41:50.905161 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 343 finished
---------------------------------------  ----------------
epoch                                       343
total_step                               348000
replay_pool/size                         348000
trainer/alpha                                 0.0631566
trainer/alpha_loss                            0.524939
trainer/entropy                              -6.19003
trainer/qf_loss                               6.63431
trainer/state_noise                           0.005
trainer/policy_loss                        -150.533
trainer/policy_loss_without_entropy         152.253
trainer/entropy_penalty                      -0.390941
trainer/entropy_percentage                   -0.00256771
trainer/Q1Pred Mean                         151.532
trainer/Q1Pred Std                           51.9438
trainer/Q1Pred Max                          246.461
trainer/Q1Pred Min                            2.4693
trainer/Q2Pred Mean                         150.893
trainer/Q2Pred Std                           52.2709
trainer/Q2Pred Max                          246.367
trainer/Q2Pred Min                           -2.91201
trainer/QTargetWithReg Mean                 151.257
trainer/QTargetWithReg Std                   51.9908
trainer/QTargetWithReg Max                  246.265
trainer/QTargetWithReg Min                   -5.6576
trainer/PolicyLossWithoutReg Mean           152.253
trainer/PolicyLossWithoutReg Std             51.5286
trainer/PolicyLossWithoutReg Max            246.852
trainer/PolicyLossWithoutReg Min              1.60339
trainer/gradient_norm                       265.875
trainer/gradient_penalty                     -1.32937
trainer/gradient_percentage                  -0.00873135
exploration/num steps total              348000
exploration/num paths total                1504
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.54906
exploration/Rewards Std                       1.30534
exploration/Rewards Max                      10.9338
exploration/Rewards Min                      -0.473866
exploration/Returns Mean                   4549.06
exploration/Returns Std                       0
exploration/Returns Max                    4549.06
exploration/Returns Min                    4549.06
exploration/Num Paths                         1
exploration/Average Returns                4549.06
evaluation_0/num steps total                  2.67544e+06
evaluation_0/num paths total              10262
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75081
evaluation_0/Rewards Std                      1.36168
evaluation_0/Rewards Max                     11.0434
evaluation_0/Rewards Min                     -0.481158
evaluation_0/Returns Mean                  4750.81
evaluation_0/Returns Std                     62.8911
evaluation_0/Returns Max                   4880.22
evaluation_0/Returns Min                   4675.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4750.81
time/epoch (s)                                0
time/total (s)                             6964.78
Epoch                                       343
---------------------------------------  ----------------
2022-11-16 12:42:06.790971 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 344 finished
---------------------------------------  ----------------
epoch                                       344
total_step                               349000
replay_pool/size                         349000
trainer/alpha                                 0.0618962
trainer/alpha_loss                            0.327853
trainer/entropy                              -6.11784
trainer/qf_loss                               6.94609
trainer/state_noise                           0.005
trainer/policy_loss                        -154.206
trainer/policy_loss_without_entropy         155.913
trainer/entropy_penalty                      -0.378671
trainer/entropy_percentage                   -0.00242873
trainer/Q1Pred Mean                         155.114
trainer/Q1Pred Std                           53.1186
trainer/Q1Pred Max                          239.331
trainer/Q1Pred Min                           -7.76941
trainer/Q2Pred Mean                         154.815
trainer/Q2Pred Std                           52.478
trainer/Q2Pred Max                          239.437
trainer/Q2Pred Min                           -5.81281
trainer/QTargetWithReg Mean                 154.797
trainer/QTargetWithReg Std                   52.541
trainer/QTargetWithReg Max                  238.482
trainer/QTargetWithReg Min                   -0.0839682
trainer/PolicyLossWithoutReg Mean           155.913
trainer/PolicyLossWithoutReg Std             51.2779
trainer/PolicyLossWithoutReg Max            239.437
trainer/PolicyLossWithoutReg Min              6.93659
trainer/gradient_norm                       265.703
trainer/gradient_penalty                     -1.32852
trainer/gradient_percentage                  -0.00852086
exploration/num steps total              349000
exploration/num paths total                1505
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51042
exploration/Rewards Std                       1.29923
exploration/Rewards Max                      10.2479
exploration/Rewards Min                      -0.532244
exploration/Returns Mean                   4510.42
exploration/Returns Std                       0
exploration/Returns Max                    4510.42
exploration/Returns Min                    4510.42
exploration/Num Paths                         1
exploration/Average Returns                4510.42
evaluation_0/num steps total                  2.68344e+06
evaluation_0/num paths total              10270
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59002
evaluation_0/Rewards Std                      1.28289
evaluation_0/Rewards Max                     10.957
evaluation_0/Rewards Min                     -0.435815
evaluation_0/Returns Mean                  4590.02
evaluation_0/Returns Std                     49.9634
evaluation_0/Returns Max                   4641.18
evaluation_0/Returns Min                   4501.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4590.02
time/epoch (s)                                0
time/total (s)                             6980.67
Epoch                                       344
---------------------------------------  ----------------
2022-11-16 12:42:23.086355 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 345 finished
---------------------------------------  ----------------
epoch                                       345
total_step                               350000
replay_pool/size                         350000
trainer/alpha                                 0.0630043
trainer/alpha_loss                            0.0380807
trainer/entropy                              -6.01377
trainer/qf_loss                               7.48417
trainer/state_noise                           0.005
trainer/policy_loss                        -148.564
trainer/policy_loss_without_entropy         150.292
trainer/entropy_penalty                      -0.378894
trainer/entropy_percentage                   -0.00252105
trainer/Q1Pred Mean                         149.055
trainer/Q1Pred Std                           49.3027
trainer/Q1Pred Max                          234.273
trainer/Q1Pred Min                            4.56132
trainer/Q2Pred Mean                         148.986
trainer/Q2Pred Std                           49.0943
trainer/Q2Pred Max                          234.319
trainer/Q2Pred Min                            6.35201
trainer/QTargetWithReg Mean                 149.762
trainer/QTargetWithReg Std                   49.2371
trainer/QTargetWithReg Max                  235.122
trainer/QTargetWithReg Min                    4.60821
trainer/PolicyLossWithoutReg Mean           150.292
trainer/PolicyLossWithoutReg Std             48.9733
trainer/PolicyLossWithoutReg Max            231.104
trainer/PolicyLossWithoutReg Min              3.46724
trainer/gradient_norm                       269.924
trainer/gradient_penalty                     -1.34962
trainer/gradient_percentage                  -0.00897997
exploration/num steps total              350000
exploration/num paths total                1506
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59028
exploration/Rewards Std                       1.37869
exploration/Rewards Max                      11.0206
exploration/Rewards Min                      -0.479522
exploration/Returns Mean                   4590.28
exploration/Returns Std                       0
exploration/Returns Max                    4590.28
exploration/Returns Min                    4590.28
exploration/Num Paths                         1
exploration/Average Returns                4590.28
evaluation_0/num steps total                  2.69144e+06
evaluation_0/num paths total              10278
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6321
evaluation_0/Rewards Std                      1.39795
evaluation_0/Rewards Max                     10.783
evaluation_0/Rewards Min                     -0.584883
evaluation_0/Returns Mean                  4632.1
evaluation_0/Returns Std                     51.8857
evaluation_0/Returns Max                   4706.45
evaluation_0/Returns Min                   4569.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4632.1
time/epoch (s)                                0
time/total (s)                             6996.96
Epoch                                       345
---------------------------------------  ----------------
2022-11-16 12:42:39.028156 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 346 finished
---------------------------------------  ----------------
epoch                                       346
total_step                               351000
replay_pool/size                         351000
trainer/alpha                                 0.0624767
trainer/alpha_loss                            1.19765
trainer/entropy                              -6.43188
trainer/qf_loss                               9.06427
trainer/state_noise                           0.005
trainer/policy_loss                        -153.427
trainer/policy_loss_without_entropy         155.153
trainer/entropy_penalty                      -0.401842
trainer/entropy_percentage                   -0.00258998
trainer/Q1Pred Mean                         154.021
trainer/Q1Pred Std                           52.5006
trainer/Q1Pred Max                          245.465
trainer/Q1Pred Min                          -24.937
trainer/Q2Pred Mean                         154.295
trainer/Q2Pred Std                           52.6324
trainer/Q2Pred Max                          248.115
trainer/Q2Pred Min                          -28.8988
trainer/QTargetWithReg Mean                 154.455
trainer/QTargetWithReg Std                   52.5451
trainer/QTargetWithReg Max                  248.24
trainer/QTargetWithReg Min                  -25.9697
trainer/PolicyLossWithoutReg Mean           155.153
trainer/PolicyLossWithoutReg Std             52.0639
trainer/PolicyLossWithoutReg Max            245.779
trainer/PolicyLossWithoutReg Min            -21.7358
trainer/gradient_norm                       264.743
trainer/gradient_penalty                     -1.32371
trainer/gradient_percentage                  -0.00853166
exploration/num steps total              351000
exploration/num paths total                1507
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.32944
exploration/Rewards Std                       1.32348
exploration/Rewards Max                      11.0163
exploration/Rewards Min                      -0.495167
exploration/Returns Mean                   4329.44
exploration/Returns Std                       0
exploration/Returns Max                    4329.44
exploration/Returns Min                    4329.44
exploration/Num Paths                         1
exploration/Average Returns                4329.44
evaluation_0/num steps total                  2.69944e+06
evaluation_0/num paths total              10286
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.43086
evaluation_0/Rewards Std                      1.31453
evaluation_0/Rewards Max                     10.8603
evaluation_0/Rewards Min                     -0.513878
evaluation_0/Returns Mean                  4430.86
evaluation_0/Returns Std                     39.8523
evaluation_0/Returns Max                   4502.62
evaluation_0/Returns Min                   4372.6
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4430.86
time/epoch (s)                                0
time/total (s)                             7012.9
Epoch                                       346
---------------------------------------  ----------------
2022-11-16 12:42:54.869760 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 347 finished
---------------------------------------  ----------------
epoch                                       347
total_step                               352000
replay_pool/size                         352000
trainer/alpha                                 0.0626631
trainer/alpha_loss                           -1.3785
trainer/entropy                              -5.50232
trainer/qf_loss                               5.76501
trainer/state_noise                           0.005
trainer/policy_loss                        -152.1
trainer/policy_loss_without_entropy         153.74
trainer/entropy_penalty                      -0.344792
trainer/entropy_percentage                   -0.00224269
trainer/Q1Pred Mean                         152.699
trainer/Q1Pred Std                           53.7444
trainer/Q1Pred Max                          248.575
trainer/Q1Pred Min                            4.61067
trainer/Q2Pred Mean                         153.37
trainer/Q2Pred Std                           54.1488
trainer/Q2Pred Max                          249.733
trainer/Q2Pred Min                            2.10718
trainer/QTargetWithReg Mean                 152.65
trainer/QTargetWithReg Std                   53.9223
trainer/QTargetWithReg Max                  249.673
trainer/QTargetWithReg Min                    4.68538
trainer/PolicyLossWithoutReg Mean           153.74
trainer/PolicyLossWithoutReg Std             53.5314
trainer/PolicyLossWithoutReg Max            249.134
trainer/PolicyLossWithoutReg Min              4.68839
trainer/gradient_norm                       259.152
trainer/gradient_penalty                     -1.29576
trainer/gradient_percentage                  -0.00842823
exploration/num steps total              352000
exploration/num paths total                1508
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58177
exploration/Rewards Std                       1.32607
exploration/Rewards Max                      10.7116
exploration/Rewards Min                      -0.441852
exploration/Returns Mean                   4581.77
exploration/Returns Std                       0
exploration/Returns Max                    4581.77
exploration/Returns Min                    4581.77
exploration/Num Paths                         1
exploration/Average Returns                4581.77
evaluation_0/num steps total                  2.70744e+06
evaluation_0/num paths total              10294
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53117
evaluation_0/Rewards Std                      1.23759
evaluation_0/Rewards Max                     11.1414
evaluation_0/Rewards Min                     -0.614905
evaluation_0/Returns Mean                  4531.17
evaluation_0/Returns Std                    108.381
evaluation_0/Returns Max                   4691.17
evaluation_0/Returns Min                   4413.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4531.17
time/epoch (s)                                0
time/total (s)                             7028.74
Epoch                                       347
---------------------------------------  ----------------
2022-11-16 12:43:11.385105 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 348 finished
---------------------------------------  ----------------
epoch                                       348
total_step                               353000
replay_pool/size                         353000
trainer/alpha                                 0.0626136
trainer/alpha_loss                            0.896988
trainer/entropy                              -6.32373
trainer/qf_loss                               8.87878
trainer/state_noise                           0.005
trainer/policy_loss                        -148.308
trainer/policy_loss_without_entropy         150.041
trainer/entropy_penalty                      -0.395951
trainer/entropy_percentage                   -0.00263895
trainer/Q1Pred Mean                         149.581
trainer/Q1Pred Std                           57.3088
trainer/Q1Pred Max                          249.558
trainer/Q1Pred Min                          -23.4209
trainer/Q2Pred Mean                         149.39
trainer/Q2Pred Std                           56.7944
trainer/Q2Pred Max                          248.193
trainer/Q2Pred Min                            0.991127
trainer/QTargetWithReg Mean                 149.874
trainer/QTargetWithReg Std                   57.201
trainer/QTargetWithReg Max                  252.496
trainer/QTargetWithReg Min                    0.287903
trainer/PolicyLossWithoutReg Mean           150.041
trainer/PolicyLossWithoutReg Std             55.9567
trainer/PolicyLossWithoutReg Max            248.317
trainer/PolicyLossWithoutReg Min              3.52307
trainer/gradient_norm                       267.528
trainer/gradient_penalty                     -1.33764
trainer/gradient_percentage                  -0.00891517
exploration/num steps total              353000
exploration/num paths total                1509
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.10839
exploration/Rewards Std                       1.25626
exploration/Rewards Max                       9.39255
exploration/Rewards Min                      -0.568055
exploration/Returns Mean                   4108.39
exploration/Returns Std                       0
exploration/Returns Max                    4108.39
exploration/Returns Min                    4108.39
exploration/Num Paths                         1
exploration/Average Returns                4108.39
evaluation_0/num steps total                  2.71544e+06
evaluation_0/num paths total              10302
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57372
evaluation_0/Rewards Std                      1.25235
evaluation_0/Rewards Max                     10.9852
evaluation_0/Rewards Min                     -0.538698
evaluation_0/Returns Mean                  4573.72
evaluation_0/Returns Std                     71.6751
evaluation_0/Returns Max                   4691.51
evaluation_0/Returns Min                   4475.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4573.72
time/epoch (s)                                0
time/total (s)                             7045.26
Epoch                                       348
---------------------------------------  ----------------
2022-11-16 12:43:28.830410 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 349 finished
---------------------------------------  ----------------
epoch                                       349
total_step                               354000
replay_pool/size                         354000
trainer/alpha                                 0.0627349
trainer/alpha_loss                           -0.139822
trainer/entropy                              -5.9495
trainer/qf_loss                               7.96795
trainer/state_noise                           0.005
trainer/policy_loss                        -149.749
trainer/policy_loss_without_entropy         151.502
trainer/entropy_penalty                      -0.373241
trainer/entropy_percentage                   -0.00246361
trainer/Q1Pred Mean                         151.061
trainer/Q1Pred Std                           53.2096
trainer/Q1Pred Max                          258.634
trainer/Q1Pred Min                          -23.1228
trainer/Q2Pred Mean                         150.811
trainer/Q2Pred Std                           53.2026
trainer/Q2Pred Max                          254.792
trainer/Q2Pred Min                          -25.254
trainer/QTargetWithReg Mean                 150.829
trainer/QTargetWithReg Std                   53.2224
trainer/QTargetWithReg Max                  258.204
trainer/QTargetWithReg Min                  -24.8013
trainer/PolicyLossWithoutReg Mean           151.502
trainer/PolicyLossWithoutReg Std             52.3497
trainer/PolicyLossWithoutReg Max            256.095
trainer/PolicyLossWithoutReg Min            -16.4584
trainer/gradient_norm                       275.979
trainer/gradient_penalty                     -1.37989
trainer/gradient_percentage                  -0.00910811
exploration/num steps total              354000
exploration/num paths total                1510
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56284
exploration/Rewards Std                       1.27044
exploration/Rewards Max                      10.5349
exploration/Rewards Min                      -0.589271
exploration/Returns Mean                   4562.84
exploration/Returns Std                       0
exploration/Returns Max                    4562.84
exploration/Returns Min                    4562.84
exploration/Num Paths                         1
exploration/Average Returns                4562.84
evaluation_0/num steps total                  2.72294e+06
evaluation_0/num paths total              10310
evaluation_0/path length Mean               937
evaluation_0/path length Std                127.268
evaluation_0/path length Max               1000
evaluation_0/path length Min                617
evaluation_0/Rewards Mean                     4.81901
evaluation_0/Rewards Std                      1.42245
evaluation_0/Rewards Max                     11.6036
evaluation_0/Rewards Min                     -0.520779
evaluation_0/Returns Mean                  4515.41
evaluation_0/Returns Std                    604.807
evaluation_0/Returns Max                   4854.88
evaluation_0/Returns Min                   2975.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4515.41
time/epoch (s)                                0
time/total (s)                             7062.7
Epoch                                       349
---------------------------------------  ----------------
2022-11-16 12:43:45.275576 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 350 finished
---------------------------------------  ----------------
epoch                                       350
total_step                               355000
replay_pool/size                         355000
trainer/alpha                                 0.0626147
trainer/alpha_loss                            0.256421
trainer/entropy                              -6.09254
trainer/qf_loss                               6.27761
trainer/state_noise                           0.005
trainer/policy_loss                        -150.272
trainer/policy_loss_without_entropy         151.956
trainer/entropy_penalty                      -0.381482
trainer/entropy_percentage                   -0.00251048
trainer/Q1Pred Mean                         151.492
trainer/Q1Pred Std                           50.3226
trainer/Q1Pred Max                          245.281
trainer/Q1Pred Min                            4.04077
trainer/Q2Pred Mean                         151.339
trainer/Q2Pred Std                           50.3688
trainer/Q2Pred Max                          243.674
trainer/Q2Pred Min                            2.61557
trainer/QTargetWithReg Mean                 151.589
trainer/QTargetWithReg Std                   50.3194
trainer/QTargetWithReg Max                  243.768
trainer/QTargetWithReg Min                    4.36645
trainer/PolicyLossWithoutReg Mean           151.956
trainer/PolicyLossWithoutReg Std             49.8083
trainer/PolicyLossWithoutReg Max            243.951
trainer/PolicyLossWithoutReg Min              3.1634
trainer/gradient_norm                       260.501
trainer/gradient_penalty                     -1.3025
trainer/gradient_percentage                  -0.00857158
exploration/num steps total              355000
exploration/num paths total                1511
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69774
exploration/Rewards Std                       1.32035
exploration/Rewards Max                      10.888
exploration/Rewards Min                      -0.603219
exploration/Returns Mean                   4697.74
exploration/Returns Std                       0
exploration/Returns Max                    4697.74
exploration/Returns Min                    4697.74
exploration/Num Paths                         1
exploration/Average Returns                4697.74
evaluation_0/num steps total                  2.73094e+06
evaluation_0/num paths total              10318
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66534
evaluation_0/Rewards Std                      1.39739
evaluation_0/Rewards Max                     11.4394
evaluation_0/Rewards Min                     -0.612882
evaluation_0/Returns Mean                  4665.34
evaluation_0/Returns Std                    189.012
evaluation_0/Returns Max                   4881.05
evaluation_0/Returns Min                   4264.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4665.34
time/epoch (s)                                0
time/total (s)                             7079.15
Epoch                                       350
---------------------------------------  ----------------
2022-11-16 12:44:02.716569 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 351 finished
---------------------------------------  ---------------
epoch                                       351
total_step                               356000
replay_pool/size                         356000
trainer/alpha                                 0.0620163
trainer/alpha_loss                            1.31879
trainer/entropy                              -6.47429
trainer/qf_loss                               8.5821
trainer/state_noise                           0.005
trainer/policy_loss                        -149.949
trainer/policy_loss_without_entropy         151.748
trainer/entropy_penalty                      -0.401512
trainer/entropy_percentage                   -0.00264591
trainer/Q1Pred Mean                         151.076
trainer/Q1Pred Std                           54.7211
trainer/Q1Pred Max                          253.308
trainer/Q1Pred Min                           -1.82084
trainer/Q2Pred Mean                         150.827
trainer/Q2Pred Std                           55.0452
trainer/Q2Pred Max                          254.174
trainer/Q2Pred Min                            0.250514
trainer/QTargetWithReg Mean                 150.391
trainer/QTargetWithReg Std                   54.7852
trainer/QTargetWithReg Max                  252.201
trainer/QTargetWithReg Min                   -2.63014
trainer/PolicyLossWithoutReg Mean           151.748
trainer/PolicyLossWithoutReg Std             54.2985
trainer/PolicyLossWithoutReg Max            252.281
trainer/PolicyLossWithoutReg Min              2.4872
trainer/gradient_norm                       279.629
trainer/gradient_penalty                     -1.39814
trainer/gradient_percentage                  -0.00921357
exploration/num steps total              356000
exploration/num paths total                1512
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75705
exploration/Rewards Std                       1.34254
exploration/Rewards Max                      10.758
exploration/Rewards Min                      -0.652581
exploration/Returns Mean                   4757.05
exploration/Returns Std                       0
exploration/Returns Max                    4757.05
exploration/Returns Min                    4757.05
exploration/Num Paths                         1
exploration/Average Returns                4757.05
evaluation_0/num steps total                  2.7386e+06
evaluation_0/num paths total              10326
evaluation_0/path length Mean               957.5
evaluation_0/path length Std                 91.5915
evaluation_0/path length Max               1000
evaluation_0/path length Min                721
evaluation_0/Rewards Mean                     4.80974
evaluation_0/Rewards Std                      1.41183
evaluation_0/Rewards Max                     11.6105
evaluation_0/Rewards Min                     -0.462877
evaluation_0/Returns Mean                  4605.32
evaluation_0/Returns Std                    429
evaluation_0/Returns Max                   4886.98
evaluation_0/Returns Min                   3504.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4605.32
time/epoch (s)                                0
time/total (s)                             7096.59
Epoch                                       351
---------------------------------------  ---------------
2022-11-16 12:44:19.033177 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 352 finished
---------------------------------------  ---------------
epoch                                       352
total_step                               357000
replay_pool/size                         357000
trainer/alpha                                 0.0630229
trainer/alpha_loss                           -0.495534
trainer/entropy                              -5.82073
trainer/qf_loss                               7.63032
trainer/state_noise                           0.005
trainer/policy_loss                        -151.119
trainer/policy_loss_without_entropy         152.837
trainer/entropy_penalty                      -0.366839
trainer/entropy_percentage                   -0.00240019
trainer/Q1Pred Mean                         151.852
trainer/Q1Pred Std                           52.1433
trainer/Q1Pred Max                          254.598
trainer/Q1Pred Min                           12.9511
trainer/Q2Pred Mean                         151.325
trainer/Q2Pred Std                           52.0903
trainer/Q2Pred Max                          251.45
trainer/Q2Pred Min                           13.546
trainer/QTargetWithReg Mean                 152.247
trainer/QTargetWithReg Std                   52.1283
trainer/QTargetWithReg Max                  253.824
trainer/QTargetWithReg Min                   11.7086
trainer/PolicyLossWithoutReg Mean           152.837
trainer/PolicyLossWithoutReg Std             51.4038
trainer/PolicyLossWithoutReg Max            252.7
trainer/PolicyLossWithoutReg Min             14.4437
trainer/gradient_norm                       270.324
trainer/gradient_penalty                     -1.35162
trainer/gradient_percentage                  -0.0088435
exploration/num steps total              357000
exploration/num paths total                1513
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7125
exploration/Rewards Std                       1.33637
exploration/Rewards Max                      11.0128
exploration/Rewards Min                      -0.531701
exploration/Returns Mean                   4712.5
exploration/Returns Std                       0
exploration/Returns Max                    4712.5
exploration/Returns Min                    4712.5
exploration/Num Paths                         1
exploration/Average Returns                4712.5
evaluation_0/num steps total                  2.7466e+06
evaluation_0/num paths total              10334
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66999
evaluation_0/Rewards Std                      1.3707
evaluation_0/Rewards Max                     11.3952
evaluation_0/Rewards Min                     -0.571066
evaluation_0/Returns Mean                  4669.99
evaluation_0/Returns Std                     41.1506
evaluation_0/Returns Max                   4725.97
evaluation_0/Returns Min                   4600.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4669.99
time/epoch (s)                                0
time/total (s)                             7112.91
Epoch                                       352
---------------------------------------  ---------------
2022-11-16 12:44:34.969150 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 353 finished
---------------------------------------  ---------------
epoch                                       353
total_step                               358000
replay_pool/size                         358000
trainer/alpha                                 0.0638168
trainer/alpha_loss                           -1.52686
trainer/entropy                              -5.44508
trainer/qf_loss                               6.32139
trainer/state_noise                           0.005
trainer/policy_loss                        -151.884
trainer/policy_loss_without_entropy         153.563
trainer/entropy_penalty                      -0.347488
trainer/entropy_percentage                   -0.00226284
trainer/Q1Pred Mean                         152.815
trainer/Q1Pred Std                           56.3245
trainer/Q1Pred Max                          250.599
trainer/Q1Pred Min                           -9.98411
trainer/Q2Pred Mean                         152.752
trainer/Q2Pred Std                           56.1418
trainer/Q2Pred Max                          248.457
trainer/Q2Pred Min                          -10.3122
trainer/QTargetWithReg Mean                 152.057
trainer/QTargetWithReg Std                   56.135
trainer/QTargetWithReg Max                  247.018
trainer/QTargetWithReg Min                  -12.7436
trainer/PolicyLossWithoutReg Mean           153.563
trainer/PolicyLossWithoutReg Std             54.919
trainer/PolicyLossWithoutReg Max            247.642
trainer/PolicyLossWithoutReg Min             -6.73921
trainer/gradient_norm                       266.147
trainer/gradient_penalty                     -1.33073
trainer/gradient_percentage                  -0.00866574
exploration/num steps total              358000
exploration/num paths total                1514
exploration/path length this epoch Mean     627
exploration/path length this epoch Std        0
exploration/path length this epoch Max      627
exploration/path length this epoch Min      627
exploration/Rewards Mean                      4.70159
exploration/Rewards Std                       1.51075
exploration/Rewards Max                      11.2344
exploration/Rewards Min                      -0.487207
exploration/Returns Mean                   2947.9
exploration/Returns Std                       0
exploration/Returns Max                    2947.9
exploration/Returns Min                    2947.9
exploration/Num Paths                         1
exploration/Average Returns                2947.9
evaluation_0/num steps total                  2.7546e+06
evaluation_0/num paths total              10342
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67586
evaluation_0/Rewards Std                      1.31624
evaluation_0/Rewards Max                     11.3877
evaluation_0/Rewards Min                     -0.625577
evaluation_0/Returns Mean                  4675.86
evaluation_0/Returns Std                     14.0104
evaluation_0/Returns Max                   4699.75
evaluation_0/Returns Min                   4660.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.86
time/epoch (s)                                0
time/total (s)                             7128.84
Epoch                                       353
---------------------------------------  ---------------
2022-11-16 12:44:50.949209 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 354 finished
---------------------------------------  ---------------
epoch                                       354
total_step                               359000
replay_pool/size                         359000
trainer/alpha                                 0.061243
trainer/alpha_loss                           -0.365807
trainer/entropy                              -5.86902
trainer/qf_loss                               7.46652
trainer/state_noise                           0.005
trainer/policy_loss                        -157.289
trainer/policy_loss_without_entropy         158.966
trainer/entropy_penalty                      -0.359436
trainer/entropy_percentage                   -0.00226108
trainer/Q1Pred Mean                         158.551
trainer/Q1Pred Std                           50.2099
trainer/Q1Pred Max                          252.429
trainer/Q1Pred Min                           14.9313
trainer/Q2Pred Mean                         158.286
trainer/Q2Pred Std                           50.3654
trainer/Q2Pred Max                          254.499
trainer/Q2Pred Min                           11.1202
trainer/QTargetWithReg Mean                 158.221
trainer/QTargetWithReg Std                   50.1883
trainer/QTargetWithReg Max                  251.545
trainer/QTargetWithReg Min                    9.34953
trainer/PolicyLossWithoutReg Mean           158.966
trainer/PolicyLossWithoutReg Std             49.8477
trainer/PolicyLossWithoutReg Max            251.525
trainer/PolicyLossWithoutReg Min             15.1495
trainer/gradient_norm                       263.597
trainer/gradient_penalty                     -1.31799
trainer/gradient_percentage                  -0.00829097
exploration/num steps total              359000
exploration/num paths total                1515
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55424
exploration/Rewards Std                       1.36763
exploration/Rewards Max                      10.6536
exploration/Rewards Min                      -0.591167
exploration/Returns Mean                   4554.24
exploration/Returns Std                       0
exploration/Returns Max                    4554.24
exploration/Returns Min                    4554.24
exploration/Num Paths                         1
exploration/Average Returns                4554.24
evaluation_0/num steps total                  2.7626e+06
evaluation_0/num paths total              10350
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.46204
evaluation_0/Rewards Std                      1.41861
evaluation_0/Rewards Max                     10.9521
evaluation_0/Rewards Min                     -0.566631
evaluation_0/Returns Mean                  4462.04
evaluation_0/Returns Std                    155.087
evaluation_0/Returns Max                   4659.01
evaluation_0/Returns Min                   4161.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4462.04
time/epoch (s)                                0
time/total (s)                             7144.82
Epoch                                       354
---------------------------------------  ---------------
2022-11-16 12:45:08.817688 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 355 finished
---------------------------------------  ----------------
epoch                                       355
total_step                               360000
replay_pool/size                         360000
trainer/alpha                                 0.0628042
trainer/alpha_loss                            0.097638
trainer/entropy                              -6.03528
trainer/qf_loss                               6.42913
trainer/state_noise                           0.005
trainer/policy_loss                        -152.968
trainer/policy_loss_without_entropy         154.717
trainer/entropy_penalty                      -0.379041
trainer/entropy_percentage                   -0.00244989
trainer/Q1Pred Mean                         153.749
trainer/Q1Pred Std                           54.9962
trainer/Q1Pred Max                          247.061
trainer/Q1Pred Min                          -17.94
trainer/Q2Pred Mean                         153.9
trainer/Q2Pred Std                           54.6335
trainer/Q2Pred Max                          247.328
trainer/Q2Pred Min                          -14.6398
trainer/QTargetWithReg Mean                 154.643
trainer/QTargetWithReg Std                   54.9402
trainer/QTargetWithReg Max                  248.673
trainer/QTargetWithReg Min                  -14.7082
trainer/PolicyLossWithoutReg Mean           154.717
trainer/PolicyLossWithoutReg Std             54.1755
trainer/PolicyLossWithoutReg Max            247.613
trainer/PolicyLossWithoutReg Min             -9.3665
trainer/gradient_norm                       274.029
trainer/gradient_penalty                     -1.37015
trainer/gradient_percentage                  -0.0088558
exploration/num steps total              360000
exploration/num paths total                1516
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64018
exploration/Rewards Std                       1.33854
exploration/Rewards Max                      10.9729
exploration/Rewards Min                      -0.644222
exploration/Returns Mean                   4640.18
exploration/Returns Std                       0
exploration/Returns Max                    4640.18
exploration/Returns Min                    4640.18
exploration/Num Paths                         1
exploration/Average Returns                4640.18
evaluation_0/num steps total                  2.77001e+06
evaluation_0/num paths total              10358
evaluation_0/path length Mean               927.125
evaluation_0/path length Std                128.627
evaluation_0/path length Max               1000
evaluation_0/path length Min                659
evaluation_0/Rewards Mean                     4.65888
evaluation_0/Rewards Std                      1.46444
evaluation_0/Rewards Max                     11.5908
evaluation_0/Rewards Min                     -0.49961
evaluation_0/Returns Mean                  4319.36
evaluation_0/Returns Std                    527.14
evaluation_0/Returns Max                   4748.73
evaluation_0/Returns Min                   3179.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4319.36
time/epoch (s)                                0
time/total (s)                             7162.69
Epoch                                       355
---------------------------------------  ----------------
2022-11-16 12:45:26.475862 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 356 finished
---------------------------------------  ---------------
epoch                                       356
total_step                               361000
replay_pool/size                         361000
trainer/alpha                                 0.0627991
trainer/alpha_loss                           -0.267404
trainer/entropy                              -5.90339
trainer/qf_loss                               7.48416
trainer/state_noise                           0.005
trainer/policy_loss                        -155.466
trainer/policy_loss_without_entropy         157.196
trainer/entropy_penalty                      -0.370727
trainer/entropy_percentage                   -0.00235838
trainer/Q1Pred Mean                         156.425
trainer/Q1Pred Std                           55.2725
trainer/Q1Pred Max                          245.363
trainer/Q1Pred Min                          -28.9104
trainer/Q2Pred Mean                         156.389
trainer/Q2Pred Std                           55.51
trainer/Q2Pred Max                          245.65
trainer/Q2Pred Min                          -33.9008
trainer/QTargetWithReg Mean                 156.104
trainer/QTargetWithReg Std                   55.2392
trainer/QTargetWithReg Max                  245.044
trainer/QTargetWithReg Min                  -31.1277
trainer/PolicyLossWithoutReg Mean           157.196
trainer/PolicyLossWithoutReg Std             54.3841
trainer/PolicyLossWithoutReg Max            245.688
trainer/PolicyLossWithoutReg Min            -24.8623
trainer/gradient_norm                       271.814
trainer/gradient_penalty                     -1.35907
trainer/gradient_percentage                  -0.00864569
exploration/num steps total              361000
exploration/num paths total                1517
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71235
exploration/Rewards Std                       1.40825
exploration/Rewards Max                      10.7863
exploration/Rewards Min                      -0.472471
exploration/Returns Mean                   4712.35
exploration/Returns Std                       0
exploration/Returns Max                    4712.35
exploration/Returns Min                    4712.35
exploration/Num Paths                         1
exploration/Average Returns                4712.35
evaluation_0/num steps total                  2.7779e+06
evaluation_0/num paths total              10366
evaluation_0/path length Mean               985.5
evaluation_0/path length Std                 38.3634
evaluation_0/path length Max               1000
evaluation_0/path length Min                884
evaluation_0/Rewards Mean                     4.48336
evaluation_0/Rewards Std                      1.38386
evaluation_0/Rewards Max                     11.1847
evaluation_0/Rewards Min                     -0.588161
evaluation_0/Returns Mean                  4418.35
evaluation_0/Returns Std                    160.85
evaluation_0/Returns Max                   4568.84
evaluation_0/Returns Min                   4094.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4418.35
time/epoch (s)                                0
time/total (s)                             7180.35
Epoch                                       356
---------------------------------------  ---------------
2022-11-16 12:45:42.709294 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 357 finished
---------------------------------------  ---------------
epoch                                       357
total_step                               362000
replay_pool/size                         362000
trainer/alpha                                 0.062442
trainer/alpha_loss                           -0.755634
trainer/entropy                              -5.72756
trainer/qf_loss                               5.74091
trainer/state_noise                           0.005
trainer/policy_loss                        -158.925
trainer/policy_loss_without_entropy         160.611
trainer/entropy_penalty                      -0.35764
trainer/entropy_percentage                   -0.00222675
trainer/Q1Pred Mean                         159.274
trainer/Q1Pred Std                           55.3187
trainer/Q1Pred Max                          247.14
trainer/Q1Pred Min                          -28.4378
trainer/Q2Pred Mean                         159.53
trainer/Q2Pred Std                           55.6367
trainer/Q2Pred Max                          250.762
trainer/Q2Pred Min                          -27.0698
trainer/QTargetWithReg Mean                 159.863
trainer/QTargetWithReg Std                   55.8063
trainer/QTargetWithReg Max                  250.985
trainer/QTargetWithReg Min                  -25.2794
trainer/PolicyLossWithoutReg Mean           160.611
trainer/PolicyLossWithoutReg Std             55.289
trainer/PolicyLossWithoutReg Max            248.387
trainer/PolicyLossWithoutReg Min            -29.8146
trainer/gradient_norm                       265.59
trainer/gradient_penalty                     -1.32795
trainer/gradient_percentage                  -0.00826811
exploration/num steps total              362000
exploration/num paths total                1518
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63304
exploration/Rewards Std                       1.36131
exploration/Rewards Max                      10.767
exploration/Rewards Min                      -0.507739
exploration/Returns Mean                   4633.04
exploration/Returns Std                       0
exploration/Returns Max                    4633.04
exploration/Returns Min                    4633.04
exploration/Num Paths                         1
exploration/Average Returns                4633.04
evaluation_0/num steps total                  2.7859e+06
evaluation_0/num paths total              10374
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62127
evaluation_0/Rewards Std                      1.33575
evaluation_0/Rewards Max                     11.3555
evaluation_0/Rewards Min                     -0.475191
evaluation_0/Returns Mean                  4621.27
evaluation_0/Returns Std                     50.7873
evaluation_0/Returns Max                   4678.61
evaluation_0/Returns Min                   4529.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4621.27
time/epoch (s)                                0
time/total (s)                             7196.58
Epoch                                       357
---------------------------------------  ---------------
2022-11-16 12:46:00.146802 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 358 finished
---------------------------------------  ----------------
epoch                                       358
total_step                               363000
replay_pool/size                         363000
trainer/alpha                                 0.0623449
trainer/alpha_loss                            0.308982
trainer/entropy                              -6.11135
trainer/qf_loss                              18.4497
trainer/state_noise                           0.005
trainer/policy_loss                        -159.536
trainer/policy_loss_without_entropy         161.277
trainer/entropy_penalty                      -0.381011
trainer/entropy_percentage                   -0.00236247
trainer/Q1Pred Mean                         160.637
trainer/Q1Pred Std                           54.5979
trainer/Q1Pred Max                          249.499
trainer/Q1Pred Min                           11.9882
trainer/Q2Pred Mean                         160.865
trainer/Q2Pred Std                           54.0577
trainer/Q2Pred Max                          247.703
trainer/Q2Pred Min                            8.87872
trainer/QTargetWithReg Mean                 160.647
trainer/QTargetWithReg Std                   54.9974
trainer/QTargetWithReg Max                  248.01
trainer/QTargetWithReg Min                    1.75675
trainer/PolicyLossWithoutReg Mean           161.277
trainer/PolicyLossWithoutReg Std             53.5716
trainer/PolicyLossWithoutReg Max            247.172
trainer/PolicyLossWithoutReg Min              9.8134
trainer/gradient_norm                       271.958
trainer/gradient_penalty                     -1.35979
trainer/gradient_percentage                  -0.0084314
exploration/num steps total              363000
exploration/num paths total                1519
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69159
exploration/Rewards Std                       1.39718
exploration/Rewards Max                      11.0621
exploration/Rewards Min                      -0.439651
exploration/Returns Mean                   4691.59
exploration/Returns Std                       0
exploration/Returns Max                    4691.59
exploration/Returns Min                    4691.59
exploration/Num Paths                         1
exploration/Average Returns                4691.59
evaluation_0/num steps total                  2.79372e+06
evaluation_0/num paths total              10382
evaluation_0/path length Mean               978
evaluation_0/path length Std                 58.2065
evaluation_0/path length Max               1000
evaluation_0/path length Min                824
evaluation_0/Rewards Mean                     4.67558
evaluation_0/Rewards Std                      1.36848
evaluation_0/Rewards Max                     11.0631
evaluation_0/Rewards Min                     -0.509374
evaluation_0/Returns Mean                  4572.72
evaluation_0/Returns Std                    255.104
evaluation_0/Returns Max                   4727.92
evaluation_0/Returns Min                   3903.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4572.72
time/epoch (s)                                0
time/total (s)                             7214.02
Epoch                                       358
---------------------------------------  ----------------
2022-11-16 12:46:16.701909 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 359 finished
---------------------------------------  ----------------
epoch                                       359
total_step                               364000
replay_pool/size                         364000
trainer/alpha                                 0.0662258
trainer/alpha_loss                           -0.760164
trainer/entropy                              -5.72001
trainer/qf_loss                               6.17167
trainer/state_noise                           0.005
trainer/policy_loss                        -155.697
trainer/policy_loss_without_entropy         157.43
trainer/entropy_penalty                      -0.378812
trainer/entropy_percentage                   -0.00240622
trainer/Q1Pred Mean                         156.301
trainer/Q1Pred Std                           55.7453
trainer/Q1Pred Max                          250.418
trainer/Q1Pred Min                          -10.9631
trainer/Q2Pred Mean                         156.163
trainer/Q2Pred Std                           55.9273
trainer/Q2Pred Max                          249.457
trainer/Q2Pred Min                           -1.59812
trainer/QTargetWithReg Mean                 156.073
trainer/QTargetWithReg Std                   55.6502
trainer/QTargetWithReg Max                  250.081
trainer/QTargetWithReg Min                  -14.4068
trainer/PolicyLossWithoutReg Mean           157.43
trainer/PolicyLossWithoutReg Std             54.7103
trainer/PolicyLossWithoutReg Max            250.014
trainer/PolicyLossWithoutReg Min             -6.76882
trainer/gradient_norm                       270.928
trainer/gradient_penalty                     -1.35464
trainer/gradient_percentage                  -0.0086047
exploration/num steps total              364000
exploration/num paths total                1520
exploration/path length this epoch Mean     626
exploration/path length this epoch Std        0
exploration/path length this epoch Max      626
exploration/path length this epoch Min      626
exploration/Rewards Mean                      4.49237
exploration/Rewards Std                       1.55984
exploration/Rewards Max                      10.5927
exploration/Rewards Min                      -0.538858
exploration/Returns Mean                   2812.23
exploration/Returns Std                       0
exploration/Returns Max                    2812.23
exploration/Returns Min                    2812.23
exploration/Num Paths                         1
exploration/Average Returns                2812.23
evaluation_0/num steps total                  2.80172e+06
evaluation_0/num paths total              10390
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.65701
evaluation_0/Rewards Std                      1.40534
evaluation_0/Rewards Max                     10.9298
evaluation_0/Rewards Min                     -0.444512
evaluation_0/Returns Mean                  4657.01
evaluation_0/Returns Std                    128.887
evaluation_0/Returns Max                   4804.87
evaluation_0/Returns Min                   4504.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4657.01
time/epoch (s)                                0
time/total (s)                             7230.57
Epoch                                       359
---------------------------------------  ----------------
2022-11-16 12:46:32.531797 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 360 finished
---------------------------------------  ----------------
epoch                                       360
total_step                               365000
replay_pool/size                         365000
trainer/alpha                                 0.0647102
trainer/alpha_loss                           -0.309037
trainer/entropy                              -5.88712
trainer/qf_loss                               7.43605
trainer/state_noise                           0.005
trainer/policy_loss                        -157.767
trainer/policy_loss_without_entropy         159.501
trainer/entropy_penalty                      -0.380957
trainer/entropy_percentage                   -0.00238843
trainer/Q1Pred Mean                         159.674
trainer/Q1Pred Std                           56.0604
trainer/Q1Pred Max                          252.997
trainer/Q1Pred Min                           17.3413
trainer/Q2Pred Mean                         159.191
trainer/Q2Pred Std                           56.0362
trainer/Q2Pred Max                          254.042
trainer/Q2Pred Min                           14.6608
trainer/QTargetWithReg Mean                 159.411
trainer/QTargetWithReg Std                   56.3026
trainer/QTargetWithReg Max                  252.403
trainer/QTargetWithReg Min                   16.7219
trainer/PolicyLossWithoutReg Mean           159.501
trainer/PolicyLossWithoutReg Std             55.4586
trainer/PolicyLossWithoutReg Max            251.952
trainer/PolicyLossWithoutReg Min             14.5925
trainer/gradient_norm                       270.648
trainer/gradient_penalty                     -1.35324
trainer/gradient_percentage                  -0.00848424
exploration/num steps total              365000
exploration/num paths total                1521
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.52007
exploration/Rewards Std                       1.313
exploration/Rewards Max                      11.0813
exploration/Rewards Min                      -0.381182
exploration/Returns Mean                   4520.07
exploration/Returns Std                       0
exploration/Returns Max                    4520.07
exploration/Returns Min                    4520.07
exploration/Num Paths                         1
exploration/Average Returns                4520.07
evaluation_0/num steps total                  2.80972e+06
evaluation_0/num paths total              10398
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.60177
evaluation_0/Rewards Std                      1.23898
evaluation_0/Rewards Max                     11.18
evaluation_0/Rewards Min                     -0.523034
evaluation_0/Returns Mean                  4601.77
evaluation_0/Returns Std                     48.5683
evaluation_0/Returns Max                   4668.77
evaluation_0/Returns Min                   4519.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4601.77
time/epoch (s)                                0
time/total (s)                             7246.4
Epoch                                       360
---------------------------------------  ----------------
2022-11-16 12:46:48.940128 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 361 finished
---------------------------------------  ----------------
epoch                                       361
total_step                               366000
replay_pool/size                         366000
trainer/alpha                                 0.0653047
trainer/alpha_loss                            0.029178
trainer/entropy                              -6.01069
trainer/qf_loss                               6.28536
trainer/state_noise                           0.005
trainer/policy_loss                        -157.476
trainer/policy_loss_without_entropy         159.195
trainer/entropy_penalty                      -0.392527
trainer/entropy_percentage                   -0.0024657
trainer/Q1Pred Mean                         158.241
trainer/Q1Pred Std                           50.6116
trainer/Q1Pred Max                          258.996
trainer/Q1Pred Min                           12.0501
trainer/Q2Pred Mean                         158.538
trainer/Q2Pred Std                           50.7879
trainer/Q2Pred Max                          255.518
trainer/Q2Pred Min                           15.8977
trainer/QTargetWithReg Mean                 158.487
trainer/QTargetWithReg Std                   50.6321
trainer/QTargetWithReg Max                  258.392
trainer/QTargetWithReg Min                   13.6962
trainer/PolicyLossWithoutReg Mean           159.195
trainer/PolicyLossWithoutReg Std             50.2061
trainer/PolicyLossWithoutReg Max            255.544
trainer/PolicyLossWithoutReg Min             16.6311
trainer/gradient_norm                       265.199
trainer/gradient_penalty                     -1.32599
trainer/gradient_percentage                  -0.00832937
exploration/num steps total              366000
exploration/num paths total                1522
exploration/path length this epoch Mean     740
exploration/path length this epoch Std        0
exploration/path length this epoch Max      740
exploration/path length this epoch Min      740
exploration/Rewards Mean                      4.42705
exploration/Rewards Std                       1.4595
exploration/Rewards Max                      10.4458
exploration/Rewards Min                      -0.435956
exploration/Returns Mean                   3276.01
exploration/Returns Std                       0
exploration/Returns Max                    3276.01
exploration/Returns Min                    3276.01
exploration/Num Paths                         1
exploration/Average Returns                3276.01
evaluation_0/num steps total                  2.81772e+06
evaluation_0/num paths total              10406
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70412
evaluation_0/Rewards Std                      1.33718
evaluation_0/Rewards Max                     11.1827
evaluation_0/Rewards Min                     -0.523724
evaluation_0/Returns Mean                  4704.12
evaluation_0/Returns Std                     27.6555
evaluation_0/Returns Max                   4739.47
evaluation_0/Returns Min                   4661.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4704.12
time/epoch (s)                                0
time/total (s)                             7262.81
Epoch                                       361
---------------------------------------  ----------------
2022-11-16 12:47:06.404889 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 362 finished
---------------------------------------  ----------------
epoch                                       362
total_step                               367000
replay_pool/size                         367000
trainer/alpha                                 0.0640285
trainer/alpha_loss                           -0.434212
trainer/entropy                              -5.84201
trainer/qf_loss                              10.6118
trainer/state_noise                           0.005
trainer/policy_loss                        -152.644
trainer/policy_loss_without_entropy         154.374
trainer/entropy_penalty                      -0.374055
trainer/entropy_percentage                   -0.00242305
trainer/Q1Pred Mean                         153.762
trainer/Q1Pred Std                           58.2221
trainer/Q1Pred Max                          247.899
trainer/Q1Pred Min                           -7.23944
trainer/Q2Pred Mean                         153.585
trainer/Q2Pred Std                           57.9708
trainer/Q2Pred Max                          247.192
trainer/Q2Pred Min                           -2.81859
trainer/QTargetWithReg Mean                 153.844
trainer/QTargetWithReg Std                   58.2218
trainer/QTargetWithReg Max                  249.218
trainer/QTargetWithReg Min                   -5.83041
trainer/PolicyLossWithoutReg Mean           154.374
trainer/PolicyLossWithoutReg Std             57.5979
trainer/PolicyLossWithoutReg Max            246.924
trainer/PolicyLossWithoutReg Min              2.0458
trainer/gradient_norm                       271.214
trainer/gradient_penalty                     -1.35607
trainer/gradient_percentage                  -0.00878431
exploration/num steps total              367000
exploration/num paths total                1523
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53581
exploration/Rewards Std                       1.35157
exploration/Rewards Max                      10.5398
exploration/Rewards Min                      -0.507271
exploration/Returns Mean                   4535.81
exploration/Returns Std                       0
exploration/Returns Max                    4535.81
exploration/Returns Min                    4535.81
exploration/Num Paths                         1
exploration/Average Returns                4535.81
evaluation_0/num steps total                  2.82538e+06
evaluation_0/num paths total              10414
evaluation_0/path length Mean               957.75
evaluation_0/path length Std                 73.1945
evaluation_0/path length Max               1000
evaluation_0/path length Min                828
evaluation_0/Rewards Mean                     4.78986
evaluation_0/Rewards Std                      1.38644
evaluation_0/Rewards Max                     10.8976
evaluation_0/Rewards Min                     -0.572341
evaluation_0/Returns Mean                  4587.49
evaluation_0/Returns Std                    391.052
evaluation_0/Returns Max                   4948.62
evaluation_0/Returns Min                   3907.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4587.49
time/epoch (s)                                0
time/total (s)                             7280.27
Epoch                                       362
---------------------------------------  ----------------
2022-11-16 12:47:22.734434 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 363 finished
---------------------------------------  ----------------
epoch                                       363
total_step                               368000
replay_pool/size                         368000
trainer/alpha                                 0.0637925
trainer/alpha_loss                            1.16436
trainer/entropy                              -6.42304
trainer/qf_loss                               7.30979
trainer/state_noise                           0.005
trainer/policy_loss                        -159.605
trainer/policy_loss_without_entropy         161.449
trainer/entropy_penalty                      -0.409742
trainer/entropy_percentage                   -0.0025379
trainer/Q1Pred Mean                         160.298
trainer/Q1Pred Std                           54.3098
trainer/Q1Pred Max                          247.56
trainer/Q1Pred Min                            3.41753
trainer/Q2Pred Mean                         160.942
trainer/Q2Pred Std                           54.6154
trainer/Q2Pred Max                          247.332
trainer/Q2Pred Min                            3.54678
trainer/QTargetWithReg Mean                 160.803
trainer/QTargetWithReg Std                   54.4303
trainer/QTargetWithReg Max                  247.811
trainer/QTargetWithReg Min                    1.17303
trainer/PolicyLossWithoutReg Mean           161.449
trainer/PolicyLossWithoutReg Std             54.0195
trainer/PolicyLossWithoutReg Max            249.027
trainer/PolicyLossWithoutReg Min              4.50095
trainer/gradient_norm                       286.992
trainer/gradient_penalty                     -1.43496
trainer/gradient_percentage                  -0.00888799
exploration/num steps total              368000
exploration/num paths total                1524
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6752
exploration/Rewards Std                       1.31508
exploration/Rewards Max                      10.4846
exploration/Rewards Min                      -0.553143
exploration/Returns Mean                   4675.2
exploration/Returns Std                       0
exploration/Returns Max                    4675.2
exploration/Returns Min                    4675.2
exploration/Num Paths                         1
exploration/Average Returns                4675.2
evaluation_0/num steps total                  2.83338e+06
evaluation_0/num paths total              10422
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67516
evaluation_0/Rewards Std                      1.4226
evaluation_0/Rewards Max                     11.7136
evaluation_0/Rewards Min                     -0.661021
evaluation_0/Returns Mean                  4675.16
evaluation_0/Returns Std                    266.724
evaluation_0/Returns Max                   4980.59
evaluation_0/Returns Min                   4174.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.16
time/epoch (s)                                0
time/total (s)                             7296.6
Epoch                                       363
---------------------------------------  ----------------
2022-11-16 12:47:38.651487 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 364 finished
---------------------------------------  ----------------
epoch                                       364
total_step                               369000
replay_pool/size                         369000
trainer/alpha                                 0.0638805
trainer/alpha_loss                           -0.536422
trainer/entropy                              -5.80498
trainer/qf_loss                               8.65344
trainer/state_noise                           0.005
trainer/policy_loss                        -154.021
trainer/policy_loss_without_entropy         155.782
trainer/entropy_penalty                      -0.370825
trainer/entropy_percentage                   -0.00238041
trainer/Q1Pred Mean                         154.851
trainer/Q1Pred Std                           59.0657
trainer/Q1Pred Max                          251.843
trainer/Q1Pred Min                           -5.25671
trainer/Q2Pred Mean                         155.355
trainer/Q2Pred Std                           59.1672
trainer/Q2Pred Max                          253.048
trainer/Q2Pred Min                           -3.88742
trainer/QTargetWithReg Mean                 155.04
trainer/QTargetWithReg Std                   58.9896
trainer/QTargetWithReg Max                  253.761
trainer/QTargetWithReg Min                   -5.57362
trainer/PolicyLossWithoutReg Mean           155.782
trainer/PolicyLossWithoutReg Std             58.2811
trainer/PolicyLossWithoutReg Max            251.805
trainer/PolicyLossWithoutReg Min              1.43051
trainer/gradient_norm                       278.009
trainer/gradient_penalty                     -1.39004
trainer/gradient_percentage                  -0.00892304
exploration/num steps total              369000
exploration/num paths total                1525
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57109
exploration/Rewards Std                       1.28321
exploration/Rewards Max                      10.6119
exploration/Rewards Min                      -0.608487
exploration/Returns Mean                   4571.09
exploration/Returns Std                       0
exploration/Returns Max                    4571.09
exploration/Returns Min                    4571.09
exploration/Num Paths                         1
exploration/Average Returns                4571.09
evaluation_0/num steps total                  2.84138e+06
evaluation_0/num paths total              10430
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71639
evaluation_0/Rewards Std                      1.26891
evaluation_0/Rewards Max                     11.0636
evaluation_0/Rewards Min                     -0.562453
evaluation_0/Returns Mean                  4716.39
evaluation_0/Returns Std                     26.8676
evaluation_0/Returns Max                   4744.12
evaluation_0/Returns Min                   4657.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4716.39
time/epoch (s)                                0
time/total (s)                             7312.52
Epoch                                       364
---------------------------------------  ----------------
2022-11-16 12:47:56.272505 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 365 finished
---------------------------------------  ----------------
epoch                                       365
total_step                               370000
replay_pool/size                         370000
trainer/alpha                                 0.0658824
trainer/alpha_loss                           -1.49331
trainer/entropy                              -5.45098
trainer/qf_loss                               7.86696
trainer/state_noise                           0.005
trainer/policy_loss                        -157.588
trainer/policy_loss_without_entropy         159.356
trainer/entropy_penalty                      -0.359124
trainer/entropy_percentage                   -0.00225359
trainer/Q1Pred Mean                         158.518
trainer/Q1Pred Std                           54.1997
trainer/Q1Pred Max                          251.326
trainer/Q1Pred Min                           10.7911
trainer/Q2Pred Mean                         158.003
trainer/Q2Pred Std                           54.1756
trainer/Q2Pred Max                          250.912
trainer/Q2Pred Min                            6.77877
trainer/QTargetWithReg Mean                 159.014
trainer/QTargetWithReg Std                   54.3642
trainer/QTargetWithReg Max                  252.741
trainer/QTargetWithReg Min                    9.17714
trainer/PolicyLossWithoutReg Mean           159.356
trainer/PolicyLossWithoutReg Std             53.8886
trainer/PolicyLossWithoutReg Max            251.312
trainer/PolicyLossWithoutReg Min             11.6364
trainer/gradient_norm                       281.817
trainer/gradient_penalty                     -1.40909
trainer/gradient_percentage                  -0.00884237
exploration/num steps total              370000
exploration/num paths total                1526
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70689
exploration/Rewards Std                       1.36097
exploration/Rewards Max                      11.0904
exploration/Rewards Min                      -0.564587
exploration/Returns Mean                   4706.89
exploration/Returns Std                       0
exploration/Returns Max                    4706.89
exploration/Returns Min                    4706.89
exploration/Num Paths                         1
exploration/Average Returns                4706.89
evaluation_0/num steps total                  2.84909e+06
evaluation_0/num paths total              10439
evaluation_0/path length Mean               855.778
evaluation_0/path length Std                167.411
evaluation_0/path length Max               1000
evaluation_0/path length Min                602
evaluation_0/Rewards Mean                     4.75069
evaluation_0/Rewards Std                      1.46251
evaluation_0/Rewards Max                     11.2246
evaluation_0/Rewards Min                     -0.5028
evaluation_0/Returns Mean                  4065.53
evaluation_0/Returns Std                    726.247
evaluation_0/Returns Max                   4903.58
evaluation_0/Returns Min                   2907.39
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4065.53
time/epoch (s)                                0
time/total (s)                             7330.14
Epoch                                       365
---------------------------------------  ----------------
2022-11-16 12:48:12.605571 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 366 finished
---------------------------------------  ----------------
epoch                                       366
total_step                               371000
replay_pool/size                         371000
trainer/alpha                                 0.0642389
trainer/alpha_loss                           -1.18231
trainer/entropy                              -5.56929
trainer/qf_loss                               6.72036
trainer/state_noise                           0.005
trainer/policy_loss                        -160.248
trainer/policy_loss_without_entropy         161.988
trainer/entropy_penalty                      -0.357765
trainer/entropy_percentage                   -0.00220859
trainer/Q1Pred Mean                         161.246
trainer/Q1Pred Std                           57.5601
trainer/Q1Pred Max                          257.949
trainer/Q1Pred Min                           -9.32121
trainer/Q2Pred Mean                         161.269
trainer/Q2Pred Std                           57.4571
trainer/Q2Pred Max                          255.947
trainer/Q2Pred Min                           -9.64209
trainer/QTargetWithReg Mean                 161.085
trainer/QTargetWithReg Std                   57.443
trainer/QTargetWithReg Max                  257.804
trainer/QTargetWithReg Min                  -11.6431
trainer/PolicyLossWithoutReg Mean           161.988
trainer/PolicyLossWithoutReg Std             56.9265
trainer/PolicyLossWithoutReg Max            256.275
trainer/PolicyLossWithoutReg Min            -10.1914
trainer/gradient_norm                       276.585
trainer/gradient_penalty                     -1.38292
trainer/gradient_percentage                  -0.00853719
exploration/num steps total              371000
exploration/num paths total                1527
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64804
exploration/Rewards Std                       1.32591
exploration/Rewards Max                      10.7144
exploration/Rewards Min                      -0.487107
exploration/Returns Mean                   4648.04
exploration/Returns Std                       0
exploration/Returns Max                    4648.04
exploration/Returns Min                    4648.04
exploration/Num Paths                         1
exploration/Average Returns                4648.04
evaluation_0/num steps total                  2.85709e+06
evaluation_0/num paths total              10447
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74595
evaluation_0/Rewards Std                      1.38334
evaluation_0/Rewards Max                     11.5306
evaluation_0/Rewards Min                     -0.551712
evaluation_0/Returns Mean                  4745.95
evaluation_0/Returns Std                    141.963
evaluation_0/Returns Max                   4891
evaluation_0/Returns Min                   4512.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4745.95
time/epoch (s)                                0
time/total (s)                             7346.47
Epoch                                       366
---------------------------------------  ----------------
2022-11-16 12:48:30.225731 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 367 finished
---------------------------------------  ----------------
epoch                                       367
total_step                               372000
replay_pool/size                         372000
trainer/alpha                                 0.0645423
trainer/alpha_loss                           -0.274883
trainer/entropy                              -5.89969
trainer/qf_loss                               9.18792
trainer/state_noise                           0.005
trainer/policy_loss                        -158.649
trainer/policy_loss_without_entropy         160.436
trainer/entropy_penalty                      -0.38078
trainer/entropy_percentage                   -0.00237341
trainer/Q1Pred Mean                         159.522
trainer/Q1Pred Std                           55.5049
trainer/Q1Pred Max                          249.182
trainer/Q1Pred Min                          -10.0324
trainer/Q2Pred Mean                         159.951
trainer/Q2Pred Std                           55.1156
trainer/Q2Pred Max                          248.133
trainer/Q2Pred Min                           -7.73957
trainer/QTargetWithReg Mean                 159.655
trainer/QTargetWithReg Std                   55.05
trainer/QTargetWithReg Max                  249.897
trainer/QTargetWithReg Min                   -0.459709
trainer/PolicyLossWithoutReg Mean           160.436
trainer/PolicyLossWithoutReg Std             55.0209
trainer/PolicyLossWithoutReg Max            247.54
trainer/PolicyLossWithoutReg Min             -2.10858
trainer/gradient_norm                       281.244
trainer/gradient_penalty                     -1.40622
trainer/gradient_percentage                  -0.00876501
exploration/num steps total              372000
exploration/num paths total                1528
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75015
exploration/Rewards Std                       1.41159
exploration/Rewards Max                      11.1703
exploration/Rewards Min                      -0.503367
exploration/Returns Mean                   4750.15
exploration/Returns Std                       0
exploration/Returns Max                    4750.15
exploration/Returns Min                    4750.15
exploration/Num Paths                         1
exploration/Average Returns                4750.15
evaluation_0/num steps total                  2.86496e+06
evaluation_0/num paths total              10455
evaluation_0/path length Mean               983.875
evaluation_0/path length Std                 42.6627
evaluation_0/path length Max               1000
evaluation_0/path length Min                871
evaluation_0/Rewards Mean                     4.74153
evaluation_0/Rewards Std                      1.47201
evaluation_0/Rewards Max                     11.3708
evaluation_0/Rewards Min                     -0.538916
evaluation_0/Returns Mean                  4665.08
evaluation_0/Returns Std                    146.398
evaluation_0/Returns Max                   4787.26
evaluation_0/Returns Min                   4295.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4665.08
time/epoch (s)                                0
time/total (s)                             7364.09
Epoch                                       367
---------------------------------------  ----------------
2022-11-16 12:48:46.274064 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 368 finished
---------------------------------------  ----------------
epoch                                       368
total_step                               373000
replay_pool/size                         373000
trainer/alpha                                 0.0650457
trainer/alpha_loss                           -0.162872
trainer/entropy                              -5.9404
trainer/qf_loss                               6.62298
trainer/state_noise                           0.005
trainer/policy_loss                        -158.022
trainer/policy_loss_without_entropy         159.824
trainer/entropy_penalty                      -0.386397
trainer/entropy_percentage                   -0.00241764
trainer/Q1Pred Mean                         158.239
trainer/Q1Pred Std                           52.4037
trainer/Q1Pred Max                          255.432
trainer/Q1Pred Min                           -9.57529
trainer/Q2Pred Mean                         158.399
trainer/Q2Pred Std                           52.5457
trainer/Q2Pred Max                          255.775
trainer/Q2Pred Min                           -2.76036
trainer/QTargetWithReg Mean                 158.615
trainer/QTargetWithReg Std                   52.4076
trainer/QTargetWithReg Max                  257.839
trainer/QTargetWithReg Min                   -5.77839
trainer/PolicyLossWithoutReg Mean           159.824
trainer/PolicyLossWithoutReg Std             51.1247
trainer/PolicyLossWithoutReg Max            255.348
trainer/PolicyLossWithoutReg Min             -2.79985
trainer/gradient_norm                       283.176
trainer/gradient_penalty                     -1.41588
trainer/gradient_percentage                  -0.00885897
exploration/num steps total              373000
exploration/num paths total                1529
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.53771
exploration/Rewards Std                       1.39435
exploration/Rewards Max                      11.0069
exploration/Rewards Min                      -0.498116
exploration/Returns Mean                   4537.71
exploration/Returns Std                       0
exploration/Returns Max                    4537.71
exploration/Returns Min                    4537.71
exploration/Num Paths                         1
exploration/Average Returns                4537.71
evaluation_0/num steps total                  2.87296e+06
evaluation_0/num paths total              10463
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85562
evaluation_0/Rewards Std                      1.3892
evaluation_0/Rewards Max                     10.739
evaluation_0/Rewards Min                     -0.412515
evaluation_0/Returns Mean                  4855.62
evaluation_0/Returns Std                     57.8349
evaluation_0/Returns Max                   4933.63
evaluation_0/Returns Min                   4764
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4855.62
time/epoch (s)                                0
time/total (s)                             7380.14
Epoch                                       368
---------------------------------------  ----------------
2022-11-16 12:49:02.104997 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 369 finished
---------------------------------------  ----------------
epoch                                       369
total_step                               374000
replay_pool/size                         374000
trainer/alpha                                 0.064134
trainer/alpha_loss                           -0.560267
trainer/entropy                              -5.79603
trainer/qf_loss                               7.33188
trainer/state_noise                           0.005
trainer/policy_loss                        -160.999
trainer/policy_loss_without_entropy         162.702
trainer/entropy_penalty                      -0.371723
trainer/entropy_percentage                   -0.00228469
trainer/Q1Pred Mean                         161.558
trainer/Q1Pred Std                           57.9431
trainer/Q1Pred Max                          259.41
trainer/Q1Pred Min                           -1.84507
trainer/Q2Pred Mean                         162.329
trainer/Q2Pred Std                           58.022
trainer/Q2Pred Max                          259.66
trainer/Q2Pred Min                           -5.37762
trainer/QTargetWithReg Mean                 162.587
trainer/QTargetWithReg Std                   57.6708
trainer/QTargetWithReg Max                  259.882
trainer/QTargetWithReg Min                   -3.14341
trainer/PolicyLossWithoutReg Mean           162.702
trainer/PolicyLossWithoutReg Std             57.0855
trainer/PolicyLossWithoutReg Max            259.681
trainer/PolicyLossWithoutReg Min             -0.272589
trainer/gradient_norm                       266.14
trainer/gradient_penalty                     -1.3307
trainer/gradient_percentage                  -0.00817877
exploration/num steps total              374000
exploration/num paths total                1530
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78955
exploration/Rewards Std                       1.37991
exploration/Rewards Max                      10.5076
exploration/Rewards Min                      -0.414412
exploration/Returns Mean                   4789.55
exploration/Returns Std                       0
exploration/Returns Max                    4789.55
exploration/Returns Min                    4789.55
exploration/Num Paths                         1
exploration/Average Returns                4789.55
evaluation_0/num steps total                  2.88096e+06
evaluation_0/num paths total              10471
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84773
evaluation_0/Rewards Std                      1.3984
evaluation_0/Rewards Max                     11.1131
evaluation_0/Rewards Min                     -0.556427
evaluation_0/Returns Mean                  4847.73
evaluation_0/Returns Std                     88.104
evaluation_0/Returns Max                   4944.18
evaluation_0/Returns Min                   4708.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4847.73
time/epoch (s)                                0
time/total (s)                             7395.97
Epoch                                       369
---------------------------------------  ----------------
2022-11-16 12:49:20.193259 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 370 finished
---------------------------------------  ----------------
epoch                                       370
total_step                               375000
replay_pool/size                         375000
trainer/alpha                                 0.0632702
trainer/alpha_loss                           -0.15199
trainer/entropy                              -5.94493
trainer/qf_loss                               6.76637
trainer/state_noise                           0.005
trainer/policy_loss                        -164.471
trainer/policy_loss_without_entropy         166.254
trainer/entropy_penalty                      -0.376137
trainer/entropy_percentage                   -0.00226242
trainer/Q1Pred Mean                         165.889
trainer/Q1Pred Std                           55.5749
trainer/Q1Pred Max                          254.007
trainer/Q1Pred Min                            1.235
trainer/Q2Pred Mean                         165.585
trainer/Q2Pred Std                           55.3583
trainer/Q2Pred Max                          252.407
trainer/Q2Pred Min                            1.46486
trainer/QTargetWithReg Mean                 165.28
trainer/QTargetWithReg Std                   55.8219
trainer/QTargetWithReg Max                  251.695
trainer/QTargetWithReg Min                   -2.6122
trainer/PolicyLossWithoutReg Mean           166.254
trainer/PolicyLossWithoutReg Std             54.7045
trainer/PolicyLossWithoutReg Max            252.074
trainer/PolicyLossWithoutReg Min              1.13403
trainer/gradient_norm                       281.526
trainer/gradient_penalty                     -1.40763
trainer/gradient_percentage                  -0.00846672
exploration/num steps total              375000
exploration/num paths total                1531
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66429
exploration/Rewards Std                       1.35869
exploration/Rewards Max                      11.3225
exploration/Rewards Min                      -0.527177
exploration/Returns Mean                   4664.29
exploration/Returns Std                       0
exploration/Returns Max                    4664.29
exploration/Returns Min                    4664.29
exploration/Num Paths                         1
exploration/Average Returns                4664.29
evaluation_0/num steps total                  2.88884e+06
evaluation_0/num paths total              10479
evaluation_0/path length Mean               985.75
evaluation_0/path length Std                 37.702
evaluation_0/path length Max               1000
evaluation_0/path length Min                886
evaluation_0/Rewards Mean                     4.73714
evaluation_0/Rewards Std                      1.41206
evaluation_0/Rewards Max                     11.1417
evaluation_0/Rewards Min                     -0.574504
evaluation_0/Returns Mean                  4669.63
evaluation_0/Returns Std                    216.021
evaluation_0/Returns Max                   4879.52
evaluation_0/Returns Min                   4141.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4669.63
time/epoch (s)                                0
time/total (s)                             7414.06
Epoch                                       370
---------------------------------------  ----------------
2022-11-16 12:49:37.509058 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 371 finished
---------------------------------------  ----------------
epoch                                       371
total_step                               376000
replay_pool/size                         376000
trainer/alpha                                 0.0646334
trainer/alpha_loss                            0.255954
trainer/entropy                              -6.09345
trainer/qf_loss                               5.89339
trainer/state_noise                           0.005
trainer/policy_loss                        -162.898
trainer/policy_loss_without_entropy         164.702
trainer/entropy_penalty                      -0.39384
trainer/entropy_percentage                   -0.00239123
trainer/Q1Pred Mean                         164.036
trainer/Q1Pred Std                           55.944
trainer/Q1Pred Max                          255.841
trainer/Q1Pred Min                          -22.8091
trainer/Q2Pred Mean                         163.517
trainer/Q2Pred Std                           55.921
trainer/Q2Pred Max                          254.711
trainer/Q2Pred Min                          -24.9823
trainer/QTargetWithReg Mean                 163.412
trainer/QTargetWithReg Std                   55.9546
trainer/QTargetWithReg Max                  254.604
trainer/QTargetWithReg Min                  -24.9314
trainer/PolicyLossWithoutReg Mean           164.702
trainer/PolicyLossWithoutReg Std             54.6924
trainer/PolicyLossWithoutReg Max            254.175
trainer/PolicyLossWithoutReg Min            -18.1452
trainer/gradient_norm                       281.991
trainer/gradient_penalty                     -1.40996
trainer/gradient_percentage                  -0.00856064
exploration/num steps total              376000
exploration/num paths total                1532
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6612
exploration/Rewards Std                       1.36345
exploration/Rewards Max                      10.1603
exploration/Rewards Min                      -0.405906
exploration/Returns Mean                   4661.2
exploration/Returns Std                       0
exploration/Returns Max                    4661.2
exploration/Returns Min                    4661.2
exploration/Num Paths                         1
exploration/Average Returns                4661.2
evaluation_0/num steps total                  2.89671e+06
evaluation_0/num paths total              10489
evaluation_0/path length Mean               786.7
evaluation_0/path length Std                222.67
evaluation_0/path length Max               1000
evaluation_0/path length Min                458
evaluation_0/Rewards Mean                     4.84457
evaluation_0/Rewards Std                      1.55673
evaluation_0/Rewards Max                     10.8921
evaluation_0/Rewards Min                     -0.519627
evaluation_0/Returns Mean                  3811.22
evaluation_0/Returns Std                   1082.32
evaluation_0/Returns Max                   4921.85
evaluation_0/Returns Min                   2187.57
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3811.22
time/epoch (s)                                0
time/total (s)                             7431.38
Epoch                                       371
---------------------------------------  ----------------
2022-11-16 12:49:55.484871 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 372 finished
---------------------------------------  ----------------
epoch                                       372
total_step                               377000
replay_pool/size                         377000
trainer/alpha                                 0.0644279
trainer/alpha_loss                            0.701992
trainer/entropy                              -6.25598
trainer/qf_loss                              10.4937
trainer/state_noise                           0.005
trainer/policy_loss                        -158.397
trainer/policy_loss_without_entropy         160.237
trainer/entropy_penalty                      -0.40306
trainer/entropy_percentage                   -0.0025154
trainer/Q1Pred Mean                         159.869
trainer/Q1Pred Std                           57.3279
trainer/Q1Pred Max                          260.787
trainer/Q1Pred Min                            6.83216
trainer/Q2Pred Mean                         159.523
trainer/Q2Pred Std                           57.406
trainer/Q2Pred Max                          260.712
trainer/Q2Pred Min                            7.81639
trainer/QTargetWithReg Mean                 159.809
trainer/QTargetWithReg Std                   57.5726
trainer/QTargetWithReg Max                  258.37
trainer/QTargetWithReg Min                   -0.471186
trainer/PolicyLossWithoutReg Mean           160.237
trainer/PolicyLossWithoutReg Std             56.4953
trainer/PolicyLossWithoutReg Max            259.72
trainer/PolicyLossWithoutReg Min              6.57006
trainer/gradient_norm                       287.441
trainer/gradient_penalty                     -1.4372
trainer/gradient_percentage                  -0.00896924
exploration/num steps total              377000
exploration/num paths total                1533
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59858
exploration/Rewards Std                       1.35131
exploration/Rewards Max                      10.3483
exploration/Rewards Min                      -0.435491
exploration/Returns Mean                   4598.58
exploration/Returns Std                       0
exploration/Returns Max                    4598.58
exploration/Returns Min                    4598.58
exploration/Num Paths                         1
exploration/Average Returns                4598.58
evaluation_0/num steps total                  2.90448e+06
evaluation_0/num paths total              10500
evaluation_0/path length Mean               706.818
evaluation_0/path length Std                250.491
evaluation_0/path length Max               1000
evaluation_0/path length Min                431
evaluation_0/Rewards Mean                     4.84156
evaluation_0/Rewards Std                      1.47675
evaluation_0/Rewards Max                     11.0271
evaluation_0/Rewards Min                     -0.588231
evaluation_0/Returns Mean                  3422.1
evaluation_0/Returns Std                   1204.13
evaluation_0/Returns Max                   4957.05
evaluation_0/Returns Min                   2071.06
evaluation_0/Num Paths                       11
evaluation_0/Average Returns               3422.1
time/epoch (s)                                0
time/total (s)                             7449.35
Epoch                                       372
---------------------------------------  ----------------
2022-11-16 12:50:11.370399 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 373 finished
---------------------------------------  ----------------
epoch                                       373
total_step                               378000
replay_pool/size                         378000
trainer/alpha                                 0.0657122
trainer/alpha_loss                           -0.0796143
trainer/entropy                              -5.97076
trainer/qf_loss                               7.24354
trainer/state_noise                           0.005
trainer/policy_loss                        -161.895
trainer/policy_loss_without_entropy         163.674
trainer/entropy_penalty                      -0.392351
trainer/entropy_percentage                   -0.00239715
trainer/Q1Pred Mean                         162.622
trainer/Q1Pred Std                           56.2505
trainer/Q1Pred Max                          259.31
trainer/Q1Pred Min                           -9.02323
trainer/Q2Pred Mean                         163.36
trainer/Q2Pred Std                           56.1357
trainer/Q2Pred Max                          257.06
trainer/Q2Pred Min                            0.238133
trainer/QTargetWithReg Mean                 163.205
trainer/QTargetWithReg Std                   56.1581
trainer/QTargetWithReg Max                  260.181
trainer/QTargetWithReg Min                   -0.214892
trainer/PolicyLossWithoutReg Mean           163.674
trainer/PolicyLossWithoutReg Std             55.063
trainer/PolicyLossWithoutReg Max            257.204
trainer/PolicyLossWithoutReg Min              1.72071
trainer/gradient_norm                       277.35
trainer/gradient_penalty                     -1.38675
trainer/gradient_percentage                  -0.00847261
exploration/num steps total              378000
exploration/num paths total                1534
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66346
exploration/Rewards Std                       1.39995
exploration/Rewards Max                      10.9032
exploration/Rewards Min                      -0.667136
exploration/Returns Mean                   4663.46
exploration/Returns Std                       0
exploration/Returns Max                    4663.46
exploration/Returns Min                    4663.46
exploration/Num Paths                         1
exploration/Average Returns                4663.46
evaluation_0/num steps total                  2.91248e+06
evaluation_0/num paths total              10508
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62003
evaluation_0/Rewards Std                      1.43539
evaluation_0/Rewards Max                     10.7471
evaluation_0/Rewards Min                     -0.595133
evaluation_0/Returns Mean                  4620.03
evaluation_0/Returns Std                    166.915
evaluation_0/Returns Max                   4879.1
evaluation_0/Returns Min                   4370.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4620.03
time/epoch (s)                                0
time/total (s)                             7465.24
Epoch                                       373
---------------------------------------  ----------------
2022-11-16 12:50:27.799210 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 374 finished
---------------------------------------  ----------------
epoch                                       374
total_step                               379000
replay_pool/size                         379000
trainer/alpha                                 0.0660719
trainer/alpha_loss                            0.437003
trainer/entropy                              -6.16085
trainer/qf_loss                               7.7403
trainer/state_noise                           0.005
trainer/policy_loss                        -162.15
trainer/policy_loss_without_entropy         163.98
trainer/entropy_penalty                      -0.407059
trainer/entropy_percentage                   -0.00248237
trainer/Q1Pred Mean                         162.541
trainer/Q1Pred Std                           54.5843
trainer/Q1Pred Max                          251.848
trainer/Q1Pred Min                            3.77856
trainer/Q2Pred Mean                         162.351
trainer/Q2Pred Std                           54.5215
trainer/Q2Pred Max                          254.578
trainer/Q2Pred Min                            7.48618
trainer/QTargetWithReg Mean                 162.938
trainer/QTargetWithReg Std                   54.868
trainer/QTargetWithReg Max                  254.033
trainer/QTargetWithReg Min                    0.173729
trainer/PolicyLossWithoutReg Mean           163.98
trainer/PolicyLossWithoutReg Std             53.8041
trainer/PolicyLossWithoutReg Max            253.469
trainer/PolicyLossWithoutReg Min              4.55509
trainer/gradient_norm                       284.509
trainer/gradient_penalty                     -1.42254
trainer/gradient_percentage                  -0.00867513
exploration/num steps total              379000
exploration/num paths total                1535
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94441
exploration/Rewards Std                       1.39248
exploration/Rewards Max                      11.2897
exploration/Rewards Min                      -0.50613
exploration/Returns Mean                   4944.41
exploration/Returns Std                       0
exploration/Returns Max                    4944.41
exploration/Returns Min                    4944.41
exploration/Num Paths                         1
exploration/Average Returns                4944.41
evaluation_0/num steps total                  2.92048e+06
evaluation_0/num paths total              10516
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71544
evaluation_0/Rewards Std                      1.3901
evaluation_0/Rewards Max                     11.1466
evaluation_0/Rewards Min                     -0.50132
evaluation_0/Returns Mean                  4715.44
evaluation_0/Returns Std                    102.061
evaluation_0/Returns Max                   4826.37
evaluation_0/Returns Min                   4477.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4715.44
time/epoch (s)                                0
time/total (s)                             7481.66
Epoch                                       374
---------------------------------------  ----------------
2022-11-16 12:50:43.698021 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 375 finished
---------------------------------------  ----------------
epoch                                       375
total_step                               380000
replay_pool/size                         380000
trainer/alpha                                 0.0639667
trainer/alpha_loss                            0.742647
trainer/entropy                              -6.2701
trainer/qf_loss                               8.25826
trainer/state_noise                           0.005
trainer/policy_loss                        -158.568
trainer/policy_loss_without_entropy         160.372
trainer/entropy_penalty                      -0.401078
trainer/entropy_percentage                   -0.00250093
trainer/Q1Pred Mean                         159.25
trainer/Q1Pred Std                           58.2789
trainer/Q1Pred Max                          257.684
trainer/Q1Pred Min                            4.27313
trainer/Q2Pred Mean                         159.251
trainer/Q2Pred Std                           57.9491
trainer/Q2Pred Max                          258.21
trainer/Q2Pred Min                            4.1257
trainer/QTargetWithReg Mean                 159.234
trainer/QTargetWithReg Std                   58.3844
trainer/QTargetWithReg Max                  258.187
trainer/QTargetWithReg Min                    3.6883
trainer/PolicyLossWithoutReg Mean           160.372
trainer/PolicyLossWithoutReg Std             57.3996
trainer/PolicyLossWithoutReg Max            257.514
trainer/PolicyLossWithoutReg Min              3.86152
trainer/gradient_norm                       280.581
trainer/gradient_penalty                     -1.4029
trainer/gradient_percentage                  -0.00874782
exploration/num steps total              380000
exploration/num paths total                1536
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55803
exploration/Rewards Std                       1.46222
exploration/Rewards Max                      10.9091
exploration/Rewards Min                      -0.567973
exploration/Returns Mean                   4558.03
exploration/Returns Std                       0
exploration/Returns Max                    4558.03
exploration/Returns Min                    4558.03
exploration/Num Paths                         1
exploration/Average Returns                4558.03
evaluation_0/num steps total                  2.92848e+06
evaluation_0/num paths total              10524
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85029
evaluation_0/Rewards Std                      1.4379
evaluation_0/Rewards Max                     11.2164
evaluation_0/Rewards Min                     -0.572973
evaluation_0/Returns Mean                  4850.29
evaluation_0/Returns Std                    131.044
evaluation_0/Returns Max                   4962.4
evaluation_0/Returns Min                   4519.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4850.29
time/epoch (s)                                0
time/total (s)                             7497.56
Epoch                                       375
---------------------------------------  ----------------
2022-11-16 12:50:59.967380 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 376 finished
---------------------------------------  ----------------
epoch                                       376
total_step                               381000
replay_pool/size                         381000
trainer/alpha                                 0.0657888
trainer/alpha_loss                           -0.0841297
trainer/entropy                              -5.96908
trainer/qf_loss                               6.71741
trainer/state_noise                           0.005
trainer/policy_loss                        -154.331
trainer/policy_loss_without_entropy         156.068
trainer/entropy_penalty                      -0.392699
trainer/entropy_percentage                   -0.00251621
trainer/Q1Pred Mean                         155.159
trainer/Q1Pred Std                           56.5418
trainer/Q1Pred Max                          262.809
trainer/Q1Pred Min                          -33.535
trainer/Q2Pred Mean                         154.989
trainer/Q2Pred Std                           56.6112
trainer/Q2Pred Max                          262.801
trainer/Q2Pred Min                          -35.3024
trainer/QTargetWithReg Mean                 155.396
trainer/QTargetWithReg Std                   56.8014
trainer/QTargetWithReg Max                  262.963
trainer/QTargetWithReg Min                  -33.4385
trainer/PolicyLossWithoutReg Mean           156.068
trainer/PolicyLossWithoutReg Std             55.6897
trainer/PolicyLossWithoutReg Max            261.536
trainer/PolicyLossWithoutReg Min            -32.1675
trainer/gradient_norm                       268.77
trainer/gradient_penalty                     -1.34385
trainer/gradient_percentage                  -0.00861068
exploration/num steps total              381000
exploration/num paths total                1537
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8889
exploration/Rewards Std                       1.40345
exploration/Rewards Max                      11.0142
exploration/Rewards Min                      -0.511244
exploration/Returns Mean                   4888.9
exploration/Returns Std                       0
exploration/Returns Max                    4888.9
exploration/Returns Min                    4888.9
exploration/Num Paths                         1
exploration/Average Returns                4888.9
evaluation_0/num steps total                  2.93648e+06
evaluation_0/num paths total              10532
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75837
evaluation_0/Rewards Std                      1.36839
evaluation_0/Rewards Max                     10.7683
evaluation_0/Rewards Min                     -0.623242
evaluation_0/Returns Mean                  4758.37
evaluation_0/Returns Std                    120.971
evaluation_0/Returns Max                   4890.35
evaluation_0/Returns Min                   4489.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4758.37
time/epoch (s)                                0
time/total (s)                             7513.83
Epoch                                       376
---------------------------------------  ----------------
2022-11-16 12:51:15.816455 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 377 finished
---------------------------------------  ----------------
epoch                                       377
total_step                               382000
replay_pool/size                         382000
trainer/alpha                                 0.0655151
trainer/alpha_loss                            0.445134
trainer/entropy                              -6.16331
trainer/qf_loss                               6.90715
trainer/state_noise                           0.005
trainer/policy_loss                        -163.042
trainer/policy_loss_without_entropy         164.881
trainer/entropy_penalty                      -0.40379
trainer/entropy_percentage                   -0.00244898
trainer/Q1Pred Mean                         164.255
trainer/Q1Pred Std                           54.8138
trainer/Q1Pred Max                          260.817
trainer/Q1Pred Min                            1.19568
trainer/Q2Pred Mean                         163.781
trainer/Q2Pred Std                           54.8427
trainer/Q2Pred Max                          260.277
trainer/Q2Pred Min                           -3.40107
trainer/QTargetWithReg Mean                 163.753
trainer/QTargetWithReg Std                   54.9836
trainer/QTargetWithReg Max                  259.291
trainer/QTargetWithReg Min                   -0.110743
trainer/PolicyLossWithoutReg Mean           164.881
trainer/PolicyLossWithoutReg Std             53.8099
trainer/PolicyLossWithoutReg Max            259.913
trainer/PolicyLossWithoutReg Min              4.80751
trainer/gradient_norm                       286.972
trainer/gradient_penalty                     -1.43486
trainer/gradient_percentage                  -0.0087024
exploration/num steps total              382000
exploration/num paths total                1538
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.47689
exploration/Rewards Std                       1.37562
exploration/Rewards Max                      10.8101
exploration/Rewards Min                      -0.642111
exploration/Returns Mean                   4476.89
exploration/Returns Std                       0
exploration/Returns Max                    4476.89
exploration/Returns Min                    4476.89
exploration/Num Paths                         1
exploration/Average Returns                4476.89
evaluation_0/num steps total                  2.94448e+06
evaluation_0/num paths total              10540
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64042
evaluation_0/Rewards Std                      1.38406
evaluation_0/Rewards Max                     10.8307
evaluation_0/Rewards Min                     -0.583043
evaluation_0/Returns Mean                  4640.42
evaluation_0/Returns Std                    125.983
evaluation_0/Returns Max                   4753.4
evaluation_0/Returns Min                   4393.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4640.42
time/epoch (s)                                0
time/total (s)                             7529.68
Epoch                                       377
---------------------------------------  ----------------
2022-11-16 12:51:31.618397 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 378 finished
---------------------------------------  ----------------
epoch                                       378
total_step                               383000
replay_pool/size                         383000
trainer/alpha                                 0.0664292
trainer/alpha_loss                           -0.693635
trainer/entropy                              -5.74421
trainer/qf_loss                              10.4218
trainer/state_noise                           0.005
trainer/policy_loss                        -154.808
trainer/policy_loss_without_entropy         156.606
trainer/entropy_penalty                      -0.381583
trainer/entropy_percentage                   -0.00243658
trainer/Q1Pred Mean                         155.603
trainer/Q1Pred Std                           57.8279
trainer/Q1Pred Max                          264.535
trainer/Q1Pred Min                           -0.411426
trainer/Q2Pred Mean                         156.184
trainer/Q2Pred Std                           57.7135
trainer/Q2Pred Max                          263.575
trainer/Q2Pred Min                            5.3441
trainer/QTargetWithReg Mean                 155.726
trainer/QTargetWithReg Std                   57.9774
trainer/QTargetWithReg Max                  264.916
trainer/QTargetWithReg Min                    1.77222
trainer/PolicyLossWithoutReg Mean           156.606
trainer/PolicyLossWithoutReg Std             57.1455
trainer/PolicyLossWithoutReg Max            263.445
trainer/PolicyLossWithoutReg Min             -0.82573
trainer/gradient_norm                       283.198
trainer/gradient_penalty                     -1.41599
trainer/gradient_percentage                  -0.00904173
exploration/num steps total              383000
exploration/num paths total                1539
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73312
exploration/Rewards Std                       1.40934
exploration/Rewards Max                      10.1417
exploration/Rewards Min                      -0.564984
exploration/Returns Mean                   4733.12
exploration/Returns Std                       0
exploration/Returns Max                    4733.12
exploration/Returns Min                    4733.12
exploration/Num Paths                         1
exploration/Average Returns                4733.12
evaluation_0/num steps total                  2.95248e+06
evaluation_0/num paths total              10548
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7666
evaluation_0/Rewards Std                      1.37208
evaluation_0/Rewards Max                     11.1632
evaluation_0/Rewards Min                     -0.524286
evaluation_0/Returns Mean                  4766.6
evaluation_0/Returns Std                    104.476
evaluation_0/Returns Max                   4925.93
evaluation_0/Returns Min                   4559.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4766.6
time/epoch (s)                                0
time/total (s)                             7545.48
Epoch                                       378
---------------------------------------  ----------------
2022-11-16 12:51:48.151794 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 379 finished
---------------------------------------  ----------------
epoch                                       379
total_step                               384000
replay_pool/size                         384000
trainer/alpha                                 0.063842
trainer/alpha_loss                            0.0408736
trainer/entropy                              -6.01486
trainer/qf_loss                               6.73623
trainer/state_noise                           0.005
trainer/policy_loss                        -158.859
trainer/policy_loss_without_entropy         160.705
trainer/entropy_penalty                      -0.384
trainer/entropy_percentage                   -0.00238947
trainer/Q1Pred Mean                         159.644
trainer/Q1Pred Std                           56.6715
trainer/Q1Pred Max                          261.001
trainer/Q1Pred Min                            1.26097
trainer/Q2Pred Mean                         159.522
trainer/Q2Pred Std                           56.4018
trainer/Q2Pred Max                          257.983
trainer/Q2Pred Min                           -3.34237
trainer/QTargetWithReg Mean                 159.93
trainer/QTargetWithReg Std                   56.9351
trainer/QTargetWithReg Max                  262.377
trainer/QTargetWithReg Min                   -2.22906
trainer/PolicyLossWithoutReg Mean           160.705
trainer/PolicyLossWithoutReg Std             55.9495
trainer/PolicyLossWithoutReg Max            258.605
trainer/PolicyLossWithoutReg Min              1.77658
trainer/gradient_norm                       292.369
trainer/gradient_penalty                     -1.46184
trainer/gradient_percentage                  -0.00909643
exploration/num steps total              384000
exploration/num paths total                1540
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7454
exploration/Rewards Std                       1.35243
exploration/Rewards Max                      11.0835
exploration/Rewards Min                      -0.491454
exploration/Returns Mean                   4745.4
exploration/Returns Std                       0
exploration/Returns Max                    4745.4
exploration/Returns Min                    4745.4
exploration/Num Paths                         1
exploration/Average Returns                4745.4
evaluation_0/num steps total                  2.96048e+06
evaluation_0/num paths total              10556
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79239
evaluation_0/Rewards Std                      1.37783
evaluation_0/Rewards Max                     11.1715
evaluation_0/Rewards Min                     -0.550804
evaluation_0/Returns Mean                  4792.39
evaluation_0/Returns Std                     78.5481
evaluation_0/Returns Max                   4907.27
evaluation_0/Returns Min                   4712
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4792.39
time/epoch (s)                                0
time/total (s)                             7562.02
Epoch                                       379
---------------------------------------  ----------------
2022-11-16 12:52:04.387167 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 380 finished
---------------------------------------  ----------------
epoch                                       380
total_step                               385000
replay_pool/size                         385000
trainer/alpha                                 0.0651839
trainer/alpha_loss                            0.584805
trainer/entropy                              -6.21417
trainer/qf_loss                               6.55614
trainer/state_noise                           0.005
trainer/policy_loss                        -158.412
trainer/policy_loss_without_entropy         160.26
trainer/entropy_penalty                      -0.405064
trainer/entropy_percentage                   -0.00252754
trainer/Q1Pred Mean                         159.789
trainer/Q1Pred Std                           60.9163
trainer/Q1Pred Max                          257.223
trainer/Q1Pred Min                           -2.09868
trainer/Q2Pred Mean                         159.737
trainer/Q2Pred Std                           61.0497
trainer/Q2Pred Max                          258.546
trainer/Q2Pred Min                           -6.01044
trainer/QTargetWithReg Mean                 159.283
trainer/QTargetWithReg Std                   61.1972
trainer/QTargetWithReg Max                  257.532
trainer/QTargetWithReg Min                   -3.9072
trainer/PolicyLossWithoutReg Mean           160.26
trainer/PolicyLossWithoutReg Std             60.5011
trainer/PolicyLossWithoutReg Max            257.994
trainer/PolicyLossWithoutReg Min             -3.45471
trainer/gradient_norm                       288.59
trainer/gradient_penalty                     -1.44295
trainer/gradient_percentage                  -0.0090038
exploration/num steps total              385000
exploration/num paths total                1541
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69817
exploration/Rewards Std                       1.39042
exploration/Rewards Max                      10.7761
exploration/Rewards Min                      -0.581231
exploration/Returns Mean                   4698.17
exploration/Returns Std                       0
exploration/Returns Max                    4698.17
exploration/Returns Min                    4698.17
exploration/Num Paths                         1
exploration/Average Returns                4698.17
evaluation_0/num steps total                  2.96848e+06
evaluation_0/num paths total              10564
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64434
evaluation_0/Rewards Std                      1.41919
evaluation_0/Rewards Max                     10.7922
evaluation_0/Rewards Min                     -0.665991
evaluation_0/Returns Mean                  4644.34
evaluation_0/Returns Std                    184.402
evaluation_0/Returns Max                   4929.05
evaluation_0/Returns Min                   4328.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4644.34
time/epoch (s)                                0
time/total (s)                             7578.25
Epoch                                       380
---------------------------------------  ----------------
2022-11-16 12:52:20.552965 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 381 finished
---------------------------------------  ----------------
epoch                                       381
total_step                               386000
replay_pool/size                         386000
trainer/alpha                                 0.0665075
trainer/alpha_loss                           -0.182
trainer/entropy                              -5.93285
trainer/qf_loss                               7.94417
trainer/state_noise                           0.005
trainer/policy_loss                        -162.763
trainer/policy_loss_without_entropy         164.584
trainer/entropy_penalty                      -0.394579
trainer/entropy_percentage                   -0.00239744
trainer/Q1Pred Mean                         164.015
trainer/Q1Pred Std                           56.4656
trainer/Q1Pred Max                          253.452
trainer/Q1Pred Min                            4.2045
trainer/Q2Pred Mean                         163.875
trainer/Q2Pred Std                           56.3678
trainer/Q2Pred Max                          251.6
trainer/Q2Pred Min                            5.3559
trainer/QTargetWithReg Mean                 164.384
trainer/QTargetWithReg Std                   56.7697
trainer/QTargetWithReg Max                  255.095
trainer/QTargetWithReg Min                    6.88312
trainer/PolicyLossWithoutReg Mean           164.584
trainer/PolicyLossWithoutReg Std             56.1539
trainer/PolicyLossWithoutReg Max            252.853
trainer/PolicyLossWithoutReg Min              7.40894
trainer/gradient_norm                       285.183
trainer/gradient_penalty                     -1.42591
trainer/gradient_percentage                  -0.00866375
exploration/num steps total              386000
exploration/num paths total                1542
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.767
exploration/Rewards Std                       1.44692
exploration/Rewards Max                      10.6378
exploration/Rewards Min                      -0.533563
exploration/Returns Mean                   4767
exploration/Returns Std                       0
exploration/Returns Max                    4767
exploration/Returns Min                    4767
exploration/Num Paths                         1
exploration/Average Returns                4767
evaluation_0/num steps total                  2.97648e+06
evaluation_0/num paths total              10572
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70018
evaluation_0/Rewards Std                      1.43305
evaluation_0/Rewards Max                     10.6891
evaluation_0/Rewards Min                     -0.534865
evaluation_0/Returns Mean                  4700.18
evaluation_0/Returns Std                    187.942
evaluation_0/Returns Max                   5019.49
evaluation_0/Returns Min                   4510.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4700.18
time/epoch (s)                                0
time/total (s)                             7594.42
Epoch                                       381
---------------------------------------  ----------------
2022-11-16 12:52:36.491630 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 382 finished
---------------------------------------  ----------------
epoch                                       382
total_step                               387000
replay_pool/size                         387000
trainer/alpha                                 0.0652175
trainer/alpha_loss                            0.81119
trainer/entropy                              -6.29712
trainer/qf_loss                               9.26961
trainer/state_noise                           0.005
trainer/policy_loss                        -161.744
trainer/policy_loss_without_entropy         163.577
trainer/entropy_penalty                      -0.410682
trainer/entropy_percentage                   -0.00251063
trainer/Q1Pred Mean                         162.388
trainer/Q1Pred Std                           57.3795
trainer/Q1Pred Max                          262.504
trainer/Q1Pred Min                           -4.74114
trainer/Q2Pred Mean                         162.482
trainer/Q2Pred Std                           57.3444
trainer/Q2Pred Max                          260.452
trainer/Q2Pred Min                            3.90772
trainer/QTargetWithReg Mean                 162.121
trainer/QTargetWithReg Std                   56.9825
trainer/QTargetWithReg Max                  260.225
trainer/QTargetWithReg Min                   -0.322145
trainer/PolicyLossWithoutReg Mean           163.577
trainer/PolicyLossWithoutReg Std             56.4337
trainer/PolicyLossWithoutReg Max            260.335
trainer/PolicyLossWithoutReg Min              3.85136
trainer/gradient_norm                       284.514
trainer/gradient_penalty                     -1.42257
trainer/gradient_percentage                  -0.00869663
exploration/num steps total              387000
exploration/num paths total                1543
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.48649
exploration/Rewards Std                       1.47306
exploration/Rewards Max                      10.193
exploration/Rewards Min                      -0.520942
exploration/Returns Mean                   4486.49
exploration/Returns Std                       0
exploration/Returns Max                    4486.49
exploration/Returns Min                    4486.49
exploration/Num Paths                         1
exploration/Average Returns                4486.49
evaluation_0/num steps total                  2.98448e+06
evaluation_0/num paths total              10580
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6908
evaluation_0/Rewards Std                      1.4134
evaluation_0/Rewards Max                     10.8045
evaluation_0/Rewards Min                     -0.544378
evaluation_0/Returns Mean                  4690.8
evaluation_0/Returns Std                    137.592
evaluation_0/Returns Max                   4829.95
evaluation_0/Returns Min                   4358.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4690.8
time/epoch (s)                                0
time/total (s)                             7610.35
Epoch                                       382
---------------------------------------  ----------------
2022-11-16 12:52:52.891772 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 383 finished
---------------------------------------  ----------------
epoch                                       383
total_step                               388000
replay_pool/size                         388000
trainer/alpha                                 0.0643812
trainer/alpha_loss                            2.97211
trainer/entropy                              -7.08348
trainer/qf_loss                              10.0278
trainer/state_noise                           0.005
trainer/policy_loss                        -166.568
trainer/policy_loss_without_entropy         168.473
trainer/entropy_penalty                      -0.456043
trainer/entropy_percentage                   -0.00270692
trainer/Q1Pred Mean                         168.202
trainer/Q1Pred Std                           54.7638
trainer/Q1Pred Max                          267.032
trainer/Q1Pred Min                            0.843784
trainer/Q2Pred Mean                         167.822
trainer/Q2Pred Std                           54.7384
trainer/Q2Pred Max                          267.728
trainer/Q2Pred Min                           -3.00001
trainer/QTargetWithReg Mean                 167.254
trainer/QTargetWithReg Std                   54.954
trainer/QTargetWithReg Max                  267.474
trainer/QTargetWithReg Min                   -2.6976
trainer/PolicyLossWithoutReg Mean           168.473
trainer/PolicyLossWithoutReg Std             53.919
trainer/PolicyLossWithoutReg Max            266.571
trainer/PolicyLossWithoutReg Min              5.67176
trainer/gradient_norm                       289.932
trainer/gradient_penalty                     -1.44966
trainer/gradient_percentage                  -0.0086047
exploration/num steps total              388000
exploration/num paths total                1544
exploration/path length this epoch Mean     676
exploration/path length this epoch Std        0
exploration/path length this epoch Max      676
exploration/path length this epoch Min      676
exploration/Rewards Mean                      4.89008
exploration/Rewards Std                       1.54047
exploration/Rewards Max                      10.6535
exploration/Rewards Min                      -0.52168
exploration/Returns Mean                   3305.7
exploration/Returns Std                       0
exploration/Returns Max                    3305.7
exploration/Returns Min                    3305.7
exploration/Num Paths                         1
exploration/Average Returns                3305.7
evaluation_0/num steps total                  2.99248e+06
evaluation_0/num paths total              10588
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76357
evaluation_0/Rewards Std                      1.40588
evaluation_0/Rewards Max                     10.7052
evaluation_0/Rewards Min                     -0.526145
evaluation_0/Returns Mean                  4763.57
evaluation_0/Returns Std                     81.182
evaluation_0/Returns Max                   4882.85
evaluation_0/Returns Min                   4645.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4763.57
time/epoch (s)                                0
time/total (s)                             7626.75
Epoch                                       383
---------------------------------------  ----------------
2022-11-16 12:53:08.741767 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 384 finished
---------------------------------------  ----------------
epoch                                       384
total_step                               389000
replay_pool/size                         389000
trainer/alpha                                 0.064999
trainer/alpha_loss                           -0.146059
trainer/entropy                              -5.94656
trainer/qf_loss                               7.51677
trainer/state_noise                           0.005
trainer/policy_loss                        -156.184
trainer/policy_loss_without_entropy         157.98
trainer/entropy_penalty                      -0.386521
trainer/entropy_percentage                   -0.00244665
trainer/Q1Pred Mean                         157.572
trainer/Q1Pred Std                           59.0368
trainer/Q1Pred Max                          262.627
trainer/Q1Pred Min                           14.7141
trainer/Q2Pred Mean                         157.24
trainer/Q2Pred Std                           58.9993
trainer/Q2Pred Max                          261.256
trainer/Q2Pred Min                           15.1641
trainer/QTargetWithReg Mean                 157.188
trainer/QTargetWithReg Std                   58.9872
trainer/QTargetWithReg Max                  261.637
trainer/QTargetWithReg Min                   12.2211
trainer/PolicyLossWithoutReg Mean           157.98
trainer/PolicyLossWithoutReg Std             58.3269
trainer/PolicyLossWithoutReg Max            260.939
trainer/PolicyLossWithoutReg Min             16.6025
trainer/gradient_norm                       281.938
trainer/gradient_penalty                     -1.40969
trainer/gradient_percentage                  -0.00892322
exploration/num steps total              389000
exploration/num paths total                1545
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95105
exploration/Rewards Std                       1.44145
exploration/Rewards Max                      10.8462
exploration/Rewards Min                      -0.633601
exploration/Returns Mean                   4951.05
exploration/Returns Std                       0
exploration/Returns Max                    4951.05
exploration/Returns Min                    4951.05
exploration/Num Paths                         1
exploration/Average Returns                4951.05
evaluation_0/num steps total                  3.00048e+06
evaluation_0/num paths total              10596
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84891
evaluation_0/Rewards Std                      1.41222
evaluation_0/Rewards Max                     10.8085
evaluation_0/Rewards Min                     -0.572799
evaluation_0/Returns Mean                  4848.91
evaluation_0/Returns Std                     48.4988
evaluation_0/Returns Max                   4946.25
evaluation_0/Returns Min                   4812.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4848.91
time/epoch (s)                                0
time/total (s)                             7642.6
Epoch                                       384
---------------------------------------  ----------------
2022-11-16 12:53:25.043620 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 385 finished
---------------------------------------  ----------------
epoch                                       385
total_step                               390000
replay_pool/size                         390000
trainer/alpha                                 0.0662132
trainer/alpha_loss                           -1.18175
trainer/entropy                              -5.5647
trainer/qf_loss                               8.2607
trainer/state_noise                           0.005
trainer/policy_loss                        -158.816
trainer/policy_loss_without_entropy         160.598
trainer/entropy_penalty                      -0.368456
trainer/entropy_percentage                   -0.00229427
trainer/Q1Pred Mean                         159.489
trainer/Q1Pred Std                           58.0815
trainer/Q1Pred Max                          264.331
trainer/Q1Pred Min                           -1.79927
trainer/Q2Pred Mean                         159.396
trainer/Q2Pred Std                           57.7002
trainer/Q2Pred Max                          266.968
trainer/Q2Pred Min                            2.10708
trainer/QTargetWithReg Mean                 159.227
trainer/QTargetWithReg Std                   57.9325
trainer/QTargetWithReg Max                  266.802
trainer/QTargetWithReg Min                    0.815628
trainer/PolicyLossWithoutReg Mean           160.598
trainer/PolicyLossWithoutReg Std             56.875
trainer/PolicyLossWithoutReg Max            265.405
trainer/PolicyLossWithoutReg Min              2.53824
trainer/gradient_norm                       282.658
trainer/gradient_penalty                     -1.41329
trainer/gradient_percentage                  -0.00880018
exploration/num steps total              390000
exploration/num paths total                1546
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67585
exploration/Rewards Std                       1.46254
exploration/Rewards Max                      10.4435
exploration/Rewards Min                      -0.562867
exploration/Returns Mean                   4675.85
exploration/Returns Std                       0
exploration/Returns Max                    4675.85
exploration/Returns Min                    4675.85
exploration/Num Paths                         1
exploration/Average Returns                4675.85
evaluation_0/num steps total                  3.00848e+06
evaluation_0/num paths total              10604
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96056
evaluation_0/Rewards Std                      1.44591
evaluation_0/Rewards Max                     10.9021
evaluation_0/Rewards Min                     -0.602861
evaluation_0/Returns Mean                  4960.56
evaluation_0/Returns Std                     58.5579
evaluation_0/Returns Max                   5024.21
evaluation_0/Returns Min                   4847.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4960.56
time/epoch (s)                                0
time/total (s)                             7658.9
Epoch                                       385
---------------------------------------  ----------------
2022-11-16 12:53:40.916278 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 386 finished
---------------------------------------  ----------------
epoch                                       386
total_step                               391000
replay_pool/size                         391000
trainer/alpha                                 0.0673513
trainer/alpha_loss                           -0.939019
trainer/entropy                              -5.65193
trainer/qf_loss                               6.74669
trainer/state_noise                           0.005
trainer/policy_loss                        -159.508
trainer/policy_loss_without_entropy         161.314
trainer/entropy_penalty                      -0.380665
trainer/entropy_percentage                   -0.00235977
trainer/Q1Pred Mean                         160.573
trainer/Q1Pred Std                           60.2198
trainer/Q1Pred Max                          266.594
trainer/Q1Pred Min                          -70.1857
trainer/Q2Pred Mean                         160.831
trainer/Q2Pred Std                           60.1353
trainer/Q2Pred Max                          265.224
trainer/Q2Pred Min                          -62.5159
trainer/QTargetWithReg Mean                 160.792
trainer/QTargetWithReg Std                   60.2787
trainer/QTargetWithReg Max                  265.41
trainer/QTargetWithReg Min                  -64.3255
trainer/PolicyLossWithoutReg Mean           161.314
trainer/PolicyLossWithoutReg Std             59.5421
trainer/PolicyLossWithoutReg Max            264.741
trainer/PolicyLossWithoutReg Min            -62.8564
trainer/gradient_norm                       285.032
trainer/gradient_penalty                     -1.42516
trainer/gradient_percentage                  -0.00883468
exploration/num steps total              391000
exploration/num paths total                1547
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86049
exploration/Rewards Std                       1.40426
exploration/Rewards Max                      11.2068
exploration/Rewards Min                      -0.577755
exploration/Returns Mean                   4860.49
exploration/Returns Std                       0
exploration/Returns Max                    4860.49
exploration/Returns Min                    4860.49
exploration/Num Paths                         1
exploration/Average Returns                4860.49
evaluation_0/num steps total                  3.01648e+06
evaluation_0/num paths total              10612
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89088
evaluation_0/Rewards Std                      1.43324
evaluation_0/Rewards Max                     10.7358
evaluation_0/Rewards Min                     -0.528455
evaluation_0/Returns Mean                  4890.88
evaluation_0/Returns Std                     75.6043
evaluation_0/Returns Max                   4974.83
evaluation_0/Returns Min                   4733.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4890.88
time/epoch (s)                                0
time/total (s)                             7674.78
Epoch                                       386
---------------------------------------  ----------------
2022-11-16 12:53:59.001096 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 387 finished
---------------------------------------  ---------------
epoch                                       387
total_step                               392000
replay_pool/size                         392000
trainer/alpha                                 0.0664132
trainer/alpha_loss                           -2.0107
trainer/entropy                              -5.25843
trainer/qf_loss                               7.6255
trainer/state_noise                           0.005
trainer/policy_loss                        -156.358
trainer/policy_loss_without_entropy         158.15
trainer/entropy_penalty                      -0.349229
trainer/entropy_percentage                   -0.00220822
trainer/Q1Pred Mean                         157.582
trainer/Q1Pred Std                           57.237
trainer/Q1Pred Max                          265.338
trainer/Q1Pred Min                            1.15848
trainer/Q2Pred Mean                         157.432
trainer/Q2Pred Std                           56.9688
trainer/Q2Pred Max                          263.342
trainer/Q2Pred Min                            1.68879
trainer/QTargetWithReg Mean                 157.057
trainer/QTargetWithReg Std                   57.1931
trainer/QTargetWithReg Max                  264.831
trainer/QTargetWithReg Min                    2.29713
trainer/PolicyLossWithoutReg Mean           158.15
trainer/PolicyLossWithoutReg Std             56.5262
trainer/PolicyLossWithoutReg Max            264.305
trainer/PolicyLossWithoutReg Min              0.244223
trainer/gradient_norm                       288.503
trainer/gradient_penalty                     -1.44251
trainer/gradient_percentage                  -0.00912119
exploration/num steps total              392000
exploration/num paths total                1548
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68714
exploration/Rewards Std                       1.42608
exploration/Rewards Max                      10.9671
exploration/Rewards Min                      -0.505959
exploration/Returns Mean                   4687.14
exploration/Returns Std                       0
exploration/Returns Max                    4687.14
exploration/Returns Min                    4687.14
exploration/Num Paths                         1
exploration/Average Returns                4687.14
evaluation_0/num steps total                  3.0236e+06
evaluation_0/num paths total              10620
evaluation_0/path length Mean               889.5
evaluation_0/path length Std                194.476
evaluation_0/path length Max               1000
evaluation_0/path length Min                489
evaluation_0/Rewards Mean                     4.664
evaluation_0/Rewards Std                      1.51274
evaluation_0/Rewards Max                     10.6385
evaluation_0/Rewards Min                     -0.5985
evaluation_0/Returns Mean                  4148.63
evaluation_0/Returns Std                    851.991
evaluation_0/Returns Max                   4719.68
evaluation_0/Returns Min                   2342.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4148.63
time/epoch (s)                                0
time/total (s)                             7692.86
Epoch                                       387
---------------------------------------  ---------------
2022-11-16 12:54:14.886036 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 388 finished
---------------------------------------  ---------------
epoch                                       388
total_step                               393000
replay_pool/size                         393000
trainer/alpha                                 0.0660895
trainer/alpha_loss                            0.750418
trainer/entropy                              -6.2762
trainer/qf_loss                               9.80692
trainer/state_noise                           0.005
trainer/policy_loss                        -164.362
trainer/policy_loss_without_entropy         166.248
trainer/entropy_penalty                      -0.414791
trainer/entropy_percentage                   -0.00249501
trainer/Q1Pred Mean                         165.687
trainer/Q1Pred Std                           56.566
trainer/Q1Pred Max                          256.566
trainer/Q1Pred Min                           -9.12494
trainer/Q2Pred Mean                         166.018
trainer/Q2Pred Std                           56.4709
trainer/Q2Pred Max                          257.897
trainer/Q2Pred Min                           -6.64422
trainer/QTargetWithReg Mean                 165.514
trainer/QTargetWithReg Std                   57.0445
trainer/QTargetWithReg Max                  258.534
trainer/QTargetWithReg Min                   -9.6555
trainer/PolicyLossWithoutReg Mean           166.248
trainer/PolicyLossWithoutReg Std             55.8715
trainer/PolicyLossWithoutReg Max            255.894
trainer/PolicyLossWithoutReg Min             -3.94131
trainer/gradient_norm                       294.251
trainer/gradient_penalty                     -1.47126
trainer/gradient_percentage                  -0.00884977
exploration/num steps total              393000
exploration/num paths total                1549
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7768
exploration/Rewards Std                       1.44872
exploration/Rewards Max                      11.0666
exploration/Rewards Min                      -0.652839
exploration/Returns Mean                   4776.8
exploration/Returns Std                       0
exploration/Returns Max                    4776.8
exploration/Returns Min                    4776.8
exploration/Num Paths                         1
exploration/Average Returns                4776.8
evaluation_0/num steps total                  3.0316e+06
evaluation_0/num paths total              10628
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77328
evaluation_0/Rewards Std                      1.35176
evaluation_0/Rewards Max                     11.0493
evaluation_0/Rewards Min                     -0.624659
evaluation_0/Returns Mean                  4773.28
evaluation_0/Returns Std                     35.1161
evaluation_0/Returns Max                   4823.41
evaluation_0/Returns Min                   4720.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4773.28
time/epoch (s)                                0
time/total (s)                             7708.75
Epoch                                       388
---------------------------------------  ---------------
2022-11-16 12:54:31.201964 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 389 finished
---------------------------------------  ---------------
epoch                                       389
total_step                               394000
replay_pool/size                         394000
trainer/alpha                                 0.0667034
trainer/alpha_loss                           -0.58186
trainer/entropy                              -5.78508
trainer/qf_loss                               8.00724
trainer/state_noise                           0.005
trainer/policy_loss                        -160.015
trainer/policy_loss_without_entropy         161.875
trainer/entropy_penalty                      -0.385884
trainer/entropy_percentage                   -0.00238385
trainer/Q1Pred Mean                         160.695
trainer/Q1Pred Std                           57.1971
trainer/Q1Pred Max                          268.885
trainer/Q1Pred Min                          -42.5305
trainer/Q2Pred Mean                         161.691
trainer/Q2Pred Std                           57.047
trainer/Q2Pred Max                          269.437
trainer/Q2Pred Min                          -34.8822
trainer/QTargetWithReg Mean                 161.364
trainer/QTargetWithReg Std                   57.5293
trainer/QTargetWithReg Max                  269.912
trainer/QTargetWithReg Min                  -45.0145
trainer/PolicyLossWithoutReg Mean           161.875
trainer/PolicyLossWithoutReg Std             56.4685
trainer/PolicyLossWithoutReg Max            269.179
trainer/PolicyLossWithoutReg Min            -33.3658
trainer/gradient_norm                       294.846
trainer/gradient_penalty                     -1.47423
trainer/gradient_percentage                  -0.00910723
exploration/num steps total              394000
exploration/num paths total                1550
exploration/path length this epoch Mean     663
exploration/path length this epoch Std        0
exploration/path length this epoch Max      663
exploration/path length this epoch Min      663
exploration/Rewards Mean                      4.85742
exploration/Rewards Std                       1.53067
exploration/Rewards Max                      10.6105
exploration/Rewards Min                      -0.661988
exploration/Returns Mean                   3220.47
exploration/Returns Std                       0
exploration/Returns Max                    3220.47
exploration/Returns Min                    3220.47
exploration/Num Paths                         1
exploration/Average Returns                3220.47
evaluation_0/num steps total                  3.0396e+06
evaluation_0/num paths total              10636
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82855
evaluation_0/Rewards Std                      1.39459
evaluation_0/Rewards Max                     10.7673
evaluation_0/Rewards Min                     -0.537725
evaluation_0/Returns Mean                  4828.55
evaluation_0/Returns Std                     36.8907
evaluation_0/Returns Max                   4919.63
evaluation_0/Returns Min                   4797.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4828.55
time/epoch (s)                                0
time/total (s)                             7725.06
Epoch                                       389
---------------------------------------  ---------------
2022-11-16 12:54:47.057269 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 390 finished
---------------------------------------  ---------------
epoch                                       390
total_step                               395000
replay_pool/size                         395000
trainer/alpha                                 0.066443
trainer/alpha_loss                            0.897702
trainer/entropy                              -6.33109
trainer/qf_loss                               7.05086
trainer/state_noise                           0.005
trainer/policy_loss                        -170.513
trainer/policy_loss_without_entropy         172.36
trainer/entropy_penalty                      -0.420657
trainer/entropy_percentage                   -0.00244057
trainer/Q1Pred Mean                         171.941
trainer/Q1Pred Std                           54.9319
trainer/Q1Pred Max                          264.473
trainer/Q1Pred Min                            4.66442
trainer/Q2Pred Mean                         172.572
trainer/Q2Pred Std                           54.709
trainer/Q2Pred Max                          264.326
trainer/Q2Pred Min                            6.86686
trainer/QTargetWithReg Mean                 171.477
trainer/QTargetWithReg Std                   54.6444
trainer/QTargetWithReg Max                  263.788
trainer/QTargetWithReg Min                    4.77779
trainer/PolicyLossWithoutReg Mean           172.36
trainer/PolicyLossWithoutReg Std             54.2522
trainer/PolicyLossWithoutReg Max            263.807
trainer/PolicyLossWithoutReg Min              4.26488
trainer/gradient_norm                       285.304
trainer/gradient_penalty                     -1.42652
trainer/gradient_percentage                  -0.00827639
exploration/num steps total              395000
exploration/num paths total                1551
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88455
exploration/Rewards Std                       1.41072
exploration/Rewards Max                      10.5615
exploration/Rewards Min                      -0.493578
exploration/Returns Mean                   4884.55
exploration/Returns Std                       0
exploration/Returns Max                    4884.55
exploration/Returns Min                    4884.55
exploration/Num Paths                         1
exploration/Average Returns                4884.55
evaluation_0/num steps total                  3.0476e+06
evaluation_0/num paths total              10644
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92307
evaluation_0/Rewards Std                      1.43103
evaluation_0/Rewards Max                     10.7028
evaluation_0/Rewards Min                     -0.547928
evaluation_0/Returns Mean                  4923.07
evaluation_0/Returns Std                     33.6794
evaluation_0/Returns Max                   4969.14
evaluation_0/Returns Min                   4874.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4923.07
time/epoch (s)                                0
time/total (s)                             7740.92
Epoch                                       390
---------------------------------------  ---------------
2022-11-16 12:55:04.990409 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 391 finished
---------------------------------------  ----------------
epoch                                       391
total_step                               396000
replay_pool/size                         396000
trainer/alpha                                 0.0653935
trainer/alpha_loss                            0.356964
trainer/entropy                              -6.13088
trainer/qf_loss                               7.46939
trainer/state_noise                           0.005
trainer/policy_loss                        -171.527
trainer/policy_loss_without_entropy         173.364
trainer/entropy_penalty                      -0.40092
trainer/entropy_percentage                   -0.00231258
trainer/Q1Pred Mean                         173.043
trainer/Q1Pred Std                           57.5653
trainer/Q1Pred Max                          266.994
trainer/Q1Pred Min                           -4.91505
trainer/Q2Pred Mean                         172.806
trainer/Q2Pred Std                           57.5345
trainer/Q2Pred Max                          264.895
trainer/Q2Pred Min                           -5.77353
trainer/QTargetWithReg Mean                 172.68
trainer/QTargetWithReg Std                   57.4826
trainer/QTargetWithReg Max                  264.829
trainer/QTargetWithReg Min                   -0.111334
trainer/PolicyLossWithoutReg Mean           173.364
trainer/PolicyLossWithoutReg Std             56.7263
trainer/PolicyLossWithoutReg Max            264.622
trainer/PolicyLossWithoutReg Min              4.52461
trainer/gradient_norm                       287.34
trainer/gradient_penalty                     -1.4367
trainer/gradient_percentage                  -0.00828718
exploration/num steps total              396000
exploration/num paths total                1552
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97322
exploration/Rewards Std                       1.42646
exploration/Rewards Max                      10.8644
exploration/Rewards Min                      -0.482365
exploration/Returns Mean                   4973.22
exploration/Returns Std                       0
exploration/Returns Max                    4973.22
exploration/Returns Min                    4973.22
exploration/Num Paths                         1
exploration/Average Returns                4973.22
evaluation_0/num steps total                  3.05537e+06
evaluation_0/num paths total              10652
evaluation_0/path length Mean               971
evaluation_0/path length Std                 76.7268
evaluation_0/path length Max               1000
evaluation_0/path length Min                768
evaluation_0/Rewards Mean                     4.92629
evaluation_0/Rewards Std                      1.47314
evaluation_0/Rewards Max                     11.0221
evaluation_0/Rewards Min                     -0.563148
evaluation_0/Returns Mean                  4783.43
evaluation_0/Returns Std                    316.491
evaluation_0/Returns Max                   4957.71
evaluation_0/Returns Min                   3952.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4783.43
time/epoch (s)                                0
time/total (s)                             7758.85
Epoch                                       391
---------------------------------------  ----------------
2022-11-16 12:55:20.855956 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 392 finished
---------------------------------------  ----------------
epoch                                       392
total_step                               397000
replay_pool/size                         397000
trainer/alpha                                 0.065456
trainer/alpha_loss                            0.840108
trainer/entropy                              -6.30811
trainer/qf_loss                               6.04236
trainer/state_noise                           0.005
trainer/policy_loss                        -162.688
trainer/policy_loss_without_entropy         164.602
trainer/entropy_penalty                      -0.412903
trainer/entropy_percentage                   -0.0025085
trainer/Q1Pred Mean                         164.083
trainer/Q1Pred Std                           55.9946
trainer/Q1Pred Max                          264.568
trainer/Q1Pred Min                           -8.25216
trainer/Q2Pred Mean                         163.82
trainer/Q2Pred Std                           55.9751
trainer/Q2Pred Max                          264.529
trainer/Q2Pred Min                           -5.67875
trainer/QTargetWithReg Mean                 163.694
trainer/QTargetWithReg Std                   56.2974
trainer/QTargetWithReg Max                  265.585
trainer/QTargetWithReg Min                  -12.0803
trainer/PolicyLossWithoutReg Mean           164.602
trainer/PolicyLossWithoutReg Std             55.6001
trainer/PolicyLossWithoutReg Max            265.565
trainer/PolicyLossWithoutReg Min             -2.00407
trainer/gradient_norm                       300.181
trainer/gradient_penalty                     -1.50091
trainer/gradient_percentage                  -0.00911841
exploration/num steps total              397000
exploration/num paths total                1553
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72099
exploration/Rewards Std                       1.41673
exploration/Rewards Max                      10.9453
exploration/Rewards Min                      -0.539305
exploration/Returns Mean                   4720.99
exploration/Returns Std                       0
exploration/Returns Max                    4720.99
exploration/Returns Min                    4720.99
exploration/Num Paths                         1
exploration/Average Returns                4720.99
evaluation_0/num steps total                  3.06337e+06
evaluation_0/num paths total              10660
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82747
evaluation_0/Rewards Std                      1.42843
evaluation_0/Rewards Max                     10.9158
evaluation_0/Rewards Min                     -0.633422
evaluation_0/Returns Mean                  4827.47
evaluation_0/Returns Std                    105.566
evaluation_0/Returns Max                   4932.41
evaluation_0/Returns Min                   4636.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4827.47
time/epoch (s)                                0
time/total (s)                             7774.72
Epoch                                       392
---------------------------------------  ----------------
2022-11-16 12:55:36.798996 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 393 finished
---------------------------------------  ----------------
epoch                                       393
total_step                               398000
replay_pool/size                         398000
trainer/alpha                                 0.0664259
trainer/alpha_loss                           -1.8619
trainer/entropy                              -5.31336
trainer/qf_loss                               6.83573
trainer/state_noise                           0.005
trainer/policy_loss                        -168.822
trainer/policy_loss_without_entropy         170.606
trainer/entropy_penalty                      -0.352945
trainer/entropy_percentage                   -0.00206878
trainer/Q1Pred Mean                         169.441
trainer/Q1Pred Std                           55.5274
trainer/Q1Pred Max                          265.797
trainer/Q1Pred Min                            4.12376
trainer/Q2Pred Mean                         169.398
trainer/Q2Pred Std                           56.0343
trainer/Q2Pred Max                          265.156
trainer/Q2Pred Min                            2.17813
trainer/QTargetWithReg Mean                 170.051
trainer/QTargetWithReg Std                   55.8741
trainer/QTargetWithReg Max                  264.466
trainer/QTargetWithReg Min                    4.14882
trainer/PolicyLossWithoutReg Mean           170.606
trainer/PolicyLossWithoutReg Std             55.2013
trainer/PolicyLossWithoutReg Max            266.205
trainer/PolicyLossWithoutReg Min              2.82256
trainer/gradient_norm                       286.098
trainer/gradient_penalty                     -1.43049
trainer/gradient_percentage                  -0.00838478
exploration/num steps total              398000
exploration/num paths total                1554
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86469
exploration/Rewards Std                       1.43933
exploration/Rewards Max                      10.8718
exploration/Rewards Min                      -0.686493
exploration/Returns Mean                   4864.69
exploration/Returns Std                       0
exploration/Returns Max                    4864.69
exploration/Returns Min                    4864.69
exploration/Num Paths                         1
exploration/Average Returns                4864.69
evaluation_0/num steps total                  3.07137e+06
evaluation_0/num paths total              10668
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92918
evaluation_0/Rewards Std                      1.44509
evaluation_0/Rewards Max                     11.0133
evaluation_0/Rewards Min                     -0.585374
evaluation_0/Returns Mean                  4929.18
evaluation_0/Returns Std                    126.703
evaluation_0/Returns Max                   5025.2
evaluation_0/Returns Min                   4653.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4929.18
time/epoch (s)                                0
time/total (s)                             7790.66
Epoch                                       393
---------------------------------------  ----------------
2022-11-16 12:55:53.123477 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 394 finished
---------------------------------------  ----------------
epoch                                       394
total_step                               399000
replay_pool/size                         399000
trainer/alpha                                 0.0673594
trainer/alpha_loss                           -0.0154396
trainer/entropy                              -5.99428
trainer/qf_loss                               7.39436
trainer/state_noise                           0.005
trainer/policy_loss                        -158.519
trainer/policy_loss_without_entropy         160.339
trainer/entropy_penalty                      -0.403771
trainer/entropy_percentage                   -0.00251823
trainer/Q1Pred Mean                         159.536
trainer/Q1Pred Std                           57.907
trainer/Q1Pred Max                          262.746
trainer/Q1Pred Min                           -2.80621
trainer/Q2Pred Mean                         159.216
trainer/Q2Pred Std                           57.6621
trainer/Q2Pred Max                          260.781
trainer/Q2Pred Min                           -2.81858
trainer/QTargetWithReg Mean                 158.863
trainer/QTargetWithReg Std                   57.8305
trainer/QTargetWithReg Max                  261.446
trainer/QTargetWithReg Min                    3.45479
trainer/PolicyLossWithoutReg Mean           160.339
trainer/PolicyLossWithoutReg Std             57.3419
trainer/PolicyLossWithoutReg Max            261.222
trainer/PolicyLossWithoutReg Min              3.58551
trainer/gradient_norm                       283.293
trainer/gradient_penalty                     -1.41647
trainer/gradient_percentage                  -0.0088342
exploration/num steps total              399000
exploration/num paths total                1555
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64476
exploration/Rewards Std                       1.4245
exploration/Rewards Max                      10.5503
exploration/Rewards Min                      -0.66389
exploration/Returns Mean                   4644.76
exploration/Returns Std                       0
exploration/Returns Max                    4644.76
exploration/Returns Min                    4644.76
exploration/Num Paths                         1
exploration/Average Returns                4644.76
evaluation_0/num steps total                  3.07937e+06
evaluation_0/num paths total              10676
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89699
evaluation_0/Rewards Std                      1.35445
evaluation_0/Rewards Max                     11.3337
evaluation_0/Rewards Min                     -0.582034
evaluation_0/Returns Mean                  4896.99
evaluation_0/Returns Std                     62.0931
evaluation_0/Returns Max                   5001.95
evaluation_0/Returns Min                   4801.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4896.99
time/epoch (s)                                0
time/total (s)                             7806.98
Epoch                                       394
---------------------------------------  ----------------
2022-11-16 12:56:08.908504 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 395 finished
---------------------------------------  ----------------
epoch                                       395
total_step                               400000
replay_pool/size                         400000
trainer/alpha                                 0.0675292
trainer/alpha_loss                           -0.68487
trainer/entropy                              -5.74589
trainer/qf_loss                               5.99268
trainer/state_noise                           0.005
trainer/policy_loss                        -166.351
trainer/policy_loss_without_entropy         168.178
trainer/entropy_penalty                      -0.388015
trainer/entropy_percentage                   -0.00230717
trainer/Q1Pred Mean                         167.614
trainer/Q1Pred Std                           59.124
trainer/Q1Pred Max                          270.22
trainer/Q1Pred Min                            4.68784
trainer/Q2Pred Mean                         166.975
trainer/Q2Pred Std                           58.7274
trainer/Q2Pred Max                          269.251
trainer/Q2Pred Min                            6.87006
trainer/QTargetWithReg Mean                 167.092
trainer/QTargetWithReg Std                   59.0959
trainer/QTargetWithReg Max                  268.381
trainer/QTargetWithReg Min                    5.74939
trainer/PolicyLossWithoutReg Mean           168.178
trainer/PolicyLossWithoutReg Std             58.2737
trainer/PolicyLossWithoutReg Max            268.779
trainer/PolicyLossWithoutReg Min              6.95204
trainer/gradient_norm                       287.752
trainer/gradient_penalty                     -1.43876
trainer/gradient_percentage                  -0.00855498
exploration/num steps total              400000
exploration/num paths total                1556
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89701
exploration/Rewards Std                       1.41742
exploration/Rewards Max                      10.5753
exploration/Rewards Min                      -0.593232
exploration/Returns Mean                   4897.01
exploration/Returns Std                       0
exploration/Returns Max                    4897.01
exploration/Returns Min                    4897.01
exploration/Num Paths                         1
exploration/Average Returns                4897.01
evaluation_0/num steps total                  3.08737e+06
evaluation_0/num paths total              10684
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97038
evaluation_0/Rewards Std                      1.4443
evaluation_0/Rewards Max                     10.9082
evaluation_0/Rewards Min                     -0.649833
evaluation_0/Returns Mean                  4970.38
evaluation_0/Returns Std                     57.4122
evaluation_0/Returns Max                   5076.82
evaluation_0/Returns Min                   4889.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4970.38
time/epoch (s)                                0
time/total (s)                             7822.77
Epoch                                       395
---------------------------------------  ----------------
2022-11-16 12:56:26.916189 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 396 finished
---------------------------------------  ----------------
epoch                                       396
total_step                               401000
replay_pool/size                         401000
trainer/alpha                                 0.0665387
trainer/alpha_loss                           -0.528096
trainer/entropy                              -5.80513
trainer/qf_loss                               6.26898
trainer/state_noise                           0.005
trainer/policy_loss                        -166.425
trainer/policy_loss_without_entropy         168.3
trainer/entropy_penalty                      -0.386266
trainer/entropy_percentage                   -0.0022951
trainer/Q1Pred Mean                         167.347
trainer/Q1Pred Std                           59.5826
trainer/Q1Pred Max                          258.919
trainer/Q1Pred Min                            0.572545
trainer/Q2Pred Mean                         167.332
trainer/Q2Pred Std                           59.6301
trainer/Q2Pred Max                          258.955
trainer/Q2Pred Min                            1.48622
trainer/QTargetWithReg Mean                 167.681
trainer/QTargetWithReg Std                   59.7901
trainer/QTargetWithReg Max                  260.256
trainer/QTargetWithReg Min                    3.52867
trainer/PolicyLossWithoutReg Mean           168.3
trainer/PolicyLossWithoutReg Std             58.9645
trainer/PolicyLossWithoutReg Max            258.351
trainer/PolicyLossWithoutReg Min              1.10706
trainer/gradient_norm                       297.803
trainer/gradient_penalty                     -1.48901
trainer/gradient_percentage                  -0.00884738
exploration/num steps total              401000
exploration/num paths total                1557
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93587
exploration/Rewards Std                       1.42531
exploration/Rewards Max                      11.2617
exploration/Rewards Min                      -0.516637
exploration/Returns Mean                   4935.87
exploration/Returns Std                       0
exploration/Returns Max                    4935.87
exploration/Returns Min                    4935.87
exploration/Num Paths                         1
exploration/Average Returns                4935.87
evaluation_0/num steps total                  3.09503e+06
evaluation_0/num paths total              10692
evaluation_0/path length Mean               957.25
evaluation_0/path length Std                113.106
evaluation_0/path length Max               1000
evaluation_0/path length Min                658
evaluation_0/Rewards Mean                     4.81713
evaluation_0/Rewards Std                      1.40631
evaluation_0/Rewards Max                     11.0447
evaluation_0/Rewards Min                     -0.504219
evaluation_0/Returns Mean                  4611.2
evaluation_0/Returns Std                    564.041
evaluation_0/Returns Max                   4922.1
evaluation_0/Returns Min                   3126.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4611.2
time/epoch (s)                                0
time/total (s)                             7840.77
Epoch                                       396
---------------------------------------  ----------------
2022-11-16 12:56:42.677695 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 397 finished
---------------------------------------  ----------------
epoch                                       397
total_step                               402000
replay_pool/size                         402000
trainer/alpha                                 0.0670687
trainer/alpha_loss                            0.932044
trainer/entropy                              -6.34489
trainer/qf_loss                               8.45476
trainer/state_noise                           0.005
trainer/policy_loss                        -160.248
trainer/policy_loss_without_entropy         162.141
trainer/entropy_penalty                      -0.425544
trainer/entropy_percentage                   -0.00262453
trainer/Q1Pred Mean                         161.261
trainer/Q1Pred Std                           58.3529
trainer/Q1Pred Max                          259.912
trainer/Q1Pred Min                            9.11176
trainer/Q2Pred Mean                         160.971
trainer/Q2Pred Std                           58.5583
trainer/Q2Pred Max                          258.421
trainer/Q2Pred Min                            9.56661
trainer/QTargetWithReg Mean                 160.58
trainer/QTargetWithReg Std                   58.6717
trainer/QTargetWithReg Max                  257.963
trainer/QTargetWithReg Min                   -0.854132
trainer/PolicyLossWithoutReg Mean           162.141
trainer/PolicyLossWithoutReg Std             57.5354
trainer/PolicyLossWithoutReg Max            258.412
trainer/PolicyLossWithoutReg Min              9.57064
trainer/gradient_norm                       293.428
trainer/gradient_penalty                     -1.46714
trainer/gradient_percentage                  -0.00904857
exploration/num steps total              402000
exploration/num paths total                1558
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58597
exploration/Rewards Std                       1.46347
exploration/Rewards Max                      11.2134
exploration/Rewards Min                      -0.471652
exploration/Returns Mean                   4585.97
exploration/Returns Std                       0
exploration/Returns Max                    4585.97
exploration/Returns Min                    4585.97
exploration/Num Paths                         1
exploration/Average Returns                4585.97
evaluation_0/num steps total                  3.10303e+06
evaluation_0/num paths total              10700
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86073
evaluation_0/Rewards Std                      1.32241
evaluation_0/Rewards Max                     11.0945
evaluation_0/Rewards Min                     -0.571004
evaluation_0/Returns Mean                  4860.73
evaluation_0/Returns Std                     25.5141
evaluation_0/Returns Max                   4919.15
evaluation_0/Returns Min                   4827.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4860.73
time/epoch (s)                                0
time/total (s)                             7856.54
Epoch                                       397
---------------------------------------  ----------------
2022-11-16 12:56:58.988488 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 398 finished
---------------------------------------  ----------------
epoch                                       398
total_step                               403000
replay_pool/size                         403000
trainer/alpha                                 0.0657607
trainer/alpha_loss                            0.243044
trainer/entropy                              -6.0893
trainer/qf_loss                               8.41917
trainer/state_noise                           0.005
trainer/policy_loss                        -162.888
trainer/policy_loss_without_entropy         164.74
trainer/entropy_penalty                      -0.400436
trainer/entropy_percentage                   -0.00243072
trainer/Q1Pred Mean                         164.277
trainer/Q1Pred Std                           54.2273
trainer/Q1Pred Max                          263.877
trainer/Q1Pred Min                            7.34018
trainer/Q2Pred Mean                         164.327
trainer/Q2Pred Std                           54.1272
trainer/Q2Pred Max                          263.682
trainer/Q2Pred Min                            5.15824
trainer/QTargetWithReg Mean                 163.912
trainer/QTargetWithReg Std                   54.2658
trainer/QTargetWithReg Max                  264.247
trainer/QTargetWithReg Min                    5.80283
trainer/PolicyLossWithoutReg Mean           164.74
trainer/PolicyLossWithoutReg Std             53.5371
trainer/PolicyLossWithoutReg Max            263.599
trainer/PolicyLossWithoutReg Min              6.00809
trainer/gradient_norm                       290.417
trainer/gradient_penalty                     -1.45208
trainer/gradient_percentage                  -0.00881438
exploration/num steps total              403000
exploration/num paths total                1559
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75825
exploration/Rewards Std                       1.42096
exploration/Rewards Max                      10.7901
exploration/Rewards Min                      -0.640092
exploration/Returns Mean                   4758.25
exploration/Returns Std                       0
exploration/Returns Max                    4758.25
exploration/Returns Min                    4758.25
exploration/Num Paths                         1
exploration/Average Returns                4758.25
evaluation_0/num steps total                  3.11103e+06
evaluation_0/num paths total              10708
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94743
evaluation_0/Rewards Std                      1.40338
evaluation_0/Rewards Max                     10.8481
evaluation_0/Rewards Min                     -0.556003
evaluation_0/Returns Mean                  4947.43
evaluation_0/Returns Std                     67.382
evaluation_0/Returns Max                   5047.58
evaluation_0/Returns Min                   4853.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4947.43
time/epoch (s)                                0
time/total (s)                             7872.85
Epoch                                       398
---------------------------------------  ----------------
2022-11-16 12:57:14.894882 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 399 finished
---------------------------------------  ----------------
epoch                                       399
total_step                               404000
replay_pool/size                         404000
trainer/alpha                                 0.0671005
trainer/alpha_loss                           -0.961282
trainer/entropy                              -5.64415
trainer/qf_loss                               9.39688
trainer/state_noise                           0.005
trainer/policy_loss                        -161.827
trainer/policy_loss_without_entropy         163.651
trainer/entropy_penalty                      -0.378726
trainer/entropy_percentage                   -0.00231423
trainer/Q1Pred Mean                         163.141
trainer/Q1Pred Std                           61.6782
trainer/Q1Pred Max                          264.951
trainer/Q1Pred Min                           -1.24627
trainer/Q2Pred Mean                         162.904
trainer/Q2Pred Std                           61.9553
trainer/Q2Pred Max                          264.279
trainer/Q2Pred Min                           -3.29348
trainer/QTargetWithReg Mean                 162.945
trainer/QTargetWithReg Std                   61.9233
trainer/QTargetWithReg Max                  264.371
trainer/QTargetWithReg Min                   -2.66921
trainer/PolicyLossWithoutReg Mean           163.651
trainer/PolicyLossWithoutReg Std             60.7043
trainer/PolicyLossWithoutReg Max            264.14
trainer/PolicyLossWithoutReg Min             -1.416
trainer/gradient_norm                       288.91
trainer/gradient_penalty                     -1.44455
trainer/gradient_percentage                  -0.00882704
exploration/num steps total              404000
exploration/num paths total                1560
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78611
exploration/Rewards Std                       1.41307
exploration/Rewards Max                      10.344
exploration/Rewards Min                      -0.515342
exploration/Returns Mean                   4786.11
exploration/Returns Std                       0
exploration/Returns Max                    4786.11
exploration/Returns Min                    4786.11
exploration/Num Paths                         1
exploration/Average Returns                4786.11
evaluation_0/num steps total                  3.11903e+06
evaluation_0/num paths total              10716
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01815
evaluation_0/Rewards Std                      1.41282
evaluation_0/Rewards Max                     10.9826
evaluation_0/Rewards Min                     -0.5868
evaluation_0/Returns Mean                  5018.15
evaluation_0/Returns Std                     68.7414
evaluation_0/Returns Max                   5100.5
evaluation_0/Returns Min                   4903.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5018.15
time/epoch (s)                                0
time/total (s)                             7888.75
Epoch                                       399
---------------------------------------  ----------------
2022-11-16 12:57:31.377359 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 400 finished
---------------------------------------  ----------------
epoch                                       400
total_step                               405000
replay_pool/size                         405000
trainer/alpha                                 0.0675351
trainer/alpha_loss                            1.93455
trainer/entropy                              -6.71771
trainer/qf_loss                               9.58724
trainer/state_noise                           0.005
trainer/policy_loss                        -169.685
trainer/policy_loss_without_entropy         171.622
trainer/entropy_penalty                      -0.453681
trainer/entropy_percentage                   -0.00264349
trainer/Q1Pred Mean                         170.737
trainer/Q1Pred Std                           63.741
trainer/Q1Pred Max                          268.708
trainer/Q1Pred Min                          -15.7014
trainer/Q2Pred Mean                         171.659
trainer/Q2Pred Std                           63.4481
trainer/Q2Pred Max                          269.584
trainer/Q2Pred Min                          -14.5939
trainer/QTargetWithReg Mean                 170.686
trainer/QTargetWithReg Std                   63.9716
trainer/QTargetWithReg Max                  270.594
trainer/QTargetWithReg Min                  -23.8624
trainer/PolicyLossWithoutReg Mean           171.622
trainer/PolicyLossWithoutReg Std             63.0339
trainer/PolicyLossWithoutReg Max            269.719
trainer/PolicyLossWithoutReg Min            -15.2106
trainer/gradient_norm                       296.692
trainer/gradient_penalty                     -1.48346
trainer/gradient_percentage                  -0.00864376
exploration/num steps total              405000
exploration/num paths total                1561
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85829
exploration/Rewards Std                       1.37296
exploration/Rewards Max                      10.5069
exploration/Rewards Min                      -0.540884
exploration/Returns Mean                   4858.29
exploration/Returns Std                       0
exploration/Returns Max                    4858.29
exploration/Returns Min                    4858.29
exploration/Num Paths                         1
exploration/Average Returns                4858.29
evaluation_0/num steps total                  3.12703e+06
evaluation_0/num paths total              10724
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86702
evaluation_0/Rewards Std                      1.31622
evaluation_0/Rewards Max                     10.385
evaluation_0/Rewards Min                     -0.584697
evaluation_0/Returns Mean                  4867.02
evaluation_0/Returns Std                     32.4381
evaluation_0/Returns Max                   4914.43
evaluation_0/Returns Min                   4807.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4867.02
time/epoch (s)                                0
time/total (s)                             7905.23
Epoch                                       400
---------------------------------------  ----------------
2022-11-16 12:57:48.924659 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 401 finished
---------------------------------------  ----------------
epoch                                       401
total_step                               406000
replay_pool/size                         406000
trainer/alpha                                 0.0665736
trainer/alpha_loss                           -0.461973
trainer/entropy                              -5.82949
trainer/qf_loss                               6.97081
trainer/state_noise                           0.005
trainer/policy_loss                        -163.592
trainer/policy_loss_without_entropy         165.405
trainer/entropy_penalty                      -0.38809
trainer/entropy_percentage                   -0.0023463
trainer/Q1Pred Mean                         165.223
trainer/Q1Pred Std                           60.2603
trainer/Q1Pred Max                          266.625
trainer/Q1Pred Min                           13.1925
trainer/Q2Pred Mean                         164.789
trainer/Q2Pred Std                           60.2762
trainer/Q2Pred Max                          266.657
trainer/Q2Pred Min                           12.1355
trainer/QTargetWithReg Mean                 164.988
trainer/QTargetWithReg Std                   60.6826
trainer/QTargetWithReg Max                  267.395
trainer/QTargetWithReg Min                   12.3622
trainer/PolicyLossWithoutReg Mean           165.405
trainer/PolicyLossWithoutReg Std             59.615
trainer/PolicyLossWithoutReg Max            265.548
trainer/PolicyLossWithoutReg Min             11.9075
trainer/gradient_norm                       285.069
trainer/gradient_penalty                     -1.42535
trainer/gradient_percentage                  -0.0086173
exploration/num steps total              406000
exploration/num paths total                1562
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82399
exploration/Rewards Std                       1.4443
exploration/Rewards Max                      10.8601
exploration/Rewards Min                      -0.621172
exploration/Returns Mean                   4823.99
exploration/Returns Std                       0
exploration/Returns Max                    4823.99
exploration/Returns Min                    4823.99
exploration/Num Paths                         1
exploration/Average Returns                4823.99
evaluation_0/num steps total                  3.13495e+06
evaluation_0/num paths total              10732
evaluation_0/path length Mean               990.625
evaluation_0/path length Std                 24.8039
evaluation_0/path length Max               1000
evaluation_0/path length Min                925
evaluation_0/Rewards Mean                     5.02133
evaluation_0/Rewards Std                      1.49998
evaluation_0/Rewards Max                     11.004
evaluation_0/Rewards Min                     -0.609739
evaluation_0/Returns Mean                  4974.26
evaluation_0/Returns Std                    124.528
evaluation_0/Returns Max                   5150
evaluation_0/Returns Min                   4710.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4974.26
time/epoch (s)                                0
time/total (s)                             7922.78
Epoch                                       401
---------------------------------------  ----------------
2022-11-16 12:58:06.844795 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 402 finished
---------------------------------------  ----------------
epoch                                       402
total_step                               407000
replay_pool/size                         407000
trainer/alpha                                 0.0671498
trainer/alpha_loss                           -0.833315
trainer/entropy                              -5.69143
trainer/qf_loss                               8.58692
trainer/state_noise                           0.005
trainer/policy_loss                        -169.684
trainer/policy_loss_without_entropy         171.554
trainer/entropy_penalty                      -0.382178
trainer/entropy_percentage                   -0.00222775
trainer/Q1Pred Mean                         170.687
trainer/Q1Pred Std                           57.1169
trainer/Q1Pred Max                          263.856
trainer/Q1Pred Min                           -6.08582
trainer/Q2Pred Mean                         171.141
trainer/Q2Pred Std                           57.1819
trainer/Q2Pred Max                          264.888
trainer/Q2Pred Min                           -5.81325
trainer/QTargetWithReg Mean                 170.9
trainer/QTargetWithReg Std                   57.0696
trainer/QTargetWithReg Max                  263.657
trainer/QTargetWithReg Min                   -0.545258
trainer/PolicyLossWithoutReg Mean           171.554
trainer/PolicyLossWithoutReg Std             55.684
trainer/PolicyLossWithoutReg Max            263.212
trainer/PolicyLossWithoutReg Min             -1.37311
trainer/gradient_norm                       297.447
trainer/gradient_penalty                     -1.48723
trainer/gradient_percentage                  -0.00866921
exploration/num steps total              407000
exploration/num paths total                1563
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89485
exploration/Rewards Std                       1.42287
exploration/Rewards Max                      10.674
exploration/Rewards Min                      -0.642652
exploration/Returns Mean                   4894.85
exploration/Returns Std                       0
exploration/Returns Max                    4894.85
exploration/Returns Min                    4894.85
exploration/Num Paths                         1
exploration/Average Returns                4894.85
evaluation_0/num steps total                  3.14281e+06
evaluation_0/num paths total              10740
evaluation_0/path length Mean               981.75
evaluation_0/path length Std                 48.285
evaluation_0/path length Max               1000
evaluation_0/path length Min                854
evaluation_0/Rewards Mean                     4.98757
evaluation_0/Rewards Std                      1.44813
evaluation_0/Rewards Max                     10.9539
evaluation_0/Rewards Min                     -0.579229
evaluation_0/Returns Mean                  4896.55
evaluation_0/Returns Std                    245.275
evaluation_0/Returns Max                   5087.51
evaluation_0/Returns Min                   4257.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4896.55
time/epoch (s)                                0
time/total (s)                             7940.7
Epoch                                       402
---------------------------------------  ----------------
2022-11-16 12:58:22.720065 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 403 finished
---------------------------------------  ----------------
epoch                                       403
total_step                               408000
replay_pool/size                         408000
trainer/alpha                                 0.0675591
trainer/alpha_loss                            0.210019
trainer/entropy                              -6.07793
trainer/qf_loss                               7.90821
trainer/state_noise                           0.005
trainer/policy_loss                        -162.982
trainer/policy_loss_without_entropy         164.873
trainer/entropy_penalty                      -0.41062
trainer/entropy_percentage                   -0.00249052
trainer/Q1Pred Mean                         163.953
trainer/Q1Pred Std                           59.6411
trainer/Q1Pred Max                          270.757
trainer/Q1Pred Min                           -2.32906
trainer/Q2Pred Mean                         164.292
trainer/Q2Pred Std                           59.4065
trainer/Q2Pred Max                          270.753
trainer/Q2Pred Min                            5.6388
trainer/QTargetWithReg Mean                 163.674
trainer/QTargetWithReg Std                   59.1586
trainer/QTargetWithReg Max                  269.801
trainer/QTargetWithReg Min                    0.181041
trainer/PolicyLossWithoutReg Mean           164.873
trainer/PolicyLossWithoutReg Std             58.1896
trainer/PolicyLossWithoutReg Max            270.321
trainer/PolicyLossWithoutReg Min              8.02464
trainer/gradient_norm                       296.03
trainer/gradient_penalty                     -1.48015
trainer/gradient_percentage                  -0.00897751
exploration/num steps total              408000
exploration/num paths total                1564
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75748
exploration/Rewards Std                       1.39529
exploration/Rewards Max                      10.7848
exploration/Rewards Min                      -0.511073
exploration/Returns Mean                   4757.48
exploration/Returns Std                       0
exploration/Returns Max                    4757.48
exploration/Returns Min                    4757.48
exploration/Num Paths                         1
exploration/Average Returns                4757.48
evaluation_0/num steps total                  3.15081e+06
evaluation_0/num paths total              10748
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88605
evaluation_0/Rewards Std                      1.35883
evaluation_0/Rewards Max                     10.8662
evaluation_0/Rewards Min                     -0.566629
evaluation_0/Returns Mean                  4886.05
evaluation_0/Returns Std                     69.6708
evaluation_0/Returns Max                   4985.85
evaluation_0/Returns Min                   4799.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4886.05
time/epoch (s)                                0
time/total (s)                             7956.58
Epoch                                       403
---------------------------------------  ----------------
2022-11-16 12:58:39.105592 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 404 finished
---------------------------------------  ----------------
epoch                                       404
total_step                               409000
replay_pool/size                         409000
trainer/alpha                                 0.0669719
trainer/alpha_loss                            0.830603
trainer/entropy                              -6.30722
trainer/qf_loss                               9.76684
trainer/state_noise                           0.005
trainer/policy_loss                        -165.571
trainer/policy_loss_without_entropy         167.495
trainer/entropy_penalty                      -0.422406
trainer/entropy_percentage                   -0.0025219
trainer/Q1Pred Mean                         166.397
trainer/Q1Pred Std                           60.2563
trainer/Q1Pred Max                          270.495
trainer/Q1Pred Min                           -6.47575
trainer/Q2Pred Mean                         166.476
trainer/Q2Pred Std                           60.4093
trainer/Q2Pred Max                          272.106
trainer/Q2Pred Min                          -13.8994
trainer/QTargetWithReg Mean                 167.108
trainer/QTargetWithReg Std                   60.9044
trainer/QTargetWithReg Max                  273.071
trainer/QTargetWithReg Min                   -0.884752
trainer/PolicyLossWithoutReg Mean           167.495
trainer/PolicyLossWithoutReg Std             58.7647
trainer/PolicyLossWithoutReg Max            271.209
trainer/PolicyLossWithoutReg Min            -12.713
trainer/gradient_norm                       300.3
trainer/gradient_penalty                     -1.5015
trainer/gradient_percentage                  -0.00896443
exploration/num steps total              409000
exploration/num paths total                1565
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74731
exploration/Rewards Std                       1.43139
exploration/Rewards Max                      10.5686
exploration/Rewards Min                      -0.536761
exploration/Returns Mean                   4747.31
exploration/Returns Std                       0
exploration/Returns Max                    4747.31
exploration/Returns Min                    4747.31
exploration/Num Paths                         1
exploration/Average Returns                4747.31
evaluation_0/num steps total                  3.15881e+06
evaluation_0/num paths total              10756
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67701
evaluation_0/Rewards Std                      1.31953
evaluation_0/Rewards Max                     10.3817
evaluation_0/Rewards Min                     -0.600789
evaluation_0/Returns Mean                  4677.01
evaluation_0/Returns Std                     31.0534
evaluation_0/Returns Max                   4726.35
evaluation_0/Returns Min                   4629.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4677.01
time/epoch (s)                                0
time/total (s)                             7972.96
Epoch                                       404
---------------------------------------  ----------------
2022-11-16 12:58:55.055579 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 405 finished
---------------------------------------  ----------------
epoch                                       405
total_step                               410000
replay_pool/size                         410000
trainer/alpha                                 0.0668808
trainer/alpha_loss                            0.227026
trainer/entropy                              -6.08394
trainer/qf_loss                               5.53399
trainer/state_noise                           0.005
trainer/policy_loss                        -165.322
trainer/policy_loss_without_entropy         167.156
trainer/entropy_penalty                      -0.406899
trainer/entropy_percentage                   -0.00243425
trainer/Q1Pred Mean                         166.815
trainer/Q1Pred Std                           59.1193
trainer/Q1Pred Max                          262.755
trainer/Q1Pred Min                          -15.233
trainer/Q2Pred Mean                         166.303
trainer/Q2Pred Std                           59.2251
trainer/Q2Pred Max                          262.262
trainer/Q2Pred Min                          -19.2245
trainer/QTargetWithReg Mean                 166.85
trainer/QTargetWithReg Std                   59.4909
trainer/QTargetWithReg Max                  264.295
trainer/QTargetWithReg Min                  -12.0582
trainer/PolicyLossWithoutReg Mean           167.156
trainer/PolicyLossWithoutReg Std             58.7994
trainer/PolicyLossWithoutReg Max            262.545
trainer/PolicyLossWithoutReg Min            -17.0963
trainer/gradient_norm                       285.32
trainer/gradient_penalty                     -1.4266
trainer/gradient_percentage                  -0.00853454
exploration/num steps total              410000
exploration/num paths total                1566
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85262
exploration/Rewards Std                       1.367
exploration/Rewards Max                      10.6291
exploration/Rewards Min                      -0.552258
exploration/Returns Mean                   4852.62
exploration/Returns Std                       0
exploration/Returns Max                    4852.62
exploration/Returns Min                    4852.62
exploration/Num Paths                         1
exploration/Average Returns                4852.62
evaluation_0/num steps total                  3.16681e+06
evaluation_0/num paths total              10764
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86121
evaluation_0/Rewards Std                      1.408
evaluation_0/Rewards Max                     11.1799
evaluation_0/Rewards Min                     -0.573742
evaluation_0/Returns Mean                  4861.21
evaluation_0/Returns Std                     23.5353
evaluation_0/Returns Max                   4908.17
evaluation_0/Returns Min                   4820.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4861.21
time/epoch (s)                                0
time/total (s)                             7988.91
Epoch                                       405
---------------------------------------  ----------------
2022-11-16 12:59:10.891688 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 406 finished
---------------------------------------  ----------------
epoch                                       406
total_step                               411000
replay_pool/size                         411000
trainer/alpha                                 0.067487
trainer/alpha_loss                           -0.462274
trainer/entropy                              -5.82852
trainer/qf_loss                               7.47301
trainer/state_noise                           0.005
trainer/policy_loss                        -162.613
trainer/policy_loss_without_entropy         164.433
trainer/entropy_penalty                      -0.393349
trainer/entropy_percentage                   -0.00239215
trainer/Q1Pred Mean                         163.427
trainer/Q1Pred Std                           59.9214
trainer/Q1Pred Max                          274.646
trainer/Q1Pred Min                          -33.2917
trainer/Q2Pred Mean                         163.881
trainer/Q2Pred Std                           60.1635
trainer/Q2Pred Max                          275.582
trainer/Q2Pred Min                          -30.9912
trainer/QTargetWithReg Mean                 163.561
trainer/QTargetWithReg Std                   60.1217
trainer/QTargetWithReg Max                  275.535
trainer/QTargetWithReg Min                  -29.2155
trainer/PolicyLossWithoutReg Mean           164.433
trainer/PolicyLossWithoutReg Std             59.5034
trainer/PolicyLossWithoutReg Max            274.189
trainer/PolicyLossWithoutReg Min            -26.0149
trainer/gradient_norm                       285.394
trainer/gradient_penalty                     -1.42697
trainer/gradient_percentage                  -0.00867811
exploration/num steps total              411000
exploration/num paths total                1567
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72464
exploration/Rewards Std                       1.38706
exploration/Rewards Max                      10.8826
exploration/Rewards Min                      -0.542075
exploration/Returns Mean                   4724.64
exploration/Returns Std                       0
exploration/Returns Max                    4724.64
exploration/Returns Min                    4724.64
exploration/Num Paths                         1
exploration/Average Returns                4724.64
evaluation_0/num steps total                  3.17481e+06
evaluation_0/num paths total              10772
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85458
evaluation_0/Rewards Std                      1.30821
evaluation_0/Rewards Max                     10.5063
evaluation_0/Rewards Min                     -0.510346
evaluation_0/Returns Mean                  4854.58
evaluation_0/Returns Std                     57.1656
evaluation_0/Returns Max                   4916.56
evaluation_0/Returns Min                   4724.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4854.58
time/epoch (s)                                0
time/total (s)                             8004.75
Epoch                                       406
---------------------------------------  ----------------
2022-11-16 12:59:27.364463 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 407 finished
---------------------------------------  ----------------
epoch                                       407
total_step                               412000
replay_pool/size                         412000
trainer/alpha                                 0.0673231
trainer/alpha_loss                            0.0091142
trainer/entropy                              -6.00338
trainer/qf_loss                               7.71343
trainer/state_noise                           0.005
trainer/policy_loss                        -162.058
trainer/policy_loss_without_entropy         163.957
trainer/entropy_penalty                      -0.404166
trainer/entropy_percentage                   -0.00246507
trainer/Q1Pred Mean                         163.31
trainer/Q1Pred Std                           65.2063
trainer/Q1Pred Max                          268.667
trainer/Q1Pred Min                          -50.2942
trainer/Q2Pred Mean                         163.044
trainer/Q2Pred Std                           65.3115
trainer/Q2Pred Max                          269.851
trainer/Q2Pred Min                          -50.2778
trainer/QTargetWithReg Mean                 162.734
trainer/QTargetWithReg Std                   65.4669
trainer/QTargetWithReg Max                  269.727
trainer/QTargetWithReg Min                  -63.781
trainer/PolicyLossWithoutReg Mean           163.957
trainer/PolicyLossWithoutReg Std             64.4982
trainer/PolicyLossWithoutReg Max            267.49
trainer/PolicyLossWithoutReg Min            -52.6236
trainer/gradient_norm                       299.111
trainer/gradient_penalty                     -1.49555
trainer/gradient_percentage                  -0.0091216
exploration/num steps total              412000
exploration/num paths total                1568
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75434
exploration/Rewards Std                       1.32203
exploration/Rewards Max                      10.5161
exploration/Rewards Min                      -0.479292
exploration/Returns Mean                   4754.34
exploration/Returns Std                       0
exploration/Returns Max                    4754.34
exploration/Returns Min                    4754.34
exploration/Num Paths                         1
exploration/Average Returns                4754.34
evaluation_0/num steps total                  3.18281e+06
evaluation_0/num paths total              10780
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91087
evaluation_0/Rewards Std                      1.36009
evaluation_0/Rewards Max                     10.8487
evaluation_0/Rewards Min                     -0.495634
evaluation_0/Returns Mean                  4910.87
evaluation_0/Returns Std                     51.2961
evaluation_0/Returns Max                   4997.29
evaluation_0/Returns Min                   4824.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4910.87
time/epoch (s)                                0
time/total (s)                             8021.22
Epoch                                       407
---------------------------------------  ----------------
2022-11-16 12:59:43.158158 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 408 finished
---------------------------------------  ----------------
epoch                                       408
total_step                               413000
replay_pool/size                         413000
trainer/alpha                                 0.0675763
trainer/alpha_loss                            1.36337
trainer/entropy                              -6.50596
trainer/qf_loss                               8.39994
trainer/state_noise                           0.005
trainer/policy_loss                        -169.877
trainer/policy_loss_without_entropy         171.834
trainer/entropy_penalty                      -0.439649
trainer/entropy_percentage                   -0.00255856
trainer/Q1Pred Mean                         171.076
trainer/Q1Pred Std                           60.1591
trainer/Q1Pred Max                          270.993
trainer/Q1Pred Min                           11.3218
trainer/Q2Pred Mean                         171.01
trainer/Q2Pred Std                           59.9847
trainer/Q2Pred Max                          270.537
trainer/Q2Pred Min                           11.8669
trainer/QTargetWithReg Mean                 171.37
trainer/QTargetWithReg Std                   60.1751
trainer/QTargetWithReg Max                  270.774
trainer/QTargetWithReg Min                    5.04232
trainer/PolicyLossWithoutReg Mean           171.834
trainer/PolicyLossWithoutReg Std             59.2715
trainer/PolicyLossWithoutReg Max            269.258
trainer/PolicyLossWithoutReg Min             13.1687
trainer/gradient_norm                       303.483
trainer/gradient_penalty                     -1.51742
trainer/gradient_percentage                  -0.00883071
exploration/num steps total              413000
exploration/num paths total                1569
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73865
exploration/Rewards Std                       1.3251
exploration/Rewards Max                      10.6333
exploration/Rewards Min                      -0.430069
exploration/Returns Mean                   4738.65
exploration/Returns Std                       0
exploration/Returns Max                    4738.65
exploration/Returns Min                    4738.65
exploration/Num Paths                         1
exploration/Average Returns                4738.65
evaluation_0/num steps total                  3.19081e+06
evaluation_0/num paths total              10788
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87173
evaluation_0/Rewards Std                      1.34175
evaluation_0/Rewards Max                     10.4975
evaluation_0/Rewards Min                     -0.571557
evaluation_0/Returns Mean                  4871.73
evaluation_0/Returns Std                     29.8658
evaluation_0/Returns Max                   4903.65
evaluation_0/Returns Min                   4829.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4871.73
time/epoch (s)                                0
time/total (s)                             8037.01
Epoch                                       408
---------------------------------------  ----------------
2022-11-16 12:59:59.585556 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 409 finished
---------------------------------------  ----------------
epoch                                       409
total_step                               414000
replay_pool/size                         414000
trainer/alpha                                 0.069
trainer/alpha_loss                           -0.684578
trainer/entropy                              -5.74395
trainer/qf_loss                               7.67441
trainer/state_noise                           0.005
trainer/policy_loss                        -167.777
trainer/policy_loss_without_entropy         169.652
trainer/entropy_penalty                      -0.396332
trainer/entropy_percentage                   -0.00233614
trainer/Q1Pred Mean                         168.897
trainer/Q1Pred Std                           62.6594
trainer/Q1Pred Max                          271.85
trainer/Q1Pred Min                            5.95946
trainer/Q2Pred Mean                         168.688
trainer/Q2Pred Std                           62.5359
trainer/Q2Pred Max                          271.295
trainer/Q2Pred Min                            1.60535
trainer/QTargetWithReg Mean                 169.133
trainer/QTargetWithReg Std                   62.7861
trainer/QTargetWithReg Max                  273.742
trainer/QTargetWithReg Min                   -1.23575
trainer/PolicyLossWithoutReg Mean           169.652
trainer/PolicyLossWithoutReg Std             61.8824
trainer/PolicyLossWithoutReg Max            270.43
trainer/PolicyLossWithoutReg Min              4.98772
trainer/gradient_norm                       295.789
trainer/gradient_penalty                     -1.47894
trainer/gradient_percentage                  -0.00871749
exploration/num steps total              414000
exploration/num paths total                1570
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76233
exploration/Rewards Std                       1.38178
exploration/Rewards Max                      10.6222
exploration/Rewards Min                      -0.59249
exploration/Returns Mean                   4762.33
exploration/Returns Std                       0
exploration/Returns Max                    4762.33
exploration/Returns Min                    4762.33
exploration/Num Paths                         1
exploration/Average Returns                4762.33
evaluation_0/num steps total                  3.19881e+06
evaluation_0/num paths total              10796
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96714
evaluation_0/Rewards Std                      1.43166
evaluation_0/Rewards Max                     10.4933
evaluation_0/Rewards Min                     -0.455159
evaluation_0/Returns Mean                  4967.14
evaluation_0/Returns Std                     26.7684
evaluation_0/Returns Max                   5000.14
evaluation_0/Returns Min                   4929.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4967.14
time/epoch (s)                                0
time/total (s)                             8053.44
Epoch                                       409
---------------------------------------  ----------------
2022-11-16 13:00:15.450544 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 410 finished
---------------------------------------  ----------------
epoch                                       410
total_step                               415000
replay_pool/size                         415000
trainer/alpha                                 0.0678579
trainer/alpha_loss                            0.25084
trainer/entropy                              -6.09323
trainer/qf_loss                               9.02468
trainer/state_noise                           0.005
trainer/policy_loss                        -165.95
trainer/policy_loss_without_entropy         167.834
trainer/entropy_penalty                      -0.413474
trainer/entropy_percentage                   -0.00246359
trainer/Q1Pred Mean                         167.346
trainer/Q1Pred Std                           63.8956
trainer/Q1Pred Max                          272.544
trainer/Q1Pred Min                           -3.0651
trainer/Q2Pred Mean                         167.103
trainer/Q2Pred Std                           64.3234
trainer/Q2Pred Max                          272.45
trainer/Q2Pred Min                          -21.272
trainer/QTargetWithReg Mean                 167.609
trainer/QTargetWithReg Std                   64.3782
trainer/QTargetWithReg Max                  272.212
trainer/QTargetWithReg Min                  -22.7519
trainer/PolicyLossWithoutReg Mean           167.834
trainer/PolicyLossWithoutReg Std             63.7438
trainer/PolicyLossWithoutReg Max            272.462
trainer/PolicyLossWithoutReg Min             -0.306498
trainer/gradient_norm                       294.115
trainer/gradient_penalty                     -1.47058
trainer/gradient_percentage                  -0.00876208
exploration/num steps total              415000
exploration/num paths total                1571
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77785
exploration/Rewards Std                       1.34637
exploration/Rewards Max                      10.4304
exploration/Rewards Min                      -0.534039
exploration/Returns Mean                   4777.85
exploration/Returns Std                       0
exploration/Returns Max                    4777.85
exploration/Returns Min                    4777.85
exploration/Num Paths                         1
exploration/Average Returns                4777.85
evaluation_0/num steps total                  3.20681e+06
evaluation_0/num paths total              10804
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7662
evaluation_0/Rewards Std                      1.36064
evaluation_0/Rewards Max                     10.4102
evaluation_0/Rewards Min                     -0.576436
evaluation_0/Returns Mean                  4766.2
evaluation_0/Returns Std                     35.0608
evaluation_0/Returns Max                   4846.49
evaluation_0/Returns Min                   4721.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4766.2
time/epoch (s)                                0
time/total (s)                             8069.3
Epoch                                       410
---------------------------------------  ----------------
2022-11-16 13:00:31.474748 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 411 finished
---------------------------------------  ----------------
epoch                                       411
total_step                               416000
replay_pool/size                         416000
trainer/alpha                                 0.0690677
trainer/alpha_loss                           -0.390778
trainer/entropy                              -5.85378
trainer/qf_loss                               8.52272
trainer/state_noise                           0.005
trainer/policy_loss                        -168.044
trainer/policy_loss_without_entropy         170.004
trainer/entropy_penalty                      -0.404307
trainer/entropy_percentage                   -0.00237822
trainer/Q1Pred Mean                         168.453
trainer/Q1Pred Std                           59.3797
trainer/Q1Pred Max                          276.319
trainer/Q1Pred Min                            5.97482
trainer/Q2Pred Mean                         168.87
trainer/Q2Pred Std                           59.5564
trainer/Q2Pred Max                          275.919
trainer/Q2Pred Min                            6.7243
trainer/QTargetWithReg Mean                 169.453
trainer/QTargetWithReg Std                   59.7875
trainer/QTargetWithReg Max                  279.018
trainer/QTargetWithReg Min                    7.04805
trainer/PolicyLossWithoutReg Mean           170.004
trainer/PolicyLossWithoutReg Std             58.7944
trainer/PolicyLossWithoutReg Max            276.911
trainer/PolicyLossWithoutReg Min              6.36074
trainer/gradient_norm                       311.067
trainer/gradient_penalty                     -1.55533
trainer/gradient_percentage                  -0.0091488
exploration/num steps total              416000
exploration/num paths total                1572
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80454
exploration/Rewards Std                       1.31451
exploration/Rewards Max                      10.4597
exploration/Rewards Min                      -0.495912
exploration/Returns Mean                   4804.54
exploration/Returns Std                       0
exploration/Returns Max                    4804.54
exploration/Returns Min                    4804.54
exploration/Num Paths                         1
exploration/Average Returns                4804.54
evaluation_0/num steps total                  3.21481e+06
evaluation_0/num paths total              10812
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03623
evaluation_0/Rewards Std                      1.38814
evaluation_0/Rewards Max                     11.2995
evaluation_0/Rewards Min                     -0.509723
evaluation_0/Returns Mean                  5036.23
evaluation_0/Returns Std                     33.0817
evaluation_0/Returns Max                   5109.92
evaluation_0/Returns Min                   4993.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5036.23
time/epoch (s)                                0
time/total (s)                             8085.33
Epoch                                       411
---------------------------------------  ----------------
2022-11-16 13:00:47.662399 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 412 finished
---------------------------------------  ----------------
epoch                                       412
total_step                               417000
replay_pool/size                         417000
trainer/alpha                                 0.0692008
trainer/alpha_loss                           -0.0781796
trainer/entropy                              -5.97073
trainer/qf_loss                               9.13871
trainer/state_noise                           0.005
trainer/policy_loss                        -169.946
trainer/policy_loss_without_entropy         171.856
trainer/entropy_penalty                      -0.413179
trainer/entropy_percentage                   -0.00240421
trainer/Q1Pred Mean                         171.04
trainer/Q1Pred Std                           60.768
trainer/Q1Pred Max                          268.775
trainer/Q1Pred Min                          -14.7426
trainer/Q2Pred Mean                         170.645
trainer/Q2Pred Std                           60.6136
trainer/Q2Pred Max                          267.335
trainer/Q2Pred Min                          -26.9841
trainer/QTargetWithReg Mean                 170.606
trainer/QTargetWithReg Std                   60.5112
trainer/QTargetWithReg Max                  269.054
trainer/QTargetWithReg Min                  -18.8627
trainer/PolicyLossWithoutReg Mean           171.856
trainer/PolicyLossWithoutReg Std             59.7902
trainer/PolicyLossWithoutReg Max            267.714
trainer/PolicyLossWithoutReg Min            -13.9651
trainer/gradient_norm                       299.414
trainer/gradient_penalty                     -1.49707
trainer/gradient_percentage                  -0.00871119
exploration/num steps total              417000
exploration/num paths total                1573
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6979
exploration/Rewards Std                       1.31463
exploration/Rewards Max                      10.5868
exploration/Rewards Min                      -0.439881
exploration/Returns Mean                   4697.9
exploration/Returns Std                       0
exploration/Returns Max                    4697.9
exploration/Returns Min                    4697.9
exploration/Num Paths                         1
exploration/Average Returns                4697.9
evaluation_0/num steps total                  3.22281e+06
evaluation_0/num paths total              10820
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58891
evaluation_0/Rewards Std                      1.27555
evaluation_0/Rewards Max                     10.4372
evaluation_0/Rewards Min                     -0.551817
evaluation_0/Returns Mean                  4588.91
evaluation_0/Returns Std                     49.7965
evaluation_0/Returns Max                   4654.02
evaluation_0/Returns Min                   4505.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4588.91
time/epoch (s)                                0
time/total (s)                             8101.51
Epoch                                       412
---------------------------------------  ----------------
2022-11-16 13:01:03.539746 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 413 finished
---------------------------------------  ----------------
epoch                                       413
total_step                               418000
replay_pool/size                         418000
trainer/alpha                                 0.0693054
trainer/alpha_loss                            0.347721
trainer/entropy                              -6.13027
trainer/qf_loss                               6.71589
trainer/state_noise                           0.005
trainer/policy_loss                        -165.411
trainer/policy_loss_without_entropy         167.293
trainer/entropy_penalty                      -0.424861
trainer/entropy_percentage                   -0.00253962
trainer/Q1Pred Mean                         166.909
trainer/Q1Pred Std                           61.2292
trainer/Q1Pred Max                          270.601
trainer/Q1Pred Min                           -1.28191
trainer/Q2Pred Mean                         166.693
trainer/Q2Pred Std                           61.3745
trainer/Q2Pred Max                          270.649
trainer/Q2Pred Min                           -1.34976
trainer/QTargetWithReg Mean                 166.246
trainer/QTargetWithReg Std                   61.4002
trainer/QTargetWithReg Max                  270.447
trainer/QTargetWithReg Min                   -9.5833
trainer/PolicyLossWithoutReg Mean           167.293
trainer/PolicyLossWithoutReg Std             60.59
trainer/PolicyLossWithoutReg Max            270.226
trainer/PolicyLossWithoutReg Min              0.626438
trainer/gradient_norm                       291.574
trainer/gradient_penalty                     -1.45787
trainer/gradient_percentage                  -0.00871445
exploration/num steps total              418000
exploration/num paths total                1574
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84183
exploration/Rewards Std                       1.36404
exploration/Rewards Max                      10.6969
exploration/Rewards Min                      -0.587942
exploration/Returns Mean                   4841.83
exploration/Returns Std                       0
exploration/Returns Max                    4841.83
exploration/Returns Min                    4841.83
exploration/Num Paths                         1
exploration/Average Returns                4841.83
evaluation_0/num steps total                  3.23081e+06
evaluation_0/num paths total              10828
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81618
evaluation_0/Rewards Std                      1.40814
evaluation_0/Rewards Max                     10.792
evaluation_0/Rewards Min                     -0.577421
evaluation_0/Returns Mean                  4816.18
evaluation_0/Returns Std                     38.6473
evaluation_0/Returns Max                   4858.22
evaluation_0/Returns Min                   4725.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4816.18
time/epoch (s)                                0
time/total (s)                             8117.39
Epoch                                       413
---------------------------------------  ----------------
2022-11-16 13:01:19.965083 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 414 finished
---------------------------------------  ----------------
epoch                                       414
total_step                               419000
replay_pool/size                         419000
trainer/alpha                                 0.0686356
trainer/alpha_loss                           -0.314744
trainer/entropy                              -5.88252
trainer/qf_loss                               6.65805
trainer/state_noise                           0.005
trainer/policy_loss                        -171.992
trainer/policy_loss_without_entropy         173.854
trainer/entropy_penalty                      -0.403751
trainer/entropy_percentage                   -0.00232236
trainer/Q1Pred Mean                         173.017
trainer/Q1Pred Std                           56.9165
trainer/Q1Pred Max                          279.608
trainer/Q1Pred Min                           15.9108
trainer/Q2Pred Mean                         172.781
trainer/Q2Pred Std                           57.4543
trainer/Q2Pred Max                          280.557
trainer/Q2Pred Min                           14.6836
trainer/QTargetWithReg Mean                 172.825
trainer/QTargetWithReg Std                   56.8164
trainer/QTargetWithReg Max                  278.938
trainer/QTargetWithReg Min                   16.6263
trainer/PolicyLossWithoutReg Mean           173.854
trainer/PolicyLossWithoutReg Std             56.8438
trainer/PolicyLossWithoutReg Max            279.917
trainer/PolicyLossWithoutReg Min             14.9146
trainer/gradient_norm                       291.511
trainer/gradient_penalty                     -1.45756
trainer/gradient_percentage                  -0.00838381
exploration/num steps total              419000
exploration/num paths total                1575
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70626
exploration/Rewards Std                       1.34446
exploration/Rewards Max                      10.4184
exploration/Rewards Min                      -0.532693
exploration/Returns Mean                   4706.26
exploration/Returns Std                       0
exploration/Returns Max                    4706.26
exploration/Returns Min                    4706.26
exploration/Num Paths                         1
exploration/Average Returns                4706.26
evaluation_0/num steps total                  3.23881e+06
evaluation_0/num paths total              10836
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98979
evaluation_0/Rewards Std                      1.3866
evaluation_0/Rewards Max                     10.9092
evaluation_0/Rewards Min                     -0.590689
evaluation_0/Returns Mean                  4989.79
evaluation_0/Returns Std                     34.5028
evaluation_0/Returns Max                   5033.5
evaluation_0/Returns Min                   4930.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4989.79
time/epoch (s)                                0
time/total (s)                             8133.82
Epoch                                       414
---------------------------------------  ----------------
2022-11-16 13:01:35.806129 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 415 finished
---------------------------------------  ----------------
epoch                                       415
total_step                               420000
replay_pool/size                         420000
trainer/alpha                                 0.0692574
trainer/alpha_loss                            0.824359
trainer/entropy                              -6.30876
trainer/qf_loss                               6.71882
trainer/state_noise                           0.005
trainer/policy_loss                        -176.927
trainer/policy_loss_without_entropy         178.902
trainer/entropy_penalty                      -0.436928
trainer/entropy_percentage                   -0.00244227
trainer/Q1Pred Mean                         178.036
trainer/Q1Pred Std                           59.5912
trainer/Q1Pred Max                          272.833
trainer/Q1Pred Min                           -2.72344
trainer/Q2Pred Mean                         177.262
trainer/Q2Pred Std                           59.6871
trainer/Q2Pred Max                          270.079
trainer/Q2Pred Min                           -7.60572
trainer/QTargetWithReg Mean                 177.493
trainer/QTargetWithReg Std                   59.5217
trainer/QTargetWithReg Max                  271.447
trainer/QTargetWithReg Min                   -0.298071
trainer/PolicyLossWithoutReg Mean           178.902
trainer/PolicyLossWithoutReg Std             57.9115
trainer/PolicyLossWithoutReg Max            271.864
trainer/PolicyLossWithoutReg Min             14.3961
trainer/gradient_norm                       307.676
trainer/gradient_penalty                     -1.53838
trainer/gradient_percentage                  -0.00859899
exploration/num steps total              420000
exploration/num paths total                1576
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80701
exploration/Rewards Std                       1.32223
exploration/Rewards Max                      10.4766
exploration/Rewards Min                      -0.502592
exploration/Returns Mean                   4807.01
exploration/Returns Std                       0
exploration/Returns Max                    4807.01
exploration/Returns Min                    4807.01
exploration/Num Paths                         1
exploration/Average Returns                4807.01
evaluation_0/num steps total                  3.24681e+06
evaluation_0/num paths total              10844
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88099
evaluation_0/Rewards Std                      1.36417
evaluation_0/Rewards Max                     10.5278
evaluation_0/Rewards Min                     -0.425811
evaluation_0/Returns Mean                  4880.99
evaluation_0/Returns Std                     30.7097
evaluation_0/Returns Max                   4949.53
evaluation_0/Returns Min                   4855.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4880.99
time/epoch (s)                                0
time/total (s)                             8149.66
Epoch                                       415
---------------------------------------  ----------------
2022-11-16 13:01:52.327443 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 416 finished
---------------------------------------  ----------------
epoch                                       416
total_step                               421000
replay_pool/size                         421000
trainer/alpha                                 0.0681217
trainer/alpha_loss                           -0.0712974
trainer/entropy                              -5.97346
trainer/qf_loss                               6.7748
trainer/state_noise                           0.005
trainer/policy_loss                        -168.603
trainer/policy_loss_without_entropy         170.475
trainer/entropy_penalty                      -0.406922
trainer/entropy_percentage                   -0.00238699
trainer/Q1Pred Mean                         169.004
trainer/Q1Pred Std                           60.3723
trainer/Q1Pred Max                          274.192
trainer/Q1Pred Min                          -10.2191
trainer/Q2Pred Mean                         169.198
trainer/Q2Pred Std                           60.2439
trainer/Q2Pred Max                          272.956
trainer/Q2Pred Min                           -8.30712
trainer/QTargetWithReg Mean                 169.211
trainer/QTargetWithReg Std                   60.2527
trainer/QTargetWithReg Max                  274.221
trainer/QTargetWithReg Min                    0.381953
trainer/PolicyLossWithoutReg Mean           170.475
trainer/PolicyLossWithoutReg Std             58.8449
trainer/PolicyLossWithoutReg Max            273.063
trainer/PolicyLossWithoutReg Min              4.8215
trainer/gradient_norm                       292.973
trainer/gradient_penalty                     -1.46487
trainer/gradient_percentage                  -0.00859286
exploration/num steps total              421000
exploration/num paths total                1577
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85766
exploration/Rewards Std                       1.37666
exploration/Rewards Max                      10.6278
exploration/Rewards Min                      -0.407387
exploration/Returns Mean                   4857.66
exploration/Returns Std                       0
exploration/Returns Max                    4857.66
exploration/Returns Min                    4857.66
exploration/Num Paths                         1
exploration/Average Returns                4857.66
evaluation_0/num steps total                  3.25481e+06
evaluation_0/num paths total              10852
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57725
evaluation_0/Rewards Std                      1.31914
evaluation_0/Rewards Max                     10.3787
evaluation_0/Rewards Min                     -0.501831
evaluation_0/Returns Mean                  4577.25
evaluation_0/Returns Std                     42.5268
evaluation_0/Returns Max                   4647.33
evaluation_0/Returns Min                   4537.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4577.25
time/epoch (s)                                0
time/total (s)                             8166.18
Epoch                                       416
---------------------------------------  ----------------
2022-11-16 13:02:08.129336 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 417 finished
---------------------------------------  ----------------
epoch                                       417
total_step                               422000
replay_pool/size                         422000
trainer/alpha                                 0.0687009
trainer/alpha_loss                           -1.59247
trainer/entropy                              -5.40531
trainer/qf_loss                               7.66364
trainer/state_noise                           0.005
trainer/policy_loss                        -169.173
trainer/policy_loss_without_entropy         171.015
trainer/entropy_penalty                      -0.37135
trainer/entropy_percentage                   -0.00217144
trainer/Q1Pred Mean                         170.449
trainer/Q1Pred Std                           61.2177
trainer/Q1Pred Max                          263.667
trainer/Q1Pred Min                            7.75137
trainer/Q2Pred Mean                         170.432
trainer/Q2Pred Std                           61.2165
trainer/Q2Pred Max                          264.419
trainer/Q2Pred Min                            6.97103
trainer/QTargetWithReg Mean                 170.448
trainer/QTargetWithReg Std                   61.1887
trainer/QTargetWithReg Max                  264.18
trainer/QTargetWithReg Min                    7.68318
trainer/PolicyLossWithoutReg Mean           171.015
trainer/PolicyLossWithoutReg Std             60.5663
trainer/PolicyLossWithoutReg Max            263.889
trainer/PolicyLossWithoutReg Min              7.39145
trainer/gradient_norm                       294.129
trainer/gradient_penalty                     -1.47064
trainer/gradient_percentage                  -0.00859949
exploration/num steps total              422000
exploration/num paths total                1578
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76834
exploration/Rewards Std                       1.29518
exploration/Rewards Max                      10.4555
exploration/Rewards Min                      -0.576535
exploration/Returns Mean                   4768.34
exploration/Returns Std                       0
exploration/Returns Max                    4768.34
exploration/Returns Min                    4768.34
exploration/Num Paths                         1
exploration/Average Returns                4768.34
evaluation_0/num steps total                  3.26281e+06
evaluation_0/num paths total              10860
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86417
evaluation_0/Rewards Std                      1.33666
evaluation_0/Rewards Max                     10.6601
evaluation_0/Rewards Min                     -0.466641
evaluation_0/Returns Mean                  4864.17
evaluation_0/Returns Std                     46.2458
evaluation_0/Returns Max                   4914.15
evaluation_0/Returns Min                   4773.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4864.17
time/epoch (s)                                0
time/total (s)                             8181.98
Epoch                                       417
---------------------------------------  ----------------
2022-11-16 13:02:24.574216 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 418 finished
---------------------------------------  ----------------
epoch                                       418
total_step                               423000
replay_pool/size                         423000
trainer/alpha                                 0.0678343
trainer/alpha_loss                           -0.0486596
trainer/entropy                              -5.98192
trainer/qf_loss                               8.87364
trainer/state_noise                           0.005
trainer/policy_loss                        -174.294
trainer/policy_loss_without_entropy         176.208
trainer/entropy_penalty                      -0.405779
trainer/entropy_percentage                   -0.00230284
trainer/Q1Pred Mean                         175.027
trainer/Q1Pred Std                           55.5799
trainer/Q1Pred Max                          273.203
trainer/Q1Pred Min                           -9.32639
trainer/Q2Pred Mean                         175.342
trainer/Q2Pred Std                           55.6733
trainer/Q2Pred Max                          271.45
trainer/Q2Pred Min                          -13.0812
trainer/QTargetWithReg Mean                 175.352
trainer/QTargetWithReg Std                   56.0708
trainer/QTargetWithReg Max                  275.334
trainer/QTargetWithReg Min                  -11.8922
trainer/PolicyLossWithoutReg Mean           176.208
trainer/PolicyLossWithoutReg Std             54.7643
trainer/PolicyLossWithoutReg Max            269.55
trainer/PolicyLossWithoutReg Min            -13.4786
trainer/gradient_norm                       301.755
trainer/gradient_penalty                     -1.50877
trainer/gradient_percentage                  -0.00856244
exploration/num steps total              423000
exploration/num paths total                1579
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8646
exploration/Rewards Std                       1.32224
exploration/Rewards Max                      10.4448
exploration/Rewards Min                      -0.588847
exploration/Returns Mean                   4864.6
exploration/Returns Std                       0
exploration/Returns Max                    4864.6
exploration/Returns Min                    4864.6
exploration/Num Paths                         1
exploration/Average Returns                4864.6
evaluation_0/num steps total                  3.27081e+06
evaluation_0/num paths total              10868
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76405
evaluation_0/Rewards Std                      1.32008
evaluation_0/Rewards Max                     10.6232
evaluation_0/Rewards Min                     -0.435256
evaluation_0/Returns Mean                  4764.05
evaluation_0/Returns Std                     60.889
evaluation_0/Returns Max                   4854.58
evaluation_0/Returns Min                   4667.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4764.05
time/epoch (s)                                0
time/total (s)                             8198.42
Epoch                                       418
---------------------------------------  ----------------
2022-11-16 13:02:40.342727 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 419 finished
---------------------------------------  ----------------
epoch                                       419
total_step                               424000
replay_pool/size                         424000
trainer/alpha                                 0.0666049
trainer/alpha_loss                            0.264753
trainer/entropy                              -6.09773
trainer/qf_loss                               8.08844
trainer/state_noise                           0.005
trainer/policy_loss                        -173.883
trainer/policy_loss_without_entropy         175.788
trainer/entropy_penalty                      -0.406138
trainer/entropy_percentage                   -0.00231039
trainer/Q1Pred Mean                         174.871
trainer/Q1Pred Std                           56.3955
trainer/Q1Pred Max                          271.782
trainer/Q1Pred Min                            5.43091
trainer/Q2Pred Mean                         175.046
trainer/Q2Pred Std                           56.5086
trainer/Q2Pred Max                          273.572
trainer/Q2Pred Min                            4.90767
trainer/QTargetWithReg Mean                 174.622
trainer/QTargetWithReg Std                   56.8235
trainer/QTargetWithReg Max                  271.987
trainer/QTargetWithReg Min                    5.35706
trainer/PolicyLossWithoutReg Mean           175.788
trainer/PolicyLossWithoutReg Std             56.1103
trainer/PolicyLossWithoutReg Max            270.507
trainer/PolicyLossWithoutReg Min              4.93596
trainer/gradient_norm                       299.654
trainer/gradient_penalty                     -1.49827
trainer/gradient_percentage                  -0.00852318
exploration/num steps total              424000
exploration/num paths total                1580
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86781
exploration/Rewards Std                       1.39634
exploration/Rewards Max                      10.8922
exploration/Rewards Min                      -0.376591
exploration/Returns Mean                   4867.81
exploration/Returns Std                       0
exploration/Returns Max                    4867.81
exploration/Returns Min                    4867.81
exploration/Num Paths                         1
exploration/Average Returns                4867.81
evaluation_0/num steps total                  3.27881e+06
evaluation_0/num paths total              10876
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73361
evaluation_0/Rewards Std                      1.28089
evaluation_0/Rewards Max                     10.3827
evaluation_0/Rewards Min                     -0.589837
evaluation_0/Returns Mean                  4733.61
evaluation_0/Returns Std                     68.0409
evaluation_0/Returns Max                   4835.53
evaluation_0/Returns Min                   4639.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4733.61
time/epoch (s)                                0
time/total (s)                             8214.19
Epoch                                       419
---------------------------------------  ----------------
2022-11-16 13:02:56.429251 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 420 finished
---------------------------------------  ----------------
epoch                                       420
total_step                               425000
replay_pool/size                         425000
trainer/alpha                                 0.0693325
trainer/alpha_loss                           -0.613863
trainer/entropy                              -5.77
trainer/qf_loss                               7.23898
trainer/state_noise                           0.005
trainer/policy_loss                        -173.537
trainer/policy_loss_without_entropy         175.525
trainer/entropy_penalty                      -0.400049
trainer/entropy_percentage                   -0.00227915
trainer/Q1Pred Mean                         174.197
trainer/Q1Pred Std                           57.038
trainer/Q1Pred Max                          276.049
trainer/Q1Pred Min                           16.9387
trainer/Q2Pred Mean                         174.346
trainer/Q2Pred Std                           57.3307
trainer/Q2Pred Max                          274.262
trainer/Q2Pred Min                           12.1018
trainer/QTargetWithReg Mean                 174.843
trainer/QTargetWithReg Std                   57.1717
trainer/QTargetWithReg Max                  274.892
trainer/QTargetWithReg Min                   12.1331
trainer/PolicyLossWithoutReg Mean           175.525
trainer/PolicyLossWithoutReg Std             56.6396
trainer/PolicyLossWithoutReg Max            274.918
trainer/PolicyLossWithoutReg Min             19.2258
trainer/gradient_norm                       317.597
trainer/gradient_penalty                     -1.58798
trainer/gradient_percentage                  -0.00904704
exploration/num steps total              425000
exploration/num paths total                1581
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77622
exploration/Rewards Std                       1.3233
exploration/Rewards Max                      10.325
exploration/Rewards Min                      -0.542237
exploration/Returns Mean                   4776.22
exploration/Returns Std                       0
exploration/Returns Max                    4776.22
exploration/Returns Min                    4776.22
exploration/Num Paths                         1
exploration/Average Returns                4776.22
evaluation_0/num steps total                  3.28681e+06
evaluation_0/num paths total              10884
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86181
evaluation_0/Rewards Std                      1.29394
evaluation_0/Rewards Max                     10.3909
evaluation_0/Rewards Min                     -0.633054
evaluation_0/Returns Mean                  4861.81
evaluation_0/Returns Std                      8.95303
evaluation_0/Returns Max                   4874.13
evaluation_0/Returns Min                   4848.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4861.81
time/epoch (s)                                0
time/total (s)                             8230.28
Epoch                                       420
---------------------------------------  ----------------
2022-11-16 13:03:12.463346 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 421 finished
---------------------------------------  ----------------
epoch                                       421
total_step                               426000
replay_pool/size                         426000
trainer/alpha                                 0.0696021
trainer/alpha_loss                            0.696414
trainer/entropy                              -6.26134
trainer/qf_loss                               6.21203
trainer/state_noise                           0.005
trainer/policy_loss                        -170.193
trainer/policy_loss_without_entropy         172.138
trainer/entropy_penalty                      -0.435802
trainer/entropy_percentage                   -0.0025317
trainer/Q1Pred Mean                         171.011
trainer/Q1Pred Std                           61.2521
trainer/Q1Pred Max                          272.514
trainer/Q1Pred Min                            4.30751
trainer/Q2Pred Mean                         170.815
trainer/Q2Pred Std                           60.7326
trainer/Q2Pred Max                          271.334
trainer/Q2Pred Min                            5.77658
trainer/QTargetWithReg Mean                 170.754
trainer/QTargetWithReg Std                   61.013
trainer/QTargetWithReg Max                  270.459
trainer/QTargetWithReg Min                    3.84227
trainer/PolicyLossWithoutReg Mean           172.138
trainer/PolicyLossWithoutReg Std             60.0557
trainer/PolicyLossWithoutReg Max            271.814
trainer/PolicyLossWithoutReg Min              4.65804
trainer/gradient_norm                       302.009
trainer/gradient_penalty                     -1.51005
trainer/gradient_percentage                  -0.00877228
exploration/num steps total              426000
exploration/num paths total                1582
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91544
exploration/Rewards Std                       1.32045
exploration/Rewards Max                      10.3227
exploration/Rewards Min                      -0.714805
exploration/Returns Mean                   4915.44
exploration/Returns Std                       0
exploration/Returns Max                    4915.44
exploration/Returns Min                    4915.44
exploration/Num Paths                         1
exploration/Average Returns                4915.44
evaluation_0/num steps total                  3.29481e+06
evaluation_0/num paths total              10892
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79848
evaluation_0/Rewards Std                      1.2975
evaluation_0/Rewards Max                     10.6144
evaluation_0/Rewards Min                     -0.547402
evaluation_0/Returns Mean                  4798.48
evaluation_0/Returns Std                     31.7432
evaluation_0/Returns Max                   4842.27
evaluation_0/Returns Min                   4738.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4798.48
time/epoch (s)                                0
time/total (s)                             8246.31
Epoch                                       421
---------------------------------------  ----------------
2022-11-16 13:03:28.254815 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 422 finished
---------------------------------------  ----------------
epoch                                       422
total_step                               427000
replay_pool/size                         427000
trainer/alpha                                 0.0666045
trainer/alpha_loss                            0.278004
trainer/entropy                              -6.10262
trainer/qf_loss                              10.5042
trainer/state_noise                           0.005
trainer/policy_loss                        -173.438
trainer/policy_loss_without_entropy         175.366
trainer/entropy_penalty                      -0.406462
trainer/entropy_percentage                   -0.00231779
trainer/Q1Pred Mean                         174.112
trainer/Q1Pred Std                           64.4282
trainer/Q1Pred Max                          279.611
trainer/Q1Pred Min                          -30.4527
trainer/Q2Pred Mean                         173.765
trainer/Q2Pred Std                           63.9837
trainer/Q2Pred Max                          276.744
trainer/Q2Pred Min                          -13.789
trainer/QTargetWithReg Mean                 173.818
trainer/QTargetWithReg Std                   63.7333
trainer/QTargetWithReg Max                  278.11
trainer/QTargetWithReg Min                   -1.18736
trainer/PolicyLossWithoutReg Mean           175.366
trainer/PolicyLossWithoutReg Std             62.9847
trainer/PolicyLossWithoutReg Max            277.662
trainer/PolicyLossWithoutReg Min             -5.08195
trainer/gradient_norm                       304.449
trainer/gradient_penalty                     -1.52224
trainer/gradient_percentage                  -0.00868036
exploration/num steps total              427000
exploration/num paths total                1583
exploration/path length this epoch Mean     648
exploration/path length this epoch Std        0
exploration/path length this epoch Max      648
exploration/path length this epoch Min      648
exploration/Rewards Mean                      5.0205
exploration/Rewards Std                       1.58232
exploration/Rewards Max                      10.6009
exploration/Rewards Min                      -0.507961
exploration/Returns Mean                   3253.28
exploration/Returns Std                       0
exploration/Returns Max                    3253.28
exploration/Returns Min                    3253.28
exploration/Num Paths                         1
exploration/Average Returns                3253.28
evaluation_0/num steps total                  3.30281e+06
evaluation_0/num paths total              10900
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62886
evaluation_0/Rewards Std                      1.291
evaluation_0/Rewards Max                     10.6924
evaluation_0/Rewards Min                     -0.551828
evaluation_0/Returns Mean                  4628.86
evaluation_0/Returns Std                     26.1736
evaluation_0/Returns Max                   4663.89
evaluation_0/Returns Min                   4571.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4628.86
time/epoch (s)                                0
time/total (s)                             8262.1
Epoch                                       422
---------------------------------------  ----------------
2022-11-16 13:03:44.867986 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 423 finished
---------------------------------------  ----------------
epoch                                       423
total_step                               428000
replay_pool/size                         428000
trainer/alpha                                 0.0680803
trainer/alpha_loss                            1.17141
trainer/entropy                              -6.4359
trainer/qf_loss                               6.84418
trainer/state_noise                           0.005
trainer/policy_loss                        -172.74
trainer/policy_loss_without_entropy         174.699
trainer/entropy_penalty                      -0.438158
trainer/entropy_percentage                   -0.00250808
trainer/Q1Pred Mean                         174.06
trainer/Q1Pred Std                           61.6341
trainer/Q1Pred Max                          274.041
trainer/Q1Pred Min                           -4.95872
trainer/Q2Pred Mean                         174.137
trainer/Q2Pred Std                           61.1183
trainer/Q2Pred Max                          273.141
trainer/Q2Pred Min                           -0.934431
trainer/QTargetWithReg Mean                 174.241
trainer/QTargetWithReg Std                   61.5296
trainer/QTargetWithReg Max                  274.506
trainer/QTargetWithReg Min                   -0.0776008
trainer/PolicyLossWithoutReg Mean           174.699
trainer/PolicyLossWithoutReg Std             60.5057
trainer/PolicyLossWithoutReg Max            271.741
trainer/PolicyLossWithoutReg Min              1.35335
trainer/gradient_norm                       304.189
trainer/gradient_penalty                     -1.52094
trainer/gradient_percentage                  -0.00870608
exploration/num steps total              428000
exploration/num paths total                1584
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9398
exploration/Rewards Std                       1.37589
exploration/Rewards Max                      10.7663
exploration/Rewards Min                      -0.502218
exploration/Returns Mean                   4939.8
exploration/Returns Std                       0
exploration/Returns Max                    4939.8
exploration/Returns Min                    4939.8
exploration/Num Paths                         1
exploration/Average Returns                4939.8
evaluation_0/num steps total                  3.31081e+06
evaluation_0/num paths total              10908
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90779
evaluation_0/Rewards Std                      1.32277
evaluation_0/Rewards Max                     10.3154
evaluation_0/Rewards Min                     -0.636989
evaluation_0/Returns Mean                  4907.79
evaluation_0/Returns Std                     43.6759
evaluation_0/Returns Max                   4969.01
evaluation_0/Returns Min                   4836.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4907.79
time/epoch (s)                                0
time/total (s)                             8278.72
Epoch                                       423
---------------------------------------  ----------------
2022-11-16 13:04:00.689058 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 424 finished
---------------------------------------  ----------------
epoch                                       424
total_step                               429000
replay_pool/size                         429000
trainer/alpha                                 0.0683281
trainer/alpha_loss                            0.246783
trainer/entropy                              -6.09197
trainer/qf_loss                               9.41545
trainer/state_noise                           0.005
trainer/policy_loss                        -174.945
trainer/policy_loss_without_entropy         176.852
trainer/entropy_penalty                      -0.416252
trainer/entropy_percentage                   -0.00235367
trainer/Q1Pred Mean                         176.991
trainer/Q1Pred Std                           63.2409
trainer/Q1Pred Max                          276.434
trainer/Q1Pred Min                           -9.27368
trainer/Q2Pred Mean                         176.283
trainer/Q2Pred Std                           63.4348
trainer/Q2Pred Max                          276.66
trainer/Q2Pred Min                           -7.53483
trainer/QTargetWithReg Mean                 176.507
trainer/QTargetWithReg Std                   63.673
trainer/QTargetWithReg Max                  275.868
trainer/QTargetWithReg Min                   -4.99926
trainer/PolicyLossWithoutReg Mean           176.852
trainer/PolicyLossWithoutReg Std             62.5873
trainer/PolicyLossWithoutReg Max            275.739
trainer/PolicyLossWithoutReg Min             -5.27256
trainer/gradient_norm                       298.17
trainer/gradient_penalty                     -1.49085
trainer/gradient_percentage                  -0.00842991
exploration/num steps total              429000
exploration/num paths total                1585
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93922
exploration/Rewards Std                       1.35058
exploration/Rewards Max                      10.3231
exploration/Rewards Min                      -0.716128
exploration/Returns Mean                   4939.22
exploration/Returns Std                       0
exploration/Returns Max                    4939.22
exploration/Returns Min                    4939.22
exploration/Num Paths                         1
exploration/Average Returns                4939.22
evaluation_0/num steps total                  3.31881e+06
evaluation_0/num paths total              10916
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79595
evaluation_0/Rewards Std                      1.34981
evaluation_0/Rewards Max                     10.7113
evaluation_0/Rewards Min                     -0.53559
evaluation_0/Returns Mean                  4795.95
evaluation_0/Returns Std                     37.2482
evaluation_0/Returns Max                   4859.28
evaluation_0/Returns Min                   4739.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4795.95
time/epoch (s)                                0
time/total (s)                             8294.54
Epoch                                       424
---------------------------------------  ----------------
2022-11-16 13:04:17.206283 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 425 finished
---------------------------------------  ----------------
epoch                                       425
total_step                               430000
replay_pool/size                         430000
trainer/alpha                                 0.068044
trainer/alpha_loss                           -0.575766
trainer/entropy                              -5.78576
trainer/qf_loss                               8.46975
trainer/state_noise                           0.005
trainer/policy_loss                        -172.307
trainer/policy_loss_without_entropy         174.129
trainer/entropy_penalty                      -0.393687
trainer/entropy_percentage                   -0.00226089
trainer/Q1Pred Mean                         174.006
trainer/Q1Pred Std                           62.0347
trainer/Q1Pred Max                          270.122
trainer/Q1Pred Min                          -13.0618
trainer/Q2Pred Mean                         173.406
trainer/Q2Pred Std                           62.0761
trainer/Q2Pred Max                          270.003
trainer/Q2Pred Min                          -15.6251
trainer/QTargetWithReg Mean                 173.414
trainer/QTargetWithReg Std                   62.3605
trainer/QTargetWithReg Max                  268.209
trainer/QTargetWithReg Min                  -16.7838
trainer/PolicyLossWithoutReg Mean           174.129
trainer/PolicyLossWithoutReg Std             61.2902
trainer/PolicyLossWithoutReg Max            268.864
trainer/PolicyLossWithoutReg Min             -7.10944
trainer/gradient_norm                       285.574
trainer/gradient_penalty                     -1.42787
trainer/gradient_percentage                  -0.00820006
exploration/num steps total              430000
exploration/num paths total                1586
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88731
exploration/Rewards Std                       1.32067
exploration/Rewards Max                      10.5541
exploration/Rewards Min                      -0.566036
exploration/Returns Mean                   4887.31
exploration/Returns Std                       0
exploration/Returns Max                    4887.31
exploration/Returns Min                    4887.31
exploration/Num Paths                         1
exploration/Average Returns                4887.31
evaluation_0/num steps total                  3.32681e+06
evaluation_0/num paths total              10924
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01405
evaluation_0/Rewards Std                      1.32838
evaluation_0/Rewards Max                     10.8411
evaluation_0/Rewards Min                     -0.583282
evaluation_0/Returns Mean                  5014.05
evaluation_0/Returns Std                     19.2982
evaluation_0/Returns Max                   5046.01
evaluation_0/Returns Min                   4976.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5014.05
time/epoch (s)                                0
time/total (s)                             8311.05
Epoch                                       425
---------------------------------------  ----------------
2022-11-16 13:04:33.020469 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 426 finished
---------------------------------------  ----------------
epoch                                       426
total_step                               431000
replay_pool/size                         431000
trainer/alpha                                 0.0677221
trainer/alpha_loss                           -0.255808
trainer/entropy                              -5.90499
trainer/qf_loss                               7.16099
trainer/state_noise                           0.005
trainer/policy_loss                        -175.064
trainer/policy_loss_without_entropy         176.975
trainer/entropy_penalty                      -0.399899
trainer/entropy_percentage                   -0.00225963
trainer/Q1Pred Mean                         176.29
trainer/Q1Pred Std                           63.4799
trainer/Q1Pred Max                          278.835
trainer/Q1Pred Min                            2.4068
trainer/Q2Pred Mean                         176.571
trainer/Q2Pred Std                           63.5666
trainer/Q2Pred Max                          280.972
trainer/Q2Pred Min                            2.64776
trainer/QTargetWithReg Mean                 176.34
trainer/QTargetWithReg Std                   63.5861
trainer/QTargetWithReg Max                  279.355
trainer/QTargetWithReg Min                    3.40432
trainer/PolicyLossWithoutReg Mean           176.975
trainer/PolicyLossWithoutReg Std             62.6801
trainer/PolicyLossWithoutReg Max            279.712
trainer/PolicyLossWithoutReg Min              1.58397
trainer/gradient_norm                       302.325
trainer/gradient_penalty                     -1.51163
trainer/gradient_percentage                  -0.00854145
exploration/num steps total              431000
exploration/num paths total                1587
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97336
exploration/Rewards Std                       1.31219
exploration/Rewards Max                      10.5386
exploration/Rewards Min                      -0.647327
exploration/Returns Mean                   4973.36
exploration/Returns Std                       0
exploration/Returns Max                    4973.36
exploration/Returns Min                    4973.36
exploration/Num Paths                         1
exploration/Average Returns                4973.36
evaluation_0/num steps total                  3.33481e+06
evaluation_0/num paths total              10932
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0497
evaluation_0/Rewards Std                      1.30879
evaluation_0/Rewards Max                     10.337
evaluation_0/Rewards Min                     -0.630387
evaluation_0/Returns Mean                  5049.7
evaluation_0/Returns Std                     22.4613
evaluation_0/Returns Max                   5072.9
evaluation_0/Returns Min                   5011.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5049.7
time/epoch (s)                                0
time/total (s)                             8326.87
Epoch                                       426
---------------------------------------  ----------------
2022-11-16 13:04:49.444066 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 427 finished
---------------------------------------  ----------------
epoch                                       427
total_step                               432000
replay_pool/size                         432000
trainer/alpha                                 0.067227
trainer/alpha_loss                           -0.592641
trainer/entropy                              -5.78047
trainer/qf_loss                               8.96604
trainer/state_noise                           0.005
trainer/policy_loss                        -177.399
trainer/policy_loss_without_entropy         179.256
trainer/entropy_penalty                      -0.388604
trainer/entropy_percentage                   -0.00216787
trainer/Q1Pred Mean                         178.716
trainer/Q1Pred Std                           64.1261
trainer/Q1Pred Max                          279.456
trainer/Q1Pred Min                           -3.66321
trainer/Q2Pred Mean                         178.113
trainer/Q2Pred Std                           64.1353
trainer/Q2Pred Max                          277.014
trainer/Q2Pred Min                           -6.94782
trainer/QTargetWithReg Mean                 178.716
trainer/QTargetWithReg Std                   64.1891
trainer/QTargetWithReg Max                  278.803
trainer/QTargetWithReg Min                    1.74357
trainer/PolicyLossWithoutReg Mean           179.256
trainer/PolicyLossWithoutReg Std             63.6731
trainer/PolicyLossWithoutReg Max            277.696
trainer/PolicyLossWithoutReg Min             -4.25924
trainer/gradient_norm                       293.593
trainer/gradient_penalty                     -1.46797
trainer/gradient_percentage                  -0.00818923
exploration/num steps total              432000
exploration/num paths total                1588
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98377
exploration/Rewards Std                       1.30239
exploration/Rewards Max                      10.7135
exploration/Rewards Min                      -0.626299
exploration/Returns Mean                   4983.77
exploration/Returns Std                       0
exploration/Returns Max                    4983.77
exploration/Returns Min                    4983.77
exploration/Num Paths                         1
exploration/Average Returns                4983.77
evaluation_0/num steps total                  3.34281e+06
evaluation_0/num paths total              10940
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04409
evaluation_0/Rewards Std                      1.32232
evaluation_0/Rewards Max                     10.3967
evaluation_0/Rewards Min                     -0.63258
evaluation_0/Returns Mean                  5044.09
evaluation_0/Returns Std                     21.6128
evaluation_0/Returns Max                   5072.42
evaluation_0/Returns Min                   4999.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5044.09
time/epoch (s)                                0
time/total (s)                             8343.29
Epoch                                       427
---------------------------------------  ----------------
2022-11-16 13:05:05.349184 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 428 finished
---------------------------------------  ----------------
epoch                                       428
total_step                               433000
replay_pool/size                         433000
trainer/alpha                                 0.0679552
trainer/alpha_loss                           -0.284423
trainer/entropy                              -5.89422
trainer/qf_loss                               9.0094
trainer/state_noise                           0.005
trainer/policy_loss                        -177.544
trainer/policy_loss_without_entropy         179.493
trainer/entropy_penalty                      -0.400543
trainer/entropy_percentage                   -0.00223152
trainer/Q1Pred Mean                         178.555
trainer/Q1Pred Std                           61.1451
trainer/Q1Pred Max                          281.393
trainer/Q1Pred Min                            7.00388
trainer/Q2Pred Mean                         178.382
trainer/Q2Pred Std                           61.2692
trainer/Q2Pred Max                          280.451
trainer/Q2Pred Min                            4.43572
trainer/QTargetWithReg Mean                 178.932
trainer/QTargetWithReg Std                   61.749
trainer/QTargetWithReg Max                  281.152
trainer/QTargetWithReg Min                   -1.13442
trainer/PolicyLossWithoutReg Mean           179.493
trainer/PolicyLossWithoutReg Std             59.8143
trainer/PolicyLossWithoutReg Max            279.482
trainer/PolicyLossWithoutReg Min              3.78219
trainer/gradient_norm                       309.75
trainer/gradient_penalty                     -1.54875
trainer/gradient_percentage                  -0.00862847
exploration/num steps total              433000
exploration/num paths total                1589
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87018
exploration/Rewards Std                       1.27487
exploration/Rewards Max                      10.3706
exploration/Rewards Min                      -0.574587
exploration/Returns Mean                   4870.18
exploration/Returns Std                       0
exploration/Returns Max                    4870.18
exploration/Returns Min                    4870.18
exploration/Num Paths                         1
exploration/Average Returns                4870.18
evaluation_0/num steps total                  3.35081e+06
evaluation_0/num paths total              10948
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79349
evaluation_0/Rewards Std                      1.32305
evaluation_0/Rewards Max                     10.3451
evaluation_0/Rewards Min                     -0.487022
evaluation_0/Returns Mean                  4793.49
evaluation_0/Returns Std                      8.90501
evaluation_0/Returns Max                   4807.2
evaluation_0/Returns Min                   4774.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4793.49
time/epoch (s)                                0
time/total (s)                             8359.2
Epoch                                       428
---------------------------------------  ----------------
2022-11-16 13:05:21.224564 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 429 finished
---------------------------------------  ----------------
epoch                                       429
total_step                               434000
replay_pool/size                         434000
trainer/alpha                                 0.0695372
trainer/alpha_loss                            0.676159
trainer/entropy                              -6.25362
trainer/qf_loss                               6.73785
trainer/state_noise                           0.005
trainer/policy_loss                        -173.961
trainer/policy_loss_without_entropy         175.908
trainer/entropy_penalty                      -0.434859
trainer/entropy_percentage                   -0.00247209
trainer/Q1Pred Mean                         174.984
trainer/Q1Pred Std                           65.1001
trainer/Q1Pred Max                          279.053
trainer/Q1Pred Min                          -22.4196
trainer/Q2Pred Mean                         175.315
trainer/Q2Pred Std                           64.8762
trainer/Q2Pred Max                          280.18
trainer/Q2Pred Min                          -18.5274
trainer/QTargetWithReg Mean                 174.612
trainer/QTargetWithReg Std                   64.9319
trainer/QTargetWithReg Max                  277.849
trainer/QTargetWithReg Min                  -19.958
trainer/PolicyLossWithoutReg Mean           175.907
trainer/PolicyLossWithoutReg Std             64.4166
trainer/PolicyLossWithoutReg Max            280.147
trainer/PolicyLossWithoutReg Min            -17.3499
trainer/gradient_norm                       302.345
trainer/gradient_penalty                     -1.51173
trainer/gradient_percentage                  -0.00859386
exploration/num steps total              434000
exploration/num paths total                1590
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84549
exploration/Rewards Std                       1.29651
exploration/Rewards Max                      10.3385
exploration/Rewards Min                      -0.490977
exploration/Returns Mean                   4845.49
exploration/Returns Std                       0
exploration/Returns Max                    4845.49
exploration/Returns Min                    4845.49
exploration/Num Paths                         1
exploration/Average Returns                4845.49
evaluation_0/num steps total                  3.35881e+06
evaluation_0/num paths total              10956
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98352
evaluation_0/Rewards Std                      1.32071
evaluation_0/Rewards Max                     10.4103
evaluation_0/Rewards Min                     -0.544483
evaluation_0/Returns Mean                  4983.52
evaluation_0/Returns Std                     27.8644
evaluation_0/Returns Max                   5040.71
evaluation_0/Returns Min                   4942.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4983.52
time/epoch (s)                                0
time/total (s)                             8375.07
Epoch                                       429
---------------------------------------  ----------------
2022-11-16 13:05:37.612013 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 430 finished
---------------------------------------  ----------------
epoch                                       430
total_step                               435000
replay_pool/size                         435000
trainer/alpha                                 0.0678012
trainer/alpha_loss                           -0.539308
trainer/entropy                              -5.7996
trainer/qf_loss                               6.4146
trainer/state_noise                           0.005
trainer/policy_loss                        -174.822
trainer/policy_loss_without_entropy         176.759
trainer/entropy_penalty                      -0.39322
trainer/entropy_percentage                   -0.00222461
trainer/Q1Pred Mean                         176.323
trainer/Q1Pred Std                           61.8492
trainer/Q1Pred Max                          283.997
trainer/Q1Pred Min                          -10.0156
trainer/Q2Pred Mean                         176.298
trainer/Q2Pred Std                           61.8513
trainer/Q2Pred Max                          282.512
trainer/Q2Pred Min                           -9.87361
trainer/QTargetWithReg Mean                 175.828
trainer/QTargetWithReg Std                   61.8504
trainer/QTargetWithReg Max                  284.245
trainer/QTargetWithReg Min                  -17.52
trainer/PolicyLossWithoutReg Mean           176.759
trainer/PolicyLossWithoutReg Std             60.8173
trainer/PolicyLossWithoutReg Max            281.98
trainer/PolicyLossWithoutReg Min            -14.5384
trainer/gradient_norm                       308.763
trainer/gradient_penalty                     -1.54381
trainer/gradient_percentage                  -0.008734
exploration/num steps total              435000
exploration/num paths total                1591
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86727
exploration/Rewards Std                       1.27686
exploration/Rewards Max                      10.5269
exploration/Rewards Min                      -0.462063
exploration/Returns Mean                   4867.27
exploration/Returns Std                       0
exploration/Returns Max                    4867.27
exploration/Returns Min                    4867.27
exploration/Num Paths                         1
exploration/Average Returns                4867.27
evaluation_0/num steps total                  3.36681e+06
evaluation_0/num paths total              10964
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79685
evaluation_0/Rewards Std                      1.31086
evaluation_0/Rewards Max                     10.4325
evaluation_0/Rewards Min                     -0.491086
evaluation_0/Returns Mean                  4796.85
evaluation_0/Returns Std                     10.1769
evaluation_0/Returns Max                   4818.13
evaluation_0/Returns Min                   4781.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4796.85
time/epoch (s)                                0
time/total (s)                             8391.46
Epoch                                       430
---------------------------------------  ----------------
2022-11-16 13:05:53.448740 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 431 finished
---------------------------------------  ----------------
epoch                                       431
total_step                               436000
replay_pool/size                         436000
trainer/alpha                                 0.0688087
trainer/alpha_loss                           -0.0191286
trainer/entropy                              -5.99285
trainer/qf_loss                               8.42322
trainer/state_noise                           0.005
trainer/policy_loss                        -177.058
trainer/policy_loss_without_entropy         178.976
trainer/entropy_penalty                      -0.412361
trainer/entropy_percentage                   -0.002304
trainer/Q1Pred Mean                         177.754
trainer/Q1Pred Std                           61.9119
trainer/Q1Pred Max                          282.583
trainer/Q1Pred Min                          -25.9364
trainer/Q2Pred Mean                         178.008
trainer/Q2Pred Std                           62.0082
trainer/Q2Pred Max                          283.712
trainer/Q2Pred Min                          -19.1725
trainer/QTargetWithReg Mean                 178.091
trainer/QTargetWithReg Std                   61.7609
trainer/QTargetWithReg Max                  284.296
trainer/QTargetWithReg Min                  -30.5296
trainer/PolicyLossWithoutReg Mean           178.976
trainer/PolicyLossWithoutReg Std             61.4202
trainer/PolicyLossWithoutReg Max            284.351
trainer/PolicyLossWithoutReg Min            -27.2592
trainer/gradient_norm                       301.168
trainer/gradient_penalty                     -1.50584
trainer/gradient_percentage                  -0.00841365
exploration/num steps total              436000
exploration/num paths total                1592
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79304
exploration/Rewards Std                       1.30267
exploration/Rewards Max                      10.2235
exploration/Rewards Min                      -0.389426
exploration/Returns Mean                   4793.04
exploration/Returns Std                       0
exploration/Returns Max                    4793.04
exploration/Returns Min                    4793.04
exploration/Num Paths                         1
exploration/Average Returns                4793.04
evaluation_0/num steps total                  3.37481e+06
evaluation_0/num paths total              10972
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95647
evaluation_0/Rewards Std                      1.35902
evaluation_0/Rewards Max                     10.3243
evaluation_0/Rewards Min                     -0.494093
evaluation_0/Returns Mean                  4956.47
evaluation_0/Returns Std                     22.8683
evaluation_0/Returns Max                   4990.91
evaluation_0/Returns Min                   4921.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4956.47
time/epoch (s)                                0
time/total (s)                             8407.29
Epoch                                       431
---------------------------------------  ----------------
2022-11-16 13:06:10.022243 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 432 finished
---------------------------------------  ----------------
epoch                                       432
total_step                               437000
replay_pool/size                         437000
trainer/alpha                                 0.0688026
trainer/alpha_loss                            2.20873
trainer/entropy                              -6.82511
trainer/qf_loss                               7.78095
trainer/state_noise                           0.005
trainer/policy_loss                        -172.735
trainer/policy_loss_without_entropy         174.794
trainer/entropy_penalty                      -0.469586
trainer/entropy_percentage                   -0.00268651
trainer/Q1Pred Mean                         173.271
trainer/Q1Pred Std                           67.0022
trainer/Q1Pred Max                          285.477
trainer/Q1Pred Min                          -10.2505
trainer/Q2Pred Mean                         172.82
trainer/Q2Pred Std                           67.2575
trainer/Q2Pred Max                          282.766
trainer/Q2Pred Min                           -7.93777
trainer/QTargetWithReg Mean                 173.124
trainer/QTargetWithReg Std                   66.9484
trainer/QTargetWithReg Max                  284.078
trainer/QTargetWithReg Min                   -0.235628
trainer/PolicyLossWithoutReg Mean           174.794
trainer/PolicyLossWithoutReg Std             65.0829
trainer/PolicyLossWithoutReg Max            282.552
trainer/PolicyLossWithoutReg Min              2.66628
trainer/gradient_norm                       317.784
trainer/gradient_penalty                     -1.58892
trainer/gradient_percentage                  -0.00909026
exploration/num steps total              437000
exploration/num paths total                1593
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78009
exploration/Rewards Std                       1.32119
exploration/Rewards Max                      10.2964
exploration/Rewards Min                      -0.560562
exploration/Returns Mean                   4780.09
exploration/Returns Std                       0
exploration/Returns Max                    4780.09
exploration/Returns Min                    4780.09
exploration/Num Paths                         1
exploration/Average Returns                4780.09
evaluation_0/num steps total                  3.38281e+06
evaluation_0/num paths total              10980
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89198
evaluation_0/Rewards Std                      1.31493
evaluation_0/Rewards Max                     10.5783
evaluation_0/Rewards Min                     -0.564216
evaluation_0/Returns Mean                  4891.98
evaluation_0/Returns Std                     37.8139
evaluation_0/Returns Max                   4966.2
evaluation_0/Returns Min                   4848.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4891.98
time/epoch (s)                                0
time/total (s)                             8423.87
Epoch                                       432
---------------------------------------  ----------------
2022-11-16 13:06:25.910133 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 433 finished
---------------------------------------  ----------------
epoch                                       433
total_step                               438000
replay_pool/size                         438000
trainer/alpha                                 0.0695465
trainer/alpha_loss                            0.339239
trainer/entropy                              -6.12725
trainer/qf_loss                              10.3179
trainer/state_noise                           0.005
trainer/policy_loss                        -176.486
trainer/policy_loss_without_entropy         178.389
trainer/entropy_penalty                      -0.426129
trainer/entropy_percentage                   -0.00238876
trainer/Q1Pred Mean                         177.162
trainer/Q1Pred Std                           67.6515
trainer/Q1Pred Max                          285.75
trainer/Q1Pred Min                            6.05263
trainer/Q2Pred Mean                         176.765
trainer/Q2Pred Std                           67.3232
trainer/Q2Pred Max                          286.011
trainer/Q2Pred Min                            5.28379
trainer/QTargetWithReg Mean                 177.295
trainer/QTargetWithReg Std                   67.2034
trainer/QTargetWithReg Max                  285.66
trainer/QTargetWithReg Min                   12.5685
trainer/PolicyLossWithoutReg Mean           178.389
trainer/PolicyLossWithoutReg Std             66.6811
trainer/PolicyLossWithoutReg Max            285.698
trainer/PolicyLossWithoutReg Min             11.2776
trainer/gradient_norm                       295.431
trainer/gradient_penalty                     -1.47716
trainer/gradient_percentage                  -0.00828053
exploration/num steps total              438000
exploration/num paths total                1594
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80495
exploration/Rewards Std                       1.28421
exploration/Rewards Max                      10.404
exploration/Rewards Min                      -0.601581
exploration/Returns Mean                   4804.95
exploration/Returns Std                       0
exploration/Returns Max                    4804.95
exploration/Returns Min                    4804.95
exploration/Num Paths                         1
exploration/Average Returns                4804.95
evaluation_0/num steps total                  3.39081e+06
evaluation_0/num paths total              10988
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82981
evaluation_0/Rewards Std                      1.34266
evaluation_0/Rewards Max                     10.7165
evaluation_0/Rewards Min                     -0.465259
evaluation_0/Returns Mean                  4829.81
evaluation_0/Returns Std                     41.604
evaluation_0/Returns Max                   4891.77
evaluation_0/Returns Min                   4764.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4829.81
time/epoch (s)                                0
time/total (s)                             8439.75
Epoch                                       433
---------------------------------------  ----------------
2022-11-16 13:06:42.408058 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 434 finished
---------------------------------------  ----------------
epoch                                       434
total_step                               439000
replay_pool/size                         439000
trainer/alpha                                 0.0689027
trainer/alpha_loss                           -0.309574
trainer/entropy                              -5.88428
trainer/qf_loss                               7.72349
trainer/state_noise                           0.005
trainer/policy_loss                        -180.38
trainer/policy_loss_without_entropy         182.301
trainer/entropy_penalty                      -0.405442
trainer/entropy_percentage                   -0.00222403
trainer/Q1Pred Mean                         181.179
trainer/Q1Pred Std                           62.4353
trainer/Q1Pred Max                          282.036
trainer/Q1Pred Min                          -27.25
trainer/Q2Pred Mean                         181.471
trainer/Q2Pred Std                           62.6131
trainer/Q2Pred Max                          283.725
trainer/Q2Pred Min                          -24.4517
trainer/QTargetWithReg Mean                 181.318
trainer/QTargetWithReg Std                   62.5706
trainer/QTargetWithReg Max                  282.049
trainer/QTargetWithReg Min                  -24.6233
trainer/PolicyLossWithoutReg Mean           182.301
trainer/PolicyLossWithoutReg Std             61.6652
trainer/PolicyLossWithoutReg Max            282.193
trainer/PolicyLossWithoutReg Min            -19.7975
trainer/gradient_norm                       303.175
trainer/gradient_penalty                     -1.51588
trainer/gradient_percentage                  -0.00831523
exploration/num steps total              439000
exploration/num paths total                1595
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69613
exploration/Rewards Std                       1.32255
exploration/Rewards Max                      10.6068
exploration/Rewards Min                      -0.498485
exploration/Returns Mean                   4696.13
exploration/Returns Std                       0
exploration/Returns Max                    4696.13
exploration/Returns Min                    4696.13
exploration/Num Paths                         1
exploration/Average Returns                4696.13
evaluation_0/num steps total                  3.39881e+06
evaluation_0/num paths total              10996
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83825
evaluation_0/Rewards Std                      1.28325
evaluation_0/Rewards Max                     10.4188
evaluation_0/Rewards Min                     -0.450655
evaluation_0/Returns Mean                  4838.25
evaluation_0/Returns Std                     21.6658
evaluation_0/Returns Max                   4861.49
evaluation_0/Returns Min                   4799.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4838.25
time/epoch (s)                                0
time/total (s)                             8456.25
Epoch                                       434
---------------------------------------  ----------------
2022-11-16 13:06:58.306571 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 435 finished
---------------------------------------  ----------------
epoch                                       435
total_step                               440000
replay_pool/size                         440000
trainer/alpha                                 0.0681039
trainer/alpha_loss                           -1.84386
trainer/entropy                              -5.31366
trainer/qf_loss                               7.87063
trainer/state_noise                           0.005
trainer/policy_loss                        -175.371
trainer/policy_loss_without_entropy         177.259
trainer/entropy_penalty                      -0.361881
trainer/entropy_percentage                   -0.00204154
trainer/Q1Pred Mean                         175.949
trainer/Q1Pred Std                           61.2343
trainer/Q1Pred Max                          285.226
trainer/Q1Pred Min                          -77.8624
trainer/Q2Pred Mean                         176.068
trainer/Q2Pred Std                           61.3277
trainer/Q2Pred Max                          283.316
trainer/Q2Pred Min                          -80.3765
trainer/QTargetWithReg Mean                 176.064
trainer/QTargetWithReg Std                   61.3129
trainer/QTargetWithReg Max                  280.918
trainer/QTargetWithReg Min                  -88.3777
trainer/PolicyLossWithoutReg Mean           177.259
trainer/PolicyLossWithoutReg Std             60.6879
trainer/PolicyLossWithoutReg Max            281.911
trainer/PolicyLossWithoutReg Min            -75.1036
trainer/gradient_norm                       305.187
trainer/gradient_penalty                     -1.52594
trainer/gradient_percentage                  -0.00860852
exploration/num steps total              440000
exploration/num paths total                1596
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68573
exploration/Rewards Std                       1.30687
exploration/Rewards Max                      10.1519
exploration/Rewards Min                      -0.412871
exploration/Returns Mean                   4685.73
exploration/Returns Std                       0
exploration/Returns Max                    4685.73
exploration/Returns Min                    4685.73
exploration/Num Paths                         1
exploration/Average Returns                4685.73
evaluation_0/num steps total                  3.40681e+06
evaluation_0/num paths total              11004
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61233
evaluation_0/Rewards Std                      1.22031
evaluation_0/Rewards Max                      9.61295
evaluation_0/Rewards Min                     -0.430747
evaluation_0/Returns Mean                  4612.33
evaluation_0/Returns Std                     37.7453
evaluation_0/Returns Max                   4675.14
evaluation_0/Returns Min                   4566.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4612.33
time/epoch (s)                                0
time/total (s)                             8472.15
Epoch                                       435
---------------------------------------  ----------------
2022-11-16 13:07:14.763726 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 436 finished
---------------------------------------  ----------------
epoch                                       436
total_step                               441000
replay_pool/size                         441000
trainer/alpha                                 0.0675118
trainer/alpha_loss                           -0.342148
trainer/entropy                              -5.87306
trainer/qf_loss                               5.65084
trainer/state_noise                           0.005
trainer/policy_loss                        -178.522
trainer/policy_loss_without_entropy         180.47
trainer/entropy_penalty                      -0.3965
trainer/entropy_percentage                   -0.00219705
trainer/Q1Pred Mean                         179.646
trainer/Q1Pred Std                           60.6345
trainer/Q1Pred Max                          280.131
trainer/Q1Pred Min                           11.6649
trainer/Q2Pred Mean                         179.382
trainer/Q2Pred Std                           60.5765
trainer/Q2Pred Max                          280.667
trainer/Q2Pred Min                           10.8956
trainer/QTargetWithReg Mean                 179.945
trainer/QTargetWithReg Std                   60.729
trainer/QTargetWithReg Max                  281.475
trainer/QTargetWithReg Min                   13.2951
trainer/PolicyLossWithoutReg Mean           180.47
trainer/PolicyLossWithoutReg Std             59.8091
trainer/PolicyLossWithoutReg Max            281.299
trainer/PolicyLossWithoutReg Min             13.0394
trainer/gradient_norm                       310.234
trainer/gradient_penalty                     -1.55117
trainer/gradient_percentage                  -0.00859519
exploration/num steps total              441000
exploration/num paths total                1597
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81069
exploration/Rewards Std                       1.29939
exploration/Rewards Max                       9.97102
exploration/Rewards Min                      -0.512993
exploration/Returns Mean                   4810.69
exploration/Returns Std                       0
exploration/Returns Max                    4810.69
exploration/Returns Min                    4810.69
exploration/Num Paths                         1
exploration/Average Returns                4810.69
evaluation_0/num steps total                  3.41481e+06
evaluation_0/num paths total              11012
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64156
evaluation_0/Rewards Std                      1.28657
evaluation_0/Rewards Max                     10.2612
evaluation_0/Rewards Min                     -0.565405
evaluation_0/Returns Mean                  4641.56
evaluation_0/Returns Std                     22.6679
evaluation_0/Returns Max                   4669.42
evaluation_0/Returns Min                   4600.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4641.56
time/epoch (s)                                0
time/total (s)                             8488.61
Epoch                                       436
---------------------------------------  ----------------
2022-11-16 13:07:30.684925 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 437 finished
---------------------------------------  ----------------
epoch                                       437
total_step                               442000
replay_pool/size                         442000
trainer/alpha                                 0.066766
trainer/alpha_loss                            0.661815
trainer/entropy                              -6.24454
trainer/qf_loss                               7.76072
trainer/state_noise                           0.005
trainer/policy_loss                        -178.587
trainer/policy_loss_without_entropy         180.554
trainer/entropy_penalty                      -0.416923
trainer/entropy_percentage                   -0.00230913
trainer/Q1Pred Mean                         179.61
trainer/Q1Pred Std                           60.9347
trainer/Q1Pred Max                          283.053
trainer/Q1Pred Min                           18.4446
trainer/Q2Pred Mean                         179.59
trainer/Q2Pred Std                           60.797
trainer/Q2Pred Max                          282.24
trainer/Q2Pred Min                           15.4122
trainer/QTargetWithReg Mean                 179.135
trainer/QTargetWithReg Std                   60.6917
trainer/QTargetWithReg Max                  283.062
trainer/QTargetWithReg Min                   16.3803
trainer/PolicyLossWithoutReg Mean           180.554
trainer/PolicyLossWithoutReg Std             60.2975
trainer/PolicyLossWithoutReg Max            283.568
trainer/PolicyLossWithoutReg Min             20.176
trainer/gradient_norm                       310.08
trainer/gradient_penalty                     -1.5504
trainer/gradient_percentage                  -0.00858691
exploration/num steps total              442000
exploration/num paths total                1598
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73402
exploration/Rewards Std                       1.32592
exploration/Rewards Max                      10.1149
exploration/Rewards Min                      -0.437686
exploration/Returns Mean                   4734.02
exploration/Returns Std                       0
exploration/Returns Max                    4734.02
exploration/Returns Min                    4734.02
exploration/Num Paths                         1
exploration/Average Returns                4734.02
evaluation_0/num steps total                  3.42281e+06
evaluation_0/num paths total              11020
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77966
evaluation_0/Rewards Std                      1.277
evaluation_0/Rewards Max                     10.333
evaluation_0/Rewards Min                     -0.526923
evaluation_0/Returns Mean                  4779.66
evaluation_0/Returns Std                     13.286
evaluation_0/Returns Max                   4796.25
evaluation_0/Returns Min                   4754.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4779.66
time/epoch (s)                                0
time/total (s)                             8504.53
Epoch                                       437
---------------------------------------  ----------------
2022-11-16 13:07:46.757844 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 438 finished
---------------------------------------  ----------------
epoch                                       438
total_step                               443000
replay_pool/size                         443000
trainer/alpha                                 0.0690066
trainer/alpha_loss                            0.664587
trainer/entropy                              -6.24858
trainer/qf_loss                               7.00938
trainer/state_noise                           0.005
trainer/policy_loss                        -182.108
trainer/policy_loss_without_entropy         184.044
trainer/entropy_penalty                      -0.431193
trainer/entropy_percentage                   -0.00234288
trainer/Q1Pred Mean                         183.199
trainer/Q1Pred Std                           65.8682
trainer/Q1Pred Max                          282.501
trainer/Q1Pred Min                          -43.8237
trainer/Q2Pred Mean                         183.465
trainer/Q2Pred Std                           66.0933
trainer/Q2Pred Max                          278.936
trainer/Q2Pred Min                          -51.1962
trainer/QTargetWithReg Mean                 182.976
trainer/QTargetWithReg Std                   66.0852
trainer/QTargetWithReg Max                  277.091
trainer/QTargetWithReg Min                  -46.7864
trainer/PolicyLossWithoutReg Mean           184.044
trainer/PolicyLossWithoutReg Std             64.5742
trainer/PolicyLossWithoutReg Max            278.335
trainer/PolicyLossWithoutReg Min            -45.4839
trainer/gradient_norm                       300.871
trainer/gradient_penalty                     -1.50436
trainer/gradient_percentage                  -0.0081739
exploration/num steps total              443000
exploration/num paths total                1599
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71996
exploration/Rewards Std                       1.29629
exploration/Rewards Max                      10.2127
exploration/Rewards Min                      -0.437054
exploration/Returns Mean                   4719.96
exploration/Returns Std                       0
exploration/Returns Max                    4719.96
exploration/Returns Min                    4719.96
exploration/Num Paths                         1
exploration/Average Returns                4719.96
evaluation_0/num steps total                  3.43081e+06
evaluation_0/num paths total              11028
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87788
evaluation_0/Rewards Std                      1.27593
evaluation_0/Rewards Max                     10.051
evaluation_0/Rewards Min                     -0.5824
evaluation_0/Returns Mean                  4877.88
evaluation_0/Returns Std                     20.1962
evaluation_0/Returns Max                   4895.19
evaluation_0/Returns Min                   4839.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4877.88
time/epoch (s)                                0
time/total (s)                             8520.6
Epoch                                       438
---------------------------------------  ----------------
2022-11-16 13:08:02.896991 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 439 finished
---------------------------------------  ----------------
epoch                                       439
total_step                               444000
replay_pool/size                         444000
trainer/alpha                                 0.0680758
trainer/alpha_loss                           -0.00138889
trainer/entropy                              -5.99948
trainer/qf_loss                               7.51911
trainer/state_noise                           0.005
trainer/policy_loss                        -180.297
trainer/policy_loss_without_entropy         182.271
trainer/entropy_penalty                      -0.40842
trainer/entropy_percentage                   -0.00224073
trainer/Q1Pred Mean                         180.649
trainer/Q1Pred Std                           66.4598
trainer/Q1Pred Max                          282.014
trainer/Q1Pred Min                           -6.11081
trainer/Q2Pred Mean                         180.772
trainer/Q2Pred Std                           66.5303
trainer/Q2Pred Max                          281.852
trainer/Q2Pred Min                           -3.51788
trainer/QTargetWithReg Mean                 181.067
trainer/QTargetWithReg Std                   66.2468
trainer/QTargetWithReg Max                  284.075
trainer/QTargetWithReg Min                   -3.69151
trainer/PolicyLossWithoutReg Mean           182.271
trainer/PolicyLossWithoutReg Std             65.3675
trainer/PolicyLossWithoutReg Max            284.165
trainer/PolicyLossWithoutReg Min             -5.92402
trainer/gradient_norm                       313.055
trainer/gradient_penalty                     -1.56528
trainer/gradient_percentage                  -0.00858765
exploration/num steps total              444000
exploration/num paths total                1600
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81407
exploration/Rewards Std                       1.32089
exploration/Rewards Max                      10.3537
exploration/Rewards Min                      -0.558589
exploration/Returns Mean                   4814.07
exploration/Returns Std                       0
exploration/Returns Max                    4814.07
exploration/Returns Min                    4814.07
exploration/Num Paths                         1
exploration/Average Returns                4814.07
evaluation_0/num steps total                  3.43881e+06
evaluation_0/num paths total              11036
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90738
evaluation_0/Rewards Std                      1.30692
evaluation_0/Rewards Max                     10.1347
evaluation_0/Rewards Min                     -0.49069
evaluation_0/Returns Mean                  4907.38
evaluation_0/Returns Std                     34.962
evaluation_0/Returns Max                   4948.65
evaluation_0/Returns Min                   4837.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4907.38
time/epoch (s)                                0
time/total (s)                             8536.74
Epoch                                       439
---------------------------------------  ----------------
2022-11-16 13:08:18.732852 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 440 finished
---------------------------------------  ----------------
epoch                                       440
total_step                               445000
replay_pool/size                         445000
trainer/alpha                                 0.066935
trainer/alpha_loss                           -0.274582
trainer/entropy                              -5.89846
trainer/qf_loss                               7.06316
trainer/state_noise                           0.005
trainer/policy_loss                        -184.876
trainer/policy_loss_without_entropy         186.837
trainer/entropy_penalty                      -0.394813
trainer/entropy_percentage                   -0.00211314
trainer/Q1Pred Mean                         185.097
trainer/Q1Pred Std                           61.7843
trainer/Q1Pred Max                          287.583
trainer/Q1Pred Min                            5.0633
trainer/Q2Pred Mean                         185.267
trainer/Q2Pred Std                           61.0193
trainer/Q2Pred Max                          285.537
trainer/Q2Pred Min                            7.64593
trainer/QTargetWithReg Mean                 185.157
trainer/QTargetWithReg Std                   61.6073
trainer/QTargetWithReg Max                  284.383
trainer/QTargetWithReg Min                    0.0800126
trainer/PolicyLossWithoutReg Mean           186.837
trainer/PolicyLossWithoutReg Std             59.22
trainer/PolicyLossWithoutReg Max            286.04
trainer/PolicyLossWithoutReg Min              7.02065
trainer/gradient_norm                       313.201
trainer/gradient_penalty                     -1.56601
trainer/gradient_percentage                  -0.00838167
exploration/num steps total              445000
exploration/num paths total                1601
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77416
exploration/Rewards Std                       1.28767
exploration/Rewards Max                      10.3993
exploration/Rewards Min                      -0.418315
exploration/Returns Mean                   4774.16
exploration/Returns Std                       0
exploration/Returns Max                    4774.16
exploration/Returns Min                    4774.16
exploration/Num Paths                         1
exploration/Average Returns                4774.16
evaluation_0/num steps total                  3.44681e+06
evaluation_0/num paths total              11044
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73759
evaluation_0/Rewards Std                      1.24335
evaluation_0/Rewards Max                     10.1989
evaluation_0/Rewards Min                     -0.52382
evaluation_0/Returns Mean                  4737.59
evaluation_0/Returns Std                      7.25419
evaluation_0/Returns Max                   4748.96
evaluation_0/Returns Min                   4723.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4737.59
time/epoch (s)                                0
time/total (s)                             8552.58
Epoch                                       440
---------------------------------------  ----------------
2022-11-16 13:08:35.186125 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 441 finished
---------------------------------------  ----------------
epoch                                       441
total_step                               446000
replay_pool/size                         446000
trainer/alpha                                 0.0666916
trainer/alpha_loss                            0.565353
trainer/entropy                              -6.20881
trainer/qf_loss                               9.10826
trainer/state_noise                           0.005
trainer/policy_loss                        -167.62
trainer/policy_loss_without_entropy         169.547
trainer/entropy_penalty                      -0.414075
trainer/entropy_percentage                   -0.00244224
trainer/Q1Pred Mean                         168.839
trainer/Q1Pred Std                           62.0321
trainer/Q1Pred Max                          283.153
trainer/Q1Pred Min                            1.27393
trainer/Q2Pred Mean                         168.676
trainer/Q2Pred Std                           62.1667
trainer/Q2Pred Max                          283.634
trainer/Q2Pred Min                            4.23034
trainer/QTargetWithReg Mean                 168.652
trainer/QTargetWithReg Std                   61.9032
trainer/QTargetWithReg Max                  283.096
trainer/QTargetWithReg Min                    6.2138
trainer/PolicyLossWithoutReg Mean           169.547
trainer/PolicyLossWithoutReg Std             61.2275
trainer/PolicyLossWithoutReg Max            282.851
trainer/PolicyLossWithoutReg Min              6.4059
trainer/gradient_norm                       302.727
trainer/gradient_penalty                     -1.51363
trainer/gradient_percentage                  -0.0089275
exploration/num steps total              446000
exploration/num paths total                1602
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85814
exploration/Rewards Std                       1.26507
exploration/Rewards Max                      10.5638
exploration/Rewards Min                      -0.599101
exploration/Returns Mean                   4858.14
exploration/Returns Std                       0
exploration/Returns Max                    4858.14
exploration/Returns Min                    4858.14
exploration/Num Paths                         1
exploration/Average Returns                4858.14
evaluation_0/num steps total                  3.45481e+06
evaluation_0/num paths total              11052
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7992
evaluation_0/Rewards Std                      1.29548
evaluation_0/Rewards Max                     10.0722
evaluation_0/Rewards Min                     -0.466023
evaluation_0/Returns Mean                  4799.2
evaluation_0/Returns Std                     15.3005
evaluation_0/Returns Max                   4822.84
evaluation_0/Returns Min                   4778.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4799.2
time/epoch (s)                                0
time/total (s)                             8569.03
Epoch                                       441
---------------------------------------  ----------------
2022-11-16 13:08:50.950299 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 442 finished
---------------------------------------  ----------------
epoch                                       442
total_step                               447000
replay_pool/size                         447000
trainer/alpha                                 0.0670052
trainer/alpha_loss                            0.741143
trainer/entropy                              -6.2742
trainer/qf_loss                               9.38132
trainer/state_noise                           0.005
trainer/policy_loss                        -172.679
trainer/policy_loss_without_entropy         174.572
trainer/entropy_penalty                      -0.420404
trainer/entropy_percentage                   -0.0024082
trainer/Q1Pred Mean                         173.021
trainer/Q1Pred Std                           69.4087
trainer/Q1Pred Max                          289.075
trainer/Q1Pred Min                            0.883038
trainer/Q2Pred Mean                         172.755
trainer/Q2Pred Std                           69.7239
trainer/Q2Pred Max                          288.922
trainer/Q2Pred Min                           -0.12153
trainer/QTargetWithReg Mean                 172.511
trainer/QTargetWithReg Std                   69.7124
trainer/QTargetWithReg Max                  289.126
trainer/QTargetWithReg Min                    4.16858
trainer/PolicyLossWithoutReg Mean           174.572
trainer/PolicyLossWithoutReg Std             68.0949
trainer/PolicyLossWithoutReg Max            288.661
trainer/PolicyLossWithoutReg Min              1.05125
trainer/gradient_norm                       294.468
trainer/gradient_penalty                     -1.47234
trainer/gradient_percentage                  -0.00843401
exploration/num steps total              447000
exploration/num paths total                1603
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80503
exploration/Rewards Std                       1.28816
exploration/Rewards Max                      10.818
exploration/Rewards Min                      -0.529264
exploration/Returns Mean                   4805.03
exploration/Returns Std                       0
exploration/Returns Max                    4805.03
exploration/Returns Min                    4805.03
exploration/Num Paths                         1
exploration/Average Returns                4805.03
evaluation_0/num steps total                  3.46281e+06
evaluation_0/num paths total              11060
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77992
evaluation_0/Rewards Std                      1.28935
evaluation_0/Rewards Max                     10.1194
evaluation_0/Rewards Min                     -0.664186
evaluation_0/Returns Mean                  4779.92
evaluation_0/Returns Std                      9.86461
evaluation_0/Returns Max                   4793.68
evaluation_0/Returns Min                   4762.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4779.92
time/epoch (s)                                0
time/total (s)                             8584.79
Epoch                                       442
---------------------------------------  ----------------
2022-11-16 13:09:07.401815 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 443 finished
---------------------------------------  ----------------
epoch                                       443
total_step                               448000
replay_pool/size                         448000
trainer/alpha                                 0.0669571
trainer/alpha_loss                           -0.72136
trainer/entropy                              -5.73317
trainer/qf_loss                               9.05122
trainer/state_noise                           0.005
trainer/policy_loss                        -178.208
trainer/policy_loss_without_entropy         180.128
trainer/entropy_penalty                      -0.383877
trainer/entropy_percentage                   -0.00213113
trainer/Q1Pred Mean                         179.599
trainer/Q1Pred Std                           66.0061
trainer/Q1Pred Max                          290.311
trainer/Q1Pred Min                            8.16959
trainer/Q2Pred Mean                         179.405
trainer/Q2Pred Std                           66.1733
trainer/Q2Pred Max                          288.759
trainer/Q2Pred Min                           10.985
trainer/QTargetWithReg Mean                 179.342
trainer/QTargetWithReg Std                   66.1092
trainer/QTargetWithReg Max                  291.581
trainer/QTargetWithReg Min                    2.63444
trainer/PolicyLossWithoutReg Mean           180.128
trainer/PolicyLossWithoutReg Std             65.0572
trainer/PolicyLossWithoutReg Max            288.345
trainer/PolicyLossWithoutReg Min              8.24481
trainer/gradient_norm                       307.248
trainer/gradient_penalty                     -1.53624
trainer/gradient_percentage                  -0.00852857
exploration/num steps total              448000
exploration/num paths total                1604
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81337
exploration/Rewards Std                       1.27223
exploration/Rewards Max                      10.1876
exploration/Rewards Min                      -0.733231
exploration/Returns Mean                   4813.37
exploration/Returns Std                       0
exploration/Returns Max                    4813.37
exploration/Returns Min                    4813.37
exploration/Num Paths                         1
exploration/Average Returns                4813.37
evaluation_0/num steps total                  3.47081e+06
evaluation_0/num paths total              11068
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81526
evaluation_0/Rewards Std                      1.32321
evaluation_0/Rewards Max                     10.4063
evaluation_0/Rewards Min                     -0.572488
evaluation_0/Returns Mean                  4815.26
evaluation_0/Returns Std                     22.8546
evaluation_0/Returns Max                   4853.19
evaluation_0/Returns Min                   4779.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4815.26
time/epoch (s)                                0
time/total (s)                             8601.24
Epoch                                       443
---------------------------------------  ----------------
2022-11-16 13:09:23.227019 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 444 finished
---------------------------------------  ----------------
epoch                                       444
total_step                               449000
replay_pool/size                         449000
trainer/alpha                                 0.066706
trainer/alpha_loss                           -0.482256
trainer/entropy                              -5.82188
trainer/qf_loss                              12.5149
trainer/state_noise                           0.005
trainer/policy_loss                        -181.75
trainer/policy_loss_without_entropy         183.677
trainer/entropy_penalty                      -0.388354
trainer/entropy_percentage                   -0.00211434
trainer/Q1Pred Mean                         182.44
trainer/Q1Pred Std                           61.4936
trainer/Q1Pred Max                          284.278
trainer/Q1Pred Min                          -37.9124
trainer/Q2Pred Mean                         182.457
trainer/Q2Pred Std                           61.217
trainer/Q2Pred Max                          283.594
trainer/Q2Pred Min                          -27.6024
trainer/QTargetWithReg Mean                 182.961
trainer/QTargetWithReg Std                   61.0499
trainer/QTargetWithReg Max                  284.105
trainer/QTargetWithReg Min                   -6.12693
trainer/PolicyLossWithoutReg Mean           183.677
trainer/PolicyLossWithoutReg Std             59.9054
trainer/PolicyLossWithoutReg Max            283.987
trainer/PolicyLossWithoutReg Min            -42.0856
trainer/gradient_norm                       307.725
trainer/gradient_penalty                     -1.53863
trainer/gradient_percentage                  -0.00837681
exploration/num steps total              449000
exploration/num paths total                1605
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79968
exploration/Rewards Std                       1.33443
exploration/Rewards Max                      10.3285
exploration/Rewards Min                      -0.604914
exploration/Returns Mean                   4799.68
exploration/Returns Std                       0
exploration/Returns Max                    4799.68
exploration/Returns Min                    4799.68
exploration/Num Paths                         1
exploration/Average Returns                4799.68
evaluation_0/num steps total                  3.47881e+06
evaluation_0/num paths total              11076
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77322
evaluation_0/Rewards Std                      1.27487
evaluation_0/Rewards Max                     10.1126
evaluation_0/Rewards Min                     -0.56068
evaluation_0/Returns Mean                  4773.22
evaluation_0/Returns Std                     13.6157
evaluation_0/Returns Max                   4794.01
evaluation_0/Returns Min                   4750.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4773.22
time/epoch (s)                                0
time/total (s)                             8617.07
Epoch                                       444
---------------------------------------  ----------------
2022-11-16 13:09:39.568866 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 445 finished
---------------------------------------  ----------------
epoch                                       445
total_step                               450000
replay_pool/size                         450000
trainer/alpha                                 0.0676975
trainer/alpha_loss                           -1.54087
trainer/entropy                              -5.42774
trainer/qf_loss                               6.6411
trainer/state_noise                           0.005
trainer/policy_loss                        -177.163
trainer/policy_loss_without_entropy         178.993
trainer/entropy_penalty                      -0.367444
trainer/entropy_percentage                   -0.00205285
trainer/Q1Pred Mean                         178.434
trainer/Q1Pred Std                           63.9051
trainer/Q1Pred Max                          285.176
trainer/Q1Pred Min                            1.24932
trainer/Q2Pred Mean                         178.117
trainer/Q2Pred Std                           63.7952
trainer/Q2Pred Max                          283.684
trainer/Q2Pred Min                            5.49991
trainer/QTargetWithReg Mean                 178.232
trainer/QTargetWithReg Std                   63.9931
trainer/QTargetWithReg Max                  284.802
trainer/QTargetWithReg Min                    6.10962
trainer/PolicyLossWithoutReg Mean           178.993
trainer/PolicyLossWithoutReg Std             63.4839
trainer/PolicyLossWithoutReg Max            284.081
trainer/PolicyLossWithoutReg Min              3.64208
trainer/gradient_norm                       292.405
trainer/gradient_penalty                     -1.46202
trainer/gradient_percentage                  -0.00816806
exploration/num steps total              450000
exploration/num paths total                1606
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78974
exploration/Rewards Std                       1.27888
exploration/Rewards Max                      10.0388
exploration/Rewards Min                      -0.671784
exploration/Returns Mean                   4789.74
exploration/Returns Std                       0
exploration/Returns Max                    4789.74
exploration/Returns Min                    4789.74
exploration/Num Paths                         1
exploration/Average Returns                4789.74
evaluation_0/num steps total                  3.48681e+06
evaluation_0/num paths total              11084
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76225
evaluation_0/Rewards Std                      1.24831
evaluation_0/Rewards Max                     10.1938
evaluation_0/Rewards Min                     -0.586807
evaluation_0/Returns Mean                  4762.25
evaluation_0/Returns Std                     22.2806
evaluation_0/Returns Max                   4790.82
evaluation_0/Returns Min                   4716.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4762.25
time/epoch (s)                                0
time/total (s)                             8633.41
Epoch                                       445
---------------------------------------  ----------------
2022-11-16 13:09:55.360807 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 446 finished
---------------------------------------  ----------------
epoch                                       446
total_step                               451000
replay_pool/size                         451000
trainer/alpha                                 0.0692285
trainer/alpha_loss                            0.25713
trainer/entropy                              -6.09629
trainer/qf_loss                              14.4205
trainer/state_noise                           0.005
trainer/policy_loss                        -176.648
trainer/policy_loss_without_entropy         178.633
trainer/entropy_penalty                      -0.422037
trainer/entropy_percentage                   -0.00236259
trainer/Q1Pred Mean                         178.273
trainer/Q1Pred Std                           63.9611
trainer/Q1Pred Max                          281.756
trainer/Q1Pred Min                          -28.0527
trainer/Q2Pred Mean                         178.552
trainer/Q2Pred Std                           63.8014
trainer/Q2Pred Max                          281.644
trainer/Q2Pred Min                          -17.1982
trainer/QTargetWithReg Mean                 177.991
trainer/QTargetWithReg Std                   63.932
trainer/QTargetWithReg Max                  281.029
trainer/QTargetWithReg Min                  -13.3285
trainer/PolicyLossWithoutReg Mean           178.633
trainer/PolicyLossWithoutReg Std             63.1537
trainer/PolicyLossWithoutReg Max            280.918
trainer/PolicyLossWithoutReg Min            -21.1972
trainer/gradient_norm                       312.544
trainer/gradient_penalty                     -1.56272
trainer/gradient_percentage                  -0.00874823
exploration/num steps total              451000
exploration/num paths total                1607
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74133
exploration/Rewards Std                       1.31204
exploration/Rewards Max                      10.3591
exploration/Rewards Min                      -0.43706
exploration/Returns Mean                   4741.33
exploration/Returns Std                       0
exploration/Returns Max                    4741.33
exploration/Returns Min                    4741.33
exploration/Num Paths                         1
exploration/Average Returns                4741.33
evaluation_0/num steps total                  3.49481e+06
evaluation_0/num paths total              11092
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81617
evaluation_0/Rewards Std                      1.29941
evaluation_0/Rewards Max                     10.6021
evaluation_0/Rewards Min                     -0.520248
evaluation_0/Returns Mean                  4816.17
evaluation_0/Returns Std                     22.7179
evaluation_0/Returns Max                   4851.72
evaluation_0/Returns Min                   4780.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4816.17
time/epoch (s)                                0
time/total (s)                             8649.2
Epoch                                       446
---------------------------------------  ----------------
2022-11-16 13:10:11.223315 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 447 finished
---------------------------------------  ----------------
epoch                                       447
total_step                               452000
replay_pool/size                         452000
trainer/alpha                                 0.0689375
trainer/alpha_loss                            0.435288
trainer/entropy                              -6.16276
trainer/qf_loss                               6.42158
trainer/state_noise                           0.005
trainer/policy_loss                        -175.266
trainer/policy_loss_without_entropy         177.295
trainer/entropy_penalty                      -0.424845
trainer/entropy_percentage                   -0.00239626
trainer/Q1Pred Mean                         176.305
trainer/Q1Pred Std                           65.7412
trainer/Q1Pred Max                          283.522
trainer/Q1Pred Min                          -18.9397
trainer/Q2Pred Mean                         176.319
trainer/Q2Pred Std                           65.6783
trainer/Q2Pred Max                          282.004
trainer/Q2Pred Min                          -13.4578
trainer/QTargetWithReg Mean                 176.413
trainer/QTargetWithReg Std                   65.6472
trainer/QTargetWithReg Max                  282.796
trainer/QTargetWithReg Min                   -2.75918
trainer/PolicyLossWithoutReg Mean           177.295
trainer/PolicyLossWithoutReg Std             65.0352
trainer/PolicyLossWithoutReg Max            282.549
trainer/PolicyLossWithoutReg Min            -11.5508
trainer/gradient_norm                       320.953
trainer/gradient_penalty                     -1.60476
trainer/gradient_percentage                  -0.00905136
exploration/num steps total              452000
exploration/num paths total                1608
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72185
exploration/Rewards Std                       1.30454
exploration/Rewards Max                      10.4018
exploration/Rewards Min                      -0.470708
exploration/Returns Mean                   4721.85
exploration/Returns Std                       0
exploration/Returns Max                    4721.85
exploration/Returns Min                    4721.85
exploration/Num Paths                         1
exploration/Average Returns                4721.85
evaluation_0/num steps total                  3.50281e+06
evaluation_0/num paths total              11100
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77443
evaluation_0/Rewards Std                      1.24198
evaluation_0/Rewards Max                     10.1734
evaluation_0/Rewards Min                     -0.545022
evaluation_0/Returns Mean                  4774.43
evaluation_0/Returns Std                      8.05841
evaluation_0/Returns Max                   4788.62
evaluation_0/Returns Min                   4759.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4774.43
time/epoch (s)                                0
time/total (s)                             8665.06
Epoch                                       447
---------------------------------------  ----------------
2022-11-16 13:10:27.620106 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 448 finished
---------------------------------------  ----------------
epoch                                       448
total_step                               453000
replay_pool/size                         453000
trainer/alpha                                 0.0690865
trainer/alpha_loss                           -0.358933
trainer/entropy                              -5.86569
trainer/qf_loss                               9.89681
trainer/state_noise                           0.005
trainer/policy_loss                        -176.46
trainer/policy_loss_without_entropy         178.426
trainer/entropy_penalty                      -0.40524
trainer/entropy_percentage                   -0.0022712
trainer/Q1Pred Mean                         177.834
trainer/Q1Pred Std                           69.2161
trainer/Q1Pred Max                          283.882
trainer/Q1Pred Min                          -28.418
trainer/Q2Pred Mean                         177.461
trainer/Q2Pred Std                           69.0744
trainer/Q2Pred Max                          284.032
trainer/Q2Pred Min                          -27.0398
trainer/QTargetWithReg Mean                 177.14
trainer/QTargetWithReg Std                   69.1826
trainer/QTargetWithReg Max                  282.319
trainer/QTargetWithReg Min                  -29.0208
trainer/PolicyLossWithoutReg Mean           178.426
trainer/PolicyLossWithoutReg Std             68.4425
trainer/PolicyLossWithoutReg Max            283.985
trainer/PolicyLossWithoutReg Min            -30.0782
trainer/gradient_norm                       312.081
trainer/gradient_penalty                     -1.56041
trainer/gradient_percentage                  -0.00874541
exploration/num steps total              453000
exploration/num paths total                1609
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74459
exploration/Rewards Std                       1.2761
exploration/Rewards Max                      10.2119
exploration/Rewards Min                      -0.573438
exploration/Returns Mean                   4744.59
exploration/Returns Std                       0
exploration/Returns Max                    4744.59
exploration/Returns Min                    4744.59
exploration/Num Paths                         1
exploration/Average Returns                4744.59
evaluation_0/num steps total                  3.51081e+06
evaluation_0/num paths total              11108
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67717
evaluation_0/Rewards Std                      1.22109
evaluation_0/Rewards Max                     10.1505
evaluation_0/Rewards Min                     -0.607015
evaluation_0/Returns Mean                  4677.17
evaluation_0/Returns Std                      8.90735
evaluation_0/Returns Max                   4694.59
evaluation_0/Returns Min                   4666.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4677.17
time/epoch (s)                                0
time/total (s)                             8681.46
Epoch                                       448
---------------------------------------  ----------------
2022-11-16 13:10:43.410852 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 449 finished
---------------------------------------  ----------------
epoch                                       449
total_step                               454000
replay_pool/size                         454000
trainer/alpha                                 0.0692185
trainer/alpha_loss                           -0.27167
trainer/entropy                              -5.89826
trainer/qf_loss                               7.84521
trainer/state_noise                           0.005
trainer/policy_loss                        -169.773
trainer/policy_loss_without_entropy         171.713
trainer/entropy_penalty                      -0.408269
trainer/entropy_percentage                   -0.00237763
trainer/Q1Pred Mean                         170.422
trainer/Q1Pred Std                           65.8664
trainer/Q1Pred Max                          275.786
trainer/Q1Pred Min                            8.03036
trainer/Q2Pred Mean                         171.04
trainer/Q2Pred Std                           66.0227
trainer/Q2Pred Max                          277.265
trainer/Q2Pred Min                            2.83305
trainer/QTargetWithReg Mean                 171.14
trainer/QTargetWithReg Std                   65.908
trainer/QTargetWithReg Max                  275.341
trainer/QTargetWithReg Min                    6.79322
trainer/PolicyLossWithoutReg Mean           171.713
trainer/PolicyLossWithoutReg Std             65.2835
trainer/PolicyLossWithoutReg Max            275.633
trainer/PolicyLossWithoutReg Min              5.27755
trainer/gradient_norm                       306.257
trainer/gradient_penalty                     -1.53128
trainer/gradient_percentage                  -0.00891771
exploration/num steps total              454000
exploration/num paths total                1610
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79768
exploration/Rewards Std                       1.28495
exploration/Rewards Max                      10.2204
exploration/Rewards Min                      -0.449166
exploration/Returns Mean                   4797.68
exploration/Returns Std                       0
exploration/Returns Max                    4797.68
exploration/Returns Min                    4797.68
exploration/Num Paths                         1
exploration/Average Returns                4797.68
evaluation_0/num steps total                  3.51881e+06
evaluation_0/num paths total              11116
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82721
evaluation_0/Rewards Std                      1.24941
evaluation_0/Rewards Max                     10.3133
evaluation_0/Rewards Min                     -0.534914
evaluation_0/Returns Mean                  4827.21
evaluation_0/Returns Std                     13.7976
evaluation_0/Returns Max                   4846.83
evaluation_0/Returns Min                   4807.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4827.21
time/epoch (s)                                0
time/total (s)                             8697.25
Epoch                                       449
---------------------------------------  ----------------
2022-11-16 13:10:59.811806 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 450 finished
---------------------------------------  ----------------
epoch                                       450
total_step                               455000
replay_pool/size                         455000
trainer/alpha                                 0.0711374
trainer/alpha_loss                            1.0251
trainer/entropy                              -6.38783
trainer/qf_loss                              11.7858
trainer/state_noise                           0.005
trainer/policy_loss                        -180.089
trainer/policy_loss_without_entropy         182.054
trainer/entropy_penalty                      -0.454413
trainer/entropy_percentage                   -0.00249604
trainer/Q1Pred Mean                         181.765
trainer/Q1Pred Std                           67.3315
trainer/Q1Pred Max                          287.861
trainer/Q1Pred Min                          -15.9673
trainer/Q2Pred Mean                         182.095
trainer/Q2Pred Std                           67.7336
trainer/Q2Pred Max                          287.954
trainer/Q2Pred Min                          -16.2321
trainer/QTargetWithReg Mean                 181.496
trainer/QTargetWithReg Std                   67.5048
trainer/QTargetWithReg Max                  287.366
trainer/QTargetWithReg Min                  -21.6537
trainer/PolicyLossWithoutReg Mean           182.054
trainer/PolicyLossWithoutReg Std             66.971
trainer/PolicyLossWithoutReg Max            287.374
trainer/PolicyLossWithoutReg Min            -21.4661
trainer/gradient_norm                       302.067
trainer/gradient_penalty                     -1.51033
trainer/gradient_percentage                  -0.00829608
exploration/num steps total              455000
exploration/num paths total                1611
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76267
exploration/Rewards Std                       1.26886
exploration/Rewards Max                      10.3193
exploration/Rewards Min                      -0.444718
exploration/Returns Mean                   4762.67
exploration/Returns Std                       0
exploration/Returns Max                    4762.67
exploration/Returns Min                    4762.67
exploration/Num Paths                         1
exploration/Average Returns                4762.67
evaluation_0/num steps total                  3.52681e+06
evaluation_0/num paths total              11124
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7968
evaluation_0/Rewards Std                      1.22679
evaluation_0/Rewards Max                     10.1201
evaluation_0/Rewards Min                     -0.502177
evaluation_0/Returns Mean                  4796.8
evaluation_0/Returns Std                      7.95782
evaluation_0/Returns Max                   4809.75
evaluation_0/Returns Min                   4784.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4796.8
time/epoch (s)                                0
time/total (s)                             8713.65
Epoch                                       450
---------------------------------------  ----------------
2022-11-16 13:11:15.772450 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 451 finished
---------------------------------------  ----------------
epoch                                       451
total_step                               456000
replay_pool/size                         456000
trainer/alpha                                 0.06969
trainer/alpha_loss                            0.1442
trainer/entropy                              -6.05413
trainer/qf_loss                               7.37751
trainer/state_noise                           0.005
trainer/policy_loss                        -182.477
trainer/policy_loss_without_entropy         184.479
trainer/entropy_penalty                      -0.421913
trainer/entropy_percentage                   -0.00228705
trainer/Q1Pred Mean                         183.971
trainer/Q1Pred Std                           65.3572
trainer/Q1Pred Max                          287.701
trainer/Q1Pred Min                           -4.2718
trainer/Q2Pred Mean                         184.212
trainer/Q2Pred Std                           65.447
trainer/Q2Pred Max                          288.027
trainer/Q2Pred Min                           -5.46699
trainer/QTargetWithReg Mean                 183.746
trainer/QTargetWithReg Std                   65.09
trainer/QTargetWithReg Max                  288.745
trainer/QTargetWithReg Min                   -7.85543
trainer/PolicyLossWithoutReg Mean           184.479
trainer/PolicyLossWithoutReg Std             64.3525
trainer/PolicyLossWithoutReg Max            287.524
trainer/PolicyLossWithoutReg Min              1.26148
trainer/gradient_norm                       316.032
trainer/gradient_penalty                     -1.58016
trainer/gradient_percentage                  -0.00856552
exploration/num steps total              456000
exploration/num paths total                1612
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77183
exploration/Rewards Std                       1.23044
exploration/Rewards Max                       9.89969
exploration/Rewards Min                      -0.533146
exploration/Returns Mean                   4771.83
exploration/Returns Std                       0
exploration/Returns Max                    4771.83
exploration/Returns Min                    4771.83
exploration/Num Paths                         1
exploration/Average Returns                4771.83
evaluation_0/num steps total                  3.53481e+06
evaluation_0/num paths total              11132
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71113
evaluation_0/Rewards Std                      1.25109
evaluation_0/Rewards Max                     10.1345
evaluation_0/Rewards Min                     -0.633092
evaluation_0/Returns Mean                  4711.13
evaluation_0/Returns Std                     12.0358
evaluation_0/Returns Max                   4732.17
evaluation_0/Returns Min                   4692.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4711.13
time/epoch (s)                                0
time/total (s)                             8729.61
Epoch                                       451
---------------------------------------  ----------------
2022-11-16 13:11:31.571406 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 452 finished
---------------------------------------  ----------------
epoch                                       452
total_step                               457000
replay_pool/size                         457000
trainer/alpha                                 0.0686953
trainer/alpha_loss                           -0.114211
trainer/entropy                              -5.95736
trainer/qf_loss                               7.80955
trainer/state_noise                           0.005
trainer/policy_loss                        -177.581
trainer/policy_loss_without_entropy         179.542
trainer/entropy_penalty                      -0.409242
trainer/entropy_percentage                   -0.00227937
trainer/Q1Pred Mean                         178.431
trainer/Q1Pred Std                           63.6956
trainer/Q1Pred Max                          288.658
trainer/Q1Pred Min                            3.17049
trainer/Q2Pred Mean                         178.403
trainer/Q2Pred Std                           63.9303
trainer/Q2Pred Max                          285.703
trainer/Q2Pred Min                            2.79057
trainer/QTargetWithReg Mean                 177.912
trainer/QTargetWithReg Std                   63.7865
trainer/QTargetWithReg Max                  286.551
trainer/QTargetWithReg Min                    1.59629
trainer/PolicyLossWithoutReg Mean           179.542
trainer/PolicyLossWithoutReg Std             63.2871
trainer/PolicyLossWithoutReg Max            288.05
trainer/PolicyLossWithoutReg Min              4.25132
trainer/gradient_norm                       310.23
trainer/gradient_penalty                     -1.55115
trainer/gradient_percentage                  -0.0086395
exploration/num steps total              457000
exploration/num paths total                1613
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7681
exploration/Rewards Std                       1.27511
exploration/Rewards Max                      10.1859
exploration/Rewards Min                      -0.561112
exploration/Returns Mean                   4768.1
exploration/Returns Std                       0
exploration/Returns Max                    4768.1
exploration/Returns Min                    4768.1
exploration/Num Paths                         1
exploration/Average Returns                4768.1
evaluation_0/num steps total                  3.54281e+06
evaluation_0/num paths total              11140
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8318
evaluation_0/Rewards Std                      1.21836
evaluation_0/Rewards Max                      9.99153
evaluation_0/Rewards Min                     -0.58187
evaluation_0/Returns Mean                  4831.8
evaluation_0/Returns Std                      7.895
evaluation_0/Returns Max                   4841.66
evaluation_0/Returns Min                   4819.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4831.8
time/epoch (s)                                0
time/total (s)                             8745.41
Epoch                                       452
---------------------------------------  ----------------
2022-11-16 13:11:48.051068 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 453 finished
---------------------------------------  ----------------
epoch                                       453
total_step                               458000
replay_pool/size                         458000
trainer/alpha                                 0.0686746
trainer/alpha_loss                            0.288677
trainer/entropy                              -6.10778
trainer/qf_loss                               6.02294
trainer/state_noise                           0.005
trainer/policy_loss                        -186.805
trainer/policy_loss_without_entropy         188.859
trainer/entropy_penalty                      -0.419449
trainer/entropy_percentage                   -0.00222097
trainer/Q1Pred Mean                         187.971
trainer/Q1Pred Std                           64.1334
trainer/Q1Pred Max                          284.998
trainer/Q1Pred Min                            7.09069
trainer/Q2Pred Mean                         188.763
trainer/Q2Pred Std                           64.2175
trainer/Q2Pred Max                          285.461
trainer/Q2Pred Min                            5.86264
trainer/QTargetWithReg Mean                 188.537
trainer/QTargetWithReg Std                   64.5477
trainer/QTargetWithReg Max                  284.662
trainer/QTargetWithReg Min                    0.997042
trainer/PolicyLossWithoutReg Mean           188.859
trainer/PolicyLossWithoutReg Std             63.365
trainer/PolicyLossWithoutReg Max            285.214
trainer/PolicyLossWithoutReg Min              1.49991
trainer/gradient_norm                       326.842
trainer/gradient_penalty                     -1.63421
trainer/gradient_percentage                  -0.00865307
exploration/num steps total              458000
exploration/num paths total                1614
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67646
exploration/Rewards Std                       1.29532
exploration/Rewards Max                      10.0333
exploration/Rewards Min                      -0.655777
exploration/Returns Mean                   4676.46
exploration/Returns Std                       0
exploration/Returns Max                    4676.46
exploration/Returns Min                    4676.46
exploration/Num Paths                         1
exploration/Average Returns                4676.46
evaluation_0/num steps total                  3.55081e+06
evaluation_0/num paths total              11148
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67341
evaluation_0/Rewards Std                      1.22539
evaluation_0/Rewards Max                      9.88422
evaluation_0/Rewards Min                     -0.57498
evaluation_0/Returns Mean                  4673.41
evaluation_0/Returns Std                     24.0825
evaluation_0/Returns Max                   4691.52
evaluation_0/Returns Min                   4613.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4673.41
time/epoch (s)                                0
time/total (s)                             8761.89
Epoch                                       453
---------------------------------------  ----------------
2022-11-16 13:12:03.862651 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 454 finished
---------------------------------------  ----------------
epoch                                       454
total_step                               459000
replay_pool/size                         459000
trainer/alpha                                 0.0690014
trainer/alpha_loss                           -0.0309929
trainer/entropy                              -5.98841
trainer/qf_loss                               8.05042
trainer/state_noise                           0.005
trainer/policy_loss                        -175.227
trainer/policy_loss_without_entropy         177.202
trainer/entropy_penalty                      -0.413209
trainer/entropy_percentage                   -0.00233184
trainer/Q1Pred Mean                         176.58
trainer/Q1Pred Std                           71.4059
trainer/Q1Pred Max                          285.74
trainer/Q1Pred Min                            0.0930312
trainer/Q2Pred Mean                         176.827
trainer/Q2Pred Std                           71.3945
trainer/Q2Pred Max                          286.447
trainer/Q2Pred Min                           -0.791297
trainer/QTargetWithReg Mean                 176.268
trainer/QTargetWithReg Std                   71.4587
trainer/QTargetWithReg Max                  285.688
trainer/QTargetWithReg Min                   -0.175053
trainer/PolicyLossWithoutReg Mean           177.202
trainer/PolicyLossWithoutReg Std             70.6875
trainer/PolicyLossWithoutReg Max            284.884
trainer/PolicyLossWithoutReg Min             -0.654855
trainer/gradient_norm                       312.441
trainer/gradient_penalty                     -1.56221
trainer/gradient_percentage                  -0.00881594
exploration/num steps total              459000
exploration/num paths total                1615
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.65506
exploration/Rewards Std                       1.2585
exploration/Rewards Max                       9.68035
exploration/Rewards Min                      -0.644735
exploration/Returns Mean                   4655.06
exploration/Returns Std                       0
exploration/Returns Max                    4655.06
exploration/Returns Min                    4655.06
exploration/Num Paths                         1
exploration/Average Returns                4655.06
evaluation_0/num steps total                  3.55881e+06
evaluation_0/num paths total              11156
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75021
evaluation_0/Rewards Std                      1.20651
evaluation_0/Rewards Max                      9.79195
evaluation_0/Rewards Min                     -0.608516
evaluation_0/Returns Mean                  4750.21
evaluation_0/Returns Std                     18.9696
evaluation_0/Returns Max                   4771.86
evaluation_0/Returns Min                   4719.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4750.21
time/epoch (s)                                0
time/total (s)                             8777.7
Epoch                                       454
---------------------------------------  ----------------
2022-11-16 13:12:20.380223 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 455 finished
---------------------------------------  ----------------
epoch                                       455
total_step                               460000
replay_pool/size                         460000
trainer/alpha                                 0.0684707
trainer/alpha_loss                           -1.50292
trainer/entropy                              -5.4395
trainer/qf_loss                              10.7613
trainer/state_noise                           0.005
trainer/policy_loss                        -180.592
trainer/policy_loss_without_entropy         182.566
trainer/entropy_penalty                      -0.372446
trainer/entropy_percentage                   -0.00204007
trainer/Q1Pred Mean                         182.413
trainer/Q1Pred Std                           72.3749
trainer/Q1Pred Max                          287.234
trainer/Q1Pred Min                          -16.7497
trainer/Q2Pred Mean                         182.698
trainer/Q2Pred Std                           72.4511
trainer/Q2Pred Max                          287.564
trainer/Q2Pred Min                          -17.3426
trainer/QTargetWithReg Mean                 182.212
trainer/QTargetWithReg Std                   72.6777
trainer/QTargetWithReg Max                  287.292
trainer/QTargetWithReg Min                  -19.869
trainer/PolicyLossWithoutReg Mean           182.566
trainer/PolicyLossWithoutReg Std             71.7421
trainer/PolicyLossWithoutReg Max            286.929
trainer/PolicyLossWithoutReg Min            -18.9411
trainer/gradient_norm                       320.139
trainer/gradient_penalty                     -1.60069
trainer/gradient_percentage                  -0.00876777
exploration/num steps total              460000
exploration/num paths total                1616
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71323
exploration/Rewards Std                       1.25958
exploration/Rewards Max                       9.96861
exploration/Rewards Min                      -0.565714
exploration/Returns Mean                   4713.23
exploration/Returns Std                       0
exploration/Returns Max                    4713.23
exploration/Returns Min                    4713.23
exploration/Num Paths                         1
exploration/Average Returns                4713.23
evaluation_0/num steps total                  3.56681e+06
evaluation_0/num paths total              11164
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75907
evaluation_0/Rewards Std                      1.20106
evaluation_0/Rewards Max                     10.0144
evaluation_0/Rewards Min                     -0.572512
evaluation_0/Returns Mean                  4759.07
evaluation_0/Returns Std                     34.6937
evaluation_0/Returns Max                   4802.5
evaluation_0/Returns Min                   4712.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4759.07
time/epoch (s)                                0
time/total (s)                             8794.22
Epoch                                       455
---------------------------------------  ----------------
2022-11-16 13:12:36.237347 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 456 finished
---------------------------------------  ----------------
epoch                                       456
total_step                               461000
replay_pool/size                         461000
trainer/alpha                                 0.068274
trainer/alpha_loss                            0.00487615
trainer/entropy                              -6.00182
trainer/qf_loss                               6.81304
trainer/state_noise                           0.005
trainer/policy_loss                        -188.985
trainer/policy_loss_without_entropy         190.917
trainer/entropy_penalty                      -0.409768
trainer/entropy_percentage                   -0.00214632
trainer/Q1Pred Mean                         189.993
trainer/Q1Pred Std                           67.3967
trainer/Q1Pred Max                          292.306
trainer/Q1Pred Min                           -5.23552
trainer/Q2Pred Mean                         189.672
trainer/Q2Pred Std                           67.3396
trainer/Q2Pred Max                          291.907
trainer/Q2Pred Min                            6.35484
trainer/QTargetWithReg Mean                 189.703
trainer/QTargetWithReg Std                   67.2715
trainer/QTargetWithReg Max                  292.401
trainer/QTargetWithReg Min                   -0.394824
trainer/PolicyLossWithoutReg Mean           190.917
trainer/PolicyLossWithoutReg Std             65.9248
trainer/PolicyLossWithoutReg Max            291.553
trainer/PolicyLossWithoutReg Min             21.1559
trainer/gradient_norm                       304.473
trainer/gradient_penalty                     -1.52236
trainer/gradient_percentage                  -0.00797397
exploration/num steps total              461000
exploration/num paths total                1617
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73007
exploration/Rewards Std                       1.25439
exploration/Rewards Max                       9.80939
exploration/Rewards Min                      -0.673553
exploration/Returns Mean                   4730.07
exploration/Returns Std                       0
exploration/Returns Max                    4730.07
exploration/Returns Min                    4730.07
exploration/Num Paths                         1
exploration/Average Returns                4730.07
evaluation_0/num steps total                  3.57481e+06
evaluation_0/num paths total              11172
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85557
evaluation_0/Rewards Std                      1.18759
evaluation_0/Rewards Max                     10.001
evaluation_0/Rewards Min                     -0.657088
evaluation_0/Returns Mean                  4855.57
evaluation_0/Returns Std                     16.0015
evaluation_0/Returns Max                   4875.7
evaluation_0/Returns Min                   4823.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4855.57
time/epoch (s)                                0
time/total (s)                             8810.08
Epoch                                       456
---------------------------------------  ----------------
2022-11-16 13:12:52.674337 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 457 finished
---------------------------------------  ----------------
epoch                                       457
total_step                               462000
replay_pool/size                         462000
trainer/alpha                                 0.067724
trainer/alpha_loss                            0.689345
trainer/entropy                              -6.25602
trainer/qf_loss                               8.0176
trainer/state_noise                           0.005
trainer/policy_loss                        -183.361
trainer/policy_loss_without_entropy         185.29
trainer/entropy_penalty                      -0.423683
trainer/entropy_percentage                   -0.0022866
trainer/Q1Pred Mean                         183.942
trainer/Q1Pred Std                           67.0257
trainer/Q1Pred Max                          289.706
trainer/Q1Pred Min                           -7.25327
trainer/Q2Pred Mean                         184.261
trainer/Q2Pred Std                           66.8579
trainer/Q2Pred Max                          288.437
trainer/Q2Pred Min                           -8.50923
trainer/QTargetWithReg Mean                 184.192
trainer/QTargetWithReg Std                   66.7526
trainer/QTargetWithReg Max                  289.187
trainer/QTargetWithReg Min                  -12.7827
trainer/PolicyLossWithoutReg Mean           185.29
trainer/PolicyLossWithoutReg Std             66.2094
trainer/PolicyLossWithoutReg Max            288.875
trainer/PolicyLossWithoutReg Min             -8.47658
trainer/gradient_norm                       300.95
trainer/gradient_penalty                     -1.50475
trainer/gradient_percentage                  -0.00812108
exploration/num steps total              462000
exploration/num paths total                1618
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66161
exploration/Rewards Std                       1.24565
exploration/Rewards Max                       9.94881
exploration/Rewards Min                      -0.636941
exploration/Returns Mean                   4661.61
exploration/Returns Std                       0
exploration/Returns Max                    4661.61
exploration/Returns Min                    4661.61
exploration/Num Paths                         1
exploration/Average Returns                4661.61
evaluation_0/num steps total                  3.58281e+06
evaluation_0/num paths total              11180
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78892
evaluation_0/Rewards Std                      1.19821
evaluation_0/Rewards Max                      9.9653
evaluation_0/Rewards Min                     -0.5917
evaluation_0/Returns Mean                  4788.92
evaluation_0/Returns Std                     11.1877
evaluation_0/Returns Max                   4803.4
evaluation_0/Returns Min                   4772.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4788.92
time/epoch (s)                                0
time/total (s)                             8826.51
Epoch                                       457
---------------------------------------  ----------------
2022-11-16 13:13:08.514162 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 458 finished
---------------------------------------  ----------------
epoch                                       458
total_step                               463000
replay_pool/size                         463000
trainer/alpha                                 0.0678639
trainer/alpha_loss                            0.845745
trainer/entropy                              -6.31436
trainer/qf_loss                               7.8271
trainer/state_noise                           0.005
trainer/policy_loss                        -186.176
trainer/policy_loss_without_entropy         188.233
trainer/entropy_penalty                      -0.428517
trainer/entropy_percentage                   -0.00227653
trainer/Q1Pred Mean                         187.369
trainer/Q1Pred Std                           67.1469
trainer/Q1Pred Max                          288.132
trainer/Q1Pred Min                            9.49221
trainer/Q2Pred Mean                         187.234
trainer/Q2Pred Std                           67.3075
trainer/Q2Pred Max                          288.044
trainer/Q2Pred Min                            1.9945
trainer/QTargetWithReg Mean                 187.423
trainer/QTargetWithReg Std                   67.2286
trainer/QTargetWithReg Max                  286.452
trainer/QTargetWithReg Min                    3.3444
trainer/PolicyLossWithoutReg Mean           188.233
trainer/PolicyLossWithoutReg Std             66.5292
trainer/PolicyLossWithoutReg Max            288.088
trainer/PolicyLossWithoutReg Min             10.1325
trainer/gradient_norm                       325.753
trainer/gradient_penalty                     -1.62877
trainer/gradient_percentage                  -0.00865293
exploration/num steps total              463000
exploration/num paths total                1619
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.59035
exploration/Rewards Std                       1.22003
exploration/Rewards Max                       9.94469
exploration/Rewards Min                      -0.443929
exploration/Returns Mean                   4590.35
exploration/Returns Std                       0
exploration/Returns Max                    4590.35
exploration/Returns Min                    4590.35
exploration/Num Paths                         1
exploration/Average Returns                4590.35
evaluation_0/num steps total                  3.59081e+06
evaluation_0/num paths total              11188
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77278
evaluation_0/Rewards Std                      1.1983
evaluation_0/Rewards Max                     10.0174
evaluation_0/Rewards Min                     -0.601394
evaluation_0/Returns Mean                  4772.78
evaluation_0/Returns Std                     13.3608
evaluation_0/Returns Max                   4794.38
evaluation_0/Returns Min                   4756.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4772.78
time/epoch (s)                                0
time/total (s)                             8842.35
Epoch                                       458
---------------------------------------  ----------------
2022-11-16 13:13:24.697747 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 459 finished
---------------------------------------  ----------------
epoch                                       459
total_step                               464000
replay_pool/size                         464000
trainer/alpha                                 0.0682241
trainer/alpha_loss                            0.79679
trainer/entropy                              -6.29675
trainer/qf_loss                               7.59989
trainer/state_noise                           0.005
trainer/policy_loss                        -190.308
trainer/policy_loss_without_entropy         192.372
trainer/entropy_penalty                      -0.42959
trainer/entropy_percentage                   -0.00223312
trainer/Q1Pred Mean                         190.149
trainer/Q1Pred Std                           59.0352
trainer/Q1Pred Max                          283.093
trainer/Q1Pred Min                           -4.32424
trainer/Q2Pred Mean                         190.955
trainer/Q2Pred Std                           59.4339
trainer/Q2Pred Max                          283.481
trainer/Q2Pred Min                           -8.46308
trainer/QTargetWithReg Mean                 191.229
trainer/QTargetWithReg Std                   59.1297
trainer/QTargetWithReg Max                  283.241
trainer/QTargetWithReg Min                   -0.955628
trainer/PolicyLossWithoutReg Mean           192.372
trainer/PolicyLossWithoutReg Std             57.5889
trainer/PolicyLossWithoutReg Max            283.368
trainer/PolicyLossWithoutReg Min              2.19764
trainer/gradient_norm                       326.829
trainer/gradient_penalty                     -1.63415
trainer/gradient_percentage                  -0.00849473
exploration/num steps total              464000
exploration/num paths total                1620
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7397
exploration/Rewards Std                       1.25195
exploration/Rewards Max                       9.99885
exploration/Rewards Min                      -0.573828
exploration/Returns Mean                   4739.7
exploration/Returns Std                       0
exploration/Returns Max                    4739.7
exploration/Returns Min                    4739.7
exploration/Num Paths                         1
exploration/Average Returns                4739.7
evaluation_0/num steps total                  3.59881e+06
evaluation_0/num paths total              11196
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78399
evaluation_0/Rewards Std                      1.22716
evaluation_0/Rewards Max                      9.88782
evaluation_0/Rewards Min                     -0.620031
evaluation_0/Returns Mean                  4783.99
evaluation_0/Returns Std                     14.0538
evaluation_0/Returns Max                   4807.2
evaluation_0/Returns Min                   4759.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4783.99
time/epoch (s)                                0
time/total (s)                             8858.53
Epoch                                       459
---------------------------------------  ----------------
2022-11-16 13:13:40.610259 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 460 finished
---------------------------------------  ----------------
epoch                                       460
total_step                               465000
replay_pool/size                         465000
trainer/alpha                                 0.067431
trainer/alpha_loss                           -0.562862
trainer/entropy                              -5.79127
trainer/qf_loss                               7.56295
trainer/state_noise                           0.005
trainer/policy_loss                        -185.376
trainer/policy_loss_without_entropy         187.425
trainer/entropy_penalty                      -0.390511
trainer/entropy_percentage                   -0.00208355
trainer/Q1Pred Mean                         186.952
trainer/Q1Pred Std                           67.4687
trainer/Q1Pred Max                          290.392
trainer/Q1Pred Min                           -1.91647
trainer/Q2Pred Mean                         186.663
trainer/Q2Pred Std                           67.4386
trainer/Q2Pred Max                          288.921
trainer/Q2Pred Min                           -6.688
trainer/QTargetWithReg Mean                 186.75
trainer/QTargetWithReg Std                   67.1996
trainer/QTargetWithReg Max                  289.407
trainer/QTargetWithReg Min                    0.176479
trainer/PolicyLossWithoutReg Mean           187.425
trainer/PolicyLossWithoutReg Std             66.4426
trainer/PolicyLossWithoutReg Max            289.323
trainer/PolicyLossWithoutReg Min              1.49431
trainer/gradient_norm                       331.693
trainer/gradient_penalty                     -1.65847
trainer/gradient_percentage                  -0.00884869
exploration/num steps total              465000
exploration/num paths total                1621
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71555
exploration/Rewards Std                       1.27619
exploration/Rewards Max                      10.562
exploration/Rewards Min                      -0.571425
exploration/Returns Mean                   4715.55
exploration/Returns Std                       0
exploration/Returns Max                    4715.55
exploration/Returns Min                    4715.55
exploration/Num Paths                         1
exploration/Average Returns                4715.55
evaluation_0/num steps total                  3.60681e+06
evaluation_0/num paths total              11204
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77447
evaluation_0/Rewards Std                      1.19801
evaluation_0/Rewards Max                      9.96479
evaluation_0/Rewards Min                     -0.498653
evaluation_0/Returns Mean                  4774.47
evaluation_0/Returns Std                     24.838
evaluation_0/Returns Max                   4816.69
evaluation_0/Returns Min                   4728.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4774.47
time/epoch (s)                                0
time/total (s)                             8874.45
Epoch                                       460
---------------------------------------  ----------------
2022-11-16 13:13:56.504705 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 461 finished
---------------------------------------  ----------------
epoch                                       461
total_step                               466000
replay_pool/size                         466000
trainer/alpha                                 0.0695427
trainer/alpha_loss                           -0.144014
trainer/entropy                              -5.94597
trainer/qf_loss                               7.94452
trainer/state_noise                           0.005
trainer/policy_loss                        -187.079
trainer/policy_loss_without_entropy         189.026
trainer/entropy_penalty                      -0.413499
trainer/entropy_percentage                   -0.00218753
trainer/Q1Pred Mean                         188.514
trainer/Q1Pred Std                           62.6013
trainer/Q1Pred Max                          285.844
trainer/Q1Pred Min                          -12.0342
trainer/Q2Pred Mean                         188.204
trainer/Q2Pred Std                           63.2127
trainer/Q2Pred Max                          286.416
trainer/Q2Pred Min                          -18.076
trainer/QTargetWithReg Mean                 188.838
trainer/QTargetWithReg Std                   62.9697
trainer/QTargetWithReg Max                  286.774
trainer/QTargetWithReg Min                  -10.6747
trainer/PolicyLossWithoutReg Mean           189.026
trainer/PolicyLossWithoutReg Std             61.9804
trainer/PolicyLossWithoutReg Max            285.348
trainer/PolicyLossWithoutReg Min             -9.2959
trainer/gradient_norm                       306.506
trainer/gradient_penalty                     -1.53253
trainer/gradient_percentage                  -0.00810754
exploration/num steps total              466000
exploration/num paths total                1622
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63857
exploration/Rewards Std                       1.25664
exploration/Rewards Max                      10.2681
exploration/Rewards Min                      -0.545707
exploration/Returns Mean                   4638.57
exploration/Returns Std                       0
exploration/Returns Max                    4638.57
exploration/Returns Min                    4638.57
exploration/Num Paths                         1
exploration/Average Returns                4638.57
evaluation_0/num steps total                  3.61481e+06
evaluation_0/num paths total              11212
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70344
evaluation_0/Rewards Std                      1.2187
evaluation_0/Rewards Max                     10.0681
evaluation_0/Rewards Min                     -0.467057
evaluation_0/Returns Mean                  4703.44
evaluation_0/Returns Std                     22.2563
evaluation_0/Returns Max                   4735.96
evaluation_0/Returns Min                   4671.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4703.44
time/epoch (s)                                0
time/total (s)                             8890.34
Epoch                                       461
---------------------------------------  ----------------
2022-11-16 13:14:13.011342 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 462 finished
---------------------------------------  ----------------
epoch                                       462
total_step                               467000
replay_pool/size                         467000
trainer/alpha                                 0.0679341
trainer/alpha_loss                           -0.824113
trainer/entropy                              -5.69356
trainer/qf_loss                               8.16807
trainer/state_noise                           0.005
trainer/policy_loss                        -187.129
trainer/policy_loss_without_entropy         189.069
trainer/entropy_penalty                      -0.386787
trainer/entropy_percentage                   -0.00204575
trainer/Q1Pred Mean                         188.745
trainer/Q1Pred Std                           65.1002
trainer/Q1Pred Max                          289.337
trainer/Q1Pred Min                            4.46729
trainer/Q2Pred Mean                         189.102
trainer/Q2Pred Std                           65.4267
trainer/Q2Pred Max                          289.972
trainer/Q2Pred Min                            1.03725
trainer/QTargetWithReg Mean                 188.196
trainer/QTargetWithReg Std                   65.4008
trainer/QTargetWithReg Max                  289.548
trainer/QTargetWithReg Min                    5.6629
trainer/PolicyLossWithoutReg Mean           189.069
trainer/PolicyLossWithoutReg Std             64.7416
trainer/PolicyLossWithoutReg Max            288.93
trainer/PolicyLossWithoutReg Min              4.27198
trainer/gradient_norm                       310.562
trainer/gradient_penalty                     -1.55281
trainer/gradient_percentage                  -0.00821293
exploration/num steps total              467000
exploration/num paths total                1623
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.5908
exploration/Rewards Std                       1.24095
exploration/Rewards Max                       9.92464
exploration/Rewards Min                      -0.647593
exploration/Returns Mean                   4590.8
exploration/Returns Std                       0
exploration/Returns Max                    4590.8
exploration/Returns Min                    4590.8
exploration/Num Paths                         1
exploration/Average Returns                4590.8
evaluation_0/num steps total                  3.62281e+06
evaluation_0/num paths total              11220
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.51522
evaluation_0/Rewards Std                      1.24963
evaluation_0/Rewards Max                     10.119
evaluation_0/Rewards Min                     -0.620829
evaluation_0/Returns Mean                  4515.22
evaluation_0/Returns Std                     14.6015
evaluation_0/Returns Max                   4532.02
evaluation_0/Returns Min                   4492.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4515.22
time/epoch (s)                                0
time/total (s)                             8906.85
Epoch                                       462
---------------------------------------  ----------------
2022-11-16 13:14:28.774805 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 463 finished
---------------------------------------  ----------------
epoch                                       463
total_step                               468000
replay_pool/size                         468000
trainer/alpha                                 0.0673576
trainer/alpha_loss                           -0.28067
trainer/entropy                              -5.89596
trainer/qf_loss                               8.74605
trainer/state_noise                           0.005
trainer/policy_loss                        -183.433
trainer/policy_loss_without_entropy         185.393
trainer/entropy_penalty                      -0.397138
trainer/entropy_percentage                   -0.00214214
trainer/Q1Pred Mean                         184.045
trainer/Q1Pred Std                           66.64
trainer/Q1Pred Max                          291.932
trainer/Q1Pred Min                            8.36066
trainer/Q2Pred Mean                         184.402
trainer/Q2Pred Std                           66.6282
trainer/Q2Pred Max                          290.938
trainer/Q2Pred Min                           11.8457
trainer/QTargetWithReg Mean                 183.651
trainer/QTargetWithReg Std                   66.6976
trainer/QTargetWithReg Max                  289.992
trainer/QTargetWithReg Min                   11.4427
trainer/PolicyLossWithoutReg Mean           185.393
trainer/PolicyLossWithoutReg Std             66.0951
trainer/PolicyLossWithoutReg Max            291.832
trainer/PolicyLossWithoutReg Min             11.182
trainer/gradient_norm                       312.449
trainer/gradient_penalty                     -1.56225
trainer/gradient_percentage                  -0.00842668
exploration/num steps total              468000
exploration/num paths total                1624
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6914
exploration/Rewards Std                       1.21578
exploration/Rewards Max                       9.73676
exploration/Rewards Min                      -0.616487
exploration/Returns Mean                   4691.4
exploration/Returns Std                       0
exploration/Returns Max                    4691.4
exploration/Returns Min                    4691.4
exploration/Num Paths                         1
exploration/Average Returns                4691.4
evaluation_0/num steps total                  3.63081e+06
evaluation_0/num paths total              11228
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72742
evaluation_0/Rewards Std                      1.19138
evaluation_0/Rewards Max                      9.72568
evaluation_0/Rewards Min                     -0.522182
evaluation_0/Returns Mean                  4727.42
evaluation_0/Returns Std                     18.3964
evaluation_0/Returns Max                   4748.04
evaluation_0/Returns Min                   4703.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4727.42
time/epoch (s)                                0
time/total (s)                             8922.61
Epoch                                       463
---------------------------------------  ----------------
2022-11-16 13:14:45.351863 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 464 finished
---------------------------------------  ----------------
epoch                                       464
total_step                               469000
replay_pool/size                         469000
trainer/alpha                                 0.0698459
trainer/alpha_loss                           -1.22008
trainer/entropy                              -5.54158
trainer/qf_loss                               4.76171
trainer/state_noise                           0.005
trainer/policy_loss                        -185.29
trainer/policy_loss_without_entropy         187.255
trainer/entropy_penalty                      -0.387057
trainer/entropy_percentage                   -0.002067
trainer/Q1Pred Mean                         186.227
trainer/Q1Pred Std                           65.2568
trainer/Q1Pred Max                          290.773
trainer/Q1Pred Min                            7.39027
trainer/Q2Pred Mean                         186.304
trainer/Q2Pred Std                           65.2414
trainer/Q2Pred Max                          289.983
trainer/Q2Pred Min                            1.51658
trainer/QTargetWithReg Mean                 186.236
trainer/QTargetWithReg Std                   65.4073
trainer/QTargetWithReg Max                  291.548
trainer/QTargetWithReg Min                   -0.90455
trainer/PolicyLossWithoutReg Mean           187.255
trainer/PolicyLossWithoutReg Std             63.7853
trainer/PolicyLossWithoutReg Max            290.002
trainer/PolicyLossWithoutReg Min              5.20376
trainer/gradient_norm                       315.598
trainer/gradient_penalty                     -1.57799
trainer/gradient_percentage                  -0.00842695
exploration/num steps total              469000
exploration/num paths total                1625
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68021
exploration/Rewards Std                       1.27366
exploration/Rewards Max                       9.95756
exploration/Rewards Min                      -0.523638
exploration/Returns Mean                   4680.21
exploration/Returns Std                       0
exploration/Returns Max                    4680.21
exploration/Returns Min                    4680.21
exploration/Num Paths                         1
exploration/Average Returns                4680.21
evaluation_0/num steps total                  3.63881e+06
evaluation_0/num paths total              11236
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70163
evaluation_0/Rewards Std                      1.29922
evaluation_0/Rewards Max                      9.96841
evaluation_0/Rewards Min                     -0.584774
evaluation_0/Returns Mean                  4701.63
evaluation_0/Returns Std                     43.7128
evaluation_0/Returns Max                   4777.68
evaluation_0/Returns Min                   4644.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4701.63
time/epoch (s)                                0
time/total (s)                             8939.19
Epoch                                       464
---------------------------------------  ----------------
2022-11-16 13:15:01.194266 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 465 finished
---------------------------------------  ----------------
epoch                                       465
total_step                               470000
replay_pool/size                         470000
trainer/alpha                                 0.068753
trainer/alpha_loss                           -0.970272
trainer/entropy                              -5.63755
trainer/qf_loss                               6.62145
trainer/state_noise                           0.005
trainer/policy_loss                        -197.885
trainer/policy_loss_without_entropy         199.901
trainer/entropy_penalty                      -0.387599
trainer/entropy_percentage                   -0.00193896
trainer/Q1Pred Mean                         199.5
trainer/Q1Pred Std                           64.5128
trainer/Q1Pred Max                          293.809
trainer/Q1Pred Min                           10.6619
trainer/Q2Pred Mean                         198.77
trainer/Q2Pred Std                           64.3071
trainer/Q2Pred Max                          293.527
trainer/Q2Pred Min                            9.79326
trainer/QTargetWithReg Mean                 199.252
trainer/QTargetWithReg Std                   64.6013
trainer/QTargetWithReg Max                  293.935
trainer/QTargetWithReg Min                    5.84837
trainer/PolicyLossWithoutReg Mean           199.901
trainer/PolicyLossWithoutReg Std             63.5011
trainer/PolicyLossWithoutReg Max            293.681
trainer/PolicyLossWithoutReg Min             10.2735
trainer/gradient_norm                       325.61
trainer/gradient_penalty                     -1.62805
trainer/gradient_percentage                  -0.00814431
exploration/num steps total              470000
exploration/num paths total                1626
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67814
exploration/Rewards Std                       1.26502
exploration/Rewards Max                      10.0518
exploration/Rewards Min                      -0.711409
exploration/Returns Mean                   4678.14
exploration/Returns Std                       0
exploration/Returns Max                    4678.14
exploration/Returns Min                    4678.14
exploration/Num Paths                         1
exploration/Average Returns                4678.14
evaluation_0/num steps total                  3.64681e+06
evaluation_0/num paths total              11244
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68179
evaluation_0/Rewards Std                      1.2065
evaluation_0/Rewards Max                      9.85917
evaluation_0/Rewards Min                     -0.586505
evaluation_0/Returns Mean                  4681.79
evaluation_0/Returns Std                     28.4341
evaluation_0/Returns Max                   4718.06
evaluation_0/Returns Min                   4622
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4681.79
time/epoch (s)                                0
time/total (s)                             8955.03
Epoch                                       465
---------------------------------------  ----------------
2022-11-16 13:15:17.526175 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 466 finished
---------------------------------------  ----------------
epoch                                       466
total_step                               471000
replay_pool/size                         471000
trainer/alpha                                 0.0693089
trainer/alpha_loss                           -0.513283
trainer/entropy                              -5.8077
trainer/qf_loss                               9.73186
trainer/state_noise                           0.005
trainer/policy_loss                        -184.035
trainer/policy_loss_without_entropy         186.026
trainer/entropy_penalty                      -0.402525
trainer/entropy_percentage                   -0.00216381
trainer/Q1Pred Mean                         185.653
trainer/Q1Pred Std                           69.5099
trainer/Q1Pred Max                          287.425
trainer/Q1Pred Min                          -11.3632
trainer/Q2Pred Mean                         184.754
trainer/Q2Pred Std                           69.4935
trainer/Q2Pred Max                          284.234
trainer/Q2Pred Min                          -17.0645
trainer/QTargetWithReg Mean                 185.522
trainer/QTargetWithReg Std                   69.6232
trainer/QTargetWithReg Max                  285.957
trainer/QTargetWithReg Min                  -13.885
trainer/PolicyLossWithoutReg Mean           186.026
trainer/PolicyLossWithoutReg Std             68.5821
trainer/PolicyLossWithoutReg Max            284.093
trainer/PolicyLossWithoutReg Min             -6.37567
trainer/gradient_norm                       317.66
trainer/gradient_penalty                     -1.5883
trainer/gradient_percentage                  -0.00853804
exploration/num steps total              471000
exploration/num paths total                1627
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67098
exploration/Rewards Std                       1.23851
exploration/Rewards Max                       9.84492
exploration/Rewards Min                      -0.511725
exploration/Returns Mean                   4670.98
exploration/Returns Std                       0
exploration/Returns Max                    4670.98
exploration/Returns Min                    4670.98
exploration/Num Paths                         1
exploration/Average Returns                4670.98
evaluation_0/num steps total                  3.65481e+06
evaluation_0/num paths total              11252
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88749
evaluation_0/Rewards Std                      1.27229
evaluation_0/Rewards Max                     10.3119
evaluation_0/Rewards Min                     -0.541179
evaluation_0/Returns Mean                  4887.49
evaluation_0/Returns Std                     28.8204
evaluation_0/Returns Max                   4927.84
evaluation_0/Returns Min                   4842.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.49
time/epoch (s)                                0
time/total (s)                             8971.36
Epoch                                       466
---------------------------------------  ----------------
2022-11-16 13:15:33.381750 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 467 finished
---------------------------------------  ----------------
epoch                                       467
total_step                               472000
replay_pool/size                         472000
trainer/alpha                                 0.0690818
trainer/alpha_loss                           -1.14378
trainer/entropy                              -5.572
trainer/qf_loss                               5.95078
trainer/state_noise                           0.005
trainer/policy_loss                        -191.26
trainer/policy_loss_without_entropy         193.232
trainer/entropy_penalty                      -0.384924
trainer/entropy_percentage                   -0.00199203
trainer/Q1Pred Mean                         192.314
trainer/Q1Pred Std                           62.9871
trainer/Q1Pred Max                          290.623
trainer/Q1Pred Min                            9.73578
trainer/Q2Pred Mean                         192.048
trainer/Q2Pred Std                           62.8535
trainer/Q2Pred Max                          291.4
trainer/Q2Pred Min                           10.706
trainer/QTargetWithReg Mean                 192.569
trainer/QTargetWithReg Std                   62.8324
trainer/QTargetWithReg Max                  290.477
trainer/QTargetWithReg Min                   11.107
trainer/PolicyLossWithoutReg Mean           193.232
trainer/PolicyLossWithoutReg Std             62.202
trainer/PolicyLossWithoutReg Max            291.838
trainer/PolicyLossWithoutReg Min              9.85687
trainer/gradient_norm                       317.393
trainer/gradient_penalty                     -1.58696
trainer/gradient_percentage                  -0.00821274
exploration/num steps total              472000
exploration/num paths total                1628
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75062
exploration/Rewards Std                       1.23736
exploration/Rewards Max                      10.2144
exploration/Rewards Min                      -0.431103
exploration/Returns Mean                   4750.62
exploration/Returns Std                       0
exploration/Returns Max                    4750.62
exploration/Returns Min                    4750.62
exploration/Num Paths                         1
exploration/Average Returns                4750.62
evaluation_0/num steps total                  3.66281e+06
evaluation_0/num paths total              11260
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69383
evaluation_0/Rewards Std                      1.21898
evaluation_0/Rewards Max                      9.89933
evaluation_0/Rewards Min                     -0.614355
evaluation_0/Returns Mean                  4693.83
evaluation_0/Returns Std                     11.1026
evaluation_0/Returns Max                   4707.54
evaluation_0/Returns Min                   4672.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4693.83
time/epoch (s)                                0
time/total (s)                             8987.22
Epoch                                       467
---------------------------------------  ----------------
2022-11-16 13:15:49.893485 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 468 finished
---------------------------------------  ----------------
epoch                                       468
total_step                               473000
replay_pool/size                         473000
trainer/alpha                                 0.0684445
trainer/alpha_loss                            0.36703
trainer/entropy                              -6.13686
trainer/qf_loss                               7.54021
trainer/state_noise                           0.005
trainer/policy_loss                        -185.347
trainer/policy_loss_without_entropy         187.33
trainer/entropy_penalty                      -0.420035
trainer/entropy_percentage                   -0.00224221
trainer/Q1Pred Mean                         186.607
trainer/Q1Pred Std                           72.4357
trainer/Q1Pred Max                          292.16
trainer/Q1Pred Min                          -12.463
trainer/Q2Pred Mean                         185.982
trainer/Q2Pred Std                           72.2619
trainer/Q2Pred Max                          291.622
trainer/Q2Pred Min                           -5.45654
trainer/QTargetWithReg Mean                 186.953
trainer/QTargetWithReg Std                   72.8177
trainer/QTargetWithReg Max                  293.023
trainer/QTargetWithReg Min                   -7.35613
trainer/PolicyLossWithoutReg Mean           187.33
trainer/PolicyLossWithoutReg Std             71.0496
trainer/PolicyLossWithoutReg Max            292.659
trainer/PolicyLossWithoutReg Min              0.107496
trainer/gradient_norm                       312.756
trainer/gradient_penalty                     -1.56378
trainer/gradient_percentage                  -0.00834772
exploration/num steps total              473000
exploration/num paths total                1629
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84314
exploration/Rewards Std                       1.23334
exploration/Rewards Max                      10.2369
exploration/Rewards Min                      -0.677331
exploration/Returns Mean                   4843.14
exploration/Returns Std                       0
exploration/Returns Max                    4843.14
exploration/Returns Min                    4843.14
exploration/Num Paths                         1
exploration/Average Returns                4843.14
evaluation_0/num steps total                  3.67081e+06
evaluation_0/num paths total              11268
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68721
evaluation_0/Rewards Std                      1.1823
evaluation_0/Rewards Max                      9.81269
evaluation_0/Rewards Min                     -0.626341
evaluation_0/Returns Mean                  4687.21
evaluation_0/Returns Std                      9.30617
evaluation_0/Returns Max                   4702.62
evaluation_0/Returns Min                   4672.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4687.21
time/epoch (s)                                0
time/total (s)                             9003.73
Epoch                                       468
---------------------------------------  ----------------
2022-11-16 13:16:05.703019 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 469 finished
---------------------------------------  ----------------
epoch                                       469
total_step                               474000
replay_pool/size                         474000
trainer/alpha                                 0.0677235
trainer/alpha_loss                            0.195667
trainer/entropy                              -6.07268
trainer/qf_loss                              10.5325
trainer/state_noise                           0.005
trainer/policy_loss                        -184.626
trainer/policy_loss_without_entropy         186.659
trainer/entropy_penalty                      -0.411263
trainer/entropy_percentage                   -0.00220329
trainer/Q1Pred Mean                         186.199
trainer/Q1Pred Std                           69.4482
trainer/Q1Pred Max                          294.675
trainer/Q1Pred Min                          -14.5721
trainer/Q2Pred Mean                         186.091
trainer/Q2Pred Std                           69.6134
trainer/Q2Pred Max                          298.502
trainer/Q2Pred Min                          -10.4392
trainer/QTargetWithReg Mean                 185.84
trainer/QTargetWithReg Std                   69.4576
trainer/QTargetWithReg Max                  294.702
trainer/QTargetWithReg Min                  -14.5021
trainer/PolicyLossWithoutReg Mean           186.659
trainer/PolicyLossWithoutReg Std             68.0148
trainer/PolicyLossWithoutReg Max            293.351
trainer/PolicyLossWithoutReg Min             -2.66039
trainer/gradient_norm                       324.232
trainer/gradient_penalty                     -1.62116
trainer/gradient_percentage                  -0.00868515
exploration/num steps total              474000
exploration/num paths total                1630
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61401
exploration/Rewards Std                       1.22247
exploration/Rewards Max                      10.1413
exploration/Rewards Min                      -0.596828
exploration/Returns Mean                   4614.01
exploration/Returns Std                       0
exploration/Returns Max                    4614.01
exploration/Returns Min                    4614.01
exploration/Num Paths                         1
exploration/Average Returns                4614.01
evaluation_0/num steps total                  3.67881e+06
evaluation_0/num paths total              11276
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6284
evaluation_0/Rewards Std                      1.20489
evaluation_0/Rewards Max                      9.93674
evaluation_0/Rewards Min                     -0.679862
evaluation_0/Returns Mean                  4628.4
evaluation_0/Returns Std                     18.3112
evaluation_0/Returns Max                   4660.33
evaluation_0/Returns Min                   4598.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4628.4
time/epoch (s)                                0
time/total (s)                             9019.54
Epoch                                       469
---------------------------------------  ----------------
2022-11-16 13:16:21.724560 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 470 finished
---------------------------------------  ----------------
epoch                                       470
total_step                               475000
replay_pool/size                         475000
trainer/alpha                                 0.0671523
trainer/alpha_loss                            1.39181
trainer/entropy                              -6.51534
trainer/qf_loss                              10.084
trainer/state_noise                           0.005
trainer/policy_loss                        -188.677
trainer/policy_loss_without_entropy         190.752
trainer/entropy_penalty                      -0.437521
trainer/entropy_percentage                   -0.00229366
trainer/Q1Pred Mean                         189.862
trainer/Q1Pred Std                           65.6566
trainer/Q1Pred Max                          289.367
trainer/Q1Pred Min                            3.0377
trainer/Q2Pred Mean                         189.514
trainer/Q2Pred Std                           65.7136
trainer/Q2Pred Max                          290.435
trainer/Q2Pred Min                            3.75183
trainer/QTargetWithReg Mean                 190.068
trainer/QTargetWithReg Std                   66.2322
trainer/QTargetWithReg Max                  289.004
trainer/QTargetWithReg Min                   -1.55885
trainer/PolicyLossWithoutReg Mean           190.752
trainer/PolicyLossWithoutReg Std             64.8908
trainer/PolicyLossWithoutReg Max            290.42
trainer/PolicyLossWithoutReg Min              9.41844
trainer/gradient_norm                       327.518
trainer/gradient_penalty                     -1.63759
trainer/gradient_percentage                  -0.00858492
exploration/num steps total              475000
exploration/num paths total                1631
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7064
exploration/Rewards Std                       1.22544
exploration/Rewards Max                      10.0134
exploration/Rewards Min                      -0.591408
exploration/Returns Mean                   4706.4
exploration/Returns Std                       0
exploration/Returns Max                    4706.4
exploration/Returns Min                    4706.4
exploration/Num Paths                         1
exploration/Average Returns                4706.4
evaluation_0/num steps total                  3.68681e+06
evaluation_0/num paths total              11284
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.33233
evaluation_0/Rewards Std                      1.20706
evaluation_0/Rewards Max                      9.50527
evaluation_0/Rewards Min                     -0.520821
evaluation_0/Returns Mean                  4332.33
evaluation_0/Returns Std                     76.2261
evaluation_0/Returns Max                   4387.23
evaluation_0/Returns Min                   4180.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4332.33
time/epoch (s)                                0
time/total (s)                             9035.56
Epoch                                       470
---------------------------------------  ----------------
2022-11-16 13:16:37.889399 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 471 finished
---------------------------------------  ----------------
epoch                                       471
total_step                               476000
replay_pool/size                         476000
trainer/alpha                                 0.068076
trainer/alpha_loss                           -0.259954
trainer/entropy                              -5.90325
trainer/qf_loss                               8.03599
trainer/state_noise                           0.005
trainer/policy_loss                        -180.053
trainer/policy_loss_without_entropy         182.024
trainer/entropy_penalty                      -0.40187
trainer/entropy_percentage                   -0.00220778
trainer/Q1Pred Mean                         181.415
trainer/Q1Pred Std                           66.79
trainer/Q1Pred Max                          289.044
trainer/Q1Pred Min                            6.58814
trainer/Q2Pred Mean                         181.195
trainer/Q2Pred Std                           66.812
trainer/Q2Pred Max                          289.107
trainer/Q2Pred Min                            5.37965
trainer/QTargetWithReg Mean                 181.943
trainer/QTargetWithReg Std                   66.6344
trainer/QTargetWithReg Max                  288.944
trainer/QTargetWithReg Min                    7.33514
trainer/PolicyLossWithoutReg Mean           182.024
trainer/PolicyLossWithoutReg Std             65.9998
trainer/PolicyLossWithoutReg Max            288.773
trainer/PolicyLossWithoutReg Min              7.71422
trainer/gradient_norm                       313.985
trainer/gradient_penalty                     -1.56992
trainer/gradient_percentage                  -0.00862481
exploration/num steps total              476000
exploration/num paths total                1632
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77373
exploration/Rewards Std                       1.23954
exploration/Rewards Max                      10.1632
exploration/Rewards Min                      -0.478994
exploration/Returns Mean                   4773.73
exploration/Returns Std                       0
exploration/Returns Max                    4773.73
exploration/Returns Min                    4773.73
exploration/Num Paths                         1
exploration/Average Returns                4773.73
evaluation_0/num steps total                  3.69481e+06
evaluation_0/num paths total              11292
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69742
evaluation_0/Rewards Std                      1.23165
evaluation_0/Rewards Max                      9.9249
evaluation_0/Rewards Min                     -0.602004
evaluation_0/Returns Mean                  4697.42
evaluation_0/Returns Std                      9.80391
evaluation_0/Returns Max                   4717.81
evaluation_0/Returns Min                   4687.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4697.42
time/epoch (s)                                0
time/total (s)                             9051.72
Epoch                                       471
---------------------------------------  ----------------
2022-11-16 13:16:53.660572 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 472 finished
---------------------------------------  ----------------
epoch                                       472
total_step                               477000
replay_pool/size                         477000
trainer/alpha                                 0.0678775
trainer/alpha_loss                            0.155876
trainer/entropy                              -6.05794
trainer/qf_loss                              12.5951
trainer/state_noise                           0.005
trainer/policy_loss                        -181.706
trainer/policy_loss_without_entropy         183.728
trainer/entropy_penalty                      -0.411198
trainer/entropy_percentage                   -0.00223809
trainer/Q1Pred Mean                         183.736
trainer/Q1Pred Std                           69.6575
trainer/Q1Pred Max                          290.644
trainer/Q1Pred Min                           -7.25857
trainer/Q2Pred Mean                         183.743
trainer/Q2Pred Std                           69.9511
trainer/Q2Pred Max                          291.333
trainer/Q2Pred Min                           -9.18669
trainer/QTargetWithReg Mean                 183.235
trainer/QTargetWithReg Std                   70.0268
trainer/QTargetWithReg Max                  291.313
trainer/QTargetWithReg Min                   -0.44677
trainer/PolicyLossWithoutReg Mean           183.728
trainer/PolicyLossWithoutReg Std             69.0775
trainer/PolicyLossWithoutReg Max            289.396
trainer/PolicyLossWithoutReg Min             -1.44951
trainer/gradient_norm                       322.019
trainer/gradient_penalty                     -1.61009
trainer/gradient_percentage                  -0.00876348
exploration/num steps total              477000
exploration/num paths total                1633
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63046
exploration/Rewards Std                       1.203
exploration/Rewards Max                       9.59542
exploration/Rewards Min                      -0.532969
exploration/Returns Mean                   4630.46
exploration/Returns Std                       0
exploration/Returns Max                    4630.46
exploration/Returns Min                    4630.46
exploration/Num Paths                         1
exploration/Average Returns                4630.46
evaluation_0/num steps total                  3.70281e+06
evaluation_0/num paths total              11300
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90161
evaluation_0/Rewards Std                      1.23206
evaluation_0/Rewards Max                     10.0505
evaluation_0/Rewards Min                     -0.606583
evaluation_0/Returns Mean                  4901.61
evaluation_0/Returns Std                     11.2641
evaluation_0/Returns Max                   4923.08
evaluation_0/Returns Min                   4881.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4901.61
time/epoch (s)                                0
time/total (s)                             9067.49
Epoch                                       472
---------------------------------------  ----------------
2022-11-16 13:17:09.587094 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 473 finished
---------------------------------------  ----------------
epoch                                       473
total_step                               478000
replay_pool/size                         478000
trainer/alpha                                 0.0688149
trainer/alpha_loss                           -0.025714
trainer/entropy                              -5.99039
trainer/qf_loss                               7.21866
trainer/state_noise                           0.005
trainer/policy_loss                        -186.146
trainer/policy_loss_without_entropy         188.162
trainer/entropy_penalty                      -0.412228
trainer/entropy_percentage                   -0.00219082
trainer/Q1Pred Mean                         186.953
trainer/Q1Pred Std                           68.2865
trainer/Q1Pred Max                          294.977
trainer/Q1Pred Min                            8.75862
trainer/Q2Pred Mean                         187.054
trainer/Q2Pred Std                           68.4993
trainer/Q2Pred Max                          295.198
trainer/Q2Pred Min                           11.509
trainer/QTargetWithReg Mean                 186.73
trainer/QTargetWithReg Std                   68.3292
trainer/QTargetWithReg Max                  293.35
trainer/QTargetWithReg Min                   -0.584188
trainer/PolicyLossWithoutReg Mean           188.162
trainer/PolicyLossWithoutReg Std             67.0512
trainer/PolicyLossWithoutReg Max            294.836
trainer/PolicyLossWithoutReg Min              8.02948
trainer/gradient_norm                       320.86
trainer/gradient_penalty                     -1.6043
trainer/gradient_percentage                  -0.00852616
exploration/num steps total              478000
exploration/num paths total                1634
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.45045
exploration/Rewards Std                       1.29311
exploration/Rewards Max                      10.1094
exploration/Rewards Min                      -0.577785
exploration/Returns Mean                   4450.45
exploration/Returns Std                       0
exploration/Returns Max                    4450.45
exploration/Returns Min                    4450.45
exploration/Num Paths                         1
exploration/Average Returns                4450.45
evaluation_0/num steps total                  3.71081e+06
evaluation_0/num paths total              11308
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.76545
evaluation_0/Rewards Std                      1.20902
evaluation_0/Rewards Max                      9.94759
evaluation_0/Rewards Min                     -0.671039
evaluation_0/Returns Mean                  4765.45
evaluation_0/Returns Std                     16.1929
evaluation_0/Returns Max                   4786.66
evaluation_0/Returns Min                   4739.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4765.45
time/epoch (s)                                0
time/total (s)                             9083.42
Epoch                                       473
---------------------------------------  ----------------
2022-11-16 13:17:42.988654 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 474 finished
---------------------------------------  ----------------
epoch                                       474
total_step                               479000
replay_pool/size                         479000
trainer/alpha                                 0.0673818
trainer/alpha_loss                           -0.70176
trainer/entropy                              -5.73983
trainer/qf_loss                               6.78679
trainer/state_noise                           0.005
trainer/policy_loss                        -179.033
trainer/policy_loss_without_entropy         180.933
trainer/entropy_penalty                      -0.38676
trainer/entropy_percentage                   -0.00213759
trainer/Q1Pred Mean                         179.87
trainer/Q1Pred Std                           69.3427
trainer/Q1Pred Max                          292.86
trainer/Q1Pred Min                           -8.31285
trainer/Q2Pred Mean                         180.123
trainer/Q2Pred Std                           69.3009
trainer/Q2Pred Max                          292.762
trainer/Q2Pred Min                           -9.15577
trainer/QTargetWithReg Mean                 179.813
trainer/QTargetWithReg Std                   69.1057
trainer/QTargetWithReg Max                  291.412
trainer/QTargetWithReg Min                   -6.28506
trainer/PolicyLossWithoutReg Mean           180.933
trainer/PolicyLossWithoutReg Std             68.4947
trainer/PolicyLossWithoutReg Max            291.274
trainer/PolicyLossWithoutReg Min             -6.83702
trainer/gradient_norm                       302.61
trainer/gradient_penalty                     -1.51305
trainer/gradient_percentage                  -0.00836249
exploration/num steps total              479000
exploration/num paths total                1635
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72028
exploration/Rewards Std                       1.22397
exploration/Rewards Max                      10.0997
exploration/Rewards Min                      -0.730163
exploration/Returns Mean                   4720.28
exploration/Returns Std                       0
exploration/Returns Max                    4720.28
exploration/Returns Min                    4720.28
exploration/Num Paths                         1
exploration/Average Returns                4720.28
evaluation_0/num steps total                  3.71811e+06
evaluation_0/num paths total              11316
evaluation_0/path length Mean               912.875
evaluation_0/path length Std                230.511
evaluation_0/path length Max               1000
evaluation_0/path length Min                303
evaluation_0/Rewards Mean                     4.64229
evaluation_0/Rewards Std                      1.27314
evaluation_0/Rewards Max                     10.0019
evaluation_0/Rewards Min                     -0.715558
evaluation_0/Returns Mean                  4237.83
evaluation_0/Returns Std                   1250.5
evaluation_0/Returns Max                   4771.34
evaluation_0/Returns Min                    932.597
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4237.83
time/epoch (s)                                0
time/total (s)                             9116.82
Epoch                                       474
---------------------------------------  ----------------
2022-11-16 13:18:04.165131 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 475 finished
---------------------------------------  ----------------
epoch                                       475
total_step                               480000
replay_pool/size                         480000
trainer/alpha                                 0.0674075
trainer/alpha_loss                           -0.671002
trainer/entropy                              -5.75119
trainer/qf_loss                               5.52838
trainer/state_noise                           0.005
trainer/policy_loss                        -185.826
trainer/policy_loss_without_entropy         187.869
trainer/entropy_penalty                      -0.387673
trainer/entropy_percentage                   -0.00206353
trainer/Q1Pred Mean                         187.245
trainer/Q1Pred Std                           67.0158
trainer/Q1Pred Max                          296.117
trainer/Q1Pred Min                           -8.69637
trainer/Q2Pred Mean                         187.026
trainer/Q2Pred Std                           66.9865
trainer/Q2Pred Max                          296.611
trainer/Q2Pred Min                           -6.85742
trainer/QTargetWithReg Mean                 186.982
trainer/QTargetWithReg Std                   66.9305
trainer/QTargetWithReg Max                  296.068
trainer/QTargetWithReg Min                   -6.99963
trainer/PolicyLossWithoutReg Mean           187.869
trainer/PolicyLossWithoutReg Std             65.9458
trainer/PolicyLossWithoutReg Max            295.584
trainer/PolicyLossWithoutReg Min             -4.98209
trainer/gradient_norm                       331.03
trainer/gradient_penalty                     -1.65515
trainer/gradient_percentage                  -0.00881012
exploration/num steps total              480000
exploration/num paths total                1636
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6031
exploration/Rewards Std                       1.22511
exploration/Rewards Max                       9.64543
exploration/Rewards Min                      -0.782999
exploration/Returns Mean                   4603.1
exploration/Returns Std                       0
exploration/Returns Max                    4603.1
exploration/Returns Min                    4603.1
exploration/Num Paths                         1
exploration/Average Returns                4603.1
evaluation_0/num steps total                  3.72611e+06
evaluation_0/num paths total              11324
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.45875
evaluation_0/Rewards Std                      1.21816
evaluation_0/Rewards Max                      9.87965
evaluation_0/Rewards Min                     -0.669672
evaluation_0/Returns Mean                  4458.75
evaluation_0/Returns Std                    269.608
evaluation_0/Returns Max                   4762.31
evaluation_0/Returns Min                   4055.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4458.75
time/epoch (s)                                0
time/total (s)                             9138
Epoch                                       475
---------------------------------------  ----------------
2022-11-16 13:18:57.066783 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 476 finished
---------------------------------------  ----------------
epoch                                       476
total_step                               481000
replay_pool/size                         481000
trainer/alpha                                 0.0694295
trainer/alpha_loss                           -0.25132
trainer/entropy                              -5.90578
trainer/qf_loss                               7.80744
trainer/state_noise                           0.005
trainer/policy_loss                        -181.378
trainer/policy_loss_without_entropy         183.39
trainer/entropy_penalty                      -0.410035
trainer/entropy_percentage                   -0.00223586
trainer/Q1Pred Mean                         181.818
trainer/Q1Pred Std                           70.6022
trainer/Q1Pred Max                          295.688
trainer/Q1Pred Min                            8.45896
trainer/Q2Pred Mean                         182.177
trainer/Q2Pred Std                           70.2969
trainer/Q2Pred Max                          293.658
trainer/Q2Pred Min                           12.1208
trainer/QTargetWithReg Mean                 181.879
trainer/QTargetWithReg Std                   70.3808
trainer/QTargetWithReg Max                  293.384
trainer/QTargetWithReg Min                   10.2979
trainer/PolicyLossWithoutReg Mean           183.39
trainer/PolicyLossWithoutReg Std             69.5559
trainer/PolicyLossWithoutReg Max            293.457
trainer/PolicyLossWithoutReg Min             12.1763
trainer/gradient_norm                       320.288
trainer/gradient_penalty                     -1.60144
trainer/gradient_percentage                  -0.00873243
exploration/num steps total              481000
exploration/num paths total                1637
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77215
exploration/Rewards Std                       1.2118
exploration/Rewards Max                       9.90177
exploration/Rewards Min                      -0.724004
exploration/Returns Mean                   4772.15
exploration/Returns Std                       0
exploration/Returns Max                    4772.15
exploration/Returns Min                    4772.15
exploration/Num Paths                         1
exploration/Average Returns                4772.15
evaluation_0/num steps total                  3.73406e+06
evaluation_0/num paths total              11332
evaluation_0/path length Mean               993.5
evaluation_0/path length Std                 17.1974
evaluation_0/path length Max               1000
evaluation_0/path length Min                948
evaluation_0/Rewards Mean                     4.74199
evaluation_0/Rewards Std                      1.19893
evaluation_0/Rewards Max                     10.0415
evaluation_0/Rewards Min                     -0.606413
evaluation_0/Returns Mean                  4711.17
evaluation_0/Returns Std                     89.1059
evaluation_0/Returns Max                   4778.44
evaluation_0/Returns Min                   4483.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4711.17
time/epoch (s)                                0
time/total (s)                             9190.9
Epoch                                       476
---------------------------------------  ----------------
2022-11-16 13:19:34.476499 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 477 finished
---------------------------------------  ----------------
epoch                                       477
total_step                               482000
replay_pool/size                         482000
trainer/alpha                                 0.0673604
trainer/alpha_loss                            0.846462
trainer/entropy                              -6.31378
trainer/qf_loss                              11.8116
trainer/state_noise                           0.005
trainer/policy_loss                        -189.464
trainer/policy_loss_without_entropy         191.466
trainer/entropy_penalty                      -0.425299
trainer/entropy_percentage                   -0.00222128
trainer/Q1Pred Mean                         190.603
trainer/Q1Pred Std                           72.6796
trainer/Q1Pred Max                          290.393
trainer/Q1Pred Min                          -23.2663
trainer/Q2Pred Mean                         190.503
trainer/Q2Pred Std                           72.2941
trainer/Q2Pred Max                          290.281
trainer/Q2Pred Min                          -18.0453
trainer/QTargetWithReg Mean                 190.219
trainer/QTargetWithReg Std                   72.6897
trainer/QTargetWithReg Max                  290.661
trainer/QTargetWithReg Min                  -18.6367
trainer/PolicyLossWithoutReg Mean           191.466
trainer/PolicyLossWithoutReg Std             70.679
trainer/PolicyLossWithoutReg Max            289.276
trainer/PolicyLossWithoutReg Min            -12.9161
trainer/gradient_norm                       315.203
trainer/gradient_penalty                     -1.57601
trainer/gradient_percentage                  -0.00823131
exploration/num steps total              482000
exploration/num paths total                1638
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.60507
exploration/Rewards Std                       1.22274
exploration/Rewards Max                      10.1405
exploration/Rewards Min                      -0.705772
exploration/Returns Mean                   4605.07
exploration/Returns Std                       0
exploration/Returns Max                    4605.07
exploration/Returns Min                    4605.07
exploration/Num Paths                         1
exploration/Average Returns                4605.07
evaluation_0/num steps total                  3.74206e+06
evaluation_0/num paths total              11340
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71215
evaluation_0/Rewards Std                      1.21912
evaluation_0/Rewards Max                      9.96433
evaluation_0/Rewards Min                     -0.701728
evaluation_0/Returns Mean                  4712.15
evaluation_0/Returns Std                     37.0685
evaluation_0/Returns Max                   4786.81
evaluation_0/Returns Min                   4671.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4712.15
time/epoch (s)                                0
time/total (s)                             9228.31
Epoch                                       477
---------------------------------------  ----------------
2022-11-16 13:20:01.776803 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 478 finished
---------------------------------------  ----------------
epoch                                       478
total_step                               483000
replay_pool/size                         483000
trainer/alpha                                 0.0676954
trainer/alpha_loss                            0.802459
trainer/entropy                              -6.298
trainer/qf_loss                               9.27819
trainer/state_noise                           0.005
trainer/policy_loss                        -186.212
trainer/policy_loss_without_entropy         188.25
trainer/entropy_penalty                      -0.426346
trainer/entropy_percentage                   -0.00226478
trainer/Q1Pred Mean                         187.434
trainer/Q1Pred Std                           65.6433
trainer/Q1Pred Max                          287.215
trainer/Q1Pred Min                            3.7705
trainer/Q2Pred Mean                         187.046
trainer/Q2Pred Std                           65.635
trainer/Q2Pred Max                          287.352
trainer/Q2Pred Min                            2.90175
trainer/QTargetWithReg Mean                 187.613
trainer/QTargetWithReg Std                   65.5033
trainer/QTargetWithReg Max                  288.671
trainer/QTargetWithReg Min                   -0.355108
trainer/PolicyLossWithoutReg Mean           188.25
trainer/PolicyLossWithoutReg Std             65.1183
trainer/PolicyLossWithoutReg Max            288.349
trainer/PolicyLossWithoutReg Min              2.63144
trainer/gradient_norm                       322.435
trainer/gradient_penalty                     -1.61218
trainer/gradient_percentage                  -0.008564
exploration/num steps total              483000
exploration/num paths total                1639
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7454
exploration/Rewards Std                       1.25655
exploration/Rewards Max                      10.2491
exploration/Rewards Min                      -0.65144
exploration/Returns Mean                   4745.4
exploration/Returns Std                       0
exploration/Returns Max                    4745.4
exploration/Returns Min                    4745.4
exploration/Num Paths                         1
exploration/Average Returns                4745.4
evaluation_0/num steps total                  3.75006e+06
evaluation_0/num paths total              11348
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70169
evaluation_0/Rewards Std                      1.25575
evaluation_0/Rewards Max                     10.0233
evaluation_0/Rewards Min                     -0.633193
evaluation_0/Returns Mean                  4701.69
evaluation_0/Returns Std                    231.069
evaluation_0/Returns Max                   4868.97
evaluation_0/Returns Min                   4111.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4701.69
time/epoch (s)                                0
time/total (s)                             9255.61
Epoch                                       478
---------------------------------------  ----------------
2022-11-16 13:20:24.285206 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 479 finished
---------------------------------------  ----------------
epoch                                       479
total_step                               484000
replay_pool/size                         484000
trainer/alpha                                 0.0672443
trainer/alpha_loss                            0.601822
trainer/entropy                              -6.22294
trainer/qf_loss                               6.98611
trainer/state_noise                           0.005
trainer/policy_loss                        -192.77
trainer/policy_loss_without_entropy         194.768
trainer/entropy_penalty                      -0.418457
trainer/entropy_percentage                   -0.00214849
trainer/Q1Pred Mean                         194.381
trainer/Q1Pred Std                           67.7292
trainer/Q1Pred Max                          290.799
trainer/Q1Pred Min                            3.58168
trainer/Q2Pred Mean                         194.904
trainer/Q2Pred Std                           67.757
trainer/Q2Pred Max                          291.684
trainer/Q2Pred Min                            5.14427
trainer/QTargetWithReg Mean                 194.138
trainer/QTargetWithReg Std                   67.8884
trainer/QTargetWithReg Max                  290.969
trainer/QTargetWithReg Min                    3.54777
trainer/PolicyLossWithoutReg Mean           194.768
trainer/PolicyLossWithoutReg Std             66.8518
trainer/PolicyLossWithoutReg Max            289.472
trainer/PolicyLossWithoutReg Min              4.49219
trainer/gradient_norm                       315.998
trainer/gradient_penalty                     -1.57999
trainer/gradient_percentage                  -0.00811215
exploration/num steps total              484000
exploration/num paths total                1640
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77135
exploration/Rewards Std                       1.23582
exploration/Rewards Max                       9.93949
exploration/Rewards Min                      -0.514947
exploration/Returns Mean                   4771.35
exploration/Returns Std                       0
exploration/Returns Max                    4771.35
exploration/Returns Min                    4771.35
exploration/Num Paths                         1
exploration/Average Returns                4771.35
evaluation_0/num steps total                  3.75806e+06
evaluation_0/num paths total              11356
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61622
evaluation_0/Rewards Std                      1.18583
evaluation_0/Rewards Max                      9.79847
evaluation_0/Rewards Min                     -0.604214
evaluation_0/Returns Mean                  4616.22
evaluation_0/Returns Std                    100.918
evaluation_0/Returns Max                   4816.63
evaluation_0/Returns Min                   4511.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4616.22
time/epoch (s)                                0
time/total (s)                             9278.11
Epoch                                       479
---------------------------------------  ----------------
2022-11-16 13:20:50.082107 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 480 finished
---------------------------------------  ----------------
epoch                                       480
total_step                               485000
replay_pool/size                         485000
trainer/alpha                                 0.067808
trainer/alpha_loss                           -0.848507
trainer/entropy                              -5.68468
trainer/qf_loss                               6.99826
trainer/state_noise                           0.005
trainer/policy_loss                        -188.788
trainer/policy_loss_without_entropy         190.76
trainer/entropy_penalty                      -0.385467
trainer/entropy_percentage                   -0.00202069
trainer/Q1Pred Mean                         189.735
trainer/Q1Pred Std                           67.055
trainer/Q1Pred Max                          294.257
trainer/Q1Pred Min                            7.8022
trainer/Q2Pred Mean                         189.613
trainer/Q2Pred Std                           67.2243
trainer/Q2Pred Max                          292.706
trainer/Q2Pred Min                            2.93408
trainer/QTargetWithReg Mean                 190.139
trainer/QTargetWithReg Std                   67.0775
trainer/QTargetWithReg Max                  294.087
trainer/QTargetWithReg Min                    8.83257
trainer/PolicyLossWithoutReg Mean           190.76
trainer/PolicyLossWithoutReg Std             66.4677
trainer/PolicyLossWithoutReg Max            293.264
trainer/PolicyLossWithoutReg Min              2.03818
trainer/gradient_norm                       317.337
trainer/gradient_penalty                     -1.58669
trainer/gradient_percentage                  -0.00831771
exploration/num steps total              485000
exploration/num paths total                1641
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50325
exploration/Rewards Std                       1.27875
exploration/Rewards Max                      10.1302
exploration/Rewards Min                      -0.599645
exploration/Returns Mean                   4503.25
exploration/Returns Std                       0
exploration/Returns Max                    4503.25
exploration/Returns Min                    4503.25
exploration/Num Paths                         1
exploration/Average Returns                4503.25
evaluation_0/num steps total                  3.76606e+06
evaluation_0/num paths total              11364
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82218
evaluation_0/Rewards Std                      1.25144
evaluation_0/Rewards Max                      9.86863
evaluation_0/Rewards Min                     -0.631732
evaluation_0/Returns Mean                  4822.18
evaluation_0/Returns Std                     40.3237
evaluation_0/Returns Max                   4870.69
evaluation_0/Returns Min                   4741.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4822.18
time/epoch (s)                                0
time/total (s)                             9303.91
Epoch                                       480
---------------------------------------  ----------------
2022-11-16 13:21:21.873786 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 481 finished
---------------------------------------  ----------------
epoch                                       481
total_step                               486000
replay_pool/size                         486000
trainer/alpha                                 0.0687171
trainer/alpha_loss                           -0.724451
trainer/entropy                              -5.72946
trainer/qf_loss                               6.75435
trainer/state_noise                           0.005
trainer/policy_loss                        -196.61
trainer/policy_loss_without_entropy         198.553
trainer/entropy_penalty                      -0.393712
trainer/entropy_percentage                   -0.0019829
trainer/Q1Pred Mean                         198.301
trainer/Q1Pred Std                           65.3582
trainer/Q1Pred Max                          291.769
trainer/Q1Pred Min                            6.12072
trainer/Q2Pred Mean                         198.318
trainer/Q2Pred Std                           65.5257
trainer/Q2Pred Max                          290.886
trainer/Q2Pred Min                            4.45179
trainer/QTargetWithReg Mean                 197.862
trainer/QTargetWithReg Std                   65.2086
trainer/QTargetWithReg Max                  290.099
trainer/QTargetWithReg Min                    6.58059
trainer/PolicyLossWithoutReg Mean           198.553
trainer/PolicyLossWithoutReg Std             64.7451
trainer/PolicyLossWithoutReg Max            291.16
trainer/PolicyLossWithoutReg Min              5.04771
trainer/gradient_norm                       309.983
trainer/gradient_penalty                     -1.54992
trainer/gradient_percentage                  -0.00780604
exploration/num steps total              486000
exploration/num paths total                1642
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72696
exploration/Rewards Std                       1.23873
exploration/Rewards Max                       9.98307
exploration/Rewards Min                      -0.648748
exploration/Returns Mean                   4726.96
exploration/Returns Std                       0
exploration/Returns Max                    4726.96
exploration/Returns Min                    4726.96
exploration/Num Paths                         1
exploration/Average Returns                4726.96
evaluation_0/num steps total                  3.77348e+06
evaluation_0/num paths total              11380
evaluation_0/path length Mean               463.625
evaluation_0/path length Std                415.809
evaluation_0/path length Max               1000
evaluation_0/path length Min                115
evaluation_0/Rewards Mean                     4.31689
evaluation_0/Rewards Std                      1.38589
evaluation_0/Rewards Max                      9.89449
evaluation_0/Rewards Min                     -0.709254
evaluation_0/Returns Mean                  2001.42
evaluation_0/Returns Std                   1925.2
evaluation_0/Returns Max                   4746.45
evaluation_0/Returns Min                    410.512
evaluation_0/Num Paths                       16
evaluation_0/Average Returns               2001.42
time/epoch (s)                                0
time/total (s)                             9335.7
Epoch                                       481
---------------------------------------  ----------------
2022-11-16 13:21:46.892835 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 482 finished
---------------------------------------  ----------------
epoch                                       482
total_step                               487000
replay_pool/size                         487000
trainer/alpha                                 0.0689836
trainer/alpha_loss                           -0.810694
trainer/entropy                              -5.69678
trainer/qf_loss                               8.30027
trainer/state_noise                           0.005
trainer/policy_loss                        -187.201
trainer/policy_loss_without_entropy         189.179
trainer/entropy_penalty                      -0.392985
trainer/entropy_percentage                   -0.00207732
trainer/Q1Pred Mean                         187.808
trainer/Q1Pred Std                           72.6454
trainer/Q1Pred Max                          294.236
trainer/Q1Pred Min                          -31.0895
trainer/Q2Pred Mean                         187.866
trainer/Q2Pred Std                           72.9457
trainer/Q2Pred Max                          295.774
trainer/Q2Pred Min                          -25.0688
trainer/QTargetWithReg Mean                 187.836
trainer/QTargetWithReg Std                   73.0299
trainer/QTargetWithReg Max                  295.666
trainer/QTargetWithReg Min                  -24.2026
trainer/PolicyLossWithoutReg Mean           189.179
trainer/PolicyLossWithoutReg Std             71.2038
trainer/PolicyLossWithoutReg Max            293.245
trainer/PolicyLossWithoutReg Min            -24.7883
trainer/gradient_norm                       317.036
trainer/gradient_penalty                     -1.58518
trainer/gradient_percentage                  -0.00837927
exploration/num steps total              487000
exploration/num paths total                1643
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.469
exploration/Rewards Std                       1.25513
exploration/Rewards Max                       9.90242
exploration/Rewards Min                      -0.558092
exploration/Returns Mean                   4469
exploration/Returns Std                       0
exploration/Returns Max                    4469
exploration/Returns Min                    4469
exploration/Num Paths                         1
exploration/Average Returns                4469
evaluation_0/num steps total                  3.78067e+06
evaluation_0/num paths total              11388
evaluation_0/path length Mean               899.375
evaluation_0/path length Std                266.229
evaluation_0/path length Max               1000
evaluation_0/path length Min                195
evaluation_0/Rewards Mean                     4.48423
evaluation_0/Rewards Std                      1.29466
evaluation_0/Rewards Max                      9.93204
evaluation_0/Rewards Min                     -0.631124
evaluation_0/Returns Mean                  4033
evaluation_0/Returns Std                   1302.59
evaluation_0/Returns Max                   4784.94
evaluation_0/Returns Min                    684.609
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4033
time/epoch (s)                                0
time/total (s)                             9360.72
Epoch                                       482
---------------------------------------  ----------------
2022-11-16 13:22:31.075992 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 483 finished
---------------------------------------  ----------------
epoch                                       483
total_step                               488000
replay_pool/size                         488000
trainer/alpha                                 0.0684775
trainer/alpha_loss                           -1.26573
trainer/entropy                              -5.52791
trainer/qf_loss                               8.26448
trainer/state_noise                           0.005
trainer/policy_loss                        -195.588
trainer/policy_loss_without_entropy         197.576
trainer/entropy_penalty                      -0.378537
trainer/entropy_percentage                   -0.00191591
trainer/Q1Pred Mean                         195.227
trainer/Q1Pred Std                           67.6032
trainer/Q1Pred Max                          287.779
trainer/Q1Pred Min                          -12.479
trainer/Q2Pred Mean                         196.001
trainer/Q2Pred Std                           67.7351
trainer/Q2Pred Max                          289.389
trainer/Q2Pred Min                           -9.16768
trainer/QTargetWithReg Mean                 196.249
trainer/QTargetWithReg Std                   67.6255
trainer/QTargetWithReg Max                  289.317
trainer/QTargetWithReg Min                  -14.0814
trainer/PolicyLossWithoutReg Mean           197.576
trainer/PolicyLossWithoutReg Std             65.6256
trainer/PolicyLossWithoutReg Max            288.618
trainer/PolicyLossWithoutReg Min             -7.06573
trainer/gradient_norm                       321.859
trainer/gradient_penalty                     -1.6093
trainer/gradient_percentage                  -0.0081452
exploration/num steps total              488000
exploration/num paths total                1644
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.02685
exploration/Rewards Std                       1.49523
exploration/Rewards Max                      10.4803
exploration/Rewards Min                      -0.76384
exploration/Returns Mean                   4026.85
exploration/Returns Std                       0
exploration/Returns Max                    4026.85
exploration/Returns Min                    4026.85
exploration/Num Paths                         1
exploration/Average Returns                4026.85
evaluation_0/num steps total                  3.78867e+06
evaluation_0/num paths total              11396
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.62352
evaluation_0/Rewards Std                      1.24956
evaluation_0/Rewards Max                     10.4227
evaluation_0/Rewards Min                     -0.630253
evaluation_0/Returns Mean                  4623.52
evaluation_0/Returns Std                    211.623
evaluation_0/Returns Max                   4841.37
evaluation_0/Returns Min                   4199.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4623.52
time/epoch (s)                                0
time/total (s)                             9404.91
Epoch                                       483
---------------------------------------  ----------------
2022-11-16 13:23:03.687513 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 484 finished
---------------------------------------  ----------------
epoch                                       484
total_step                               489000
replay_pool/size                         489000
trainer/alpha                                 0.0690825
trainer/alpha_loss                            0.569611
trainer/entropy                              -6.21314
trainer/qf_loss                              11.7508
trainer/state_noise                           0.005
trainer/policy_loss                        -194.93
trainer/policy_loss_without_entropy         196.935
trainer/entropy_penalty                      -0.429219
trainer/entropy_percentage                   -0.0021795
trainer/Q1Pred Mean                         195.906
trainer/Q1Pred Std                           64.7473
trainer/Q1Pred Max                          293.032
trainer/Q1Pred Min                          -13.6921
trainer/Q2Pred Mean                         196.222
trainer/Q2Pred Std                           64.6312
trainer/Q2Pred Max                          294.962
trainer/Q2Pred Min                           -0.0407041
trainer/QTargetWithReg Mean                 195.919
trainer/QTargetWithReg Std                   64.9187
trainer/QTargetWithReg Max                  293.875
trainer/QTargetWithReg Min                  -12.218
trainer/PolicyLossWithoutReg Mean           196.935
trainer/PolicyLossWithoutReg Std             63.5639
trainer/PolicyLossWithoutReg Max            293.038
trainer/PolicyLossWithoutReg Min             -5.70512
trainer/gradient_norm                       315.113
trainer/gradient_penalty                     -1.57556
trainer/gradient_percentage                  -0.00800043
exploration/num steps total              489000
exploration/num paths total                1645
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51049
exploration/Rewards Std                       1.27773
exploration/Rewards Max                      10.1606
exploration/Rewards Min                      -0.611113
exploration/Returns Mean                   4510.49
exploration/Returns Std                       0
exploration/Returns Max                    4510.49
exploration/Returns Min                    4510.49
exploration/Num Paths                         1
exploration/Average Returns                4510.49
evaluation_0/num steps total                  3.79667e+06
evaluation_0/num paths total              11404
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8193
evaluation_0/Rewards Std                      1.26194
evaluation_0/Rewards Max                     10.3549
evaluation_0/Rewards Min                     -0.667715
evaluation_0/Returns Mean                  4819.3
evaluation_0/Returns Std                     41.7687
evaluation_0/Returns Max                   4879.06
evaluation_0/Returns Min                   4736.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4819.3
time/epoch (s)                                0
time/total (s)                             9437.51
Epoch                                       484
---------------------------------------  ----------------
2022-11-16 13:23:18.174992 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 485 finished
---------------------------------------  ----------------
epoch                                       485
total_step                               490000
replay_pool/size                         490000
trainer/alpha                                 0.0690295
trainer/alpha_loss                            0.633927
trainer/entropy                              -6.23713
trainer/qf_loss                               6.36042
trainer/state_noise                           0.005
trainer/policy_loss                        -188.736
trainer/policy_loss_without_entropy         190.681
trainer/entropy_penalty                      -0.430546
trainer/entropy_percentage                   -0.00225794
trainer/Q1Pred Mean                         189.941
trainer/Q1Pred Std                           69.4981
trainer/Q1Pred Max                          295.801
trainer/Q1Pred Min                           -7.80352
trainer/Q2Pred Mean                         190.054
trainer/Q2Pred Std                           69.5406
trainer/Q2Pred Max                          295.433
trainer/Q2Pred Min                          -12.1183
trainer/QTargetWithReg Mean                 189.769
trainer/QTargetWithReg Std                   69.4967
trainer/QTargetWithReg Max                  295.16
trainer/QTargetWithReg Min                   -8.9087
trainer/PolicyLossWithoutReg Mean           190.681
trainer/PolicyLossWithoutReg Std             68.8386
trainer/PolicyLossWithoutReg Max            295.501
trainer/PolicyLossWithoutReg Min             -1.53776
trainer/gradient_norm                       302.892
trainer/gradient_penalty                     -1.51446
trainer/gradient_percentage                  -0.00794239
exploration/num steps total              490000
exploration/num paths total                1646
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.37909
exploration/Rewards Std                       1.32606
exploration/Rewards Max                       9.93961
exploration/Rewards Min                      -0.572708
exploration/Returns Mean                   4379.09
exploration/Returns Std                       0
exploration/Returns Max                    4379.09
exploration/Returns Min                    4379.09
exploration/Num Paths                         1
exploration/Average Returns                4379.09
evaluation_0/num steps total                  3.80467e+06
evaluation_0/num paths total              11412
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90919
evaluation_0/Rewards Std                      1.24468
evaluation_0/Rewards Max                     10.3004
evaluation_0/Rewards Min                     -0.640191
evaluation_0/Returns Mean                  4909.19
evaluation_0/Returns Std                     30.9279
evaluation_0/Returns Max                   4942.8
evaluation_0/Returns Min                   4849.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4909.19
time/epoch (s)                                0
time/total (s)                             9452
Epoch                                       485
---------------------------------------  ----------------
2022-11-16 13:24:28.961502 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 486 finished
---------------------------------------  ----------------
epoch                                       486
total_step                               491000
replay_pool/size                         491000
trainer/alpha                                 0.0695267
trainer/alpha_loss                           -0.905842
trainer/entropy                              -5.66021
trainer/qf_loss                               7.66241
trainer/state_noise                           0.005
trainer/policy_loss                        -180.082
trainer/policy_loss_without_entropy         182.032
trainer/entropy_penalty                      -0.393536
trainer/entropy_percentage                   -0.00216191
trainer/Q1Pred Mean                         180.997
trainer/Q1Pred Std                           71.1582
trainer/Q1Pred Max                          293.062
trainer/Q1Pred Min                            0.00211513
trainer/Q2Pred Mean                         181.004
trainer/Q2Pred Std                           71.2699
trainer/Q2Pred Max                          294.618
trainer/Q2Pred Min                           -2.66989
trainer/QTargetWithReg Mean                 181.076
trainer/QTargetWithReg Std                   71.1516
trainer/QTargetWithReg Max                  293.682
trainer/QTargetWithReg Min                   -1.96559
trainer/PolicyLossWithoutReg Mean           182.032
trainer/PolicyLossWithoutReg Std             70.3263
trainer/PolicyLossWithoutReg Max            292.944
trainer/PolicyLossWithoutReg Min             -0.891226
trainer/gradient_norm                       311.217
trainer/gradient_penalty                     -1.55609
trainer/gradient_percentage                  -0.00854843
exploration/num steps total              491000
exploration/num paths total                1647
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78562
exploration/Rewards Std                       1.24567
exploration/Rewards Max                      10.0982
exploration/Rewards Min                      -0.607248
exploration/Returns Mean                   4785.62
exploration/Returns Std                       0
exploration/Returns Max                    4785.62
exploration/Returns Min                    4785.62
exploration/Num Paths                         1
exploration/Average Returns                4785.62
evaluation_0/num steps total                  3.81267e+06
evaluation_0/num paths total              11420
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70601
evaluation_0/Rewards Std                      1.23807
evaluation_0/Rewards Max                      9.98978
evaluation_0/Rewards Min                     -0.646433
evaluation_0/Returns Mean                  4706.01
evaluation_0/Returns Std                     26.411
evaluation_0/Returns Max                   4752.96
evaluation_0/Returns Min                   4664.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4706.01
time/epoch (s)                                0
time/total (s)                             9522.8
Epoch                                       486
---------------------------------------  ----------------
2022-11-16 13:25:59.534118 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 487 finished
---------------------------------------  ----------------
epoch                                       487
total_step                               492000
replay_pool/size                         492000
trainer/alpha                                 0.0684276
trainer/alpha_loss                            0.342142
trainer/entropy                              -6.12757
trainer/qf_loss                               6.81052
trainer/state_noise                           0.005
trainer/policy_loss                        -194.836
trainer/policy_loss_without_entropy         196.898
trainer/entropy_penalty                      -0.419295
trainer/entropy_percentage                   -0.0021295
trainer/Q1Pred Mean                         195.588
trainer/Q1Pred Std                           68.7382
trainer/Q1Pred Max                          290.53
trainer/Q1Pred Min                          -18.7984
trainer/Q2Pred Mean                         195.618
trainer/Q2Pred Std                           69.0915
trainer/Q2Pred Max                          289.885
trainer/Q2Pred Min                          -20.5604
trainer/QTargetWithReg Mean                 196.079
trainer/QTargetWithReg Std                   69.2246
trainer/QTargetWithReg Max                  291.444
trainer/QTargetWithReg Min                  -26.8322
trainer/PolicyLossWithoutReg Mean           196.898
trainer/PolicyLossWithoutReg Std             67.9348
trainer/PolicyLossWithoutReg Max            289.145
trainer/PolicyLossWithoutReg Min            -15.9912
trainer/gradient_norm                       328.516
trainer/gradient_penalty                     -1.64258
trainer/gradient_percentage                  -0.00834228
exploration/num steps total              492000
exploration/num paths total                1648
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.41344
exploration/Rewards Std                       1.28208
exploration/Rewards Max                       9.7759
exploration/Rewards Min                      -0.75815
exploration/Returns Mean                   4413.44
exploration/Returns Std                       0
exploration/Returns Max                    4413.44
exploration/Returns Min                    4413.44
exploration/Num Paths                         1
exploration/Average Returns                4413.44
evaluation_0/num steps total                  3.82067e+06
evaluation_0/num paths total              11428
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67075
evaluation_0/Rewards Std                      1.22749
evaluation_0/Rewards Max                     10.1994
evaluation_0/Rewards Min                     -0.658466
evaluation_0/Returns Mean                  4670.75
evaluation_0/Returns Std                    198.714
evaluation_0/Returns Max                   4857.09
evaluation_0/Returns Min                   4388.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4670.75
time/epoch (s)                                0
time/total (s)                             9613.37
Epoch                                       487
---------------------------------------  ----------------
2022-11-16 13:27:36.339202 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 488 finished
---------------------------------------  ----------------
epoch                                       488
total_step                               493000
replay_pool/size                         493000
trainer/alpha                                 0.0674411
trainer/alpha_loss                           -1.99043
trainer/entropy                              -5.26181
trainer/qf_loss                               9.24898
trainer/state_noise                           0.005
trainer/policy_loss                        -192.994
trainer/policy_loss_without_entropy         194.954
trainer/entropy_penalty                      -0.354862
trainer/entropy_percentage                   -0.00182024
trainer/Q1Pred Mean                         194.818
trainer/Q1Pred Std                           70.1552
trainer/Q1Pred Max                          297.63
trainer/Q1Pred Min                          -20.6139
trainer/Q2Pred Mean                         194.708
trainer/Q2Pred Std                           70.2524
trainer/Q2Pred Max                          299.804
trainer/Q2Pred Min                          -19.7649
trainer/QTargetWithReg Mean                 194.485
trainer/QTargetWithReg Std                   70.1028
trainer/QTargetWithReg Max                  297.025
trainer/QTargetWithReg Min                   -9.27667
trainer/PolicyLossWithoutReg Mean           194.954
trainer/PolicyLossWithoutReg Std             69.156
trainer/PolicyLossWithoutReg Max            295.66
trainer/PolicyLossWithoutReg Min            -19.0606
trainer/gradient_norm                       320.85
trainer/gradient_penalty                     -1.60425
trainer/gradient_percentage                  -0.00822888
exploration/num steps total              493000
exploration/num paths total                1649
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83588
exploration/Rewards Std                       1.24807
exploration/Rewards Max                      10.1425
exploration/Rewards Min                      -0.677088
exploration/Returns Mean                   4835.88
exploration/Returns Std                       0
exploration/Returns Max                    4835.88
exploration/Returns Min                    4835.88
exploration/Num Paths                         1
exploration/Average Returns                4835.88
evaluation_0/num steps total                  3.82867e+06
evaluation_0/num paths total              11436
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53075
evaluation_0/Rewards Std                      1.2396
evaluation_0/Rewards Max                     10.1552
evaluation_0/Rewards Min                     -0.638792
evaluation_0/Returns Mean                  4530.75
evaluation_0/Returns Std                    185.874
evaluation_0/Returns Max                   4699.73
evaluation_0/Returns Min                   4165.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4530.75
time/epoch (s)                                0
time/total (s)                             9710.18
Epoch                                       488
---------------------------------------  ----------------
2022-11-16 13:29:09.143122 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 489 finished
---------------------------------------  ----------------
epoch                                       489
total_step                               494000
replay_pool/size                         494000
trainer/alpha                                 0.0671644
trainer/alpha_loss                           -0.807968
trainer/entropy                              -5.70081
trainer/qf_loss                               8.17493
trainer/state_noise                           0.005
trainer/policy_loss                        -188.082
trainer/policy_loss_without_entropy         190.016
trainer/entropy_penalty                      -0.382892
trainer/entropy_percentage                   -0.00201505
trainer/Q1Pred Mean                         189.674
trainer/Q1Pred Std                           67.8987
trainer/Q1Pred Max                          295.399
trainer/Q1Pred Min                            3.70212
trainer/Q2Pred Mean                         189.144
trainer/Q2Pred Std                           67.7287
trainer/Q2Pred Max                          294.035
trainer/Q2Pred Min                            6.83161
trainer/QTargetWithReg Mean                 188.776
trainer/QTargetWithReg Std                   68.3943
trainer/QTargetWithReg Max                  297.177
trainer/QTargetWithReg Min                   -0.964381
trainer/PolicyLossWithoutReg Mean           190.016
trainer/PolicyLossWithoutReg Std             66.3781
trainer/PolicyLossWithoutReg Max            294.334
trainer/PolicyLossWithoutReg Min              5.75717
trainer/gradient_norm                       310.297
trainer/gradient_penalty                     -1.55149
trainer/gradient_percentage                  -0.00816503
exploration/num steps total              494000
exploration/num paths total                1650
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79787
exploration/Rewards Std                       1.20556
exploration/Rewards Max                      10.0064
exploration/Rewards Min                      -0.676058
exploration/Returns Mean                   4797.87
exploration/Returns Std                       0
exploration/Returns Max                    4797.87
exploration/Returns Min                    4797.87
exploration/Num Paths                         1
exploration/Average Returns                4797.87
evaluation_0/num steps total                  3.83667e+06
evaluation_0/num paths total              11444
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80658
evaluation_0/Rewards Std                      1.21528
evaluation_0/Rewards Max                     10.0498
evaluation_0/Rewards Min                     -0.609575
evaluation_0/Returns Mean                  4806.58
evaluation_0/Returns Std                     11.7844
evaluation_0/Returns Max                   4834.72
evaluation_0/Returns Min                   4795.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4806.58
time/epoch (s)                                0
time/total (s)                             9802.98
Epoch                                       489
---------------------------------------  ----------------
2022-11-16 13:29:27.639814 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 490 finished
---------------------------------------  ----------------
epoch                                       490
total_step                               495000
replay_pool/size                         495000
trainer/alpha                                 0.0659079
trainer/alpha_loss                            0.798477
trainer/entropy                              -6.29358
trainer/qf_loss                               8.38864
trainer/state_noise                           0.005
trainer/policy_loss                        -192.927
trainer/policy_loss_without_entropy         194.97
trainer/entropy_penalty                      -0.414796
trainer/entropy_percentage                   -0.00212749
trainer/Q1Pred Mean                         194.575
trainer/Q1Pred Std                           70.7751
trainer/Q1Pred Max                          291.441
trainer/Q1Pred Min                            0.847721
trainer/Q2Pred Mean                         194.304
trainer/Q2Pred Std                           71.0011
trainer/Q2Pred Max                          290.474
trainer/Q2Pred Min                           -1.49338
trainer/QTargetWithReg Mean                 193.394
trainer/QTargetWithReg Std                   70.4834
trainer/QTargetWithReg Max                  289.161
trainer/QTargetWithReg Min                    1.25891
trainer/PolicyLossWithoutReg Mean           194.97
trainer/PolicyLossWithoutReg Std             69.0903
trainer/PolicyLossWithoutReg Max            289.375
trainer/PolicyLossWithoutReg Min              2.67928
trainer/gradient_norm                       325.61
trainer/gradient_penalty                     -1.62805
trainer/gradient_percentage                  -0.00835025
exploration/num steps total              495000
exploration/num paths total                1651
exploration/path length this epoch Mean     993
exploration/path length this epoch Std        0
exploration/path length this epoch Max      993
exploration/path length this epoch Min      993
exploration/Rewards Mean                      4.78517
exploration/Rewards Std                       1.28422
exploration/Rewards Max                      10.1537
exploration/Rewards Min                      -0.542155
exploration/Returns Mean                   4751.67
exploration/Returns Std                       0
exploration/Returns Max                    4751.67
exploration/Returns Min                    4751.67
exploration/Num Paths                         1
exploration/Average Returns                4751.67
evaluation_0/num steps total                  3.84467e+06
evaluation_0/num paths total              11452
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.529
evaluation_0/Rewards Std                      1.22551
evaluation_0/Rewards Max                     10.1019
evaluation_0/Rewards Min                     -0.608155
evaluation_0/Returns Mean                  4529
evaluation_0/Returns Std                    305.54
evaluation_0/Returns Max                   4936.51
evaluation_0/Returns Min                   4259.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4529
time/epoch (s)                                0
time/total (s)                             9821.46
Epoch                                       490
---------------------------------------  ----------------
2022-11-16 13:29:43.442535 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 491 finished
---------------------------------------  ----------------
epoch                                       491
total_step                               496000
replay_pool/size                         496000
trainer/alpha                                 0.0664817
trainer/alpha_loss                           -1.00824
trainer/entropy                              -5.62808
trainer/qf_loss                               7.85672
trainer/state_noise                           0.005
trainer/policy_loss                        -191.681
trainer/policy_loss_without_entropy         193.547
trainer/entropy_penalty                      -0.374164
trainer/entropy_percentage                   -0.00193319
trainer/Q1Pred Mean                         192.663
trainer/Q1Pred Std                           69.7223
trainer/Q1Pred Max                          294.652
trainer/Q1Pred Min                           -8.50919
trainer/Q2Pred Mean                         192.349
trainer/Q2Pred Std                           69.7274
trainer/Q2Pred Max                          292.897
trainer/Q2Pred Min                          -10.358
trainer/QTargetWithReg Mean                 192.162
trainer/QTargetWithReg Std                   69.8292
trainer/QTargetWithReg Max                  292.835
trainer/QTargetWithReg Min                   -1.72085
trainer/PolicyLossWithoutReg Mean           193.547
trainer/PolicyLossWithoutReg Std             69.1147
trainer/PolicyLossWithoutReg Max            293.63
trainer/PolicyLossWithoutReg Min             -1.2936
trainer/gradient_norm                       298.474
trainer/gradient_penalty                     -1.49237
trainer/gradient_percentage                  -0.00771063
exploration/num steps total              496000
exploration/num paths total                1652
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75851
exploration/Rewards Std                       1.25967
exploration/Rewards Max                      10.4977
exploration/Rewards Min                      -0.588132
exploration/Returns Mean                   4758.51
exploration/Returns Std                       0
exploration/Returns Max                    4758.51
exploration/Returns Min                    4758.51
exploration/Num Paths                         1
exploration/Average Returns                4758.51
evaluation_0/num steps total                  3.85267e+06
evaluation_0/num paths total              11460
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.46766
evaluation_0/Rewards Std                      1.1476
evaluation_0/Rewards Max                      9.2667
evaluation_0/Rewards Min                     -0.638905
evaluation_0/Returns Mean                  4467.66
evaluation_0/Returns Std                     22.2133
evaluation_0/Returns Max                   4492.01
evaluation_0/Returns Min                   4422.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4467.66
time/epoch (s)                                0
time/total (s)                             9837.26
Epoch                                       491
---------------------------------------  ----------------
2022-11-16 13:30:01.412295 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 492 finished
---------------------------------------  ----------------
epoch                                       492
total_step                               497000
replay_pool/size                         497000
trainer/alpha                                 0.064651
trainer/alpha_loss                           -0.229175
trainer/entropy                              -5.91632
trainer/qf_loss                               7.40764
trainer/state_noise                           0.005
trainer/policy_loss                        -192.756
trainer/policy_loss_without_entropy         194.681
trainer/entropy_penalty                      -0.382496
trainer/entropy_percentage                   -0.00196473
trainer/Q1Pred Mean                         194.111
trainer/Q1Pred Std                           72.1951
trainer/Q1Pred Max                          301.128
trainer/Q1Pred Min                          -25.7987
trainer/Q2Pred Mean                         193.277
trainer/Q2Pred Std                           72.4206
trainer/Q2Pred Max                          300.336
trainer/Q2Pred Min                          -26.501
trainer/QTargetWithReg Mean                 193.36
trainer/QTargetWithReg Std                   72.4547
trainer/QTargetWithReg Max                  300.394
trainer/QTargetWithReg Min                  -28.5097
trainer/PolicyLossWithoutReg Mean           194.681
trainer/PolicyLossWithoutReg Std             71.104
trainer/PolicyLossWithoutReg Max            300.47
trainer/PolicyLossWithoutReg Min            -22.2389
trainer/gradient_norm                       308.495
trainer/gradient_penalty                     -1.54248
trainer/gradient_percentage                  -0.00792309
exploration/num steps total              497000
exploration/num paths total                1653
exploration/path length this epoch Mean     837
exploration/path length this epoch Std        0
exploration/path length this epoch Max      837
exploration/path length this epoch Min      837
exploration/Rewards Mean                      4.81587
exploration/Rewards Std                       1.27541
exploration/Rewards Max                      10.0733
exploration/Rewards Min                      -0.644139
exploration/Returns Mean                   4030.89
exploration/Returns Std                       0
exploration/Returns Max                    4030.89
exploration/Returns Min                    4030.89
exploration/Num Paths                         1
exploration/Average Returns                4030.89
evaluation_0/num steps total                  3.86061e+06
evaluation_0/num paths total              11468
evaluation_0/path length Mean               992.875
evaluation_0/path length Std                 18.851
evaluation_0/path length Max               1000
evaluation_0/path length Min                943
evaluation_0/Rewards Mean                     4.87081
evaluation_0/Rewards Std                      1.23356
evaluation_0/Rewards Max                     10.3431
evaluation_0/Rewards Min                     -0.749565
evaluation_0/Returns Mean                  4836.1
evaluation_0/Returns Std                     96.966
evaluation_0/Returns Max                   4923.54
evaluation_0/Returns Min                   4592.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.1
time/epoch (s)                                0
time/total (s)                             9855.23
Epoch                                       492
---------------------------------------  ----------------
2022-11-16 13:30:17.222042 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 493 finished
---------------------------------------  ----------------
epoch                                       493
total_step                               498000
replay_pool/size                         498000
trainer/alpha                                 0.0666233
trainer/alpha_loss                           -0.480741
trainer/entropy                              -5.82252
trainer/qf_loss                               7.15957
trainer/state_noise                           0.005
trainer/policy_loss                        -189.366
trainer/policy_loss_without_entropy         191.302
trainer/entropy_penalty                      -0.387915
trainer/entropy_percentage                   -0.00202777
trainer/Q1Pred Mean                         190.376
trainer/Q1Pred Std                           67.6661
trainer/Q1Pred Max                          298.283
trainer/Q1Pred Min                           -9.51934
trainer/Q2Pred Mean                         190.327
trainer/Q2Pred Std                           67.3695
trainer/Q2Pred Max                          298.624
trainer/Q2Pred Min                           -9.92159
trainer/QTargetWithReg Mean                 190.293
trainer/QTargetWithReg Std                   67.4089
trainer/QTargetWithReg Max                  297.697
trainer/QTargetWithReg Min                   -6.20724
trainer/PolicyLossWithoutReg Mean           191.302
trainer/PolicyLossWithoutReg Std             66.7495
trainer/PolicyLossWithoutReg Max            297.771
trainer/PolicyLossWithoutReg Min             -5.60834
trainer/gradient_norm                       309.493
trainer/gradient_penalty                     -1.54747
trainer/gradient_percentage                  -0.00808915
exploration/num steps total              498000
exploration/num paths total                1654
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84956
exploration/Rewards Std                       1.23212
exploration/Rewards Max                      10.1413
exploration/Rewards Min                      -0.704112
exploration/Returns Mean                   4849.56
exploration/Returns Std                       0
exploration/Returns Max                    4849.56
exploration/Returns Min                    4849.56
exploration/Num Paths                         1
exploration/Average Returns                4849.56
evaluation_0/num steps total                  3.86861e+06
evaluation_0/num paths total              11476
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64398
evaluation_0/Rewards Std                      1.17583
evaluation_0/Rewards Max                      9.85388
evaluation_0/Rewards Min                     -0.601787
evaluation_0/Returns Mean                  4643.98
evaluation_0/Returns Std                    150.476
evaluation_0/Returns Max                   4895.45
evaluation_0/Returns Min                   4518.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4643.98
time/epoch (s)                                0
time/total (s)                             9871.04
Epoch                                       493
---------------------------------------  ----------------
2022-11-16 13:30:33.477913 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 494 finished
---------------------------------------  ----------------
epoch                                       494
total_step                               499000
replay_pool/size                         499000
trainer/alpha                                 0.0669921
trainer/alpha_loss                           -0.0191947
trainer/entropy                              -5.9929
trainer/qf_loss                               7.02303
trainer/state_noise                           0.005
trainer/policy_loss                        -192.133
trainer/policy_loss_without_entropy         194.148
trainer/entropy_penalty                      -0.401477
trainer/entropy_percentage                   -0.0020679
trainer/Q1Pred Mean                         193.966
trainer/Q1Pred Std                           71.6813
trainer/Q1Pred Max                          301.728
trainer/Q1Pred Min                            6.64263
trainer/Q2Pred Mean                         193.363
trainer/Q2Pred Std                           71.096
trainer/Q2Pred Max                          301.071
trainer/Q2Pred Min                            4.57454
trainer/QTargetWithReg Mean                 193.623
trainer/QTargetWithReg Std                   71.7028
trainer/QTargetWithReg Max                  300.161
trainer/QTargetWithReg Min                   -6.38175
trainer/PolicyLossWithoutReg Mean           194.147
trainer/PolicyLossWithoutReg Std             70.4909
trainer/PolicyLossWithoutReg Max            301.327
trainer/PolicyLossWithoutReg Min              5.63433
trainer/gradient_norm                       322.629
trainer/gradient_penalty                     -1.61315
trainer/gradient_percentage                  -0.00830887
exploration/num steps total              499000
exploration/num paths total                1655
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83904
exploration/Rewards Std                       1.22605
exploration/Rewards Max                      10.1065
exploration/Rewards Min                      -0.628613
exploration/Returns Mean                   4839.04
exploration/Returns Std                       0
exploration/Returns Max                    4839.04
exploration/Returns Min                    4839.04
exploration/Num Paths                         1
exploration/Average Returns                4839.04
evaluation_0/num steps total                  3.87661e+06
evaluation_0/num paths total              11484
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87506
evaluation_0/Rewards Std                      1.21327
evaluation_0/Rewards Max                     10.0644
evaluation_0/Rewards Min                     -0.569417
evaluation_0/Returns Mean                  4875.06
evaluation_0/Returns Std                      8.73488
evaluation_0/Returns Max                   4892.64
evaluation_0/Returns Min                   4861.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4875.06
time/epoch (s)                                0
time/total (s)                             9887.3
Epoch                                       494
---------------------------------------  ----------------
2022-11-16 13:30:49.394409 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 495 finished
---------------------------------------  ----------------
epoch                                       495
total_step                               500000
replay_pool/size                         500000
trainer/alpha                                 0.0662813
trainer/alpha_loss                           -0.372477
trainer/entropy                              -5.86275
trainer/qf_loss                               7.0199
trainer/state_noise                           0.005
trainer/policy_loss                        -194.301
trainer/policy_loss_without_entropy         196.25
trainer/entropy_penalty                      -0.388591
trainer/entropy_percentage                   -0.00198008
trainer/Q1Pred Mean                         195.329
trainer/Q1Pred Std                           71.9048
trainer/Q1Pred Max                          295.053
trainer/Q1Pred Min                            3.81411
trainer/Q2Pred Mean                         195.56
trainer/Q2Pred Std                           71.8677
trainer/Q2Pred Max                          295.154
trainer/Q2Pred Min                            5.17811
trainer/QTargetWithReg Mean                 195.789
trainer/QTargetWithReg Std                   72.0206
trainer/QTargetWithReg Max                  296.37
trainer/QTargetWithReg Min                    3.72834
trainer/PolicyLossWithoutReg Mean           196.25
trainer/PolicyLossWithoutReg Std             71.3628
trainer/PolicyLossWithoutReg Max            295.273
trainer/PolicyLossWithoutReg Min              4.07437
trainer/gradient_norm                       312.03
trainer/gradient_penalty                     -1.56015
trainer/gradient_percentage                  -0.00794979
exploration/num steps total              500000
exploration/num paths total                1656
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73162
exploration/Rewards Std                       1.23334
exploration/Rewards Max                      10.0339
exploration/Rewards Min                      -0.629736
exploration/Returns Mean                   4731.62
exploration/Returns Std                       0
exploration/Returns Max                    4731.62
exploration/Returns Min                    4731.62
exploration/Num Paths                         1
exploration/Average Returns                4731.62
evaluation_0/num steps total                  3.88461e+06
evaluation_0/num paths total              11492
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87129
evaluation_0/Rewards Std                      1.29602
evaluation_0/Rewards Max                     10.4739
evaluation_0/Rewards Min                     -0.704851
evaluation_0/Returns Mean                  4871.29
evaluation_0/Returns Std                     14.6879
evaluation_0/Returns Max                   4894.03
evaluation_0/Returns Min                   4851.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4871.29
time/epoch (s)                                0
time/total (s)                             9903.21
Epoch                                       495
---------------------------------------  ----------------
2022-11-16 13:31:05.098012 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 496 finished
---------------------------------------  ----------------
epoch                                       496
total_step                               501000
replay_pool/size                         501000
trainer/alpha                                 0.0667771
trainer/alpha_loss                            1.02679
trainer/entropy                              -6.37939
trainer/qf_loss                               9.36502
trainer/state_noise                           0.005
trainer/policy_loss                        -185.436
trainer/policy_loss_without_entropy         187.491
trainer/entropy_penalty                      -0.425997
trainer/entropy_percentage                   -0.00227209
trainer/Q1Pred Mean                         186.248
trainer/Q1Pred Std                           71.4733
trainer/Q1Pred Max                          295.604
trainer/Q1Pred Min                           -7.22696
trainer/Q2Pred Mean                         186.224
trainer/Q2Pred Std                           71.2162
trainer/Q2Pred Max                          295.559
trainer/Q2Pred Min                           -8.56775
trainer/QTargetWithReg Mean                 186.28
trainer/QTargetWithReg Std                   71.418
trainer/QTargetWithReg Max                  295.889
trainer/QTargetWithReg Min                   -5.58863
trainer/PolicyLossWithoutReg Mean           187.491
trainer/PolicyLossWithoutReg Std             70.5431
trainer/PolicyLossWithoutReg Max            295.985
trainer/PolicyLossWithoutReg Min              4.94328
trainer/gradient_norm                       325.756
trainer/gradient_penalty                     -1.62878
trainer/gradient_percentage                  -0.00868722
exploration/num steps total              501000
exploration/num paths total                1657
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89845
exploration/Rewards Std                       1.23535
exploration/Rewards Max                      10.3601
exploration/Rewards Min                      -0.634044
exploration/Returns Mean                   4898.45
exploration/Returns Std                       0
exploration/Returns Max                    4898.45
exploration/Returns Min                    4898.45
exploration/Num Paths                         1
exploration/Average Returns                4898.45
evaluation_0/num steps total                  3.89261e+06
evaluation_0/num paths total              11500
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85679
evaluation_0/Rewards Std                      1.20488
evaluation_0/Rewards Max                     10.0791
evaluation_0/Rewards Min                     -0.634951
evaluation_0/Returns Mean                  4856.79
evaluation_0/Returns Std                     48.9561
evaluation_0/Returns Max                   4916.83
evaluation_0/Returns Min                   4772.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4856.79
time/epoch (s)                                0
time/total (s)                             9918.91
Epoch                                       496
---------------------------------------  ----------------
2022-11-16 13:31:26.273748 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 497 finished
---------------------------------------  ----------------
epoch                                       497
total_step                               502000
replay_pool/size                         502000
trainer/alpha                                 0.0672094
trainer/alpha_loss                           -1.90148
trainer/entropy                              -5.29569
trainer/qf_loss                               6.26434
trainer/state_noise                           0.005
trainer/policy_loss                        -192.397
trainer/policy_loss_without_entropy         194.367
trainer/entropy_penalty                      -0.35592
trainer/entropy_percentage                   -0.00183117
trainer/Q1Pred Mean                         194.491
trainer/Q1Pred Std                           69.3551
trainer/Q1Pred Max                          301.957
trainer/Q1Pred Min                           -6.87728
trainer/Q2Pred Mean                         193.849
trainer/Q2Pred Std                           69.295
trainer/Q2Pred Max                          300.327
trainer/Q2Pred Min                           -9.94731
trainer/QTargetWithReg Mean                 194.115
trainer/QTargetWithReg Std                   69.2145
trainer/QTargetWithReg Max                  299.862
trainer/QTargetWithReg Min                   -5.66936
trainer/PolicyLossWithoutReg Mean           194.367
trainer/PolicyLossWithoutReg Std             68.3762
trainer/PolicyLossWithoutReg Max            299.789
trainer/PolicyLossWithoutReg Min             -2.2971
trainer/gradient_norm                       322.836
trainer/gradient_penalty                     -1.61418
trainer/gradient_percentage                  -0.0083048
exploration/num steps total              502000
exploration/num paths total                1658
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90191
exploration/Rewards Std                       1.22331
exploration/Rewards Max                      10.3652
exploration/Rewards Min                      -0.648615
exploration/Returns Mean                   4901.91
exploration/Returns Std                       0
exploration/Returns Max                    4901.91
exploration/Returns Min                    4901.91
exploration/Num Paths                         1
exploration/Average Returns                4901.91
evaluation_0/num steps total                  3.90025e+06
evaluation_0/num paths total              11526
evaluation_0/path length Mean               293.692
evaluation_0/path length Std                428.713
evaluation_0/path length Max               1000
evaluation_0/path length Min                 33
evaluation_0/Rewards Mean                     4.70749
evaluation_0/Rewards Std                      1.5476
evaluation_0/Rewards Max                     10.2135
evaluation_0/Rewards Min                     -0.629741
evaluation_0/Returns Mean                  1382.55
evaluation_0/Returns Std                   2181.48
evaluation_0/Returns Max                   5036.16
evaluation_0/Returns Min                     55.4756
evaluation_0/Num Paths                       26
evaluation_0/Average Returns               1382.55
time/epoch (s)                                0
time/total (s)                             9940.09
Epoch                                       497
---------------------------------------  ----------------
2022-11-16 13:31:42.121698 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 498 finished
---------------------------------------  ----------------
epoch                                       498
total_step                               503000
replay_pool/size                         503000
trainer/alpha                                 0.0668679
trainer/alpha_loss                            0.441648
trainer/entropy                              -6.16326
trainer/qf_loss                               6.88909
trainer/state_noise                           0.005
trainer/policy_loss                        -193.393
trainer/policy_loss_without_entropy         195.391
trainer/entropy_penalty                      -0.412124
trainer/entropy_percentage                   -0.00210923
trainer/Q1Pred Mean                         194.81
trainer/Q1Pred Std                           66.8529
trainer/Q1Pred Max                          295.682
trainer/Q1Pred Min                            4.90046
trainer/Q2Pred Mean                         195.265
trainer/Q2Pred Std                           67.0517
trainer/Q2Pred Max                          295.908
trainer/Q2Pred Min                           -1.55587
trainer/QTargetWithReg Mean                 194.908
trainer/QTargetWithReg Std                   67.2085
trainer/QTargetWithReg Max                  295.13
trainer/QTargetWithReg Min                    3.5681
trainer/PolicyLossWithoutReg Mean           195.391
trainer/PolicyLossWithoutReg Std             66.3027
trainer/PolicyLossWithoutReg Max            295.649
trainer/PolicyLossWithoutReg Min             -3.47545
trainer/gradient_norm                       317.118
trainer/gradient_penalty                     -1.58559
trainer/gradient_percentage                  -0.00811497
exploration/num steps total              503000
exploration/num paths total                1659
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73174
exploration/Rewards Std                       1.28968
exploration/Rewards Max                      10.4165
exploration/Rewards Min                      -0.515429
exploration/Returns Mean                   4731.74
exploration/Returns Std                       0
exploration/Returns Max                    4731.74
exploration/Returns Min                    4731.74
exploration/Num Paths                         1
exploration/Average Returns                4731.74
evaluation_0/num steps total                  3.90825e+06
evaluation_0/num paths total              11534
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86138
evaluation_0/Rewards Std                      1.25774
evaluation_0/Rewards Max                     10.3705
evaluation_0/Rewards Min                     -0.655497
evaluation_0/Returns Mean                  4861.38
evaluation_0/Returns Std                     19.613
evaluation_0/Returns Max                   4884.17
evaluation_0/Returns Min                   4829.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4861.38
time/epoch (s)                                0
time/total (s)                             9955.94
Epoch                                       498
---------------------------------------  ----------------
2022-11-16 13:31:58.554734 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 499 finished
---------------------------------------  ----------------
epoch                                       499
total_step                               504000
replay_pool/size                         504000
trainer/alpha                                 0.0673792
trainer/alpha_loss                           -0.296064
trainer/entropy                              -5.89025
trainer/qf_loss                              55.9745
trainer/state_noise                           0.005
trainer/policy_loss                        -193.789
trainer/policy_loss_without_entropy         195.777
trainer/entropy_penalty                      -0.39688
trainer/entropy_percentage                   -0.0020272
trainer/Q1Pred Mean                         195.153
trainer/Q1Pred Std                           72.6548
trainer/Q1Pred Max                          296.876
trainer/Q1Pred Min                            2.0716
trainer/Q2Pred Mean                         195.72
trainer/Q2Pred Std                           72.6474
trainer/Q2Pred Max                          298.78
trainer/Q2Pred Min                            3.66114
trainer/QTargetWithReg Mean                 194.75
trainer/QTargetWithReg Std                   73.3377
trainer/QTargetWithReg Max                  299.144
trainer/QTargetWithReg Min                    5.20611
trainer/PolicyLossWithoutReg Mean           195.777
trainer/PolicyLossWithoutReg Std             71.8491
trainer/PolicyLossWithoutReg Max            298.039
trainer/PolicyLossWithoutReg Min              3.76669
trainer/gradient_norm                       318.195
trainer/gradient_penalty                     -1.59097
trainer/gradient_percentage                  -0.00812644
exploration/num steps total              504000
exploration/num paths total                1660
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89174
exploration/Rewards Std                       1.27005
exploration/Rewards Max                      10.4561
exploration/Rewards Min                      -0.496858
exploration/Returns Mean                   4891.74
exploration/Returns Std                       0
exploration/Returns Max                    4891.74
exploration/Returns Min                    4891.74
exploration/Num Paths                         1
exploration/Average Returns                4891.74
evaluation_0/num steps total                  3.91625e+06
evaluation_0/num paths total              11542
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.59846
evaluation_0/Rewards Std                      1.18916
evaluation_0/Rewards Max                     10.003
evaluation_0/Rewards Min                     -0.696352
evaluation_0/Returns Mean                  4598.46
evaluation_0/Returns Std                    246.087
evaluation_0/Returns Max                   4933.11
evaluation_0/Returns Min                   4352.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4598.46
time/epoch (s)                                0
time/total (s)                             9972.37
Epoch                                       499
---------------------------------------  ----------------
2022-11-16 13:32:14.331301 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 500 finished
---------------------------------------  ----------------
epoch                                       500
total_step                               505000
replay_pool/size                         505000
trainer/alpha                                 0.0671311
trainer/alpha_loss                           -0.906299
trainer/entropy                              -5.66444
trainer/qf_loss                              10.1375
trainer/state_noise                           0.005
trainer/policy_loss                        -184.288
trainer/policy_loss_without_entropy         186.242
trainer/entropy_penalty                      -0.38026
trainer/entropy_percentage                   -0.00204176
trainer/Q1Pred Mean                         185.475
trainer/Q1Pred Std                           71.0475
trainer/Q1Pred Max                          294.219
trainer/Q1Pred Min                          -11.9261
trainer/Q2Pred Mean                         185.242
trainer/Q2Pred Std                           71.2414
trainer/Q2Pred Max                          292.009
trainer/Q2Pred Min                          -10.7999
trainer/QTargetWithReg Mean                 185.717
trainer/QTargetWithReg Std                   71.1903
trainer/QTargetWithReg Max                  295.252
trainer/QTargetWithReg Min                  -14.4725
trainer/PolicyLossWithoutReg Mean           186.242
trainer/PolicyLossWithoutReg Std             70.6142
trainer/PolicyLossWithoutReg Max            293.508
trainer/PolicyLossWithoutReg Min            -11.1774
trainer/gradient_norm                       314.713
trainer/gradient_penalty                     -1.57357
trainer/gradient_percentage                  -0.00844906
exploration/num steps total              505000
exploration/num paths total                1661
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77954
exploration/Rewards Std                       1.22391
exploration/Rewards Max                      10.4175
exploration/Rewards Min                      -0.612855
exploration/Returns Mean                   4779.54
exploration/Returns Std                       0
exploration/Returns Max                    4779.54
exploration/Returns Min                    4779.54
exploration/Num Paths                         1
exploration/Average Returns                4779.54
evaluation_0/num steps total                  3.92425e+06
evaluation_0/num paths total              11550
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96123
evaluation_0/Rewards Std                      1.31181
evaluation_0/Rewards Max                     10.5854
evaluation_0/Rewards Min                     -0.657864
evaluation_0/Returns Mean                  4961.23
evaluation_0/Returns Std                     12.1231
evaluation_0/Returns Max                   4977.55
evaluation_0/Returns Min                   4945.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4961.23
time/epoch (s)                                0
time/total (s)                             9988.15
Epoch                                       500
---------------------------------------  ----------------
2022-11-16 13:32:30.868758 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 501 finished
---------------------------------------  ----------------
epoch                                       501
total_step                               506000
replay_pool/size                         506000
trainer/alpha                                 0.0672481
trainer/alpha_loss                            0.212178
trainer/entropy                              -6.0786
trainer/qf_loss                               7.87909
trainer/state_noise                           0.005
trainer/policy_loss                        -196.043
trainer/policy_loss_without_entropy         198.033
trainer/entropy_penalty                      -0.408774
trainer/entropy_percentage                   -0.00206417
trainer/Q1Pred Mean                         197.265
trainer/Q1Pred Std                           65.6751
trainer/Q1Pred Max                          295.533
trainer/Q1Pred Min                           -3.3627
trainer/Q2Pred Mean                         197.321
trainer/Q2Pred Std                           65.444
trainer/Q2Pred Max                          294.184
trainer/Q2Pred Min                           -2.96598
trainer/QTargetWithReg Mean                 197.267
trainer/QTargetWithReg Std                   65.4081
trainer/QTargetWithReg Max                  296.421
trainer/QTargetWithReg Min                    1.63387
trainer/PolicyLossWithoutReg Mean           198.033
trainer/PolicyLossWithoutReg Std             63.9049
trainer/PolicyLossWithoutReg Max            293.633
trainer/PolicyLossWithoutReg Min              1.63119
trainer/gradient_norm                       316.143
trainer/gradient_penalty                     -1.58071
trainer/gradient_percentage                  -0.00798208
exploration/num steps total              506000
exploration/num paths total                1662
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9056
exploration/Rewards Std                       1.25815
exploration/Rewards Max                      10.1072
exploration/Rewards Min                      -0.744293
exploration/Returns Mean                   4905.6
exploration/Returns Std                       0
exploration/Returns Max                    4905.6
exploration/Returns Min                    4905.6
exploration/Num Paths                         1
exploration/Average Returns                4905.6
evaluation_0/num steps total                  3.93222e+06
evaluation_0/num paths total              11782
evaluation_0/path length Mean                34.3707
evaluation_0/path length Std                  0.587663
evaluation_0/path length Max                 36
evaluation_0/path length Min                 33
evaluation_0/Rewards Mean                     1.71245
evaluation_0/Rewards Std                      1.59582
evaluation_0/Rewards Max                      4.05274
evaluation_0/Rewards Min                     -0.771418
evaluation_0/Returns Mean                    58.858
evaluation_0/Returns Std                      1.41849
evaluation_0/Returns Max                     63.2392
evaluation_0/Returns Min                     54.8854
evaluation_0/Num Paths                      232
evaluation_0/Average Returns                 58.858
time/epoch (s)                                0
time/total (s)                            10004.7
Epoch                                       501
---------------------------------------  ----------------
2022-11-16 13:32:46.775378 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 502 finished
---------------------------------------  ----------------
epoch                                       502
total_step                               507000
replay_pool/size                         507000
trainer/alpha                                 0.0668519
trainer/alpha_loss                            0.791301
trainer/entropy                              -6.29248
trainer/qf_loss                               5.58558
trainer/state_noise                           0.005
trainer/policy_loss                        -196.683
trainer/policy_loss_without_entropy         198.664
trainer/entropy_penalty                      -0.420664
trainer/entropy_percentage                   -0.00211746
trainer/Q1Pred Mean                         197.52
trainer/Q1Pred Std                           72.4808
trainer/Q1Pred Max                          299.376
trainer/Q1Pred Min                            7.1806
trainer/Q2Pred Mean                         197.747
trainer/Q2Pred Std                           72.4635
trainer/Q2Pred Max                          299.595
trainer/Q2Pred Min                           10.301
trainer/QTargetWithReg Mean                 197.719
trainer/QTargetWithReg Std                   72.7002
trainer/QTargetWithReg Max                  299.383
trainer/QTargetWithReg Min                    7.03953
trainer/PolicyLossWithoutReg Mean           198.664
trainer/PolicyLossWithoutReg Std             71.9338
trainer/PolicyLossWithoutReg Max            300.315
trainer/PolicyLossWithoutReg Min             11.0429
trainer/gradient_norm                       312.07
trainer/gradient_penalty                     -1.56035
trainer/gradient_percentage                  -0.0078542
exploration/num steps total              507000
exploration/num paths total                1663
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88449
exploration/Rewards Std                       1.22799
exploration/Rewards Max                      10.2021
exploration/Rewards Min                      -0.648438
exploration/Returns Mean                   4884.49
exploration/Returns Std                       0
exploration/Returns Max                    4884.49
exploration/Returns Min                    4884.49
exploration/Num Paths                         1
exploration/Average Returns                4884.49
evaluation_0/num steps total                  3.94022e+06
evaluation_0/num paths total              11790
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88214
evaluation_0/Rewards Std                      1.23277
evaluation_0/Rewards Max                     10.228
evaluation_0/Rewards Min                     -0.557802
evaluation_0/Returns Mean                  4882.14
evaluation_0/Returns Std                     21.0641
evaluation_0/Returns Max                   4904.55
evaluation_0/Returns Min                   4830.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4882.14
time/epoch (s)                                0
time/total (s)                            10020.6
Epoch                                       502
---------------------------------------  ----------------
2022-11-16 13:33:06.185666 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 503 finished
---------------------------------------  ----------------
epoch                                       503
total_step                               508000
replay_pool/size                         508000
trainer/alpha                                 0.0669982
trainer/alpha_loss                            0.211171
trainer/entropy                              -6.07813
trainer/qf_loss                               8.61961
trainer/state_noise                           0.005
trainer/policy_loss                        -197.448
trainer/policy_loss_without_entropy         199.387
trainer/entropy_penalty                      -0.407224
trainer/entropy_percentage                   -0.00204238
trainer/Q1Pred Mean                         198.628
trainer/Q1Pred Std                           69.7161
trainer/Q1Pred Max                          292.919
trainer/Q1Pred Min                          -10.2479
trainer/Q2Pred Mean                         198.086
trainer/Q2Pred Std                           69.9199
trainer/Q2Pred Max                          292.03
trainer/Q2Pred Min                           -9.20519
trainer/QTargetWithReg Mean                 198.271
trainer/QTargetWithReg Std                   69.9253
trainer/QTargetWithReg Max                  293.577
trainer/QTargetWithReg Min                   -9.73219
trainer/PolicyLossWithoutReg Mean           199.387
trainer/PolicyLossWithoutReg Std             68.2474
trainer/PolicyLossWithoutReg Max            292.698
trainer/PolicyLossWithoutReg Min             -7.45574
trainer/gradient_norm                       306.2
trainer/gradient_penalty                     -1.531
trainer/gradient_percentage                  -0.00767856
exploration/num steps total              508000
exploration/num paths total                1664
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85183
exploration/Rewards Std                       1.24156
exploration/Rewards Max                       9.85826
exploration/Rewards Min                      -0.57624
exploration/Returns Mean                   4851.83
exploration/Returns Std                       0
exploration/Returns Max                    4851.83
exploration/Returns Min                    4851.83
exploration/Num Paths                         1
exploration/Average Returns                4851.83
evaluation_0/num steps total                  3.94756e+06
evaluation_0/num paths total              11807
evaluation_0/path length Mean               431.647
evaluation_0/path length Std                475.518
evaluation_0/path length Max               1000
evaluation_0/path length Min                 33
evaluation_0/Rewards Mean                     4.86767
evaluation_0/Rewards Std                      1.39631
evaluation_0/Rewards Max                     10.1478
evaluation_0/Rewards Min                     -0.665882
evaluation_0/Returns Mean                  2101.11
evaluation_0/Returns Std                   2440.48
evaluation_0/Returns Max                   5048.83
evaluation_0/Returns Min                     56.3031
evaluation_0/Num Paths                       17
evaluation_0/Average Returns               2101.11
time/epoch (s)                                0
time/total (s)                            10040
Epoch                                       503
---------------------------------------  ----------------
2022-11-16 13:33:22.161142 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 504 finished
---------------------------------------  ----------------
epoch                                       504
total_step                               509000
replay_pool/size                         509000
trainer/alpha                                 0.0674458
trainer/alpha_loss                            1.19501
trainer/entropy                              -6.4432
trainer/qf_loss                               9.64732
trainer/state_noise                           0.005
trainer/policy_loss                        -199.286
trainer/policy_loss_without_entropy         201.303
trainer/entropy_penalty                      -0.434567
trainer/entropy_percentage                   -0.00215877
trainer/Q1Pred Mean                         200.349
trainer/Q1Pred Std                           67.1381
trainer/Q1Pred Max                          304.858
trainer/Q1Pred Min                           -5.67169
trainer/Q2Pred Mean                         200.526
trainer/Q2Pred Std                           67.264
trainer/Q2Pred Max                          303.184
trainer/Q2Pred Min                           -2.58228
trainer/QTargetWithReg Mean                 200.105
trainer/QTargetWithReg Std                   67.0993
trainer/QTargetWithReg Max                  305.866
trainer/QTargetWithReg Min                   -0.346058
trainer/PolicyLossWithoutReg Mean           201.303
trainer/PolicyLossWithoutReg Std             65.5308
trainer/PolicyLossWithoutReg Max            302.813
trainer/PolicyLossWithoutReg Min              7.07517
trainer/gradient_norm                       316.491
trainer/gradient_penalty                     -1.58246
trainer/gradient_percentage                  -0.00786105
exploration/num steps total              509000
exploration/num paths total                1665
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9866
exploration/Rewards Std                       1.25922
exploration/Rewards Max                      10.4709
exploration/Rewards Min                      -0.683558
exploration/Returns Mean                   4986.6
exploration/Returns Std                       0
exploration/Returns Max                    4986.6
exploration/Returns Min                    4986.6
exploration/Num Paths                         1
exploration/Average Returns                4986.6
evaluation_0/num steps total                  3.95556e+06
evaluation_0/num paths total              11815
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91073
evaluation_0/Rewards Std                      1.24633
evaluation_0/Rewards Max                     10.2803
evaluation_0/Rewards Min                     -0.663873
evaluation_0/Returns Mean                  4910.73
evaluation_0/Returns Std                     18.0167
evaluation_0/Returns Max                   4929.9
evaluation_0/Returns Min                   4873.83
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4910.73
time/epoch (s)                                0
time/total (s)                            10056
Epoch                                       504
---------------------------------------  ----------------
2022-11-16 13:33:38.274110 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 505 finished
---------------------------------------  ----------------
epoch                                       505
total_step                               510000
replay_pool/size                         510000
trainer/alpha                                 0.0664282
trainer/alpha_loss                           -0.164994
trainer/entropy                              -5.93915
trainer/qf_loss                               7.58712
trainer/state_noise                           0.005
trainer/policy_loss                        -202.013
trainer/policy_loss_without_entropy         203.989
trainer/entropy_penalty                      -0.394527
trainer/entropy_percentage                   -0.00193406
trainer/Q1Pred Mean                         203.217
trainer/Q1Pred Std                           65.8836
trainer/Q1Pred Max                          299.995
trainer/Q1Pred Min                           -5.63145
trainer/Q2Pred Mean                         203.495
trainer/Q2Pred Std                           65.577
trainer/Q2Pred Max                          300.241
trainer/Q2Pred Min                           -3.48398
trainer/QTargetWithReg Mean                 203.304
trainer/QTargetWithReg Std                   66.0181
trainer/QTargetWithReg Max                  300.935
trainer/QTargetWithReg Min                   -2.16637
trainer/PolicyLossWithoutReg Mean           203.989
trainer/PolicyLossWithoutReg Std             64.773
trainer/PolicyLossWithoutReg Max            300.526
trainer/PolicyLossWithoutReg Min             -2.66637
trainer/gradient_norm                       316.279
trainer/gradient_penalty                     -1.58139
trainer/gradient_percentage                  -0.00775234
exploration/num steps total              510000
exploration/num paths total                1666
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0052
exploration/Rewards Std                       1.28215
exploration/Rewards Max                      10.2017
exploration/Rewards Min                      -0.590644
exploration/Returns Mean                   5005.2
exploration/Returns Std                       0
exploration/Returns Max                    5005.2
exploration/Returns Min                    5005.2
exploration/Num Paths                         1
exploration/Average Returns                5005.2
evaluation_0/num steps total                  3.96354e+06
evaluation_0/num paths total              12053
evaluation_0/path length Mean                33.5084
evaluation_0/path length Std                  0.508264
evaluation_0/path length Max                 35
evaluation_0/path length Min                 33
evaluation_0/Rewards Mean                     1.76027
evaluation_0/Rewards Std                      1.61877
evaluation_0/Rewards Max                      4.01902
evaluation_0/Rewards Min                     -0.691239
evaluation_0/Returns Mean                    58.9838
evaluation_0/Returns Std                      1.39236
evaluation_0/Returns Max                     63.8607
evaluation_0/Returns Min                     57.0454
evaluation_0/Num Paths                      238
evaluation_0/Average Returns                 58.9838
time/epoch (s)                                0
time/total (s)                            10072.1
Epoch                                       505
---------------------------------------  ----------------
2022-11-16 13:33:54.612593 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 506 finished
---------------------------------------  ----------------
epoch                                       506
total_step                               511000
replay_pool/size                         511000
trainer/alpha                                 0.0668183
trainer/alpha_loss                            0.384897
trainer/entropy                              -6.14225
trainer/qf_loss                               7.07838
trainer/state_noise                           0.005
trainer/policy_loss                        -193.642
trainer/policy_loss_without_entropy         195.672
trainer/entropy_penalty                      -0.410414
trainer/entropy_percentage                   -0.00209746
trainer/Q1Pred Mean                         195.26
trainer/Q1Pred Std                           65.578
trainer/Q1Pred Max                          302.689
trainer/Q1Pred Min                           20.8426
trainer/Q2Pred Mean                         194.689
trainer/Q2Pred Std                           65.6428
trainer/Q2Pred Max                          301.157
trainer/Q2Pred Min                           18.6542
trainer/QTargetWithReg Mean                 194.99
trainer/QTargetWithReg Std                   66.1969
trainer/QTargetWithReg Max                  302.982
trainer/QTargetWithReg Min                   14.2319
trainer/PolicyLossWithoutReg Mean           195.672
trainer/PolicyLossWithoutReg Std             64.9859
trainer/PolicyLossWithoutReg Max            300.926
trainer/PolicyLossWithoutReg Min             18.6586
trainer/gradient_norm                       323.985
trainer/gradient_penalty                     -1.61992
trainer/gradient_percentage                  -0.00827875
exploration/num steps total              511000
exploration/num paths total                1667
exploration/path length this epoch Mean      36
exploration/path length this epoch Std        0
exploration/path length this epoch Max       36
exploration/path length this epoch Min       36
exploration/Rewards Mean                      1.90903
exploration/Rewards Std                       1.68249
exploration/Rewards Max                       4.03342
exploration/Rewards Min                      -0.657746
exploration/Returns Mean                     68.7249
exploration/Returns Std                       0
exploration/Returns Max                      68.7249
exploration/Returns Min                      68.7249
exploration/Num Paths                         1
exploration/Average Returns                  68.7249
evaluation_0/num steps total                  3.97154e+06
evaluation_0/num paths total              12061
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.37218
evaluation_0/Rewards Std                      1.11419
evaluation_0/Rewards Max                      8.93818
evaluation_0/Rewards Min                     -0.686485
evaluation_0/Returns Mean                  4372.18
evaluation_0/Returns Std                     31.4698
evaluation_0/Returns Max                   4443.57
evaluation_0/Returns Min                   4334.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4372.18
time/epoch (s)                                0
time/total (s)                            10088.4
Epoch                                       506
---------------------------------------  ----------------
2022-11-16 13:34:10.309517 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 507 finished
---------------------------------------  ----------------
epoch                                       507
total_step                               512000
replay_pool/size                         512000
trainer/alpha                                 0.0676542
trainer/alpha_loss                           -0.519011
trainer/entropy                              -5.80729
trainer/qf_loss                               9.96061
trainer/state_noise                           0.005
trainer/policy_loss                        -206.722
trainer/policy_loss_without_entropy         208.749
trainer/entropy_penalty                      -0.392887
trainer/entropy_percentage                   -0.00188211
trainer/Q1Pred Mean                         207.401
trainer/Q1Pred Std                           64.9276
trainer/Q1Pred Max                          298.446
trainer/Q1Pred Min                            1.49769
trainer/Q2Pred Mean                         208.08
trainer/Q2Pred Std                           65.1796
trainer/Q2Pred Max                          299.298
trainer/Q2Pred Min                            3.56272
trainer/QTargetWithReg Mean                 207.719
trainer/QTargetWithReg Std                   65.024
trainer/QTargetWithReg Max                  300.416
trainer/QTargetWithReg Min                    3.74009
trainer/PolicyLossWithoutReg Mean           208.749
trainer/PolicyLossWithoutReg Std             64.3162
trainer/PolicyLossWithoutReg Max            299.071
trainer/PolicyLossWithoutReg Min              2.57352
trainer/gradient_norm                       326.818
trainer/gradient_penalty                     -1.63409
trainer/gradient_percentage                  -0.00782802
exploration/num steps total              512000
exploration/num paths total                1668
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84061
exploration/Rewards Std                       1.26255
exploration/Rewards Max                      10.1761
exploration/Rewards Min                      -0.68924
exploration/Returns Mean                   4840.61
exploration/Returns Std                       0
exploration/Returns Max                    4840.61
exploration/Returns Min                    4840.61
exploration/Num Paths                         1
exploration/Average Returns                4840.61
evaluation_0/num steps total                  3.97954e+06
evaluation_0/num paths total              12069
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.53388
evaluation_0/Rewards Std                      1.15794
evaluation_0/Rewards Max                      9.18935
evaluation_0/Rewards Min                     -0.584505
evaluation_0/Returns Mean                  4533.88
evaluation_0/Returns Std                     21.045
evaluation_0/Returns Max                   4567.41
evaluation_0/Returns Min                   4509.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4533.88
time/epoch (s)                                0
time/total (s)                            10104.1
Epoch                                       507
---------------------------------------  ----------------
2022-11-16 13:34:26.866961 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 508 finished
---------------------------------------  ----------------
epoch                                       508
total_step                               513000
replay_pool/size                         513000
trainer/alpha                                 0.0675858
trainer/alpha_loss                            0.36019
trainer/entropy                              -6.13368
trainer/qf_loss                               8.04503
trainer/state_noise                           0.005
trainer/policy_loss                        -193.247
trainer/policy_loss_without_entropy         195.215
trainer/entropy_penalty                      -0.414549
trainer/entropy_percentage                   -0.00212355
trainer/Q1Pred Mean                         194.026
trainer/Q1Pred Std                           69.9601
trainer/Q1Pred Max                          301.415
trainer/Q1Pred Min                           -3.83865
trainer/Q2Pred Mean                         194.25
trainer/Q2Pred Std                           70.2795
trainer/Q2Pred Max                          300.422
trainer/Q2Pred Min                           -4.78445
trainer/QTargetWithReg Mean                 194.395
trainer/QTargetWithReg Std                   69.8883
trainer/QTargetWithReg Max                  302.073
trainer/QTargetWithReg Min                   -0.167523
trainer/PolicyLossWithoutReg Mean           195.215
trainer/PolicyLossWithoutReg Std             69.3984
trainer/PolicyLossWithoutReg Max            300.959
trainer/PolicyLossWithoutReg Min             -2.23665
trainer/gradient_norm                       310.803
trainer/gradient_penalty                     -1.55401
trainer/gradient_percentage                  -0.00796052
exploration/num steps total              513000
exploration/num paths total                1669
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93819
exploration/Rewards Std                       1.29556
exploration/Rewards Max                      10.3202
exploration/Rewards Min                      -0.630214
exploration/Returns Mean                   4938.19
exploration/Returns Std                       0
exploration/Returns Max                    4938.19
exploration/Returns Min                    4938.19
exploration/Num Paths                         1
exploration/Average Returns                4938.19
evaluation_0/num steps total                  3.98754e+06
evaluation_0/num paths total              12077
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91609
evaluation_0/Rewards Std                      1.23609
evaluation_0/Rewards Max                     10.1973
evaluation_0/Rewards Min                     -0.553251
evaluation_0/Returns Mean                  4916.09
evaluation_0/Returns Std                     13.0835
evaluation_0/Returns Max                   4939.21
evaluation_0/Returns Min                   4897.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4916.09
time/epoch (s)                                0
time/total (s)                            10120.7
Epoch                                       508
---------------------------------------  ----------------
2022-11-16 13:34:42.659763 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 509 finished
---------------------------------------  ----------------
epoch                                       509
total_step                               514000
replay_pool/size                         514000
trainer/alpha                                 0.0672155
trainer/alpha_loss                           -0.624387
trainer/entropy                              -5.76871
trainer/qf_loss                               8.9895
trainer/state_noise                           0.005
trainer/policy_loss                        -198.007
trainer/policy_loss_without_entropy         200
trainer/entropy_penalty                      -0.387747
trainer/entropy_percentage                   -0.00193873
trainer/Q1Pred Mean                         199.156
trainer/Q1Pred Std                           65.0508
trainer/Q1Pred Max                          299.22
trainer/Q1Pred Min                           13.694
trainer/Q2Pred Mean                         199.095
trainer/Q2Pred Std                           65.0041
trainer/Q2Pred Max                          297.573
trainer/Q2Pred Min                            6.68981
trainer/QTargetWithReg Mean                 199.341
trainer/QTargetWithReg Std                   65.1893
trainer/QTargetWithReg Max                  297.891
trainer/QTargetWithReg Min                   11.997
trainer/PolicyLossWithoutReg Mean           200
trainer/PolicyLossWithoutReg Std             64.2177
trainer/PolicyLossWithoutReg Max            297.629
trainer/PolicyLossWithoutReg Min             14.5702
trainer/gradient_norm                       321.045
trainer/gradient_penalty                     -1.60522
trainer/gradient_percentage                  -0.0080261
exploration/num steps total              514000
exploration/num paths total                1670
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85589
exploration/Rewards Std                       1.2399
exploration/Rewards Max                       9.96559
exploration/Rewards Min                      -0.479085
exploration/Returns Mean                   4855.89
exploration/Returns Std                       0
exploration/Returns Max                    4855.89
exploration/Returns Min                    4855.89
exploration/Num Paths                         1
exploration/Average Returns                4855.89
evaluation_0/num steps total                  3.99554e+06
evaluation_0/num paths total              12085
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00896
evaluation_0/Rewards Std                      1.20464
evaluation_0/Rewards Max                     10.0595
evaluation_0/Rewards Min                     -0.49128
evaluation_0/Returns Mean                  5008.96
evaluation_0/Returns Std                      8.65186
evaluation_0/Returns Max                   5026.91
evaluation_0/Returns Min                   4996.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5008.96
time/epoch (s)                                0
time/total (s)                            10136.5
Epoch                                       509
---------------------------------------  ----------------
2022-11-16 13:34:59.037135 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 510 finished
---------------------------------------  ----------------
epoch                                       510
total_step                               515000
replay_pool/size                         515000
trainer/alpha                                 0.0693983
trainer/alpha_loss                           -0.228689
trainer/entropy                              -5.91428
trainer/qf_loss                               9.44626
trainer/state_noise                           0.005
trainer/policy_loss                        -192.871
trainer/policy_loss_without_entropy         194.916
trainer/entropy_penalty                      -0.410441
trainer/entropy_percentage                   -0.00210573
trainer/Q1Pred Mean                         194.253
trainer/Q1Pred Std                           70.2897
trainer/Q1Pred Max                          301.772
trainer/Q1Pred Min                            3.25969
trainer/Q2Pred Mean                         194.128
trainer/Q2Pred Std                           70.5088
trainer/Q2Pred Max                          302.167
trainer/Q2Pred Min                           10.2824
trainer/QTargetWithReg Mean                 193.97
trainer/QTargetWithReg Std                   70.6361
trainer/QTargetWithReg Max                  302.225
trainer/QTargetWithReg Min                   12.6512
trainer/PolicyLossWithoutReg Mean           194.916
trainer/PolicyLossWithoutReg Std             69.8184
trainer/PolicyLossWithoutReg Max            301.402
trainer/PolicyLossWithoutReg Min             13.5786
trainer/gradient_norm                       326.998
trainer/gradient_penalty                     -1.63499
trainer/gradient_percentage                  -0.00838816
exploration/num steps total              515000
exploration/num paths total                1671
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00724
exploration/Rewards Std                       1.28574
exploration/Rewards Max                      10.5049
exploration/Rewards Min                      -0.52073
exploration/Returns Mean                   5007.24
exploration/Returns Std                       0
exploration/Returns Max                    5007.24
exploration/Returns Min                    5007.24
exploration/Num Paths                         1
exploration/Average Returns                5007.24
evaluation_0/num steps total                  4.00354e+06
evaluation_0/num paths total              12093
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0162
evaluation_0/Rewards Std                      1.26901
evaluation_0/Rewards Max                     10.5099
evaluation_0/Rewards Min                     -0.570157
evaluation_0/Returns Mean                  5016.2
evaluation_0/Returns Std                     19.9518
evaluation_0/Returns Max                   5051.09
evaluation_0/Returns Min                   4989.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5016.2
time/epoch (s)                                0
time/total (s)                            10152.8
Epoch                                       510
---------------------------------------  ----------------
2022-11-16 13:35:14.936407 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 511 finished
---------------------------------------  ----------------
epoch                                       511
total_step                               516000
replay_pool/size                         516000
trainer/alpha                                 0.0670396
trainer/alpha_loss                            0.14835
trainer/entropy                              -6.05489
trainer/qf_loss                               7.84458
trainer/state_noise                           0.005
trainer/policy_loss                        -202.336
trainer/policy_loss_without_entropy         204.351
trainer/entropy_penalty                      -0.405918
trainer/entropy_percentage                   -0.00198637
trainer/Q1Pred Mean                         203.916
trainer/Q1Pred Std                           66.9983
trainer/Q1Pred Max                          297.128
trainer/Q1Pred Min                          -14.3841
trainer/Q2Pred Mean                         204
trainer/Q2Pred Std                           66.961
trainer/Q2Pred Max                          297.509
trainer/Q2Pred Min                          -17.2566
trainer/QTargetWithReg Mean                 203.4
trainer/QTargetWithReg Std                   66.9825
trainer/QTargetWithReg Max                  297.159
trainer/QTargetWithReg Min                   -9.47785
trainer/PolicyLossWithoutReg Mean           204.351
trainer/PolicyLossWithoutReg Std             66.1958
trainer/PolicyLossWithoutReg Max            295.965
trainer/PolicyLossWithoutReg Min             -7.60564
trainer/gradient_norm                       321.885
trainer/gradient_penalty                     -1.60943
trainer/gradient_percentage                  -0.0078758
exploration/num steps total              516000
exploration/num paths total                1672
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81456
exploration/Rewards Std                       1.22563
exploration/Rewards Max                      10.0405
exploration/Rewards Min                      -0.666093
exploration/Returns Mean                   4814.56
exploration/Returns Std                       0
exploration/Returns Max                    4814.56
exploration/Returns Min                    4814.56
exploration/Num Paths                         1
exploration/Average Returns                4814.56
evaluation_0/num steps total                  4.01154e+06
evaluation_0/num paths total              12101
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91882
evaluation_0/Rewards Std                      1.23014
evaluation_0/Rewards Max                     10.2565
evaluation_0/Rewards Min                     -0.646406
evaluation_0/Returns Mean                  4918.82
evaluation_0/Returns Std                     25.5848
evaluation_0/Returns Max                   4958.48
evaluation_0/Returns Min                   4869.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4918.82
time/epoch (s)                                0
time/total (s)                            10168.7
Epoch                                       511
---------------------------------------  ----------------
2022-11-16 13:35:31.276218 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 512 finished
---------------------------------------  ----------------
epoch                                       512
total_step                               517000
replay_pool/size                         517000
trainer/alpha                                 0.0672375
trainer/alpha_loss                            0.0450396
trainer/entropy                              -6.01669
trainer/qf_loss                               9.97548
trainer/state_noise                           0.005
trainer/policy_loss                        -182.723
trainer/policy_loss_without_entropy         184.766
trainer/entropy_penalty                      -0.404547
trainer/entropy_percentage                   -0.00218951
trainer/Q1Pred Mean                         183.245
trainer/Q1Pred Std                           75.287
trainer/Q1Pred Max                          298.225
trainer/Q1Pred Min                           -9.53724
trainer/Q2Pred Mean                         183.746
trainer/Q2Pred Std                           75.1166
trainer/Q2Pred Max                          299.7
trainer/Q2Pred Min                           -9.28492
trainer/QTargetWithReg Mean                 183.696
trainer/QTargetWithReg Std                   75.4801
trainer/QTargetWithReg Max                  299.91
trainer/QTargetWithReg Min                  -13.0901
trainer/PolicyLossWithoutReg Mean           184.766
trainer/PolicyLossWithoutReg Std             73.8616
trainer/PolicyLossWithoutReg Max            298.056
trainer/PolicyLossWithoutReg Min             -5.37254
trainer/gradient_norm                       327.609
trainer/gradient_penalty                     -1.63804
trainer/gradient_percentage                  -0.00886553
exploration/num steps total              517000
exploration/num paths total                1673
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00661
exploration/Rewards Std                       1.23208
exploration/Rewards Max                       9.88187
exploration/Rewards Min                      -0.740886
exploration/Returns Mean                   5006.61
exploration/Returns Std                       0
exploration/Returns Max                    5006.61
exploration/Returns Min                    5006.61
exploration/Num Paths                         1
exploration/Average Returns                5006.61
evaluation_0/num steps total                  4.01954e+06
evaluation_0/num paths total              12109
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82608
evaluation_0/Rewards Std                      1.20889
evaluation_0/Rewards Max                     10.3683
evaluation_0/Rewards Min                     -0.507236
evaluation_0/Returns Mean                  4826.08
evaluation_0/Returns Std                    213.796
evaluation_0/Returns Max                   5094.24
evaluation_0/Returns Min                   4519.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4826.08
time/epoch (s)                                0
time/total (s)                            10185.1
Epoch                                       512
---------------------------------------  ----------------
2022-11-16 13:35:47.244513 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 513 finished
---------------------------------------  ----------------
epoch                                       513
total_step                               518000
replay_pool/size                         518000
trainer/alpha                                 0.0680209
trainer/alpha_loss                           -0.437222
trainer/entropy                              -5.83733
trainer/qf_loss                               7.31998
trainer/state_noise                           0.005
trainer/policy_loss                        -197.646
trainer/policy_loss_without_entropy         199.565
trainer/entropy_penalty                      -0.39706
trainer/entropy_percentage                   -0.00198963
trainer/Q1Pred Mean                         198.25
trainer/Q1Pred Std                           67.0755
trainer/Q1Pred Max                          302.899
trainer/Q1Pred Min                           13.8283
trainer/Q2Pred Mean                         198.347
trainer/Q2Pred Std                           67.2923
trainer/Q2Pred Max                          302.799
trainer/Q2Pred Min                            6.35238
trainer/QTargetWithReg Mean                 198.334
trainer/QTargetWithReg Std                   67.341
trainer/QTargetWithReg Max                  303.333
trainer/QTargetWithReg Min                   -0.455827
trainer/PolicyLossWithoutReg Mean           199.565
trainer/PolicyLossWithoutReg Std             65.7163
trainer/PolicyLossWithoutReg Max            303.102
trainer/PolicyLossWithoutReg Min             19.8327
trainer/gradient_norm                       304.419
trainer/gradient_penalty                     -1.5221
trainer/gradient_percentage                  -0.00762706
exploration/num steps total              518000
exploration/num paths total                1674
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82346
exploration/Rewards Std                       1.2584
exploration/Rewards Max                      10.3048
exploration/Rewards Min                      -0.607315
exploration/Returns Mean                   4823.46
exploration/Returns Std                       0
exploration/Returns Max                    4823.46
exploration/Returns Min                    4823.46
exploration/Num Paths                         1
exploration/Average Returns                4823.46
evaluation_0/num steps total                  4.02754e+06
evaluation_0/num paths total              12117
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94145
evaluation_0/Rewards Std                      1.22229
evaluation_0/Rewards Max                     10.0981
evaluation_0/Rewards Min                     -0.555405
evaluation_0/Returns Mean                  4941.45
evaluation_0/Returns Std                     15.1509
evaluation_0/Returns Max                   4967.38
evaluation_0/Returns Min                   4918.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4941.45
time/epoch (s)                                0
time/total (s)                            10201.1
Epoch                                       513
---------------------------------------  ----------------
2022-11-16 13:36:08.274088 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 514 finished
---------------------------------------  ----------------
epoch                                       514
total_step                               519000
replay_pool/size                         519000
trainer/alpha                                 0.0672104
trainer/alpha_loss                           -0.565564
trainer/entropy                              -5.79052
trainer/qf_loss                              10.93
trainer/state_noise                           0.005
trainer/policy_loss                        -208.205
trainer/policy_loss_without_entropy         210.234
trainer/entropy_penalty                      -0.389183
trainer/entropy_percentage                   -0.00185119
trainer/Q1Pred Mean                         208.738
trainer/Q1Pred Std                           68.9582
trainer/Q1Pred Max                          301.425
trainer/Q1Pred Min                           -7.29047
trainer/Q2Pred Mean                         208.94
trainer/Q2Pred Std                           68.6503
trainer/Q2Pred Max                          300.156
trainer/Q2Pred Min                            4.91555
trainer/QTargetWithReg Mean                 208.643
trainer/QTargetWithReg Std                   69.0672
trainer/QTargetWithReg Max                  305.254
trainer/QTargetWithReg Min                    3.74009
trainer/PolicyLossWithoutReg Mean           210.234
trainer/PolicyLossWithoutReg Std             67.7852
trainer/PolicyLossWithoutReg Max            300.283
trainer/PolicyLossWithoutReg Min              3.90769
trainer/gradient_norm                       327.982
trainer/gradient_penalty                     -1.63991
trainer/gradient_percentage                  -0.0078004
exploration/num steps total              519000
exploration/num paths total                1675
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96311
exploration/Rewards Std                       1.2478
exploration/Rewards Max                      10.3585
exploration/Rewards Min                      -0.603902
exploration/Returns Mean                   4963.11
exploration/Returns Std                       0
exploration/Returns Max                    4963.11
exploration/Returns Min                    4963.11
exploration/Num Paths                         1
exploration/Average Returns                4963.11
evaluation_0/num steps total                  4.03544e+06
evaluation_0/num paths total              12149
evaluation_0/path length Mean               246.875
evaluation_0/path length Std                398.517
evaluation_0/path length Max               1000
evaluation_0/path length Min                 34
evaluation_0/Rewards Mean                     4.63298
evaluation_0/Rewards Std                      1.64239
evaluation_0/Rewards Max                     10.385
evaluation_0/Rewards Min                     -0.567949
evaluation_0/Returns Mean                  1143.77
evaluation_0/Returns Std                   2034.1
evaluation_0/Returns Max                   5024.72
evaluation_0/Returns Min                     58.6354
evaluation_0/Num Paths                       32
evaluation_0/Average Returns               1143.77
time/epoch (s)                                0
time/total (s)                            10222.1
Epoch                                       514
---------------------------------------  ----------------
2022-11-16 13:36:24.209035 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 515 finished
---------------------------------------  ----------------
epoch                                       515
total_step                               520000
replay_pool/size                         520000
trainer/alpha                                 0.0659298
trainer/alpha_loss                           -1.46238
trainer/entropy                              -5.46213
trainer/qf_loss                               6.23726
trainer/state_noise                           0.005
trainer/policy_loss                        -202.913
trainer/policy_loss_without_entropy         204.854
trainer/entropy_penalty                      -0.360117
trainer/entropy_percentage                   -0.00175792
trainer/Q1Pred Mean                         204.377
trainer/Q1Pred Std                           65.7655
trainer/Q1Pred Max                          303.976
trainer/Q1Pred Min                           18.5603
trainer/Q2Pred Mean                         204.098
trainer/Q2Pred Std                           65.8172
trainer/Q2Pred Max                          303.896
trainer/Q2Pred Min                           17.4426
trainer/QTargetWithReg Mean                 203.73
trainer/QTargetWithReg Std                   65.8814
trainer/QTargetWithReg Max                  303.353
trainer/QTargetWithReg Min                   18.8349
trainer/PolicyLossWithoutReg Mean           204.854
trainer/PolicyLossWithoutReg Std             64.9411
trainer/PolicyLossWithoutReg Max            303.891
trainer/PolicyLossWithoutReg Min             18.3687
trainer/gradient_norm                       316.168
trainer/gradient_penalty                     -1.58084
trainer/gradient_percentage                  -0.00771692
exploration/num steps total              520000
exploration/num paths total                1676
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87836
exploration/Rewards Std                       1.25039
exploration/Rewards Max                      10.0985
exploration/Rewards Min                      -0.475973
exploration/Returns Mean                   4878.36
exploration/Returns Std                       0
exploration/Returns Max                    4878.36
exploration/Returns Min                    4878.36
exploration/Num Paths                         1
exploration/Average Returns                4878.36
evaluation_0/num steps total                  4.04344e+06
evaluation_0/num paths total              12157
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17826
evaluation_0/Rewards Std                      1.30284
evaluation_0/Rewards Max                     10.6723
evaluation_0/Rewards Min                     -0.607891
evaluation_0/Returns Mean                  5178.26
evaluation_0/Returns Std                     74.269
evaluation_0/Returns Max                   5292.68
evaluation_0/Returns Min                   5013.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5178.26
time/epoch (s)                                0
time/total (s)                            10238
Epoch                                       515
---------------------------------------  ----------------
2022-11-16 13:36:40.091575 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 516 finished
---------------------------------------  ----------------
epoch                                       516
total_step                               521000
replay_pool/size                         521000
trainer/alpha                                 0.0648793
trainer/alpha_loss                            0.764405
trainer/entropy                              -6.27946
trainer/qf_loss                              12.0784
trainer/state_noise                           0.005
trainer/policy_loss                        -190.733
trainer/policy_loss_without_entropy         192.704
trainer/entropy_penalty                      -0.407407
trainer/entropy_percentage                   -0.00211416
trainer/Q1Pred Mean                         191.402
trainer/Q1Pred Std                           72.6205
trainer/Q1Pred Max                          299.057
trainer/Q1Pred Min                           -1.3906
trainer/Q2Pred Mean                         191.638
trainer/Q2Pred Std                           72.8299
trainer/Q2Pred Max                          298.403
trainer/Q2Pred Min                            3.82924
trainer/QTargetWithReg Mean                 191.543
trainer/QTargetWithReg Std                   73.1775
trainer/QTargetWithReg Max                  298.898
trainer/QTargetWithReg Min                    2.79321
trainer/PolicyLossWithoutReg Mean           192.704
trainer/PolicyLossWithoutReg Std             71.4206
trainer/PolicyLossWithoutReg Max            298.872
trainer/PolicyLossWithoutReg Min              3.41931
trainer/gradient_norm                       312.638
trainer/gradient_penalty                     -1.56319
trainer/gradient_percentage                  -0.00811189
exploration/num steps total              521000
exploration/num paths total                1677
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01657
exploration/Rewards Std                       1.27873
exploration/Rewards Max                      10.1664
exploration/Rewards Min                      -0.655409
exploration/Returns Mean                   5016.57
exploration/Returns Std                       0
exploration/Returns Max                    5016.57
exploration/Returns Min                    5016.57
exploration/Num Paths                         1
exploration/Average Returns                5016.57
evaluation_0/num steps total                  4.05144e+06
evaluation_0/num paths total              12165
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06352
evaluation_0/Rewards Std                      1.24444
evaluation_0/Rewards Max                     10.1169
evaluation_0/Rewards Min                     -0.637767
evaluation_0/Returns Mean                  5063.52
evaluation_0/Returns Std                     14.005
evaluation_0/Returns Max                   5073.58
evaluation_0/Returns Min                   5031.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5063.52
time/epoch (s)                                0
time/total (s)                            10253.9
Epoch                                       516
---------------------------------------  ----------------
2022-11-16 13:36:56.593552 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 517 finished
---------------------------------------  ----------------
epoch                                       517
total_step                               522000
replay_pool/size                         522000
trainer/alpha                                 0.0665524
trainer/alpha_loss                           -0.0594979
trainer/entropy                              -5.97804
trainer/qf_loss                               9.27604
trainer/state_noise                           0.005
trainer/policy_loss                        -197.002
trainer/policy_loss_without_entropy         199.017
trainer/entropy_penalty                      -0.397853
trainer/entropy_percentage                   -0.00199909
trainer/Q1Pred Mean                         198.382
trainer/Q1Pred Std                           73.255
trainer/Q1Pred Max                          302.796
trainer/Q1Pred Min                          -22.4521
trainer/Q2Pred Mean                         198.388
trainer/Q2Pred Std                           73.1902
trainer/Q2Pred Max                          301.38
trainer/Q2Pred Min                          -19.6071
trainer/QTargetWithReg Mean                 198.88
trainer/QTargetWithReg Std                   73.2536
trainer/QTargetWithReg Max                  301.943
trainer/QTargetWithReg Min                  -20.3266
trainer/PolicyLossWithoutReg Mean           199.017
trainer/PolicyLossWithoutReg Std             72.3164
trainer/PolicyLossWithoutReg Max            302.285
trainer/PolicyLossWithoutReg Min            -15.5193
trainer/gradient_norm                       323.369
trainer/gradient_penalty                     -1.61684
trainer/gradient_percentage                  -0.00812414
exploration/num steps total              522000
exploration/num paths total                1678
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91326
exploration/Rewards Std                       1.28215
exploration/Rewards Max                      10.2361
exploration/Rewards Min                      -0.583178
exploration/Returns Mean                   4913.26
exploration/Returns Std                       0
exploration/Returns Max                    4913.26
exploration/Returns Min                    4913.26
exploration/Num Paths                         1
exploration/Average Returns                4913.26
evaluation_0/num steps total                  4.05944e+06
evaluation_0/num paths total              12173
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95581
evaluation_0/Rewards Std                      1.20647
evaluation_0/Rewards Max                     10.0155
evaluation_0/Rewards Min                     -0.574126
evaluation_0/Returns Mean                  4955.81
evaluation_0/Returns Std                     11.2103
evaluation_0/Returns Max                   4974.98
evaluation_0/Returns Min                   4945
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4955.81
time/epoch (s)                                0
time/total (s)                            10270.4
Epoch                                       517
---------------------------------------  ----------------
2022-11-16 13:37:12.450948 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 518 finished
---------------------------------------  ----------------
epoch                                       518
total_step                               523000
replay_pool/size                         523000
trainer/alpha                                 0.0653426
trainer/alpha_loss                            1.57178
trainer/entropy                              -6.57615
trainer/qf_loss                               8.68762
trainer/state_noise                           0.005
trainer/policy_loss                        -196.725
trainer/policy_loss_without_entropy         198.727
trainer/entropy_penalty                      -0.429702
trainer/entropy_percentage                   -0.00216227
trainer/Q1Pred Mean                         197.649
trainer/Q1Pred Std                           72.1732
trainer/Q1Pred Max                          298.153
trainer/Q1Pred Min                           -8.13219
trainer/Q2Pred Mean                         197.679
trainer/Q2Pred Std                           72.1549
trainer/Q2Pred Max                          298.601
trainer/Q2Pred Min                           -9.65193
trainer/QTargetWithReg Mean                 198.217
trainer/QTargetWithReg Std                   72.3395
trainer/QTargetWithReg Max                  298.939
trainer/QTargetWithReg Min                  -12.5573
trainer/PolicyLossWithoutReg Mean           198.727
trainer/PolicyLossWithoutReg Std             71.4915
trainer/PolicyLossWithoutReg Max            298.516
trainer/PolicyLossWithoutReg Min             -4.2342
trainer/gradient_norm                       314.611
trainer/gradient_penalty                     -1.57306
trainer/gradient_percentage                  -0.00791565
exploration/num steps total              523000
exploration/num paths total                1679
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01838
exploration/Rewards Std                       1.22434
exploration/Rewards Max                       9.92542
exploration/Rewards Min                      -0.518154
exploration/Returns Mean                   5018.38
exploration/Returns Std                       0
exploration/Returns Max                    5018.38
exploration/Returns Min                    5018.38
exploration/Num Paths                         1
exploration/Average Returns                5018.38
evaluation_0/num steps total                  4.06744e+06
evaluation_0/num paths total              12181
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96712
evaluation_0/Rewards Std                      1.25005
evaluation_0/Rewards Max                     10.2117
evaluation_0/Rewards Min                     -0.575087
evaluation_0/Returns Mean                  4967.12
evaluation_0/Returns Std                     43.3097
evaluation_0/Returns Max                   5012.8
evaluation_0/Returns Min                   4866.82
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4967.12
time/epoch (s)                                0
time/total (s)                            10286.3
Epoch                                       518
---------------------------------------  ----------------
2022-11-16 13:37:28.897542 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 519 finished
---------------------------------------  ----------------
epoch                                       519
total_step                               524000
replay_pool/size                         524000
trainer/alpha                                 0.0676547
trainer/alpha_loss                           -0.134336
trainer/entropy                              -5.95013
trainer/qf_loss                              10.2626
trainer/state_noise                           0.005
trainer/policy_loss                        -189.569
trainer/policy_loss_without_entropy         191.528
trainer/entropy_penalty                      -0.402554
trainer/entropy_percentage                   -0.0021018
trainer/Q1Pred Mean                         190.24
trainer/Q1Pred Std                           71.3962
trainer/Q1Pred Max                          302.911
trainer/Q1Pred Min                           12.3715
trainer/Q2Pred Mean                         190.93
trainer/Q2Pred Std                           71.4832
trainer/Q2Pred Max                          302.181
trainer/Q2Pred Min                            6.49951
trainer/QTargetWithReg Mean                 190.953
trainer/QTargetWithReg Std                   71.8851
trainer/QTargetWithReg Max                  303.69
trainer/QTargetWithReg Min                    8.98685
trainer/PolicyLossWithoutReg Mean           191.528
trainer/PolicyLossWithoutReg Std             70.5703
trainer/PolicyLossWithoutReg Max            302.312
trainer/PolicyLossWithoutReg Min             10.7445
trainer/gradient_norm                       311.283
trainer/gradient_penalty                     -1.55642
trainer/gradient_percentage                  -0.00812632
exploration/num steps total              524000
exploration/num paths total                1680
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94447
exploration/Rewards Std                       1.27139
exploration/Rewards Max                      10.196
exploration/Rewards Min                      -0.552264
exploration/Returns Mean                   4944.47
exploration/Returns Std                       0
exploration/Returns Max                    4944.47
exploration/Returns Min                    4944.47
exploration/Num Paths                         1
exploration/Average Returns                4944.47
evaluation_0/num steps total                  4.07544e+06
evaluation_0/num paths total              12189
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00631
evaluation_0/Rewards Std                      1.22441
evaluation_0/Rewards Max                     10.0614
evaluation_0/Rewards Min                     -0.505012
evaluation_0/Returns Mean                  5006.31
evaluation_0/Returns Std                     13.7543
evaluation_0/Returns Max                   5031.13
evaluation_0/Returns Min                   4984.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5006.31
time/epoch (s)                                0
time/total (s)                            10302.7
Epoch                                       519
---------------------------------------  ----------------
2022-11-16 13:37:44.740046 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 520 finished
---------------------------------------  ----------------
epoch                                       520
total_step                               525000
replay_pool/size                         525000
trainer/alpha                                 0.0661213
trainer/alpha_loss                           -0.782964
trainer/entropy                              -5.71176
trainer/qf_loss                              11.5596
trainer/state_noise                           0.005
trainer/policy_loss                        -195.915
trainer/policy_loss_without_entropy         197.851
trainer/entropy_penalty                      -0.377669
trainer/entropy_percentage                   -0.00190886
trainer/Q1Pred Mean                         197.029
trainer/Q1Pred Std                           68.2141
trainer/Q1Pred Max                          304.422
trainer/Q1Pred Min                            4.68139
trainer/Q2Pred Mean                         196.918
trainer/Q2Pred Std                           68.4063
trainer/Q2Pred Max                          303.598
trainer/Q2Pred Min                            4.76766
trainer/QTargetWithReg Mean                 196.895
trainer/QTargetWithReg Std                   68.2487
trainer/QTargetWithReg Max                  304.386
trainer/QTargetWithReg Min                    7.3731
trainer/PolicyLossWithoutReg Mean           197.851
trainer/PolicyLossWithoutReg Std             67.658
trainer/PolicyLossWithoutReg Max            304.452
trainer/PolicyLossWithoutReg Min              4.90937
trainer/gradient_norm                       311.564
trainer/gradient_penalty                     -1.55782
trainer/gradient_percentage                  -0.00787372
exploration/num steps total              525000
exploration/num paths total                1681
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04983
exploration/Rewards Std                       1.33414
exploration/Rewards Max                      10.8128
exploration/Rewards Min                      -0.485236
exploration/Returns Mean                   5049.83
exploration/Returns Std                       0
exploration/Returns Max                    5049.83
exploration/Returns Min                    5049.83
exploration/Num Paths                         1
exploration/Average Returns                5049.83
evaluation_0/num steps total                  4.08344e+06
evaluation_0/num paths total              12197
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97917
evaluation_0/Rewards Std                      1.23181
evaluation_0/Rewards Max                     10.1852
evaluation_0/Rewards Min                     -0.543189
evaluation_0/Returns Mean                  4979.17
evaluation_0/Returns Std                     33.0526
evaluation_0/Returns Max                   5025.2
evaluation_0/Returns Min                   4936.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4979.17
time/epoch (s)                                0
time/total (s)                            10318.5
Epoch                                       520
---------------------------------------  ----------------
2022-11-16 13:38:01.164024 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 521 finished
---------------------------------------  ----------------
epoch                                       521
total_step                               526000
replay_pool/size                         526000
trainer/alpha                                 0.065192
trainer/alpha_loss                            1.17153
trainer/entropy                              -6.42907
trainer/qf_loss                               7.03678
trainer/state_noise                           0.005
trainer/policy_loss                        -201.46
trainer/policy_loss_without_entropy         203.495
trainer/entropy_penalty                      -0.419124
trainer/entropy_percentage                   -0.00205963
trainer/Q1Pred Mean                         202.883
trainer/Q1Pred Std                           66.6034
trainer/Q1Pred Max                          302.898
trainer/Q1Pred Min                           -1.48943
trainer/Q2Pred Mean                         202.637
trainer/Q2Pred Std                           66.7627
trainer/Q2Pred Max                          302.903
trainer/Q2Pred Min                           -2.74483
trainer/QTargetWithReg Mean                 202.578
trainer/QTargetWithReg Std                   66.7612
trainer/QTargetWithReg Max                  303.008
trainer/QTargetWithReg Min                   -4.27952
trainer/PolicyLossWithoutReg Mean           203.495
trainer/PolicyLossWithoutReg Std             65.9489
trainer/PolicyLossWithoutReg Max            301.437
trainer/PolicyLossWithoutReg Min             -0.137104
trainer/gradient_norm                       323.154
trainer/gradient_penalty                     -1.61577
trainer/gradient_percentage                  -0.00794012
exploration/num steps total              526000
exploration/num paths total                1682
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96039
exploration/Rewards Std                       1.24118
exploration/Rewards Max                      10.3349
exploration/Rewards Min                      -0.577959
exploration/Returns Mean                   4960.39
exploration/Returns Std                       0
exploration/Returns Max                    4960.39
exploration/Returns Min                    4960.39
exploration/Num Paths                         1
exploration/Average Returns                4960.39
evaluation_0/num steps total                  4.09144e+06
evaluation_0/num paths total              12205
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01353
evaluation_0/Rewards Std                      1.25888
evaluation_0/Rewards Max                     10.3106
evaluation_0/Rewards Min                     -0.54224
evaluation_0/Returns Mean                  5013.53
evaluation_0/Returns Std                     44.8766
evaluation_0/Returns Max                   5099.52
evaluation_0/Returns Min                   4956.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5013.53
time/epoch (s)                                0
time/total (s)                            10335
Epoch                                       521
---------------------------------------  ----------------
2022-11-16 13:38:16.993732 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 522 finished
---------------------------------------  ----------------
epoch                                       522
total_step                               527000
replay_pool/size                         527000
trainer/alpha                                 0.0670977
trainer/alpha_loss                           -0.18114
trainer/entropy                              -5.93295
trainer/qf_loss                              13.6319
trainer/state_noise                           0.005
trainer/policy_loss                        -195.912
trainer/policy_loss_without_entropy         197.903
trainer/entropy_penalty                      -0.398087
trainer/entropy_percentage                   -0.00201153
trainer/Q1Pred Mean                         196.419
trainer/Q1Pred Std                           68.6735
trainer/Q1Pred Max                          302.501
trainer/Q1Pred Min                           -2.91625
trainer/Q2Pred Mean                         196.383
trainer/Q2Pred Std                           68.8042
trainer/Q2Pred Max                          303.097
trainer/Q2Pred Min                            0.0494798
trainer/QTargetWithReg Mean                 196.282
trainer/QTargetWithReg Std                   69.1854
trainer/QTargetWithReg Max                  303.501
trainer/QTargetWithReg Min                   -6.43228
trainer/PolicyLossWithoutReg Mean           197.903
trainer/PolicyLossWithoutReg Std             66.303
trainer/PolicyLossWithoutReg Max            302.843
trainer/PolicyLossWithoutReg Min             13.9375
trainer/gradient_norm                       318.464
trainer/gradient_penalty                     -1.59232
trainer/gradient_percentage                  -0.00804597
exploration/num steps total              527000
exploration/num paths total                1683
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81449
exploration/Rewards Std                       1.2162
exploration/Rewards Max                      10.085
exploration/Rewards Min                      -0.55461
exploration/Returns Mean                   4814.49
exploration/Returns Std                       0
exploration/Returns Max                    4814.49
exploration/Returns Min                    4814.49
exploration/Num Paths                         1
exploration/Average Returns                4814.49
evaluation_0/num steps total                  4.09944e+06
evaluation_0/num paths total              12213
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99981
evaluation_0/Rewards Std                      1.25537
evaluation_0/Rewards Max                     10.1911
evaluation_0/Rewards Min                     -0.404301
evaluation_0/Returns Mean                  4999.81
evaluation_0/Returns Std                     11.6829
evaluation_0/Returns Max                   5014.75
evaluation_0/Returns Min                   4979.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4999.81
time/epoch (s)                                0
time/total (s)                            10350.8
Epoch                                       522
---------------------------------------  ----------------
2022-11-16 13:38:33.301942 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 523 finished
---------------------------------------  ----------------
epoch                                       523
total_step                               528000
replay_pool/size                         528000
trainer/alpha                                 0.0671809
trainer/alpha_loss                            1.09615
trainer/entropy                              -6.40591
trainer/qf_loss                               6.6766
trainer/state_noise                           0.005
trainer/policy_loss                        -194.347
trainer/policy_loss_without_entropy         196.453
trainer/entropy_penalty                      -0.430355
trainer/entropy_percentage                   -0.00219062
trainer/Q1Pred Mean                         196.112
trainer/Q1Pred Std                           71.0356
trainer/Q1Pred Max                          303.79
trainer/Q1Pred Min                          -17.2654
trainer/Q2Pred Mean                         195.858
trainer/Q2Pred Std                           70.6957
trainer/Q2Pred Max                          303.459
trainer/Q2Pred Min                          -23.1346
trainer/QTargetWithReg Mean                 195.64
trainer/QTargetWithReg Std                   70.944
trainer/QTargetWithReg Max                  302.517
trainer/QTargetWithReg Min                  -21.4125
trainer/PolicyLossWithoutReg Mean           196.453
trainer/PolicyLossWithoutReg Std             70.3182
trainer/PolicyLossWithoutReg Max            303.771
trainer/PolicyLossWithoutReg Min            -23.9076
trainer/gradient_norm                       335.131
trainer/gradient_penalty                     -1.67565
trainer/gradient_percentage                  -0.00852952
exploration/num steps total              528000
exploration/num paths total                1684
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00749
exploration/Rewards Std                       1.34527
exploration/Rewards Max                      10.5595
exploration/Rewards Min                      -0.562255
exploration/Returns Mean                   5007.49
exploration/Returns Std                       0
exploration/Returns Max                    5007.49
exploration/Returns Min                    5007.49
exploration/Num Paths                         1
exploration/Average Returns                5007.49
evaluation_0/num steps total                  4.10744e+06
evaluation_0/num paths total              12221
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09096
evaluation_0/Rewards Std                      1.3039
evaluation_0/Rewards Max                     10.5136
evaluation_0/Rewards Min                     -0.510891
evaluation_0/Returns Mean                  5090.96
evaluation_0/Returns Std                     36.8251
evaluation_0/Returns Max                   5163.71
evaluation_0/Returns Min                   5051.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5090.96
time/epoch (s)                                0
time/total (s)                            10367.1
Epoch                                       523
---------------------------------------  ----------------
2022-11-16 13:38:49.243923 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 524 finished
---------------------------------------  ----------------
epoch                                       524
total_step                               529000
replay_pool/size                         529000
trainer/alpha                                 0.0648965
trainer/alpha_loss                            0.658588
trainer/entropy                              -6.24079
trainer/qf_loss                               9.09698
trainer/state_noise                           0.005
trainer/policy_loss                        -194.279
trainer/policy_loss_without_entropy         196.31
trainer/entropy_penalty                      -0.405005
trainer/entropy_percentage                   -0.00206309
trainer/Q1Pred Mean                         195.997
trainer/Q1Pred Std                           71.5443
trainer/Q1Pred Max                          304.524
trainer/Q1Pred Min                          -27.5623
trainer/Q2Pred Mean                         196.161
trainer/Q2Pred Std                           71.5259
trainer/Q2Pred Max                          303.335
trainer/Q2Pred Min                          -26.0198
trainer/QTargetWithReg Mean                 195.634
trainer/QTargetWithReg Std                   72.2919
trainer/QTargetWithReg Max                  304.01
trainer/QTargetWithReg Min                  -53.0494
trainer/PolicyLossWithoutReg Mean           196.31
trainer/PolicyLossWithoutReg Std             70.9174
trainer/PolicyLossWithoutReg Max            304.46
trainer/PolicyLossWithoutReg Min            -27.516
trainer/gradient_norm                       325.287
trainer/gradient_penalty                     -1.62643
trainer/gradient_percentage                  -0.00828502
exploration/num steps total              529000
exploration/num paths total                1685
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82682
exploration/Rewards Std                       1.25983
exploration/Rewards Max                      10.2764
exploration/Rewards Min                      -0.433399
exploration/Returns Mean                   4826.82
exploration/Returns Std                       0
exploration/Returns Max                    4826.82
exploration/Returns Min                    4826.82
exploration/Num Paths                         1
exploration/Average Returns                4826.82
evaluation_0/num steps total                  4.11544e+06
evaluation_0/num paths total              12229
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94938
evaluation_0/Rewards Std                      1.23458
evaluation_0/Rewards Max                     10.2256
evaluation_0/Rewards Min                     -0.657487
evaluation_0/Returns Mean                  4949.38
evaluation_0/Returns Std                     17.3961
evaluation_0/Returns Max                   4975.3
evaluation_0/Returns Min                   4922.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4949.38
time/epoch (s)                                0
time/total (s)                            10383.1
Epoch                                       524
---------------------------------------  ----------------
2022-11-16 13:39:05.485765 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 525 finished
---------------------------------------  ----------------
epoch                                       525
total_step                               530000
replay_pool/size                         530000
trainer/alpha                                 0.0658285
trainer/alpha_loss                           -1.36349
trainer/entropy                              -5.49883
trainer/qf_loss                               7.61518
trainer/state_noise                           0.005
trainer/policy_loss                        -209.22
trainer/policy_loss_without_entropy         211.221
trainer/entropy_penalty                      -0.36198
trainer/entropy_percentage                   -0.00171375
trainer/Q1Pred Mean                         210.788
trainer/Q1Pred Std                           66.2458
trainer/Q1Pred Max                          310.124
trainer/Q1Pred Min                           19.4039
trainer/Q2Pred Mean                         210.541
trainer/Q2Pred Std                           66.2547
trainer/Q2Pred Max                          311.124
trainer/Q2Pred Min                           18.89
trainer/QTargetWithReg Mean                 210.679
trainer/QTargetWithReg Std                   66.7502
trainer/QTargetWithReg Max                  311.224
trainer/QTargetWithReg Min                   18.9034
trainer/PolicyLossWithoutReg Mean           211.221
trainer/PolicyLossWithoutReg Std             65.8167
trainer/PolicyLossWithoutReg Max            310.87
trainer/PolicyLossWithoutReg Min             16.6902
trainer/gradient_norm                       327.775
trainer/gradient_penalty                     -1.63888
trainer/gradient_percentage                  -0.00775907
exploration/num steps total              530000
exploration/num paths total                1686
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7353
exploration/Rewards Std                       1.19544
exploration/Rewards Max                       9.80243
exploration/Rewards Min                      -0.637054
exploration/Returns Mean                   4735.3
exploration/Returns Std                       0
exploration/Returns Max                    4735.3
exploration/Returns Min                    4735.3
exploration/Num Paths                         1
exploration/Average Returns                4735.3
evaluation_0/num steps total                  4.12344e+06
evaluation_0/num paths total              12237
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91827
evaluation_0/Rewards Std                      1.2776
evaluation_0/Rewards Max                     10.464
evaluation_0/Rewards Min                     -0.577274
evaluation_0/Returns Mean                  4918.27
evaluation_0/Returns Std                     69.1754
evaluation_0/Returns Max                   4980.23
evaluation_0/Returns Min                   4759.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4918.27
time/epoch (s)                                0
time/total (s)                            10399.3
Epoch                                       525
---------------------------------------  ----------------
2022-11-16 13:39:21.466059 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 526 finished
---------------------------------------  ----------------
epoch                                       526
total_step                               531000
replay_pool/size                         531000
trainer/alpha                                 0.0660035
trainer/alpha_loss                            0.342842
trainer/entropy                              -6.12614
trainer/qf_loss                              11.4684
trainer/state_noise                           0.005
trainer/policy_loss                        -203.158
trainer/policy_loss_without_entropy         205.236
trainer/entropy_penalty                      -0.404346
trainer/entropy_percentage                   -0.00197016
trainer/Q1Pred Mean                         204.893
trainer/Q1Pred Std                           70.4974
trainer/Q1Pred Max                          311.182
trainer/Q1Pred Min                          -47.2212
trainer/Q2Pred Mean                         204.942
trainer/Q2Pred Std                           70.2221
trainer/Q2Pred Max                          311.467
trainer/Q2Pred Min                          -43.7779
trainer/QTargetWithReg Mean                 204.916
trainer/QTargetWithReg Std                   70.0788
trainer/QTargetWithReg Max                  312.062
trainer/QTargetWithReg Min                  -44.4063
trainer/PolicyLossWithoutReg Mean           205.236
trainer/PolicyLossWithoutReg Std             69.6818
trainer/PolicyLossWithoutReg Max            310.877
trainer/PolicyLossWithoutReg Min            -43.4453
trainer/gradient_norm                       334.578
trainer/gradient_penalty                     -1.67289
trainer/gradient_percentage                  -0.00815108
exploration/num steps total              531000
exploration/num paths total                1687
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81805
exploration/Rewards Std                       1.22274
exploration/Rewards Max                      10.1361
exploration/Rewards Min                      -0.533791
exploration/Returns Mean                   4818.05
exploration/Returns Std                       0
exploration/Returns Max                    4818.05
exploration/Returns Min                    4818.05
exploration/Num Paths                         1
exploration/Average Returns                4818.05
evaluation_0/num steps total                  4.13144e+06
evaluation_0/num paths total              12245
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00236
evaluation_0/Rewards Std                      1.27396
evaluation_0/Rewards Max                     10.3125
evaluation_0/Rewards Min                     -0.638559
evaluation_0/Returns Mean                  5002.36
evaluation_0/Returns Std                     32.1873
evaluation_0/Returns Max                   5055.03
evaluation_0/Returns Min                   4939.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5002.36
time/epoch (s)                                0
time/total (s)                            10415.3
Epoch                                       526
---------------------------------------  ----------------
2022-11-16 13:39:37.306930 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 527 finished
---------------------------------------  ----------------
epoch                                       527
total_step                               532000
replay_pool/size                         532000
trainer/alpha                                 0.0660182
trainer/alpha_loss                           -0.269236
trainer/entropy                              -5.90093
trainer/qf_loss                              11.51
trainer/state_noise                           0.005
trainer/policy_loss                        -199.32
trainer/policy_loss_without_entropy         201.293
trainer/entropy_penalty                      -0.389569
trainer/entropy_percentage                   -0.00193533
trainer/Q1Pred Mean                         200.215
trainer/Q1Pred Std                           71.008
trainer/Q1Pred Max                          305.445
trainer/Q1Pred Min                            2.46107
trainer/Q2Pred Mean                         200.705
trainer/Q2Pred Std                           71.0782
trainer/Q2Pred Max                          306.261
trainer/Q2Pred Min                            1.53732
trainer/QTargetWithReg Mean                 200.171
trainer/QTargetWithReg Std                   71.1041
trainer/QTargetWithReg Max                  305.723
trainer/QTargetWithReg Min                    3.02444
trainer/PolicyLossWithoutReg Mean           201.293
trainer/PolicyLossWithoutReg Std             70.1038
trainer/PolicyLossWithoutReg Max            305.582
trainer/PolicyLossWithoutReg Min              1.63553
trainer/gradient_norm                       316.705
trainer/gradient_penalty                     -1.58352
trainer/gradient_percentage                  -0.00786676
exploration/num steps total              532000
exploration/num paths total                1688
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83751
exploration/Rewards Std                       1.22657
exploration/Rewards Max                       9.89641
exploration/Rewards Min                      -0.571385
exploration/Returns Mean                   4837.51
exploration/Returns Std                       0
exploration/Returns Max                    4837.51
exploration/Returns Min                    4837.51
exploration/Num Paths                         1
exploration/Average Returns                4837.51
evaluation_0/num steps total                  4.13944e+06
evaluation_0/num paths total              12253
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04625
evaluation_0/Rewards Std                      1.24548
evaluation_0/Rewards Max                     10.2627
evaluation_0/Rewards Min                     -0.532741
evaluation_0/Returns Mean                  5046.25
evaluation_0/Returns Std                     31.7663
evaluation_0/Returns Max                   5085.63
evaluation_0/Returns Min                   4999.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5046.25
time/epoch (s)                                0
time/total (s)                            10431.1
Epoch                                       527
---------------------------------------  ----------------
2022-11-16 13:39:53.787249 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 528 finished
---------------------------------------  ----------------
epoch                                       528
total_step                               533000
replay_pool/size                         533000
trainer/alpha                                 0.0659719
trainer/alpha_loss                           -0.166615
trainer/entropy                              -5.93871
trainer/qf_loss                              10.3855
trainer/state_noise                           0.005
trainer/policy_loss                        -201.292
trainer/policy_loss_without_entropy         203.267
trainer/entropy_penalty                      -0.391788
trainer/entropy_percentage                   -0.00192745
trainer/Q1Pred Mean                         202.712
trainer/Q1Pred Std                           69.1452
trainer/Q1Pred Max                          310.446
trainer/Q1Pred Min                            0.556526
trainer/Q2Pred Mean                         202.607
trainer/Q2Pred Std                           69.3944
trainer/Q2Pred Max                          308.665
trainer/Q2Pred Min                            6.02188
trainer/QTargetWithReg Mean                 202.929
trainer/QTargetWithReg Std                   69.4347
trainer/QTargetWithReg Max                  309.865
trainer/QTargetWithReg Min                    3.00754
trainer/PolicyLossWithoutReg Mean           203.267
trainer/PolicyLossWithoutReg Std             68.7597
trainer/PolicyLossWithoutReg Max            308.671
trainer/PolicyLossWithoutReg Min              1.81358
trainer/gradient_norm                       316.733
trainer/gradient_penalty                     -1.58367
trainer/gradient_percentage                  -0.00779105
exploration/num steps total              533000
exploration/num paths total                1689
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91923
exploration/Rewards Std                       1.22926
exploration/Rewards Max                       9.86974
exploration/Rewards Min                      -0.528573
exploration/Returns Mean                   4919.23
exploration/Returns Std                       0
exploration/Returns Max                    4919.23
exploration/Returns Min                    4919.23
exploration/Num Paths                         1
exploration/Average Returns                4919.23
evaluation_0/num steps total                  4.14744e+06
evaluation_0/num paths total              12261
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90554
evaluation_0/Rewards Std                      1.24967
evaluation_0/Rewards Max                     10.0995
evaluation_0/Rewards Min                     -0.576361
evaluation_0/Returns Mean                  4905.54
evaluation_0/Returns Std                     12.625
evaluation_0/Returns Max                   4924.64
evaluation_0/Returns Min                   4882.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4905.54
time/epoch (s)                                0
time/total (s)                            10447.6
Epoch                                       528
---------------------------------------  ----------------
2022-11-16 13:40:09.675767 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 529 finished
---------------------------------------  ----------------
epoch                                       529
total_step                               534000
replay_pool/size                         534000
trainer/alpha                                 0.0659011
trainer/alpha_loss                            0.266079
trainer/entropy                              -6.09784
trainer/qf_loss                               8.58743
trainer/state_noise                           0.005
trainer/policy_loss                        -192.658
trainer/policy_loss_without_entropy         194.707
trainer/entropy_penalty                      -0.401854
trainer/entropy_percentage                   -0.00206389
trainer/Q1Pred Mean                         194.003
trainer/Q1Pred Std                           72.0302
trainer/Q1Pred Max                          306.105
trainer/Q1Pred Min                          -24.352
trainer/Q2Pred Mean                         194.582
trainer/Q2Pred Std                           71.7405
trainer/Q2Pred Max                          306.85
trainer/Q2Pred Min                          -22.7783
trainer/QTargetWithReg Mean                 194.568
trainer/QTargetWithReg Std                   71.9476
trainer/QTargetWithReg Max                  306.382
trainer/QTargetWithReg Min                  -22.1885
trainer/PolicyLossWithoutReg Mean           194.707
trainer/PolicyLossWithoutReg Std             70.9962
trainer/PolicyLossWithoutReg Max            306.012
trainer/PolicyLossWithoutReg Min            -21.7051
trainer/gradient_norm                       329.437
trainer/gradient_penalty                     -1.64718
trainer/gradient_percentage                  -0.0084598
exploration/num steps total              534000
exploration/num paths total                1690
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.57623
exploration/Rewards Std                       1.32521
exploration/Rewards Max                       9.92635
exploration/Rewards Min                      -0.67129
exploration/Returns Mean                   4576.23
exploration/Returns Std                       0
exploration/Returns Max                    4576.23
exploration/Returns Min                    4576.23
exploration/Num Paths                         1
exploration/Average Returns                4576.23
evaluation_0/num steps total                  4.15544e+06
evaluation_0/num paths total              12269
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90226
evaluation_0/Rewards Std                      1.27874
evaluation_0/Rewards Max                     10.1291
evaluation_0/Rewards Min                     -0.521472
evaluation_0/Returns Mean                  4902.26
evaluation_0/Returns Std                     36.77
evaluation_0/Returns Max                   4952.71
evaluation_0/Returns Min                   4829.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4902.26
time/epoch (s)                                0
time/total (s)                            10463.5
Epoch                                       529
---------------------------------------  ----------------
2022-11-16 13:40:25.550853 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 530 finished
---------------------------------------  ----------------
epoch                                       530
total_step                               535000
replay_pool/size                         535000
trainer/alpha                                 0.0658962
trainer/alpha_loss                           -0.219698
trainer/entropy                              -5.91922
trainer/qf_loss                              10.5742
trainer/state_noise                           0.005
trainer/policy_loss                        -191.406
trainer/policy_loss_without_entropy         193.471
trainer/entropy_penalty                      -0.390054
trainer/entropy_percentage                   -0.00201608
trainer/Q1Pred Mean                         192.828
trainer/Q1Pred Std                           80.3452
trainer/Q1Pred Max                          304.105
trainer/Q1Pred Min                          -33.3353
trainer/Q2Pred Mean                         192.684
trainer/Q2Pred Std                           80.4865
trainer/Q2Pred Max                          305.536
trainer/Q2Pred Min                          -42.7751
trainer/QTargetWithReg Mean                 192.476
trainer/QTargetWithReg Std                   81.0357
trainer/QTargetWithReg Max                  305.16
trainer/QTargetWithReg Min                  -39.0909
trainer/PolicyLossWithoutReg Mean           193.471
trainer/PolicyLossWithoutReg Std             79.046
trainer/PolicyLossWithoutReg Max            304.485
trainer/PolicyLossWithoutReg Min            -29.7122
trainer/gradient_norm                       335.078
trainer/gradient_penalty                     -1.67539
trainer/gradient_percentage                  -0.00865964
exploration/num steps total              535000
exploration/num paths total                1691
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72178
exploration/Rewards Std                       1.23568
exploration/Rewards Max                       9.80858
exploration/Rewards Min                      -0.481088
exploration/Returns Mean                   4721.78
exploration/Returns Std                       0
exploration/Returns Max                    4721.78
exploration/Returns Min                    4721.78
exploration/Num Paths                         1
exploration/Average Returns                4721.78
evaluation_0/num steps total                  4.16344e+06
evaluation_0/num paths total              12277
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71361
evaluation_0/Rewards Std                      1.29917
evaluation_0/Rewards Max                     10.1678
evaluation_0/Rewards Min                     -0.498848
evaluation_0/Returns Mean                  4713.61
evaluation_0/Returns Std                     55.3489
evaluation_0/Returns Max                   4827.94
evaluation_0/Returns Min                   4654.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4713.61
time/epoch (s)                                0
time/total (s)                            10479.4
Epoch                                       530
---------------------------------------  ----------------
2022-11-16 13:40:41.966277 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 531 finished
---------------------------------------  ----------------
epoch                                       531
total_step                               536000
replay_pool/size                         536000
trainer/alpha                                 0.0657087
trainer/alpha_loss                           -0.165165
trainer/entropy                              -5.93933
trainer/qf_loss                               7.27981
trainer/state_noise                           0.005
trainer/policy_loss                        -200.483
trainer/policy_loss_without_entropy         202.481
trainer/entropy_penalty                      -0.390266
trainer/entropy_percentage                   -0.00192742
trainer/Q1Pred Mean                         202.098
trainer/Q1Pred Std                           72.7667
trainer/Q1Pred Max                          305.312
trainer/Q1Pred Min                            6.37019
trainer/Q2Pred Mean                         202.231
trainer/Q2Pred Std                           72.5132
trainer/Q2Pred Max                          304.181
trainer/Q2Pred Min                            7.54364
trainer/QTargetWithReg Mean                 201.429
trainer/QTargetWithReg Std                   72.5795
trainer/QTargetWithReg Max                  303.323
trainer/QTargetWithReg Min                    4.27747
trainer/PolicyLossWithoutReg Mean           202.481
trainer/PolicyLossWithoutReg Std             71.7733
trainer/PolicyLossWithoutReg Max            303.692
trainer/PolicyLossWithoutReg Min              6.25248
trainer/gradient_norm                       321.562
trainer/gradient_penalty                     -1.60781
trainer/gradient_percentage                  -0.00794056
exploration/num steps total              536000
exploration/num paths total                1692
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68906
exploration/Rewards Std                       1.36371
exploration/Rewards Max                      10.2129
exploration/Rewards Min                      -0.493524
exploration/Returns Mean                   4689.06
exploration/Returns Std                       0
exploration/Returns Max                    4689.06
exploration/Returns Min                    4689.06
exploration/Num Paths                         1
exploration/Average Returns                4689.06
evaluation_0/num steps total                  4.17144e+06
evaluation_0/num paths total              12285
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9585
evaluation_0/Rewards Std                      1.27816
evaluation_0/Rewards Max                     10.2378
evaluation_0/Rewards Min                     -0.594235
evaluation_0/Returns Mean                  4958.5
evaluation_0/Returns Std                     39.4284
evaluation_0/Returns Max                   5018.05
evaluation_0/Returns Min                   4892.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4958.5
time/epoch (s)                                0
time/total (s)                            10495.8
Epoch                                       531
---------------------------------------  ----------------
2022-11-16 13:40:59.332167 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 532 finished
---------------------------------------  ----------------
epoch                                       532
total_step                               537000
replay_pool/size                         537000
trainer/alpha                                 0.0665087
trainer/alpha_loss                            0.128048
trainer/entropy                              -6.04724
trainer/qf_loss                               6.31762
trainer/state_noise                           0.005
trainer/policy_loss                        -197.442
trainer/policy_loss_without_entropy         199.523
trainer/entropy_penalty                      -0.402194
trainer/entropy_percentage                   -0.00201578
trainer/Q1Pred Mean                         199.084
trainer/Q1Pred Std                           70.1632
trainer/Q1Pred Max                          312.037
trainer/Q1Pred Min                            2.66741
trainer/Q2Pred Mean                         198.522
trainer/Q2Pred Std                           70.1493
trainer/Q2Pred Max                          309.015
trainer/Q2Pred Min                            2.84988
trainer/QTargetWithReg Mean                 198.693
trainer/QTargetWithReg Std                   70.0372
trainer/QTargetWithReg Max                  309.979
trainer/QTargetWithReg Min                    2.21223
trainer/PolicyLossWithoutReg Mean           199.523
trainer/PolicyLossWithoutReg Std             69.3562
trainer/PolicyLossWithoutReg Max            307.615
trainer/PolicyLossWithoutReg Min              3.94189
trainer/gradient_norm                       335.711
trainer/gradient_penalty                     -1.67855
trainer/gradient_percentage                  -0.00841286
exploration/num steps total              537000
exploration/num paths total                1693
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78693
exploration/Rewards Std                       1.28256
exploration/Rewards Max                      10.1349
exploration/Rewards Min                      -0.424587
exploration/Returns Mean                   4786.93
exploration/Returns Std                       0
exploration/Returns Max                    4786.93
exploration/Returns Min                    4786.93
exploration/Num Paths                         1
exploration/Average Returns                4786.93
evaluation_0/num steps total                  4.17875e+06
evaluation_0/num paths total              12294
evaluation_0/path length Mean               813
evaluation_0/path length Std                349.846
evaluation_0/path length Max               1000
evaluation_0/path length Min                157
evaluation_0/Rewards Mean                     4.53298
evaluation_0/Rewards Std                      1.47378
evaluation_0/Rewards Max                     10.3908
evaluation_0/Rewards Min                     -0.558005
evaluation_0/Returns Mean                  3685.31
evaluation_0/Returns Std                   1732.07
evaluation_0/Returns Max                   4959.3
evaluation_0/Returns Min                    461.484
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3685.31
time/epoch (s)                                0
time/total (s)                            10513.1
Epoch                                       532
---------------------------------------  ----------------
2022-11-16 13:41:15.822425 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 533 finished
---------------------------------------  ----------------
epoch                                       533
total_step                               538000
replay_pool/size                         538000
trainer/alpha                                 0.0668739
trainer/alpha_loss                           -0.420297
trainer/entropy                              -5.84462
trainer/qf_loss                               6.80747
trainer/state_noise                           0.005
trainer/policy_loss                        -205.775
trainer/policy_loss_without_entropy         207.806
trainer/entropy_penalty                      -0.390853
trainer/entropy_percentage                   -0.00188085
trainer/Q1Pred Mean                         206.205
trainer/Q1Pred Std                           70.2496
trainer/Q1Pred Max                          304.947
trainer/Q1Pred Min                          -17.6231
trainer/Q2Pred Mean                         206.859
trainer/Q2Pred Std                           70.4506
trainer/Q2Pred Max                          306.709
trainer/Q2Pred Min                          -34.5602
trainer/QTargetWithReg Mean                 206.658
trainer/QTargetWithReg Std                   70.3847
trainer/QTargetWithReg Max                  306.85
trainer/QTargetWithReg Min                  -17.3354
trainer/PolicyLossWithoutReg Mean           207.806
trainer/PolicyLossWithoutReg Std             68.6348
trainer/PolicyLossWithoutReg Max            306.021
trainer/PolicyLossWithoutReg Min             -3.69081
trainer/gradient_norm                       328.136
trainer/gradient_penalty                     -1.64068
trainer/gradient_percentage                  -0.00789524
exploration/num steps total              538000
exploration/num paths total                1694
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.51902
exploration/Rewards Std                       1.39634
exploration/Rewards Max                      10.1705
exploration/Rewards Min                      -0.475157
exploration/Returns Mean                   4519.02
exploration/Returns Std                       0
exploration/Returns Max                    4519.02
exploration/Returns Min                    4519.02
exploration/Num Paths                         1
exploration/Average Returns                4519.02
evaluation_0/num steps total                  4.18675e+06
evaluation_0/num paths total              12302
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.32528
evaluation_0/Rewards Std                      1.20805
evaluation_0/Rewards Max                      9.55984
evaluation_0/Rewards Min                     -0.586304
evaluation_0/Returns Mean                  4325.28
evaluation_0/Returns Std                     45.9458
evaluation_0/Returns Max                   4410.38
evaluation_0/Returns Min                   4271.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4325.28
time/epoch (s)                                0
time/total (s)                            10529.6
Epoch                                       533
---------------------------------------  ----------------
2022-11-16 13:41:33.242589 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 534 finished
---------------------------------------  ----------------
epoch                                       534
total_step                               539000
replay_pool/size                         539000
trainer/alpha                                 0.0685374
trainer/alpha_loss                           -1.11307
trainer/entropy                              -5.58474
trainer/qf_loss                               7.26651
trainer/state_noise                           0.005
trainer/policy_loss                        -210.214
trainer/policy_loss_without_entropy         212.237
trainer/entropy_penalty                      -0.382764
trainer/entropy_percentage                   -0.00180347
trainer/Q1Pred Mean                         211.365
trainer/Q1Pred Std                           73.8609
trainer/Q1Pred Max                          306.686
trainer/Q1Pred Min                            1.93573
trainer/Q2Pred Mean                         211.405
trainer/Q2Pred Std                           73.9081
trainer/Q2Pred Max                          308.204
trainer/Q2Pred Min                           -0.660857
trainer/QTargetWithReg Mean                 211.42
trainer/QTargetWithReg Std                   73.6051
trainer/QTargetWithReg Max                  308.302
trainer/QTargetWithReg Min                   -0.428324
trainer/PolicyLossWithoutReg Mean           212.237
trainer/PolicyLossWithoutReg Std             72.8486
trainer/PolicyLossWithoutReg Max            306.232
trainer/PolicyLossWithoutReg Min             -0.911691
trainer/gradient_norm                       328.181
trainer/gradient_penalty                     -1.6409
trainer/gradient_percentage                  -0.00773146
exploration/num steps total              539000
exploration/num paths total                1695
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73586
exploration/Rewards Std                       1.27127
exploration/Rewards Max                       9.86288
exploration/Rewards Min                      -0.489637
exploration/Returns Mean                   4735.86
exploration/Returns Std                       0
exploration/Returns Max                    4735.86
exploration/Returns Min                    4735.86
exploration/Num Paths                         1
exploration/Average Returns                4735.86
evaluation_0/num steps total                  4.19433e+06
evaluation_0/num paths total              12312
evaluation_0/path length Mean               758.1
evaluation_0/path length Std                369.539
evaluation_0/path length Max               1000
evaluation_0/path length Min                182
evaluation_0/Rewards Mean                     4.38779
evaluation_0/Rewards Std                      1.411
evaluation_0/Rewards Max                     10.1356
evaluation_0/Rewards Min                     -0.669101
evaluation_0/Returns Mean                  3326.38
evaluation_0/Returns Std                   1815.92
evaluation_0/Returns Max                   4587.78
evaluation_0/Returns Min                    524.896
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3326.38
time/epoch (s)                                0
time/total (s)                            10547
Epoch                                       534
---------------------------------------  ----------------
2022-11-16 13:41:49.755385 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 535 finished
---------------------------------------  ----------------
epoch                                       535
total_step                               540000
replay_pool/size                         540000
trainer/alpha                                 0.0673507
trainer/alpha_loss                           -0.763147
trainer/entropy                              -5.71712
trainer/qf_loss                              10.257
trainer/state_noise                           0.005
trainer/policy_loss                        -201.174
trainer/policy_loss_without_entropy         203.248
trainer/entropy_penalty                      -0.385052
trainer/entropy_percentage                   -0.00189449
trainer/Q1Pred Mean                         202.137
trainer/Q1Pred Std                           73.8451
trainer/Q1Pred Max                          312.313
trainer/Q1Pred Min                          -24.0251
trainer/Q2Pred Mean                         201.814
trainer/Q2Pred Std                           73.5737
trainer/Q2Pred Max                          311.565
trainer/Q2Pred Min                          -13.7826
trainer/QTargetWithReg Mean                 202.044
trainer/QTargetWithReg Std                   73.2009
trainer/QTargetWithReg Max                  309.281
trainer/QTargetWithReg Min                  -13.1753
trainer/PolicyLossWithoutReg Mean           203.248
trainer/PolicyLossWithoutReg Std             72.694
trainer/PolicyLossWithoutReg Max            312.361
trainer/PolicyLossWithoutReg Min            -17.71
trainer/gradient_norm                       337.835
trainer/gradient_penalty                     -1.68918
trainer/gradient_percentage                  -0.0083109
exploration/num steps total              540000
exploration/num paths total                1696
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73177
exploration/Rewards Std                       1.25243
exploration/Rewards Max                      10.141
exploration/Rewards Min                      -0.775714
exploration/Returns Mean                   4731.77
exploration/Returns Std                       0
exploration/Returns Max                    4731.77
exploration/Returns Min                    4731.77
exploration/Num Paths                         1
exploration/Average Returns                4731.77
evaluation_0/num steps total                  4.20233e+06
evaluation_0/num paths total              12320
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8577
evaluation_0/Rewards Std                      1.24513
evaluation_0/Rewards Max                     10.0382
evaluation_0/Rewards Min                     -0.678217
evaluation_0/Returns Mean                  4857.7
evaluation_0/Returns Std                     26.1198
evaluation_0/Returns Max                   4894.79
evaluation_0/Returns Min                   4812.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4857.7
time/epoch (s)                                0
time/total (s)                            10563.6
Epoch                                       535
---------------------------------------  ----------------
2022-11-16 13:42:05.535431 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 536 finished
---------------------------------------  ----------------
epoch                                       536
total_step                               541000
replay_pool/size                         541000
trainer/alpha                                 0.0685966
trainer/alpha_loss                           -0.178217
trainer/entropy                              -5.93349
trainer/qf_loss                               6.96556
trainer/state_noise                           0.005
trainer/policy_loss                        -202.593
trainer/policy_loss_without_entropy         204.619
trainer/entropy_penalty                      -0.407017
trainer/entropy_percentage                   -0.00198915
trainer/Q1Pred Mean                         204.054
trainer/Q1Pred Std                           73.921
trainer/Q1Pred Max                          306.784
trainer/Q1Pred Min                          -10.8497
trainer/Q2Pred Mean                         203.783
trainer/Q2Pred Std                           73.8841
trainer/Q2Pred Max                          305.328
trainer/Q2Pred Min                           -4.69614
trainer/QTargetWithReg Mean                 204.07
trainer/QTargetWithReg Std                   73.5634
trainer/QTargetWithReg Max                  307.655
trainer/QTargetWithReg Min                   -2.70153
trainer/PolicyLossWithoutReg Mean           204.619
trainer/PolicyLossWithoutReg Std             73.1591
trainer/PolicyLossWithoutReg Max            306.261
trainer/PolicyLossWithoutReg Min             -5.79085
trainer/gradient_norm                       323.651
trainer/gradient_penalty                     -1.61825
trainer/gradient_percentage                  -0.00790863
exploration/num steps total              541000
exploration/num paths total                1697
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81565
exploration/Rewards Std                       1.22301
exploration/Rewards Max                       9.83717
exploration/Rewards Min                      -0.675344
exploration/Returns Mean                   4815.65
exploration/Returns Std                       0
exploration/Returns Max                    4815.65
exploration/Returns Min                    4815.65
exploration/Num Paths                         1
exploration/Average Returns                4815.65
evaluation_0/num steps total                  4.21033e+06
evaluation_0/num paths total              12328
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88674
evaluation_0/Rewards Std                      1.36226
evaluation_0/Rewards Max                     10.4381
evaluation_0/Rewards Min                     -0.815789
evaluation_0/Returns Mean                  4886.74
evaluation_0/Returns Std                     47.6485
evaluation_0/Returns Max                   4989.28
evaluation_0/Returns Min                   4835.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4886.74
time/epoch (s)                                0
time/total (s)                            10579.3
Epoch                                       536
---------------------------------------  ----------------
2022-11-16 13:42:21.985035 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 537 finished
---------------------------------------  ----------------
epoch                                       537
total_step                               542000
replay_pool/size                         542000
trainer/alpha                                 0.0664881
trainer/alpha_loss                           -1.15004
trainer/entropy                              -5.57572
trainer/qf_loss                               7.35279
trainer/state_noise                           0.005
trainer/policy_loss                        -196.385
trainer/policy_loss_without_entropy         198.404
trainer/entropy_penalty                      -0.370719
trainer/entropy_percentage                   -0.00186851
trainer/Q1Pred Mean                         197.66
trainer/Q1Pred Std                           71.9609
trainer/Q1Pred Max                          306.697
trainer/Q1Pred Min                          -32.2426
trainer/Q2Pred Mean                         198.177
trainer/Q2Pred Std                           72.1066
trainer/Q2Pred Max                          304.943
trainer/Q2Pred Min                          -26.1472
trainer/QTargetWithReg Mean                 198.15
trainer/QTargetWithReg Std                   71.7799
trainer/QTargetWithReg Max                  306.433
trainer/QTargetWithReg Min                  -31.0556
trainer/PolicyLossWithoutReg Mean           198.404
trainer/PolicyLossWithoutReg Std             71.2426
trainer/PolicyLossWithoutReg Max            303.664
trainer/PolicyLossWithoutReg Min            -25.4087
trainer/gradient_norm                       329.561
trainer/gradient_penalty                     -1.64781
trainer/gradient_percentage                  -0.00830532
exploration/num steps total              542000
exploration/num paths total                1698
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91487
exploration/Rewards Std                       1.29798
exploration/Rewards Max                       9.93756
exploration/Rewards Min                      -0.750722
exploration/Returns Mean                   4914.87
exploration/Returns Std                       0
exploration/Returns Max                    4914.87
exploration/Returns Min                    4914.87
exploration/Num Paths                         1
exploration/Average Returns                4914.87
evaluation_0/num steps total                  4.21833e+06
evaluation_0/num paths total              12336
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93422
evaluation_0/Rewards Std                      1.28553
evaluation_0/Rewards Max                     10.2617
evaluation_0/Rewards Min                     -0.683855
evaluation_0/Returns Mean                  4934.22
evaluation_0/Returns Std                     53.6546
evaluation_0/Returns Max                   5018.41
evaluation_0/Returns Min                   4841.61
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4934.22
time/epoch (s)                                0
time/total (s)                            10595.8
Epoch                                       537
---------------------------------------  ----------------
2022-11-16 13:42:37.860322 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 538 finished
---------------------------------------  ----------------
epoch                                       538
total_step                               543000
replay_pool/size                         543000
trainer/alpha                                 0.0666984
trainer/alpha_loss                            1.60991
trainer/entropy                              -6.59456
trainer/qf_loss                              11.2588
trainer/state_noise                           0.005
trainer/policy_loss                        -193.859
trainer/policy_loss_without_entropy         195.991
trainer/entropy_penalty                      -0.439846
trainer/entropy_percentage                   -0.00224421
trainer/Q1Pred Mean                         195.027
trainer/Q1Pred Std                           79.0164
trainer/Q1Pred Max                          314.711
trainer/Q1Pred Min                          -13.3932
trainer/Q2Pred Mean                         194.39
trainer/Q2Pred Std                           78.8904
trainer/Q2Pred Max                          312.328
trainer/Q2Pred Min                           -8.03549
trainer/QTargetWithReg Mean                 195.018
trainer/QTargetWithReg Std                   79.2695
trainer/QTargetWithReg Max                  315.59
trainer/QTargetWithReg Min                  -25.3859
trainer/PolicyLossWithoutReg Mean           195.991
trainer/PolicyLossWithoutReg Std             76.8075
trainer/PolicyLossWithoutReg Max            311.38
trainer/PolicyLossWithoutReg Min            -16.039
trainer/gradient_norm                       338.412
trainer/gradient_penalty                     -1.69206
trainer/gradient_percentage                  -0.00863334
exploration/num steps total              543000
exploration/num paths total                1699
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88731
exploration/Rewards Std                       1.19802
exploration/Rewards Max                       9.87419
exploration/Rewards Min                      -0.60872
exploration/Returns Mean                   4887.31
exploration/Returns Std                       0
exploration/Returns Max                    4887.31
exploration/Returns Min                    4887.31
exploration/Num Paths                         1
exploration/Average Returns                4887.31
evaluation_0/num steps total                  4.22633e+06
evaluation_0/num paths total              12344
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95548
evaluation_0/Rewards Std                      1.23951
evaluation_0/Rewards Max                      9.99215
evaluation_0/Rewards Min                     -0.587184
evaluation_0/Returns Mean                  4955.48
evaluation_0/Returns Std                     40.6169
evaluation_0/Returns Max                   5015.89
evaluation_0/Returns Min                   4902.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4955.48
time/epoch (s)                                0
time/total (s)                            10611.7
Epoch                                       538
---------------------------------------  ----------------
2022-11-16 13:42:53.792224 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 539 finished
---------------------------------------  ----------------
epoch                                       539
total_step                               544000
replay_pool/size                         544000
trainer/alpha                                 0.0677588
trainer/alpha_loss                           -0.675445
trainer/entropy                              -5.74906
trainer/qf_loss                               6.15802
trainer/state_noise                           0.005
trainer/policy_loss                        -206.033
trainer/policy_loss_without_entropy         208.051
trainer/entropy_penalty                      -0.38955
trainer/entropy_percentage                   -0.00187238
trainer/Q1Pred Mean                         207.542
trainer/Q1Pred Std                           67.0432
trainer/Q1Pred Max                          312.757
trainer/Q1Pred Min                            7.83067
trainer/Q2Pred Mean                         207.703
trainer/Q2Pred Std                           67.1408
trainer/Q2Pred Max                          312.363
trainer/Q2Pred Min                            7.67007
trainer/QTargetWithReg Mean                 207.848
trainer/QTargetWithReg Std                   67.1097
trainer/QTargetWithReg Max                  313.041
trainer/QTargetWithReg Min                    6.0938
trainer/PolicyLossWithoutReg Mean           208.051
trainer/PolicyLossWithoutReg Std             66.3145
trainer/PolicyLossWithoutReg Max            312.175
trainer/PolicyLossWithoutReg Min              6.17768
trainer/gradient_norm                       325.786
trainer/gradient_penalty                     -1.62893
trainer/gradient_percentage                  -0.00782947
exploration/num steps total              544000
exploration/num paths total                1700
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90918
exploration/Rewards Std                       1.24168
exploration/Rewards Max                       9.94761
exploration/Rewards Min                      -0.614484
exploration/Returns Mean                   4909.18
exploration/Returns Std                       0
exploration/Returns Max                    4909.18
exploration/Returns Min                    4909.18
exploration/Num Paths                         1
exploration/Average Returns                4909.18
evaluation_0/num steps total                  4.23433e+06
evaluation_0/num paths total              12352
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04547
evaluation_0/Rewards Std                      1.20716
evaluation_0/Rewards Max                      9.86687
evaluation_0/Rewards Min                     -0.511174
evaluation_0/Returns Mean                  5045.47
evaluation_0/Returns Std                     10.9815
evaluation_0/Returns Max                   5062.67
evaluation_0/Returns Min                   5031.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5045.47
time/epoch (s)                                0
time/total (s)                            10627.6
Epoch                                       539
---------------------------------------  ----------------
2022-11-16 13:43:10.079771 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 540 finished
---------------------------------------  ----------------
epoch                                       540
total_step                               545000
replay_pool/size                         545000
trainer/alpha                                 0.0664074
trainer/alpha_loss                            0.637044
trainer/entropy                              -6.2349
trainer/qf_loss                               6.96388
trainer/state_noise                           0.005
trainer/policy_loss                        -211.039
trainer/policy_loss_without_entropy         213.106
trainer/entropy_penalty                      -0.414044
trainer/entropy_percentage                   -0.0019429
trainer/Q1Pred Mean                         212.373
trainer/Q1Pred Std                           67.6978
trainer/Q1Pred Max                          305.323
trainer/Q1Pred Min                          -23.1449
trainer/Q2Pred Mean                         212.291
trainer/Q2Pred Std                           67.6724
trainer/Q2Pred Max                          305.632
trainer/Q2Pred Min                          -26.4462
trainer/QTargetWithReg Mean                 213.075
trainer/QTargetWithReg Std                   67.7415
trainer/QTargetWithReg Max                  306.255
trainer/QTargetWithReg Min                  -24.6336
trainer/PolicyLossWithoutReg Mean           213.106
trainer/PolicyLossWithoutReg Std             66.9477
trainer/PolicyLossWithoutReg Max            303.998
trainer/PolicyLossWithoutReg Min            -17.3054
trainer/gradient_norm                       330.62
trainer/gradient_penalty                     -1.6531
trainer/gradient_percentage                  -0.00775719
exploration/num steps total              545000
exploration/num paths total                1701
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91733
exploration/Rewards Std                       1.22171
exploration/Rewards Max                       9.70557
exploration/Rewards Min                      -0.553437
exploration/Returns Mean                   4917.33
exploration/Returns Std                       0
exploration/Returns Max                    4917.33
exploration/Returns Min                    4917.33
exploration/Num Paths                         1
exploration/Average Returns                4917.33
evaluation_0/num steps total                  4.24233e+06
evaluation_0/num paths total              12360
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91236
evaluation_0/Rewards Std                      1.19283
evaluation_0/Rewards Max                      9.85092
evaluation_0/Rewards Min                     -0.610532
evaluation_0/Returns Mean                  4912.36
evaluation_0/Returns Std                     26.6647
evaluation_0/Returns Max                   4942.06
evaluation_0/Returns Min                   4856.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4912.36
time/epoch (s)                                0
time/total (s)                            10643.9
Epoch                                       540
---------------------------------------  ----------------
2022-11-16 13:43:25.860254 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 541 finished
---------------------------------------  ----------------
epoch                                       541
total_step                               546000
replay_pool/size                         546000
trainer/alpha                                 0.0648167
trainer/alpha_loss                           -0.663205
trainer/entropy                              -5.7576
trainer/qf_loss                               8.3882
trainer/state_noise                           0.005
trainer/policy_loss                        -199.856
trainer/policy_loss_without_entropy         201.891
trainer/entropy_penalty                      -0.373189
trainer/entropy_percentage                   -0.00184846
trainer/Q1Pred Mean                         200.776
trainer/Q1Pred Std                           78.7497
trainer/Q1Pred Max                          311.343
trainer/Q1Pred Min                            2.59263
trainer/Q2Pred Mean                         200.983
trainer/Q2Pred Std                           79.1111
trainer/Q2Pred Max                          311.935
trainer/Q2Pred Min                            2.1642
trainer/QTargetWithReg Mean                 200.271
trainer/QTargetWithReg Std                   78.8366
trainer/QTargetWithReg Max                  312.11
trainer/QTargetWithReg Min                    0.477739
trainer/PolicyLossWithoutReg Mean           201.891
trainer/PolicyLossWithoutReg Std             78.0587
trainer/PolicyLossWithoutReg Max            311.792
trainer/PolicyLossWithoutReg Min              0.956528
trainer/gradient_norm                       332.516
trainer/gradient_penalty                     -1.66258
trainer/gradient_percentage                  -0.00823502
exploration/num steps total              546000
exploration/num paths total                1702
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94451
exploration/Rewards Std                       1.20175
exploration/Rewards Max                      10.102
exploration/Rewards Min                      -0.703707
exploration/Returns Mean                   4944.51
exploration/Returns Std                       0
exploration/Returns Max                    4944.51
exploration/Returns Min                    4944.51
exploration/Num Paths                         1
exploration/Average Returns                4944.51
evaluation_0/num steps total                  4.25033e+06
evaluation_0/num paths total              12368
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05382
evaluation_0/Rewards Std                      1.24569
evaluation_0/Rewards Max                     10.1408
evaluation_0/Rewards Min                     -0.592199
evaluation_0/Returns Mean                  5053.82
evaluation_0/Returns Std                     21.2502
evaluation_0/Returns Max                   5091.92
evaluation_0/Returns Min                   5023.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5053.82
time/epoch (s)                                0
time/total (s)                            10659.7
Epoch                                       541
---------------------------------------  ----------------
2022-11-16 13:43:42.384794 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 542 finished
---------------------------------------  ----------------
epoch                                       542
total_step                               547000
replay_pool/size                         547000
trainer/alpha                                 0.0650412
trainer/alpha_loss                           -0.781726
trainer/entropy                              -5.71394
trainer/qf_loss                               6.37352
trainer/state_noise                           0.005
trainer/policy_loss                        -202.434
trainer/policy_loss_without_entropy         204.478
trainer/entropy_penalty                      -0.371642
trainer/entropy_percentage                   -0.00181751
trainer/Q1Pred Mean                         203.803
trainer/Q1Pred Std                           76.2751
trainer/Q1Pred Max                          310.912
trainer/Q1Pred Min                          -17.5264
trainer/Q2Pred Mean                         203.995
trainer/Q2Pred Std                           76.0456
trainer/Q2Pred Max                          309.881
trainer/Q2Pred Min                          -23.4827
trainer/QTargetWithReg Mean                 203.266
trainer/QTargetWithReg Std                   76.3141
trainer/QTargetWithReg Max                  310.41
trainer/QTargetWithReg Min                  -26.6987
trainer/PolicyLossWithoutReg Mean           204.478
trainer/PolicyLossWithoutReg Std             74.7127
trainer/PolicyLossWithoutReg Max            309.353
trainer/PolicyLossWithoutReg Min            -21.4614
trainer/gradient_norm                       334.46
trainer/gradient_penalty                     -1.6723
trainer/gradient_percentage                  -0.00817837
exploration/num steps total              547000
exploration/num paths total                1703
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95101
exploration/Rewards Std                       1.23295
exploration/Rewards Max                       9.81254
exploration/Rewards Min                      -0.7382
exploration/Returns Mean                   4951.01
exploration/Returns Std                       0
exploration/Returns Max                    4951.01
exploration/Returns Min                    4951.01
exploration/Num Paths                         1
exploration/Average Returns                4951.01
evaluation_0/num steps total                  4.25833e+06
evaluation_0/num paths total              12376
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99378
evaluation_0/Rewards Std                      1.21398
evaluation_0/Rewards Max                      9.87164
evaluation_0/Rewards Min                     -0.628377
evaluation_0/Returns Mean                  4993.78
evaluation_0/Returns Std                     12.7781
evaluation_0/Returns Max                   5009.13
evaluation_0/Returns Min                   4973.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4993.78
time/epoch (s)                                0
time/total (s)                            10676.2
Epoch                                       542
---------------------------------------  ----------------
2022-11-16 13:43:58.131585 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 543 finished
---------------------------------------  ----------------
epoch                                       543
total_step                               548000
replay_pool/size                         548000
trainer/alpha                                 0.0652324
trainer/alpha_loss                           -0.176989
trainer/entropy                              -5.93516
trainer/qf_loss                               8.25601
trainer/state_noise                           0.005
trainer/policy_loss                        -195.279
trainer/policy_loss_without_entropy         197.319
trainer/entropy_penalty                      -0.387165
trainer/entropy_percentage                   -0.00196213
trainer/Q1Pred Mean                         196.241
trainer/Q1Pred Std                           75.474
trainer/Q1Pred Max                          309.925
trainer/Q1Pred Min                           -4.90398
trainer/Q2Pred Mean                         196.032
trainer/Q2Pred Std                           74.9381
trainer/Q2Pred Max                          307.944
trainer/Q2Pred Min                           -6.44025
trainer/QTargetWithReg Mean                 196.315
trainer/QTargetWithReg Std                   75.4946
trainer/QTargetWithReg Max                  311.47
trainer/QTargetWithReg Min                   -4.9496
trainer/PolicyLossWithoutReg Mean           197.319
trainer/PolicyLossWithoutReg Std             74.7612
trainer/PolicyLossWithoutReg Max            308.835
trainer/PolicyLossWithoutReg Min             -0.822177
trainer/gradient_norm                       330.649
trainer/gradient_penalty                     -1.65324
trainer/gradient_percentage                  -0.00837853
exploration/num steps total              548000
exploration/num paths total                1704
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87153
exploration/Rewards Std                       1.22153
exploration/Rewards Max                       9.97432
exploration/Rewards Min                      -0.405597
exploration/Returns Mean                   4871.53
exploration/Returns Std                       0
exploration/Returns Max                    4871.53
exploration/Returns Min                    4871.53
exploration/Num Paths                         1
exploration/Average Returns                4871.53
evaluation_0/num steps total                  4.26633e+06
evaluation_0/num paths total              12384
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92923
evaluation_0/Rewards Std                      1.21904
evaluation_0/Rewards Max                      9.87428
evaluation_0/Rewards Min                     -0.541099
evaluation_0/Returns Mean                  4929.23
evaluation_0/Returns Std                     11.5376
evaluation_0/Returns Max                   4944.54
evaluation_0/Returns Min                   4905.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4929.23
time/epoch (s)                                0
time/total (s)                            10691.9
Epoch                                       543
---------------------------------------  ----------------
2022-11-16 13:44:14.546043 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 544 finished
---------------------------------------  ----------------
epoch                                       544
total_step                               549000
replay_pool/size                         549000
trainer/alpha                                 0.0673093
trainer/alpha_loss                            0.0563482
trainer/entropy                              -6.02088
trainer/qf_loss                               8.25453
trainer/state_noise                           0.005
trainer/policy_loss                        -206.867
trainer/policy_loss_without_entropy         208.935
trainer/entropy_penalty                      -0.405261
trainer/entropy_percentage                   -0.00193966
trainer/Q1Pred Mean                         208.26
trainer/Q1Pred Std                           71.5949
trainer/Q1Pred Max                          310.886
trainer/Q1Pred Min                            5.45393
trainer/Q2Pred Mean                         208.142
trainer/Q2Pred Std                           71.6287
trainer/Q2Pred Max                          311.288
trainer/Q2Pred Min                            6.90423
trainer/QTargetWithReg Mean                 208.566
trainer/QTargetWithReg Std                   71.4161
trainer/QTargetWithReg Max                  311.722
trainer/QTargetWithReg Min                    6.39599
trainer/PolicyLossWithoutReg Mean           208.935
trainer/PolicyLossWithoutReg Std             70.7687
trainer/PolicyLossWithoutReg Max            310.897
trainer/PolicyLossWithoutReg Min              5.8692
trainer/gradient_norm                       332.545
trainer/gradient_penalty                     -1.66273
trainer/gradient_percentage                  -0.00795811
exploration/num steps total              549000
exploration/num paths total                1705
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8605
exploration/Rewards Std                       1.22057
exploration/Rewards Max                       9.76818
exploration/Rewards Min                      -0.615872
exploration/Returns Mean                   4860.5
exploration/Returns Std                       0
exploration/Returns Max                    4860.5
exploration/Returns Min                    4860.5
exploration/Num Paths                         1
exploration/Average Returns                4860.5
evaluation_0/num steps total                  4.27433e+06
evaluation_0/num paths total              12392
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89192
evaluation_0/Rewards Std                      1.17645
evaluation_0/Rewards Max                      9.78054
evaluation_0/Rewards Min                     -0.695763
evaluation_0/Returns Mean                  4891.92
evaluation_0/Returns Std                     29.1115
evaluation_0/Returns Max                   4940.85
evaluation_0/Returns Min                   4847.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4891.92
time/epoch (s)                                0
time/total (s)                            10708.3
Epoch                                       544
---------------------------------------  ----------------
2022-11-16 13:44:30.364206 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 545 finished
---------------------------------------  ----------------
epoch                                       545
total_step                               550000
replay_pool/size                         550000
trainer/alpha                                 0.0665317
trainer/alpha_loss                           -0.729522
trainer/entropy                              -5.73081
trainer/qf_loss                               5.48786
trainer/state_noise                           0.005
trainer/policy_loss                        -215.864
trainer/policy_loss_without_entropy         217.877
trainer/entropy_penalty                      -0.38128
trainer/entropy_percentage                   -0.00174998
trainer/Q1Pred Mean                         217.381
trainer/Q1Pred Std                           69.7267
trainer/Q1Pred Max                          310.176
trainer/Q1Pred Min                            8.76423
trainer/Q2Pred Mean                         217.437
trainer/Q2Pred Std                           69.541
trainer/Q2Pred Max                          310.337
trainer/Q2Pred Min                           10.4523
trainer/QTargetWithReg Mean                 217.082
trainer/QTargetWithReg Std                   69.2517
trainer/QTargetWithReg Max                  310.86
trainer/QTargetWithReg Min                    8.33561
trainer/PolicyLossWithoutReg Mean           217.877
trainer/PolicyLossWithoutReg Std             68.6666
trainer/PolicyLossWithoutReg Max            309.422
trainer/PolicyLossWithoutReg Min              9.39698
trainer/gradient_norm                       326.177
trainer/gradient_penalty                     -1.63088
trainer/gradient_percentage                  -0.00748535
exploration/num steps total              550000
exploration/num paths total                1706
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94866
exploration/Rewards Std                       1.21854
exploration/Rewards Max                       9.99787
exploration/Rewards Min                      -0.751423
exploration/Returns Mean                   4948.66
exploration/Returns Std                       0
exploration/Returns Max                    4948.66
exploration/Returns Min                    4948.66
exploration/Num Paths                         1
exploration/Average Returns                4948.66
evaluation_0/num steps total                  4.28233e+06
evaluation_0/num paths total              12400
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01191
evaluation_0/Rewards Std                      1.20303
evaluation_0/Rewards Max                      9.94532
evaluation_0/Rewards Min                     -0.663162
evaluation_0/Returns Mean                  5011.91
evaluation_0/Returns Std                     11.7007
evaluation_0/Returns Max                   5026.72
evaluation_0/Returns Min                   4994.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5011.91
time/epoch (s)                                0
time/total (s)                            10724.2
Epoch                                       545
---------------------------------------  ----------------
2022-11-16 13:44:46.503052 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 546 finished
---------------------------------------  ----------------
epoch                                       546
total_step                               551000
replay_pool/size                         551000
trainer/alpha                                 0.067711
trainer/alpha_loss                           -0.0210059
trainer/entropy                              -5.9922
trainer/qf_loss                               6.90869
trainer/state_noise                           0.005
trainer/policy_loss                        -207.595
trainer/policy_loss_without_entropy         209.66
trainer/entropy_penalty                      -0.405737
trainer/entropy_percentage                   -0.00193521
trainer/Q1Pred Mean                         209.211
trainer/Q1Pred Std                           65.0096
trainer/Q1Pred Max                          311.49
trainer/Q1Pred Min                           37.4262
trainer/Q2Pred Mean                         209.216
trainer/Q2Pred Std                           65.3197
trainer/Q2Pred Max                          312.301
trainer/Q2Pred Min                           36.3082
trainer/QTargetWithReg Mean                 208.628
trainer/QTargetWithReg Std                   65.5258
trainer/QTargetWithReg Max                  311.791
trainer/QTargetWithReg Min                   26.3976
trainer/PolicyLossWithoutReg Mean           209.66
trainer/PolicyLossWithoutReg Std             64.3017
trainer/PolicyLossWithoutReg Max            310.393
trainer/PolicyLossWithoutReg Min             41.8129
trainer/gradient_norm                       331.8
trainer/gradient_penalty                     -1.659
trainer/gradient_percentage                  -0.00791281
exploration/num steps total              551000
exploration/num paths total                1707
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9773
exploration/Rewards Std                       1.24108
exploration/Rewards Max                      10.2165
exploration/Rewards Min                      -0.603156
exploration/Returns Mean                   4977.3
exploration/Returns Std                       0
exploration/Returns Max                    4977.3
exploration/Returns Min                    4977.3
exploration/Num Paths                         1
exploration/Average Returns                4977.3
evaluation_0/num steps total                  4.29033e+06
evaluation_0/num paths total              12408
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96289
evaluation_0/Rewards Std                      1.24042
evaluation_0/Rewards Max                     10.0165
evaluation_0/Rewards Min                     -0.721713
evaluation_0/Returns Mean                  4962.89
evaluation_0/Returns Std                     90.0765
evaluation_0/Returns Max                   5068.27
evaluation_0/Returns Min                   4751.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4962.89
time/epoch (s)                                0
time/total (s)                            10740.3
Epoch                                       546
---------------------------------------  ----------------
2022-11-16 13:45:02.655074 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 547 finished
---------------------------------------  ----------------
epoch                                       547
total_step                               552000
replay_pool/size                         552000
trainer/alpha                                 0.0666969
trainer/alpha_loss                            0.255635
trainer/entropy                              -6.09441
trainer/qf_loss                              10.8009
trainer/state_noise                           0.005
trainer/policy_loss                        -200.901
trainer/policy_loss_without_entropy         202.983
trainer/entropy_penalty                      -0.406478
trainer/entropy_percentage                   -0.00200252
trainer/Q1Pred Mean                         201.876
trainer/Q1Pred Std                           75.1149
trainer/Q1Pred Max                          310.423
trainer/Q1Pred Min                           13.2457
trainer/Q2Pred Mean                         201.77
trainer/Q2Pred Std                           74.9656
trainer/Q2Pred Max                          310.903
trainer/Q2Pred Min                           10.9979
trainer/QTargetWithReg Mean                 202.273
trainer/QTargetWithReg Std                   74.8359
trainer/QTargetWithReg Max                  310.515
trainer/QTargetWithReg Min                   14.8164
trainer/PolicyLossWithoutReg Mean           202.983
trainer/PolicyLossWithoutReg Std             74.2086
trainer/PolicyLossWithoutReg Max            310.071
trainer/PolicyLossWithoutReg Min             10.8997
trainer/gradient_norm                       335.124
trainer/gradient_penalty                     -1.67562
trainer/gradient_percentage                  -0.00825498
exploration/num steps total              552000
exploration/num paths total                1708
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72959
exploration/Rewards Std                       1.26704
exploration/Rewards Max                       9.69242
exploration/Rewards Min                      -0.664897
exploration/Returns Mean                   4729.59
exploration/Returns Std                       0
exploration/Returns Max                    4729.59
exploration/Returns Min                    4729.59
exploration/Num Paths                         1
exploration/Average Returns                4729.59
evaluation_0/num steps total                  4.29833e+06
evaluation_0/num paths total              12416
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94797
evaluation_0/Rewards Std                      1.18679
evaluation_0/Rewards Max                      9.76027
evaluation_0/Rewards Min                     -0.534885
evaluation_0/Returns Mean                  4947.97
evaluation_0/Returns Std                     12.7375
evaluation_0/Returns Max                   4965.74
evaluation_0/Returns Min                   4924.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4947.97
time/epoch (s)                                0
time/total (s)                            10756.5
Epoch                                       547
---------------------------------------  ----------------
2022-11-16 13:45:18.480736 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 548 finished
---------------------------------------  ----------------
epoch                                       548
total_step                               553000
replay_pool/size                         553000
trainer/alpha                                 0.0671687
trainer/alpha_loss                            0.483745
trainer/entropy                              -6.17913
trainer/qf_loss                              10.9594
trainer/state_noise                           0.005
trainer/policy_loss                        -203.745
trainer/policy_loss_without_entropy         205.815
trainer/entropy_penalty                      -0.415044
trainer/entropy_percentage                   -0.00201659
trainer/Q1Pred Mean                         204.759
trainer/Q1Pred Std                           72.8897
trainer/Q1Pred Max                          310.927
trainer/Q1Pred Min                           -2.06146
trainer/Q2Pred Mean                         204.83
trainer/Q2Pred Std                           73.0014
trainer/Q2Pred Max                          311.118
trainer/Q2Pred Min                           -3.01661
trainer/QTargetWithReg Mean                 205.189
trainer/QTargetWithReg Std                   73.2007
trainer/QTargetWithReg Max                  311.848
trainer/QTargetWithReg Min                   -6.38954
trainer/PolicyLossWithoutReg Mean           205.815
trainer/PolicyLossWithoutReg Std             71.9996
trainer/PolicyLossWithoutReg Max            311.4
trainer/PolicyLossWithoutReg Min             -3.47682
trainer/gradient_norm                       330.869
trainer/gradient_penalty                     -1.65435
trainer/gradient_percentage                  -0.00803804
exploration/num steps total              553000
exploration/num paths total                1709
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88951
exploration/Rewards Std                       1.23842
exploration/Rewards Max                      10.0172
exploration/Rewards Min                      -0.457587
exploration/Returns Mean                   4889.51
exploration/Returns Std                       0
exploration/Returns Max                    4889.51
exploration/Returns Min                    4889.51
exploration/Num Paths                         1
exploration/Average Returns                4889.51
evaluation_0/num steps total                  4.30633e+06
evaluation_0/num paths total              12424
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92549
evaluation_0/Rewards Std                      1.17955
evaluation_0/Rewards Max                      9.70592
evaluation_0/Rewards Min                     -0.567378
evaluation_0/Returns Mean                  4925.49
evaluation_0/Returns Std                     20.9277
evaluation_0/Returns Max                   4953.21
evaluation_0/Returns Min                   4884.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4925.49
time/epoch (s)                                0
time/total (s)                            10772.3
Epoch                                       548
---------------------------------------  ----------------
2022-11-16 13:45:35.011880 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 549 finished
---------------------------------------  ----------------
epoch                                       549
total_step                               554000
replay_pool/size                         554000
trainer/alpha                                 0.0655527
trainer/alpha_loss                            0.47446
trainer/entropy                              -6.17412
trainer/qf_loss                              10.7919
trainer/state_noise                           0.005
trainer/policy_loss                        -211.362
trainer/policy_loss_without_entropy         213.432
trainer/entropy_penalty                      -0.40473
trainer/entropy_percentage                   -0.00189629
trainer/Q1Pred Mean                         212.673
trainer/Q1Pred Std                           71.8693
trainer/Q1Pred Max                          313.943
trainer/Q1Pred Min                            5.44203
trainer/Q2Pred Mean                         213.189
trainer/Q2Pred Std                           71.8023
trainer/Q2Pred Max                          313.403
trainer/Q2Pred Min                            3.47334
trainer/QTargetWithReg Mean                 212.355
trainer/QTargetWithReg Std                   72.3473
trainer/QTargetWithReg Max                  313.784
trainer/QTargetWithReg Min                    3.22283
trainer/PolicyLossWithoutReg Mean           213.432
trainer/PolicyLossWithoutReg Std             71.3667
trainer/PolicyLossWithoutReg Max            313.291
trainer/PolicyLossWithoutReg Min              4.06126
trainer/gradient_norm                       333.051
trainer/gradient_penalty                     -1.66526
trainer/gradient_percentage                  -0.00780227
exploration/num steps total              554000
exploration/num paths total                1710
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87306
exploration/Rewards Std                       1.22587
exploration/Rewards Max                       9.98768
exploration/Rewards Min                      -0.566148
exploration/Returns Mean                   4873.06
exploration/Returns Std                       0
exploration/Returns Max                    4873.06
exploration/Returns Min                    4873.06
exploration/Num Paths                         1
exploration/Average Returns                4873.06
evaluation_0/num steps total                  4.31433e+06
evaluation_0/num paths total              12432
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96859
evaluation_0/Rewards Std                      1.22298
evaluation_0/Rewards Max                      9.96572
evaluation_0/Rewards Min                     -0.627404
evaluation_0/Returns Mean                  4968.59
evaluation_0/Returns Std                      7.26119
evaluation_0/Returns Max                   4978.98
evaluation_0/Returns Min                   4957.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4968.59
time/epoch (s)                                0
time/total (s)                            10788.8
Epoch                                       549
---------------------------------------  ----------------
2022-11-16 13:45:50.815810 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 550 finished
---------------------------------------  ----------------
epoch                                       550
total_step                               555000
replay_pool/size                         555000
trainer/alpha                                 0.0664584
trainer/alpha_loss                            0.121146
trainer/entropy                              -6.04468
trainer/qf_loss                               7.45435
trainer/state_noise                           0.005
trainer/policy_loss                        -206.066
trainer/policy_loss_without_entropy         208.145
trainer/entropy_penalty                      -0.40172
trainer/entropy_percentage                   -0.00193
trainer/Q1Pred Mean                         206.817
trainer/Q1Pred Std                           69.715
trainer/Q1Pred Max                          308.938
trainer/Q1Pred Min                           -4.90024
trainer/Q2Pred Mean                         206.582
trainer/Q2Pred Std                           69.9724
trainer/Q2Pred Max                          310.67
trainer/Q2Pred Min                           -5.25522
trainer/QTargetWithReg Mean                 206.763
trainer/QTargetWithReg Std                   69.2965
trainer/QTargetWithReg Max                  308.457
trainer/QTargetWithReg Min                   -0.45089
trainer/PolicyLossWithoutReg Mean           208.145
trainer/PolicyLossWithoutReg Std             68.3303
trainer/PolicyLossWithoutReg Max            308.583
trainer/PolicyLossWithoutReg Min             22.3873
trainer/gradient_norm                       335.553
trainer/gradient_penalty                     -1.67776
trainer/gradient_percentage                  -0.00806054
exploration/num steps total              555000
exploration/num paths total                1711
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95835
exploration/Rewards Std                       1.26427
exploration/Rewards Max                       9.93474
exploration/Rewards Min                      -0.693267
exploration/Returns Mean                   4958.35
exploration/Returns Std                       0
exploration/Returns Max                    4958.35
exploration/Returns Min                    4958.35
exploration/Num Paths                         1
exploration/Average Returns                4958.35
evaluation_0/num steps total                  4.32233e+06
evaluation_0/num paths total              12440
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93363
evaluation_0/Rewards Std                      1.26582
evaluation_0/Rewards Max                     10.2235
evaluation_0/Rewards Min                     -0.593445
evaluation_0/Returns Mean                  4933.63
evaluation_0/Returns Std                     21.7968
evaluation_0/Returns Max                   4974.75
evaluation_0/Returns Min                   4901.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4933.63
time/epoch (s)                                0
time/total (s)                            10804.6
Epoch                                       550
---------------------------------------  ----------------
2022-11-16 13:46:07.407996 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 551 finished
---------------------------------------  ----------------
epoch                                       551
total_step                               556000
replay_pool/size                         556000
trainer/alpha                                 0.067411
trainer/alpha_loss                           -0.0770516
trainer/entropy                              -5.97143
trainer/qf_loss                               8.13677
trainer/state_noise                           0.005
trainer/policy_loss                        -196.537
trainer/policy_loss_without_entropy         198.592
trainer/entropy_penalty                      -0.40254
trainer/entropy_percentage                   -0.00202697
trainer/Q1Pred Mean                         197.834
trainer/Q1Pred Std                           76.5257
trainer/Q1Pred Max                          309.57
trainer/Q1Pred Min                           -1.46736
trainer/Q2Pred Mean                         197.973
trainer/Q2Pred Std                           76.6551
trainer/Q2Pred Max                          309.904
trainer/Q2Pred Min                           -2.44251
trainer/QTargetWithReg Mean                 197.083
trainer/QTargetWithReg Std                   76.9324
trainer/QTargetWithReg Max                  309.887
trainer/QTargetWithReg Min                   -7.41842
trainer/PolicyLossWithoutReg Mean           198.592
trainer/PolicyLossWithoutReg Std             75.551
trainer/PolicyLossWithoutReg Max            309.709
trainer/PolicyLossWithoutReg Min              2.96308
trainer/gradient_norm                       330.425
trainer/gradient_penalty                     -1.65212
trainer/gradient_percentage                  -0.00831919
exploration/num steps total              556000
exploration/num paths total                1712
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.6216
exploration/Rewards Std                       1.22965
exploration/Rewards Max                       9.96901
exploration/Rewards Min                      -0.536883
exploration/Returns Mean                   4621.6
exploration/Returns Std                       0
exploration/Returns Max                    4621.6
exploration/Returns Min                    4621.6
exploration/Num Paths                         1
exploration/Average Returns                4621.6
evaluation_0/num steps total                  4.33033e+06
evaluation_0/num paths total              12448
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04165
evaluation_0/Rewards Std                      1.2075
evaluation_0/Rewards Max                      9.88048
evaluation_0/Rewards Min                     -0.582408
evaluation_0/Returns Mean                  5041.65
evaluation_0/Returns Std                      9.21958
evaluation_0/Returns Max                   5056.3
evaluation_0/Returns Min                   5027.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5041.65
time/epoch (s)                                0
time/total (s)                            10821.2
Epoch                                       551
---------------------------------------  ----------------
2022-11-16 13:46:23.244636 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 552 finished
---------------------------------------  ----------------
epoch                                       552
total_step                               557000
replay_pool/size                         557000
trainer/alpha                                 0.0669117
trainer/alpha_loss                            0.238797
trainer/entropy                              -6.0883
trainer/qf_loss                               7.80224
trainer/state_noise                           0.005
trainer/policy_loss                        -208.043
trainer/policy_loss_without_entropy         210.139
trainer/entropy_penalty                      -0.407379
trainer/entropy_percentage                   -0.00193862
trainer/Q1Pred Mean                         209.801
trainer/Q1Pred Std                           68.5358
trainer/Q1Pred Max                          311.873
trainer/Q1Pred Min                          -21.5157
trainer/Q2Pred Mean                         209.18
trainer/Q2Pred Std                           68.3716
trainer/Q2Pred Max                          309.853
trainer/Q2Pred Min                          -12.5797
trainer/QTargetWithReg Mean                 209.883
trainer/QTargetWithReg Std                   68.7218
trainer/QTargetWithReg Max                  312.821
trainer/QTargetWithReg Min                  -21.1702
trainer/PolicyLossWithoutReg Mean           210.139
trainer/PolicyLossWithoutReg Std             67.5955
trainer/PolicyLossWithoutReg Max            310.159
trainer/PolicyLossWithoutReg Min            -16.3267
trainer/gradient_norm                       337.706
trainer/gradient_penalty                     -1.68853
trainer/gradient_percentage                  -0.00803531
exploration/num steps total              557000
exploration/num paths total                1713
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99465
exploration/Rewards Std                       1.22122
exploration/Rewards Max                      10.0798
exploration/Rewards Min                      -0.678422
exploration/Returns Mean                   4994.65
exploration/Returns Std                       0
exploration/Returns Max                    4994.65
exploration/Returns Min                    4994.65
exploration/Num Paths                         1
exploration/Average Returns                4994.65
evaluation_0/num steps total                  4.33833e+06
evaluation_0/num paths total              12456
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81273
evaluation_0/Rewards Std                      1.22563
evaluation_0/Rewards Max                      9.86693
evaluation_0/Rewards Min                     -0.772814
evaluation_0/Returns Mean                  4812.73
evaluation_0/Returns Std                     31.1683
evaluation_0/Returns Max                   4849.15
evaluation_0/Returns Min                   4766.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4812.73
time/epoch (s)                                0
time/total (s)                            10837
Epoch                                       552
---------------------------------------  ----------------
2022-11-16 13:46:39.673637 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 553 finished
---------------------------------------  ----------------
epoch                                       553
total_step                               558000
replay_pool/size                         558000
trainer/alpha                                 0.0664374
trainer/alpha_loss                            0.0398071
trainer/entropy                              -6.01468
trainer/qf_loss                               7.17592
trainer/state_noise                           0.005
trainer/policy_loss                        -201.728
trainer/policy_loss_without_entropy         203.814
trainer/entropy_penalty                      -0.3996
trainer/entropy_percentage                   -0.00196061
trainer/Q1Pred Mean                         202.811
trainer/Q1Pred Std                           71.3925
trainer/Q1Pred Max                          305.59
trainer/Q1Pred Min                          -20.455
trainer/Q2Pred Mean                         202.372
trainer/Q2Pred Std                           71.8853
trainer/Q2Pred Max                          305.48
trainer/Q2Pred Min                          -24.1421
trainer/QTargetWithReg Mean                 202.483
trainer/QTargetWithReg Std                   71.5818
trainer/QTargetWithReg Max                  305.853
trainer/QTargetWithReg Min                  -14.0013
trainer/PolicyLossWithoutReg Mean           203.814
trainer/PolicyLossWithoutReg Std             70.5467
trainer/PolicyLossWithoutReg Max            304.845
trainer/PolicyLossWithoutReg Min            -12.8413
trainer/gradient_norm                       337.371
trainer/gradient_penalty                     -1.68685
trainer/gradient_percentage                  -0.00827643
exploration/num steps total              558000
exploration/num paths total                1714
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81121
exploration/Rewards Std                       1.20254
exploration/Rewards Max                       9.66242
exploration/Rewards Min                      -0.749375
exploration/Returns Mean                   4811.21
exploration/Returns Std                       0
exploration/Returns Max                    4811.21
exploration/Returns Min                    4811.21
exploration/Num Paths                         1
exploration/Average Returns                4811.21
evaluation_0/num steps total                  4.34633e+06
evaluation_0/num paths total              12464
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91682
evaluation_0/Rewards Std                      1.20992
evaluation_0/Rewards Max                      9.84757
evaluation_0/Rewards Min                     -0.71572
evaluation_0/Returns Mean                  4916.82
evaluation_0/Returns Std                     46.674
evaluation_0/Returns Max                   4958.44
evaluation_0/Returns Min                   4796.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4916.82
time/epoch (s)                                0
time/total (s)                            10853.5
Epoch                                       553
---------------------------------------  ----------------
2022-11-16 13:46:55.627548 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 554 finished
---------------------------------------  ----------------
epoch                                       554
total_step                               559000
replay_pool/size                         559000
trainer/alpha                                 0.0660285
trainer/alpha_loss                            0.445478
trainer/entropy                              -6.16392
trainer/qf_loss                               7.80289
trainer/state_noise                           0.005
trainer/policy_loss                        -206.823
trainer/policy_loss_without_entropy         208.869
trainer/entropy_penalty                      -0.406995
trainer/entropy_percentage                   -0.00194857
trainer/Q1Pred Mean                         207.572
trainer/Q1Pred Std                           72.2095
trainer/Q1Pred Max                          310.43
trainer/Q1Pred Min                          -75.9522
trainer/Q2Pred Mean                         207.225
trainer/Q2Pred Std                           71.6995
trainer/Q2Pred Max                          309.387
trainer/Q2Pred Min                          -63.2304
trainer/QTargetWithReg Mean                 207.887
trainer/QTargetWithReg Std                   72.1901
trainer/QTargetWithReg Max                  310.63
trainer/QTargetWithReg Min                  -76.3173
trainer/PolicyLossWithoutReg Mean           208.869
trainer/PolicyLossWithoutReg Std             70.0583
trainer/PolicyLossWithoutReg Max            309.39
trainer/PolicyLossWithoutReg Min            -51.7351
trainer/gradient_norm                       327.782
trainer/gradient_penalty                     -1.63891
trainer/gradient_percentage                  -0.00784659
exploration/num steps total              559000
exploration/num paths total                1715
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9282
exploration/Rewards Std                       1.19963
exploration/Rewards Max                       9.85379
exploration/Rewards Min                      -0.727992
exploration/Returns Mean                   4928.2
exploration/Returns Std                       0
exploration/Returns Max                    4928.2
exploration/Returns Min                    4928.2
exploration/Num Paths                         1
exploration/Average Returns                4928.2
evaluation_0/num steps total                  4.35433e+06
evaluation_0/num paths total              12472
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.43822
evaluation_0/Rewards Std                      1.17606
evaluation_0/Rewards Max                     10.0846
evaluation_0/Rewards Min                     -0.689721
evaluation_0/Returns Mean                  4438.22
evaluation_0/Returns Std                    203.931
evaluation_0/Returns Max                   4971.81
evaluation_0/Returns Min                   4304.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4438.22
time/epoch (s)                                0
time/total (s)                            10869.4
Epoch                                       554
---------------------------------------  ----------------
2022-11-16 13:47:12.016626 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 555 finished
---------------------------------------  ----------------
epoch                                       555
total_step                               560000
replay_pool/size                         560000
trainer/alpha                                 0.065594
trainer/alpha_loss                            0.680619
trainer/entropy                              -6.24984
trainer/qf_loss                              10.1333
trainer/state_noise                           0.005
trainer/policy_loss                        -204.176
trainer/policy_loss_without_entropy         206.289
trainer/entropy_penalty                      -0.409952
trainer/entropy_percentage                   -0.00198727
trainer/Q1Pred Mean                         205.093
trainer/Q1Pred Std                           67.709
trainer/Q1Pred Max                          309.913
trainer/Q1Pred Min                            6.10532
trainer/Q2Pred Mean                         204.584
trainer/Q2Pred Std                           67.329
trainer/Q2Pred Max                          308.136
trainer/Q2Pred Min                           10.1427
trainer/QTargetWithReg Mean                 205.125
trainer/QTargetWithReg Std                   67.7271
trainer/QTargetWithReg Max                  310.205
trainer/QTargetWithReg Min                    3.56991
trainer/PolicyLossWithoutReg Mean           206.289
trainer/PolicyLossWithoutReg Std             66.0913
trainer/PolicyLossWithoutReg Max            308.715
trainer/PolicyLossWithoutReg Min              7.55637
trainer/gradient_norm                       340.644
trainer/gradient_penalty                     -1.70322
trainer/gradient_percentage                  -0.00825648
exploration/num steps total              560000
exploration/num paths total                1716
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81811
exploration/Rewards Std                       1.2168
exploration/Rewards Max                       9.66256
exploration/Rewards Min                      -0.554589
exploration/Returns Mean                   4818.11
exploration/Returns Std                       0
exploration/Returns Max                    4818.11
exploration/Returns Min                    4818.11
exploration/Num Paths                         1
exploration/Average Returns                4818.11
evaluation_0/num steps total                  4.36233e+06
evaluation_0/num paths total              12480
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.43487
evaluation_0/Rewards Std                      1.28547
evaluation_0/Rewards Max                     10.1726
evaluation_0/Rewards Min                     -0.704678
evaluation_0/Returns Mean                  4434.87
evaluation_0/Returns Std                    368.434
evaluation_0/Returns Max                   4964.42
evaluation_0/Returns Min                   4082.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4434.87
time/epoch (s)                                0
time/total (s)                            10885.8
Epoch                                       555
---------------------------------------  ----------------
2022-11-16 13:47:28.023845 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 556 finished
---------------------------------------  ----------------
epoch                                       556
total_step                               561000
replay_pool/size                         561000
trainer/alpha                                 0.0668229
trainer/alpha_loss                           -0.533683
trainer/entropy                              -5.80275
trainer/qf_loss                               6.7656
trainer/state_noise                           0.005
trainer/policy_loss                        -203.319
trainer/policy_loss_without_entropy         205.354
trainer/entropy_penalty                      -0.387757
trainer/entropy_percentage                   -0.00188824
trainer/Q1Pred Mean                         204.793
trainer/Q1Pred Std                           66.3213
trainer/Q1Pred Max                          311.398
trainer/Q1Pred Min                           14.7135
trainer/Q2Pred Mean                         204.424
trainer/Q2Pred Std                           66.3396
trainer/Q2Pred Max                          311.795
trainer/Q2Pred Min                           27.3897
trainer/QTargetWithReg Mean                 205.308
trainer/QTargetWithReg Std                   66.5155
trainer/QTargetWithReg Max                  311.206
trainer/QTargetWithReg Min                   17.1182
trainer/PolicyLossWithoutReg Mean           205.354
trainer/PolicyLossWithoutReg Std             65.5387
trainer/PolicyLossWithoutReg Max            310.673
trainer/PolicyLossWithoutReg Min             23.1911
trainer/gradient_norm                       329.329
trainer/gradient_penalty                     -1.64664
trainer/gradient_percentage                  -0.00801857
exploration/num steps total              561000
exploration/num paths total                1717
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.64682
exploration/Rewards Std                       1.34431
exploration/Rewards Max                      10.2816
exploration/Rewards Min                      -0.511961
exploration/Returns Mean                   4646.82
exploration/Returns Std                       0
exploration/Returns Max                    4646.82
exploration/Returns Min                    4646.82
exploration/Num Paths                         1
exploration/Average Returns                4646.82
evaluation_0/num steps total                  4.37033e+06
evaluation_0/num paths total              12488
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88257
evaluation_0/Rewards Std                      1.21419
evaluation_0/Rewards Max                      9.91968
evaluation_0/Rewards Min                     -0.58034
evaluation_0/Returns Mean                  4882.57
evaluation_0/Returns Std                     20.0477
evaluation_0/Returns Max                   4903.18
evaluation_0/Returns Min                   4846.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4882.57
time/epoch (s)                                0
time/total (s)                            10901.8
Epoch                                       556
---------------------------------------  ----------------
2022-11-16 13:47:43.959574 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 557 finished
---------------------------------------  ----------------
epoch                                       557
total_step                               562000
replay_pool/size                         562000
trainer/alpha                                 0.0666181
trainer/alpha_loss                            0.652176
trainer/entropy                              -6.24076
trainer/qf_loss                               6.83337
trainer/state_noise                           0.005
trainer/policy_loss                        -202.142
trainer/policy_loss_without_entropy         204.232
trainer/entropy_penalty                      -0.415748
trainer/entropy_percentage                   -0.00203567
trainer/Q1Pred Mean                         203.166
trainer/Q1Pred Std                           72.2313
trainer/Q1Pred Max                          309.094
trainer/Q1Pred Min                          -26.0078
trainer/Q2Pred Mean                         203.388
trainer/Q2Pred Std                           72.4033
trainer/Q2Pred Max                          309.242
trainer/Q2Pred Min                          -26.4726
trainer/QTargetWithReg Mean                 203.345
trainer/QTargetWithReg Std                   72.4562
trainer/QTargetWithReg Max                  308.689
trainer/QTargetWithReg Min                  -26.2533
trainer/PolicyLossWithoutReg Mean           204.232
trainer/PolicyLossWithoutReg Std             71.4724
trainer/PolicyLossWithoutReg Max            308.64
trainer/PolicyLossWithoutReg Min            -26.7264
trainer/gradient_norm                       334.848
trainer/gradient_penalty                     -1.67424
trainer/gradient_percentage                  -0.00819776
exploration/num steps total              562000
exploration/num paths total                1718
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84972
exploration/Rewards Std                       1.28392
exploration/Rewards Max                      10.1787
exploration/Rewards Min                      -0.571006
exploration/Returns Mean                   4849.72
exploration/Returns Std                       0
exploration/Returns Max                    4849.72
exploration/Returns Min                    4849.72
exploration/Num Paths                         1
exploration/Average Returns                4849.72
evaluation_0/num steps total                  4.37833e+06
evaluation_0/num paths total              12496
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.82873
evaluation_0/Rewards Std                      1.29717
evaluation_0/Rewards Max                     10.0835
evaluation_0/Rewards Min                     -0.69758
evaluation_0/Returns Mean                  4828.73
evaluation_0/Returns Std                     23.8738
evaluation_0/Returns Max                   4864.68
evaluation_0/Returns Min                   4795.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4828.73
time/epoch (s)                                0
time/total (s)                            10917.8
Epoch                                       557
---------------------------------------  ----------------
2022-11-16 13:48:00.369277 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 558 finished
---------------------------------------  ----------------
epoch                                       558
total_step                               563000
replay_pool/size                         563000
trainer/alpha                                 0.0667079
trainer/alpha_loss                            0.46901
trainer/entropy                              -6.17323
trainer/qf_loss                              10.7945
trainer/state_noise                           0.005
trainer/policy_loss                        -211.636
trainer/policy_loss_without_entropy         213.767
trainer/entropy_penalty                      -0.411803
trainer/entropy_percentage                   -0.00192641
trainer/Q1Pred Mean                         212.977
trainer/Q1Pred Std                           66.5547
trainer/Q1Pred Max                          308.012
trainer/Q1Pred Min                           24.3393
trainer/Q2Pred Mean                         212.601
trainer/Q2Pred Std                           66.5277
trainer/Q2Pred Max                          308.99
trainer/Q2Pred Min                           27.6085
trainer/QTargetWithReg Mean                 213.078
trainer/QTargetWithReg Std                   66.8386
trainer/QTargetWithReg Max                  309.949
trainer/QTargetWithReg Min                    2.54756
trainer/PolicyLossWithoutReg Mean           213.767
trainer/PolicyLossWithoutReg Std             65.7331
trainer/PolicyLossWithoutReg Max            308.459
trainer/PolicyLossWithoutReg Min             25.1834
trainer/gradient_norm                       343.89
trainer/gradient_penalty                     -1.71945
trainer/gradient_percentage                  -0.00804357
exploration/num steps total              563000
exploration/num paths total                1719
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9518
exploration/Rewards Std                       1.23564
exploration/Rewards Max                       9.9326
exploration/Rewards Min                      -0.601077
exploration/Returns Mean                   4951.8
exploration/Returns Std                       0
exploration/Returns Max                    4951.8
exploration/Returns Min                    4951.8
exploration/Num Paths                         1
exploration/Average Returns                4951.8
evaluation_0/num steps total                  4.38633e+06
evaluation_0/num paths total              12504
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88147
evaluation_0/Rewards Std                      1.23548
evaluation_0/Rewards Max                      9.89528
evaluation_0/Rewards Min                     -0.707435
evaluation_0/Returns Mean                  4881.47
evaluation_0/Returns Std                     34.3721
evaluation_0/Returns Max                   4938.21
evaluation_0/Returns Min                   4833.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4881.47
time/epoch (s)                                0
time/total (s)                            10934.2
Epoch                                       558
---------------------------------------  ----------------
2022-11-16 13:48:16.254293 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 559 finished
---------------------------------------  ----------------
epoch                                       559
total_step                               564000
replay_pool/size                         564000
trainer/alpha                                 0.0659347
trainer/alpha_loss                           -0.373888
trainer/entropy                              -5.8625
trainer/qf_loss                               8.01905
trainer/state_noise                           0.005
trainer/policy_loss                        -209.189
trainer/policy_loss_without_entropy         211.144
trainer/entropy_penalty                      -0.386542
trainer/entropy_percentage                   -0.0018307
trainer/Q1Pred Mean                         210.093
trainer/Q1Pred Std                           74.3919
trainer/Q1Pred Max                          310.582
trainer/Q1Pred Min                            6.9387
trainer/Q2Pred Mean                         210.632
trainer/Q2Pred Std                           74.6232
trainer/Q2Pred Max                          311.141
trainer/Q2Pred Min                            3.86552
trainer/QTargetWithReg Mean                 210.479
trainer/QTargetWithReg Std                   74.4113
trainer/QTargetWithReg Max                  310.673
trainer/QTargetWithReg Min                    5.36053
trainer/PolicyLossWithoutReg Mean           211.144
trainer/PolicyLossWithoutReg Std             73.6938
trainer/PolicyLossWithoutReg Max            310.317
trainer/PolicyLossWithoutReg Min              6.04121
trainer/gradient_norm                       313.767
trainer/gradient_penalty                     -1.56883
trainer/gradient_percentage                  -0.00743015
exploration/num steps total              564000
exploration/num paths total                1720
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96619
exploration/Rewards Std                       1.21835
exploration/Rewards Max                       9.95443
exploration/Rewards Min                      -0.627479
exploration/Returns Mean                   4966.19
exploration/Returns Std                       0
exploration/Returns Max                    4966.19
exploration/Returns Min                    4966.19
exploration/Num Paths                         1
exploration/Average Returns                4966.19
evaluation_0/num steps total                  4.39433e+06
evaluation_0/num paths total              12512
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95103
evaluation_0/Rewards Std                      1.28708
evaluation_0/Rewards Max                     10.034
evaluation_0/Rewards Min                     -0.719089
evaluation_0/Returns Mean                  4951.03
evaluation_0/Returns Std                     17.6289
evaluation_0/Returns Max                   4980.38
evaluation_0/Returns Min                   4915.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4951.03
time/epoch (s)                                0
time/total (s)                            10950
Epoch                                       559
---------------------------------------  ----------------
2022-11-16 13:48:32.763916 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 560 finished
---------------------------------------  ----------------
epoch                                       560
total_step                               565000
replay_pool/size                         565000
trainer/alpha                                 0.0654381
trainer/alpha_loss                            0.69986
trainer/entropy                              -6.25667
trainer/qf_loss                               9.65658
trainer/state_noise                           0.005
trainer/policy_loss                        -203.565
trainer/policy_loss_without_entropy         205.6
trainer/entropy_penalty                      -0.409425
trainer/entropy_percentage                   -0.00199137
trainer/Q1Pred Mean                         205.05
trainer/Q1Pred Std                           75.3805
trainer/Q1Pred Max                          315.199
trainer/Q1Pred Min                          -19.5706
trainer/Q2Pred Mean                         204.805
trainer/Q2Pred Std                           75.4357
trainer/Q2Pred Max                          313.726
trainer/Q2Pred Min                           -9.63427
trainer/QTargetWithReg Mean                 205.103
trainer/QTargetWithReg Std                   75.4593
trainer/QTargetWithReg Max                  312.97
trainer/QTargetWithReg Min                   -0.291876
trainer/PolicyLossWithoutReg Mean           205.6
trainer/PolicyLossWithoutReg Std             74.0601
trainer/PolicyLossWithoutReg Max            313.692
trainer/PolicyLossWithoutReg Min              9.18957
trainer/gradient_norm                       325.189
trainer/gradient_penalty                     -1.62595
trainer/gradient_percentage                  -0.0079083
exploration/num steps total              565000
exploration/num paths total                1721
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91479
exploration/Rewards Std                       1.27352
exploration/Rewards Max                      10.0962
exploration/Rewards Min                      -0.710931
exploration/Returns Mean                   4914.79
exploration/Returns Std                       0
exploration/Returns Max                    4914.79
exploration/Returns Min                    4914.79
exploration/Num Paths                         1
exploration/Average Returns                4914.79
evaluation_0/num steps total                  4.40233e+06
evaluation_0/num paths total              12520
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92686
evaluation_0/Rewards Std                      1.27525
evaluation_0/Rewards Max                     10.0603
evaluation_0/Rewards Min                     -0.670602
evaluation_0/Returns Mean                  4926.86
evaluation_0/Returns Std                     60.6913
evaluation_0/Returns Max                   5031.15
evaluation_0/Returns Min                   4868.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4926.86
time/epoch (s)                                0
time/total (s)                            10966.6
Epoch                                       560
---------------------------------------  ----------------
2022-11-16 13:48:48.677761 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 561 finished
---------------------------------------  ----------------
epoch                                       561
total_step                               566000
replay_pool/size                         566000
trainer/alpha                                 0.0680373
trainer/alpha_loss                           -0.538453
trainer/entropy                              -5.79966
trainer/qf_loss                               8.75005
trainer/state_noise                           0.005
trainer/policy_loss                        -205.218
trainer/policy_loss_without_entropy         207.279
trainer/entropy_penalty                      -0.394593
trainer/entropy_percentage                   -0.00190368
trainer/Q1Pred Mean                         206.64
trainer/Q1Pred Std                           73.9579
trainer/Q1Pred Max                          309.739
trainer/Q1Pred Min                          -25.3335
trainer/Q2Pred Mean                         206.204
trainer/Q2Pred Std                           73.7638
trainer/Q2Pred Max                          308.556
trainer/Q2Pred Min                          -24.0805
trainer/QTargetWithReg Mean                 206.5
trainer/QTargetWithReg Std                   74.5043
trainer/QTargetWithReg Max                  309.511
trainer/QTargetWithReg Min                  -27.2928
trainer/PolicyLossWithoutReg Mean           207.279
trainer/PolicyLossWithoutReg Std             73.4073
trainer/PolicyLossWithoutReg Max            309.071
trainer/PolicyLossWithoutReg Min            -24.4265
trainer/gradient_norm                       333.174
trainer/gradient_penalty                     -1.66587
trainer/gradient_percentage                  -0.00803687
exploration/num steps total              566000
exploration/num paths total                1722
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99206
exploration/Rewards Std                       1.2416
exploration/Rewards Max                       9.9038
exploration/Rewards Min                      -0.566599
exploration/Returns Mean                   4992.06
exploration/Returns Std                       0
exploration/Returns Max                    4992.06
exploration/Returns Min                    4992.06
exploration/Num Paths                         1
exploration/Average Returns                4992.06
evaluation_0/num steps total                  4.41033e+06
evaluation_0/num paths total              12528
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98675
evaluation_0/Rewards Std                      1.20604
evaluation_0/Rewards Max                      9.78354
evaluation_0/Rewards Min                     -0.658149
evaluation_0/Returns Mean                  4986.75
evaluation_0/Returns Std                      8.78654
evaluation_0/Returns Max                   5003.58
evaluation_0/Returns Min                   4974.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4986.75
time/epoch (s)                                0
time/total (s)                            10982.5
Epoch                                       561
---------------------------------------  ----------------
2022-11-16 13:49:05.099256 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 562 finished
---------------------------------------  ----------------
epoch                                       562
total_step                               567000
replay_pool/size                         567000
trainer/alpha                                 0.0659639
trainer/alpha_loss                            0.701247
trainer/entropy                              -6.25794
trainer/qf_loss                               8.64821
trainer/state_noise                           0.005
trainer/policy_loss                        -201.184
trainer/policy_loss_without_entropy         203.224
trainer/entropy_penalty                      -0.412798
trainer/entropy_percentage                   -0.00203125
trainer/Q1Pred Mean                         202.227
trainer/Q1Pred Std                           76.1911
trainer/Q1Pred Max                          312.093
trainer/Q1Pred Min                           12.221
trainer/Q2Pred Mean                         202.165
trainer/Q2Pred Std                           75.9353
trainer/Q2Pred Max                          312.406
trainer/Q2Pred Min                           10.0977
trainer/QTargetWithReg Mean                 202.601
trainer/QTargetWithReg Std                   76.3098
trainer/QTargetWithReg Max                  310.221
trainer/QTargetWithReg Min                   12.0019
trainer/PolicyLossWithoutReg Mean           203.224
trainer/PolicyLossWithoutReg Std             75.7037
trainer/PolicyLossWithoutReg Max            312.748
trainer/PolicyLossWithoutReg Min              9.7605
trainer/gradient_norm                       325.374
trainer/gradient_penalty                     -1.62687
trainer/gradient_percentage                  -0.0080053
exploration/num steps total              567000
exploration/num paths total                1723
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94306
exploration/Rewards Std                       1.20958
exploration/Rewards Max                       9.66209
exploration/Rewards Min                      -0.691003
exploration/Returns Mean                   4943.06
exploration/Returns Std                       0
exploration/Returns Max                    4943.06
exploration/Returns Min                    4943.06
exploration/Num Paths                         1
exploration/Average Returns                4943.06
evaluation_0/num steps total                  4.41833e+06
evaluation_0/num paths total              12536
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90034
evaluation_0/Rewards Std                      1.26248
evaluation_0/Rewards Max                      9.9011
evaluation_0/Rewards Min                     -0.655695
evaluation_0/Returns Mean                  4900.34
evaluation_0/Returns Std                     75.1757
evaluation_0/Returns Max                   4981.51
evaluation_0/Returns Min                   4752.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4900.34
time/epoch (s)                                0
time/total (s)                            10998.9
Epoch                                       562
---------------------------------------  ----------------
2022-11-16 13:49:20.956638 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 563 finished
---------------------------------------  ----------------
epoch                                       563
total_step                               568000
replay_pool/size                         568000
trainer/alpha                                 0.0669996
trainer/alpha_loss                           -0.744178
trainer/entropy                              -5.7247
trainer/qf_loss                               7.39294
trainer/state_noise                           0.005
trainer/policy_loss                        -208.065
trainer/policy_loss_without_entropy         210.15
trainer/entropy_penalty                      -0.383553
trainer/entropy_percentage                   -0.00182513
trainer/Q1Pred Mean                         210.078
trainer/Q1Pred Std                           67.851
trainer/Q1Pred Max                          309.666
trainer/Q1Pred Min                           13.3401
trainer/Q2Pred Mean                         209.897
trainer/Q2Pred Std                           67.8204
trainer/Q2Pred Max                          308.491
trainer/Q2Pred Min                           13.845
trainer/QTargetWithReg Mean                 209.164
trainer/QTargetWithReg Std                   67.9631
trainer/QTargetWithReg Max                  307.721
trainer/QTargetWithReg Min                   12.287
trainer/PolicyLossWithoutReg Mean           210.15
trainer/PolicyLossWithoutReg Std             67.096
trainer/PolicyLossWithoutReg Max            307.42
trainer/PolicyLossWithoutReg Min             13.2728
trainer/gradient_norm                       340.316
trainer/gradient_penalty                     -1.70158
trainer/gradient_percentage                  -0.00809695
exploration/num steps total              568000
exploration/num paths total                1724
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69029
exploration/Rewards Std                       1.24001
exploration/Rewards Max                       9.74928
exploration/Rewards Min                      -0.76837
exploration/Returns Mean                   4690.29
exploration/Returns Std                       0
exploration/Returns Max                    4690.29
exploration/Returns Min                    4690.29
exploration/Num Paths                         1
exploration/Average Returns                4690.29
evaluation_0/num steps total                  4.42633e+06
evaluation_0/num paths total              12544
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89032
evaluation_0/Rewards Std                      1.24548
evaluation_0/Rewards Max                      9.89148
evaluation_0/Rewards Min                     -0.670196
evaluation_0/Returns Mean                  4890.32
evaluation_0/Returns Std                     32.2219
evaluation_0/Returns Max                   4931.78
evaluation_0/Returns Min                   4818.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4890.32
time/epoch (s)                                0
time/total (s)                            11014.8
Epoch                                       563
---------------------------------------  ----------------
2022-11-16 13:49:36.845435 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 564 finished
---------------------------------------  ----------------
epoch                                       564
total_step                               569000
replay_pool/size                         569000
trainer/alpha                                 0.067043
trainer/alpha_loss                            0.792429
trainer/entropy                              -6.29322
trainer/qf_loss                              12.1393
trainer/state_noise                           0.005
trainer/policy_loss                        -212.018
trainer/policy_loss_without_entropy         214.093
trainer/entropy_penalty                      -0.421917
trainer/entropy_percentage                   -0.00197071
trainer/Q1Pred Mean                         213.783
trainer/Q1Pred Std                           67.3774
trainer/Q1Pred Max                          309.846
trainer/Q1Pred Min                           -9.65968
trainer/Q2Pred Mean                         214.708
trainer/Q2Pred Std                           67.3988
trainer/Q2Pred Max                          310.985
trainer/Q2Pred Min                           -9.74361
trainer/QTargetWithReg Mean                 213.053
trainer/QTargetWithReg Std                   67.5095
trainer/QTargetWithReg Max                  313.576
trainer/QTargetWithReg Min                   -5.58746
trainer/PolicyLossWithoutReg Mean           214.093
trainer/PolicyLossWithoutReg Std             66.1787
trainer/PolicyLossWithoutReg Max            309.224
trainer/PolicyLossWithoutReg Min              3.80275
trainer/gradient_norm                       330.757
trainer/gradient_penalty                     -1.65378
trainer/gradient_percentage                  -0.00772459
exploration/num steps total              569000
exploration/num paths total                1725
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78422
exploration/Rewards Std                       1.23663
exploration/Rewards Max                       9.71917
exploration/Rewards Min                      -0.597094
exploration/Returns Mean                   4784.22
exploration/Returns Std                       0
exploration/Returns Max                    4784.22
exploration/Returns Min                    4784.22
exploration/Num Paths                         1
exploration/Average Returns                4784.22
evaluation_0/num steps total                  4.43433e+06
evaluation_0/num paths total              12552
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57629
evaluation_0/Rewards Std                      1.23621
evaluation_0/Rewards Max                      9.75446
evaluation_0/Rewards Min                     -0.710088
evaluation_0/Returns Mean                  4576.29
evaluation_0/Returns Std                    100.373
evaluation_0/Returns Max                   4677.34
evaluation_0/Returns Min                   4360.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4576.29
time/epoch (s)                                0
time/total (s)                            11030.6
Epoch                                       564
---------------------------------------  ----------------
2022-11-16 13:49:53.315931 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 565 finished
---------------------------------------  ----------------
epoch                                       565
total_step                               570000
replay_pool/size                         570000
trainer/alpha                                 0.0672062
trainer/alpha_loss                            0.0409444
trainer/entropy                              -6.01516
trainer/qf_loss                               7.02033
trainer/state_noise                           0.005
trainer/policy_loss                        -205.185
trainer/policy_loss_without_entropy         207.248
trainer/entropy_penalty                      -0.404257
trainer/entropy_percentage                   -0.0019506
trainer/Q1Pred Mean                         206.14
trainer/Q1Pred Std                           70.0507
trainer/Q1Pred Max                          313.685
trainer/Q1Pred Min                            9.65484
trainer/Q2Pred Mean                         206.46
trainer/Q2Pred Std                           70.4061
trainer/Q2Pred Max                          313.278
trainer/Q2Pred Min                            9.93751
trainer/QTargetWithReg Mean                 206.272
trainer/QTargetWithReg Std                   70.264
trainer/QTargetWithReg Max                  312.229
trainer/QTargetWithReg Min                    9.48952
trainer/PolicyLossWithoutReg Mean           207.248
trainer/PolicyLossWithoutReg Std             69.5138
trainer/PolicyLossWithoutReg Max            312.919
trainer/PolicyLossWithoutReg Min              9.95309
trainer/gradient_norm                       331.667
trainer/gradient_penalty                     -1.65833
trainer/gradient_percentage                  -0.0080017
exploration/num steps total              570000
exploration/num paths total                1726
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63916
exploration/Rewards Std                       1.23054
exploration/Rewards Max                       9.70127
exploration/Rewards Min                      -0.620816
exploration/Returns Mean                   4639.16
exploration/Returns Std                       0
exploration/Returns Max                    4639.16
exploration/Returns Min                    4639.16
exploration/Num Paths                         1
exploration/Average Returns                4639.16
evaluation_0/num steps total                  4.44233e+06
evaluation_0/num paths total              12560
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83009
evaluation_0/Rewards Std                      1.24312
evaluation_0/Rewards Max                      9.82641
evaluation_0/Rewards Min                     -0.796753
evaluation_0/Returns Mean                  4830.09
evaluation_0/Returns Std                     35.2738
evaluation_0/Returns Max                   4884.18
evaluation_0/Returns Min                   4763.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4830.09
time/epoch (s)                                0
time/total (s)                            11047.1
Epoch                                       565
---------------------------------------  ----------------
2022-11-16 13:50:09.151988 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 566 finished
---------------------------------------  ----------------
epoch                                       566
total_step                               571000
replay_pool/size                         571000
trainer/alpha                                 0.0665972
trainer/alpha_loss                            0.18013
trainer/entropy                              -6.06649
trainer/qf_loss                               5.73
trainer/state_noise                           0.005
trainer/policy_loss                        -211.63
trainer/policy_loss_without_entropy         213.723
trainer/entropy_penalty                      -0.404011
trainer/entropy_percentage                   -0.00189035
trainer/Q1Pred Mean                         212.456
trainer/Q1Pred Std                           71.0694
trainer/Q1Pred Max                          310.006
trainer/Q1Pred Min                           -3.29373
trainer/Q2Pred Mean                         212.717
trainer/Q2Pred Std                           71.0201
trainer/Q2Pred Max                          308.305
trainer/Q2Pred Min                           -3.57586
trainer/QTargetWithReg Mean                 212.787
trainer/QTargetWithReg Std                   70.7941
trainer/QTargetWithReg Max                  308.311
trainer/QTargetWithReg Min                    0.0844665
trainer/PolicyLossWithoutReg Mean           213.723
trainer/PolicyLossWithoutReg Std             70.2354
trainer/PolicyLossWithoutReg Max            308.853
trainer/PolicyLossWithoutReg Min             -3.0522
trainer/gradient_norm                       337.825
trainer/gradient_penalty                     -1.68912
trainer/gradient_percentage                  -0.00790332
exploration/num steps total              571000
exploration/num paths total                1727
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81793
exploration/Rewards Std                       1.23687
exploration/Rewards Max                       9.8118
exploration/Rewards Min                      -0.829064
exploration/Returns Mean                   4817.93
exploration/Returns Std                       0
exploration/Returns Max                    4817.93
exploration/Returns Min                    4817.93
exploration/Num Paths                         1
exploration/Average Returns                4817.93
evaluation_0/num steps total                  4.45033e+06
evaluation_0/num paths total              12568
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90713
evaluation_0/Rewards Std                      1.20123
evaluation_0/Rewards Max                      9.66117
evaluation_0/Rewards Min                     -0.644346
evaluation_0/Returns Mean                  4907.13
evaluation_0/Returns Std                     15.305
evaluation_0/Returns Max                   4921.72
evaluation_0/Returns Min                   4872.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4907.13
time/epoch (s)                                0
time/total (s)                            11062.9
Epoch                                       566
---------------------------------------  ----------------
2022-11-16 13:50:25.586367 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 567 finished
---------------------------------------  ----------------
epoch                                       567
total_step                               572000
replay_pool/size                         572000
trainer/alpha                                 0.0665551
trainer/alpha_loss                           -0.214986
trainer/entropy                              -5.92066
trainer/qf_loss                               6.68221
trainer/state_noise                           0.005
trainer/policy_loss                        -199.516
trainer/policy_loss_without_entropy         201.568
trainer/entropy_penalty                      -0.39405
trainer/entropy_percentage                   -0.00195493
trainer/Q1Pred Mean                         200.752
trainer/Q1Pred Std                           74.3756
trainer/Q1Pred Max                          309.064
trainer/Q1Pred Min                          -17.978
trainer/Q2Pred Mean                         200.613
trainer/Q2Pred Std                           74.1521
trainer/Q2Pred Max                          308.749
trainer/Q2Pred Min                          -15.5843
trainer/QTargetWithReg Mean                 200.902
trainer/QTargetWithReg Std                   74.1866
trainer/QTargetWithReg Max                  308.136
trainer/QTargetWithReg Min                  -12.3265
trainer/PolicyLossWithoutReg Mean           201.568
trainer/PolicyLossWithoutReg Std             73.5456
trainer/PolicyLossWithoutReg Max            308.641
trainer/PolicyLossWithoutReg Min            -14.8451
trainer/gradient_norm                       331.419
trainer/gradient_penalty                     -1.6571
trainer/gradient_percentage                  -0.00822104
exploration/num steps total              572000
exploration/num paths total                1728
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71649
exploration/Rewards Std                       1.20222
exploration/Rewards Max                       9.657
exploration/Rewards Min                      -0.588549
exploration/Returns Mean                   4716.49
exploration/Returns Std                       0
exploration/Returns Max                    4716.49
exploration/Returns Min                    4716.49
exploration/Num Paths                         1
exploration/Average Returns                4716.49
evaluation_0/num steps total                  4.45833e+06
evaluation_0/num paths total              12576
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69744
evaluation_0/Rewards Std                      1.30215
evaluation_0/Rewards Max                     10.0225
evaluation_0/Rewards Min                     -0.729516
evaluation_0/Returns Mean                  4697.44
evaluation_0/Returns Std                     62.0226
evaluation_0/Returns Max                   4791
evaluation_0/Returns Min                   4588.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4697.44
time/epoch (s)                                0
time/total (s)                            11079.4
Epoch                                       567
---------------------------------------  ----------------
2022-11-16 13:50:41.412332 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 568 finished
---------------------------------------  ----------------
epoch                                       568
total_step                               573000
replay_pool/size                         573000
trainer/alpha                                 0.0648833
trainer/alpha_loss                           -0.37669
trainer/entropy                              -5.86228
trainer/qf_loss                               8.01477
trainer/state_noise                           0.005
trainer/policy_loss                        -205.776
trainer/policy_loss_without_entropy         207.795
trainer/entropy_penalty                      -0.380364
trainer/entropy_percentage                   -0.00183048
trainer/Q1Pred Mean                         206.915
trainer/Q1Pred Std                           75.4471
trainer/Q1Pred Max                          310.914
trainer/Q1Pred Min                          -27.2839
trainer/Q2Pred Mean                         207.5
trainer/Q2Pred Std                           74.7833
trainer/Q2Pred Max                          311.144
trainer/Q2Pred Min                          -23.5621
trainer/QTargetWithReg Mean                 207.42
trainer/QTargetWithReg Std                   75.2416
trainer/QTargetWithReg Max                  311.91
trainer/QTargetWithReg Min                  -16.2983
trainer/PolicyLossWithoutReg Mean           207.795
trainer/PolicyLossWithoutReg Std             74.464
trainer/PolicyLossWithoutReg Max            310.501
trainer/PolicyLossWithoutReg Min            -21.6305
trainer/gradient_norm                       327.74
trainer/gradient_penalty                     -1.6387
trainer/gradient_percentage                  -0.00788613
exploration/num steps total              573000
exploration/num paths total                1729
exploration/path length this epoch Mean     171
exploration/path length this epoch Std        0
exploration/path length this epoch Max      171
exploration/path length this epoch Min      171
exploration/Rewards Mean                      3.38835
exploration/Rewards Std                       1.37832
exploration/Rewards Max                       6.45022
exploration/Rewards Min                      -0.81198
exploration/Returns Mean                    579.408
exploration/Returns Std                       0
exploration/Returns Max                     579.408
exploration/Returns Min                     579.408
exploration/Num Paths                         1
exploration/Average Returns                 579.408
evaluation_0/num steps total                  4.46633e+06
evaluation_0/num paths total              12584
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87373
evaluation_0/Rewards Std                      1.16459
evaluation_0/Rewards Max                      9.67414
evaluation_0/Rewards Min                     -0.67717
evaluation_0/Returns Mean                  4873.73
evaluation_0/Returns Std                     12.3062
evaluation_0/Returns Max                   4890.79
evaluation_0/Returns Min                   4849.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4873.73
time/epoch (s)                                0
time/total (s)                            11095.2
Epoch                                       568
---------------------------------------  ----------------
2022-11-16 13:50:57.821401 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 569 finished
---------------------------------------  ----------------
epoch                                       569
total_step                               574000
replay_pool/size                         574000
trainer/alpha                                 0.0666597
trainer/alpha_loss                           -0.0135284
trainer/entropy                              -5.995
trainer/qf_loss                               9.71455
trainer/state_noise                           0.005
trainer/policy_loss                        -201.617
trainer/policy_loss_without_entropy         203.699
trainer/entropy_penalty                      -0.399625
trainer/entropy_percentage                   -0.00196184
trainer/Q1Pred Mean                         203.061
trainer/Q1Pred Std                           76.0102
trainer/Q1Pred Max                          316.298
trainer/Q1Pred Min                           -8.93227
trainer/Q2Pred Mean                         203.232
trainer/Q2Pred Std                           75.6978
trainer/Q2Pred Max                          315.299
trainer/Q2Pred Min                           -8.79954
trainer/QTargetWithReg Mean                 202.319
trainer/QTargetWithReg Std                   75.7874
trainer/QTargetWithReg Max                  315.886
trainer/QTargetWithReg Min                  -21.9339
trainer/PolicyLossWithoutReg Mean           203.699
trainer/PolicyLossWithoutReg Std             74.8493
trainer/PolicyLossWithoutReg Max            315.484
trainer/PolicyLossWithoutReg Min            -13.3893
trainer/gradient_norm                       336.473
trainer/gradient_penalty                     -1.68237
trainer/gradient_percentage                  -0.00825907
exploration/num steps total              574000
exploration/num paths total                1730
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81275
exploration/Rewards Std                       1.17191
exploration/Rewards Max                       9.71439
exploration/Rewards Min                      -0.656792
exploration/Returns Mean                   4812.75
exploration/Returns Std                       0
exploration/Returns Max                    4812.75
exploration/Returns Min                    4812.75
exploration/Num Paths                         1
exploration/Average Returns                4812.75
evaluation_0/num steps total                  4.47433e+06
evaluation_0/num paths total              12592
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92108
evaluation_0/Rewards Std                      1.18742
evaluation_0/Rewards Max                      9.7131
evaluation_0/Rewards Min                     -0.626494
evaluation_0/Returns Mean                  4921.08
evaluation_0/Returns Std                     10.1978
evaluation_0/Returns Max                   4937.67
evaluation_0/Returns Min                   4904.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4921.08
time/epoch (s)                                0
time/total (s)                            11111.6
Epoch                                       569
---------------------------------------  ----------------
2022-11-16 13:51:13.647289 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 570 finished
---------------------------------------  ----------------
epoch                                       570
total_step                               575000
replay_pool/size                         575000
trainer/alpha                                 0.0660603
trainer/alpha_loss                           -0.543997
trainer/entropy                              -5.7998
trainer/qf_loss                              10.0173
trainer/state_noise                           0.005
trainer/policy_loss                        -208.33
trainer/policy_loss_without_entropy         210.298
trainer/entropy_penalty                      -0.383137
trainer/entropy_percentage                   -0.00182188
trainer/Q1Pred Mean                         210.194
trainer/Q1Pred Std                           75.9812
trainer/Q1Pred Max                          311.419
trainer/Q1Pred Min                            3.91222
trainer/Q2Pred Mean                         210.096
trainer/Q2Pred Std                           75.9536
trainer/Q2Pred Max                          311.447
trainer/Q2Pred Min                            2.13024
trainer/QTargetWithReg Mean                 209.819
trainer/QTargetWithReg Std                   76.603
trainer/QTargetWithReg Max                  310.777
trainer/QTargetWithReg Min                    1.17241
trainer/PolicyLossWithoutReg Mean           210.298
trainer/PolicyLossWithoutReg Std             75.3679
trainer/PolicyLossWithoutReg Max            311.49
trainer/PolicyLossWithoutReg Min              4.11694
trainer/gradient_norm                       316.909
trainer/gradient_penalty                     -1.58455
trainer/gradient_percentage                  -0.00753478
exploration/num steps total              575000
exploration/num paths total                1731
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91069
exploration/Rewards Std                       1.23246
exploration/Rewards Max                       9.92389
exploration/Rewards Min                      -0.587397
exploration/Returns Mean                   4910.69
exploration/Returns Std                       0
exploration/Returns Max                    4910.69
exploration/Returns Min                    4910.69
exploration/Num Paths                         1
exploration/Average Returns                4910.69
evaluation_0/num steps total                  4.48233e+06
evaluation_0/num paths total              12600
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91274
evaluation_0/Rewards Std                      1.2234
evaluation_0/Rewards Max                      9.87972
evaluation_0/Rewards Min                     -0.675996
evaluation_0/Returns Mean                  4912.74
evaluation_0/Returns Std                     46.3765
evaluation_0/Returns Max                   4979.21
evaluation_0/Returns Min                   4840.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4912.74
time/epoch (s)                                0
time/total (s)                            11127.4
Epoch                                       570
---------------------------------------  ----------------
2022-11-16 13:51:29.626676 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 571 finished
---------------------------------------  ----------------
epoch                                       571
total_step                               576000
replay_pool/size                         576000
trainer/alpha                                 0.0652088
trainer/alpha_loss                           -0.702505
trainer/entropy                              -5.74268
trainer/qf_loss                               5.55161
trainer/state_noise                           0.005
trainer/policy_loss                        -207.027
trainer/policy_loss_without_entropy         209.019
trainer/entropy_penalty                      -0.374473
trainer/entropy_percentage                   -0.00179157
trainer/Q1Pred Mean                         208.374
trainer/Q1Pred Std                           74.8399
trainer/Q1Pred Max                          316.383
trainer/Q1Pred Min                          -16.8495
trainer/Q2Pred Mean                         208.614
trainer/Q2Pred Std                           74.7369
trainer/Q2Pred Max                          314.96
trainer/Q2Pred Min                          -23.0388
trainer/QTargetWithReg Mean                 208.534
trainer/QTargetWithReg Std                   74.559
trainer/QTargetWithReg Max                  314.107
trainer/QTargetWithReg Min                  -22.4493
trainer/PolicyLossWithoutReg Mean           209.019
trainer/PolicyLossWithoutReg Std             74.2568
trainer/PolicyLossWithoutReg Max            314.798
trainer/PolicyLossWithoutReg Min            -19.2714
trainer/gradient_norm                       323.622
trainer/gradient_penalty                     -1.61811
trainer/gradient_percentage                  -0.00774145
exploration/num steps total              576000
exploration/num paths total                1732
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91925
exploration/Rewards Std                       1.21092
exploration/Rewards Max                       9.95668
exploration/Rewards Min                      -0.495826
exploration/Returns Mean                   4919.25
exploration/Returns Std                       0
exploration/Returns Max                    4919.25
exploration/Returns Min                    4919.25
exploration/Num Paths                         1
exploration/Average Returns                4919.25
evaluation_0/num steps total                  4.49033e+06
evaluation_0/num paths total              12608
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.57083
evaluation_0/Rewards Std                      1.26495
evaluation_0/Rewards Max                      9.62373
evaluation_0/Rewards Min                     -0.685911
evaluation_0/Returns Mean                  4570.83
evaluation_0/Returns Std                    140.683
evaluation_0/Returns Max                   4707.25
evaluation_0/Returns Min                   4331.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4570.83
time/epoch (s)                                0
time/total (s)                            11143.4
Epoch                                       571
---------------------------------------  ----------------
2022-11-16 13:51:45.886009 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 572 finished
---------------------------------------  ----------------
epoch                                       572
total_step                               577000
replay_pool/size                         577000
trainer/alpha                                 0.0679689
trainer/alpha_loss                           -0.0701193
trainer/entropy                              -5.97392
trainer/qf_loss                               8.89861
trainer/state_noise                           0.005
trainer/policy_loss                        -201.43
trainer/policy_loss_without_entropy         203.51
trainer/entropy_penalty                      -0.406041
trainer/entropy_percentage                   -0.00199519
trainer/Q1Pred Mean                         202.592
trainer/Q1Pred Std                           72.8646
trainer/Q1Pred Max                          313.592
trainer/Q1Pred Min                          -40.835
trainer/Q2Pred Mean                         202.729
trainer/Q2Pred Std                           72.9639
trainer/Q2Pred Max                          314.452
trainer/Q2Pred Min                          -38.7233
trainer/QTargetWithReg Mean                 202.907
trainer/QTargetWithReg Std                   73.4104
trainer/QTargetWithReg Max                  313.642
trainer/QTargetWithReg Min                  -36.2441
trainer/PolicyLossWithoutReg Mean           203.51
trainer/PolicyLossWithoutReg Std             72.3752
trainer/PolicyLossWithoutReg Max            313.871
trainer/PolicyLossWithoutReg Min            -41.9601
trainer/gradient_norm                       334.891
trainer/gradient_penalty                     -1.67445
trainer/gradient_percentage                  -0.00822787
exploration/num steps total              577000
exploration/num paths total                1733
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.58441
exploration/Rewards Std                       1.24338
exploration/Rewards Max                       9.56017
exploration/Rewards Min                      -0.661921
exploration/Returns Mean                   4584.41
exploration/Returns Std                       0
exploration/Returns Max                    4584.41
exploration/Returns Min                    4584.41
exploration/Num Paths                         1
exploration/Average Returns                4584.41
evaluation_0/num steps total                  4.49833e+06
evaluation_0/num paths total              12616
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80474
evaluation_0/Rewards Std                      1.25278
evaluation_0/Rewards Max                     10.0741
evaluation_0/Rewards Min                     -0.715211
evaluation_0/Returns Mean                  4804.74
evaluation_0/Returns Std                     39.5979
evaluation_0/Returns Max                   4861.26
evaluation_0/Returns Min                   4742.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4804.74
time/epoch (s)                                0
time/total (s)                            11159.7
Epoch                                       572
---------------------------------------  ----------------
2022-11-16 13:52:01.736594 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 573 finished
---------------------------------------  ----------------
epoch                                       573
total_step                               578000
replay_pool/size                         578000
trainer/alpha                                 0.0658832
trainer/alpha_loss                            0.152855
trainer/entropy                              -6.0562
trainer/qf_loss                               9.65161
trainer/state_noise                           0.005
trainer/policy_loss                        -207.535
trainer/policy_loss_without_entropy         209.654
trainer/entropy_penalty                      -0.399002
trainer/entropy_percentage                   -0.00190314
trainer/Q1Pred Mean                         209.119
trainer/Q1Pred Std                           75.524
trainer/Q1Pred Max                          309.643
trainer/Q1Pred Min                            0.962169
trainer/Q2Pred Mean                         208.919
trainer/Q2Pred Std                           75.6734
trainer/Q2Pred Max                          309.014
trainer/Q2Pred Min                            7.29946
trainer/QTargetWithReg Mean                 209.093
trainer/QTargetWithReg Std                   75.5302
trainer/QTargetWithReg Max                  309.385
trainer/QTargetWithReg Min                    2.78617
trainer/PolicyLossWithoutReg Mean           209.654
trainer/PolicyLossWithoutReg Std             74.6039
trainer/PolicyLossWithoutReg Max            308.929
trainer/PolicyLossWithoutReg Min              9.67015
trainer/gradient_norm                       343.966
trainer/gradient_penalty                     -1.71983
trainer/gradient_percentage                  -0.00820319
exploration/num steps total              578000
exploration/num paths total                1734
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80045
exploration/Rewards Std                       1.283
exploration/Rewards Max                       9.91084
exploration/Rewards Min                      -0.700614
exploration/Returns Mean                   4800.45
exploration/Returns Std                       0
exploration/Returns Max                    4800.45
exploration/Returns Min                    4800.45
exploration/Num Paths                         1
exploration/Average Returns                4800.45
evaluation_0/num steps total                  4.50633e+06
evaluation_0/num paths total              12624
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98748
evaluation_0/Rewards Std                      1.29557
evaluation_0/Rewards Max                     10.1448
evaluation_0/Rewards Min                     -0.718964
evaluation_0/Returns Mean                  4987.48
evaluation_0/Returns Std                     35.0578
evaluation_0/Returns Max                   5039.37
evaluation_0/Returns Min                   4915.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4987.48
time/epoch (s)                                0
time/total (s)                            11175.5
Epoch                                       573
---------------------------------------  ----------------
2022-11-16 13:52:18.148343 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 574 finished
---------------------------------------  ----------------
epoch                                       574
total_step                               579000
replay_pool/size                         579000
trainer/alpha                                 0.0658388
trainer/alpha_loss                            0.526781
trainer/entropy                              -6.19362
trainer/qf_loss                               8.34674
trainer/state_noise                           0.005
trainer/policy_loss                        -201.607
trainer/policy_loss_without_entropy         203.653
trainer/entropy_penalty                      -0.407781
trainer/entropy_percentage                   -0.00200233
trainer/Q1Pred Mean                         202.981
trainer/Q1Pred Std                           76.0633
trainer/Q1Pred Max                          312.132
trainer/Q1Pred Min                          -14.8883
trainer/Q2Pred Mean                         202.811
trainer/Q2Pred Std                           76.0237
trainer/Q2Pred Max                          311.207
trainer/Q2Pred Min                           -9.70783
trainer/QTargetWithReg Mean                 203.05
trainer/QTargetWithReg Std                   76.5573
trainer/QTargetWithReg Max                  312.68
trainer/QTargetWithReg Min                  -22.5576
trainer/PolicyLossWithoutReg Mean           203.653
trainer/PolicyLossWithoutReg Std             75.2613
trainer/PolicyLossWithoutReg Max            311.173
trainer/PolicyLossWithoutReg Min            -15.8495
trainer/gradient_norm                       327.549
trainer/gradient_penalty                     -1.63774
trainer/gradient_percentage                  -0.00804185
exploration/num steps total              579000
exploration/num paths total                1735
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84081
exploration/Rewards Std                       1.20665
exploration/Rewards Max                       9.69422
exploration/Rewards Min                      -0.618299
exploration/Returns Mean                   4840.81
exploration/Returns Std                       0
exploration/Returns Max                    4840.81
exploration/Returns Min                    4840.81
exploration/Num Paths                         1
exploration/Average Returns                4840.81
evaluation_0/num steps total                  4.51433e+06
evaluation_0/num paths total              12632
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92609
evaluation_0/Rewards Std                      1.29849
evaluation_0/Rewards Max                     10.0725
evaluation_0/Rewards Min                     -0.632038
evaluation_0/Returns Mean                  4926.09
evaluation_0/Returns Std                     25.4067
evaluation_0/Returns Max                   4975.88
evaluation_0/Returns Min                   4890.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4926.09
time/epoch (s)                                0
time/total (s)                            11191.9
Epoch                                       574
---------------------------------------  ----------------
2022-11-16 13:52:34.027043 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 575 finished
---------------------------------------  ----------------
epoch                                       575
total_step                               580000
replay_pool/size                         580000
trainer/alpha                                 0.0671043
trainer/alpha_loss                           -1.80906
trainer/entropy                              -5.33035
trainer/qf_loss                               6.11125
trainer/state_noise                           0.005
trainer/policy_loss                        -219.781
trainer/policy_loss_without_entropy         221.799
trainer/entropy_penalty                      -0.35769
trainer/entropy_percentage                   -0.00161268
trainer/Q1Pred Mean                         221.94
trainer/Q1Pred Std                           70.3547
trainer/Q1Pred Max                          310.873
trainer/Q1Pred Min                            9.20544
trainer/Q2Pred Mean                         221.419
trainer/Q2Pred Std                           70.3084
trainer/Q2Pred Max                          309.89
trainer/Q2Pred Min                           10.41
trainer/QTargetWithReg Mean                 221.603
trainer/QTargetWithReg Std                   70.2799
trainer/QTargetWithReg Max                  308.588
trainer/QTargetWithReg Min                   10.0796
trainer/PolicyLossWithoutReg Mean           221.799
trainer/PolicyLossWithoutReg Std             69.7578
trainer/PolicyLossWithoutReg Max            309.543
trainer/PolicyLossWithoutReg Min              8.76455
trainer/gradient_norm                       331.945
trainer/gradient_penalty                     -1.65973
trainer/gradient_percentage                  -0.00748303
exploration/num steps total              580000
exploration/num paths total                1736
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85116
exploration/Rewards Std                       1.23637
exploration/Rewards Max                       9.91866
exploration/Rewards Min                      -0.499128
exploration/Returns Mean                   4851.16
exploration/Returns Std                       0
exploration/Returns Max                    4851.16
exploration/Returns Min                    4851.16
exploration/Num Paths                         1
exploration/Average Returns                4851.16
evaluation_0/num steps total                  4.52233e+06
evaluation_0/num paths total              12640
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00445
evaluation_0/Rewards Std                      1.2624
evaluation_0/Rewards Max                      9.98909
evaluation_0/Rewards Min                     -0.675917
evaluation_0/Returns Mean                  5004.45
evaluation_0/Returns Std                     27.0544
evaluation_0/Returns Max                   5047.87
evaluation_0/Returns Min                   4960.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5004.45
time/epoch (s)                                0
time/total (s)                            11207.8
Epoch                                       575
---------------------------------------  ----------------
2022-11-16 13:52:50.533178 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 576 finished
---------------------------------------  ----------------
epoch                                       576
total_step                               581000
replay_pool/size                         581000
trainer/alpha                                 0.0661159
trainer/alpha_loss                            0.943856
trainer/entropy                              -6.34744
trainer/qf_loss                               7.63568
trainer/state_noise                           0.005
trainer/policy_loss                        -202.493
trainer/policy_loss_without_entropy         204.589
trainer/entropy_penalty                      -0.419667
trainer/entropy_percentage                   -0.00205127
trainer/Q1Pred Mean                         203.445
trainer/Q1Pred Std                           74.2112
trainer/Q1Pred Max                          311.777
trainer/Q1Pred Min                          -17.2178
trainer/Q2Pred Mean                         203.447
trainer/Q2Pred Std                           74.605
trainer/Q2Pred Max                          309.686
trainer/Q2Pred Min                          -29.3248
trainer/QTargetWithReg Mean                 203.467
trainer/QTargetWithReg Std                   74.3539
trainer/QTargetWithReg Max                  310.851
trainer/QTargetWithReg Min                  -17.8976
trainer/PolicyLossWithoutReg Mean           204.589
trainer/PolicyLossWithoutReg Std             73.5168
trainer/PolicyLossWithoutReg Max            309.83
trainer/PolicyLossWithoutReg Min            -21.2126
trainer/gradient_norm                       335.136
trainer/gradient_penalty                     -1.67568
trainer/gradient_percentage                  -0.00819048
exploration/num steps total              581000
exploration/num paths total                1737
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89132
exploration/Rewards Std                       1.22285
exploration/Rewards Max                       9.97383
exploration/Rewards Min                      -0.539341
exploration/Returns Mean                   4891.32
exploration/Returns Std                       0
exploration/Returns Max                    4891.32
exploration/Returns Min                    4891.32
exploration/Num Paths                         1
exploration/Average Returns                4891.32
evaluation_0/num steps total                  4.53033e+06
evaluation_0/num paths total              12648
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75442
evaluation_0/Rewards Std                      1.28489
evaluation_0/Rewards Max                      9.93849
evaluation_0/Rewards Min                     -0.609459
evaluation_0/Returns Mean                  4754.42
evaluation_0/Returns Std                     46.4926
evaluation_0/Returns Max                   4822.57
evaluation_0/Returns Min                   4675.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4754.42
time/epoch (s)                                0
time/total (s)                            11224.3
Epoch                                       576
---------------------------------------  ----------------
2022-11-16 13:53:06.342198 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 577 finished
---------------------------------------  ----------------
epoch                                       577
total_step                               582000
replay_pool/size                         582000
trainer/alpha                                 0.0648689
trainer/alpha_loss                           -0.744036
trainer/entropy                              -5.728
trainer/qf_loss                               6.45014
trainer/state_noise                           0.005
trainer/policy_loss                        -208.668
trainer/policy_loss_without_entropy         210.731
trainer/entropy_penalty                      -0.371569
trainer/entropy_percentage                   -0.00176324
trainer/Q1Pred Mean                         209.952
trainer/Q1Pred Std                           73.6679
trainer/Q1Pred Max                          314.195
trainer/Q1Pred Min                            4.84197
trainer/Q2Pred Mean                         210.232
trainer/Q2Pred Std                           73.6475
trainer/Q2Pred Max                          314.784
trainer/Q2Pred Min                            5.37154
trainer/QTargetWithReg Mean                 210.023
trainer/QTargetWithReg Std                   73.8388
trainer/QTargetWithReg Max                  313.715
trainer/QTargetWithReg Min                    4.90014
trainer/PolicyLossWithoutReg Mean           210.731
trainer/PolicyLossWithoutReg Std             72.9508
trainer/PolicyLossWithoutReg Max            313.594
trainer/PolicyLossWithoutReg Min              5.12858
trainer/gradient_norm                       338.201
trainer/gradient_penalty                     -1.691
trainer/gradient_percentage                  -0.00802448
exploration/num steps total              582000
exploration/num paths total                1738
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61158
exploration/Rewards Std                       1.33413
exploration/Rewards Max                       9.97225
exploration/Rewards Min                      -0.619062
exploration/Returns Mean                   4611.58
exploration/Returns Std                       0
exploration/Returns Max                    4611.58
exploration/Returns Min                    4611.58
exploration/Num Paths                         1
exploration/Average Returns                4611.58
evaluation_0/num steps total                  4.53833e+06
evaluation_0/num paths total              12656
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67531
evaluation_0/Rewards Std                      1.27305
evaluation_0/Rewards Max                     10.1076
evaluation_0/Rewards Min                     -0.705141
evaluation_0/Returns Mean                  4675.31
evaluation_0/Returns Std                     36.9287
evaluation_0/Returns Max                   4727.98
evaluation_0/Returns Min                   4605.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.31
time/epoch (s)                                0
time/total (s)                            11240.1
Epoch                                       577
---------------------------------------  ----------------
2022-11-16 13:53:22.761688 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 578 finished
---------------------------------------  ----------------
epoch                                       578
total_step                               583000
replay_pool/size                         583000
trainer/alpha                                 0.0654916
trainer/alpha_loss                           -0.180726
trainer/entropy                              -5.9337
trainer/qf_loss                               7.667
trainer/state_noise                           0.005
trainer/policy_loss                        -203.492
trainer/policy_loss_without_entropy         205.598
trainer/entropy_penalty                      -0.388608
trainer/entropy_percentage                   -0.00189013
trainer/Q1Pred Mean                         204.352
trainer/Q1Pred Std                           73.9073
trainer/Q1Pred Max                          308.313
trainer/Q1Pred Min                           -1.92478
trainer/Q2Pred Mean                         204.557
trainer/Q2Pred Std                           73.7425
trainer/Q2Pred Max                          307.448
trainer/Q2Pred Min                           -3.02002
trainer/QTargetWithReg Mean                 204.913
trainer/QTargetWithReg Std                   73.8218
trainer/QTargetWithReg Max                  308.054
trainer/QTargetWithReg Min                   -1.29636
trainer/PolicyLossWithoutReg Mean           205.598
trainer/PolicyLossWithoutReg Std             72.6805
trainer/PolicyLossWithoutReg Max            307.945
trainer/PolicyLossWithoutReg Min             -1.92864
trainer/gradient_norm                       343.495
trainer/gradient_penalty                     -1.71748
trainer/gradient_percentage                  -0.00835356
exploration/num steps total              583000
exploration/num paths total                1739
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83374
exploration/Rewards Std                       1.29942
exploration/Rewards Max                      10.2505
exploration/Rewards Min                      -0.795522
exploration/Returns Mean                   4833.74
exploration/Returns Std                       0
exploration/Returns Max                    4833.74
exploration/Returns Min                    4833.74
exploration/Num Paths                         1
exploration/Average Returns                4833.74
evaluation_0/num steps total                  4.54633e+06
evaluation_0/num paths total              12664
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9384
evaluation_0/Rewards Std                      1.29402
evaluation_0/Rewards Max                     10.0808
evaluation_0/Rewards Min                     -0.755573
evaluation_0/Returns Mean                  4938.4
evaluation_0/Returns Std                     12.5637
evaluation_0/Returns Max                   4954.27
evaluation_0/Returns Min                   4918.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4938.4
time/epoch (s)                                0
time/total (s)                            11256.6
Epoch                                       578
---------------------------------------  ----------------
2022-11-16 13:53:38.604606 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 579 finished
---------------------------------------  ----------------
epoch                                       579
total_step                               584000
replay_pool/size                         584000
trainer/alpha                                 0.0663668
trainer/alpha_loss                           -0.112084
trainer/entropy                              -5.95868
trainer/qf_loss                               8.31071
trainer/state_noise                           0.005
trainer/policy_loss                        -211.964
trainer/policy_loss_without_entropy         214.021
trainer/entropy_penalty                      -0.395459
trainer/entropy_percentage                   -0.00184775
trainer/Q1Pred Mean                         213.17
trainer/Q1Pred Std                           72.7823
trainer/Q1Pred Max                          309.673
trainer/Q1Pred Min                            2.95217
trainer/Q2Pred Mean                         213.195
trainer/Q2Pred Std                           72.7654
trainer/Q2Pred Max                          308.829
trainer/Q2Pred Min                            1.30107
trainer/QTargetWithReg Mean                 213.202
trainer/QTargetWithReg Std                   72.761
trainer/QTargetWithReg Max                  307.904
trainer/QTargetWithReg Min                    0.533091
trainer/PolicyLossWithoutReg Mean           214.021
trainer/PolicyLossWithoutReg Std             72.0099
trainer/PolicyLossWithoutReg Max            309.417
trainer/PolicyLossWithoutReg Min              3.81867
trainer/gradient_norm                       332.348
trainer/gradient_penalty                     -1.66174
trainer/gradient_percentage                  -0.00776437
exploration/num steps total              584000
exploration/num paths total                1740
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75921
exploration/Rewards Std                       1.32085
exploration/Rewards Max                      10.1672
exploration/Rewards Min                      -0.823533
exploration/Returns Mean                   4759.21
exploration/Returns Std                       0
exploration/Returns Max                    4759.21
exploration/Returns Min                    4759.21
exploration/Num Paths                         1
exploration/Average Returns                4759.21
evaluation_0/num steps total                  4.55433e+06
evaluation_0/num paths total              12672
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87737
evaluation_0/Rewards Std                      1.2271
evaluation_0/Rewards Max                      9.96008
evaluation_0/Rewards Min                     -0.644002
evaluation_0/Returns Mean                  4877.37
evaluation_0/Returns Std                     52.4754
evaluation_0/Returns Max                   4935.59
evaluation_0/Returns Min                   4771.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4877.37
time/epoch (s)                                0
time/total (s)                            11272.4
Epoch                                       579
---------------------------------------  ----------------
2022-11-16 13:53:55.074907 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 580 finished
---------------------------------------  ----------------
epoch                                       580
total_step                               585000
replay_pool/size                         585000
trainer/alpha                                 0.0662405
trainer/alpha_loss                           -1.64594
trainer/entropy                              -5.39367
trainer/qf_loss                               7.54078
trainer/state_noise                           0.005
trainer/policy_loss                        -210.211
trainer/policy_loss_without_entropy         212.225
trainer/entropy_penalty                      -0.35728
trainer/entropy_percentage                   -0.00168349
trainer/Q1Pred Mean                         211.209
trainer/Q1Pred Std                           74.232
trainer/Q1Pred Max                          316.191
trainer/Q1Pred Min                          -15.0428
trainer/Q2Pred Mean                         211.264
trainer/Q2Pred Std                           74.2465
trainer/Q2Pred Max                          314.302
trainer/Q2Pred Min                          -24.711
trainer/QTargetWithReg Mean                 212.087
trainer/QTargetWithReg Std                   73.9399
trainer/QTargetWithReg Max                  315.917
trainer/QTargetWithReg Min                  -11.0539
trainer/PolicyLossWithoutReg Mean           212.225
trainer/PolicyLossWithoutReg Std             73.8889
trainer/PolicyLossWithoutReg Max            315.36
trainer/PolicyLossWithoutReg Min            -27.5777
trainer/gradient_norm                       331.445
trainer/gradient_penalty                     -1.65722
trainer/gradient_percentage                  -0.00780879
exploration/num steps total              585000
exploration/num paths total                1741
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76102
exploration/Rewards Std                       1.22727
exploration/Rewards Max                       9.94369
exploration/Rewards Min                      -0.517996
exploration/Returns Mean                   4761.02
exploration/Returns Std                       0
exploration/Returns Max                    4761.02
exploration/Returns Min                    4761.02
exploration/Num Paths                         1
exploration/Average Returns                4761.02
evaluation_0/num steps total                  4.56233e+06
evaluation_0/num paths total              12680
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95587
evaluation_0/Rewards Std                      1.22857
evaluation_0/Rewards Max                     10.058
evaluation_0/Rewards Min                     -0.518258
evaluation_0/Returns Mean                  4955.87
evaluation_0/Returns Std                     28.0333
evaluation_0/Returns Max                   4997.78
evaluation_0/Returns Min                   4920.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4955.87
time/epoch (s)                                0
time/total (s)                            11288.9
Epoch                                       580
---------------------------------------  ----------------
2022-11-16 13:54:10.956645 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 581 finished
---------------------------------------  ----------------
epoch                                       581
total_step                               586000
replay_pool/size                         586000
trainer/alpha                                 0.0645565
trainer/alpha_loss                            0.37999
trainer/entropy                              -6.13866
trainer/qf_loss                               7.40728
trainer/state_noise                           0.005
trainer/policy_loss                        -207.07
trainer/policy_loss_without_entropy         209.166
trainer/entropy_penalty                      -0.39629
trainer/entropy_percentage                   -0.00189462
trainer/Q1Pred Mean                         207.909
trainer/Q1Pred Std                           75.1493
trainer/Q1Pred Max                          312.433
trainer/Q1Pred Min                           -4.79599
trainer/Q2Pred Mean                         208.693
trainer/Q2Pred Std                           75.2847
trainer/Q2Pred Max                          314.112
trainer/Q2Pred Min                           -5.38069
trainer/QTargetWithReg Mean                 207.905
trainer/QTargetWithReg Std                   75.0158
trainer/QTargetWithReg Max                  312.096
trainer/QTargetWithReg Min                   -0.342174
trainer/PolicyLossWithoutReg Mean           209.166
trainer/PolicyLossWithoutReg Std             74.0698
trainer/PolicyLossWithoutReg Max            313.094
trainer/PolicyLossWithoutReg Min             11.2502
trainer/gradient_norm                       339.852
trainer/gradient_penalty                     -1.69926
trainer/gradient_percentage                  -0.00812397
exploration/num steps total              586000
exploration/num paths total                1742
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55463
exploration/Rewards Std                       1.21272
exploration/Rewards Max                       9.7239
exploration/Rewards Min                      -0.622686
exploration/Returns Mean                   4554.63
exploration/Returns Std                       0
exploration/Returns Max                    4554.63
exploration/Returns Min                    4554.63
exploration/Num Paths                         1
exploration/Average Returns                4554.63
evaluation_0/num steps total                  4.57033e+06
evaluation_0/num paths total              12688
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.66058
evaluation_0/Rewards Std                      1.23556
evaluation_0/Rewards Max                      9.95431
evaluation_0/Rewards Min                     -0.725637
evaluation_0/Returns Mean                  4660.58
evaluation_0/Returns Std                     54.9193
evaluation_0/Returns Max                   4714.77
evaluation_0/Returns Min                   4567.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4660.58
time/epoch (s)                                0
time/total (s)                            11304.7
Epoch                                       581
---------------------------------------  ----------------
2022-11-16 13:54:27.259649 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 582 finished
---------------------------------------  ----------------
epoch                                       582
total_step                               587000
replay_pool/size                         587000
trainer/alpha                                 0.065307
trainer/alpha_loss                           -0.615509
trainer/entropy                              -5.77443
trainer/qf_loss                               9.15377
trainer/state_noise                           0.005
trainer/policy_loss                        -212.965
trainer/policy_loss_without_entropy         215.061
trainer/entropy_penalty                      -0.37711
trainer/entropy_percentage                   -0.00175351
trainer/Q1Pred Mean                         214.691
trainer/Q1Pred Std                           67.2669
trainer/Q1Pred Max                          307.849
trainer/Q1Pred Min                           23.391
trainer/Q2Pred Mean                         214.167
trainer/Q2Pred Std                           67.4143
trainer/Q2Pred Max                          309.02
trainer/Q2Pred Min                           22.4369
trainer/QTargetWithReg Mean                 214.524
trainer/QTargetWithReg Std                   67.4349
trainer/QTargetWithReg Max                  308.548
trainer/QTargetWithReg Min                   24.2221
trainer/PolicyLossWithoutReg Mean           215.061
trainer/PolicyLossWithoutReg Std             66.5073
trainer/PolicyLossWithoutReg Max            308.587
trainer/PolicyLossWithoutReg Min             21.789
trainer/gradient_norm                       343.783
trainer/gradient_penalty                     -1.71892
trainer/gradient_percentage                  -0.0079927
exploration/num steps total              587000
exploration/num paths total                1743
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87087
exploration/Rewards Std                       1.23995
exploration/Rewards Max                      10.066
exploration/Rewards Min                      -0.621869
exploration/Returns Mean                   4870.87
exploration/Returns Std                       0
exploration/Returns Max                    4870.87
exploration/Returns Min                    4870.87
exploration/Num Paths                         1
exploration/Average Returns                4870.87
evaluation_0/num steps total                  4.57833e+06
evaluation_0/num paths total              12696
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.80765
evaluation_0/Rewards Std                      1.18347
evaluation_0/Rewards Max                      9.83483
evaluation_0/Rewards Min                     -0.686177
evaluation_0/Returns Mean                  4807.65
evaluation_0/Returns Std                     36.6898
evaluation_0/Returns Max                   4866.42
evaluation_0/Returns Min                   4762.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4807.65
time/epoch (s)                                0
time/total (s)                            11321
Epoch                                       582
---------------------------------------  ----------------
2022-11-16 13:54:43.260145 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 583 finished
---------------------------------------  ----------------
epoch                                       583
total_step                               588000
replay_pool/size                         588000
trainer/alpha                                 0.0667153
trainer/alpha_loss                           -0.493653
trainer/entropy                              -5.81766
trainer/qf_loss                               6.35004
trainer/state_noise                           0.005
trainer/policy_loss                        -205.108
trainer/policy_loss_without_entropy         207.158
trainer/entropy_penalty                      -0.388127
trainer/entropy_percentage                   -0.00187358
trainer/Q1Pred Mean                         206.6
trainer/Q1Pred Std                           74.9716
trainer/Q1Pred Max                          308.83
trainer/Q1Pred Min                           -8.51713
trainer/Q2Pred Mean                         206.828
trainer/Q2Pred Std                           74.7142
trainer/Q2Pred Max                          308.213
trainer/Q2Pred Min                           -3.92597
trainer/QTargetWithReg Mean                 206.288
trainer/QTargetWithReg Std                   74.9173
trainer/QTargetWithReg Max                  308.671
trainer/QTargetWithReg Min                   -0.615339
trainer/PolicyLossWithoutReg Mean           207.158
trainer/PolicyLossWithoutReg Std             74.2528
trainer/PolicyLossWithoutReg Max            307.712
trainer/PolicyLossWithoutReg Min             -6.91754
trainer/gradient_norm                       332.284
trainer/gradient_penalty                     -1.66142
trainer/gradient_percentage                  -0.00802009
exploration/num steps total              588000
exploration/num paths total                1744
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82488
exploration/Rewards Std                       1.25134
exploration/Rewards Max                       9.81414
exploration/Rewards Min                      -0.62932
exploration/Returns Mean                   4824.88
exploration/Returns Std                       0
exploration/Returns Max                    4824.88
exploration/Returns Min                    4824.88
exploration/Num Paths                         1
exploration/Average Returns                4824.88
evaluation_0/num steps total                  4.58633e+06
evaluation_0/num paths total              12704
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78366
evaluation_0/Rewards Std                      1.19618
evaluation_0/Rewards Max                      9.80237
evaluation_0/Rewards Min                     -0.669467
evaluation_0/Returns Mean                  4783.66
evaluation_0/Returns Std                     17.4776
evaluation_0/Returns Max                   4813.03
evaluation_0/Returns Min                   4755.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4783.66
time/epoch (s)                                0
time/total (s)                            11337
Epoch                                       583
---------------------------------------  ----------------
2022-11-16 13:54:59.085203 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 584 finished
---------------------------------------  ----------------
epoch                                       584
total_step                               589000
replay_pool/size                         589000
trainer/alpha                                 0.0657813
trainer/alpha_loss                           -0.42076
trainer/entropy                              -5.84538
trainer/qf_loss                               5.79954
trainer/state_noise                           0.005
trainer/policy_loss                        -214.792
trainer/policy_loss_without_entropy         216.906
trainer/entropy_penalty                      -0.384517
trainer/entropy_percentage                   -0.00177273
trainer/Q1Pred Mean                         216.41
trainer/Q1Pred Std                           63.9279
trainer/Q1Pred Max                          308.459
trainer/Q1Pred Min                           15.875
trainer/Q2Pred Mean                         215.977
trainer/Q2Pred Std                           63.7374
trainer/Q2Pred Max                          306.664
trainer/Q2Pred Min                           16.1355
trainer/QTargetWithReg Mean                 216.64
trainer/QTargetWithReg Std                   63.7754
trainer/QTargetWithReg Max                  306.607
trainer/QTargetWithReg Min                   14.7643
trainer/PolicyLossWithoutReg Mean           216.906
trainer/PolicyLossWithoutReg Std             63.2376
trainer/PolicyLossWithoutReg Max            307.029
trainer/PolicyLossWithoutReg Min             16.1983
trainer/gradient_norm                       345.866
trainer/gradient_penalty                     -1.72933
trainer/gradient_percentage                  -0.0079727
exploration/num steps total              589000
exploration/num paths total                1745
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91727
exploration/Rewards Std                       1.20799
exploration/Rewards Max                       9.9158
exploration/Rewards Min                      -0.660855
exploration/Returns Mean                   4917.27
exploration/Returns Std                       0
exploration/Returns Max                    4917.27
exploration/Returns Min                    4917.27
exploration/Num Paths                         1
exploration/Average Returns                4917.27
evaluation_0/num steps total                  4.59433e+06
evaluation_0/num paths total              12712
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92688
evaluation_0/Rewards Std                      1.2037
evaluation_0/Rewards Max                      9.91376
evaluation_0/Rewards Min                     -0.592918
evaluation_0/Returns Mean                  4926.88
evaluation_0/Returns Std                     13.7144
evaluation_0/Returns Max                   4952.66
evaluation_0/Returns Min                   4912.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4926.88
time/epoch (s)                                0
time/total (s)                            11352.9
Epoch                                       584
---------------------------------------  ----------------
2022-11-16 13:55:15.552544 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 585 finished
---------------------------------------  ----------------
epoch                                       585
total_step                               590000
replay_pool/size                         590000
trainer/alpha                                 0.0646039
trainer/alpha_loss                           -0.47274
trainer/entropy                              -5.82743
trainer/qf_loss                               7.85119
trainer/state_noise                           0.005
trainer/policy_loss                        -209.869
trainer/policy_loss_without_entropy         211.939
trainer/entropy_penalty                      -0.376475
trainer/entropy_percentage                   -0.00177634
trainer/Q1Pred Mean                         211.488
trainer/Q1Pred Std                           74.6868
trainer/Q1Pred Max                          315.74
trainer/Q1Pred Min                           -7.40357
trainer/Q2Pred Mean                         211.206
trainer/Q2Pred Std                           74.7223
trainer/Q2Pred Max                          317.167
trainer/Q2Pred Min                           -4.27474
trainer/QTargetWithReg Mean                 210.924
trainer/QTargetWithReg Std                   74.8954
trainer/QTargetWithReg Max                  316.977
trainer/QTargetWithReg Min                   -6.27392
trainer/PolicyLossWithoutReg Mean           211.939
trainer/PolicyLossWithoutReg Std             74.0885
trainer/PolicyLossWithoutReg Max            316.592
trainer/PolicyLossWithoutReg Min             -3.17013
trainer/gradient_norm                       338.604
trainer/gradient_penalty                     -1.69302
trainer/gradient_percentage                  -0.00798827
exploration/num steps total              590000
exploration/num paths total                1746
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69478
exploration/Rewards Std                       1.22494
exploration/Rewards Max                      10.0739
exploration/Rewards Min                      -0.601588
exploration/Returns Mean                   4694.78
exploration/Returns Std                       0
exploration/Returns Max                    4694.78
exploration/Returns Min                    4694.78
exploration/Num Paths                         1
exploration/Average Returns                4694.78
evaluation_0/num steps total                  4.60233e+06
evaluation_0/num paths total              12720
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70258
evaluation_0/Rewards Std                      1.18772
evaluation_0/Rewards Max                      9.66111
evaluation_0/Rewards Min                     -0.607308
evaluation_0/Returns Mean                  4702.58
evaluation_0/Returns Std                     55.3114
evaluation_0/Returns Max                   4787.85
evaluation_0/Returns Min                   4638.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4702.58
time/epoch (s)                                0
time/total (s)                            11369.3
Epoch                                       585
---------------------------------------  ----------------
2022-11-16 13:55:31.361179 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 586 finished
---------------------------------------  ----------------
epoch                                       586
total_step                               591000
replay_pool/size                         591000
trainer/alpha                                 0.0652704
trainer/alpha_loss                           -0.990309
trainer/entropy                              -5.63713
trainer/qf_loss                               5.53043
trainer/state_noise                           0.005
trainer/policy_loss                        -207.027
trainer/policy_loss_without_entropy         209.08
trainer/entropy_penalty                      -0.367938
trainer/entropy_percentage                   -0.0017598
trainer/Q1Pred Mean                         208.227
trainer/Q1Pred Std                           74.1182
trainer/Q1Pred Max                          310.621
trainer/Q1Pred Min                            5.0691
trainer/Q2Pred Mean                         208.483
trainer/Q2Pred Std                           73.85
trainer/Q2Pred Max                          310.722
trainer/Q2Pred Min                            3.88333
trainer/QTargetWithReg Mean                 208.655
trainer/QTargetWithReg Std                   73.7534
trainer/QTargetWithReg Max                  309.83
trainer/QTargetWithReg Min                    5.44032
trainer/PolicyLossWithoutReg Mean           209.08
trainer/PolicyLossWithoutReg Std             73.5285
trainer/PolicyLossWithoutReg Max            310.66
trainer/PolicyLossWithoutReg Min              3.9038
trainer/gradient_norm                       337.069
trainer/gradient_penalty                     -1.68535
trainer/gradient_percentage                  -0.00806077
exploration/num steps total              591000
exploration/num paths total                1747
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78411
exploration/Rewards Std                       1.24302
exploration/Rewards Max                       9.72366
exploration/Rewards Min                      -0.545426
exploration/Returns Mean                   4784.11
exploration/Returns Std                       0
exploration/Returns Max                    4784.11
exploration/Returns Min                    4784.11
exploration/Num Paths                         1
exploration/Average Returns                4784.11
evaluation_0/num steps total                  4.61033e+06
evaluation_0/num paths total              12728
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74783
evaluation_0/Rewards Std                      1.20958
evaluation_0/Rewards Max                      9.77388
evaluation_0/Rewards Min                     -0.653592
evaluation_0/Returns Mean                  4747.83
evaluation_0/Returns Std                     51.4929
evaluation_0/Returns Max                   4833.29
evaluation_0/Returns Min                   4669.85
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4747.83
time/epoch (s)                                0
time/total (s)                            11385.1
Epoch                                       586
---------------------------------------  ----------------
2022-11-16 13:55:47.810832 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 587 finished
---------------------------------------  ----------------
epoch                                       587
total_step                               592000
replay_pool/size                         592000
trainer/alpha                                 0.0645912
trainer/alpha_loss                            0.169514
trainer/entropy                              -6.06188
trainer/qf_loss                               8.05273
trainer/state_noise                           0.005
trainer/policy_loss                        -201.784
trainer/policy_loss_without_entropy         203.835
trainer/entropy_penalty                      -0.391544
trainer/entropy_percentage                   -0.00192089
trainer/Q1Pred Mean                         203.347
trainer/Q1Pred Std                           79.4142
trainer/Q1Pred Max                          310.499
trainer/Q1Pred Min                          -15.9889
trainer/Q2Pred Mean                         203.288
trainer/Q2Pred Std                           79.2985
trainer/Q2Pred Max                          309.481
trainer/Q2Pred Min                           -9.90342
trainer/QTargetWithReg Mean                 203.008
trainer/QTargetWithReg Std                   79.384
trainer/QTargetWithReg Max                  310.559
trainer/QTargetWithReg Min                  -12.6713
trainer/PolicyLossWithoutReg Mean           203.835
trainer/PolicyLossWithoutReg Std             78.5222
trainer/PolicyLossWithoutReg Max            309.269
trainer/PolicyLossWithoutReg Min            -15.8968
trainer/gradient_norm                       331.94
trainer/gradient_penalty                     -1.6597
trainer/gradient_percentage                  -0.00814236
exploration/num steps total              592000
exploration/num paths total                1748
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80857
exploration/Rewards Std                       1.21811
exploration/Rewards Max                       9.72319
exploration/Rewards Min                      -0.582656
exploration/Returns Mean                   4808.57
exploration/Returns Std                       0
exploration/Returns Max                    4808.57
exploration/Returns Min                    4808.57
exploration/Num Paths                         1
exploration/Average Returns                4808.57
evaluation_0/num steps total                  4.61833e+06
evaluation_0/num paths total              12736
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72939
evaluation_0/Rewards Std                      1.22179
evaluation_0/Rewards Max                      9.80392
evaluation_0/Rewards Min                     -0.652043
evaluation_0/Returns Mean                  4729.39
evaluation_0/Returns Std                     23.3838
evaluation_0/Returns Max                   4784.85
evaluation_0/Returns Min                   4700.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4729.39
time/epoch (s)                                0
time/total (s)                            11401.6
Epoch                                       587
---------------------------------------  ----------------
2022-11-16 13:56:03.666367 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 588 finished
---------------------------------------  ----------------
epoch                                       588
total_step                               593000
replay_pool/size                         593000
trainer/alpha                                 0.0631355
trainer/alpha_loss                           -1.59689
trainer/entropy                              -5.4219
trainer/qf_loss                               8.90886
trainer/state_noise                           0.005
trainer/policy_loss                        -208.439
trainer/policy_loss_without_entropy         210.517
trainer/entropy_penalty                      -0.342314
trainer/entropy_percentage                   -0.00162607
trainer/Q1Pred Mean                         210.17
trainer/Q1Pred Std                           72.3903
trainer/Q1Pred Max                          310.964
trainer/Q1Pred Min                          -13.4652
trainer/Q2Pred Mean                         209.775
trainer/Q2Pred Std                           72.1967
trainer/Q2Pred Max                          314.516
trainer/Q2Pred Min                          -11.9359
trainer/QTargetWithReg Mean                 209.263
trainer/QTargetWithReg Std                   72.1569
trainer/QTargetWithReg Max                  312.195
trainer/QTargetWithReg Min                  -21.5951
trainer/PolicyLossWithoutReg Mean           210.517
trainer/PolicyLossWithoutReg Std             71.4457
trainer/PolicyLossWithoutReg Max            309.884
trainer/PolicyLossWithoutReg Min             -4.97296
trainer/gradient_norm                       347.175
trainer/gradient_penalty                     -1.73588
trainer/gradient_percentage                  -0.00824579
exploration/num steps total              593000
exploration/num paths total                1749
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85158
exploration/Rewards Std                       1.23448
exploration/Rewards Max                      10.1871
exploration/Rewards Min                      -0.69572
exploration/Returns Mean                   4851.58
exploration/Returns Std                       0
exploration/Returns Max                    4851.58
exploration/Returns Min                    4851.58
exploration/Num Paths                         1
exploration/Average Returns                4851.58
evaluation_0/num steps total                  4.62633e+06
evaluation_0/num paths total              12744
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87641
evaluation_0/Rewards Std                      1.22096
evaluation_0/Rewards Max                      9.90253
evaluation_0/Rewards Min                     -0.673747
evaluation_0/Returns Mean                  4876.41
evaluation_0/Returns Std                     12.4929
evaluation_0/Returns Max                   4900.34
evaluation_0/Returns Min                   4856.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4876.41
time/epoch (s)                                0
time/total (s)                            11417.5
Epoch                                       588
---------------------------------------  ----------------
2022-11-16 13:56:20.043842 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 589 finished
---------------------------------------  ----------------
epoch                                       589
total_step                               594000
replay_pool/size                         594000
trainer/alpha                                 0.0651716
trainer/alpha_loss                           -0.186517
trainer/entropy                              -5.9317
trainer/qf_loss                               6.78209
trainer/state_noise                           0.005
trainer/policy_loss                        -217.716
trainer/policy_loss_without_entropy         219.774
trainer/entropy_penalty                      -0.386578
trainer/entropy_percentage                   -0.00175898
trainer/Q1Pred Mean                         218.608
trainer/Q1Pred Std                           69.1282
trainer/Q1Pred Max                          311.507
trainer/Q1Pred Min                            4.50958
trainer/Q2Pred Mean                         218.838
trainer/Q2Pred Std                           69.0765
trainer/Q2Pred Max                          311.912
trainer/Q2Pred Min                            6.38533
trainer/QTargetWithReg Mean                 219.32
trainer/QTargetWithReg Std                   69.0674
trainer/QTargetWithReg Max                  312.148
trainer/QTargetWithReg Min                    4.44444
trainer/PolicyLossWithoutReg Mean           219.774
trainer/PolicyLossWithoutReg Std             68.3066
trainer/PolicyLossWithoutReg Max            311.846
trainer/PolicyLossWithoutReg Min              6.15883
trainer/gradient_norm                       334.317
trainer/gradient_penalty                     -1.67159
trainer/gradient_percentage                  -0.00760593
exploration/num steps total              594000
exploration/num paths total                1750
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75598
exploration/Rewards Std                       1.22705
exploration/Rewards Max                       9.82387
exploration/Rewards Min                      -0.708776
exploration/Returns Mean                   4755.98
exploration/Returns Std                       0
exploration/Returns Max                    4755.98
exploration/Returns Min                    4755.98
exploration/Num Paths                         1
exploration/Average Returns                4755.98
evaluation_0/num steps total                  4.63433e+06
evaluation_0/num paths total              12752
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92607
evaluation_0/Rewards Std                      1.19934
evaluation_0/Rewards Max                      9.99179
evaluation_0/Rewards Min                     -0.558153
evaluation_0/Returns Mean                  4926.07
evaluation_0/Returns Std                     11.5222
evaluation_0/Returns Max                   4943.59
evaluation_0/Returns Min                   4908.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4926.07
time/epoch (s)                                0
time/total (s)                            11433.8
Epoch                                       589
---------------------------------------  ----------------
2022-11-16 13:56:36.007568 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 590 finished
---------------------------------------  ----------------
epoch                                       590
total_step                               595000
replay_pool/size                         595000
trainer/alpha                                 0.0645009
trainer/alpha_loss                           -1.51546
trainer/entropy                              -5.44714
trainer/qf_loss                               5.55684
trainer/state_noise                           0.005
trainer/policy_loss                        -211.307
trainer/policy_loss_without_entropy         213.374
trainer/entropy_penalty                      -0.351346
trainer/entropy_percentage                   -0.00164662
trainer/Q1Pred Mean                         213.224
trainer/Q1Pred Std                           72.5322
trainer/Q1Pred Max                          306.318
trainer/Q1Pred Min                           -4.56786
trainer/Q2Pred Mean                         213.137
trainer/Q2Pred Std                           72.4227
trainer/Q2Pred Max                          306.048
trainer/Q2Pred Min                           -5.50051
trainer/QTargetWithReg Mean                 213.155
trainer/QTargetWithReg Std                   72.5514
trainer/QTargetWithReg Max                  306.856
trainer/QTargetWithReg Min                    2.46547
trainer/PolicyLossWithoutReg Mean           213.374
trainer/PolicyLossWithoutReg Std             71.5458
trainer/PolicyLossWithoutReg Max            305.263
trainer/PolicyLossWithoutReg Min             -4.79933
trainer/gradient_norm                       343.105
trainer/gradient_penalty                     -1.71552
trainer/gradient_percentage                  -0.00803999
exploration/num steps total              595000
exploration/num paths total                1751
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81068
exploration/Rewards Std                       1.2407
exploration/Rewards Max                      10.195
exploration/Rewards Min                      -0.550736
exploration/Returns Mean                   4810.68
exploration/Returns Std                       0
exploration/Returns Max                    4810.68
exploration/Returns Min                    4810.68
exploration/Num Paths                         1
exploration/Average Returns                4810.68
evaluation_0/num steps total                  4.64233e+06
evaluation_0/num paths total              12760
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91627
evaluation_0/Rewards Std                      1.20181
evaluation_0/Rewards Max                      9.97599
evaluation_0/Rewards Min                     -0.63205
evaluation_0/Returns Mean                  4916.27
evaluation_0/Returns Std                     15.0854
evaluation_0/Returns Max                   4937.93
evaluation_0/Returns Min                   4886.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4916.27
time/epoch (s)                                0
time/total (s)                            11449.8
Epoch                                       590
---------------------------------------  ----------------
2022-11-16 13:56:52.174620 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 591 finished
---------------------------------------  ----------------
epoch                                       591
total_step                               596000
replay_pool/size                         596000
trainer/alpha                                 0.0646939
trainer/alpha_loss                           -1.14088
trainer/entropy                              -5.58332
trainer/qf_loss                               5.45616
trainer/state_noise                           0.005
trainer/policy_loss                        -210.213
trainer/policy_loss_without_entropy         212.289
trainer/entropy_penalty                      -0.361207
trainer/entropy_percentage                   -0.00170149
trainer/Q1Pred Mean                         210.893
trainer/Q1Pred Std                           74.1273
trainer/Q1Pred Max                          313.066
trainer/Q1Pred Min                            7.04678
trainer/Q2Pred Mean                         211.149
trainer/Q2Pred Std                           74.2218
trainer/Q2Pred Max                          313.846
trainer/Q2Pred Min                            7.04832
trainer/QTargetWithReg Mean                 211.421
trainer/QTargetWithReg Std                   74.183
trainer/QTargetWithReg Max                  314.211
trainer/QTargetWithReg Min                    8.43565
trainer/PolicyLossWithoutReg Mean           212.289
trainer/PolicyLossWithoutReg Std             73.3171
trainer/PolicyLossWithoutReg Max            313.502
trainer/PolicyLossWithoutReg Min              7.35486
trainer/gradient_norm                       342.945
trainer/gradient_penalty                     -1.71473
trainer/gradient_percentage                  -0.00807732
exploration/num steps total              596000
exploration/num paths total                1752
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98221
exploration/Rewards Std                       1.24098
exploration/Rewards Max                      10.2042
exploration/Rewards Min                      -0.620703
exploration/Returns Mean                   4982.21
exploration/Returns Std                       0
exploration/Returns Max                    4982.21
exploration/Returns Min                    4982.21
exploration/Num Paths                         1
exploration/Average Returns                4982.21
evaluation_0/num steps total                  4.65033e+06
evaluation_0/num paths total              12768
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9122
evaluation_0/Rewards Std                      1.25871
evaluation_0/Rewards Max                     10.0514
evaluation_0/Rewards Min                     -0.684748
evaluation_0/Returns Mean                  4912.2
evaluation_0/Returns Std                     45.9382
evaluation_0/Returns Max                   5010.98
evaluation_0/Returns Min                   4860.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4912.2
time/epoch (s)                                0
time/total (s)                            11466
Epoch                                       591
---------------------------------------  ----------------
2022-11-16 13:57:08.210442 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 592 finished
---------------------------------------  ----------------
epoch                                       592
total_step                               597000
replay_pool/size                         597000
trainer/alpha                                 0.0634196
trainer/alpha_loss                            0.48118
trainer/entropy                              -6.17447
trainer/qf_loss                               5.90196
trainer/state_noise                           0.005
trainer/policy_loss                        -223.015
trainer/policy_loss_without_entropy         225.087
trainer/entropy_penalty                      -0.391582
trainer/entropy_percentage                   -0.0017397
trainer/Q1Pred Mean                         223.711
trainer/Q1Pred Std                           67.9463
trainer/Q1Pred Max                          313.989
trainer/Q1Pred Min                           39.53
trainer/Q2Pred Mean                         223.649
trainer/Q2Pred Std                           68.1863
trainer/Q2Pred Max                          312.982
trainer/Q2Pred Min                           37.6109
trainer/QTargetWithReg Mean                 223.999
trainer/QTargetWithReg Std                   67.982
trainer/QTargetWithReg Max                  314.196
trainer/QTargetWithReg Min                   37.6642
trainer/PolicyLossWithoutReg Mean           225.087
trainer/PolicyLossWithoutReg Std             67.2618
trainer/PolicyLossWithoutReg Max            314.073
trainer/PolicyLossWithoutReg Min             38.2267
trainer/gradient_norm                       335.97
trainer/gradient_penalty                     -1.67985
trainer/gradient_percentage                  -0.00746313
exploration/num steps total              597000
exploration/num paths total                1753
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.76822
exploration/Rewards Std                       1.28522
exploration/Rewards Max                       9.737
exploration/Rewards Min                      -0.695708
exploration/Returns Mean                   4768.22
exploration/Returns Std                       0
exploration/Returns Max                    4768.22
exploration/Returns Min                    4768.22
exploration/Num Paths                         1
exploration/Average Returns                4768.22
evaluation_0/num steps total                  4.65833e+06
evaluation_0/num paths total              12776
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94391
evaluation_0/Rewards Std                      1.23089
evaluation_0/Rewards Max                     10.0711
evaluation_0/Rewards Min                     -0.572834
evaluation_0/Returns Mean                  4943.91
evaluation_0/Returns Std                     56.1937
evaluation_0/Returns Max                   5002.06
evaluation_0/Returns Min                   4860.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4943.91
time/epoch (s)                                0
time/total (s)                            11482
Epoch                                       592
---------------------------------------  ----------------
2022-11-16 13:57:24.006068 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 593 finished
---------------------------------------  ----------------
epoch                                       593
total_step                               598000
replay_pool/size                         598000
trainer/alpha                                 0.0642967
trainer/alpha_loss                           -2.05534
trainer/entropy                              -5.25102
trainer/qf_loss                              10.1832
trainer/state_noise                           0.005
trainer/policy_loss                        -209.65
trainer/policy_loss_without_entropy         211.768
trainer/entropy_penalty                      -0.337623
trainer/entropy_percentage                   -0.00159431
trainer/Q1Pred Mean                         211.483
trainer/Q1Pred Std                           71.7354
trainer/Q1Pred Max                          309.131
trainer/Q1Pred Min                           15.5325
trainer/Q2Pred Mean                         211.459
trainer/Q2Pred Std                           71.7725
trainer/Q2Pred Max                          308.162
trainer/Q2Pred Min                            9.53832
trainer/QTargetWithReg Mean                 211.475
trainer/QTargetWithReg Std                   71.7127
trainer/QTargetWithReg Max                  309.292
trainer/QTargetWithReg Min                   14.3672
trainer/PolicyLossWithoutReg Mean           211.767
trainer/PolicyLossWithoutReg Std             70.7641
trainer/PolicyLossWithoutReg Max            308.759
trainer/PolicyLossWithoutReg Min             14.5495
trainer/gradient_norm                       355.981
trainer/gradient_penalty                     -1.77991
trainer/gradient_percentage                  -0.008405
exploration/num steps total              598000
exploration/num paths total                1754
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73438
exploration/Rewards Std                       1.22139
exploration/Rewards Max                       9.85326
exploration/Rewards Min                      -0.46384
exploration/Returns Mean                   4734.38
exploration/Returns Std                       0
exploration/Returns Max                    4734.38
exploration/Returns Min                    4734.38
exploration/Num Paths                         1
exploration/Average Returns                4734.38
evaluation_0/num steps total                  4.66633e+06
evaluation_0/num paths total              12784
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03848
evaluation_0/Rewards Std                      1.26273
evaluation_0/Rewards Max                     10.1805
evaluation_0/Rewards Min                     -0.622942
evaluation_0/Returns Mean                  5038.48
evaluation_0/Returns Std                     20.0839
evaluation_0/Returns Max                   5060.19
evaluation_0/Returns Min                   4996.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5038.48
time/epoch (s)                                0
time/total (s)                            11497.8
Epoch                                       593
---------------------------------------  ----------------
2022-11-16 13:57:40.614424 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 594 finished
---------------------------------------  ----------------
epoch                                       594
total_step                               599000
replay_pool/size                         599000
trainer/alpha                                 0.0625026
trainer/alpha_loss                            0.306875
trainer/entropy                              -6.11069
trainer/qf_loss                               8.22075
trainer/state_noise                           0.005
trainer/policy_loss                        -202.914
trainer/policy_loss_without_entropy         205.027
trainer/entropy_penalty                      -0.381933
trainer/entropy_percentage                   -0.00186285
trainer/Q1Pred Mean                         204.862
trainer/Q1Pred Std                           77.5618
trainer/Q1Pred Max                          311.204
trainer/Q1Pred Min                          -28.1039
trainer/Q2Pred Mean                         204.819
trainer/Q2Pred Std                           77.8854
trainer/Q2Pred Max                          311.989
trainer/Q2Pred Min                          -23.7483
trainer/QTargetWithReg Mean                 204.343
trainer/QTargetWithReg Std                   77.7727
trainer/QTargetWithReg Max                  310.94
trainer/QTargetWithReg Min                  -29.6492
trainer/PolicyLossWithoutReg Mean           205.027
trainer/PolicyLossWithoutReg Std             77.0471
trainer/PolicyLossWithoutReg Max            310.702
trainer/PolicyLossWithoutReg Min            -20.9843
trainer/gradient_norm                       346.196
trainer/gradient_penalty                     -1.73098
trainer/gradient_percentage                  -0.0084427
exploration/num steps total              599000
exploration/num paths total                1755
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80319
exploration/Rewards Std                       1.22841
exploration/Rewards Max                      10.0056
exploration/Rewards Min                      -0.781744
exploration/Returns Mean                   4803.19
exploration/Returns Std                       0
exploration/Returns Max                    4803.19
exploration/Returns Min                    4803.19
exploration/Num Paths                         1
exploration/Average Returns                4803.19
evaluation_0/num steps total                  4.67433e+06
evaluation_0/num paths total              12792
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84656
evaluation_0/Rewards Std                      1.2125
evaluation_0/Rewards Max                      9.91718
evaluation_0/Rewards Min                     -0.606362
evaluation_0/Returns Mean                  4846.56
evaluation_0/Returns Std                     25.6636
evaluation_0/Returns Max                   4882.69
evaluation_0/Returns Min                   4800.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4846.56
time/epoch (s)                                0
time/total (s)                            11514.4
Epoch                                       594
---------------------------------------  ----------------
2022-11-16 13:57:56.496902 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 595 finished
---------------------------------------  ----------------
epoch                                       595
total_step                               600000
replay_pool/size                         600000
trainer/alpha                                 0.0649779
trainer/alpha_loss                           -1.83751
trainer/entropy                              -5.3278
trainer/qf_loss                               4.99131
trainer/state_noise                           0.005
trainer/policy_loss                        -217.443
trainer/policy_loss_without_entropy         219.488
trainer/entropy_penalty                      -0.346189
trainer/entropy_percentage                   -0.00157726
trainer/Q1Pred Mean                         219.021
trainer/Q1Pred Std                           68.1641
trainer/Q1Pred Max                          311.403
trainer/Q1Pred Min                           19.013
trainer/Q2Pred Mean                         218.497
trainer/Q2Pred Std                           68.2367
trainer/Q2Pred Max                          309.972
trainer/Q2Pred Min                           20.1017
trainer/QTargetWithReg Mean                 218.524
trainer/QTargetWithReg Std                   68.5344
trainer/QTargetWithReg Max                  310.06
trainer/QTargetWithReg Min                   19.7626
trainer/PolicyLossWithoutReg Mean           219.488
trainer/PolicyLossWithoutReg Std             67.4825
trainer/PolicyLossWithoutReg Max            310.589
trainer/PolicyLossWithoutReg Min             20.259
trainer/gradient_norm                       339.802
trainer/gradient_penalty                     -1.69901
trainer/gradient_percentage                  -0.0077408
exploration/num steps total              600000
exploration/num paths total                1756
exploration/path length this epoch Mean     391
exploration/path length this epoch Std        0
exploration/path length this epoch Max      391
exploration/path length this epoch Min      391
exploration/Rewards Mean                      4.32211
exploration/Rewards Std                       1.40735
exploration/Rewards Max                       9.49811
exploration/Rewards Min                      -0.589152
exploration/Returns Mean                   1689.95
exploration/Returns Std                       0
exploration/Returns Max                    1689.95
exploration/Returns Min                    1689.95
exploration/Num Paths                         1
exploration/Average Returns                1689.95
evaluation_0/num steps total                  4.68233e+06
evaluation_0/num paths total              12800
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73311
evaluation_0/Rewards Std                      1.18657
evaluation_0/Rewards Max                      9.88305
evaluation_0/Rewards Min                     -0.592005
evaluation_0/Returns Mean                  4733.11
evaluation_0/Returns Std                     14.9119
evaluation_0/Returns Max                   4759.01
evaluation_0/Returns Min                   4705.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4733.11
time/epoch (s)                                0
time/total (s)                            11530.3
Epoch                                       595
---------------------------------------  ----------------
2022-11-16 13:58:13.473125 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 596 finished
---------------------------------------  ----------------
epoch                                       596
total_step                               601000
replay_pool/size                         601000
trainer/alpha                                 0.063298
trainer/alpha_loss                            1.12512
trainer/entropy                              -6.40765
trainer/qf_loss                               6.8554
trainer/state_noise                           0.005
trainer/policy_loss                        -209.487
trainer/policy_loss_without_entropy         211.61
trainer/entropy_penalty                      -0.405592
trainer/entropy_percentage                   -0.0019167
trainer/Q1Pred Mean                         210.947
trainer/Q1Pred Std                           71.3981
trainer/Q1Pred Max                          313.319
trainer/Q1Pred Min                           -6.69986
trainer/Q2Pred Mean                         211.629
trainer/Q2Pred Std                           71.1892
trainer/Q2Pred Max                          312.92
trainer/Q2Pred Min                          -11.5979
trainer/QTargetWithReg Mean                 211.172
trainer/QTargetWithReg Std                   71.3077
trainer/QTargetWithReg Max                  313.232
trainer/QTargetWithReg Min                   -0.427287
trainer/PolicyLossWithoutReg Mean           211.61
trainer/PolicyLossWithoutReg Std             70.1281
trainer/PolicyLossWithoutReg Max            311.922
trainer/PolicyLossWithoutReg Min              0.80308
trainer/gradient_norm                       343.431
trainer/gradient_penalty                     -1.71715
trainer/gradient_percentage                  -0.00811472
exploration/num steps total              601000
exploration/num paths total                1757
exploration/path length this epoch Mean     918
exploration/path length this epoch Std        0
exploration/path length this epoch Max      918
exploration/path length this epoch Min      918
exploration/Rewards Mean                      4.6595
exploration/Rewards Std                       1.26194
exploration/Rewards Max                      10.0154
exploration/Rewards Min                      -0.611181
exploration/Returns Mean                   4277.42
exploration/Returns Std                       0
exploration/Returns Max                    4277.42
exploration/Returns Min                    4277.42
exploration/Num Paths                         1
exploration/Average Returns                4277.42
evaluation_0/num steps total                  4.69024e+06
evaluation_0/num paths total              12814
evaluation_0/path length Mean               564.786
evaluation_0/path length Std                 58.192
evaluation_0/path length Max                740
evaluation_0/path length Min                472
evaluation_0/Rewards Mean                     4.66199
evaluation_0/Rewards Std                      1.41965
evaluation_0/Rewards Max                     10.4432
evaluation_0/Rewards Min                     -0.577883
evaluation_0/Returns Mean                  2633.02
evaluation_0/Returns Std                    318.916
evaluation_0/Returns Max                   3644.66
evaluation_0/Returns Min                   2150.76
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2633.02
time/epoch (s)                                0
time/total (s)                            11547.3
Epoch                                       596
---------------------------------------  ----------------
2022-11-16 13:58:29.328222 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 597 finished
---------------------------------------  ----------------
epoch                                       597
total_step                               602000
replay_pool/size                         602000
trainer/alpha                                 0.0636
trainer/alpha_loss                            1.125
trainer/entropy                              -6.40831
trainer/qf_loss                               6.2794
trainer/state_noise                           0.005
trainer/policy_loss                        -212.184
trainer/policy_loss_without_entropy         214.248
trainer/entropy_penalty                      -0.407568
trainer/entropy_percentage                   -0.00190232
trainer/Q1Pred Mean                         213.889
trainer/Q1Pred Std                           75.4265
trainer/Q1Pred Max                          313.268
trainer/Q1Pred Min                           -0.242222
trainer/Q2Pred Mean                         213.682
trainer/Q2Pred Std                           75.3874
trainer/Q2Pred Max                          313.675
trainer/Q2Pred Min                            3.0162
trainer/QTargetWithReg Mean                 213.742
trainer/QTargetWithReg Std                   75.658
trainer/QTargetWithReg Max                  312.976
trainer/QTargetWithReg Min                    1.55196
trainer/PolicyLossWithoutReg Mean           214.248
trainer/PolicyLossWithoutReg Std             74.6385
trainer/PolicyLossWithoutReg Max            313.179
trainer/PolicyLossWithoutReg Min             -0.841956
trainer/gradient_norm                       331.44
trainer/gradient_penalty                     -1.6572
trainer/gradient_percentage                  -0.00773495
exploration/num steps total              602000
exploration/num paths total                1758
exploration/path length this epoch Mean     847
exploration/path length this epoch Std        0
exploration/path length this epoch Max      847
exploration/path length this epoch Min      847
exploration/Rewards Mean                      4.68442
exploration/Rewards Std                       1.30634
exploration/Rewards Max                      10.2628
exploration/Rewards Min                      -0.470954
exploration/Returns Mean                   3967.7
exploration/Returns Std                       0
exploration/Returns Max                    3967.7
exploration/Returns Min                    3967.7
exploration/Num Paths                         1
exploration/Average Returns                3967.7
evaluation_0/num steps total                  4.69824e+06
evaluation_0/num paths total              12822
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88282
evaluation_0/Rewards Std                      1.24149
evaluation_0/Rewards Max                     10.2436
evaluation_0/Rewards Min                     -0.611931
evaluation_0/Returns Mean                  4882.82
evaluation_0/Returns Std                     36.9184
evaluation_0/Returns Max                   4947.57
evaluation_0/Returns Min                   4817.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4882.82
time/epoch (s)                                0
time/total (s)                            11563.1
Epoch                                       597
---------------------------------------  ----------------
2022-11-16 13:58:45.251867 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 598 finished
---------------------------------------  ----------------
epoch                                       598
total_step                               603000
replay_pool/size                         603000
trainer/alpha                                 0.0638283
trainer/alpha_loss                            0.833619
trainer/entropy                              -6.30293
trainer/qf_loss                               8.58086
trainer/state_noise                           0.005
trainer/policy_loss                        -214.73
trainer/policy_loss_without_entropy         216.848
trainer/entropy_penalty                      -0.402305
trainer/entropy_percentage                   -0.00185524
trainer/Q1Pred Mean                         215.593
trainer/Q1Pred Std                           72.6877
trainer/Q1Pred Max                          310.837
trainer/Q1Pred Min                          -12.7117
trainer/Q2Pred Mean                         215.396
trainer/Q2Pred Std                           72.3561
trainer/Q2Pred Max                          311.641
trainer/Q2Pred Min                            4.43023
trainer/QTargetWithReg Mean                 215.953
trainer/QTargetWithReg Std                   72.7526
trainer/QTargetWithReg Max                  311.284
trainer/QTargetWithReg Min                   -0.765769
trainer/PolicyLossWithoutReg Mean           216.848
trainer/PolicyLossWithoutReg Std             70.7998
trainer/PolicyLossWithoutReg Max            310.748
trainer/PolicyLossWithoutReg Min              6.82063
trainer/gradient_norm                       343.124
trainer/gradient_penalty                     -1.71562
trainer/gradient_percentage                  -0.00791162
exploration/num steps total              603000
exploration/num paths total                1759
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84595
exploration/Rewards Std                       1.28373
exploration/Rewards Max                      10.1108
exploration/Rewards Min                      -0.709425
exploration/Returns Mean                   4845.95
exploration/Returns Std                       0
exploration/Returns Max                    4845.95
exploration/Returns Min                    4845.95
exploration/Num Paths                         1
exploration/Average Returns                4845.95
evaluation_0/num steps total                  4.70624e+06
evaluation_0/num paths total              12830
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92961
evaluation_0/Rewards Std                      1.22839
evaluation_0/Rewards Max                     10.109
evaluation_0/Rewards Min                     -0.67897
evaluation_0/Returns Mean                  4929.61
evaluation_0/Returns Std                     20.6165
evaluation_0/Returns Max                   4962.68
evaluation_0/Returns Min                   4899.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4929.61
time/epoch (s)                                0
time/total (s)                            11579
Epoch                                       598
---------------------------------------  ----------------
2022-11-16 13:59:01.534409 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 599 finished
---------------------------------------  ----------------
epoch                                       599
total_step                               604000
replay_pool/size                         604000
trainer/alpha                                 0.0631687
trainer/alpha_loss                           -1.39084
trainer/entropy                              -5.49641
trainer/qf_loss                               8.77911
trainer/state_noise                           0.005
trainer/policy_loss                        -203.598
trainer/policy_loss_without_entropy         205.57
trainer/entropy_penalty                      -0.347201
trainer/entropy_percentage                   -0.00168896
trainer/Q1Pred Mean                         204.816
trainer/Q1Pred Std                           77.2905
trainer/Q1Pred Max                          311.17
trainer/Q1Pred Min                            7.54196
trainer/Q2Pred Mean                         204.801
trainer/Q2Pred Std                           77.2634
trainer/Q2Pred Max                          310.274
trainer/Q2Pred Min                            6.52514
trainer/QTargetWithReg Mean                 205.25
trainer/QTargetWithReg Std                   77.3192
trainer/QTargetWithReg Max                  309.963
trainer/QTargetWithReg Min                    6.03114
trainer/PolicyLossWithoutReg Mean           205.57
trainer/PolicyLossWithoutReg Std             76.8474
trainer/PolicyLossWithoutReg Max            309.424
trainer/PolicyLossWithoutReg Min              6.88644
trainer/gradient_norm                       325.121
trainer/gradient_penalty                     -1.6256
trainer/gradient_percentage                  -0.00790778
exploration/num steps total              604000
exploration/num paths total                1760
exploration/path length this epoch Mean     858
exploration/path length this epoch Std        0
exploration/path length this epoch Max      858
exploration/path length this epoch Min      858
exploration/Rewards Mean                      4.6976
exploration/Rewards Std                       1.25644
exploration/Rewards Max                       9.83968
exploration/Rewards Min                      -0.719016
exploration/Returns Mean                   4030.54
exploration/Returns Std                       0
exploration/Returns Max                    4030.54
exploration/Returns Min                    4030.54
exploration/Num Paths                         1
exploration/Average Returns                4030.54
evaluation_0/num steps total                  4.71385e+06
evaluation_0/num paths total              12844
evaluation_0/path length Mean               543.357
evaluation_0/path length Std                 51.7226
evaluation_0/path length Max                570
evaluation_0/path length Min                392
evaluation_0/Rewards Mean                     4.73682
evaluation_0/Rewards Std                      1.41871
evaluation_0/Rewards Max                     10.4304
evaluation_0/Rewards Min                     -0.576797
evaluation_0/Returns Mean                  2573.79
evaluation_0/Returns Std                    283.206
evaluation_0/Returns Max                   2723.31
evaluation_0/Returns Min                   1752.1
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2573.79
time/epoch (s)                                0
time/total (s)                            11595.3
Epoch                                       599
---------------------------------------  ----------------
2022-11-16 13:59:18.085696 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 600 finished
---------------------------------------  ----------------
epoch                                       600
total_step                               605000
replay_pool/size                         605000
trainer/alpha                                 0.0625424
trainer/alpha_loss                            0.415093
trainer/entropy                              -6.14975
trainer/qf_loss                               5.56872
trainer/state_noise                           0.005
trainer/policy_loss                        -212.416
trainer/policy_loss_without_entropy         214.507
trainer/entropy_penalty                      -0.38462
trainer/entropy_percentage                   -0.00179304
trainer/Q1Pred Mean                         214.121
trainer/Q1Pred Std                           71.3443
trainer/Q1Pred Max                          309.435
trainer/Q1Pred Min                            6.51911
trainer/Q2Pred Mean                         213.819
trainer/Q2Pred Std                           71.0749
trainer/Q2Pred Max                          308.326
trainer/Q2Pred Min                            7.87351
trainer/QTargetWithReg Mean                 214.126
trainer/QTargetWithReg Std                   71.3477
trainer/QTargetWithReg Max                  309.506
trainer/QTargetWithReg Min                    8.94847
trainer/PolicyLossWithoutReg Mean           214.507
trainer/PolicyLossWithoutReg Std             70.661
trainer/PolicyLossWithoutReg Max            308.941
trainer/PolicyLossWithoutReg Min              9.28361
trainer/gradient_norm                       341.326
trainer/gradient_penalty                     -1.70663
trainer/gradient_percentage                  -0.00795604
exploration/num steps total              605000
exploration/num paths total                1761
exploration/path length this epoch Mean     493
exploration/path length this epoch Std        0
exploration/path length this epoch Max      493
exploration/path length this epoch Min      493
exploration/Rewards Mean                      4.53846
exploration/Rewards Std                       1.38998
exploration/Rewards Max                      10.1664
exploration/Rewards Min                      -0.518627
exploration/Returns Mean                   2237.46
exploration/Returns Std                       0
exploration/Returns Max                    2237.46
exploration/Returns Min                    2237.46
exploration/Num Paths                         1
exploration/Average Returns                2237.46
evaluation_0/num steps total                  4.72145e+06
evaluation_0/num paths total              12857
evaluation_0/path length Mean               584.615
evaluation_0/path length Std                139.535
evaluation_0/path length Max                859
evaluation_0/path length Min                489
evaluation_0/Rewards Mean                     4.60534
evaluation_0/Rewards Std                      1.34848
evaluation_0/Rewards Max                     10.298
evaluation_0/Rewards Min                     -0.784177
evaluation_0/Returns Mean                  2692.35
evaluation_0/Returns Std                    714.409
evaluation_0/Returns Max                   4107.75
evaluation_0/Returns Min                   2196.69
evaluation_0/Num Paths                       13
evaluation_0/Average Returns               2692.35
time/epoch (s)                                0
time/total (s)                            11611.9
Epoch                                       600
---------------------------------------  ----------------
2022-11-16 13:59:34.640833 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 601 finished
---------------------------------------  ----------------
epoch                                       601
total_step                               606000
replay_pool/size                         606000
trainer/alpha                                 0.0634147
trainer/alpha_loss                            0.630047
trainer/entropy                              -6.22843
trainer/qf_loss                               6.73616
trainer/state_noise                           0.005
trainer/policy_loss                        -212.57
trainer/policy_loss_without_entropy         214.624
trainer/entropy_penalty                      -0.394974
trainer/entropy_percentage                   -0.00184031
trainer/Q1Pred Mean                         213.607
trainer/Q1Pred Std                           75.7765
trainer/Q1Pred Max                          310.348
trainer/Q1Pred Min                            5.13377
trainer/Q2Pred Mean                         214.022
trainer/Q2Pred Std                           75.5613
trainer/Q2Pred Max                          311.442
trainer/Q2Pred Min                            7.81051
trainer/QTargetWithReg Mean                 214.009
trainer/QTargetWithReg Std                   75.7531
trainer/QTargetWithReg Max                  311.359
trainer/QTargetWithReg Min                    5.15647
trainer/PolicyLossWithoutReg Mean           214.624
trainer/PolicyLossWithoutReg Std             74.9764
trainer/PolicyLossWithoutReg Max            310.167
trainer/PolicyLossWithoutReg Min              5.63239
trainer/gradient_norm                       331.618
trainer/gradient_penalty                     -1.65809
trainer/gradient_percentage                  -0.00772557
exploration/num steps total              606000
exploration/num paths total                1762
exploration/path length this epoch Mean     662
exploration/path length this epoch Std        0
exploration/path length this epoch Max      662
exploration/path length this epoch Min      662
exploration/Rewards Mean                      4.61507
exploration/Rewards Std                       1.34577
exploration/Rewards Max                      10.0746
exploration/Rewards Min                      -0.641869
exploration/Returns Mean                   3055.18
exploration/Returns Std                       0
exploration/Returns Max                    3055.18
exploration/Returns Min                    3055.18
exploration/Num Paths                         1
exploration/Average Returns                3055.18
evaluation_0/num steps total                  4.72945e+06
evaluation_0/num paths total              12865
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93083
evaluation_0/Rewards Std                      1.21747
evaluation_0/Rewards Max                     10.0974
evaluation_0/Rewards Min                     -0.57485
evaluation_0/Returns Mean                  4930.83
evaluation_0/Returns Std                     11.7965
evaluation_0/Returns Max                   4949.14
evaluation_0/Returns Min                   4913.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4930.83
time/epoch (s)                                0
time/total (s)                            11628.4
Epoch                                       601
---------------------------------------  ----------------
2022-11-16 13:59:52.023377 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 602 finished
---------------------------------------  ----------------
epoch                                       602
total_step                               607000
replay_pool/size                         607000
trainer/alpha                                 0.0625802
trainer/alpha_loss                           -0.0471159
trainer/entropy                              -5.983
trainer/qf_loss                               6.52526
trainer/state_noise                           0.005
trainer/policy_loss                        -209.366
trainer/policy_loss_without_entropy         211.476
trainer/entropy_penalty                      -0.374417
trainer/entropy_percentage                   -0.0017705
trainer/Q1Pred Mean                         210.471
trainer/Q1Pred Std                           73.0336
trainer/Q1Pred Max                          311.56
trainer/Q1Pred Min                          -19.2183
trainer/Q2Pred Mean                         210.334
trainer/Q2Pred Std                           73.2136
trainer/Q2Pred Max                          312.384
trainer/Q2Pred Min                          -15.6036
trainer/QTargetWithReg Mean                 210.231
trainer/QTargetWithReg Std                   73.5818
trainer/QTargetWithReg Max                  314.122
trainer/QTargetWithReg Min                  -16.47
trainer/PolicyLossWithoutReg Mean           211.476
trainer/PolicyLossWithoutReg Std             71.4955
trainer/PolicyLossWithoutReg Max            310.943
trainer/PolicyLossWithoutReg Min            -13.7793
trainer/gradient_norm                       347.049
trainer/gradient_penalty                     -1.73525
trainer/gradient_percentage                  -0.00820541
exploration/num steps total              607000
exploration/num paths total                1763
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81947
exploration/Rewards Std                       1.23079
exploration/Rewards Max                       9.80794
exploration/Rewards Min                      -0.597082
exploration/Returns Mean                   4819.47
exploration/Returns Std                       0
exploration/Returns Max                    4819.47
exploration/Returns Min                    4819.47
exploration/Num Paths                         1
exploration/Average Returns                4819.47
evaluation_0/num steps total                  4.73703e+06
evaluation_0/num paths total              12875
evaluation_0/path length Mean               758
evaluation_0/path length Std                189.87
evaluation_0/path length Max               1000
evaluation_0/path length Min                587
evaluation_0/Rewards Mean                     4.6829
evaluation_0/Rewards Std                      1.29671
evaluation_0/Rewards Max                     10.138
evaluation_0/Rewards Min                     -0.639528
evaluation_0/Returns Mean                  3549.64
evaluation_0/Returns Std                    884.09
evaluation_0/Returns Max                   4861.36
evaluation_0/Returns Min                   2752.21
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3549.64
time/epoch (s)                                0
time/total (s)                            11645.8
Epoch                                       602
---------------------------------------  ----------------
2022-11-16 14:00:10.115794 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 603 finished
---------------------------------------  ----------------
epoch                                       603
total_step                               608000
replay_pool/size                         608000
trainer/alpha                                 0.0641507
trainer/alpha_loss                           -0.560209
trainer/entropy                              -5.79603
trainer/qf_loss                               5.26068
trainer/state_noise                           0.005
trainer/policy_loss                        -205.566
trainer/policy_loss_without_entropy         207.631
trainer/entropy_penalty                      -0.371819
trainer/entropy_percentage                   -0.00179077
trainer/Q1Pred Mean                         207.306
trainer/Q1Pred Std                           75.0497
trainer/Q1Pred Max                          310.087
trainer/Q1Pred Min                            2.30587
trainer/Q2Pred Mean                         207.688
trainer/Q2Pred Std                           74.9825
trainer/Q2Pred Max                          309.655
trainer/Q2Pred Min                            3.65727
trainer/QTargetWithReg Mean                 207.281
trainer/QTargetWithReg Std                   74.8337
trainer/QTargetWithReg Max                  310.092
trainer/QTargetWithReg Min                    1.4064
trainer/PolicyLossWithoutReg Mean           207.631
trainer/PolicyLossWithoutReg Std             74.2313
trainer/PolicyLossWithoutReg Max            309.464
trainer/PolicyLossWithoutReg Min              1.76912
trainer/gradient_norm                       338.615
trainer/gradient_penalty                     -1.69307
trainer/gradient_percentage                  -0.00815427
exploration/num steps total              608000
exploration/num paths total                1765
exploration/path length this epoch Mean     354
exploration/path length this epoch Std       47
exploration/path length this epoch Max      401
exploration/path length this epoch Min      307
exploration/Rewards Mean                      4.36719
exploration/Rewards Std                       1.43718
exploration/Rewards Max                       9.78964
exploration/Rewards Min                      -0.637185
exploration/Returns Mean                   1545.98
exploration/Returns Std                     230.719
exploration/Returns Max                    1776.7
exploration/Returns Min                    1315.27
exploration/Num Paths                         2
exploration/Average Returns                1545.98
evaluation_0/num steps total                  4.74472e+06
evaluation_0/num paths total              12885
evaluation_0/path length Mean               769.7
evaluation_0/path length Std                276.153
evaluation_0/path length Max               1000
evaluation_0/path length Min                409
evaluation_0/Rewards Mean                     4.68079
evaluation_0/Rewards Std                      1.26096
evaluation_0/Rewards Max                      9.97854
evaluation_0/Rewards Min                     -0.574221
evaluation_0/Returns Mean                  3602.81
evaluation_0/Returns Std                   1375.59
evaluation_0/Returns Max                   4809.53
evaluation_0/Returns Min                   1791.28
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3602.81
time/epoch (s)                                0
time/total (s)                            11663.9
Epoch                                       603
---------------------------------------  ----------------
2022-11-16 14:00:27.501301 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 604 finished
---------------------------------------  ----------------
epoch                                       604
total_step                               609000
replay_pool/size                         609000
trainer/alpha                                 0.0638377
trainer/alpha_loss                            0.759103
trainer/entropy                              -6.27589
trainer/qf_loss                               6.40881
trainer/state_noise                           0.005
trainer/policy_loss                        -205.753
trainer/policy_loss_without_entropy         207.861
trainer/entropy_penalty                      -0.400639
trainer/entropy_percentage                   -0.00192743
trainer/Q1Pred Mean                         206.217
trainer/Q1Pred Std                           74.4613
trainer/Q1Pred Max                          311.06
trainer/Q1Pred Min                           -7.22164
trainer/Q2Pred Mean                         206.34
trainer/Q2Pred Std                           74.8875
trainer/Q2Pred Max                          310.088
trainer/Q2Pred Min                            0.482945
trainer/QTargetWithReg Mean                 206.488
trainer/QTargetWithReg Std                   74.5957
trainer/QTargetWithReg Max                  310.419
trainer/QTargetWithReg Min                   -1.78181
trainer/PolicyLossWithoutReg Mean           207.861
trainer/PolicyLossWithoutReg Std             73.5886
trainer/PolicyLossWithoutReg Max            311.768
trainer/PolicyLossWithoutReg Min              1.75474
trainer/gradient_norm                       341.61
trainer/gradient_penalty                     -1.70805
trainer/gradient_percentage                  -0.00821727
exploration/num steps total              609000
exploration/num paths total                1766
exploration/path length this epoch Mean     484
exploration/path length this epoch Std        0
exploration/path length this epoch Max      484
exploration/path length this epoch Min      484
exploration/Rewards Mean                      4.54813
exploration/Rewards Std                       1.3744
exploration/Rewards Max                       9.8049
exploration/Rewards Min                      -0.510516
exploration/Returns Mean                   2201.29
exploration/Returns Std                       0
exploration/Returns Max                    2201.29
exploration/Returns Min                    2201.29
exploration/Num Paths                         1
exploration/Average Returns                2201.29
evaluation_0/num steps total                  4.75252e+06
evaluation_0/num paths total              12894
evaluation_0/path length Mean               866.667
evaluation_0/path length Std                123.79
evaluation_0/path length Max               1000
evaluation_0/path length Min                667
evaluation_0/Rewards Mean                     4.91897
evaluation_0/Rewards Std                      1.31768
evaluation_0/Rewards Max                     10.3109
evaluation_0/Rewards Min                     -0.571238
evaluation_0/Returns Mean                  4263.11
evaluation_0/Returns Std                    663.109
evaluation_0/Returns Max                   4997.43
evaluation_0/Returns Min                   3198.9
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4263.11
time/epoch (s)                                0
time/total (s)                            11681.3
Epoch                                       604
---------------------------------------  ----------------
2022-11-16 14:00:43.930210 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 605 finished
---------------------------------------  ----------------
epoch                                       605
total_step                               610000
replay_pool/size                         610000
trainer/alpha                                 0.063821
trainer/alpha_loss                           -0.47962
trainer/entropy                              -5.8257
trainer/qf_loss                               4.59323
trainer/state_noise                           0.005
trainer/policy_loss                        -214.491
trainer/policy_loss_without_entropy         216.547
trainer/entropy_penalty                      -0.371802
trainer/entropy_percentage                   -0.00171696
trainer/Q1Pred Mean                         215.745
trainer/Q1Pred Std                           71.5703
trainer/Q1Pred Max                          310.358
trainer/Q1Pred Min                            8.27955
trainer/Q2Pred Mean                         216.355
trainer/Q2Pred Std                           71.5944
trainer/Q2Pred Max                          310.317
trainer/Q2Pred Min                            6.50954
trainer/QTargetWithReg Mean                 216.639
trainer/QTargetWithReg Std                   71.6641
trainer/QTargetWithReg Max                  311.046
trainer/QTargetWithReg Min                    8.261
trainer/PolicyLossWithoutReg Mean           216.547
trainer/PolicyLossWithoutReg Std             70.6714
trainer/PolicyLossWithoutReg Max            310.756
trainer/PolicyLossWithoutReg Min              6.34699
trainer/gradient_norm                       336.772
trainer/gradient_penalty                     -1.68386
trainer/gradient_percentage                  -0.00777596
exploration/num steps total              610000
exploration/num paths total                1767
exploration/path length this epoch Mean     661
exploration/path length this epoch Std        0
exploration/path length this epoch Max      661
exploration/path length this epoch Min      661
exploration/Rewards Mean                      4.61594
exploration/Rewards Std                       1.3177
exploration/Rewards Max                       9.98941
exploration/Rewards Min                      -0.535712
exploration/Returns Mean                   3051.13
exploration/Returns Std                       0
exploration/Returns Max                    3051.13
exploration/Returns Min                    3051.13
exploration/Num Paths                         1
exploration/Average Returns                3051.13
evaluation_0/num steps total                  4.76052e+06
evaluation_0/num paths total              12902
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6754
evaluation_0/Rewards Std                      1.2213
evaluation_0/Rewards Max                      9.85587
evaluation_0/Rewards Min                     -0.592835
evaluation_0/Returns Mean                  4675.4
evaluation_0/Returns Std                    101.462
evaluation_0/Returns Max                   4784.7
evaluation_0/Returns Min                   4500.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4675.4
time/epoch (s)                                0
time/total (s)                            11697.7
Epoch                                       605
---------------------------------------  ----------------
2022-11-16 14:00:59.795484 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 606 finished
---------------------------------------  ----------------
epoch                                       606
total_step                               611000
replay_pool/size                         611000
trainer/alpha                                 0.063549
trainer/alpha_loss                           -0.859137
trainer/entropy                              -5.68826
trainer/qf_loss                               6.31746
trainer/state_noise                           0.005
trainer/policy_loss                        -213.019
trainer/policy_loss_without_entropy         215.099
trainer/entropy_penalty                      -0.361484
trainer/entropy_percentage                   -0.00168055
trainer/Q1Pred Mean                         214.521
trainer/Q1Pred Std                           73.6516
trainer/Q1Pred Max                          314.527
trainer/Q1Pred Min                           14.977
trainer/Q2Pred Mean                         214.409
trainer/Q2Pred Std                           73.3799
trainer/Q2Pred Max                          315.244
trainer/Q2Pred Min                           12.3374
trainer/QTargetWithReg Mean                 214.178
trainer/QTargetWithReg Std                   73.1752
trainer/QTargetWithReg Max                  314.883
trainer/QTargetWithReg Min                   12.2198
trainer/PolicyLossWithoutReg Mean           215.099
trainer/PolicyLossWithoutReg Std             72.7621
trainer/PolicyLossWithoutReg Max            314.63
trainer/PolicyLossWithoutReg Min             10.7156
trainer/gradient_norm                       343.717
trainer/gradient_penalty                     -1.71858
trainer/gradient_percentage                  -0.00798974
exploration/num steps total              611000
exploration/num paths total                1768
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56593
exploration/Rewards Std                       1.21637
exploration/Rewards Max                       9.92772
exploration/Rewards Min                      -0.576545
exploration/Returns Mean                   4565.93
exploration/Returns Std                       0
exploration/Returns Max                    4565.93
exploration/Returns Min                    4565.93
exploration/Num Paths                         1
exploration/Average Returns                4565.93
evaluation_0/num steps total                  4.76852e+06
evaluation_0/num paths total              12910
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67462
evaluation_0/Rewards Std                      1.19927
evaluation_0/Rewards Max                      9.91774
evaluation_0/Rewards Min                     -0.569888
evaluation_0/Returns Mean                  4674.62
evaluation_0/Returns Std                     55.4384
evaluation_0/Returns Max                   4749
evaluation_0/Returns Min                   4564.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4674.62
time/epoch (s)                                0
time/total (s)                            11713.6
Epoch                                       606
---------------------------------------  ----------------
2022-11-16 14:01:16.190855 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 607 finished
---------------------------------------  ----------------
epoch                                       607
total_step                               612000
replay_pool/size                         612000
trainer/alpha                                 0.0629641
trainer/alpha_loss                           -0.123987
trainer/entropy                              -5.95516
trainer/qf_loss                               6.6955
trainer/state_noise                           0.005
trainer/policy_loss                        -207.948
trainer/policy_loss_without_entropy         209.982
trainer/entropy_penalty                      -0.374961
trainer/entropy_percentage                   -0.00178568
trainer/Q1Pred Mean                         209.502
trainer/Q1Pred Std                           74.0553
trainer/Q1Pred Max                          312.133
trainer/Q1Pred Min                            9.45483
trainer/Q2Pred Mean                         209.41
trainer/Q2Pred Std                           73.7668
trainer/Q2Pred Max                          310.84
trainer/Q2Pred Min                            9.55915
trainer/QTargetWithReg Mean                 209.262
trainer/QTargetWithReg Std                   73.9042
trainer/QTargetWithReg Max                  312.566
trainer/QTargetWithReg Min                    8.17974
trainer/PolicyLossWithoutReg Mean           209.982
trainer/PolicyLossWithoutReg Std             73.0077
trainer/PolicyLossWithoutReg Max            310.388
trainer/PolicyLossWithoutReg Min             10.5939
trainer/gradient_norm                       331.93
trainer/gradient_penalty                     -1.65965
trainer/gradient_percentage                  -0.00790375
exploration/num steps total              612000
exploration/num paths total                1769
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84836
exploration/Rewards Std                       1.21194
exploration/Rewards Max                       9.87415
exploration/Rewards Min                      -0.471792
exploration/Returns Mean                   4848.36
exploration/Returns Std                       0
exploration/Returns Max                    4848.36
exploration/Returns Min                    4848.36
exploration/Num Paths                         1
exploration/Average Returns                4848.36
evaluation_0/num steps total                  4.77652e+06
evaluation_0/num paths total              12918
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90131
evaluation_0/Rewards Std                      1.23859
evaluation_0/Rewards Max                     10.1042
evaluation_0/Rewards Min                     -0.642107
evaluation_0/Returns Mean                  4901.31
evaluation_0/Returns Std                     74.5476
evaluation_0/Returns Max                   4978.7
evaluation_0/Returns Min                   4725.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4901.31
time/epoch (s)                                0
time/total (s)                            11730
Epoch                                       607
---------------------------------------  ----------------
2022-11-16 14:01:33.563017 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 608 finished
---------------------------------------  ----------------
epoch                                       608
total_step                               613000
replay_pool/size                         613000
trainer/alpha                                 0.0626789
trainer/alpha_loss                           -0.347286
trainer/entropy                              -5.87462
trainer/qf_loss                               5.51067
trainer/state_noise                           0.005
trainer/policy_loss                        -217.115
trainer/policy_loss_without_entropy         219.196
trainer/entropy_penalty                      -0.368214
trainer/entropy_percentage                   -0.00167984
trainer/Q1Pred Mean                         218.314
trainer/Q1Pred Std                           69.5814
trainer/Q1Pred Max                          312.248
trainer/Q1Pred Min                            5.68382
trainer/Q2Pred Mean                         218.617
trainer/Q2Pred Std                           69.4776
trainer/Q2Pred Max                          312.383
trainer/Q2Pred Min                            7.54403
trainer/QTargetWithReg Mean                 218.585
trainer/QTargetWithReg Std                   69.6981
trainer/QTargetWithReg Max                  313.887
trainer/QTargetWithReg Min                    2.88684
trainer/PolicyLossWithoutReg Mean           219.196
trainer/PolicyLossWithoutReg Std             68.8373
trainer/PolicyLossWithoutReg Max            312.266
trainer/PolicyLossWithoutReg Min              5.85595
trainer/gradient_norm                       342.579
trainer/gradient_penalty                     -1.7129
trainer/gradient_percentage                  -0.00781443
exploration/num steps total              613000
exploration/num paths total                1770
exploration/path length this epoch Mean     486
exploration/path length this epoch Std        0
exploration/path length this epoch Max      486
exploration/path length this epoch Min      486
exploration/Rewards Mean                      4.57562
exploration/Rewards Std                       1.38101
exploration/Rewards Max                       9.7379
exploration/Rewards Min                      -0.57548
exploration/Returns Mean                   2223.75
exploration/Returns Std                       0
exploration/Returns Max                    2223.75
exploration/Returns Min                    2223.75
exploration/Num Paths                         1
exploration/Average Returns                2223.75
evaluation_0/num steps total                  4.78414e+06
evaluation_0/num paths total              12926
evaluation_0/path length Mean               952.5
evaluation_0/path length Std                 75.9177
evaluation_0/path length Max               1000
evaluation_0/path length Min                783
evaluation_0/Rewards Mean                     4.69865
evaluation_0/Rewards Std                      1.17184
evaluation_0/Rewards Max                      9.75823
evaluation_0/Rewards Min                     -0.48191
evaluation_0/Returns Mean                  4475.46
evaluation_0/Returns Std                    384.489
evaluation_0/Returns Max                   4745.63
evaluation_0/Returns Min                   3631.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4475.46
time/epoch (s)                                0
time/total (s)                            11747.3
Epoch                                       608
---------------------------------------  ----------------
2022-11-16 14:01:50.606006 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 609 finished
---------------------------------------  ----------------
epoch                                       609
total_step                               614000
replay_pool/size                         614000
trainer/alpha                                 0.0613244
trainer/alpha_loss                            0.918523
trainer/entropy                              -6.32902
trainer/qf_loss                               7.69271
trainer/state_noise                           0.005
trainer/policy_loss                        -210.716
trainer/policy_loss_without_entropy         212.767
trainer/entropy_penalty                      -0.388124
trainer/entropy_percentage                   -0.00182417
trainer/Q1Pred Mean                         212.303
trainer/Q1Pred Std                           74.7868
trainer/Q1Pred Max                          313.442
trainer/Q1Pred Min                            6.62155
trainer/Q2Pred Mean                         212.218
trainer/Q2Pred Std                           74.8802
trainer/Q2Pred Max                          313.912
trainer/Q2Pred Min                            7.47921
trainer/QTargetWithReg Mean                 212.115
trainer/QTargetWithReg Std                   74.6897
trainer/QTargetWithReg Max                  311.937
trainer/QTargetWithReg Min                    4.40031
trainer/PolicyLossWithoutReg Mean           212.767
trainer/PolicyLossWithoutReg Std             74.08
trainer/PolicyLossWithoutReg Max            312.703
trainer/PolicyLossWithoutReg Min              7.92252
trainer/gradient_norm                       332.691
trainer/gradient_penalty                     -1.66345
trainer/gradient_percentage                  -0.00781819
exploration/num steps total              614000
exploration/num paths total                1772
exploration/path length this epoch Mean     492.5
exploration/path length this epoch Std        1.5
exploration/path length this epoch Max      494
exploration/path length this epoch Min      491
exploration/Rewards Mean                      4.51498
exploration/Rewards Std                       1.3664
exploration/Rewards Max                       9.85301
exploration/Rewards Min                      -0.54853
exploration/Returns Mean                   2223.63
exploration/Returns Std                       4.9307
exploration/Returns Max                    2228.56
exploration/Returns Min                    2218.7
exploration/Num Paths                         2
exploration/Average Returns                2223.63
evaluation_0/num steps total                  4.79189e+06
evaluation_0/num paths total              12940
evaluation_0/path length Mean               553.071
evaluation_0/path length Std                 93.9783
evaluation_0/path length Max                855
evaluation_0/path length Min                494
evaluation_0/Rewards Mean                     4.70508
evaluation_0/Rewards Std                      1.35577
evaluation_0/Rewards Max                     10.3092
evaluation_0/Rewards Min                     -0.514011
evaluation_0/Returns Mean                  2602.25
evaluation_0/Returns Std                    478.974
evaluation_0/Returns Max                   4128.25
evaluation_0/Returns Min                   2292.72
evaluation_0/Num Paths                       14
evaluation_0/Average Returns               2602.25
time/epoch (s)                                0
time/total (s)                            11764.4
Epoch                                       609
---------------------------------------  ----------------
2022-11-16 14:02:06.558228 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 610 finished
---------------------------------------  ----------------
epoch                                       610
total_step                               615000
replay_pool/size                         615000
trainer/alpha                                 0.0637846
trainer/alpha_loss                            0.26804
trainer/entropy                              -6.09739
trainer/qf_loss                              10.3804
trainer/state_noise                           0.005
trainer/policy_loss                        -212.297
trainer/policy_loss_without_entropy         214.402
trainer/entropy_penalty                      -0.388919
trainer/entropy_percentage                   -0.00181397
trainer/Q1Pred Mean                         213.671
trainer/Q1Pred Std                           81.3624
trainer/Q1Pred Max                          313.492
trainer/Q1Pred Min                            5.18256
trainer/Q2Pred Mean                         213.666
trainer/Q2Pred Std                           81.3901
trainer/Q2Pred Max                          309.765
trainer/Q2Pred Min                            4.93066
trainer/QTargetWithReg Mean                 213.733
trainer/QTargetWithReg Std                   81.5912
trainer/QTargetWithReg Max                  311.507
trainer/QTargetWithReg Min                    4.59189
trainer/PolicyLossWithoutReg Mean           214.402
trainer/PolicyLossWithoutReg Std             80.833
trainer/PolicyLossWithoutReg Max            310.805
trainer/PolicyLossWithoutReg Min              6.65182
trainer/gradient_norm                       343.282
trainer/gradient_penalty                     -1.71641
trainer/gradient_percentage                  -0.00800557
exploration/num steps total              615000
exploration/num paths total                1773
exploration/path length this epoch Mean     501
exploration/path length this epoch Std        0
exploration/path length this epoch Max      501
exploration/path length this epoch Min      501
exploration/Rewards Mean                      4.65712
exploration/Rewards Std                       1.37801
exploration/Rewards Max                      10.0918
exploration/Rewards Min                      -0.444809
exploration/Returns Mean                   2333.22
exploration/Returns Std                       0
exploration/Returns Max                    2333.22
exploration/Returns Min                    2333.22
exploration/Num Paths                         1
exploration/Average Returns                2333.22
evaluation_0/num steps total                  4.79989e+06
evaluation_0/num paths total              12948
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00001
evaluation_0/Rewards Std                      1.25364
evaluation_0/Rewards Max                     10.2271
evaluation_0/Rewards Min                     -0.474318
evaluation_0/Returns Mean                  5000.01
evaluation_0/Returns Std                     19.2103
evaluation_0/Returns Max                   5024.34
evaluation_0/Returns Min                   4973.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5000.01
time/epoch (s)                                0
time/total (s)                            11780.3
Epoch                                       610
---------------------------------------  ----------------
2022-11-16 14:02:22.756568 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 611 finished
---------------------------------------  ----------------
epoch                                       611
total_step                               616000
replay_pool/size                         616000
trainer/alpha                                 0.0636954
trainer/alpha_loss                            0.792847
trainer/entropy                              -6.28793
trainer/qf_loss                               5.97187
trainer/state_noise                           0.005
trainer/policy_loss                        -215.285
trainer/policy_loss_without_entropy         217.48
trainer/entropy_penalty                      -0.400512
trainer/entropy_percentage                   -0.0018416
trainer/Q1Pred Mean                         216.811
trainer/Q1Pred Std                           70.2621
trainer/Q1Pred Max                          312.48
trainer/Q1Pred Min                           14.8459
trainer/Q2Pred Mean                         216.525
trainer/Q2Pred Std                           70.2509
trainer/Q2Pred Max                          311.25
trainer/Q2Pred Min                            9.81337
trainer/QTargetWithReg Mean                 216.653
trainer/QTargetWithReg Std                   70.1129
trainer/QTargetWithReg Max                  311.675
trainer/QTargetWithReg Min                    9.85535
trainer/PolicyLossWithoutReg Mean           217.48
trainer/PolicyLossWithoutReg Std             69.4378
trainer/PolicyLossWithoutReg Max            312.204
trainer/PolicyLossWithoutReg Min             13.7044
trainer/gradient_norm                       358.897
trainer/gradient_penalty                     -1.79449
trainer/gradient_percentage                  -0.00825125
exploration/num steps total              616000
exploration/num paths total                1776
exploration/path length this epoch Mean     256
exploration/path length this epoch Std      108.037
exploration/path length this epoch Max      402
exploration/path length this epoch Min      144
exploration/Rewards Mean                      4.12722
exploration/Rewards Std                       1.52924
exploration/Rewards Max                       9.80985
exploration/Rewards Min                      -0.725839
exploration/Returns Mean                   1056.57
exploration/Returns Std                     556.165
exploration/Returns Max                    1799.6
exploration/Returns Min                     461.658
exploration/Num Paths                         3
exploration/Average Returns                1056.57
evaluation_0/num steps total                  4.80789e+06
evaluation_0/num paths total              12956
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86734
evaluation_0/Rewards Std                      1.24387
evaluation_0/Rewards Max                     10.0994
evaluation_0/Rewards Min                     -0.558633
evaluation_0/Returns Mean                  4867.34
evaluation_0/Returns Std                     72.6793
evaluation_0/Returns Max                   4958.29
evaluation_0/Returns Min                   4720.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4867.34
time/epoch (s)                                0
time/total (s)                            11796.5
Epoch                                       611
---------------------------------------  ----------------
2022-11-16 14:02:38.827974 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 612 finished
---------------------------------------  ----------------
epoch                                       612
total_step                               617000
replay_pool/size                         617000
trainer/alpha                                 0.0647749
trainer/alpha_loss                            0.00940146
trainer/entropy                              -6.00344
trainer/qf_loss                               6.86664
trainer/state_noise                           0.005
trainer/policy_loss                        -209.903
trainer/policy_loss_without_entropy         212.03
trainer/entropy_penalty                      -0.388872
trainer/entropy_percentage                   -0.00183404
trainer/Q1Pred Mean                         210.667
trainer/Q1Pred Std                           73.6475
trainer/Q1Pred Max                          314.079
trainer/Q1Pred Min                           -6.7607
trainer/Q2Pred Mean                         210.913
trainer/Q2Pred Std                           73.2112
trainer/Q2Pred Max                          313.175
trainer/Q2Pred Min                           -0.0740658
trainer/QTargetWithReg Mean                 210.989
trainer/QTargetWithReg Std                   73.6106
trainer/QTargetWithReg Max                  312.929
trainer/QTargetWithReg Min                    1.05813
trainer/PolicyLossWithoutReg Mean           212.03
trainer/PolicyLossWithoutReg Std             72.1188
trainer/PolicyLossWithoutReg Max            313.343
trainer/PolicyLossWithoutReg Min              3.67773
trainer/gradient_norm                       347.52
trainer/gradient_penalty                     -1.7376
trainer/gradient_percentage                  -0.00819508
exploration/num steps total              617000
exploration/num paths total                1777
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75525
exploration/Rewards Std                       1.2264
exploration/Rewards Max                       9.69159
exploration/Rewards Min                      -0.53642
exploration/Returns Mean                   4755.25
exploration/Returns Std                       0
exploration/Returns Max                    4755.25
exploration/Returns Min                    4755.25
exploration/Num Paths                         1
exploration/Average Returns                4755.25
evaluation_0/num steps total                  4.81589e+06
evaluation_0/num paths total              12964
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98471
evaluation_0/Rewards Std                      1.24462
evaluation_0/Rewards Max                      9.97416
evaluation_0/Rewards Min                     -0.432107
evaluation_0/Returns Mean                  4984.71
evaluation_0/Returns Std                     64.6266
evaluation_0/Returns Max                   5033.9
evaluation_0/Returns Min                   4818.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4984.71
time/epoch (s)                                0
time/total (s)                            11812.6
Epoch                                       612
---------------------------------------  ----------------
2022-11-16 14:02:54.728628 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 613 finished
---------------------------------------  ----------------
epoch                                       613
total_step                               618000
replay_pool/size                         618000
trainer/alpha                                 0.0652408
trainer/alpha_loss                           -1.59098
trainer/entropy                              -5.41711
trainer/qf_loss                              13.8667
trainer/state_noise                           0.005
trainer/policy_loss                        -207.702
trainer/policy_loss_without_entropy         209.724
trainer/entropy_penalty                      -0.353416
trainer/entropy_percentage                   -0.00168515
trainer/Q1Pred Mean                         208.609
trainer/Q1Pred Std                           75.1325
trainer/Q1Pred Max                          310.308
trainer/Q1Pred Min                            8.42062
trainer/Q2Pred Mean                         208.783
trainer/Q2Pred Std                           75.604
trainer/Q2Pred Max                          308.33
trainer/Q2Pred Min                           -2.66152
trainer/QTargetWithReg Mean                 210.123
trainer/QTargetWithReg Std                   76.0042
trainer/QTargetWithReg Max                  312.838
trainer/QTargetWithReg Min                    1.5663
trainer/PolicyLossWithoutReg Mean           209.724
trainer/PolicyLossWithoutReg Std             74.7017
trainer/PolicyLossWithoutReg Max            308.149
trainer/PolicyLossWithoutReg Min             10.764
trainer/gradient_norm                       333.685
trainer/gradient_penalty                     -1.66842
trainer/gradient_percentage                  -0.00795534
exploration/num steps total              618000
exploration/num paths total                1778
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70899
exploration/Rewards Std                       1.22789
exploration/Rewards Max                       9.8287
exploration/Rewards Min                      -0.308958
exploration/Returns Mean                   4708.99
exploration/Returns Std                       0
exploration/Returns Max                    4708.99
exploration/Returns Min                    4708.99
exploration/Num Paths                         1
exploration/Average Returns                4708.99
evaluation_0/num steps total                  4.82389e+06
evaluation_0/num paths total              12972
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6335
evaluation_0/Rewards Std                      1.21885
evaluation_0/Rewards Max                      9.79252
evaluation_0/Rewards Min                     -0.465135
evaluation_0/Returns Mean                  4633.5
evaluation_0/Returns Std                     71.449
evaluation_0/Returns Max                   4682.76
evaluation_0/Returns Min                   4456.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4633.5
time/epoch (s)                                0
time/total (s)                            11828.5
Epoch                                       613
---------------------------------------  ----------------
2022-11-16 14:03:11.018428 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 614 finished
---------------------------------------  ----------------
epoch                                       614
total_step                               619000
replay_pool/size                         619000
trainer/alpha                                 0.0640286
trainer/alpha_loss                           -0.151216
trainer/entropy                              -5.94498
trainer/qf_loss                               7.90043
trainer/state_noise                           0.005
trainer/policy_loss                        -209.516
trainer/policy_loss_without_entropy         211.511
trainer/entropy_penalty                      -0.380648
trainer/entropy_percentage                   -0.00179966
trainer/Q1Pred Mean                         210.525
trainer/Q1Pred Std                           73.6386
trainer/Q1Pred Max                          313.882
trainer/Q1Pred Min                            6.08145
trainer/Q2Pred Mean                         210.819
trainer/Q2Pred Std                           73.6092
trainer/Q2Pred Max                          314.424
trainer/Q2Pred Min                            4.80677
trainer/QTargetWithReg Mean                 210.421
trainer/QTargetWithReg Std                   74.2276
trainer/QTargetWithReg Max                  313.989
trainer/QTargetWithReg Min                    4.13574
trainer/PolicyLossWithoutReg Mean           211.511
trainer/PolicyLossWithoutReg Std             73.1924
trainer/PolicyLossWithoutReg Max            314.196
trainer/PolicyLossWithoutReg Min              5.26588
trainer/gradient_norm                       322.846
trainer/gradient_penalty                     -1.61423
trainer/gradient_percentage                  -0.00763191
exploration/num steps total              619000
exploration/num paths total                1779
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72976
exploration/Rewards Std                       1.22034
exploration/Rewards Max                       9.76626
exploration/Rewards Min                      -0.450905
exploration/Returns Mean                   4729.76
exploration/Returns Std                       0
exploration/Returns Max                    4729.76
exploration/Returns Min                    4729.76
exploration/Num Paths                         1
exploration/Average Returns                4729.76
evaluation_0/num steps total                  4.83189e+06
evaluation_0/num paths total              12980
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02643
evaluation_0/Rewards Std                      1.2064
evaluation_0/Rewards Max                      9.86837
evaluation_0/Rewards Min                     -0.439911
evaluation_0/Returns Mean                  5026.43
evaluation_0/Returns Std                      9.1631
evaluation_0/Returns Max                   5043.41
evaluation_0/Returns Min                   5017.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5026.43
time/epoch (s)                                0
time/total (s)                            11844.8
Epoch                                       614
---------------------------------------  ----------------
2022-11-16 14:03:26.842098 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 615 finished
---------------------------------------  ----------------
epoch                                       615
total_step                               620000
replay_pool/size                         620000
trainer/alpha                                 0.0632668
trainer/alpha_loss                           -0.949123
trainer/entropy                              -5.65617
trainer/qf_loss                               8.03876
trainer/state_noise                           0.005
trainer/policy_loss                        -212.486
trainer/policy_loss_without_entropy         214.54
trainer/entropy_penalty                      -0.357848
trainer/entropy_percentage                   -0.00166798
trainer/Q1Pred Mean                         214.242
trainer/Q1Pred Std                           73.8853
trainer/Q1Pred Max                          309.462
trainer/Q1Pred Min                           -9.07825
trainer/Q2Pred Mean                         214.366
trainer/Q2Pred Std                           74.1116
trainer/Q2Pred Max                          309.886
trainer/Q2Pred Min                          -20.2281
trainer/QTargetWithReg Mean                 213.808
trainer/QTargetWithReg Std                   74.148
trainer/QTargetWithReg Max                  308.964
trainer/QTargetWithReg Min                  -11.5676
trainer/PolicyLossWithoutReg Mean           214.54
trainer/PolicyLossWithoutReg Std             73.4308
trainer/PolicyLossWithoutReg Max            309.836
trainer/PolicyLossWithoutReg Min            -15.5761
trainer/gradient_norm                       339.106
trainer/gradient_penalty                     -1.69553
trainer/gradient_percentage                  -0.00790311
exploration/num steps total              620000
exploration/num paths total                1780
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71731
exploration/Rewards Std                       1.19902
exploration/Rewards Max                       9.69595
exploration/Rewards Min                      -0.487987
exploration/Returns Mean                   4717.31
exploration/Returns Std                       0
exploration/Returns Max                    4717.31
exploration/Returns Min                    4717.31
exploration/Num Paths                         1
exploration/Average Returns                4717.31
evaluation_0/num steps total                  4.83989e+06
evaluation_0/num paths total              12988
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85784
evaluation_0/Rewards Std                      1.24219
evaluation_0/Rewards Max                      9.94326
evaluation_0/Rewards Min                     -0.365801
evaluation_0/Returns Mean                  4857.84
evaluation_0/Returns Std                    151.634
evaluation_0/Returns Max                   5001.18
evaluation_0/Returns Min                   4642.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4857.84
time/epoch (s)                                0
time/total (s)                            11860.6
Epoch                                       615
---------------------------------------  ----------------
2022-11-16 14:03:44.809388 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 616 finished
---------------------------------------  ---------------
epoch                                       616
total_step                               621000
replay_pool/size                         621000
trainer/alpha                                 0.0644675
trainer/alpha_loss                           -0.094602
trainer/entropy                              -5.96549
trainer/qf_loss                               8.12649
trainer/state_noise                           0.005
trainer/policy_loss                        -206.546
trainer/policy_loss_without_entropy         208.665
trainer/entropy_penalty                      -0.38458
trainer/entropy_percentage                   -0.00184305
trainer/Q1Pred Mean                         208.512
trainer/Q1Pred Std                           74.9411
trainer/Q1Pred Max                          307.919
trainer/Q1Pred Min                           -0.281518
trainer/Q2Pred Mean                         207.975
trainer/Q2Pred Std                           75.2624
trainer/Q2Pred Max                          308.747
trainer/Q2Pred Min                           -4.16988
trainer/QTargetWithReg Mean                 207.666
trainer/QTargetWithReg Std                   75.0628
trainer/QTargetWithReg Max                  308.647
trainer/QTargetWithReg Min                   -0.779514
trainer/PolicyLossWithoutReg Mean           208.665
trainer/PolicyLossWithoutReg Std             73.9207
trainer/PolicyLossWithoutReg Max            308.193
trainer/PolicyLossWithoutReg Min              1.83381
trainer/gradient_norm                       346.899
trainer/gradient_penalty                     -1.73449
trainer/gradient_percentage                  -0.00831232
exploration/num steps total              621000
exploration/num paths total                1781
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.46388
exploration/Rewards Std                       1.23918
exploration/Rewards Max                       9.80238
exploration/Rewards Min                      -0.414395
exploration/Returns Mean                   4463.88
exploration/Returns Std                       0
exploration/Returns Max                    4463.88
exploration/Returns Min                    4463.88
exploration/Num Paths                         1
exploration/Average Returns                4463.88
evaluation_0/num steps total                  4.8475e+06
evaluation_0/num paths total              12997
evaluation_0/path length Mean               845.556
evaluation_0/path length Std                221.115
evaluation_0/path length Max               1000
evaluation_0/path length Min                493
evaluation_0/Rewards Mean                     4.6462
evaluation_0/Rewards Std                      1.28983
evaluation_0/Rewards Max                      9.89835
evaluation_0/Rewards Min                     -0.49962
evaluation_0/Returns Mean                  3928.62
evaluation_0/Returns Std                   1062.84
evaluation_0/Returns Max                   4789.28
evaluation_0/Returns Min                   2256.93
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               3928.62
time/epoch (s)                                0
time/total (s)                            11878.6
Epoch                                       616
---------------------------------------  ---------------
2022-11-16 14:04:00.675149 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 617 finished
---------------------------------------  ---------------
epoch                                       617
total_step                               622000
replay_pool/size                         622000
trainer/alpha                                 0.0637666
trainer/alpha_loss                           -0.815002
trainer/entropy                              -5.7039
trainer/qf_loss                              10.4236
trainer/state_noise                           0.005
trainer/policy_loss                        -207.564
trainer/policy_loss_without_entropy         209.577
trainer/entropy_penalty                      -0.363718
trainer/entropy_percentage                   -0.00173549
trainer/Q1Pred Mean                         208.728
trainer/Q1Pred Std                           73.7278
trainer/Q1Pred Max                          313.098
trainer/Q1Pred Min                            4.6431
trainer/Q2Pred Mean                         208.99
trainer/Q2Pred Std                           73.7535
trainer/Q2Pred Max                          310.388
trainer/Q2Pred Min                            6.20666
trainer/QTargetWithReg Mean                 208.521
trainer/QTargetWithReg Std                   73.8981
trainer/QTargetWithReg Max                  312.259
trainer/QTargetWithReg Min                    4.19898
trainer/PolicyLossWithoutReg Mean           209.577
trainer/PolicyLossWithoutReg Std             72.943
trainer/PolicyLossWithoutReg Max            310.393
trainer/PolicyLossWithoutReg Min              5.92705
trainer/gradient_norm                       329.741
trainer/gradient_penalty                     -1.64871
trainer/gradient_percentage                  -0.00786684
exploration/num steps total              622000
exploration/num paths total                1782
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15298
exploration/Rewards Std                       1.3082
exploration/Rewards Max                       9.53647
exploration/Rewards Min                      -0.424066
exploration/Returns Mean                   4152.98
exploration/Returns Std                       0
exploration/Returns Max                    4152.98
exploration/Returns Min                    4152.98
exploration/Num Paths                         1
exploration/Average Returns                4152.98
evaluation_0/num steps total                  4.8555e+06
evaluation_0/num paths total              13005
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92506
evaluation_0/Rewards Std                      1.22507
evaluation_0/Rewards Max                      9.92748
evaluation_0/Rewards Min                     -0.503097
evaluation_0/Returns Mean                  4925.06
evaluation_0/Returns Std                     91.5763
evaluation_0/Returns Max                   5057.26
evaluation_0/Returns Min                   4813.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4925.06
time/epoch (s)                                0
time/total (s)                            11894.5
Epoch                                       617
---------------------------------------  ---------------
2022-11-16 14:04:18.716038 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 618 finished
---------------------------------------  ---------------
epoch                                       618
total_step                               623000
replay_pool/size                         623000
trainer/alpha                                 0.0654618
trainer/alpha_loss                            0.368344
trainer/entropy                              -6.13512
trainer/qf_loss                               5.51754
trainer/state_noise                           0.005
trainer/policy_loss                        -210.186
trainer/policy_loss_without_entropy         212.25
trainer/entropy_penalty                      -0.401616
trainer/entropy_percentage                   -0.00189218
trainer/Q1Pred Mean                         211.347
trainer/Q1Pred Std                           72.265
trainer/Q1Pred Max                          314.566
trainer/Q1Pred Min                            7.14572
trainer/Q2Pred Mean                         211.223
trainer/Q2Pred Std                           72.3012
trainer/Q2Pred Max                          313.211
trainer/Q2Pred Min                            6.04142
trainer/QTargetWithReg Mean                 211.648
trainer/QTargetWithReg Std                   72.6322
trainer/QTargetWithReg Max                  314.825
trainer/QTargetWithReg Min                    5.26218
trainer/PolicyLossWithoutReg Mean           212.25
trainer/PolicyLossWithoutReg Std             71.6176
trainer/PolicyLossWithoutReg Max            313.671
trainer/PolicyLossWithoutReg Min              6.91479
trainer/gradient_norm                       332.562
trainer/gradient_penalty                     -1.66281
trainer/gradient_percentage                  -0.0078342
exploration/num steps total              623000
exploration/num paths total                1783
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.69216
exploration/Rewards Std                       1.18704
exploration/Rewards Max                       9.49825
exploration/Rewards Min                      -0.482724
exploration/Returns Mean                   4692.16
exploration/Returns Std                       0
exploration/Returns Max                    4692.16
exploration/Returns Min                    4692.16
exploration/Num Paths                         1
exploration/Average Returns                4692.16
evaluation_0/num steps total                  4.8633e+06
evaluation_0/num paths total              13014
evaluation_0/path length Mean               866.889
evaluation_0/path length Std                188.281
evaluation_0/path length Max               1000
evaluation_0/path length Min                592
evaluation_0/Rewards Mean                     4.65862
evaluation_0/Rewards Std                      1.244
evaluation_0/Rewards Max                      9.9016
evaluation_0/Rewards Min                     -0.566889
evaluation_0/Returns Mean                  4038.51
evaluation_0/Returns Std                    871.066
evaluation_0/Returns Max                   4687.35
evaluation_0/Returns Min                   2776.9
evaluation_0/Num Paths                        9
evaluation_0/Average Returns               4038.51
time/epoch (s)                                0
time/total (s)                            11912.5
Epoch                                       618
---------------------------------------  ---------------
2022-11-16 14:04:36.121377 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 619 finished
---------------------------------------  ----------------
epoch                                       619
total_step                               624000
replay_pool/size                         624000
trainer/alpha                                 0.0641757
trainer/alpha_loss                           -0.534114
trainer/entropy                              -5.8055
trainer/qf_loss                               7.61052
trainer/state_noise                           0.005
trainer/policy_loss                        -206.065
trainer/policy_loss_without_entropy         208.04
trainer/entropy_penalty                      -0.372573
trainer/entropy_percentage                   -0.00179087
trainer/Q1Pred Mean                         207.523
trainer/Q1Pred Std                           82.5859
trainer/Q1Pred Max                          305.911
trainer/Q1Pred Min                            0.336148
trainer/Q2Pred Mean                         207.157
trainer/Q2Pred Std                           82.8665
trainer/Q2Pred Max                          307.041
trainer/Q2Pred Min                           -5.44478
trainer/QTargetWithReg Mean                 207.7
trainer/QTargetWithReg Std                   82.8741
trainer/QTargetWithReg Max                  309.226
trainer/QTargetWithReg Min                    1.38902
trainer/PolicyLossWithoutReg Mean           208.04
trainer/PolicyLossWithoutReg Std             82.0099
trainer/PolicyLossWithoutReg Max            307.763
trainer/PolicyLossWithoutReg Min              5.31301
trainer/gradient_norm                       320.573
trainer/gradient_penalty                     -1.60286
trainer/gradient_percentage                  -0.00770459
exploration/num steps total              624000
exploration/num paths total                1784
exploration/path length this epoch Mean     408
exploration/path length this epoch Std        0
exploration/path length this epoch Max      408
exploration/path length this epoch Min      408
exploration/Rewards Mean                      4.42531
exploration/Rewards Std                       1.35779
exploration/Rewards Max                       9.16502
exploration/Rewards Min                      -0.696718
exploration/Returns Mean                   1805.53
exploration/Returns Std                       0
exploration/Returns Max                    1805.53
exploration/Returns Min                    1805.53
exploration/Num Paths                         1
exploration/Average Returns                1805.53
evaluation_0/num steps total                  4.87122e+06
evaluation_0/num paths total              13022
evaluation_0/path length Mean               990.625
evaluation_0/path length Std                 24.8039
evaluation_0/path length Max               1000
evaluation_0/path length Min                925
evaluation_0/Rewards Mean                     4.68697
evaluation_0/Rewards Std                      1.27066
evaluation_0/Rewards Max                      9.5329
evaluation_0/Rewards Min                     -0.512765
evaluation_0/Returns Mean                  4643.03
evaluation_0/Returns Std                    173.299
evaluation_0/Returns Max                   4817.99
evaluation_0/Returns Min                   4333.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4643.03
time/epoch (s)                                0
time/total (s)                            11929.9
Epoch                                       619
---------------------------------------  ----------------
2022-11-16 14:04:53.862391 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 620 finished
---------------------------------------  ----------------
epoch                                       620
total_step                               625000
replay_pool/size                         625000
trainer/alpha                                 0.0631375
trainer/alpha_loss                            0.888036
trainer/entropy                              -6.32148
trainer/qf_loss                               9.1401
trainer/state_noise                           0.005
trainer/policy_loss                        -204.744
trainer/policy_loss_without_entropy         206.755
trainer/entropy_penalty                      -0.399122
trainer/entropy_percentage                   -0.00193041
trainer/Q1Pred Mean                         206.01
trainer/Q1Pred Std                           79.47
trainer/Q1Pred Max                          311.836
trainer/Q1Pred Min                           -5.80086
trainer/Q2Pred Mean                         206.346
trainer/Q2Pred Std                           79.283
trainer/Q2Pred Max                          313.756
trainer/Q2Pred Min                           -7.31035
trainer/QTargetWithReg Mean                 205.477
trainer/QTargetWithReg Std                   79.3601
trainer/QTargetWithReg Max                  310.961
trainer/QTargetWithReg Min                   -4.65776
trainer/PolicyLossWithoutReg Mean           206.755
trainer/PolicyLossWithoutReg Std             78.5722
trainer/PolicyLossWithoutReg Max            311.555
trainer/PolicyLossWithoutReg Min             -3.96828
trainer/gradient_norm                       322.219
trainer/gradient_penalty                     -1.6111
trainer/gradient_percentage                  -0.00779231
exploration/num steps total              625000
exploration/num paths total                1785
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.15437
exploration/Rewards Std                       1.35952
exploration/Rewards Max                       9.62296
exploration/Rewards Min                      -0.445728
exploration/Returns Mean                   4154.37
exploration/Returns Std                       0
exploration/Returns Max                    4154.37
exploration/Returns Min                    4154.37
exploration/Num Paths                         1
exploration/Average Returns                4154.37
evaluation_0/num steps total                  4.87832e+06
evaluation_0/num paths total              13032
evaluation_0/path length Mean               709.8
evaluation_0/path length Std                443.288
evaluation_0/path length Max               1000
evaluation_0/path length Min                 32
evaluation_0/Rewards Mean                     4.84326
evaluation_0/Rewards Std                      1.25557
evaluation_0/Rewards Max                      9.38001
evaluation_0/Rewards Min                     -0.541656
evaluation_0/Returns Mean                  3437.75
evaluation_0/Returns Std                   2219.36
evaluation_0/Returns Max                   4911.39
evaluation_0/Returns Min                     44.4989
evaluation_0/Num Paths                       10
evaluation_0/Average Returns               3437.75
time/epoch (s)                                0
time/total (s)                            11947.6
Epoch                                       620
---------------------------------------  ----------------
2022-11-16 14:05:09.877173 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 621 finished
---------------------------------------  ----------------
epoch                                       621
total_step                               626000
replay_pool/size                         626000
trainer/alpha                                 0.062888
trainer/alpha_loss                           -0.495977
trainer/entropy                              -5.8207
trainer/qf_loss                               5.49333
trainer/state_noise                           0.005
trainer/policy_loss                        -216.903
trainer/policy_loss_without_entropy         218.897
trainer/entropy_penalty                      -0.366052
trainer/entropy_percentage                   -0.00167226
trainer/Q1Pred Mean                         218.465
trainer/Q1Pred Std                           70.3964
trainer/Q1Pred Max                          310.272
trainer/Q1Pred Min                            9.71173
trainer/Q2Pred Mean                         218.268
trainer/Q2Pred Std                           70.137
trainer/Q2Pred Max                          310.054
trainer/Q2Pred Min                           14.7278
trainer/QTargetWithReg Mean                 218.486
trainer/QTargetWithReg Std                   70.4526
trainer/QTargetWithReg Max                  309.615
trainer/QTargetWithReg Min                   10.2014
trainer/PolicyLossWithoutReg Mean           218.897
trainer/PolicyLossWithoutReg Std             69.574
trainer/PolicyLossWithoutReg Max            309.79
trainer/PolicyLossWithoutReg Min             12.8127
trainer/gradient_norm                       325.426
trainer/gradient_penalty                     -1.62713
trainer/gradient_percentage                  -0.00743333
exploration/num steps total              626000
exploration/num paths total                1786
exploration/path length this epoch Mean      37
exploration/path length this epoch Std        0
exploration/path length this epoch Max       37
exploration/path length this epoch Min       37
exploration/Rewards Mean                      1.58213
exploration/Rewards Std                       1.58079
exploration/Rewards Max                       4.30057
exploration/Rewards Min                      -0.588458
exploration/Returns Mean                     58.539
exploration/Returns Std                       0
exploration/Returns Max                      58.539
exploration/Returns Min                      58.539
exploration/Num Paths                         1
exploration/Average Returns                  58.539
evaluation_0/num steps total                  4.88632e+06
evaluation_0/num paths total              13040
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02622
evaluation_0/Rewards Std                      1.27951
evaluation_0/Rewards Max                      9.93523
evaluation_0/Rewards Min                     -0.492813
evaluation_0/Returns Mean                  5026.22
evaluation_0/Returns Std                     10.4271
evaluation_0/Returns Max                   5044.78
evaluation_0/Returns Min                   5012.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5026.22
time/epoch (s)                                0
time/total (s)                            11963.7
Epoch                                       621
---------------------------------------  ----------------
2022-11-16 14:05:26.013577 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 622 finished
---------------------------------------  ----------------
epoch                                       622
total_step                               627000
replay_pool/size                         627000
trainer/alpha                                 0.0633591
trainer/alpha_loss                            1.50694
trainer/entropy                              -6.54618
trainer/qf_loss                               7.80083
trainer/state_noise                           0.005
trainer/policy_loss                        -201.471
trainer/policy_loss_without_entropy         203.539
trainer/entropy_penalty                      -0.41476
trainer/entropy_percentage                   -0.00203774
trainer/Q1Pred Mean                         202.706
trainer/Q1Pred Std                           80.0537
trainer/Q1Pred Max                          310.839
trainer/Q1Pred Min                            3.12806
trainer/Q2Pred Mean                         202.779
trainer/Q2Pred Std                           79.8018
trainer/Q2Pred Max                          312.505
trainer/Q2Pred Min                            2.57046
trainer/QTargetWithReg Mean                 203.102
trainer/QTargetWithReg Std                   80.2566
trainer/QTargetWithReg Max                  313.189
trainer/QTargetWithReg Min                    4.66743
trainer/PolicyLossWithoutReg Mean           203.539
trainer/PolicyLossWithoutReg Std             78.7219
trainer/PolicyLossWithoutReg Max            311.054
trainer/PolicyLossWithoutReg Min              1.56859
trainer/gradient_norm                       330.706
trainer/gradient_penalty                     -1.65353
trainer/gradient_percentage                  -0.00812388
exploration/num steps total              627000
exploration/num paths total                1787
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.61889
exploration/Rewards Std                       1.25904
exploration/Rewards Max                       9.82916
exploration/Rewards Min                      -0.594586
exploration/Returns Mean                   4618.89
exploration/Returns Std                       0
exploration/Returns Max                    4618.89
exploration/Returns Min                    4618.89
exploration/Num Paths                         1
exploration/Average Returns                4618.89
evaluation_0/num steps total                  4.89432e+06
evaluation_0/num paths total              13048
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.72441
evaluation_0/Rewards Std                      1.24734
evaluation_0/Rewards Max                      9.84604
evaluation_0/Rewards Min                     -0.499472
evaluation_0/Returns Mean                  4724.41
evaluation_0/Returns Std                    119.613
evaluation_0/Returns Max                   4871.95
evaluation_0/Returns Min                   4467.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4724.41
time/epoch (s)                                0
time/total (s)                            11979.8
Epoch                                       622
---------------------------------------  ----------------
2022-11-16 14:05:42.205967 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 623 finished
---------------------------------------  ----------------
epoch                                       623
total_step                               628000
replay_pool/size                         628000
trainer/alpha                                 0.0633167
trainer/alpha_loss                            0.713088
trainer/entropy                              -6.25839
trainer/qf_loss                               9.14419
trainer/state_noise                           0.005
trainer/policy_loss                        -203.924
trainer/policy_loss_without_entropy         206.02
trainer/entropy_penalty                      -0.396261
trainer/entropy_percentage                   -0.00192341
trainer/Q1Pred Mean                         205.644
trainer/Q1Pred Std                           76.7036
trainer/Q1Pred Max                          315.289
trainer/Q1Pred Min                            4.34973
trainer/Q2Pred Mean                         205.291
trainer/Q2Pred Std                           76.8333
trainer/Q2Pred Max                          315.618
trainer/Q2Pred Min                            4.6554
trainer/QTargetWithReg Mean                 205.192
trainer/QTargetWithReg Std                   76.8676
trainer/QTargetWithReg Max                  314.857
trainer/QTargetWithReg Min                    5.63317
trainer/PolicyLossWithoutReg Mean           206.02
trainer/PolicyLossWithoutReg Std             76.2265
trainer/PolicyLossWithoutReg Max            314.761
trainer/PolicyLossWithoutReg Min              7.46075
trainer/gradient_norm                       339.809
trainer/gradient_penalty                     -1.69905
trainer/gradient_percentage                  -0.00824701
exploration/num steps total              628000
exploration/num paths total                1788
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.55484
exploration/Rewards Std                       1.2367
exploration/Rewards Max                       9.99131
exploration/Rewards Min                      -0.555856
exploration/Returns Mean                   4554.84
exploration/Returns Std                       0
exploration/Returns Max                    4554.84
exploration/Returns Min                    4554.84
exploration/Num Paths                         1
exploration/Average Returns                4554.84
evaluation_0/num steps total                  4.90232e+06
evaluation_0/num paths total              13056
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.67796
evaluation_0/Rewards Std                      1.27453
evaluation_0/Rewards Max                      9.79969
evaluation_0/Rewards Min                     -0.544551
evaluation_0/Returns Mean                  4677.96
evaluation_0/Returns Std                    175.227
evaluation_0/Returns Max                   4829.3
evaluation_0/Returns Min                   4280.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4677.96
time/epoch (s)                                0
time/total (s)                            11996
Epoch                                       623
---------------------------------------  ----------------
2022-11-16 14:05:57.991268 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 624 finished
---------------------------------------  ----------------
epoch                                       624
total_step                               629000
replay_pool/size                         629000
trainer/alpha                                 0.0639264
trainer/alpha_loss                            0.36408
trainer/entropy                              -6.13238
trainer/qf_loss                               4.90872
trainer/state_noise                           0.005
trainer/policy_loss                        -216.378
trainer/policy_loss_without_entropy         218.446
trainer/entropy_penalty                      -0.392021
trainer/entropy_percentage                   -0.00179459
trainer/Q1Pred Mean                         217.983
trainer/Q1Pred Std                           71.7195
trainer/Q1Pred Max                          305.459
trainer/Q1Pred Min                          -24.6093
trainer/Q2Pred Mean                         218.204
trainer/Q2Pred Std                           71.4941
trainer/Q2Pred Max                          306.329
trainer/Q2Pred Min                          -24.0334
trainer/QTargetWithReg Mean                 218.403
trainer/QTargetWithReg Std                   71.6291
trainer/QTargetWithReg Max                  307.261
trainer/QTargetWithReg Min                  -22.3988
trainer/PolicyLossWithoutReg Mean           218.446
trainer/PolicyLossWithoutReg Std             70.8855
trainer/PolicyLossWithoutReg Max            305.22
trainer/PolicyLossWithoutReg Min            -19.5461
trainer/gradient_norm                       335.268
trainer/gradient_penalty                     -1.67634
trainer/gradient_percentage                  -0.00767394
exploration/num steps total              629000
exploration/num paths total                1789
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70026
exploration/Rewards Std                       1.21336
exploration/Rewards Max                       9.67515
exploration/Rewards Min                      -0.381162
exploration/Returns Mean                   4700.26
exploration/Returns Std                       0
exploration/Returns Max                    4700.26
exploration/Returns Min                    4700.26
exploration/Num Paths                         1
exploration/Average Returns                4700.26
evaluation_0/num steps total                  4.91032e+06
evaluation_0/num paths total              13064
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.6299
evaluation_0/Rewards Std                      1.19797
evaluation_0/Rewards Max                      9.80342
evaluation_0/Rewards Min                     -0.456532
evaluation_0/Returns Mean                  4629.9
evaluation_0/Returns Std                     72.1227
evaluation_0/Returns Max                   4767.4
evaluation_0/Returns Min                   4560.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4629.9
time/epoch (s)                                0
time/total (s)                            12011.8
Epoch                                       624
---------------------------------------  ----------------
2022-11-16 14:06:14.528692 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 625 finished
---------------------------------------  ----------------
epoch                                       625
total_step                               630000
replay_pool/size                         630000
trainer/alpha                                 0.0643981
trainer/alpha_loss                           -0.19088
trainer/entropy                              -5.9304
trainer/qf_loss                               6.31518
trainer/state_noise                           0.005
trainer/policy_loss                        -216.886
trainer/policy_loss_without_entropy         218.891
trainer/entropy_penalty                      -0.381907
trainer/entropy_percentage                   -0.00174474
trainer/Q1Pred Mean                         219.025
trainer/Q1Pred Std                           72.7974
trainer/Q1Pred Max                          311.867
trainer/Q1Pred Min                           -8.56592
trainer/Q2Pred Mean                         218.835
trainer/Q2Pred Std                           72.6269
trainer/Q2Pred Max                          309.885
trainer/Q2Pred Min                          -12.7849
trainer/QTargetWithReg Mean                 218.33
trainer/QTargetWithReg Std                   72.8532
trainer/QTargetWithReg Max                  309.626
trainer/QTargetWithReg Min                   -9.63668
trainer/PolicyLossWithoutReg Mean           218.891
trainer/PolicyLossWithoutReg Std             71.9872
trainer/PolicyLossWithoutReg Max            309.789
trainer/PolicyLossWithoutReg Min             -6.43608
trainer/gradient_norm                       324.553
trainer/gradient_penalty                     -1.62277
trainer/gradient_percentage                  -0.00741358
exploration/num steps total              630000
exploration/num paths total                1790
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91563
exploration/Rewards Std                       1.25115
exploration/Rewards Max                       9.9101
exploration/Rewards Min                      -0.56998
exploration/Returns Mean                   4915.63
exploration/Returns Std                       0
exploration/Returns Max                    4915.63
exploration/Returns Min                    4915.63
exploration/Num Paths                         1
exploration/Average Returns                4915.63
evaluation_0/num steps total                  4.91832e+06
evaluation_0/num paths total              13072
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81251
evaluation_0/Rewards Std                      1.22692
evaluation_0/Rewards Max                     10.0629
evaluation_0/Rewards Min                     -0.39044
evaluation_0/Returns Mean                  4812.51
evaluation_0/Returns Std                     54.7606
evaluation_0/Returns Max                   4902.86
evaluation_0/Returns Min                   4748.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4812.51
time/epoch (s)                                0
time/total (s)                            12028.3
Epoch                                       625
---------------------------------------  ----------------
2022-11-16 14:06:30.424835 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 626 finished
---------------------------------------  ----------------
epoch                                       626
total_step                               631000
replay_pool/size                         631000
trainer/alpha                                 0.065603
trainer/alpha_loss                           -0.570032
trainer/entropy                              -5.79076
trainer/qf_loss                               5.55373
trainer/state_noise                           0.005
trainer/policy_loss                        -213.343
trainer/policy_loss_without_entropy         215.419
trainer/entropy_penalty                      -0.379891
trainer/entropy_percentage                   -0.0017635
trainer/Q1Pred Mean                         214.891
trainer/Q1Pred Std                           73.688
trainer/Q1Pred Max                          308.378
trainer/Q1Pred Min                           -1.04524
trainer/Q2Pred Mean                         215.283
trainer/Q2Pred Std                           73.3925
trainer/Q2Pred Max                          308.703
trainer/Q2Pred Min                            2.60291
trainer/QTargetWithReg Mean                 214.801
trainer/QTargetWithReg Std                   73.3516
trainer/QTargetWithReg Max                  308.304
trainer/QTargetWithReg Min                    3.45592
trainer/PolicyLossWithoutReg Mean           215.419
trainer/PolicyLossWithoutReg Std             72.8234
trainer/PolicyLossWithoutReg Max            308.628
trainer/PolicyLossWithoutReg Min             -2.51339
trainer/gradient_norm                       339.128
trainer/gradient_penalty                     -1.69564
trainer/gradient_percentage                  -0.00787137
exploration/num steps total              631000
exploration/num paths total                1791
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89933
exploration/Rewards Std                       1.23983
exploration/Rewards Max                      10.2899
exploration/Rewards Min                      -0.357029
exploration/Returns Mean                   4899.33
exploration/Returns Std                       0
exploration/Returns Max                    4899.33
exploration/Returns Min                    4899.33
exploration/Num Paths                         1
exploration/Average Returns                4899.33
evaluation_0/num steps total                  4.92632e+06
evaluation_0/num paths total              13080
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83728
evaluation_0/Rewards Std                      1.30062
evaluation_0/Rewards Max                     10.2781
evaluation_0/Rewards Min                     -0.468188
evaluation_0/Returns Mean                  4837.28
evaluation_0/Returns Std                     60.693
evaluation_0/Returns Max                   4976.84
evaluation_0/Returns Min                   4770.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4837.28
time/epoch (s)                                0
time/total (s)                            12044.2
Epoch                                       626
---------------------------------------  ----------------
2022-11-16 14:06:46.907223 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 627 finished
---------------------------------------  ----------------
epoch                                       627
total_step                               632000
replay_pool/size                         632000
trainer/alpha                                 0.0635363
trainer/alpha_loss                            0.896299
trainer/entropy                              -6.32519
trainer/qf_loss                               7.36362
trainer/state_noise                           0.005
trainer/policy_loss                        -212.56
trainer/policy_loss_without_entropy         214.636
trainer/entropy_penalty                      -0.401879
trainer/entropy_percentage                   -0.00187237
trainer/Q1Pred Mean                         213.981
trainer/Q1Pred Std                           73.2588
trainer/Q1Pred Max                          316.518
trainer/Q1Pred Min                           -8.15422
trainer/Q2Pred Mean                         213.552
trainer/Q2Pred Std                           73.2228
trainer/Q2Pred Max                          316.596
trainer/Q2Pred Min                           -9.45555
trainer/QTargetWithReg Mean                 213.35
trainer/QTargetWithReg Std                   73.0307
trainer/QTargetWithReg Max                  315
trainer/QTargetWithReg Min                   -8.8982
trainer/PolicyLossWithoutReg Mean           214.636
trainer/PolicyLossWithoutReg Std             71.261
trainer/PolicyLossWithoutReg Max            316.825
trainer/PolicyLossWithoutReg Min             -3.96718
trainer/gradient_norm                       334.832
trainer/gradient_penalty                     -1.67416
trainer/gradient_percentage                  -0.00779999
exploration/num steps total              632000
exploration/num paths total                1792
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.86416
exploration/Rewards Std                       1.24622
exploration/Rewards Max                       9.8502
exploration/Rewards Min                      -0.423576
exploration/Returns Mean                   4864.16
exploration/Returns Std                       0
exploration/Returns Max                    4864.16
exploration/Returns Min                    4864.16
exploration/Num Paths                         1
exploration/Average Returns                4864.16
evaluation_0/num steps total                  4.93432e+06
evaluation_0/num paths total              13088
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9251
evaluation_0/Rewards Std                      1.24985
evaluation_0/Rewards Max                     10.0126
evaluation_0/Rewards Min                     -0.454376
evaluation_0/Returns Mean                  4925.1
evaluation_0/Returns Std                    104.945
evaluation_0/Returns Max                   5057.21
evaluation_0/Returns Min                   4775.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4925.1
time/epoch (s)                                0
time/total (s)                            12060.7
Epoch                                       627
---------------------------------------  ----------------
2022-11-16 14:07:02.763670 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 628 finished
---------------------------------------  ----------------
epoch                                       628
total_step                               633000
replay_pool/size                         633000
trainer/alpha                                 0.0634526
trainer/alpha_loss                           -0.410147
trainer/entropy                              -5.85126
trainer/qf_loss                               9.22709
trainer/state_noise                           0.005
trainer/policy_loss                        -217.171
trainer/policy_loss_without_entropy         219.243
trainer/entropy_penalty                      -0.371278
trainer/entropy_percentage                   -0.00169345
trainer/Q1Pred Mean                         217.717
trainer/Q1Pred Std                           72.9789
trainer/Q1Pred Max                          315.849
trainer/Q1Pred Min                          -20.7932
trainer/Q2Pred Mean                         217.872
trainer/Q2Pred Std                           72.6276
trainer/Q2Pred Max                          316.279
trainer/Q2Pred Min                           -6.9256
trainer/QTargetWithReg Mean                 218.475
trainer/QTargetWithReg Std                   72.7631
trainer/QTargetWithReg Max                  315.716
trainer/QTargetWithReg Min                   -0.422721
trainer/PolicyLossWithoutReg Mean           219.243
trainer/PolicyLossWithoutReg Std             70.7724
trainer/PolicyLossWithoutReg Max            315.826
trainer/PolicyLossWithoutReg Min              5.87173
trainer/gradient_norm                       340.21
trainer/gradient_penalty                     -1.70105
trainer/gradient_percentage                  -0.00775872
exploration/num steps total              633000
exploration/num paths total                1793
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.66405
exploration/Rewards Std                       1.17323
exploration/Rewards Max                       9.6541
exploration/Rewards Min                      -0.678425
exploration/Returns Mean                   4664.05
exploration/Returns Std                       0
exploration/Returns Max                    4664.05
exploration/Returns Min                    4664.05
exploration/Num Paths                         1
exploration/Average Returns                4664.05
evaluation_0/num steps total                  4.94232e+06
evaluation_0/num paths total              13096
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84125
evaluation_0/Rewards Std                      1.23792
evaluation_0/Rewards Max                      9.94342
evaluation_0/Rewards Min                     -0.475473
evaluation_0/Returns Mean                  4841.25
evaluation_0/Returns Std                    120.645
evaluation_0/Returns Max                   4980.2
evaluation_0/Returns Min                   4654.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4841.25
time/epoch (s)                                0
time/total (s)                            12076.5
Epoch                                       628
---------------------------------------  ----------------
2022-11-16 14:07:18.588734 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 629 finished
---------------------------------------  ----------------
epoch                                       629
total_step                               634000
replay_pool/size                         634000
trainer/alpha                                 0.0622954
trainer/alpha_loss                           -1.89381
trainer/entropy                              -5.31769
trainer/qf_loss                             145.779
trainer/state_noise                           0.005
trainer/policy_loss                        -210.648
trainer/policy_loss_without_entropy         212.655
trainer/entropy_penalty                      -0.331268
trainer/entropy_percentage                   -0.00155777
trainer/Q1Pred Mean                         213.022
trainer/Q1Pred Std                           73.5695
trainer/Q1Pred Max                          306.984
trainer/Q1Pred Min                            8.65232
trainer/Q2Pred Mean                         212.707
trainer/Q2Pred Std                           73.4381
trainer/Q2Pred Max                          305.761
trainer/Q2Pred Min                            9.14418
trainer/QTargetWithReg Mean                 212.335
trainer/QTargetWithReg Std                   74.6562
trainer/QTargetWithReg Max                  306.052
trainer/QTargetWithReg Min                    5.17294
trainer/PolicyLossWithoutReg Mean           212.655
trainer/PolicyLossWithoutReg Std             72.922
trainer/PolicyLossWithoutReg Max            305.308
trainer/PolicyLossWithoutReg Min              8.40318
trainer/gradient_norm                       335.181
trainer/gradient_penalty                     -1.6759
trainer/gradient_percentage                  -0.00788087
exploration/num steps total              634000
exploration/num paths total                1794
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82963
exploration/Rewards Std                       1.19281
exploration/Rewards Max                       9.59683
exploration/Rewards Min                      -0.521621
exploration/Returns Mean                   4829.63
exploration/Returns Std                       0
exploration/Returns Max                    4829.63
exploration/Returns Min                    4829.63
exploration/Num Paths                         1
exploration/Average Returns                4829.63
evaluation_0/num steps total                  4.95032e+06
evaluation_0/num paths total              13104
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.48147
evaluation_0/Rewards Std                      1.18176
evaluation_0/Rewards Max                      9.60786
evaluation_0/Rewards Min                     -0.454543
evaluation_0/Returns Mean                  4481.47
evaluation_0/Returns Std                     79.493
evaluation_0/Returns Max                   4620.81
evaluation_0/Returns Min                   4402.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4481.47
time/epoch (s)                                0
time/total (s)                            12092.4
Epoch                                       629
---------------------------------------  ----------------
2022-11-16 14:07:36.568834 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 630 finished
---------------------------------------  ----------------
epoch                                       630
total_step                               635000
replay_pool/size                         635000
trainer/alpha                                 0.0651793
trainer/alpha_loss                            0.41163
trainer/entropy                              -6.15075
trainer/qf_loss                               7.5416
trainer/state_noise                           0.005
trainer/policy_loss                        -217.373
trainer/policy_loss_without_entropy         219.454
trainer/entropy_penalty                      -0.400902
trainer/entropy_percentage                   -0.00182682
trainer/Q1Pred Mean                         219.53
trainer/Q1Pred Std                           70.1651
trainer/Q1Pred Max                          307.289
trainer/Q1Pred Min                            0.175051
trainer/Q2Pred Mean                         219.453
trainer/Q2Pred Std                           70.0674
trainer/Q2Pred Max                          310.546
trainer/Q2Pred Min                            3.66913
trainer/QTargetWithReg Mean                 218.471
trainer/QTargetWithReg Std                   70.4599
trainer/QTargetWithReg Max                  310.162
trainer/QTargetWithReg Min                   -1.05981
trainer/PolicyLossWithoutReg Mean           219.454
trainer/PolicyLossWithoutReg Std             69.2545
trainer/PolicyLossWithoutReg Max            307.161
trainer/PolicyLossWithoutReg Min              8.4884
trainer/gradient_norm                       335.93
trainer/gradient_penalty                     -1.67965
trainer/gradient_percentage                  -0.00765378
exploration/num steps total              635000
exploration/num paths total                1795
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.72952
exploration/Rewards Std                       1.18747
exploration/Rewards Max                       9.76254
exploration/Rewards Min                      -0.362964
exploration/Returns Mean                   4729.52
exploration/Returns Std                       0
exploration/Returns Max                    4729.52
exploration/Returns Min                    4729.52
exploration/Num Paths                         1
exploration/Average Returns                4729.52
evaluation_0/num steps total                  4.95826e+06
evaluation_0/num paths total              13112
evaluation_0/path length Mean               992
evaluation_0/path length Std                 21.166
evaluation_0/path length Max               1000
evaluation_0/path length Min                936
evaluation_0/Rewards Mean                     4.68184
evaluation_0/Rewards Std                      1.227
evaluation_0/Rewards Max                      9.91352
evaluation_0/Rewards Min                     -0.415995
evaluation_0/Returns Mean                  4644.39
evaluation_0/Returns Std                    158.121
evaluation_0/Returns Max                   4835.29
evaluation_0/Returns Min                   4342.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4644.39
time/epoch (s)                                0
time/total (s)                            12110.3
Epoch                                       630
---------------------------------------  ----------------
2022-11-16 14:07:52.420259 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 631 finished
---------------------------------------  ----------------
epoch                                       631
total_step                               636000
replay_pool/size                         636000
trainer/alpha                                 0.0644752
trainer/alpha_loss                           -0.906397
trainer/entropy                              -5.66937
trainer/qf_loss                               5.41721
trainer/state_noise                           0.005
trainer/policy_loss                        -211.072
trainer/policy_loss_without_entropy         213.09
trainer/entropy_penalty                      -0.365534
trainer/entropy_percentage                   -0.0017154
trainer/Q1Pred Mean                         212.333
trainer/Q1Pred Std                           74.4647
trainer/Q1Pred Max                          309.683
trainer/Q1Pred Min                            5.1039
trainer/Q2Pred Mean                         212.266
trainer/Q2Pred Std                           74.0205
trainer/Q2Pred Max                          308.736
trainer/Q2Pred Min                            8.8622
trainer/QTargetWithReg Mean                 212.582
trainer/QTargetWithReg Std                   74.0983
trainer/QTargetWithReg Max                  309.073
trainer/QTargetWithReg Min                    7.05506
trainer/PolicyLossWithoutReg Mean           213.09
trainer/PolicyLossWithoutReg Std             73.7888
trainer/PolicyLossWithoutReg Max            308.934
trainer/PolicyLossWithoutReg Min              5.88834
trainer/gradient_norm                       330.485
trainer/gradient_penalty                     -1.65242
trainer/gradient_percentage                  -0.00775459
exploration/num steps total              636000
exploration/num paths total                1796
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.68534
exploration/Rewards Std                       1.25015
exploration/Rewards Max                      10.2536
exploration/Rewards Min                      -0.440281
exploration/Returns Mean                   4685.34
exploration/Returns Std                       0
exploration/Returns Max                    4685.34
exploration/Returns Min                    4685.34
exploration/Num Paths                         1
exploration/Average Returns                4685.34
evaluation_0/num steps total                  4.96626e+06
evaluation_0/num paths total              13120
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.81109
evaluation_0/Rewards Std                      1.2162
evaluation_0/Rewards Max                      9.75355
evaluation_0/Rewards Min                     -0.380136
evaluation_0/Returns Mean                  4811.09
evaluation_0/Returns Std                     23.476
evaluation_0/Returns Max                   4835.78
evaluation_0/Returns Min                   4761.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4811.09
time/epoch (s)                                0
time/total (s)                            12126.2
Epoch                                       631
---------------------------------------  ----------------
2022-11-16 14:08:08.945599 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 632 finished
---------------------------------------  ----------------
epoch                                       632
total_step                               637000
replay_pool/size                         637000
trainer/alpha                                 0.0649406
trainer/alpha_loss                            0.0886219
trainer/entropy                              -6.03241
trainer/qf_loss                               6.64391
trainer/state_noise                           0.005
trainer/policy_loss                        -212.011
trainer/policy_loss_without_entropy         214.073
trainer/entropy_penalty                      -0.391748
trainer/entropy_percentage                   -0.00182997
trainer/Q1Pred Mean                         213.158
trainer/Q1Pred Std                           78.993
trainer/Q1Pred Max                          312.771
trainer/Q1Pred Min                           -2.40781
trainer/Q2Pred Mean                         213.66
trainer/Q2Pred Std                           78.8773
trainer/Q2Pred Max                          313.061
trainer/Q2Pred Min                           -2.92492
trainer/QTargetWithReg Mean                 212.626
trainer/QTargetWithReg Std                   79.3042
trainer/QTargetWithReg Max                  315.498
trainer/QTargetWithReg Min                   -0.427608
trainer/PolicyLossWithoutReg Mean           214.073
trainer/PolicyLossWithoutReg Std             77.4599
trainer/PolicyLossWithoutReg Max            312.871
trainer/PolicyLossWithoutReg Min             12.7569
trainer/gradient_norm                       334.062
trainer/gradient_penalty                     -1.67031
trainer/gradient_percentage                  -0.00780253
exploration/num steps total              637000
exploration/num paths total                1797
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.56444
exploration/Rewards Std                       1.33772
exploration/Rewards Max                      10.2256
exploration/Rewards Min                      -0.316768
exploration/Returns Mean                   4564.44
exploration/Returns Std                       0
exploration/Returns Max                    4564.44
exploration/Returns Min                    4564.44
exploration/Num Paths                         1
exploration/Average Returns                4564.44
evaluation_0/num steps total                  4.97426e+06
evaluation_0/num paths total              13128
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98591
evaluation_0/Rewards Std                      1.25533
evaluation_0/Rewards Max                     10.1346
evaluation_0/Rewards Min                     -0.48618
evaluation_0/Returns Mean                  4985.91
evaluation_0/Returns Std                     66.6185
evaluation_0/Returns Max                   5034.59
evaluation_0/Returns Min                   4858.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4985.91
time/epoch (s)                                0
time/total (s)                            12142.7
Epoch                                       632
---------------------------------------  ----------------
2022-11-16 14:08:26.305484 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 633 finished
---------------------------------------  ----------------
epoch                                       633
total_step                               638000
replay_pool/size                         638000
trainer/alpha                                 0.0629877
trainer/alpha_loss                           -0.205827
trainer/entropy                              -5.92555
trainer/qf_loss                               7.95277
trainer/state_noise                           0.005
trainer/policy_loss                        -208.336
trainer/policy_loss_without_entropy         210.33
trainer/entropy_penalty                      -0.373237
trainer/entropy_percentage                   -0.00177453
trainer/Q1Pred Mean                         209.802
trainer/Q1Pred Std                           77.1135
trainer/Q1Pred Max                          308.964
trainer/Q1Pred Min                           -1.84933
trainer/Q2Pred Mean                         209.644
trainer/Q2Pred Std                           76.6677
trainer/Q2Pred Max                          307.906
trainer/Q2Pred Min                           -6.15014
trainer/QTargetWithReg Mean                 209.529
trainer/QTargetWithReg Std                   76.7083
trainer/QTargetWithReg Max                  308.313
trainer/QTargetWithReg Min                   -1.9331
trainer/PolicyLossWithoutReg Mean           210.33
trainer/PolicyLossWithoutReg Std             75.9386
trainer/PolicyLossWithoutReg Max            308.898
trainer/PolicyLossWithoutReg Min             -5.54337
trainer/gradient_norm                       324.148
trainer/gradient_penalty                     -1.62074
trainer/gradient_percentage                  -0.0077057
exploration/num steps total              638000
exploration/num paths total                1798
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.50487
exploration/Rewards Std                       1.27755
exploration/Rewards Max                       9.8429
exploration/Rewards Min                      -0.431076
exploration/Returns Mean                   4504.87
exploration/Returns Std                       0
exploration/Returns Max                    4504.87
exploration/Returns Min                    4504.87
exploration/Num Paths                         1
exploration/Average Returns                4504.87
evaluation_0/num steps total                  4.98211e+06
evaluation_0/num paths total              13136
evaluation_0/path length Mean               981.625
evaluation_0/path length Std                 48.6157
evaluation_0/path length Max               1000
evaluation_0/path length Min                853
evaluation_0/Rewards Mean                     5.14853
evaluation_0/Rewards Std                      1.25265
evaluation_0/Rewards Max                     10.2091
evaluation_0/Rewards Min                     -0.49307
evaluation_0/Returns Mean                  5053.92
evaluation_0/Returns Std                    282.585
evaluation_0/Returns Max                   5179.2
evaluation_0/Returns Min                   4307.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5053.92
time/epoch (s)                                0
time/total (s)                            12160.1
Epoch                                       633
---------------------------------------  ----------------
2022-11-16 14:08:42.874005 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 634 finished
---------------------------------------  ----------------
epoch                                       634
total_step                               639000
replay_pool/size                         639000
trainer/alpha                                 0.0635613
trainer/alpha_loss                            0.294695
trainer/entropy                              -6.10693
trainer/qf_loss                               9.16588
trainer/state_noise                           0.005
trainer/policy_loss                        -208.055
trainer/policy_loss_without_entropy         210.178
trainer/entropy_penalty                      -0.388164
trainer/entropy_percentage                   -0.00184684
trainer/Q1Pred Mean                         209.663
trainer/Q1Pred Std                           72.9378
trainer/Q1Pred Max                          305.514
trainer/Q1Pred Min                           -1.42192
trainer/Q2Pred Mean                         209.514
trainer/Q2Pred Std                           73.2797
trainer/Q2Pred Max                          305.422
trainer/Q2Pred Min                           -4.77091
trainer/QTargetWithReg Mean                 210.008
trainer/QTargetWithReg Std                   73.3033
trainer/QTargetWithReg Max                  305.243
trainer/QTargetWithReg Min                  -11.8374
trainer/PolicyLossWithoutReg Mean           210.178
trainer/PolicyLossWithoutReg Std             71.8554
trainer/PolicyLossWithoutReg Max            304.203
trainer/PolicyLossWithoutReg Min              2.89641
trainer/gradient_norm                       346.93
trainer/gradient_penalty                     -1.73465
trainer/gradient_percentage                  -0.00825326
exploration/num steps total              639000
exploration/num paths total                1799
exploration/path length this epoch Mean     573
exploration/path length this epoch Std        0
exploration/path length this epoch Max      573
exploration/path length this epoch Min      573
exploration/Rewards Mean                      4.6537
exploration/Rewards Std                       1.33308
exploration/Rewards Max                      10.0689
exploration/Rewards Min                      -0.493781
exploration/Returns Mean                   2666.57
exploration/Returns Std                       0
exploration/Returns Max                    2666.57
exploration/Returns Min                    2666.57
exploration/Num Paths                         1
exploration/Average Returns                2666.57
evaluation_0/num steps total                  4.99011e+06
evaluation_0/num paths total              13144
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.70663
evaluation_0/Rewards Std                      1.29032
evaluation_0/Rewards Max                     10.0755
evaluation_0/Rewards Min                     -0.445688
evaluation_0/Returns Mean                  4706.63
evaluation_0/Returns Std                     74.0471
evaluation_0/Returns Max                   4765.84
evaluation_0/Returns Min                   4516.64
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4706.63
time/epoch (s)                                0
time/total (s)                            12176.6
Epoch                                       634
---------------------------------------  ----------------
2022-11-16 14:09:00.362607 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 635 finished
---------------------------------------  ----------------
epoch                                       635
total_step                               640000
replay_pool/size                         640000
trainer/alpha                                 0.0642216
trainer/alpha_loss                            0.443066
trainer/entropy                              -6.16137
trainer/qf_loss                               7.7294
trainer/state_noise                           0.005
trainer/policy_loss                        -205.379
trainer/policy_loss_without_entropy         207.443
trainer/entropy_penalty                      -0.395693
trainer/entropy_percentage                   -0.00190748
trainer/Q1Pred Mean                         206.215
trainer/Q1Pred Std                           77.9793
trainer/Q1Pred Max                          305.949
trainer/Q1Pred Min                            7.39055
trainer/Q2Pred Mean                         206.098
trainer/Q2Pred Std                           78.0824
trainer/Q2Pred Max                          304.819
trainer/Q2Pred Min                            8.40403
trainer/QTargetWithReg Mean                 206.433
trainer/QTargetWithReg Std                   78.6456
trainer/QTargetWithReg Max                  306.434
trainer/QTargetWithReg Min                   -0.0273003
trainer/PolicyLossWithoutReg Mean           207.443
trainer/PolicyLossWithoutReg Std             76.8798
trainer/PolicyLossWithoutReg Max            305.866
trainer/PolicyLossWithoutReg Min              5.59115
trainer/gradient_norm                       333.631
trainer/gradient_penalty                     -1.66816
trainer/gradient_percentage                  -0.00804151
exploration/num steps total              640000
exploration/num paths total                1800
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67333
exploration/Rewards Std                       1.31288
exploration/Rewards Max                      10.1492
exploration/Rewards Min                      -0.364808
exploration/Returns Mean                   4673.33
exploration/Returns Std                       0
exploration/Returns Max                    4673.33
exploration/Returns Min                    4673.33
exploration/Num Paths                         1
exploration/Average Returns                4673.33
evaluation_0/num steps total                  4.99796e+06
evaluation_0/num paths total              13152
evaluation_0/path length Mean               981.25
evaluation_0/path length Std                 49.6078
evaluation_0/path length Max               1000
evaluation_0/path length Min                850
evaluation_0/Rewards Mean                     4.79383
evaluation_0/Rewards Std                      1.31573
evaluation_0/Rewards Max                     10.0912
evaluation_0/Rewards Min                     -0.444429
evaluation_0/Returns Mean                  4703.94
evaluation_0/Returns Std                    390.797
evaluation_0/Returns Max                   4994.28
evaluation_0/Returns Min                   3771.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4703.94
time/epoch (s)                                0
time/total (s)                            12194.1
Epoch                                       635
---------------------------------------  ----------------
2022-11-16 14:09:16.916440 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 636 finished
---------------------------------------  ----------------
epoch                                       636
total_step                               641000
replay_pool/size                         641000
trainer/alpha                                 0.0637237
trainer/alpha_loss                           -1.69903
trainer/entropy                              -5.38286
trainer/qf_loss                               6.35027
trainer/state_noise                           0.005
trainer/policy_loss                        -209.293
trainer/policy_loss_without_entropy         211.275
trainer/entropy_penalty                      -0.343016
trainer/entropy_percentage                   -0.00162355
trainer/Q1Pred Mean                         211.134
trainer/Q1Pred Std                           75.0539
trainer/Q1Pred Max                          308.113
trainer/Q1Pred Min                           -3.46034
trainer/Q2Pred Mean                         211.226
trainer/Q2Pred Std                           75.2706
trainer/Q2Pred Max                          308.697
trainer/Q2Pred Min                           -2.4985
trainer/QTargetWithReg Mean                 210.837
trainer/QTargetWithReg Std                   75.1115
trainer/QTargetWithReg Max                  308.276
trainer/QTargetWithReg Min                    3.21949
trainer/PolicyLossWithoutReg Mean           211.275
trainer/PolicyLossWithoutReg Std             74.444
trainer/PolicyLossWithoutReg Max            307.618
trainer/PolicyLossWithoutReg Min             -4.53694
trainer/gradient_norm                       327.907
trainer/gradient_penalty                     -1.63953
trainer/gradient_percentage                  -0.00776018
exploration/num steps total              641000
exploration/num paths total                1801
exploration/path length this epoch Mean     588
exploration/path length this epoch Std        0
exploration/path length this epoch Max      588
exploration/path length this epoch Min      588
exploration/Rewards Mean                      4.54687
exploration/Rewards Std                       1.29223
exploration/Rewards Max                       9.6024
exploration/Rewards Min                      -0.422741
exploration/Returns Mean                   2673.56
exploration/Returns Std                       0
exploration/Returns Max                    2673.56
exploration/Returns Min                    2673.56
exploration/Num Paths                         1
exploration/Average Returns                2673.56
evaluation_0/num steps total                  5.00596e+06
evaluation_0/num paths total              13160
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83015
evaluation_0/Rewards Std                      1.20049
evaluation_0/Rewards Max                      9.96051
evaluation_0/Rewards Min                     -0.438682
evaluation_0/Returns Mean                  4830.15
evaluation_0/Returns Std                     45.3978
evaluation_0/Returns Max                   4925.5
evaluation_0/Returns Min                   4793.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4830.15
time/epoch (s)                                0
time/total (s)                            12210.7
Epoch                                       636
---------------------------------------  ----------------
2022-11-16 14:09:32.777683 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 637 finished
---------------------------------------  ----------------
epoch                                       637
total_step                               642000
replay_pool/size                         642000
trainer/alpha                                 0.0645259
trainer/alpha_loss                            0.91095
trainer/entropy                              -6.33238
trainer/qf_loss                               5.7029
trainer/state_noise                           0.005
trainer/policy_loss                        -207.229
trainer/policy_loss_without_entropy         209.323
trainer/entropy_penalty                      -0.408602
trainer/entropy_percentage                   -0.00195202
trainer/Q1Pred Mean                         208.485
trainer/Q1Pred Std                           77.9266
trainer/Q1Pred Max                          309.144
trainer/Q1Pred Min                          -20.9805
trainer/Q2Pred Mean                         208.118
trainer/Q2Pred Std                           77.8749
trainer/Q2Pred Max                          308.531
trainer/Q2Pred Min                          -27.1318
trainer/QTargetWithReg Mean                 208.493
trainer/QTargetWithReg Std                   77.8434
trainer/QTargetWithReg Max                  307.36
trainer/QTargetWithReg Min                  -23.3771
trainer/PolicyLossWithoutReg Mean           209.323
trainer/PolicyLossWithoutReg Std             76.933
trainer/PolicyLossWithoutReg Max            309.285
trainer/PolicyLossWithoutReg Min            -14.4153
trainer/gradient_norm                       337.155
trainer/gradient_penalty                     -1.68578
trainer/gradient_percentage                  -0.00805346
exploration/num steps total              642000
exploration/num paths total                1802
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01739
exploration/Rewards Std                       1.25244
exploration/Rewards Max                      10.2499
exploration/Rewards Min                      -0.399579
exploration/Returns Mean                   5017.39
exploration/Returns Std                       0
exploration/Returns Max                    5017.39
exploration/Returns Min                    5017.39
exploration/Num Paths                         1
exploration/Average Returns                5017.39
evaluation_0/num steps total                  5.01396e+06
evaluation_0/num paths total              13168
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01312
evaluation_0/Rewards Std                      1.28663
evaluation_0/Rewards Max                     10.468
evaluation_0/Rewards Min                     -0.410607
evaluation_0/Returns Mean                  5013.12
evaluation_0/Returns Std                     33.2765
evaluation_0/Returns Max                   5083.53
evaluation_0/Returns Min                   4972.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5013.12
time/epoch (s)                                0
time/total (s)                            12226.5
Epoch                                       637
---------------------------------------  ----------------
2022-11-16 14:09:48.933444 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 638 finished
---------------------------------------  ----------------
epoch                                       638
total_step                               643000
replay_pool/size                         643000
trainer/alpha                                 0.0665582
trainer/alpha_loss                            0.124367
trainer/entropy                              -6.0459
trainer/qf_loss                               9.10084
trainer/state_noise                           0.005
trainer/policy_loss                        -213.932
trainer/policy_loss_without_entropy         215.962
trainer/entropy_penalty                      -0.402404
trainer/entropy_percentage                   -0.00186331
trainer/Q1Pred Mean                         215.248
trainer/Q1Pred Std                           70.3207
trainer/Q1Pred Max                          307.868
trainer/Q1Pred Min                           -4.14056
trainer/Q2Pred Mean                         215.182
trainer/Q2Pred Std                           70.3525
trainer/Q2Pred Max                          306.267
trainer/Q2Pred Min                           -4.84791
trainer/QTargetWithReg Mean                 215.233
trainer/QTargetWithReg Std                   70.2976
trainer/QTargetWithReg Max                  306.636
trainer/QTargetWithReg Min                   -0.0729068
trainer/PolicyLossWithoutReg Mean           215.962
trainer/PolicyLossWithoutReg Std             69.0868
trainer/PolicyLossWithoutReg Max            307.008
trainer/PolicyLossWithoutReg Min              5.77478
trainer/gradient_norm                       325.466
trainer/gradient_penalty                     -1.62733
trainer/gradient_percentage                  -0.00753526
exploration/num steps total              643000
exploration/num paths total                1803
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80051
exploration/Rewards Std                       1.21664
exploration/Rewards Max                       9.87872
exploration/Rewards Min                      -0.54232
exploration/Returns Mean                   4800.51
exploration/Returns Std                       0
exploration/Returns Max                    4800.51
exploration/Returns Min                    4800.51
exploration/Num Paths                         1
exploration/Average Returns                4800.51
evaluation_0/num steps total                  5.02196e+06
evaluation_0/num paths total              13176
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93557
evaluation_0/Rewards Std                      1.24896
evaluation_0/Rewards Max                      9.96988
evaluation_0/Rewards Min                     -0.461882
evaluation_0/Returns Mean                  4935.57
evaluation_0/Returns Std                     75.9054
evaluation_0/Returns Max                   5024.95
evaluation_0/Returns Min                   4760.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4935.57
time/epoch (s)                                0
time/total (s)                            12242.7
Epoch                                       638
---------------------------------------  ----------------
2022-11-16 14:10:05.035742 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 639 finished
---------------------------------------  ----------------
epoch                                       639
total_step                               644000
replay_pool/size                         644000
trainer/alpha                                 0.064878
trainer/alpha_loss                           -0.925126
trainer/entropy                              -5.66177
trainer/qf_loss                               6.59914
trainer/state_noise                           0.005
trainer/policy_loss                        -209.602
trainer/policy_loss_without_entropy         211.633
trainer/entropy_penalty                      -0.367324
trainer/entropy_percentage                   -0.00173567
trainer/Q1Pred Mean                         211.219
trainer/Q1Pred Std                           77.3703
trainer/Q1Pred Max                          314.244
trainer/Q1Pred Min                           -7.5478
trainer/Q2Pred Mean                         210.577
trainer/Q2Pred Std                           77.438
trainer/Q2Pred Max                          313.388
trainer/Q2Pred Min                           -4.31615
trainer/QTargetWithReg Mean                 210.879
trainer/QTargetWithReg Std                   77.9793
trainer/QTargetWithReg Max                  315.219
trainer/QTargetWithReg Min                  -14.4431
trainer/PolicyLossWithoutReg Mean           211.632
trainer/PolicyLossWithoutReg Std             75.9159
trainer/PolicyLossWithoutReg Max            313.291
trainer/PolicyLossWithoutReg Min             -7.09165
trainer/gradient_norm                       332.688
trainer/gradient_penalty                     -1.66344
trainer/gradient_percentage                  -0.00786005
exploration/num steps total              644000
exploration/num paths total                1804
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93903
exploration/Rewards Std                       1.26114
exploration/Rewards Max                       9.97294
exploration/Rewards Min                      -0.356804
exploration/Returns Mean                   4939.03
exploration/Returns Std                       0
exploration/Returns Max                    4939.03
exploration/Returns Min                    4939.03
exploration/Num Paths                         1
exploration/Average Returns                4939.03
evaluation_0/num steps total                  5.02996e+06
evaluation_0/num paths total              13184
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02269
evaluation_0/Rewards Std                      1.24177
evaluation_0/Rewards Max                     10.09
evaluation_0/Rewards Min                     -0.537468
evaluation_0/Returns Mean                  5022.69
evaluation_0/Returns Std                     45.7456
evaluation_0/Returns Max                   5096.6
evaluation_0/Returns Min                   4968.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5022.69
time/epoch (s)                                0
time/total (s)                            12258.8
Epoch                                       639
---------------------------------------  ----------------
2022-11-16 14:10:20.981925 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 640 finished
---------------------------------------  ----------------
epoch                                       640
total_step                               645000
replay_pool/size                         645000
trainer/alpha                                 0.0631005
trainer/alpha_loss                            0.68682
trainer/entropy                              -6.24857
trainer/qf_loss                               7.47182
trainer/state_noise                           0.005
trainer/policy_loss                        -202.86
trainer/policy_loss_without_entropy         204.902
trainer/entropy_penalty                      -0.394287
trainer/entropy_percentage                   -0.00192428
trainer/Q1Pred Mean                         204.232
trainer/Q1Pred Std                           77.1918
trainer/Q1Pred Max                          309.818
trainer/Q1Pred Min                           -0.133186
trainer/Q2Pred Mean                         204.008
trainer/Q2Pred Std                           77.1277
trainer/Q2Pred Max                          311.094
trainer/Q2Pred Min                            4.36226
trainer/QTargetWithReg Mean                 203.564
trainer/QTargetWithReg Std                   77.0348
trainer/QTargetWithReg Max                  310.159
trainer/QTargetWithReg Min                    0.0429579
trainer/PolicyLossWithoutReg Mean           204.902
trainer/PolicyLossWithoutReg Std             76.0643
trainer/PolicyLossWithoutReg Max            310.603
trainer/PolicyLossWithoutReg Min              6.21145
trainer/gradient_norm                       329.483
trainer/gradient_penalty                     -1.64741
trainer/gradient_percentage                  -0.00804002
exploration/num steps total              645000
exploration/num paths total                1805
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01139
exploration/Rewards Std                       1.20456
exploration/Rewards Max                       9.67119
exploration/Rewards Min                      -0.423459
exploration/Returns Mean                   5011.39
exploration/Returns Std                       0
exploration/Returns Max                    5011.39
exploration/Returns Min                    5011.39
exploration/Num Paths                         1
exploration/Average Returns                5011.39
evaluation_0/num steps total                  5.03796e+06
evaluation_0/num paths total              13192
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68669
evaluation_0/Rewards Std                      1.23811
evaluation_0/Rewards Max                     10.0535
evaluation_0/Rewards Min                     -0.555635
evaluation_0/Returns Mean                  4686.69
evaluation_0/Returns Std                    134.771
evaluation_0/Returns Max                   4867.89
evaluation_0/Returns Min                   4378.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4686.69
time/epoch (s)                                0
time/total (s)                            12274.7
Epoch                                       640
---------------------------------------  ----------------
2022-11-16 14:10:37.399052 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 641 finished
---------------------------------------  ----------------
epoch                                       641
total_step                               646000
replay_pool/size                         646000
trainer/alpha                                 0.0649279
trainer/alpha_loss                           -0.203935
trainer/entropy                              -5.92542
trainer/qf_loss                               8.84011
trainer/state_noise                           0.005
trainer/policy_loss                        -208.668
trainer/policy_loss_without_entropy         210.693
trainer/entropy_penalty                      -0.384725
trainer/entropy_percentage                   -0.001826
trainer/Q1Pred Mean                         209.216
trainer/Q1Pred Std                           79.2409
trainer/Q1Pred Max                          311.916
trainer/Q1Pred Min                           -5.58647
trainer/Q2Pred Mean                         209.243
trainer/Q2Pred Std                           79.2298
trainer/Q2Pred Max                          313.13
trainer/Q2Pred Min                           -3.77627
trainer/QTargetWithReg Mean                 209.471
trainer/QTargetWithReg Std                   79.4336
trainer/QTargetWithReg Max                  314.499
trainer/QTargetWithReg Min                   -0.849291
trainer/PolicyLossWithoutReg Mean           210.693
trainer/PolicyLossWithoutReg Std             77.8726
trainer/PolicyLossWithoutReg Max            312.044
trainer/PolicyLossWithoutReg Min             -0.39373
trainer/gradient_norm                       328.088
trainer/gradient_penalty                     -1.64044
trainer/gradient_percentage                  -0.00778592
exploration/num steps total              646000
exploration/num paths total                1806
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08084
exploration/Rewards Std                       1.23208
exploration/Rewards Max                       9.91709
exploration/Rewards Min                      -0.474923
exploration/Returns Mean                   5080.84
exploration/Returns Std                       0
exploration/Returns Max                    5080.84
exploration/Returns Min                    5080.84
exploration/Num Paths                         1
exploration/Average Returns                5080.84
evaluation_0/num steps total                  5.04596e+06
evaluation_0/num paths total              13200
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10076
evaluation_0/Rewards Std                      1.27642
evaluation_0/Rewards Max                     10.3192
evaluation_0/Rewards Min                     -0.33469
evaluation_0/Returns Mean                  5100.76
evaluation_0/Returns Std                     38.5081
evaluation_0/Returns Max                   5179.44
evaluation_0/Returns Min                   5051.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5100.76
time/epoch (s)                                0
time/total (s)                            12291.2
Epoch                                       641
---------------------------------------  ----------------
2022-11-16 14:10:53.212181 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 642 finished
---------------------------------------  ----------------
epoch                                       642
total_step                               647000
replay_pool/size                         647000
trainer/alpha                                 0.0627987
trainer/alpha_loss                           -0.512474
trainer/entropy                              -5.81484
trainer/qf_loss                               8.13957
trainer/state_noise                           0.005
trainer/policy_loss                        -218.019
trainer/policy_loss_without_entropy         220.089
trainer/entropy_penalty                      -0.365164
trainer/entropy_percentage                   -0.00165917
trainer/Q1Pred Mean                         219.855
trainer/Q1Pred Std                           69.2777
trainer/Q1Pred Max                          313.151
trainer/Q1Pred Min                           14.6543
trainer/Q2Pred Mean                         219.395
trainer/Q2Pred Std                           68.9238
trainer/Q2Pred Max                          310.997
trainer/Q2Pred Min                           14.6149
trainer/QTargetWithReg Mean                 219.318
trainer/QTargetWithReg Std                   69.0505
trainer/QTargetWithReg Max                  312.854
trainer/QTargetWithReg Min                   12.5884
trainer/PolicyLossWithoutReg Mean           220.089
trainer/PolicyLossWithoutReg Std             68.2745
trainer/PolicyLossWithoutReg Max            312.46
trainer/PolicyLossWithoutReg Min             14.588
trainer/gradient_norm                       340.874
trainer/gradient_penalty                     -1.70437
trainer/gradient_percentage                  -0.00774402
exploration/num steps total              647000
exploration/num paths total                1807
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95728
exploration/Rewards Std                       1.24795
exploration/Rewards Max                       9.96278
exploration/Rewards Min                      -0.381582
exploration/Returns Mean                   4957.28
exploration/Returns Std                       0
exploration/Returns Max                    4957.28
exploration/Returns Min                    4957.28
exploration/Num Paths                         1
exploration/Average Returns                4957.28
evaluation_0/num steps total                  5.05396e+06
evaluation_0/num paths total              13208
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18186
evaluation_0/Rewards Std                      1.26353
evaluation_0/Rewards Max                     10.3195
evaluation_0/Rewards Min                     -0.407403
evaluation_0/Returns Mean                  5181.86
evaluation_0/Returns Std                     25.3753
evaluation_0/Returns Max                   5211.16
evaluation_0/Returns Min                   5141.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5181.86
time/epoch (s)                                0
time/total (s)                            12307
Epoch                                       642
---------------------------------------  ----------------
2022-11-16 14:11:09.755583 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 643 finished
---------------------------------------  ----------------
epoch                                       643
total_step                               648000
replay_pool/size                         648000
trainer/alpha                                 0.0625678
trainer/alpha_loss                           -0.248813
trainer/entropy                              -5.91023
trainer/qf_loss                               9.75103
trainer/state_noise                           0.005
trainer/policy_loss                        -215.057
trainer/policy_loss_without_entropy         217.176
trainer/entropy_penalty                      -0.36979
trainer/entropy_percentage                   -0.00170272
trainer/Q1Pred Mean                         217.407
trainer/Q1Pred Std                           73.4187
trainer/Q1Pred Max                          314.169
trainer/Q1Pred Min                           -7.28892
trainer/Q2Pred Mean                         217.516
trainer/Q2Pred Std                           73.2582
trainer/Q2Pred Max                          314.364
trainer/Q2Pred Min                           -4.15289
trainer/QTargetWithReg Mean                 216.497
trainer/QTargetWithReg Std                   73.4246
trainer/QTargetWithReg Max                  315.306
trainer/QTargetWithReg Min                  -14.0398
trainer/PolicyLossWithoutReg Mean           217.176
trainer/PolicyLossWithoutReg Std             72.6055
trainer/PolicyLossWithoutReg Max            313.635
trainer/PolicyLossWithoutReg Min             -7.86104
trainer/gradient_norm                       349.812
trainer/gradient_penalty                     -1.74906
trainer/gradient_percentage                  -0.00805366
exploration/num steps total              648000
exploration/num paths total                1808
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05976
exploration/Rewards Std                       1.28964
exploration/Rewards Max                      10.1059
exploration/Rewards Min                      -0.377765
exploration/Returns Mean                   5059.76
exploration/Returns Std                       0
exploration/Returns Max                    5059.76
exploration/Returns Min                    5059.76
exploration/Num Paths                         1
exploration/Average Returns                5059.76
evaluation_0/num steps total                  5.06196e+06
evaluation_0/num paths total              13216
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09378
evaluation_0/Rewards Std                      1.25237
evaluation_0/Rewards Max                     10.1083
evaluation_0/Rewards Min                     -0.472154
evaluation_0/Returns Mean                  5093.78
evaluation_0/Returns Std                      7.59354
evaluation_0/Returns Max                   5105.1
evaluation_0/Returns Min                   5079.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5093.78
time/epoch (s)                                0
time/total (s)                            12323.5
Epoch                                       643
---------------------------------------  ----------------
2022-11-16 14:11:25.630750 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 644 finished
---------------------------------------  ----------------
epoch                                       644
total_step                               649000
replay_pool/size                         649000
trainer/alpha                                 0.0643009
trainer/alpha_loss                            0.302715
trainer/entropy                              -6.11031
trainer/qf_loss                              15.0393
trainer/state_noise                           0.005
trainer/policy_loss                        -202.859
trainer/policy_loss_without_entropy         204.993
trainer/entropy_penalty                      -0.392899
trainer/entropy_percentage                   -0.00191664
trainer/Q1Pred Mean                         204.863
trainer/Q1Pred Std                           75.7134
trainer/Q1Pred Max                          310.121
trainer/Q1Pred Min                           16.0229
trainer/Q2Pred Mean                         204.97
trainer/Q2Pred Std                           75.5609
trainer/Q2Pred Max                          309.618
trainer/Q2Pred Min                           12.668
trainer/QTargetWithReg Mean                 204.663
trainer/QTargetWithReg Std                   75.4043
trainer/QTargetWithReg Max                  310.17
trainer/QTargetWithReg Min                    8.17836
trainer/PolicyLossWithoutReg Mean           204.993
trainer/PolicyLossWithoutReg Std             74.9893
trainer/PolicyLossWithoutReg Max            309.217
trainer/PolicyLossWithoutReg Min             16.3522
trainer/gradient_norm                       348.281
trainer/gradient_penalty                     -1.7414
trainer/gradient_percentage                  -0.00849494
exploration/num steps total              649000
exploration/num paths total                1809
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01179
exploration/Rewards Std                       1.31102
exploration/Rewards Max                      10.3006
exploration/Rewards Min                      -0.450382
exploration/Returns Mean                   5011.79
exploration/Returns Std                       0
exploration/Returns Max                    5011.79
exploration/Returns Min                    5011.79
exploration/Num Paths                         1
exploration/Average Returns                5011.79
evaluation_0/num steps total                  5.06996e+06
evaluation_0/num paths total              13224
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04572
evaluation_0/Rewards Std                      1.30526
evaluation_0/Rewards Max                     10.3925
evaluation_0/Rewards Min                     -0.484223
evaluation_0/Returns Mean                  5045.72
evaluation_0/Returns Std                     29.4082
evaluation_0/Returns Max                   5085.57
evaluation_0/Returns Min                   4995.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5045.72
time/epoch (s)                                0
time/total (s)                            12339.4
Epoch                                       644
---------------------------------------  ----------------
2022-11-16 14:11:42.066501 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 645 finished
---------------------------------------  ----------------
epoch                                       645
total_step                               650000
replay_pool/size                         650000
trainer/alpha                                 0.0621977
trainer/alpha_loss                           -0.839802
trainer/entropy                              -5.69761
trainer/qf_loss                               6.70535
trainer/state_noise                           0.005
trainer/policy_loss                        -211.109
trainer/policy_loss_without_entropy         213.14
trainer/entropy_penalty                      -0.354378
trainer/entropy_percentage                   -0.00166265
trainer/Q1Pred Mean                         212.977
trainer/Q1Pred Std                           74.2865
trainer/Q1Pred Max                          314.704
trainer/Q1Pred Min                            6.9928
trainer/Q2Pred Mean                         213.335
trainer/Q2Pred Std                           74.2547
trainer/Q2Pred Max                          316.788
trainer/Q2Pred Min                            5.63959
trainer/QTargetWithReg Mean                 213.07
trainer/QTargetWithReg Std                   74.3071
trainer/QTargetWithReg Max                  315.831
trainer/QTargetWithReg Min                    4.04392
trainer/PolicyLossWithoutReg Mean           213.14
trainer/PolicyLossWithoutReg Std             73.4976
trainer/PolicyLossWithoutReg Max            314.174
trainer/PolicyLossWithoutReg Min              5.3208
trainer/gradient_norm                       335.375
trainer/gradient_penalty                     -1.67688
trainer/gradient_percentage                  -0.00786747
exploration/num steps total              650000
exploration/num paths total                1810
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94106
exploration/Rewards Std                       1.27877
exploration/Rewards Max                      10.0421
exploration/Rewards Min                      -0.492465
exploration/Returns Mean                   4941.06
exploration/Returns Std                       0
exploration/Returns Max                    4941.06
exploration/Returns Min                    4941.06
exploration/Num Paths                         1
exploration/Average Returns                4941.06
evaluation_0/num steps total                  5.07796e+06
evaluation_0/num paths total              13232
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00416
evaluation_0/Rewards Std                      1.27358
evaluation_0/Rewards Max                     10.0829
evaluation_0/Rewards Min                     -0.294412
evaluation_0/Returns Mean                  5004.16
evaluation_0/Returns Std                      8.92152
evaluation_0/Returns Max                   5015.24
evaluation_0/Returns Min                   4988.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5004.16
time/epoch (s)                                0
time/total (s)                            12355.8
Epoch                                       645
---------------------------------------  ----------------
2022-11-16 14:11:58.040994 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 646 finished
---------------------------------------  ----------------
epoch                                       646
total_step                               651000
replay_pool/size                         651000
trainer/alpha                                 0.0621624
trainer/alpha_loss                           -0.530042
trainer/entropy                              -5.80919
trainer/qf_loss                               8.23978
trainer/state_noise                           0.005
trainer/policy_loss                        -217.741
trainer/policy_loss_without_entropy         219.761
trainer/entropy_penalty                      -0.361113
trainer/entropy_percentage                   -0.00164321
trainer/Q1Pred Mean                         218.137
trainer/Q1Pred Std                           65.696
trainer/Q1Pred Max                          306.358
trainer/Q1Pred Min                           -8.55997
trainer/Q2Pred Mean                         218.053
trainer/Q2Pred Std                           65.9748
trainer/Q2Pred Max                          306.475
trainer/Q2Pred Min                          -12.9609
trainer/QTargetWithReg Mean                 218.7
trainer/QTargetWithReg Std                   66.5462
trainer/QTargetWithReg Max                  314.413
trainer/QTargetWithReg Min                    0.288284
trainer/PolicyLossWithoutReg Mean           219.761
trainer/PolicyLossWithoutReg Std             64.6487
trainer/PolicyLossWithoutReg Max            306.212
trainer/PolicyLossWithoutReg Min             23.8417
trainer/gradient_norm                       331.746
trainer/gradient_penalty                     -1.65873
trainer/gradient_percentage                  -0.00754789
exploration/num steps total              651000
exploration/num paths total                1811
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89351
exploration/Rewards Std                       1.24454
exploration/Rewards Max                      10.4134
exploration/Rewards Min                      -0.388803
exploration/Returns Mean                   4893.51
exploration/Returns Std                       0
exploration/Returns Max                    4893.51
exploration/Returns Min                    4893.51
exploration/Num Paths                         1
exploration/Average Returns                4893.51
evaluation_0/num steps total                  5.08596e+06
evaluation_0/num paths total              13240
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99934
evaluation_0/Rewards Std                      1.31242
evaluation_0/Rewards Max                     10.491
evaluation_0/Rewards Min                     -0.315723
evaluation_0/Returns Mean                  4999.34
evaluation_0/Returns Std                     32.2327
evaluation_0/Returns Max                   5037.01
evaluation_0/Returns Min                   4949.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4999.34
time/epoch (s)                                0
time/total (s)                            12371.8
Epoch                                       646
---------------------------------------  ----------------
2022-11-16 14:12:13.952751 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 647 finished
---------------------------------------  ----------------
epoch                                       647
total_step                               652000
replay_pool/size                         652000
trainer/alpha                                 0.0647886
trainer/alpha_loss                            0.462919
trainer/entropy                              -6.16915
trainer/qf_loss                               6.56194
trainer/state_noise                           0.005
trainer/policy_loss                        -211.698
trainer/policy_loss_without_entropy         213.801
trainer/entropy_penalty                      -0.399691
trainer/entropy_percentage                   -0.00186945
trainer/Q1Pred Mean                         213.222
trainer/Q1Pred Std                           75.0516
trainer/Q1Pred Max                          314.231
trainer/Q1Pred Min                            3.22195
trainer/Q2Pred Mean                         213.428
trainer/Q2Pred Std                           74.6699
trainer/Q2Pred Max                          313.841
trainer/Q2Pred Min                            6.08686
trainer/QTargetWithReg Mean                 213.533
trainer/QTargetWithReg Std                   74.6968
trainer/QTargetWithReg Max                  317.533
trainer/QTargetWithReg Min                    3.77785
trainer/PolicyLossWithoutReg Mean           213.801
trainer/PolicyLossWithoutReg Std             74.1264
trainer/PolicyLossWithoutReg Max            313.022
trainer/PolicyLossWithoutReg Min              6.66934
trainer/gradient_norm                       340.636
trainer/gradient_penalty                     -1.70318
trainer/gradient_percentage                  -0.00796619
exploration/num steps total              652000
exploration/num paths total                1812
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99901
exploration/Rewards Std                       1.32497
exploration/Rewards Max                      10.3363
exploration/Rewards Min                      -0.307972
exploration/Returns Mean                   4999.01
exploration/Returns Std                       0
exploration/Returns Max                    4999.01
exploration/Returns Min                    4999.01
exploration/Num Paths                         1
exploration/Average Returns                4999.01
evaluation_0/num steps total                  5.09396e+06
evaluation_0/num paths total              13248
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9437
evaluation_0/Rewards Std                      1.28555
evaluation_0/Rewards Max                     10.3302
evaluation_0/Rewards Min                     -0.471533
evaluation_0/Returns Mean                  4943.7
evaluation_0/Returns Std                     10.3006
evaluation_0/Returns Max                   4960.68
evaluation_0/Returns Min                   4925.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4943.7
time/epoch (s)                                0
time/total (s)                            12387.7
Epoch                                       647
---------------------------------------  ----------------
2022-11-16 14:12:30.400482 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 648 finished
---------------------------------------  ----------------
epoch                                       648
total_step                               653000
replay_pool/size                         653000
trainer/alpha                                 0.0633978
trainer/alpha_loss                            0.659651
trainer/entropy                              -6.23912
trainer/qf_loss                               6.42167
trainer/state_noise                           0.005
trainer/policy_loss                        -219.12
trainer/policy_loss_without_entropy         221.253
trainer/entropy_penalty                      -0.395547
trainer/entropy_percentage                   -0.00178776
trainer/Q1Pred Mean                         220.295
trainer/Q1Pred Std                           69.1495
trainer/Q1Pred Max                          313.252
trainer/Q1Pred Min                           -2.15353
trainer/Q2Pred Mean                         220.366
trainer/Q2Pred Std                           69.0307
trainer/Q2Pred Max                          311.308
trainer/Q2Pred Min                           -0.043035
trainer/QTargetWithReg Mean                 219.365
trainer/QTargetWithReg Std                   68.987
trainer/QTargetWithReg Max                  311.498
trainer/QTargetWithReg Min                   -5.58121
trainer/PolicyLossWithoutReg Mean           221.253
trainer/PolicyLossWithoutReg Std             67.339
trainer/PolicyLossWithoutReg Max            312.008
trainer/PolicyLossWithoutReg Min             12.9912
trainer/gradient_norm                       347.558
trainer/gradient_penalty                     -1.73779
trainer/gradient_percentage                  -0.00785432
exploration/num steps total              653000
exploration/num paths total                1813
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94079
exploration/Rewards Std                       1.26232
exploration/Rewards Max                       9.99614
exploration/Rewards Min                      -0.512371
exploration/Returns Mean                   4940.79
exploration/Returns Std                       0
exploration/Returns Max                    4940.79
exploration/Returns Min                    4940.79
exploration/Num Paths                         1
exploration/Average Returns                4940.79
evaluation_0/num steps total                  5.10196e+06
evaluation_0/num paths total              13256
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05492
evaluation_0/Rewards Std                      1.27571
evaluation_0/Rewards Max                     10.278
evaluation_0/Rewards Min                     -0.430735
evaluation_0/Returns Mean                  5054.92
evaluation_0/Returns Std                     23.0588
evaluation_0/Returns Max                   5099.06
evaluation_0/Returns Min                   5021.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5054.92
time/epoch (s)                                0
time/total (s)                            12404.2
Epoch                                       648
---------------------------------------  ----------------
2022-11-16 14:12:46.160233 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 649 finished
---------------------------------------  ----------------
epoch                                       649
total_step                               654000
replay_pool/size                         654000
trainer/alpha                                 0.0639742
trainer/alpha_loss                           -1.14685
trainer/entropy                              -5.58282
trainer/qf_loss                               7.80839
trainer/state_noise                           0.005
trainer/policy_loss                        -211.87
trainer/policy_loss_without_entropy         213.915
trainer/entropy_penalty                      -0.357157
trainer/entropy_percentage                   -0.00166962
trainer/Q1Pred Mean                         213.305
trainer/Q1Pred Std                           71.9204
trainer/Q1Pred Max                          309.695
trainer/Q1Pred Min                            8.72061
trainer/Q2Pred Mean                         213.582
trainer/Q2Pred Std                           71.9592
trainer/Q2Pred Max                          309.839
trainer/Q2Pred Min                            7.28555
trainer/QTargetWithReg Mean                 213.007
trainer/QTargetWithReg Std                   72.0083
trainer/QTargetWithReg Max                  310.104
trainer/QTargetWithReg Min                    6.89989
trainer/PolicyLossWithoutReg Mean           213.915
trainer/PolicyLossWithoutReg Std             71.1498
trainer/PolicyLossWithoutReg Max            309.795
trainer/PolicyLossWithoutReg Min              8.11354
trainer/gradient_norm                       337.514
trainer/gradient_penalty                     -1.68757
trainer/gradient_percentage                  -0.00788898
exploration/num steps total              654000
exploration/num paths total                1814
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04765
exploration/Rewards Std                       1.26536
exploration/Rewards Max                      10.1455
exploration/Rewards Min                      -0.355631
exploration/Returns Mean                   5047.65
exploration/Returns Std                       0
exploration/Returns Max                    5047.65
exploration/Returns Min                    5047.65
exploration/Num Paths                         1
exploration/Average Returns                5047.65
evaluation_0/num steps total                  5.10996e+06
evaluation_0/num paths total              13264
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08649
evaluation_0/Rewards Std                      1.27671
evaluation_0/Rewards Max                     10.2895
evaluation_0/Rewards Min                     -0.461371
evaluation_0/Returns Mean                  5086.49
evaluation_0/Returns Std                     11.5019
evaluation_0/Returns Max                   5113.54
evaluation_0/Returns Min                   5078.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5086.49
time/epoch (s)                                0
time/total (s)                            12419.9
Epoch                                       649
---------------------------------------  ----------------
2022-11-16 14:13:02.761120 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 650 finished
---------------------------------------  ----------------
epoch                                       650
total_step                               655000
replay_pool/size                         655000
trainer/alpha                                 0.064743
trainer/alpha_loss                            0.363656
trainer/entropy                              -6.13285
trainer/qf_loss                               7.55477
trainer/state_noise                           0.005
trainer/policy_loss                        -208.248
trainer/policy_loss_without_entropy         210.381
trainer/entropy_penalty                      -0.397059
trainer/entropy_percentage                   -0.00188733
trainer/Q1Pred Mean                         209.365
trainer/Q1Pred Std                           74.8795
trainer/Q1Pred Max                          310.298
trainer/Q1Pred Min                           -1.07621
trainer/Q2Pred Mean                         209.534
trainer/Q2Pred Std                           75.0653
trainer/Q2Pred Max                          311.928
trainer/Q2Pred Min                           -4.05105
trainer/QTargetWithReg Mean                 208.883
trainer/QTargetWithReg Std                   75.2149
trainer/QTargetWithReg Max                  310.153
trainer/QTargetWithReg Min                   -1.1191
trainer/PolicyLossWithoutReg Mean           210.381
trainer/PolicyLossWithoutReg Std             73.9453
trainer/PolicyLossWithoutReg Max            310.703
trainer/PolicyLossWithoutReg Min             -7.11085
trainer/gradient_norm                       347.221
trainer/gradient_penalty                     -1.73611
trainer/gradient_percentage                  -0.0082522
exploration/num steps total              655000
exploration/num paths total                1815
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96299
exploration/Rewards Std                       1.30823
exploration/Rewards Max                      10.3213
exploration/Rewards Min                      -0.555774
exploration/Returns Mean                   4962.99
exploration/Returns Std                       0
exploration/Returns Max                    4962.99
exploration/Returns Min                    4962.99
exploration/Num Paths                         1
exploration/Average Returns                4962.99
evaluation_0/num steps total                  5.11796e+06
evaluation_0/num paths total              13272
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06476
evaluation_0/Rewards Std                      1.32579
evaluation_0/Rewards Max                     10.4906
evaluation_0/Rewards Min                     -0.27683
evaluation_0/Returns Mean                  5064.76
evaluation_0/Returns Std                     20.4672
evaluation_0/Returns Max                   5109.22
evaluation_0/Returns Min                   5039.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5064.76
time/epoch (s)                                0
time/total (s)                            12436.5
Epoch                                       650
---------------------------------------  ----------------
2022-11-16 14:13:18.540377 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 651 finished
---------------------------------------  ----------------
epoch                                       651
total_step                               656000
replay_pool/size                         656000
trainer/alpha                                 0.0639881
trainer/alpha_loss                           -0.353777
trainer/entropy                              -5.87131
trainer/qf_loss                               8.03431
trainer/state_noise                           0.005
trainer/policy_loss                        -211.78
trainer/policy_loss_without_entropy         213.842
trainer/entropy_penalty                      -0.375694
trainer/entropy_percentage                   -0.00175688
trainer/Q1Pred Mean                         213.726
trainer/Q1Pred Std                           75.4906
trainer/Q1Pred Max                          314.437
trainer/Q1Pred Min                            2.96668
trainer/Q2Pred Mean                         213.916
trainer/Q2Pred Std                           75.5056
trainer/Q2Pred Max                          316.118
trainer/Q2Pred Min                            6.03651
trainer/QTargetWithReg Mean                 213.232
trainer/QTargetWithReg Std                   75.4186
trainer/QTargetWithReg Max                  312.595
trainer/QTargetWithReg Min                    4.64246
trainer/PolicyLossWithoutReg Mean           213.842
trainer/PolicyLossWithoutReg Std             74.5713
trainer/PolicyLossWithoutReg Max            314.597
trainer/PolicyLossWithoutReg Min              5.64509
trainer/gradient_norm                       337.294
trainer/gradient_penalty                     -1.68647
trainer/gradient_percentage                  -0.00788653
exploration/num steps total              656000
exploration/num paths total                1816
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04646
exploration/Rewards Std                       1.3262
exploration/Rewards Max                      10.505
exploration/Rewards Min                      -0.350399
exploration/Returns Mean                   5046.46
exploration/Returns Std                       0
exploration/Returns Max                    5046.46
exploration/Returns Min                    5046.46
exploration/Num Paths                         1
exploration/Average Returns                5046.46
evaluation_0/num steps total                  5.12596e+06
evaluation_0/num paths total              13280
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99193
evaluation_0/Rewards Std                      1.27278
evaluation_0/Rewards Max                     10.0947
evaluation_0/Rewards Min                     -0.348172
evaluation_0/Returns Mean                  4991.93
evaluation_0/Returns Std                     87.9237
evaluation_0/Returns Max                   5052.15
evaluation_0/Returns Min                   4788.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4991.93
time/epoch (s)                                0
time/total (s)                            12452.3
Epoch                                       651
---------------------------------------  ----------------
2022-11-16 14:13:34.863783 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 652 finished
---------------------------------------  ----------------
epoch                                       652
total_step                               657000
replay_pool/size                         657000
trainer/alpha                                 0.0642314
trainer/alpha_loss                            0.0486918
trainer/entropy                              -6.01774
trainer/qf_loss                               7.28035
trainer/state_noise                           0.005
trainer/policy_loss                        -214.647
trainer/policy_loss_without_entropy         216.759
trainer/entropy_penalty                      -0.386528
trainer/entropy_percentage                   -0.00178321
trainer/Q1Pred Mean                         216.284
trainer/Q1Pred Std                           69.4284
trainer/Q1Pred Max                          310.46
trainer/Q1Pred Min                            1.44125
trainer/Q2Pred Mean                         215.678
trainer/Q2Pred Std                           69.7133
trainer/Q2Pred Max                          309.836
trainer/Q2Pred Min                            0.506196
trainer/QTargetWithReg Mean                 216.799
trainer/QTargetWithReg Std                   69.8051
trainer/QTargetWithReg Max                  310.551
trainer/QTargetWithReg Min                    4.98511
trainer/PolicyLossWithoutReg Mean           216.759
trainer/PolicyLossWithoutReg Std             68.9487
trainer/PolicyLossWithoutReg Max            311.042
trainer/PolicyLossWithoutReg Min              0.659052
trainer/gradient_norm                       345.239
trainer/gradient_penalty                     -1.72619
trainer/gradient_percentage                  -0.00796363
exploration/num steps total              657000
exploration/num paths total                1817
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99119
exploration/Rewards Std                       1.31184
exploration/Rewards Max                      10.2037
exploration/Rewards Min                      -0.465297
exploration/Returns Mean                   4991.19
exploration/Returns Std                       0
exploration/Returns Max                    4991.19
exploration/Returns Min                    4991.19
exploration/Num Paths                         1
exploration/Average Returns                4991.19
evaluation_0/num steps total                  5.13396e+06
evaluation_0/num paths total              13288
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92534
evaluation_0/Rewards Std                      1.31069
evaluation_0/Rewards Max                     10.3946
evaluation_0/Rewards Min                     -0.434253
evaluation_0/Returns Mean                  4925.34
evaluation_0/Returns Std                     93.1811
evaluation_0/Returns Max                   5033.94
evaluation_0/Returns Min                   4744.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4925.34
time/epoch (s)                                0
time/total (s)                            12468.6
Epoch                                       652
---------------------------------------  ----------------
2022-11-16 14:13:50.754206 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 653 finished
---------------------------------------  ----------------
epoch                                       653
total_step                               658000
replay_pool/size                         658000
trainer/alpha                                 0.064483
trainer/alpha_loss                           -0.245878
trainer/entropy                              -5.91031
trainer/qf_loss                               8.62062
trainer/state_noise                           0.005
trainer/policy_loss                        -209.7
trainer/policy_loss_without_entropy         211.835
trainer/entropy_penalty                      -0.381114
trainer/entropy_percentage                   -0.00179911
trainer/Q1Pred Mean                         211.261
trainer/Q1Pred Std                           73.8149
trainer/Q1Pred Max                          303.153
trainer/Q1Pred Min                          -15.9538
trainer/Q2Pred Mean                         211.31
trainer/Q2Pred Std                           73.7953
trainer/Q2Pred Max                          302.752
trainer/Q2Pred Min                          -19.4227
trainer/QTargetWithReg Mean                 211.419
trainer/QTargetWithReg Std                   73.931
trainer/QTargetWithReg Max                  302.611
trainer/QTargetWithReg Min                  -14.8243
trainer/PolicyLossWithoutReg Mean           211.834
trainer/PolicyLossWithoutReg Std             72.8802
trainer/PolicyLossWithoutReg Max            302.895
trainer/PolicyLossWithoutReg Min             -4.92404
trainer/gradient_norm                       350.769
trainer/gradient_penalty                     -1.75384
trainer/gradient_percentage                  -0.00827931
exploration/num steps total              658000
exploration/num paths total                1818
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82805
exploration/Rewards Std                       1.35207
exploration/Rewards Max                      10.244
exploration/Rewards Min                      -0.399349
exploration/Returns Mean                   4828.05
exploration/Returns Std                       0
exploration/Returns Max                    4828.05
exploration/Returns Min                    4828.05
exploration/Num Paths                         1
exploration/Average Returns                4828.05
evaluation_0/num steps total                  5.14196e+06
evaluation_0/num paths total              13296
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94526
evaluation_0/Rewards Std                      1.30213
evaluation_0/Rewards Max                     10.3484
evaluation_0/Rewards Min                     -0.423184
evaluation_0/Returns Mean                  4945.26
evaluation_0/Returns Std                     13.967
evaluation_0/Returns Max                   4967.54
evaluation_0/Returns Min                   4923
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4945.26
time/epoch (s)                                0
time/total (s)                            12484.5
Epoch                                       653
---------------------------------------  ----------------
2022-11-16 14:14:06.723568 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 654 finished
---------------------------------------  ----------------
epoch                                       654
total_step                               659000
replay_pool/size                         659000
trainer/alpha                                 0.0640226
trainer/alpha_loss                           -0.439249
trainer/entropy                              -5.84018
trainer/qf_loss                              11.2267
trainer/state_noise                           0.005
trainer/policy_loss                        -218.294
trainer/policy_loss_without_entropy         220.434
trainer/entropy_penalty                      -0.373903
trainer/entropy_percentage                   -0.00169621
trainer/Q1Pred Mean                         220.399
trainer/Q1Pred Std                           70.9454
trainer/Q1Pred Max                          305.236
trainer/Q1Pred Min                           -0.378024
trainer/Q2Pred Mean                         220.586
trainer/Q2Pred Std                           70.5976
trainer/Q2Pred Max                          304.949
trainer/Q2Pred Min                            6.92123
trainer/QTargetWithReg Mean                 220.258
trainer/QTargetWithReg Std                   71.58
trainer/QTargetWithReg Max                  306.46
trainer/QTargetWithReg Min                    0.751328
trainer/PolicyLossWithoutReg Mean           220.434
trainer/PolicyLossWithoutReg Std             69.8173
trainer/PolicyLossWithoutReg Max            303.815
trainer/PolicyLossWithoutReg Min              2.43923
trainer/gradient_norm                       353.34
trainer/gradient_penalty                     -1.7667
trainer/gradient_percentage                  -0.00801464
exploration/num steps total              659000
exploration/num paths total                1819
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0426
exploration/Rewards Std                       1.2896
exploration/Rewards Max                      10.429
exploration/Rewards Min                      -0.286475
exploration/Returns Mean                   5042.6
exploration/Returns Std                       0
exploration/Returns Max                    5042.6
exploration/Returns Min                    5042.6
exploration/Num Paths                         1
exploration/Average Returns                5042.6
evaluation_0/num steps total                  5.14996e+06
evaluation_0/num paths total              13304
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07693
evaluation_0/Rewards Std                      1.31327
evaluation_0/Rewards Max                     10.2959
evaluation_0/Rewards Min                     -0.494568
evaluation_0/Returns Mean                  5076.93
evaluation_0/Returns Std                     13.0196
evaluation_0/Returns Max                   5093.48
evaluation_0/Returns Min                   5056.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5076.93
time/epoch (s)                                0
time/total (s)                            12500.5
Epoch                                       654
---------------------------------------  ----------------
2022-11-16 14:14:22.965504 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 655 finished
---------------------------------------  ----------------
epoch                                       655
total_step                               660000
replay_pool/size                         660000
trainer/alpha                                 0.064899
trainer/alpha_loss                            0.327561
trainer/entropy                              -6.11977
trainer/qf_loss                               6.41306
trainer/state_noise                           0.005
trainer/policy_loss                        -216.384
trainer/policy_loss_without_entropy         218.475
trainer/entropy_penalty                      -0.397167
trainer/entropy_percentage                   -0.00181791
trainer/Q1Pred Mean                         217.512
trainer/Q1Pred Std                           71.9962
trainer/Q1Pred Max                          304.305
trainer/Q1Pred Min                            8.33351
trainer/Q2Pred Mean                         217.387
trainer/Q2Pred Std                           71.9357
trainer/Q2Pred Max                          303.541
trainer/Q2Pred Min                            8.59489
trainer/QTargetWithReg Mean                 217.422
trainer/QTargetWithReg Std                   72.2497
trainer/QTargetWithReg Max                  303.648
trainer/QTargetWithReg Min                    8.40363
trainer/PolicyLossWithoutReg Mean           218.475
trainer/PolicyLossWithoutReg Std             70.5699
trainer/PolicyLossWithoutReg Max            304.715
trainer/PolicyLossWithoutReg Min              8.57867
trainer/gradient_norm                       338.719
trainer/gradient_penalty                     -1.69359
trainer/gradient_percentage                  -0.0077519
exploration/num steps total              660000
exploration/num paths total                1820
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84565
exploration/Rewards Std                       1.34932
exploration/Rewards Max                      10.3419
exploration/Rewards Min                      -0.490521
exploration/Returns Mean                   4845.65
exploration/Returns Std                       0
exploration/Returns Max                    4845.65
exploration/Returns Min                    4845.65
exploration/Num Paths                         1
exploration/Average Returns                4845.65
evaluation_0/num steps total                  5.15796e+06
evaluation_0/num paths total              13312
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11705
evaluation_0/Rewards Std                      1.25612
evaluation_0/Rewards Max                     10.1242
evaluation_0/Rewards Min                     -0.424046
evaluation_0/Returns Mean                  5117.05
evaluation_0/Returns Std                      7.11141
evaluation_0/Returns Max                   5123.29
evaluation_0/Returns Min                   5100.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5117.05
time/epoch (s)                                0
time/total (s)                            12516.7
Epoch                                       655
---------------------------------------  ----------------
2022-11-16 14:14:38.917749 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 656 finished
---------------------------------------  ----------------
epoch                                       656
total_step                               661000
replay_pool/size                         661000
trainer/alpha                                 0.0647656
trainer/alpha_loss                            0.21845
trainer/entropy                              -6.07981
trainer/qf_loss                               8.89936
trainer/state_noise                           0.005
trainer/policy_loss                        -218.529
trainer/policy_loss_without_entropy         220.701
trainer/entropy_penalty                      -0.393763
trainer/entropy_percentage                   -0.00178415
trainer/Q1Pred Mean                         220.128
trainer/Q1Pred Std                           68.914
trainer/Q1Pred Max                          312.558
trainer/Q1Pred Min                           10.1662
trainer/Q2Pred Mean                         220.006
trainer/Q2Pred Std                           69.0052
trainer/Q2Pred Max                          312.038
trainer/Q2Pred Min                           11.8133
trainer/QTargetWithReg Mean                 219.716
trainer/QTargetWithReg Std                   69.0801
trainer/QTargetWithReg Max                  313.322
trainer/QTargetWithReg Min                    3.02158
trainer/PolicyLossWithoutReg Mean           220.701
trainer/PolicyLossWithoutReg Std             68.2118
trainer/PolicyLossWithoutReg Max            312.654
trainer/PolicyLossWithoutReg Min             10.159
trainer/gradient_norm                       355.59
trainer/gradient_penalty                     -1.77795
trainer/gradient_percentage                  -0.00805594
exploration/num steps total              661000
exploration/num paths total                1821
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98641
exploration/Rewards Std                       1.3332
exploration/Rewards Max                      10.1358
exploration/Rewards Min                      -0.355912
exploration/Returns Mean                   4986.41
exploration/Returns Std                       0
exploration/Returns Max                    4986.41
exploration/Returns Min                    4986.41
exploration/Num Paths                         1
exploration/Average Returns                4986.41
evaluation_0/num steps total                  5.16596e+06
evaluation_0/num paths total              13320
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0599
evaluation_0/Rewards Std                      1.31196
evaluation_0/Rewards Max                     10.4628
evaluation_0/Rewards Min                     -0.484098
evaluation_0/Returns Mean                  5059.9
evaluation_0/Returns Std                      6.02812
evaluation_0/Returns Max                   5067.52
evaluation_0/Returns Min                   5051.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5059.9
time/epoch (s)                                0
time/total (s)                            12532.7
Epoch                                       656
---------------------------------------  ----------------
2022-11-16 14:14:55.309494 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 657 finished
---------------------------------------  ----------------
epoch                                       657
total_step                               662000
replay_pool/size                         662000
trainer/alpha                                 0.0652163
trainer/alpha_loss                            0.64126
trainer/entropy                              -6.23492
trainer/qf_loss                              10.1684
trainer/state_noise                           0.005
trainer/policy_loss                        -202.307
trainer/policy_loss_without_entropy         204.456
trainer/entropy_penalty                      -0.406618
trainer/entropy_percentage                   -0.00198878
trainer/Q1Pred Mean                         204.004
trainer/Q1Pred Std                           73.9302
trainer/Q1Pred Max                          301.025
trainer/Q1Pred Min                           10.761
trainer/Q2Pred Mean                         204.028
trainer/Q2Pred Std                           74.0776
trainer/Q2Pred Max                          300.872
trainer/Q2Pred Min                            7.04504
trainer/QTargetWithReg Mean                 203.785
trainer/QTargetWithReg Std                   74.5624
trainer/QTargetWithReg Max                  301.649
trainer/QTargetWithReg Min                    2.06915
trainer/PolicyLossWithoutReg Mean           204.456
trainer/PolicyLossWithoutReg Std             73.3507
trainer/PolicyLossWithoutReg Max            301.152
trainer/PolicyLossWithoutReg Min              7.15764
trainer/gradient_norm                       348.501
trainer/gradient_penalty                     -1.7425
trainer/gradient_percentage                  -0.00852264
exploration/num steps total              662000
exploration/num paths total                1822
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96742
exploration/Rewards Std                       1.35364
exploration/Rewards Max                      10.2855
exploration/Rewards Min                      -0.556188
exploration/Returns Mean                   4967.42
exploration/Returns Std                       0
exploration/Returns Max                    4967.42
exploration/Returns Min                    4967.42
exploration/Num Paths                         1
exploration/Average Returns                4967.42
evaluation_0/num steps total                  5.17396e+06
evaluation_0/num paths total              13328
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0973
evaluation_0/Rewards Std                      1.31271
evaluation_0/Rewards Max                     10.504
evaluation_0/Rewards Min                     -0.454316
evaluation_0/Returns Mean                  5097.3
evaluation_0/Returns Std                     13.2759
evaluation_0/Returns Max                   5119.26
evaluation_0/Returns Min                   5076.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5097.3
time/epoch (s)                                0
time/total (s)                            12549.1
Epoch                                       657
---------------------------------------  ----------------
2022-11-16 14:15:11.155522 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 658 finished
---------------------------------------  ----------------
epoch                                       658
total_step                               663000
replay_pool/size                         663000
trainer/alpha                                 0.0643868
trainer/alpha_loss                            1.23999
trainer/entropy                              -6.45207
trainer/qf_loss                               6.66313
trainer/state_noise                           0.005
trainer/policy_loss                        -210.168
trainer/policy_loss_without_entropy         212.294
trainer/entropy_penalty                      -0.415429
trainer/entropy_percentage                   -0.00195686
trainer/Q1Pred Mean                         211.236
trainer/Q1Pred Std                           74.9692
trainer/Q1Pred Max                          311.838
trainer/Q1Pred Min                           -6.3398
trainer/Q2Pred Mean                         211.391
trainer/Q2Pred Std                           75.0962
trainer/Q2Pred Max                          311.151
trainer/Q2Pred Min                           -0.436104
trainer/QTargetWithReg Mean                 210.979
trainer/QTargetWithReg Std                   75.342
trainer/QTargetWithReg Max                  312.912
trainer/QTargetWithReg Min                  -12.3706
trainer/PolicyLossWithoutReg Mean           212.294
trainer/PolicyLossWithoutReg Std             74.0807
trainer/PolicyLossWithoutReg Max            311.85
trainer/PolicyLossWithoutReg Min              9.64989
trainer/gradient_norm                       342.082
trainer/gradient_penalty                     -1.71041
trainer/gradient_percentage                  -0.0080568
exploration/num steps total              663000
exploration/num paths total                1823
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01579
exploration/Rewards Std                       1.33579
exploration/Rewards Max                      10.616
exploration/Rewards Min                      -0.528589
exploration/Returns Mean                   5015.79
exploration/Returns Std                       0
exploration/Returns Max                    5015.79
exploration/Returns Min                    5015.79
exploration/Num Paths                         1
exploration/Average Returns                5015.79
evaluation_0/num steps total                  5.18196e+06
evaluation_0/num paths total              13336
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09011
evaluation_0/Rewards Std                      1.36353
evaluation_0/Rewards Max                     10.6321
evaluation_0/Rewards Min                     -0.426651
evaluation_0/Returns Mean                  5090.11
evaluation_0/Returns Std                     15.855
evaluation_0/Returns Max                   5102.82
evaluation_0/Returns Min                   5053.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5090.11
time/epoch (s)                                0
time/total (s)                            12564.9
Epoch                                       658
---------------------------------------  ----------------
2022-11-16 14:15:27.766509 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 659 finished
---------------------------------------  ----------------
epoch                                       659
total_step                               664000
replay_pool/size                         664000
trainer/alpha                                 0.0652119
trainer/alpha_loss                            1.13913
trainer/entropy                              -6.41722
trainer/qf_loss                               7.92221
trainer/state_noise                           0.005
trainer/policy_loss                        -207.678
trainer/policy_loss_without_entropy         209.778
trainer/entropy_penalty                      -0.418479
trainer/entropy_percentage                   -0.00199487
trainer/Q1Pred Mean                         209.363
trainer/Q1Pred Std                           73.9857
trainer/Q1Pred Max                          307.062
trainer/Q1Pred Min                          -10.7611
trainer/Q2Pred Mean                         209.267
trainer/Q2Pred Std                           74.042
trainer/Q2Pred Max                          307.703
trainer/Q2Pred Min                          -16.6345
trainer/QTargetWithReg Mean                 208.914
trainer/QTargetWithReg Std                   73.9746
trainer/QTargetWithReg Max                  307.098
trainer/QTargetWithReg Min                  -18.8693
trainer/PolicyLossWithoutReg Mean           209.778
trainer/PolicyLossWithoutReg Std             73.108
trainer/PolicyLossWithoutReg Max            306.755
trainer/PolicyLossWithoutReg Min             -8.77425
trainer/gradient_norm                       336.221
trainer/gradient_penalty                     -1.68111
trainer/gradient_percentage                  -0.00801374
exploration/num steps total              664000
exploration/num paths total                1824
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05975
exploration/Rewards Std                       1.35624
exploration/Rewards Max                      10.5644
exploration/Rewards Min                      -0.462777
exploration/Returns Mean                   5059.75
exploration/Returns Std                       0
exploration/Returns Max                    5059.75
exploration/Returns Min                    5059.75
exploration/Num Paths                         1
exploration/Average Returns                5059.75
evaluation_0/num steps total                  5.18996e+06
evaluation_0/num paths total              13344
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05246
evaluation_0/Rewards Std                      1.34955
evaluation_0/Rewards Max                     10.4744
evaluation_0/Rewards Min                     -0.439536
evaluation_0/Returns Mean                  5052.46
evaluation_0/Returns Std                     25.9066
evaluation_0/Returns Max                   5084.85
evaluation_0/Returns Min                   5015.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5052.46
time/epoch (s)                                0
time/total (s)                            12581.5
Epoch                                       659
---------------------------------------  ----------------
2022-11-16 14:15:43.516405 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 660 finished
---------------------------------------  ----------------
epoch                                       660
total_step                               665000
replay_pool/size                         665000
trainer/alpha                                 0.0642193
trainer/alpha_loss                           -0.329062
trainer/entropy                              -5.88015
trainer/qf_loss                              10.6864
trainer/state_noise                           0.005
trainer/policy_loss                        -211.782
trainer/policy_loss_without_entropy         213.944
trainer/entropy_penalty                      -0.377619
trainer/entropy_percentage                   -0.00176504
trainer/Q1Pred Mean                         211.966
trainer/Q1Pred Std                           72.2004
trainer/Q1Pred Max                          306.852
trainer/Q1Pred Min                            5.69471
trainer/Q2Pred Mean                         212.735
trainer/Q2Pred Std                           72.5296
trainer/Q2Pred Max                          307.925
trainer/Q2Pred Min                            2.60635
trainer/QTargetWithReg Mean                 212.4
trainer/QTargetWithReg Std                   72.4476
trainer/QTargetWithReg Max                  306.36
trainer/QTargetWithReg Min                   -0.985178
trainer/PolicyLossWithoutReg Mean           213.944
trainer/PolicyLossWithoutReg Std             70.4177
trainer/PolicyLossWithoutReg Max            306.955
trainer/PolicyLossWithoutReg Min              4.37961
trainer/gradient_norm                       356.874
trainer/gradient_penalty                     -1.78437
trainer/gradient_percentage                  -0.00834037
exploration/num steps total              665000
exploration/num paths total                1825
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98023
exploration/Rewards Std                       1.35128
exploration/Rewards Max                      10.4223
exploration/Rewards Min                      -0.386558
exploration/Returns Mean                   4980.23
exploration/Returns Std                       0
exploration/Returns Max                    4980.23
exploration/Returns Min                    4980.23
exploration/Num Paths                         1
exploration/Average Returns                4980.23
evaluation_0/num steps total                  5.19796e+06
evaluation_0/num paths total              13352
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08181
evaluation_0/Rewards Std                      1.34288
evaluation_0/Rewards Max                     10.5639
evaluation_0/Rewards Min                     -0.267188
evaluation_0/Returns Mean                  5081.81
evaluation_0/Returns Std                     20.9822
evaluation_0/Returns Max                   5115.83
evaluation_0/Returns Min                   5039.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5081.81
time/epoch (s)                                0
time/total (s)                            12597.3
Epoch                                       660
---------------------------------------  ----------------
2022-11-16 14:16:01.578476 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 661 finished
---------------------------------------  ----------------
epoch                                       661
total_step                               666000
replay_pool/size                         666000
trainer/alpha                                 0.0649601
trainer/alpha_loss                            0.0330278
trainer/entropy                              -6.01208
trainer/qf_loss                               6.11137
trainer/state_noise                           0.005
trainer/policy_loss                        -213.44
trainer/policy_loss_without_entropy         215.526
trainer/entropy_penalty                      -0.390545
trainer/entropy_percentage                   -0.00181206
trainer/Q1Pred Mean                         214.631
trainer/Q1Pred Std                           75.4449
trainer/Q1Pred Max                          308.448
trainer/Q1Pred Min                            3.13764
trainer/Q2Pred Mean                         214.91
trainer/Q2Pred Std                           75.5478
trainer/Q2Pred Max                          309.954
trainer/Q2Pred Min                           -2.02583
trainer/QTargetWithReg Mean                 213.9
trainer/QTargetWithReg Std                   75.4365
trainer/QTargetWithReg Max                  306.877
trainer/QTargetWithReg Min                   -0.360031
trainer/PolicyLossWithoutReg Mean           215.526
trainer/PolicyLossWithoutReg Std             74.6453
trainer/PolicyLossWithoutReg Max            309.204
trainer/PolicyLossWithoutReg Min              5.2759
trainer/gradient_norm                       338.933
trainer/gradient_penalty                     -1.69467
trainer/gradient_percentage                  -0.00786295
exploration/num steps total              666000
exploration/num paths total                1826
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0614
exploration/Rewards Std                       1.34566
exploration/Rewards Max                      10.3632
exploration/Rewards Min                      -0.299064
exploration/Returns Mean                   5061.4
exploration/Returns Std                       0
exploration/Returns Max                    5061.4
exploration/Returns Min                    5061.4
exploration/Num Paths                         1
exploration/Average Returns                5061.4
evaluation_0/num steps total                  5.20552e+06
evaluation_0/num paths total              13360
evaluation_0/path length Mean               945.25
evaluation_0/path length Std                144.855
evaluation_0/path length Max               1000
evaluation_0/path length Min                562
evaluation_0/Rewards Mean                     4.96211
evaluation_0/Rewards Std                      1.41912
evaluation_0/Rewards Max                     11.2634
evaluation_0/Rewards Min                     -0.423369
evaluation_0/Returns Mean                  4690.43
evaluation_0/Returns Std                    719.958
evaluation_0/Returns Max                   5043.43
evaluation_0/Returns Min                   2794.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4690.43
time/epoch (s)                                0
time/total (s)                            12615.3
Epoch                                       661
---------------------------------------  ----------------
2022-11-16 14:16:17.459671 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 662 finished
---------------------------------------  ----------------
epoch                                       662
total_step                               667000
replay_pool/size                         667000
trainer/alpha                                 0.064399
trainer/alpha_loss                           -1.78393
trainer/entropy                              -5.34954
trainer/qf_loss                               7.8065
trainer/state_noise                           0.005
trainer/policy_loss                        -213.851
trainer/policy_loss_without_entropy         215.917
trainer/entropy_penalty                      -0.344505
trainer/entropy_percentage                   -0.00159554
trainer/Q1Pred Mean                         215.338
trainer/Q1Pred Std                           68.3145
trainer/Q1Pred Max                          314.845
trainer/Q1Pred Min                           12.563
trainer/Q2Pred Mean                         215.617
trainer/Q2Pred Std                           68.3748
trainer/Q2Pred Max                          316.509
trainer/Q2Pred Min                           13.665
trainer/QTargetWithReg Mean                 215.635
trainer/QTargetWithReg Std                   68.4696
trainer/QTargetWithReg Max                  315.342
trainer/QTargetWithReg Min                   13.5196
trainer/PolicyLossWithoutReg Mean           215.917
trainer/PolicyLossWithoutReg Std             67.7331
trainer/PolicyLossWithoutReg Max            315.693
trainer/PolicyLossWithoutReg Min             13.3163
trainer/gradient_norm                       344.314
trainer/gradient_penalty                     -1.72157
trainer/gradient_percentage                  -0.00797329
exploration/num steps total              667000
exploration/num paths total                1827
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00408
exploration/Rewards Std                       1.36372
exploration/Rewards Max                      10.4412
exploration/Rewards Min                      -0.402805
exploration/Returns Mean                   5004.08
exploration/Returns Std                       0
exploration/Returns Max                    5004.08
exploration/Returns Min                    5004.08
exploration/Num Paths                         1
exploration/Average Returns                5004.08
evaluation_0/num steps total                  5.21352e+06
evaluation_0/num paths total              13368
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02734
evaluation_0/Rewards Std                      1.34731
evaluation_0/Rewards Max                     10.6691
evaluation_0/Rewards Min                     -0.333608
evaluation_0/Returns Mean                  5027.34
evaluation_0/Returns Std                     30.7764
evaluation_0/Returns Max                   5084.27
evaluation_0/Returns Min                   4989.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5027.34
time/epoch (s)                                0
time/total (s)                            12631.2
Epoch                                       662
---------------------------------------  ----------------
2022-11-16 14:16:33.816378 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 663 finished
---------------------------------------  ----------------
epoch                                       663
total_step                               668000
replay_pool/size                         668000
trainer/alpha                                 0.0629057
trainer/alpha_loss                           -0.398658
trainer/entropy                              -5.85588
trainer/qf_loss                              11.3259
trainer/state_noise                           0.005
trainer/policy_loss                        -211.691
trainer/policy_loss_without_entropy         213.724
trainer/entropy_penalty                      -0.368368
trainer/entropy_percentage                   -0.00172357
trainer/Q1Pred Mean                         212.695
trainer/Q1Pred Std                           75.385
trainer/Q1Pred Max                          306.737
trainer/Q1Pred Min                            4.9541
trainer/Q2Pred Mean                         212.947
trainer/Q2Pred Std                           75.5783
trainer/Q2Pred Max                          307.589
trainer/Q2Pred Min                            3.59022
trainer/QTargetWithReg Mean                 212.891
trainer/QTargetWithReg Std                   75.9864
trainer/QTargetWithReg Max                  307.472
trainer/QTargetWithReg Min                    1.52841
trainer/PolicyLossWithoutReg Mean           213.724
trainer/PolicyLossWithoutReg Std             74.22
trainer/PolicyLossWithoutReg Max            306.504
trainer/PolicyLossWithoutReg Min              4.67809
trainer/gradient_norm                       332.938
trainer/gradient_penalty                     -1.66469
trainer/gradient_percentage                  -0.00778897
exploration/num steps total              668000
exploration/num paths total                1828
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02253
exploration/Rewards Std                       1.34577
exploration/Rewards Max                      10.3013
exploration/Rewards Min                      -0.329899
exploration/Returns Mean                   5022.53
exploration/Returns Std                       0
exploration/Returns Max                    5022.53
exploration/Returns Min                    5022.53
exploration/Num Paths                         1
exploration/Average Returns                5022.53
evaluation_0/num steps total                  5.22152e+06
evaluation_0/num paths total              13376
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04564
evaluation_0/Rewards Std                      1.35457
evaluation_0/Rewards Max                     10.7082
evaluation_0/Rewards Min                     -0.424152
evaluation_0/Returns Mean                  5045.64
evaluation_0/Returns Std                     33.7427
evaluation_0/Returns Max                   5084.05
evaluation_0/Returns Min                   4994.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5045.64
time/epoch (s)                                0
time/total (s)                            12647.6
Epoch                                       663
---------------------------------------  ----------------
2022-11-16 14:16:49.662741 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 664 finished
---------------------------------------  ----------------
epoch                                       664
total_step                               669000
replay_pool/size                         669000
trainer/alpha                                 0.0635943
trainer/alpha_loss                           -0.487293
trainer/entropy                              -5.82314
trainer/qf_loss                               7.40213
trainer/state_noise                           0.005
trainer/policy_loss                        -218.641
trainer/policy_loss_without_entropy         220.742
trainer/entropy_penalty                      -0.370319
trainer/entropy_percentage                   -0.00167761
trainer/Q1Pred Mean                         220.169
trainer/Q1Pred Std                           71.4135
trainer/Q1Pred Max                          308.07
trainer/Q1Pred Min                           -4.80823
trainer/Q2Pred Mean                         220.539
trainer/Q2Pred Std                           71.4429
trainer/Q2Pred Max                          308.89
trainer/Q2Pred Min                           -2.01796
trainer/QTargetWithReg Mean                 220.665
trainer/QTargetWithReg Std                   71.2412
trainer/QTargetWithReg Max                  308.151
trainer/QTargetWithReg Min                   -0.877545
trainer/PolicyLossWithoutReg Mean           220.742
trainer/PolicyLossWithoutReg Std             70.5893
trainer/PolicyLossWithoutReg Max            307.938
trainer/PolicyLossWithoutReg Min             -3.41008
trainer/gradient_norm                       346.179
trainer/gradient_penalty                     -1.73089
trainer/gradient_percentage                  -0.00784125
exploration/num steps total              669000
exploration/num paths total                1829
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00964
exploration/Rewards Std                       1.32809
exploration/Rewards Max                      10.2402
exploration/Rewards Min                      -0.394151
exploration/Returns Mean                   5009.64
exploration/Returns Std                       0
exploration/Returns Max                    5009.64
exploration/Returns Min                    5009.64
exploration/Num Paths                         1
exploration/Average Returns                5009.64
evaluation_0/num steps total                  5.22952e+06
evaluation_0/num paths total              13384
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03566
evaluation_0/Rewards Std                      1.2854
evaluation_0/Rewards Max                     10.365
evaluation_0/Rewards Min                     -0.439557
evaluation_0/Returns Mean                  5035.66
evaluation_0/Returns Std                     13.0373
evaluation_0/Returns Max                   5054.39
evaluation_0/Returns Min                   5014.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5035.66
time/epoch (s)                                0
time/total (s)                            12663.4
Epoch                                       664
---------------------------------------  ----------------
2022-11-16 14:17:05.671365 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 665 finished
---------------------------------------  ----------------
epoch                                       665
total_step                               670000
replay_pool/size                         670000
trainer/alpha                                 0.0648292
trainer/alpha_loss                           -0.49698
trainer/entropy                              -5.81835
trainer/qf_loss                               7.65698
trainer/state_noise                           0.005
trainer/policy_loss                        -213.16
trainer/policy_loss_without_entropy         215.211
trainer/entropy_penalty                      -0.377199
trainer/entropy_percentage                   -0.00175269
trainer/Q1Pred Mean                         214.664
trainer/Q1Pred Std                           74.2025
trainer/Q1Pred Max                          307.59
trainer/Q1Pred Min                          -10.4274
trainer/Q2Pred Mean                         214.859
trainer/Q2Pred Std                           74.0607
trainer/Q2Pred Max                          306.366
trainer/Q2Pred Min                          -12.7233
trainer/QTargetWithReg Mean                 214.671
trainer/QTargetWithReg Std                   74.5479
trainer/QTargetWithReg Max                  309.589
trainer/QTargetWithReg Min                   -8.25428
trainer/PolicyLossWithoutReg Mean           215.211
trainer/PolicyLossWithoutReg Std             72.8017
trainer/PolicyLossWithoutReg Max            306.769
trainer/PolicyLossWithoutReg Min             -4.6571
trainer/gradient_norm                       334.737
trainer/gradient_penalty                     -1.67369
trainer/gradient_percentage                  -0.00777694
exploration/num steps total              670000
exploration/num paths total                1830
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94325
exploration/Rewards Std                       1.32903
exploration/Rewards Max                      10.4787
exploration/Rewards Min                      -0.443091
exploration/Returns Mean                   4943.25
exploration/Returns Std                       0
exploration/Returns Max                    4943.25
exploration/Returns Min                    4943.25
exploration/Num Paths                         1
exploration/Average Returns                4943.25
evaluation_0/num steps total                  5.23752e+06
evaluation_0/num paths total              13392
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06036
evaluation_0/Rewards Std                      1.34278
evaluation_0/Rewards Max                     10.7895
evaluation_0/Rewards Min                     -0.451151
evaluation_0/Returns Mean                  5060.36
evaluation_0/Returns Std                     23.1776
evaluation_0/Returns Max                   5095.38
evaluation_0/Returns Min                   5028.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5060.36
time/epoch (s)                                0
time/total (s)                            12679.4
Epoch                                       665
---------------------------------------  ----------------
2022-11-16 14:17:21.804084 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 666 finished
---------------------------------------  ----------------
epoch                                       666
total_step                               671000
replay_pool/size                         671000
trainer/alpha                                 0.065049
trainer/alpha_loss                           -0.727722
trainer/entropy                              -5.73369
trainer/qf_loss                               6.88908
trainer/state_noise                           0.005
trainer/policy_loss                        -207.869
trainer/policy_loss_without_entropy         209.866
trainer/entropy_penalty                      -0.372971
trainer/entropy_percentage                   -0.00177719
trainer/Q1Pred Mean                         209.592
trainer/Q1Pred Std                           73.8922
trainer/Q1Pred Max                          305.979
trainer/Q1Pred Min                            7.03285
trainer/Q2Pred Mean                         209.744
trainer/Q2Pred Std                           73.9348
trainer/Q2Pred Max                          306.075
trainer/Q2Pred Min                           10.5042
trainer/QTargetWithReg Mean                 209.586
trainer/QTargetWithReg Std                   73.9214
trainer/QTargetWithReg Max                  305.081
trainer/QTargetWithReg Min                    8.75066
trainer/PolicyLossWithoutReg Mean           209.866
trainer/PolicyLossWithoutReg Std             72.9243
trainer/PolicyLossWithoutReg Max            305.865
trainer/PolicyLossWithoutReg Min              6.17861
trainer/gradient_norm                       324.745
trainer/gradient_penalty                     -1.62372
trainer/gradient_percentage                  -0.00773697
exploration/num steps total              671000
exploration/num paths total                1831
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96421
exploration/Rewards Std                       1.36186
exploration/Rewards Max                      10.8551
exploration/Rewards Min                      -0.475962
exploration/Returns Mean                   4964.21
exploration/Returns Std                       0
exploration/Returns Max                    4964.21
exploration/Returns Min                    4964.21
exploration/Num Paths                         1
exploration/Average Returns                4964.21
evaluation_0/num steps total                  5.24552e+06
evaluation_0/num paths total              13400
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06013
evaluation_0/Rewards Std                      1.32689
evaluation_0/Rewards Max                     10.7151
evaluation_0/Rewards Min                     -0.362831
evaluation_0/Returns Mean                  5060.13
evaluation_0/Returns Std                     11.0218
evaluation_0/Returns Max                   5075.59
evaluation_0/Returns Min                   5045.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5060.13
time/epoch (s)                                0
time/total (s)                            12695.6
Epoch                                       666
---------------------------------------  ----------------
2022-11-16 14:17:37.655781 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 667 finished
---------------------------------------  ----------------
epoch                                       667
total_step                               672000
replay_pool/size                         672000
trainer/alpha                                 0.0617294
trainer/alpha_loss                            0.713816
trainer/entropy                              -6.25628
trainer/qf_loss                              10.724
trainer/state_noise                           0.005
trainer/policy_loss                        -212.348
trainer/policy_loss_without_entropy         214.534
trainer/entropy_penalty                      -0.386196
trainer/entropy_percentage                   -0.00180016
trainer/Q1Pred Mean                         213.5
trainer/Q1Pred Std                           74.2956
trainer/Q1Pred Max                          312.47
trainer/Q1Pred Min                            1.49785
trainer/Q2Pred Mean                         213.81
trainer/Q2Pred Std                           74.4801
trainer/Q2Pred Max                          310.588
trainer/Q2Pred Min                            1.13517
trainer/QTargetWithReg Mean                 213.124
trainer/QTargetWithReg Std                   74.3159
trainer/QTargetWithReg Max                  312.189
trainer/QTargetWithReg Min                   -1.38662
trainer/PolicyLossWithoutReg Mean           214.534
trainer/PolicyLossWithoutReg Std             73.0613
trainer/PolicyLossWithoutReg Max            310.026
trainer/PolicyLossWithoutReg Min             -2.18161
trainer/gradient_norm                       360.099
trainer/gradient_penalty                     -1.8005
trainer/gradient_percentage                  -0.00839257
exploration/num steps total              672000
exploration/num paths total                1832
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09224
exploration/Rewards Std                       1.33927
exploration/Rewards Max                      10.543
exploration/Rewards Min                      -0.412496
exploration/Returns Mean                   5092.24
exploration/Returns Std                       0
exploration/Returns Max                    5092.24
exploration/Returns Min                    5092.24
exploration/Num Paths                         1
exploration/Average Returns                5092.24
evaluation_0/num steps total                  5.25352e+06
evaluation_0/num paths total              13408
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03858
evaluation_0/Rewards Std                      1.31641
evaluation_0/Rewards Max                     10.7371
evaluation_0/Rewards Min                     -0.30669
evaluation_0/Returns Mean                  5038.58
evaluation_0/Returns Std                     24.2791
evaluation_0/Returns Max                   5081.06
evaluation_0/Returns Min                   5008.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5038.58
time/epoch (s)                                0
time/total (s)                            12711.4
Epoch                                       667
---------------------------------------  ----------------
2022-11-16 14:17:54.126143 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 668 finished
---------------------------------------  ----------------
epoch                                       668
total_step                               673000
replay_pool/size                         673000
trainer/alpha                                 0.0620489
trainer/alpha_loss                            0.511054
trainer/entropy                              -6.18384
trainer/qf_loss                               7.86925
trainer/state_noise                           0.005
trainer/policy_loss                        -213.555
trainer/policy_loss_without_entropy         215.658
trainer/entropy_penalty                      -0.383701
trainer/entropy_percentage                   -0.00177921
trainer/Q1Pred Mean                         214.911
trainer/Q1Pred Std                           74.2051
trainer/Q1Pred Max                          306.684
trainer/Q1Pred Min                          -15.3003
trainer/Q2Pred Mean                         214.834
trainer/Q2Pred Std                           73.6725
trainer/Q2Pred Max                          306.109
trainer/Q2Pred Min                          -15.1155
trainer/QTargetWithReg Mean                 215.032
trainer/QTargetWithReg Std                   73.5524
trainer/QTargetWithReg Max                  306.112
trainer/QTargetWithReg Min                   -8.30553
trainer/PolicyLossWithoutReg Mean           215.658
trainer/PolicyLossWithoutReg Std             72.683
trainer/PolicyLossWithoutReg Max            305.621
trainer/PolicyLossWithoutReg Min            -11.6623
trainer/gradient_norm                       343.956
trainer/gradient_penalty                     -1.71978
trainer/gradient_percentage                  -0.00797456
exploration/num steps total              673000
exploration/num paths total                1833
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02752
exploration/Rewards Std                       1.33288
exploration/Rewards Max                      10.461
exploration/Rewards Min                      -0.418244
exploration/Returns Mean                   5027.52
exploration/Returns Std                       0
exploration/Returns Max                    5027.52
exploration/Returns Min                    5027.52
exploration/Num Paths                         1
exploration/Average Returns                5027.52
evaluation_0/num steps total                  5.26152e+06
evaluation_0/num paths total              13416
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00909
evaluation_0/Rewards Std                      1.31179
evaluation_0/Rewards Max                     10.5477
evaluation_0/Rewards Min                     -0.413158
evaluation_0/Returns Mean                  5009.09
evaluation_0/Returns Std                     12.5183
evaluation_0/Returns Max                   5026.26
evaluation_0/Returns Min                   4988.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5009.09
time/epoch (s)                                0
time/total (s)                            12727.9
Epoch                                       668
---------------------------------------  ----------------
2022-11-16 14:18:10.105741 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 669 finished
---------------------------------------  ----------------
epoch                                       669
total_step                               674000
replay_pool/size                         674000
trainer/alpha                                 0.0614835
trainer/alpha_loss                           -0.291259
trainer/entropy                              -5.89557
trainer/qf_loss                               8.07484
trainer/state_noise                           0.005
trainer/policy_loss                        -219.626
trainer/policy_loss_without_entropy         221.725
trainer/entropy_penalty                      -0.36248
trainer/entropy_percentage                   -0.00163482
trainer/Q1Pred Mean                         221.073
trainer/Q1Pred Std                           70.8654
trainer/Q1Pred Max                          313.51
trainer/Q1Pred Min                            4.24597
trainer/Q2Pred Mean                         221.465
trainer/Q2Pred Std                           71.2157
trainer/Q2Pred Max                          314.294
trainer/Q2Pred Min                           -0.847836
trainer/QTargetWithReg Mean                 221.094
trainer/QTargetWithReg Std                   70.6773
trainer/QTargetWithReg Max                  312.936
trainer/QTargetWithReg Min                    8.80923
trainer/PolicyLossWithoutReg Mean           221.725
trainer/PolicyLossWithoutReg Std             70.0205
trainer/PolicyLossWithoutReg Max            313.497
trainer/PolicyLossWithoutReg Min              7.05306
trainer/gradient_norm                       347.209
trainer/gradient_penalty                     -1.73605
trainer/gradient_percentage                  -0.00782973
exploration/num steps total              674000
exploration/num paths total                1834
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97914
exploration/Rewards Std                       1.30669
exploration/Rewards Max                      10.5087
exploration/Rewards Min                      -0.558594
exploration/Returns Mean                   4979.14
exploration/Returns Std                       0
exploration/Returns Max                    4979.14
exploration/Returns Min                    4979.14
exploration/Num Paths                         1
exploration/Average Returns                4979.14
evaluation_0/num steps total                  5.26952e+06
evaluation_0/num paths total              13424
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04787
evaluation_0/Rewards Std                      1.37666
evaluation_0/Rewards Max                     10.6526
evaluation_0/Rewards Min                     -0.310574
evaluation_0/Returns Mean                  5047.87
evaluation_0/Returns Std                      8.45953
evaluation_0/Returns Max                   5056.01
evaluation_0/Returns Min                   5033.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5047.87
time/epoch (s)                                0
time/total (s)                            12743.9
Epoch                                       669
---------------------------------------  ----------------
2022-11-16 14:18:26.612864 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 670 finished
---------------------------------------  ----------------
epoch                                       670
total_step                               675000
replay_pool/size                         675000
trainer/alpha                                 0.0626606
trainer/alpha_loss                            0.112834
trainer/entropy                              -6.04074
trainer/qf_loss                               6.94152
trainer/state_noise                           0.005
trainer/policy_loss                        -215.762
trainer/policy_loss_without_entropy         217.882
trainer/entropy_penalty                      -0.378516
trainer/entropy_percentage                   -0.00173726
trainer/Q1Pred Mean                         217.056
trainer/Q1Pred Std                           70.6162
trainer/Q1Pred Max                          311.475
trainer/Q1Pred Min                          -48.605
trainer/Q2Pred Mean                         217.096
trainer/Q2Pred Std                           70.8024
trainer/Q2Pred Max                          312.61
trainer/Q2Pred Min                          -48.3384
trainer/QTargetWithReg Mean                 217.515
trainer/QTargetWithReg Std                   70.4834
trainer/QTargetWithReg Max                  312.193
trainer/QTargetWithReg Min                  -38.099
trainer/PolicyLossWithoutReg Mean           217.882
trainer/PolicyLossWithoutReg Std             70.0602
trainer/PolicyLossWithoutReg Max            311.443
trainer/PolicyLossWithoutReg Min            -40.3913
trainer/gradient_norm                       348.166
trainer/gradient_penalty                     -1.74083
trainer/gradient_percentage                  -0.00798981
exploration/num steps total              675000
exploration/num paths total                1835
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01253
exploration/Rewards Std                       1.41341
exploration/Rewards Max                      10.7859
exploration/Rewards Min                      -0.32423
exploration/Returns Mean                   5012.53
exploration/Returns Std                       0
exploration/Returns Max                    5012.53
exploration/Returns Min                    5012.53
exploration/Num Paths                         1
exploration/Average Returns                5012.53
evaluation_0/num steps total                  5.27752e+06
evaluation_0/num paths total              13432
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04554
evaluation_0/Rewards Std                      1.32446
evaluation_0/Rewards Max                     10.6648
evaluation_0/Rewards Min                     -0.268467
evaluation_0/Returns Mean                  5045.54
evaluation_0/Returns Std                     48.633
evaluation_0/Returns Max                   5136.33
evaluation_0/Returns Min                   4984.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5045.54
time/epoch (s)                                0
time/total (s)                            12760.4
Epoch                                       670
---------------------------------------  ----------------
2022-11-16 14:18:42.467404 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 671 finished
---------------------------------------  ----------------
epoch                                       671
total_step                               676000
replay_pool/size                         676000
trainer/alpha                                 0.0645575
trainer/alpha_loss                            1.02129
trainer/entropy                              -6.37269
trainer/qf_loss                              20.5816
trainer/state_noise                           0.005
trainer/policy_loss                        -217.574
trainer/policy_loss_without_entropy         219.68
trainer/entropy_penalty                      -0.411405
trainer/entropy_percentage                   -0.00187275
trainer/Q1Pred Mean                         218.685
trainer/Q1Pred Std                           70.3668
trainer/Q1Pred Max                          313.55
trainer/Q1Pred Min                           -0.761372
trainer/Q2Pred Mean                         218.6
trainer/Q2Pred Std                           69.9264
trainer/Q2Pred Max                          310.865
trainer/Q2Pred Min                            0.432042
trainer/QTargetWithReg Mean                 218.139
trainer/QTargetWithReg Std                   70.8151
trainer/QTargetWithReg Max                  313.112
trainer/QTargetWithReg Min                   -2.56894
trainer/PolicyLossWithoutReg Mean           219.68
trainer/PolicyLossWithoutReg Std             69.1441
trainer/PolicyLossWithoutReg Max            312.054
trainer/PolicyLossWithoutReg Min             19.5259
trainer/gradient_norm                       338.933
trainer/gradient_penalty                     -1.69466
trainer/gradient_percentage                  -0.00771423
exploration/num steps total              676000
exploration/num paths total                1836
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99409
exploration/Rewards Std                       1.35239
exploration/Rewards Max                      10.3603
exploration/Rewards Min                      -0.274981
exploration/Returns Mean                   4994.09
exploration/Returns Std                       0
exploration/Returns Max                    4994.09
exploration/Returns Min                    4994.09
exploration/Num Paths                         1
exploration/Average Returns                4994.09
evaluation_0/num steps total                  5.28552e+06
evaluation_0/num paths total              13440
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10691
evaluation_0/Rewards Std                      1.33661
evaluation_0/Rewards Max                     10.7037
evaluation_0/Rewards Min                     -0.275262
evaluation_0/Returns Mean                  5106.91
evaluation_0/Returns Std                     29.8918
evaluation_0/Returns Max                   5149.84
evaluation_0/Returns Min                   5073.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5106.91
time/epoch (s)                                0
time/total (s)                            12776.2
Epoch                                       671
---------------------------------------  ----------------
2022-11-16 14:18:58.845644 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 672 finished
---------------------------------------  ----------------
epoch                                       672
total_step                               677000
replay_pool/size                         677000
trainer/alpha                                 0.0631421
trainer/alpha_loss                           -0.537121
trainer/entropy                              -5.80554
trainer/qf_loss                               7.60255
trainer/state_noise                           0.005
trainer/policy_loss                        -222.193
trainer/policy_loss_without_entropy         224.276
trainer/entropy_penalty                      -0.366574
trainer/entropy_percentage                   -0.00163448
trainer/Q1Pred Mean                         223.305
trainer/Q1Pred Std                           70.8539
trainer/Q1Pred Max                          310.063
trainer/Q1Pred Min                            9.64398
trainer/Q2Pred Mean                         223.227
trainer/Q2Pred Std                           70.6037
trainer/Q2Pred Max                          308.094
trainer/Q2Pred Min                           13.1881
trainer/QTargetWithReg Mean                 223.356
trainer/QTargetWithReg Std                   71.0089
trainer/QTargetWithReg Max                  308.781
trainer/QTargetWithReg Min                   12.1339
trainer/PolicyLossWithoutReg Mean           224.276
trainer/PolicyLossWithoutReg Std             70.3062
trainer/PolicyLossWithoutReg Max            308.824
trainer/PolicyLossWithoutReg Min             15.6131
trainer/gradient_norm                       343.204
trainer/gradient_penalty                     -1.71602
trainer/gradient_percentage                  -0.00765137
exploration/num steps total              677000
exploration/num paths total                1837
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08863
exploration/Rewards Std                       1.31795
exploration/Rewards Max                      10.2762
exploration/Rewards Min                      -0.283383
exploration/Returns Mean                   5088.63
exploration/Returns Std                       0
exploration/Returns Max                    5088.63
exploration/Returns Min                    5088.63
exploration/Num Paths                         1
exploration/Average Returns                5088.63
evaluation_0/num steps total                  5.29352e+06
evaluation_0/num paths total              13448
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02131
evaluation_0/Rewards Std                      1.33565
evaluation_0/Rewards Max                     10.8067
evaluation_0/Rewards Min                     -0.360104
evaluation_0/Returns Mean                  5021.31
evaluation_0/Returns Std                     40.5993
evaluation_0/Returns Max                   5076.7
evaluation_0/Returns Min                   4947.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5021.31
time/epoch (s)                                0
time/total (s)                            12792.6
Epoch                                       672
---------------------------------------  ----------------
2022-11-16 14:19:14.745836 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 673 finished
---------------------------------------  ----------------
epoch                                       673
total_step                               678000
replay_pool/size                         678000
trainer/alpha                                 0.0625936
trainer/alpha_loss                            0.459956
trainer/entropy                              -6.16598
trainer/qf_loss                              16.1024
trainer/state_noise                           0.005
trainer/policy_loss                        -217.318
trainer/policy_loss_without_entropy         219.36
trainer/entropy_penalty                      -0.385951
trainer/entropy_percentage                   -0.00175944
trainer/Q1Pred Mean                         218.574
trainer/Q1Pred Std                           71.8041
trainer/Q1Pred Max                          309.94
trainer/Q1Pred Min                            3.26848
trainer/Q2Pred Mean                         218.395
trainer/Q2Pred Std                           71.6972
trainer/Q2Pred Max                          308.597
trainer/Q2Pred Min                           -7.66719
trainer/QTargetWithReg Mean                 218.511
trainer/QTargetWithReg Std                   72.2241
trainer/QTargetWithReg Max                  311.56
trainer/QTargetWithReg Min                   -8.74933
trainer/PolicyLossWithoutReg Mean           219.36
trainer/PolicyLossWithoutReg Std             71.1681
trainer/PolicyLossWithoutReg Max            309.513
trainer/PolicyLossWithoutReg Min            -10.1125
trainer/gradient_norm                       331.184
trainer/gradient_penalty                     -1.65592
trainer/gradient_percentage                  -0.00754889
exploration/num steps total              678000
exploration/num paths total                1838
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85287
exploration/Rewards Std                       1.32175
exploration/Rewards Max                      10.2096
exploration/Rewards Min                      -0.520743
exploration/Returns Mean                   4852.87
exploration/Returns Std                       0
exploration/Returns Max                    4852.87
exploration/Returns Min                    4852.87
exploration/Num Paths                         1
exploration/Average Returns                4852.87
evaluation_0/num steps total                  5.30152e+06
evaluation_0/num paths total              13456
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04957
evaluation_0/Rewards Std                      1.34397
evaluation_0/Rewards Max                     10.6303
evaluation_0/Rewards Min                     -0.384823
evaluation_0/Returns Mean                  5049.57
evaluation_0/Returns Std                     25.1871
evaluation_0/Returns Max                   5082.92
evaluation_0/Returns Min                   4994.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5049.57
time/epoch (s)                                0
time/total (s)                            12808.5
Epoch                                       673
---------------------------------------  ----------------
2022-11-16 14:19:30.902520 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 674 finished
---------------------------------------  ----------------
epoch                                       674
total_step                               679000
replay_pool/size                         679000
trainer/alpha                                 0.0621223
trainer/alpha_loss                           -0.667077
trainer/entropy                              -5.75993
trainer/qf_loss                               5.55798
trainer/state_noise                           0.005
trainer/policy_loss                        -213.275
trainer/policy_loss_without_entropy         215.255
trainer/entropy_penalty                      -0.35782
trainer/entropy_percentage                   -0.00166231
trainer/Q1Pred Mean                         214.291
trainer/Q1Pred Std                           78.5105
trainer/Q1Pred Max                          307.029
trainer/Q1Pred Min                            7.24509
trainer/Q2Pred Mean                         214.392
trainer/Q2Pred Std                           78.6055
trainer/Q2Pred Max                          307.925
trainer/Q2Pred Min                            6.80821
trainer/QTargetWithReg Mean                 213.89
trainer/QTargetWithReg Std                   78.5108
trainer/QTargetWithReg Max                  304.037
trainer/QTargetWithReg Min                    4.85904
trainer/PolicyLossWithoutReg Mean           215.255
trainer/PolicyLossWithoutReg Std             78.1153
trainer/PolicyLossWithoutReg Max            307.612
trainer/PolicyLossWithoutReg Min              7.777
trainer/gradient_norm                       324.421
trainer/gradient_penalty                     -1.6221
trainer/gradient_percentage                  -0.00753574
exploration/num steps total              679000
exploration/num paths total                1839
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07299
exploration/Rewards Std                       1.33304
exploration/Rewards Max                      10.7618
exploration/Rewards Min                      -0.542656
exploration/Returns Mean                   5072.99
exploration/Returns Std                       0
exploration/Returns Max                    5072.99
exploration/Returns Min                    5072.99
exploration/Num Paths                         1
exploration/Average Returns                5072.99
evaluation_0/num steps total                  5.30952e+06
evaluation_0/num paths total              13464
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04899
evaluation_0/Rewards Std                      1.3352
evaluation_0/Rewards Max                     10.6989
evaluation_0/Rewards Min                     -0.557702
evaluation_0/Returns Mean                  5048.99
evaluation_0/Returns Std                     18.0887
evaluation_0/Returns Max                   5072.32
evaluation_0/Returns Min                   5009.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5048.99
time/epoch (s)                                0
time/total (s)                            12824.7
Epoch                                       674
---------------------------------------  ----------------
2022-11-16 14:19:47.119188 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 675 finished
---------------------------------------  ----------------
epoch                                       675
total_step                               680000
replay_pool/size                         680000
trainer/alpha                                 0.062759
trainer/alpha_loss                            0.298648
trainer/entropy                              -6.10788
trainer/qf_loss                               7.26248
trainer/state_noise                           0.005
trainer/policy_loss                        -212.564
trainer/policy_loss_without_entropy         214.675
trainer/entropy_penalty                      -0.383325
trainer/entropy_percentage                   -0.00178561
trainer/Q1Pred Mean                         213.704
trainer/Q1Pred Std                           73.0966
trainer/Q1Pred Max                          308.715
trainer/Q1Pred Min                           11.8013
trainer/Q2Pred Mean                         214.152
trainer/Q2Pred Std                           72.8399
trainer/Q2Pred Max                          313.32
trainer/Q2Pred Min                           11.5909
trainer/QTargetWithReg Mean                 213.824
trainer/QTargetWithReg Std                   72.8233
trainer/QTargetWithReg Max                  313.023
trainer/QTargetWithReg Min                   14.2649
trainer/PolicyLossWithoutReg Mean           214.675
trainer/PolicyLossWithoutReg Std             72.007
trainer/PolicyLossWithoutReg Max            309.528
trainer/PolicyLossWithoutReg Min             11.3934
trainer/gradient_norm                       345.514
trainer/gradient_penalty                     -1.72757
trainer/gradient_percentage                  -0.00804737
exploration/num steps total              680000
exploration/num paths total                1840
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01464
exploration/Rewards Std                       1.33722
exploration/Rewards Max                      10.3115
exploration/Rewards Min                      -0.601743
exploration/Returns Mean                   5014.64
exploration/Returns Std                       0
exploration/Returns Max                    5014.64
exploration/Returns Min                    5014.64
exploration/Num Paths                         1
exploration/Average Returns                5014.64
evaluation_0/num steps total                  5.31752e+06
evaluation_0/num paths total              13472
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06171
evaluation_0/Rewards Std                      1.34946
evaluation_0/Rewards Max                     10.6651
evaluation_0/Rewards Min                     -0.48415
evaluation_0/Returns Mean                  5061.71
evaluation_0/Returns Std                     49.9294
evaluation_0/Returns Max                   5148.85
evaluation_0/Returns Min                   5009.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5061.71
time/epoch (s)                                0
time/total (s)                            12840.9
Epoch                                       675
---------------------------------------  ----------------
2022-11-16 14:20:02.986893 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 676 finished
---------------------------------------  ----------------
epoch                                       676
total_step                               681000
replay_pool/size                         681000
trainer/alpha                                 0.063334
trainer/alpha_loss                           -0.43508
trainer/entropy                              -5.84233
trainer/qf_loss                               8.19922
trainer/state_noise                           0.005
trainer/policy_loss                        -206.049
trainer/policy_loss_without_entropy         208.174
trainer/entropy_penalty                      -0.370018
trainer/entropy_percentage                   -0.00177744
trainer/Q1Pred Mean                         207.495
trainer/Q1Pred Std                           73.2386
trainer/Q1Pred Max                          308.283
trainer/Q1Pred Min                            8.05843
trainer/Q2Pred Mean                         207.688
trainer/Q2Pred Std                           72.9832
trainer/Q2Pred Max                          308.729
trainer/Q2Pred Min                           14.8535
trainer/QTargetWithReg Mean                 207.465
trainer/QTargetWithReg Std                   73.4318
trainer/QTargetWithReg Max                  307.843
trainer/QTargetWithReg Min                   18.1917
trainer/PolicyLossWithoutReg Mean           208.174
trainer/PolicyLossWithoutReg Std             72.5359
trainer/PolicyLossWithoutReg Max            308.345
trainer/PolicyLossWithoutReg Min             14.5641
trainer/gradient_norm                       350.972
trainer/gradient_penalty                     -1.75486
trainer/gradient_percentage                  -0.00842977
exploration/num steps total              681000
exploration/num paths total                1841
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00921
exploration/Rewards Std                       1.34687
exploration/Rewards Max                      10.3155
exploration/Rewards Min                      -0.48862
exploration/Returns Mean                   5009.21
exploration/Returns Std                       0
exploration/Returns Max                    5009.21
exploration/Returns Min                    5009.21
exploration/Num Paths                         1
exploration/Average Returns                5009.21
evaluation_0/num steps total                  5.32552e+06
evaluation_0/num paths total              13480
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.12758
evaluation_0/Rewards Std                      1.33747
evaluation_0/Rewards Max                     10.5757
evaluation_0/Rewards Min                     -0.530145
evaluation_0/Returns Mean                  5127.58
evaluation_0/Returns Std                     19.7593
evaluation_0/Returns Max                   5153.46
evaluation_0/Returns Min                   5087.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5127.58
time/epoch (s)                                0
time/total (s)                            12856.7
Epoch                                       676
---------------------------------------  ----------------
2022-11-16 14:20:19.557055 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 677 finished
---------------------------------------  ----------------
epoch                                       677
total_step                               682000
replay_pool/size                         682000
trainer/alpha                                 0.0641183
trainer/alpha_loss                           -0.397875
trainer/entropy                              -5.85516
trainer/qf_loss                               5.275
trainer/state_noise                           0.005
trainer/policy_loss                        -218.368
trainer/policy_loss_without_entropy         220.509
trainer/entropy_penalty                      -0.375423
trainer/entropy_percentage                   -0.00170253
trainer/Q1Pred Mean                         220.133
trainer/Q1Pred Std                           73.3735
trainer/Q1Pred Max                          305.551
trainer/Q1Pred Min                          -14.1067
trainer/Q2Pred Mean                         219.451
trainer/Q2Pred Std                           73.0755
trainer/Q2Pred Max                          303.604
trainer/Q2Pred Min                           -7.42728
trainer/QTargetWithReg Mean                 220.007
trainer/QTargetWithReg Std                   73.0529
trainer/QTargetWithReg Max                  305.235
trainer/QTargetWithReg Min                   -1.98982
trainer/PolicyLossWithoutReg Mean           220.509
trainer/PolicyLossWithoutReg Std             71.5458
trainer/PolicyLossWithoutReg Max            303.323
trainer/PolicyLossWithoutReg Min              7.98614
trainer/gradient_norm                       353.054
trainer/gradient_penalty                     -1.76527
trainer/gradient_percentage                  -0.00800543
exploration/num steps total              682000
exploration/num paths total                1842
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01732
exploration/Rewards Std                       1.31324
exploration/Rewards Max                      10.5031
exploration/Rewards Min                      -0.448476
exploration/Returns Mean                   5017.32
exploration/Returns Std                       0
exploration/Returns Max                    5017.32
exploration/Returns Min                    5017.32
exploration/Num Paths                         1
exploration/Average Returns                5017.32
evaluation_0/num steps total                  5.33352e+06
evaluation_0/num paths total              13488
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01694
evaluation_0/Rewards Std                      1.33257
evaluation_0/Rewards Max                     10.53
evaluation_0/Rewards Min                     -0.548781
evaluation_0/Returns Mean                  5016.94
evaluation_0/Returns Std                     22.5039
evaluation_0/Returns Max                   5050.98
evaluation_0/Returns Min                   4980.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5016.94
time/epoch (s)                                0
time/total (s)                            12873.3
Epoch                                       677
---------------------------------------  ----------------
2022-11-16 14:20:35.412592 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 678 finished
---------------------------------------  ----------------
epoch                                       678
total_step                               683000
replay_pool/size                         683000
trainer/alpha                                 0.0644037
trainer/alpha_loss                           -0.0982003
trainer/entropy                              -5.96419
trainer/qf_loss                              18.094
trainer/state_noise                           0.005
trainer/policy_loss                        -219.569
trainer/policy_loss_without_entropy         221.71
trainer/entropy_penalty                      -0.384116
trainer/entropy_percentage                   -0.00173252
trainer/Q1Pred Mean                         220.745
trainer/Q1Pred Std                           70.5455
trainer/Q1Pred Max                          307.753
trainer/Q1Pred Min                            7.36886
trainer/Q2Pred Mean                         220.912
trainer/Q2Pred Std                           70.6271
trainer/Q2Pred Max                          308.04
trainer/Q2Pred Min                            9.14835
trainer/QTargetWithReg Mean                 221.293
trainer/QTargetWithReg Std                   71.0109
trainer/QTargetWithReg Max                  309.011
trainer/QTargetWithReg Min                    8.50347
trainer/PolicyLossWithoutReg Mean           221.71
trainer/PolicyLossWithoutReg Std             69.8971
trainer/PolicyLossWithoutReg Max            306.899
trainer/PolicyLossWithoutReg Min              8.59025
trainer/gradient_norm                       351.282
trainer/gradient_penalty                     -1.75641
trainer/gradient_percentage                  -0.0079221
exploration/num steps total              683000
exploration/num paths total                1843
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03708
exploration/Rewards Std                       1.34698
exploration/Rewards Max                      10.5907
exploration/Rewards Min                      -0.53886
exploration/Returns Mean                   5037.08
exploration/Returns Std                       0
exploration/Returns Max                    5037.08
exploration/Returns Min                    5037.08
exploration/Num Paths                         1
exploration/Average Returns                5037.08
evaluation_0/num steps total                  5.34152e+06
evaluation_0/num paths total              13496
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13049
evaluation_0/Rewards Std                      1.3561
evaluation_0/Rewards Max                     10.7694
evaluation_0/Rewards Min                     -0.463634
evaluation_0/Returns Mean                  5130.49
evaluation_0/Returns Std                     28.0491
evaluation_0/Returns Max                   5178.25
evaluation_0/Returns Min                   5093.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5130.49
time/epoch (s)                                0
time/total (s)                            12889.2
Epoch                                       678
---------------------------------------  ----------------
2022-11-16 14:20:51.751980 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 679 finished
---------------------------------------  ----------------
epoch                                       679
total_step                               684000
replay_pool/size                         684000
trainer/alpha                                 0.0622789
trainer/alpha_loss                            1.30976
trainer/entropy                              -6.47179
trainer/qf_loss                               7.00328
trainer/state_noise                           0.005
trainer/policy_loss                        -209.118
trainer/policy_loss_without_entropy         211.233
trainer/entropy_penalty                      -0.403056
trainer/entropy_percentage                   -0.00190811
trainer/Q1Pred Mean                         210.86
trainer/Q1Pred Std                           79.8457
trainer/Q1Pred Max                          316.206
trainer/Q1Pred Min                            3.91917
trainer/Q2Pred Mean                         210.685
trainer/Q2Pred Std                           79.8998
trainer/Q2Pred Max                          315.29
trainer/Q2Pred Min                            4.29703
trainer/QTargetWithReg Mean                 210.6
trainer/QTargetWithReg Std                   79.2884
trainer/QTargetWithReg Max                  315.349
trainer/QTargetWithReg Min                    4.62607
trainer/PolicyLossWithoutReg Mean           211.233
trainer/PolicyLossWithoutReg Std             78.9637
trainer/PolicyLossWithoutReg Max            316.101
trainer/PolicyLossWithoutReg Min              4.82927
trainer/gradient_norm                       342.331
trainer/gradient_penalty                     -1.71166
trainer/gradient_percentage                  -0.00810316
exploration/num steps total              684000
exploration/num paths total                1844
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01584
exploration/Rewards Std                       1.35123
exploration/Rewards Max                      10.1599
exploration/Rewards Min                      -0.546414
exploration/Returns Mean                   5015.84
exploration/Returns Std                       0
exploration/Returns Max                    5015.84
exploration/Returns Min                    5015.84
exploration/Num Paths                         1
exploration/Average Returns                5015.84
evaluation_0/num steps total                  5.34952e+06
evaluation_0/num paths total              13504
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1354
evaluation_0/Rewards Std                      1.32742
evaluation_0/Rewards Max                     10.6897
evaluation_0/Rewards Min                     -0.393758
evaluation_0/Returns Mean                  5135.4
evaluation_0/Returns Std                     20.649
evaluation_0/Returns Max                   5166.58
evaluation_0/Returns Min                   5092.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5135.4
time/epoch (s)                                0
time/total (s)                            12905.5
Epoch                                       679
---------------------------------------  ----------------
2022-11-16 14:21:07.618591 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 680 finished
---------------------------------------  ----------------
epoch                                       680
total_step                               685000
replay_pool/size                         685000
trainer/alpha                                 0.0646173
trainer/alpha_loss                            0.42929
trainer/entropy                              -6.15671
trainer/qf_loss                               5.04425
trainer/state_noise                           0.005
trainer/policy_loss                        -220.107
trainer/policy_loss_without_entropy         222.219
trainer/entropy_penalty                      -0.39783
trainer/entropy_percentage                   -0.00179026
trainer/Q1Pred Mean                         221.391
trainer/Q1Pred Std                           70.534
trainer/Q1Pred Max                          308.48
trainer/Q1Pred Min                          -12.4602
trainer/Q2Pred Mean                         221.658
trainer/Q2Pred Std                           70.4454
trainer/Q2Pred Max                          310.956
trainer/Q2Pred Min                           -7.54602
trainer/QTargetWithReg Mean                 221.609
trainer/QTargetWithReg Std                   70.6455
trainer/QTargetWithReg Max                  308.827
trainer/QTargetWithReg Min                   -9.36557
trainer/PolicyLossWithoutReg Mean           222.219
trainer/PolicyLossWithoutReg Std             69.9102
trainer/PolicyLossWithoutReg Max            309.153
trainer/PolicyLossWithoutReg Min             -8.484
trainer/gradient_norm                       342.816
trainer/gradient_penalty                     -1.71408
trainer/gradient_percentage                  -0.00771348
exploration/num steps total              685000
exploration/num paths total                1845
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02146
exploration/Rewards Std                       1.31707
exploration/Rewards Max                      10.1859
exploration/Rewards Min                      -0.47495
exploration/Returns Mean                   5021.46
exploration/Returns Std                       0
exploration/Returns Max                    5021.46
exploration/Returns Min                    5021.46
exploration/Num Paths                         1
exploration/Average Returns                5021.46
evaluation_0/num steps total                  5.35752e+06
evaluation_0/num paths total              13512
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9634
evaluation_0/Rewards Std                      1.31431
evaluation_0/Rewards Max                     10.4356
evaluation_0/Rewards Min                     -0.47185
evaluation_0/Returns Mean                  4963.4
evaluation_0/Returns Std                     29.0264
evaluation_0/Returns Max                   4993.89
evaluation_0/Returns Min                   4902.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4963.4
time/epoch (s)                                0
time/total (s)                            12921.4
Epoch                                       680
---------------------------------------  ----------------
2022-11-16 14:21:23.563796 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 681 finished
---------------------------------------  ----------------
epoch                                       681
total_step                               686000
replay_pool/size                         686000
trainer/alpha                                 0.061443
trainer/alpha_loss                            0.713358
trainer/entropy                              -6.2557
trainer/qf_loss                              10.3153
trainer/state_noise                           0.005
trainer/policy_loss                        -214.856
trainer/policy_loss_without_entropy         217.023
trainer/entropy_penalty                      -0.384369
trainer/entropy_percentage                   -0.0017711
trainer/Q1Pred Mean                         216.014
trainer/Q1Pred Std                           72.3573
trainer/Q1Pred Max                          315.503
trainer/Q1Pred Min                          -17.5562
trainer/Q2Pred Mean                         216.105
trainer/Q2Pred Std                           72.1867
trainer/Q2Pred Max                          314.02
trainer/Q2Pred Min                          -20.4405
trainer/QTargetWithReg Mean                 216.387
trainer/QTargetWithReg Std                   72.3856
trainer/QTargetWithReg Max                  314.083
trainer/QTargetWithReg Min                    1.14628
trainer/PolicyLossWithoutReg Mean           217.023
trainer/PolicyLossWithoutReg Std             71.2708
trainer/PolicyLossWithoutReg Max            314.428
trainer/PolicyLossWithoutReg Min              5.27368
trainer/gradient_norm                       356.41
trainer/gradient_penalty                     -1.78205
trainer/gradient_percentage                  -0.00821134
exploration/num steps total              686000
exploration/num paths total                1846
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04256
exploration/Rewards Std                       1.34265
exploration/Rewards Max                      10.4891
exploration/Rewards Min                      -0.458011
exploration/Returns Mean                   5042.56
exploration/Returns Std                       0
exploration/Returns Max                    5042.56
exploration/Returns Min                    5042.56
exploration/Num Paths                         1
exploration/Average Returns                5042.56
evaluation_0/num steps total                  5.36552e+06
evaluation_0/num paths total              13520
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07043
evaluation_0/Rewards Std                      1.33465
evaluation_0/Rewards Max                     10.6232
evaluation_0/Rewards Min                     -0.450902
evaluation_0/Returns Mean                  5070.43
evaluation_0/Returns Std                     28.9462
evaluation_0/Returns Max                   5107.03
evaluation_0/Returns Min                   5008.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5070.43
time/epoch (s)                                0
time/total (s)                            12937.3
Epoch                                       681
---------------------------------------  ----------------
2022-11-16 14:21:39.917105 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 682 finished
---------------------------------------  ----------------
epoch                                       682
total_step                               687000
replay_pool/size                         687000
trainer/alpha                                 0.0633419
trainer/alpha_loss                            0.17138
trainer/entropy                              -6.06211
trainer/qf_loss                               6.42434
trainer/state_noise                           0.005
trainer/policy_loss                        -212.795
trainer/policy_loss_without_entropy         214.918
trainer/entropy_penalty                      -0.383986
trainer/entropy_percentage                   -0.00178666
trainer/Q1Pred Mean                         214.69
trainer/Q1Pred Std                           74.2629
trainer/Q1Pred Max                          306.38
trainer/Q1Pred Min                            0.634469
trainer/Q2Pred Mean                         214.425
trainer/Q2Pred Std                           74.464
trainer/Q2Pred Max                          303.471
trainer/Q2Pred Min                            4.50967
trainer/QTargetWithReg Mean                 214.535
trainer/QTargetWithReg Std                   74.4935
trainer/QTargetWithReg Max                  306.541
trainer/QTargetWithReg Min                    3.36687
trainer/PolicyLossWithoutReg Mean           214.918
trainer/PolicyLossWithoutReg Std             73.4877
trainer/PolicyLossWithoutReg Max            304.532
trainer/PolicyLossWithoutReg Min              1.30764
trainer/gradient_norm                       347.767
trainer/gradient_penalty                     -1.73883
trainer/gradient_percentage                  -0.00809068
exploration/num steps total              687000
exploration/num paths total                1847
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08948
exploration/Rewards Std                       1.34172
exploration/Rewards Max                      10.5405
exploration/Rewards Min                      -0.3395
exploration/Returns Mean                   5089.48
exploration/Returns Std                       0
exploration/Returns Max                    5089.48
exploration/Returns Min                    5089.48
exploration/Num Paths                         1
exploration/Average Returns                5089.48
evaluation_0/num steps total                  5.37352e+06
evaluation_0/num paths total              13528
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11405
evaluation_0/Rewards Std                      1.31795
evaluation_0/Rewards Max                     10.4676
evaluation_0/Rewards Min                     -0.459631
evaluation_0/Returns Mean                  5114.05
evaluation_0/Returns Std                     23.5354
evaluation_0/Returns Max                   5135.37
evaluation_0/Returns Min                   5065.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5114.05
time/epoch (s)                                0
time/total (s)                            12953.7
Epoch                                       682
---------------------------------------  ----------------
2022-11-16 14:21:55.853103 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 683 finished
---------------------------------------  ----------------
epoch                                       683
total_step                               688000
replay_pool/size                         688000
trainer/alpha                                 0.0648233
trainer/alpha_loss                           -0.362092
trainer/entropy                              -5.86765
trainer/qf_loss                               5.89377
trainer/state_noise                           0.005
trainer/policy_loss                        -215.433
trainer/policy_loss_without_entropy         217.533
trainer/entropy_penalty                      -0.38036
trainer/entropy_percentage                   -0.00174852
trainer/Q1Pred Mean                         216.646
trainer/Q1Pred Std                           71.8229
trainer/Q1Pred Max                          312.337
trainer/Q1Pred Min                           13.4424
trainer/Q2Pred Mean                         217.003
trainer/Q2Pred Std                           71.7797
trainer/Q2Pred Max                          310.912
trainer/Q2Pred Min                           13.0633
trainer/QTargetWithReg Mean                 216.989
trainer/QTargetWithReg Std                   71.6114
trainer/QTargetWithReg Max                  312.641
trainer/QTargetWithReg Min                   15.7423
trainer/PolicyLossWithoutReg Mean           217.533
trainer/PolicyLossWithoutReg Std             70.8814
trainer/PolicyLossWithoutReg Max            311.282
trainer/PolicyLossWithoutReg Min             14.9882
trainer/gradient_norm                       343.937
trainer/gradient_penalty                     -1.71968
trainer/gradient_percentage                  -0.0079054
exploration/num steps total              688000
exploration/num paths total                1848
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96534
exploration/Rewards Std                       1.33917
exploration/Rewards Max                      10.621
exploration/Rewards Min                      -0.391385
exploration/Returns Mean                   4965.34
exploration/Returns Std                       0
exploration/Returns Max                    4965.34
exploration/Returns Min                    4965.34
exploration/Num Paths                         1
exploration/Average Returns                4965.34
evaluation_0/num steps total                  5.38152e+06
evaluation_0/num paths total              13536
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04487
evaluation_0/Rewards Std                      1.34263
evaluation_0/Rewards Max                     10.5433
evaluation_0/Rewards Min                     -0.430437
evaluation_0/Returns Mean                  5044.87
evaluation_0/Returns Std                     11.7418
evaluation_0/Returns Max                   5063.29
evaluation_0/Returns Min                   5030.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5044.87
time/epoch (s)                                0
time/total (s)                            12969.6
Epoch                                       683
---------------------------------------  ----------------
2022-11-16 14:22:12.233715 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 684 finished
---------------------------------------  ----------------
epoch                                       684
total_step                               689000
replay_pool/size                         689000
trainer/alpha                                 0.0649095
trainer/alpha_loss                            1.36945
trainer/entropy                              -6.50075
trainer/qf_loss                               9.15567
trainer/state_noise                           0.005
trainer/policy_loss                        -207.475
trainer/policy_loss_without_entropy         209.644
trainer/entropy_penalty                      -0.421961
trainer/entropy_percentage                   -0.00201275
trainer/Q1Pred Mean                         209.746
trainer/Q1Pred Std                           74.8769
trainer/Q1Pred Max                          308.162
trainer/Q1Pred Min                            5.42493
trainer/Q2Pred Mean                         209.689
trainer/Q2Pred Std                           74.7884
trainer/Q2Pred Max                          307.714
trainer/Q2Pred Min                            2.37037
trainer/QTargetWithReg Mean                 208.934
trainer/QTargetWithReg Std                   74.838
trainer/QTargetWithReg Max                  308.096
trainer/QTargetWithReg Min                    8.034
trainer/PolicyLossWithoutReg Mean           209.644
trainer/PolicyLossWithoutReg Std             73.9349
trainer/PolicyLossWithoutReg Max            306.175
trainer/PolicyLossWithoutReg Min              7.86854
trainer/gradient_norm                       349.24
trainer/gradient_penalty                     -1.7462
trainer/gradient_percentage                  -0.00832938
exploration/num steps total              689000
exploration/num paths total                1849
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09041
exploration/Rewards Std                       1.36303
exploration/Rewards Max                      10.7052
exploration/Rewards Min                      -0.41535
exploration/Returns Mean                   5090.41
exploration/Returns Std                       0
exploration/Returns Max                    5090.41
exploration/Returns Min                    5090.41
exploration/Num Paths                         1
exploration/Average Returns                5090.41
evaluation_0/num steps total                  5.38952e+06
evaluation_0/num paths total              13544
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11923
evaluation_0/Rewards Std                      1.32532
evaluation_0/Rewards Max                     10.7709
evaluation_0/Rewards Min                     -0.479897
evaluation_0/Returns Mean                  5119.23
evaluation_0/Returns Std                     25.1628
evaluation_0/Returns Max                   5157.26
evaluation_0/Returns Min                   5077.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5119.23
time/epoch (s)                                0
time/total (s)                            12986
Epoch                                       684
---------------------------------------  ----------------
2022-11-16 14:22:28.041025 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 685 finished
---------------------------------------  ----------------
epoch                                       685
total_step                               690000
replay_pool/size                         690000
trainer/alpha                                 0.0629516
trainer/alpha_loss                           -0.0145687
trainer/entropy                              -5.99473
trainer/qf_loss                               6.37188
trainer/state_noise                           0.005
trainer/policy_loss                        -222.302
trainer/policy_loss_without_entropy         224.443
trainer/entropy_penalty                      -0.377378
trainer/entropy_percentage                   -0.0016814
trainer/Q1Pred Mean                         224.064
trainer/Q1Pred Std                           69.2111
trainer/Q1Pred Max                          313.354
trainer/Q1Pred Min                            4.40089
trainer/Q2Pred Mean                         223.896
trainer/Q2Pred Std                           69.0622
trainer/Q2Pred Max                          314.174
trainer/Q2Pred Min                            0.612278
trainer/QTargetWithReg Mean                 223.824
trainer/QTargetWithReg Std                   69.142
trainer/QTargetWithReg Max                  316.31
trainer/QTargetWithReg Min                    3.4485
trainer/PolicyLossWithoutReg Mean           224.443
trainer/PolicyLossWithoutReg Std             68.2292
trainer/PolicyLossWithoutReg Max            312.949
trainer/PolicyLossWithoutReg Min              2.44621
trainer/gradient_norm                       352.793
trainer/gradient_penalty                     -1.76396
trainer/gradient_percentage                  -0.00785928
exploration/num steps total              690000
exploration/num paths total                1850
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04974
exploration/Rewards Std                       1.33851
exploration/Rewards Max                      10.5821
exploration/Rewards Min                      -0.445708
exploration/Returns Mean                   5049.74
exploration/Returns Std                       0
exploration/Returns Max                    5049.74
exploration/Returns Min                    5049.74
exploration/Num Paths                         1
exploration/Average Returns                5049.74
evaluation_0/num steps total                  5.39752e+06
evaluation_0/num paths total              13552
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13432
evaluation_0/Rewards Std                      1.35044
evaluation_0/Rewards Max                     10.8587
evaluation_0/Rewards Min                     -0.394945
evaluation_0/Returns Mean                  5134.32
evaluation_0/Returns Std                     15.2963
evaluation_0/Returns Max                   5158.46
evaluation_0/Returns Min                   5107.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5134.32
time/epoch (s)                                0
time/total (s)                            13001.8
Epoch                                       685
---------------------------------------  ----------------
2022-11-16 14:22:44.631519 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 686 finished
---------------------------------------  ----------------
epoch                                       686
total_step                               691000
replay_pool/size                         691000
trainer/alpha                                 0.0635508
trainer/alpha_loss                           -0.478747
trainer/entropy                              -5.82629
trainer/qf_loss                               8.34885
trainer/state_noise                           0.005
trainer/policy_loss                        -222.591
trainer/policy_loss_without_entropy         224.718
trainer/entropy_penalty                      -0.370265
trainer/entropy_percentage                   -0.00164769
trainer/Q1Pred Mean                         224.703
trainer/Q1Pred Std                           67.439
trainer/Q1Pred Max                          312.922
trainer/Q1Pred Min                            3.60376
trainer/Q2Pred Mean                         224.698
trainer/Q2Pred Std                           67.39
trainer/Q2Pred Max                          314.464
trainer/Q2Pred Min                            9.68192
trainer/QTargetWithReg Mean                 224.684
trainer/QTargetWithReg Std                   67.6277
trainer/QTargetWithReg Max                  315.235
trainer/QTargetWithReg Min                   -0.99841
trainer/PolicyLossWithoutReg Mean           224.718
trainer/PolicyLossWithoutReg Std             66.2138
trainer/PolicyLossWithoutReg Max            312.358
trainer/PolicyLossWithoutReg Min              9.81183
trainer/gradient_norm                       351.392
trainer/gradient_penalty                     -1.75696
trainer/gradient_percentage                  -0.0078185
exploration/num steps total              691000
exploration/num paths total                1851
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02986
exploration/Rewards Std                       1.33213
exploration/Rewards Max                      10.5512
exploration/Rewards Min                      -0.269964
exploration/Returns Mean                   5029.86
exploration/Returns Std                       0
exploration/Returns Max                    5029.86
exploration/Returns Min                    5029.86
exploration/Num Paths                         1
exploration/Average Returns                5029.86
evaluation_0/num steps total                  5.40552e+06
evaluation_0/num paths total              13560
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03496
evaluation_0/Rewards Std                      1.34301
evaluation_0/Rewards Max                     10.9174
evaluation_0/Rewards Min                     -0.522517
evaluation_0/Returns Mean                  5034.96
evaluation_0/Returns Std                     26.1843
evaluation_0/Returns Max                   5065.83
evaluation_0/Returns Min                   4984.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5034.96
time/epoch (s)                                0
time/total (s)                            13018.4
Epoch                                       686
---------------------------------------  ----------------
2022-11-16 14:23:00.452945 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 687 finished
---------------------------------------  ----------------
epoch                                       687
total_step                               692000
replay_pool/size                         692000
trainer/alpha                                 0.0641768
trainer/alpha_loss                           -0.202863
trainer/entropy                              -5.92613
trainer/qf_loss                               6.94426
trainer/state_noise                           0.005
trainer/policy_loss                        -212.371
trainer/policy_loss_without_entropy         214.544
trainer/entropy_penalty                      -0.38032
trainer/entropy_percentage                   -0.00177269
trainer/Q1Pred Mean                         215.123
trainer/Q1Pred Std                           77.3631
trainer/Q1Pred Max                          306.852
trainer/Q1Pred Min                            9.17688
trainer/Q2Pred Mean                         214.394
trainer/Q2Pred Std                           77.6721
trainer/Q2Pred Max                          307.113
trainer/Q2Pred Min                            6.14266
trainer/QTargetWithReg Mean                 214.126
trainer/QTargetWithReg Std                   77.5065
trainer/QTargetWithReg Max                  305.181
trainer/QTargetWithReg Min                    5.55439
trainer/PolicyLossWithoutReg Mean           214.544
trainer/PolicyLossWithoutReg Std             76.7787
trainer/PolicyLossWithoutReg Max            303.975
trainer/PolicyLossWithoutReg Min              6.50535
trainer/gradient_norm                       358.381
trainer/gradient_penalty                     -1.7919
trainer/gradient_percentage                  -0.00835217
exploration/num steps total              692000
exploration/num paths total                1852
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96864
exploration/Rewards Std                       1.35046
exploration/Rewards Max                      10.3974
exploration/Rewards Min                      -0.485336
exploration/Returns Mean                   4968.64
exploration/Returns Std                       0
exploration/Returns Max                    4968.64
exploration/Returns Min                    4968.64
exploration/Num Paths                         1
exploration/Average Returns                4968.64
evaluation_0/num steps total                  5.41352e+06
evaluation_0/num paths total              13568
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97611
evaluation_0/Rewards Std                      1.37413
evaluation_0/Rewards Max                     10.6183
evaluation_0/Rewards Min                     -0.533329
evaluation_0/Returns Mean                  4976.11
evaluation_0/Returns Std                     29.8683
evaluation_0/Returns Max                   5022
evaluation_0/Returns Min                   4943.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4976.11
time/epoch (s)                                0
time/total (s)                            13034.2
Epoch                                       687
---------------------------------------  ----------------
2022-11-16 14:23:16.840944 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 688 finished
---------------------------------------  ----------------
epoch                                       688
total_step                               693000
replay_pool/size                         693000
trainer/alpha                                 0.0632307
trainer/alpha_loss                           -0.191948
trainer/entropy                              -5.93047
trainer/qf_loss                               5.69125
trainer/state_noise                           0.005
trainer/policy_loss                        -218.444
trainer/policy_loss_without_entropy         220.515
trainer/entropy_penalty                      -0.374988
trainer/entropy_percentage                   -0.00170051
trainer/Q1Pred Mean                         219.999
trainer/Q1Pred Std                           73.5447
trainer/Q1Pred Max                          307.348
trainer/Q1Pred Min                           25.554
trainer/Q2Pred Mean                         219.885
trainer/Q2Pred Std                           73.0559
trainer/Q2Pred Max                          307.286
trainer/Q2Pred Min                           24.0675
trainer/QTargetWithReg Mean                 220.592
trainer/QTargetWithReg Std                   73.341
trainer/QTargetWithReg Max                  308.018
trainer/QTargetWithReg Min                   23.4616
trainer/PolicyLossWithoutReg Mean           220.515
trainer/PolicyLossWithoutReg Std             72.8582
trainer/PolicyLossWithoutReg Max            307.271
trainer/PolicyLossWithoutReg Min             25.1043
trainer/gradient_norm                       339.202
trainer/gradient_penalty                     -1.69601
trainer/gradient_percentage                  -0.00769113
exploration/num steps total              693000
exploration/num paths total                1853
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97887
exploration/Rewards Std                       1.41039
exploration/Rewards Max                      10.2954
exploration/Rewards Min                      -0.553237
exploration/Returns Mean                   4978.87
exploration/Returns Std                       0
exploration/Returns Max                    4978.87
exploration/Returns Min                    4978.87
exploration/Num Paths                         1
exploration/Average Returns                4978.87
evaluation_0/num steps total                  5.42152e+06
evaluation_0/num paths total              13576
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9829
evaluation_0/Rewards Std                      1.34299
evaluation_0/Rewards Max                     10.5567
evaluation_0/Rewards Min                     -0.543953
evaluation_0/Returns Mean                  4982.9
evaluation_0/Returns Std                     18.2695
evaluation_0/Returns Max                   5003.66
evaluation_0/Returns Min                   4952.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4982.9
time/epoch (s)                                0
time/total (s)                            13050.6
Epoch                                       688
---------------------------------------  ----------------
2022-11-16 14:23:32.682069 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 689 finished
---------------------------------------  ----------------
epoch                                       689
total_step                               694000
replay_pool/size                         694000
trainer/alpha                                 0.0624952
trainer/alpha_loss                           -0.49695
trainer/entropy                              -5.82076
trainer/qf_loss                               5.93147
trainer/state_noise                           0.005
trainer/policy_loss                        -214.858
trainer/policy_loss_without_entropy         216.917
trainer/entropy_penalty                      -0.36377
trainer/entropy_percentage                   -0.001677
trainer/Q1Pred Mean                         216.106
trainer/Q1Pred Std                           71.9527
trainer/Q1Pred Max                          302.173
trainer/Q1Pred Min                           -4.3358
trainer/Q2Pred Mean                         215.993
trainer/Q2Pred Std                           72.1554
trainer/Q2Pred Max                          301.854
trainer/Q2Pred Min                           -1.16284
trainer/QTargetWithReg Mean                 216.123
trainer/QTargetWithReg Std                   71.9539
trainer/QTargetWithReg Max                  302.673
trainer/QTargetWithReg Min                   -3.36446
trainer/PolicyLossWithoutReg Mean           216.917
trainer/PolicyLossWithoutReg Std             71.5063
trainer/PolicyLossWithoutReg Max            301.83
trainer/PolicyLossWithoutReg Min             -4.25856
trainer/gradient_norm                       339.005
trainer/gradient_penalty                     -1.69503
trainer/gradient_percentage                  -0.00781418
exploration/num steps total              694000
exploration/num paths total                1854
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98242
exploration/Rewards Std                       1.30101
exploration/Rewards Max                      10.3949
exploration/Rewards Min                      -0.414074
exploration/Returns Mean                   4982.42
exploration/Returns Std                       0
exploration/Returns Max                    4982.42
exploration/Returns Min                    4982.42
exploration/Num Paths                         1
exploration/Average Returns                4982.42
evaluation_0/num steps total                  5.42952e+06
evaluation_0/num paths total              13584
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03577
evaluation_0/Rewards Std                      1.31723
evaluation_0/Rewards Max                     10.6463
evaluation_0/Rewards Min                     -0.429809
evaluation_0/Returns Mean                  5035.77
evaluation_0/Returns Std                     54.2213
evaluation_0/Returns Max                   5107.54
evaluation_0/Returns Min                   4967.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5035.77
time/epoch (s)                                0
time/total (s)                            13066.4
Epoch                                       689
---------------------------------------  ----------------
2022-11-16 14:23:48.507009 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 690 finished
---------------------------------------  ----------------
epoch                                       690
total_step                               695000
replay_pool/size                         695000
trainer/alpha                                 0.0634662
trainer/alpha_loss                           -0.985755
trainer/entropy                              -5.64248
trainer/qf_loss                               7.66529
trainer/state_noise                           0.005
trainer/policy_loss                        -214.431
trainer/policy_loss_without_entropy         216.499
trainer/entropy_penalty                      -0.358107
trainer/entropy_percentage                   -0.00165408
trainer/Q1Pred Mean                         215.627
trainer/Q1Pred Std                           72.6695
trainer/Q1Pred Max                          313.974
trainer/Q1Pred Min                           -6.74336
trainer/Q2Pred Mean                         215.672
trainer/Q2Pred Std                           72.8527
trainer/Q2Pred Max                          313.787
trainer/Q2Pred Min                            3.85545
trainer/QTargetWithReg Mean                 216.507
trainer/QTargetWithReg Std                   72.959
trainer/QTargetWithReg Max                  313.94
trainer/QTargetWithReg Min                   -0.907561
trainer/PolicyLossWithoutReg Mean           216.499
trainer/PolicyLossWithoutReg Std             72.2329
trainer/PolicyLossWithoutReg Max            314.184
trainer/PolicyLossWithoutReg Min              3.10856
trainer/gradient_norm                       341.946
trainer/gradient_penalty                     -1.70973
trainer/gradient_percentage                  -0.00789717
exploration/num steps total              695000
exploration/num paths total                1855
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94916
exploration/Rewards Std                       1.32384
exploration/Rewards Max                      10.8471
exploration/Rewards Min                      -0.464476
exploration/Returns Mean                   4949.16
exploration/Returns Std                       0
exploration/Returns Max                    4949.16
exploration/Returns Min                    4949.16
exploration/Num Paths                         1
exploration/Average Returns                4949.16
evaluation_0/num steps total                  5.43752e+06
evaluation_0/num paths total              13592
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01409
evaluation_0/Rewards Std                      1.29653
evaluation_0/Rewards Max                     10.783
evaluation_0/Rewards Min                     -0.418176
evaluation_0/Returns Mean                  5014.09
evaluation_0/Returns Std                     51.1399
evaluation_0/Returns Max                   5078.77
evaluation_0/Returns Min                   4917.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5014.09
time/epoch (s)                                0
time/total (s)                            13082.3
Epoch                                       690
---------------------------------------  ----------------
2022-11-16 14:24:05.001306 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 691 finished
---------------------------------------  ----------------
epoch                                       691
total_step                               696000
replay_pool/size                         696000
trainer/alpha                                 0.0614608
trainer/alpha_loss                           -0.364427
trainer/entropy                              -5.86936
trainer/qf_loss                               6.6163
trainer/state_noise                           0.005
trainer/policy_loss                        -214.31
trainer/policy_loss_without_entropy         216.394
trainer/entropy_penalty                      -0.360735
trainer/entropy_percentage                   -0.00166703
trainer/Q1Pred Mean                         215.474
trainer/Q1Pred Std                           73.5529
trainer/Q1Pred Max                          305.331
trainer/Q1Pred Min                          -25.6014
trainer/Q2Pred Mean                         215.659
trainer/Q2Pred Std                           73.5401
trainer/Q2Pred Max                          304.64
trainer/Q2Pred Min                          -12.6225
trainer/QTargetWithReg Mean                 215.965
trainer/QTargetWithReg Std                   73.8813
trainer/QTargetWithReg Max                  305.202
trainer/QTargetWithReg Min                  -27.9246
trainer/PolicyLossWithoutReg Mean           216.394
trainer/PolicyLossWithoutReg Std             72.499
trainer/PolicyLossWithoutReg Max            304.302
trainer/PolicyLossWithoutReg Min             -7.23674
trainer/gradient_norm                       344.711
trainer/gradient_penalty                     -1.72355
trainer/gradient_percentage                  -0.00796488
exploration/num steps total              696000
exploration/num paths total                1856
exploration/path length this epoch Mean     976
exploration/path length this epoch Std        0
exploration/path length this epoch Max      976
exploration/path length this epoch Min      976
exploration/Rewards Mean                      5.06699
exploration/Rewards Std                       1.36257
exploration/Rewards Max                      10.4363
exploration/Rewards Min                      -0.423118
exploration/Returns Mean                   4945.38
exploration/Returns Std                       0
exploration/Returns Max                    4945.38
exploration/Returns Min                    4945.38
exploration/Num Paths                         1
exploration/Average Returns                4945.38
evaluation_0/num steps total                  5.44552e+06
evaluation_0/num paths total              13600
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98379
evaluation_0/Rewards Std                      1.29345
evaluation_0/Rewards Max                     10.3961
evaluation_0/Rewards Min                     -0.481347
evaluation_0/Returns Mean                  4983.79
evaluation_0/Returns Std                     18.1856
evaluation_0/Returns Max                   5018.34
evaluation_0/Returns Min                   4958.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4983.79
time/epoch (s)                                0
time/total (s)                            13098.8
Epoch                                       691
---------------------------------------  ----------------
2022-11-16 14:24:20.798421 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 692 finished
---------------------------------------  ----------------
epoch                                       692
total_step                               697000
replay_pool/size                         697000
trainer/alpha                                 0.0624311
trainer/alpha_loss                           -0.441965
trainer/entropy                              -5.84065
trainer/qf_loss                               5.2652
trainer/state_noise                           0.005
trainer/policy_loss                        -224.051
trainer/policy_loss_without_entropy         226.16
trainer/entropy_penalty                      -0.364638
trainer/entropy_percentage                   -0.0016123
trainer/Q1Pred Mean                         226.502
trainer/Q1Pred Std                           67.3419
trainer/Q1Pred Max                          311.323
trainer/Q1Pred Min                           24.3807
trainer/Q2Pred Mean                         226.348
trainer/Q2Pred Std                           67.6207
trainer/Q2Pred Max                          310.312
trainer/Q2Pred Min                           24.2927
trainer/QTargetWithReg Mean                 226.282
trainer/QTargetWithReg Std                   67.4234
trainer/QTargetWithReg Max                  309.917
trainer/QTargetWithReg Min                   24.1004
trainer/PolicyLossWithoutReg Mean           226.16
trainer/PolicyLossWithoutReg Std             66.6091
trainer/PolicyLossWithoutReg Max            309.788
trainer/PolicyLossWithoutReg Min             24.3723
trainer/gradient_norm                       348.972
trainer/gradient_penalty                     -1.74486
trainer/gradient_percentage                  -0.00771514
exploration/num steps total              697000
exploration/num paths total                1857
exploration/path length this epoch Mean     477
exploration/path length this epoch Std        0
exploration/path length this epoch Max      477
exploration/path length this epoch Min      477
exploration/Rewards Mean                      4.54748
exploration/Rewards Std                       1.43135
exploration/Rewards Max                      10.1734
exploration/Rewards Min                      -0.509192
exploration/Returns Mean                   2169.15
exploration/Returns Std                       0
exploration/Returns Max                    2169.15
exploration/Returns Min                    2169.15
exploration/Num Paths                         1
exploration/Average Returns                2169.15
evaluation_0/num steps total                  5.45352e+06
evaluation_0/num paths total              13608
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90684
evaluation_0/Rewards Std                      1.29992
evaluation_0/Rewards Max                     10.5524
evaluation_0/Rewards Min                     -0.456401
evaluation_0/Returns Mean                  4906.84
evaluation_0/Returns Std                     33.0317
evaluation_0/Returns Max                   4967.72
evaluation_0/Returns Min                   4855.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4906.84
time/epoch (s)                                0
time/total (s)                            13114.5
Epoch                                       692
---------------------------------------  ----------------
2022-11-16 14:24:37.268995 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 693 finished
---------------------------------------  ----------------
epoch                                       693
total_step                               698000
replay_pool/size                         698000
trainer/alpha                                 0.064881
trainer/alpha_loss                           -0.648567
trainer/entropy                              -5.76287
trainer/qf_loss                               6.77095
trainer/state_noise                           0.005
trainer/policy_loss                        -218.351
trainer/policy_loss_without_entropy         220.452
trainer/entropy_penalty                      -0.373901
trainer/entropy_percentage                   -0.00169607
trainer/Q1Pred Mean                         219.29
trainer/Q1Pred Std                           72.9147
trainer/Q1Pred Max                          307.01
trainer/Q1Pred Min                            9.22779
trainer/Q2Pred Mean                         219.374
trainer/Q2Pred Std                           72.8907
trainer/Q2Pred Max                          306.193
trainer/Q2Pred Min                            9.1239
trainer/QTargetWithReg Mean                 219.315
trainer/QTargetWithReg Std                   72.4158
trainer/QTargetWithReg Max                  306.329
trainer/QTargetWithReg Min                   12.6117
trainer/PolicyLossWithoutReg Mean           220.452
trainer/PolicyLossWithoutReg Std             72.1047
trainer/PolicyLossWithoutReg Max            307.333
trainer/PolicyLossWithoutReg Min              9.96685
trainer/gradient_norm                       345.322
trainer/gradient_penalty                     -1.72661
trainer/gradient_percentage                  -0.00783214
exploration/num steps total              698000
exploration/num paths total                1858
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04346
exploration/Rewards Std                       1.31705
exploration/Rewards Max                      10.2567
exploration/Rewards Min                      -0.425667
exploration/Returns Mean                   5043.46
exploration/Returns Std                       0
exploration/Returns Max                    5043.46
exploration/Returns Min                    5043.46
exploration/Num Paths                         1
exploration/Average Returns                5043.46
evaluation_0/num steps total                  5.46152e+06
evaluation_0/num paths total              13616
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04226
evaluation_0/Rewards Std                      1.30344
evaluation_0/Rewards Max                     10.5578
evaluation_0/Rewards Min                     -0.472413
evaluation_0/Returns Mean                  5042.26
evaluation_0/Returns Std                     29.1286
evaluation_0/Returns Max                   5102.93
evaluation_0/Returns Min                   5010.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5042.26
time/epoch (s)                                0
time/total (s)                            13131
Epoch                                       693
---------------------------------------  ----------------
2022-11-16 14:24:53.142089 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 694 finished
---------------------------------------  ----------------
epoch                                       694
total_step                               699000
replay_pool/size                         699000
trainer/alpha                                 0.0650023
trainer/alpha_loss                           -0.374041
trainer/entropy                              -5.86315
trainer/qf_loss                               7.59159
trainer/state_noise                           0.005
trainer/policy_loss                        -216.427
trainer/policy_loss_without_entropy         218.551
trainer/entropy_penalty                      -0.381119
trainer/entropy_percentage                   -0.00174384
trainer/Q1Pred Mean                         217.702
trainer/Q1Pred Std                           74.9504
trainer/Q1Pred Max                          310.209
trainer/Q1Pred Min                           20.9425
trainer/Q2Pred Mean                         217.713
trainer/Q2Pred Std                           75.2958
trainer/Q2Pred Max                          312.352
trainer/Q2Pred Min                           15.5432
trainer/QTargetWithReg Mean                 217.737
trainer/QTargetWithReg Std                   74.9556
trainer/QTargetWithReg Max                  311.37
trainer/QTargetWithReg Min                   20.0414
trainer/PolicyLossWithoutReg Mean           218.551
trainer/PolicyLossWithoutReg Std             74.72
trainer/PolicyLossWithoutReg Max            310.757
trainer/PolicyLossWithoutReg Min             16.629
trainer/gradient_norm                       348.73
trainer/gradient_penalty                     -1.74365
trainer/gradient_percentage                  -0.00797823
exploration/num steps total              699000
exploration/num paths total                1859
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03838
exploration/Rewards Std                       1.36142
exploration/Rewards Max                      10.4729
exploration/Rewards Min                      -0.482256
exploration/Returns Mean                   5038.38
exploration/Returns Std                       0
exploration/Returns Max                    5038.38
exploration/Returns Min                    5038.38
exploration/Num Paths                         1
exploration/Average Returns                5038.38
evaluation_0/num steps total                  5.46952e+06
evaluation_0/num paths total              13624
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1224
evaluation_0/Rewards Std                      1.31192
evaluation_0/Rewards Max                     10.7899
evaluation_0/Rewards Min                     -0.483193
evaluation_0/Returns Mean                  5122.4
evaluation_0/Returns Std                     24.3078
evaluation_0/Returns Max                   5156.2
evaluation_0/Returns Min                   5068.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5122.4
time/epoch (s)                                0
time/total (s)                            13146.9
Epoch                                       694
---------------------------------------  ----------------
2022-11-16 14:25:09.555955 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 695 finished
---------------------------------------  ----------------
epoch                                       695
total_step                               700000
replay_pool/size                         700000
trainer/alpha                                 0.0626764
trainer/alpha_loss                            1.75652
trainer/entropy                              -6.63412
trainer/qf_loss                               9.54798
trainer/state_noise                           0.005
trainer/policy_loss                        -216.642
trainer/policy_loss_without_entropy         218.768
trainer/entropy_penalty                      -0.415803
trainer/entropy_percentage                   -0.00190065
trainer/Q1Pred Mean                         218.123
trainer/Q1Pred Std                           70.7239
trainer/Q1Pred Max                          308.851
trainer/Q1Pred Min                           -4.48633
trainer/Q2Pred Mean                         217.745
trainer/Q2Pred Std                           70.6465
trainer/Q2Pred Max                          307.028
trainer/Q2Pred Min                           -6.80002
trainer/QTargetWithReg Mean                 217.757
trainer/QTargetWithReg Std                   70.563
trainer/QTargetWithReg Max                  308.551
trainer/QTargetWithReg Min                   -0.243142
trainer/PolicyLossWithoutReg Mean           218.768
trainer/PolicyLossWithoutReg Std             69.8642
trainer/PolicyLossWithoutReg Max            307.089
trainer/PolicyLossWithoutReg Min            -10.51
trainer/gradient_norm                       342.104
trainer/gradient_penalty                     -1.71052
trainer/gradient_percentage                  -0.00781886
exploration/num steps total              700000
exploration/num paths total                1860
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91046
exploration/Rewards Std                       1.31997
exploration/Rewards Max                      10.5271
exploration/Rewards Min                      -0.5238
exploration/Returns Mean                   4910.46
exploration/Returns Std                       0
exploration/Returns Max                    4910.46
exploration/Returns Min                    4910.46
exploration/Num Paths                         1
exploration/Average Returns                4910.46
evaluation_0/num steps total                  5.47752e+06
evaluation_0/num paths total              13632
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08652
evaluation_0/Rewards Std                      1.27426
evaluation_0/Rewards Max                     10.437
evaluation_0/Rewards Min                     -0.474089
evaluation_0/Returns Mean                  5086.52
evaluation_0/Returns Std                     14.6415
evaluation_0/Returns Max                   5122.95
evaluation_0/Returns Min                   5074.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5086.52
time/epoch (s)                                0
time/total (s)                            13163.3
Epoch                                       695
---------------------------------------  ----------------
2022-11-16 14:25:25.411990 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 696 finished
---------------------------------------  ----------------
epoch                                       696
total_step                               701000
replay_pool/size                         701000
trainer/alpha                                 0.0639514
trainer/alpha_loss                            0.0165564
trainer/entropy                              -6.00602
trainer/qf_loss                               6.31958
trainer/state_noise                           0.005
trainer/policy_loss                        -220.758
trainer/policy_loss_without_entropy         222.865
trainer/entropy_penalty                      -0.384093
trainer/entropy_percentage                   -0.00172343
trainer/Q1Pred Mean                         221.799
trainer/Q1Pred Std                           73.8821
trainer/Q1Pred Max                          309.384
trainer/Q1Pred Min                           11.1678
trainer/Q2Pred Mean                         221.649
trainer/Q2Pred Std                           73.9706
trainer/Q2Pred Max                          309.681
trainer/Q2Pred Min                            8.42338
trainer/QTargetWithReg Mean                 220.908
trainer/QTargetWithReg Std                   73.4986
trainer/QTargetWithReg Max                  308.618
trainer/QTargetWithReg Min                   15.9234
trainer/PolicyLossWithoutReg Mean           222.865
trainer/PolicyLossWithoutReg Std             71.998
trainer/PolicyLossWithoutReg Max            308.748
trainer/PolicyLossWithoutReg Min             28.746
trainer/gradient_norm                       344.588
trainer/gradient_penalty                     -1.72294
trainer/gradient_percentage                  -0.00773087
exploration/num steps total              701000
exploration/num paths total                1861
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04019
exploration/Rewards Std                       1.31793
exploration/Rewards Max                      10.3163
exploration/Rewards Min                      -0.377325
exploration/Returns Mean                   5040.19
exploration/Returns Std                       0
exploration/Returns Max                    5040.19
exploration/Returns Min                    5040.19
exploration/Num Paths                         1
exploration/Average Returns                5040.19
evaluation_0/num steps total                  5.48552e+06
evaluation_0/num paths total              13640
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97313
evaluation_0/Rewards Std                      1.29648
evaluation_0/Rewards Max                     10.4411
evaluation_0/Rewards Min                     -0.54256
evaluation_0/Returns Mean                  4973.13
evaluation_0/Returns Std                     13.5745
evaluation_0/Returns Max                   4999.76
evaluation_0/Returns Min                   4952.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4973.13
time/epoch (s)                                0
time/total (s)                            13179.2
Epoch                                       696
---------------------------------------  ----------------
2022-11-16 14:25:41.703162 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 697 finished
---------------------------------------  ----------------
epoch                                       697
total_step                               702000
replay_pool/size                         702000
trainer/alpha                                 0.0636367
trainer/alpha_loss                           -1.18267
trainer/entropy                              -5.57064
trainer/qf_loss                               8.10796
trainer/state_noise                           0.005
trainer/policy_loss                        -214.528
trainer/policy_loss_without_entropy         216.611
trainer/entropy_penalty                      -0.354497
trainer/entropy_percentage                   -0.00163656
trainer/Q1Pred Mean                         216.119
trainer/Q1Pred Std                           73.5307
trainer/Q1Pred Max                          318.384
trainer/Q1Pred Min                            1.43699
trainer/Q2Pred Mean                         216.324
trainer/Q2Pred Std                           73.305
trainer/Q2Pred Max                          318.68
trainer/Q2Pred Min                           -0.762578
trainer/QTargetWithReg Mean                 215.874
trainer/QTargetWithReg Std                   73.5197
trainer/QTargetWithReg Max                  317.343
trainer/QTargetWithReg Min                    2.09615
trainer/PolicyLossWithoutReg Mean           216.611
trainer/PolicyLossWithoutReg Std             72.4259
trainer/PolicyLossWithoutReg Max            318.215
trainer/PolicyLossWithoutReg Min              1.84256
trainer/gradient_norm                       345.854
trainer/gradient_penalty                     -1.72927
trainer/gradient_percentage                  -0.00798328
exploration/num steps total              702000
exploration/num paths total                1862
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01448
exploration/Rewards Std                       1.32835
exploration/Rewards Max                      10.1266
exploration/Rewards Min                      -0.540799
exploration/Returns Mean                   5014.48
exploration/Returns Std                       0
exploration/Returns Max                    5014.48
exploration/Returns Min                    5014.48
exploration/Num Paths                         1
exploration/Average Returns                5014.48
evaluation_0/num steps total                  5.49352e+06
evaluation_0/num paths total              13648
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02829
evaluation_0/Rewards Std                      1.35284
evaluation_0/Rewards Max                     10.7575
evaluation_0/Rewards Min                     -0.444678
evaluation_0/Returns Mean                  5028.29
evaluation_0/Returns Std                     72.6317
evaluation_0/Returns Max                   5103.88
evaluation_0/Returns Min                   4890.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5028.29
time/epoch (s)                                0
time/total (s)                            13195.5
Epoch                                       697
---------------------------------------  ----------------
2022-11-16 14:25:57.787029 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 698 finished
---------------------------------------  ----------------
epoch                                       698
total_step                               703000
replay_pool/size                         703000
trainer/alpha                                 0.0633907
trainer/alpha_loss                            0.445888
trainer/entropy                              -6.16164
trainer/qf_loss                               5.48927
trainer/state_noise                           0.005
trainer/policy_loss                        -222.888
trainer/policy_loss_without_entropy         224.995
trainer/entropy_penalty                      -0.390591
trainer/entropy_percentage                   -0.001736
trainer/Q1Pred Mean                         223.771
trainer/Q1Pred Std                           68.7111
trainer/Q1Pred Max                          308.51
trainer/Q1Pred Min                           -2.0896
trainer/Q2Pred Mean                         223.668
trainer/Q2Pred Std                           68.6971
trainer/Q2Pred Max                          308.111
trainer/Q2Pred Min                            0.722125
trainer/QTargetWithReg Mean                 224.273
trainer/QTargetWithReg Std                   68.56
trainer/QTargetWithReg Max                  308.001
trainer/QTargetWithReg Min                    1.71335
trainer/PolicyLossWithoutReg Mean           224.995
trainer/PolicyLossWithoutReg Std             67.7945
trainer/PolicyLossWithoutReg Max            309.215
trainer/PolicyLossWithoutReg Min              3.80161
trainer/gradient_norm                       343.159
trainer/gradient_penalty                     -1.7158
trainer/gradient_percentage                  -0.00762593
exploration/num steps total              703000
exploration/num paths total                1863
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99698
exploration/Rewards Std                       1.33616
exploration/Rewards Max                      10.6559
exploration/Rewards Min                      -0.497097
exploration/Returns Mean                   4996.98
exploration/Returns Std                       0
exploration/Returns Max                    4996.98
exploration/Returns Min                    4996.98
exploration/Num Paths                         1
exploration/Average Returns                4996.98
evaluation_0/num steps total                  5.50152e+06
evaluation_0/num paths total              13656
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88022
evaluation_0/Rewards Std                      1.32563
evaluation_0/Rewards Max                     10.5339
evaluation_0/Rewards Min                     -0.443455
evaluation_0/Returns Mean                  4880.22
evaluation_0/Returns Std                     44.9744
evaluation_0/Returns Max                   4943.46
evaluation_0/Returns Min                   4824.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4880.22
time/epoch (s)                                0
time/total (s)                            13211.5
Epoch                                       698
---------------------------------------  ----------------
2022-11-16 14:26:13.775079 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 699 finished
---------------------------------------  ----------------
epoch                                       699
total_step                               704000
replay_pool/size                         704000
trainer/alpha                                 0.0632398
trainer/alpha_loss                           -0.333732
trainer/entropy                              -5.87911
trainer/qf_loss                              11.2021
trainer/state_noise                           0.005
trainer/policy_loss                        -218.32
trainer/policy_loss_without_entropy         220.375
trainer/entropy_penalty                      -0.371794
trainer/entropy_percentage                   -0.00168709
trainer/Q1Pred Mean                         220.475
trainer/Q1Pred Std                           72.6991
trainer/Q1Pred Max                          311.236
trainer/Q1Pred Min                           -6.18306
trainer/Q2Pred Mean                         219.934
trainer/Q2Pred Std                           72.6011
trainer/Q2Pred Max                          310.61
trainer/Q2Pred Min                           -7.00626
trainer/QTargetWithReg Mean                 220.345
trainer/QTargetWithReg Std                   72.3599
trainer/QTargetWithReg Max                  310.021
trainer/QTargetWithReg Min                   -0.6238
trainer/PolicyLossWithoutReg Mean           220.375
trainer/PolicyLossWithoutReg Std             71.6198
trainer/PolicyLossWithoutReg Max            310.516
trainer/PolicyLossWithoutReg Min             -1.24231
trainer/gradient_norm                       336.675
trainer/gradient_penalty                     -1.68338
trainer/gradient_percentage                  -0.00763868
exploration/num steps total              704000
exploration/num paths total                1864
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01501
exploration/Rewards Std                       1.31488
exploration/Rewards Max                      10.3129
exploration/Rewards Min                      -0.312079
exploration/Returns Mean                   5015.01
exploration/Returns Std                       0
exploration/Returns Max                    5015.01
exploration/Returns Min                    5015.01
exploration/Num Paths                         1
exploration/Average Returns                5015.01
evaluation_0/num steps total                  5.50952e+06
evaluation_0/num paths total              13664
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88765
evaluation_0/Rewards Std                      1.33246
evaluation_0/Rewards Max                     10.6472
evaluation_0/Rewards Min                     -0.432992
evaluation_0/Returns Mean                  4887.65
evaluation_0/Returns Std                     37.7116
evaluation_0/Returns Max                   4942.36
evaluation_0/Returns Min                   4842.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4887.65
time/epoch (s)                                0
time/total (s)                            13227.5
Epoch                                       699
---------------------------------------  ----------------
2022-11-16 14:26:30.109735 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 700 finished
---------------------------------------  ----------------
epoch                                       700
total_step                               705000
replay_pool/size                         705000
trainer/alpha                                 0.0633638
trainer/alpha_loss                           -0.873273
trainer/entropy                              -5.68346
trainer/qf_loss                               8.24668
trainer/state_noise                           0.005
trainer/policy_loss                        -214.346
trainer/policy_loss_without_entropy         216.459
trainer/entropy_penalty                      -0.360125
trainer/entropy_percentage                   -0.00166371
trainer/Q1Pred Mean                         215.502
trainer/Q1Pred Std                           73.1107
trainer/Q1Pred Max                          306.22
trainer/Q1Pred Min                            0.651297
trainer/Q2Pred Mean                         215.724
trainer/Q2Pred Std                           73.2569
trainer/Q2Pred Max                          306.511
trainer/Q2Pred Min                            0.462092
trainer/QTargetWithReg Mean                 215.838
trainer/QTargetWithReg Std                   73.2567
trainer/QTargetWithReg Max                  308.399
trainer/QTargetWithReg Min                    3.18258
trainer/PolicyLossWithoutReg Mean           216.459
trainer/PolicyLossWithoutReg Std             72.7222
trainer/PolicyLossWithoutReg Max            306.578
trainer/PolicyLossWithoutReg Min              0.477605
trainer/gradient_norm                       350.461
trainer/gradient_penalty                     -1.7523
trainer/gradient_percentage                  -0.00809533
exploration/num steps total              705000
exploration/num paths total                1865
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03355
exploration/Rewards Std                       1.31383
exploration/Rewards Max                      10.1775
exploration/Rewards Min                      -0.498615
exploration/Returns Mean                   5033.55
exploration/Returns Std                       0
exploration/Returns Max                    5033.55
exploration/Returns Min                    5033.55
exploration/Num Paths                         1
exploration/Average Returns                5033.55
evaluation_0/num steps total                  5.51752e+06
evaluation_0/num paths total              13672
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97687
evaluation_0/Rewards Std                      1.302
evaluation_0/Rewards Max                     10.5942
evaluation_0/Rewards Min                     -0.457272
evaluation_0/Returns Mean                  4976.87
evaluation_0/Returns Std                     37.3909
evaluation_0/Returns Max                   5026.55
evaluation_0/Returns Min                   4921.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4976.87
time/epoch (s)                                0
time/total (s)                            13243.9
Epoch                                       700
---------------------------------------  ----------------
2022-11-16 14:26:45.923916 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 701 finished
---------------------------------------  ----------------
epoch                                       701
total_step                               706000
replay_pool/size                         706000
trainer/alpha                                 0.0640929
trainer/alpha_loss                            1.33792
trainer/entropy                              -6.48694
trainer/qf_loss                               8.37935
trainer/state_noise                           0.005
trainer/policy_loss                        -216.485
trainer/policy_loss_without_entropy         218.728
trainer/entropy_penalty                      -0.415767
trainer/entropy_percentage                   -0.00190084
trainer/Q1Pred Mean                         217.762
trainer/Q1Pred Std                           75.3348
trainer/Q1Pred Max                          306.832
trainer/Q1Pred Min                           -7.00475
trainer/Q2Pred Mean                         217.787
trainer/Q2Pred Std                           75.2604
trainer/Q2Pred Max                          306.724
trainer/Q2Pred Min                           -0.0411299
trainer/QTargetWithReg Mean                 217.58
trainer/QTargetWithReg Std                   75.4649
trainer/QTargetWithReg Max                  306.248
trainer/QTargetWithReg Min                   -3.9377
trainer/PolicyLossWithoutReg Mean           218.728
trainer/PolicyLossWithoutReg Std             74.1483
trainer/PolicyLossWithoutReg Max            306.991
trainer/PolicyLossWithoutReg Min             -0.768578
trainer/gradient_norm                       365.459
trainer/gradient_penalty                     -1.8273
trainer/gradient_percentage                  -0.00835419
exploration/num steps total              706000
exploration/num paths total                1866
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77182
exploration/Rewards Std                       1.28719
exploration/Rewards Max                      10.5714
exploration/Rewards Min                      -0.282005
exploration/Returns Mean                   4771.82
exploration/Returns Std                       0
exploration/Returns Max                    4771.82
exploration/Returns Min                    4771.82
exploration/Num Paths                         1
exploration/Average Returns                4771.82
evaluation_0/num steps total                  5.52552e+06
evaluation_0/num paths total              13680
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86498
evaluation_0/Rewards Std                      1.32354
evaluation_0/Rewards Max                     10.4456
evaluation_0/Rewards Min                     -0.476341
evaluation_0/Returns Mean                  4864.98
evaluation_0/Returns Std                     65.3733
evaluation_0/Returns Max                   4958.62
evaluation_0/Returns Min                   4713.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4864.98
time/epoch (s)                                0
time/total (s)                            13259.7
Epoch                                       701
---------------------------------------  ----------------
2022-11-16 14:27:02.332604 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 702 finished
---------------------------------------  ----------------
epoch                                       702
total_step                               707000
replay_pool/size                         707000
trainer/alpha                                 0.0627633
trainer/alpha_loss                            0.410272
trainer/entropy                              -6.1482
trainer/qf_loss                               7.99988
trainer/state_noise                           0.005
trainer/policy_loss                        -218.413
trainer/policy_loss_without_entropy         220.536
trainer/entropy_penalty                      -0.385881
trainer/entropy_percentage                   -0.00174974
trainer/Q1Pred Mean                         219.717
trainer/Q1Pred Std                           75.24
trainer/Q1Pred Max                          307.825
trainer/Q1Pred Min                            3.01533
trainer/Q2Pred Mean                         219.448
trainer/Q2Pred Std                           75.6822
trainer/Q2Pred Max                          307.102
trainer/Q2Pred Min                            1.95513
trainer/QTargetWithReg Mean                 219.84
trainer/QTargetWithReg Std                   75.6907
trainer/QTargetWithReg Max                  307.926
trainer/QTargetWithReg Min                    4.54845
trainer/PolicyLossWithoutReg Mean           220.536
trainer/PolicyLossWithoutReg Std             74.8747
trainer/PolicyLossWithoutReg Max            307.241
trainer/PolicyLossWithoutReg Min              2.10494
trainer/gradient_norm                       347.402
trainer/gradient_penalty                     -1.73701
trainer/gradient_percentage                  -0.00787632
exploration/num steps total              707000
exploration/num paths total                1867
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01929
exploration/Rewards Std                       1.33566
exploration/Rewards Max                      10.202
exploration/Rewards Min                      -0.357574
exploration/Returns Mean                   5019.29
exploration/Returns Std                       0
exploration/Returns Max                    5019.29
exploration/Returns Min                    5019.29
exploration/Num Paths                         1
exploration/Average Returns                5019.29
evaluation_0/num steps total                  5.53352e+06
evaluation_0/num paths total              13688
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94202
evaluation_0/Rewards Std                      1.31475
evaluation_0/Rewards Max                     10.5871
evaluation_0/Rewards Min                     -0.472752
evaluation_0/Returns Mean                  4942.02
evaluation_0/Returns Std                     60.5749
evaluation_0/Returns Max                   5050.54
evaluation_0/Returns Min                   4878.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4942.02
time/epoch (s)                                0
time/total (s)                            13276.1
Epoch                                       702
---------------------------------------  ----------------
2022-11-16 14:27:19.682842 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 703 finished
---------------------------------------  ----------------
epoch                                       703
total_step                               708000
replay_pool/size                         708000
trainer/alpha                                 0.0636682
trainer/alpha_loss                           -0.420231
trainer/entropy                              -5.84741
trainer/qf_loss                               7.09139
trainer/state_noise                           0.005
trainer/policy_loss                        -220.986
trainer/policy_loss_without_entropy         223.184
trainer/entropy_penalty                      -0.372294
trainer/entropy_percentage                   -0.0016681
trainer/Q1Pred Mean                         223.733
trainer/Q1Pred Std                           74.3547
trainer/Q1Pred Max                          307.055
trainer/Q1Pred Min                            2.07236
trainer/Q2Pred Mean                         223.433
trainer/Q2Pred Std                           74.523
trainer/Q2Pred Max                          306.511
trainer/Q2Pred Min                           -7.43182
trainer/QTargetWithReg Mean                 222.689
trainer/QTargetWithReg Std                   74.5935
trainer/QTargetWithReg Max                  307.503
trainer/QTargetWithReg Min                   -1.44327
trainer/PolicyLossWithoutReg Mean           223.184
trainer/PolicyLossWithoutReg Std             73.673
trainer/PolicyLossWithoutReg Max            305.647
trainer/PolicyLossWithoutReg Min             -0.872237
trainer/gradient_norm                       365.027
trainer/gradient_penalty                     -1.82513
trainer/gradient_percentage                  -0.00817771
exploration/num steps total              708000
exploration/num paths total                1868
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9977
exploration/Rewards Std                       1.30505
exploration/Rewards Max                      10.4533
exploration/Rewards Min                      -0.486028
exploration/Returns Mean                   4997.7
exploration/Returns Std                       0
exploration/Returns Max                    4997.7
exploration/Returns Min                    4997.7
exploration/Num Paths                         1
exploration/Average Returns                4997.7
evaluation_0/num steps total                  5.54146e+06
evaluation_0/num paths total              13696
evaluation_0/path length Mean               991.625
evaluation_0/path length Std                 22.1582
evaluation_0/path length Max               1000
evaluation_0/path length Min                933
evaluation_0/Rewards Mean                     4.86904
evaluation_0/Rewards Std                      1.39265
evaluation_0/Rewards Max                     10.6999
evaluation_0/Rewards Min                     -0.488909
evaluation_0/Returns Mean                  4828.26
evaluation_0/Returns Std                    267.867
evaluation_0/Returns Max                   5090.75
evaluation_0/Returns Min                   4363.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4828.26
time/epoch (s)                                0
time/total (s)                            13293.4
Epoch                                       703
---------------------------------------  ----------------
2022-11-16 14:27:35.768165 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 704 finished
---------------------------------------  ----------------
epoch                                       704
total_step                               709000
replay_pool/size                         709000
trainer/alpha                                 0.0641754
trainer/alpha_loss                           -0.847794
trainer/entropy                              -5.69127
trainer/qf_loss                               6.40659
trainer/state_noise                           0.005
trainer/policy_loss                        -216.682
trainer/policy_loss_without_entropy         218.813
trainer/entropy_penalty                      -0.365239
trainer/entropy_percentage                   -0.00166918
trainer/Q1Pred Mean                         218.671
trainer/Q1Pred Std                           71.8189
trainer/Q1Pred Max                          308.078
trainer/Q1Pred Min                            0.571522
trainer/Q2Pred Mean                         218.781
trainer/Q2Pred Std                           71.8633
trainer/Q2Pred Max                          306.612
trainer/Q2Pred Min                           -5.29811
trainer/QTargetWithReg Mean                 218.075
trainer/QTargetWithReg Std                   71.7897
trainer/QTargetWithReg Max                  307.681
trainer/QTargetWithReg Min                    0.219243
trainer/PolicyLossWithoutReg Mean           218.813
trainer/PolicyLossWithoutReg Std             71.1097
trainer/PolicyLossWithoutReg Max            306.546
trainer/PolicyLossWithoutReg Min            -11.6176
trainer/gradient_norm                       353.266
trainer/gradient_penalty                     -1.76633
trainer/gradient_percentage                  -0.00807232
exploration/num steps total              709000
exploration/num paths total                1869
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.77462
exploration/Rewards Std                       1.33083
exploration/Rewards Max                      10.358
exploration/Rewards Min                      -0.433268
exploration/Returns Mean                   4774.62
exploration/Returns Std                       0
exploration/Returns Max                    4774.62
exploration/Returns Min                    4774.62
exploration/Num Paths                         1
exploration/Average Returns                4774.62
evaluation_0/num steps total                  5.54946e+06
evaluation_0/num paths total              13704
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0295
evaluation_0/Rewards Std                      1.30672
evaluation_0/Rewards Max                     10.8565
evaluation_0/Rewards Min                     -0.460811
evaluation_0/Returns Mean                  5029.5
evaluation_0/Returns Std                     50.7715
evaluation_0/Returns Max                   5094.29
evaluation_0/Returns Min                   4954.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5029.5
time/epoch (s)                                0
time/total (s)                            13309.5
Epoch                                       704
---------------------------------------  ----------------
2022-11-16 14:27:51.801450 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 705 finished
---------------------------------------  ----------------
epoch                                       705
total_step                               710000
replay_pool/size                         710000
trainer/alpha                                 0.0625594
trainer/alpha_loss                            0.244522
trainer/entropy                              -6.08822
trainer/qf_loss                              13.8402
trainer/state_noise                           0.005
trainer/policy_loss                        -221.172
trainer/policy_loss_without_entropy         223.288
trainer/entropy_penalty                      -0.380875
trainer/entropy_percentage                   -0.00170576
trainer/Q1Pred Mean                         222.843
trainer/Q1Pred Std                           70.6341
trainer/Q1Pred Max                          305.648
trainer/Q1Pred Min                           -6.11559
trainer/Q2Pred Mean                         222.87
trainer/Q2Pred Std                           70.9915
trainer/Q2Pred Max                          304.911
trainer/Q2Pred Min                            0.899951
trainer/QTargetWithReg Mean                 222.824
trainer/QTargetWithReg Std                   70.902
trainer/QTargetWithReg Max                  305.786
trainer/QTargetWithReg Min                    3.92202
trainer/PolicyLossWithoutReg Mean           223.288
trainer/PolicyLossWithoutReg Std             70.2856
trainer/PolicyLossWithoutReg Max            305.04
trainer/PolicyLossWithoutReg Min             -3.88165
trainer/gradient_norm                       347.08
trainer/gradient_penalty                     -1.7354
trainer/gradient_percentage                  -0.00777203
exploration/num steps total              710000
exploration/num paths total                1870
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90755
exploration/Rewards Std                       1.31138
exploration/Rewards Max                      10.1533
exploration/Rewards Min                      -0.406702
exploration/Returns Mean                   4907.55
exploration/Returns Std                       0
exploration/Returns Max                    4907.55
exploration/Returns Min                    4907.55
exploration/Num Paths                         1
exploration/Average Returns                4907.55
evaluation_0/num steps total                  5.55746e+06
evaluation_0/num paths total              13712
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1271
evaluation_0/Rewards Std                      1.3001
evaluation_0/Rewards Max                     10.7686
evaluation_0/Rewards Min                     -0.452347
evaluation_0/Returns Mean                  5127.1
evaluation_0/Returns Std                     13.0997
evaluation_0/Returns Max                   5149.22
evaluation_0/Returns Min                   5105.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5127.1
time/epoch (s)                                0
time/total (s)                            13325.5
Epoch                                       705
---------------------------------------  ----------------
2022-11-16 14:28:07.594746 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 706 finished
---------------------------------------  ----------------
epoch                                       706
total_step                               711000
replay_pool/size                         711000
trainer/alpha                                 0.0629877
trainer/alpha_loss                            1.08649
trainer/entropy                              -6.39298
trainer/qf_loss                               6.88509
trainer/state_noise                           0.005
trainer/policy_loss                        -220.557
trainer/policy_loss_without_entropy         222.698
trainer/entropy_penalty                      -0.402679
trainer/entropy_percentage                   -0.00180819
trainer/Q1Pred Mean                         222.066
trainer/Q1Pred Std                           71.0027
trainer/Q1Pred Max                          304.971
trainer/Q1Pred Min                           -3.66609
trainer/Q2Pred Mean                         222.25
trainer/Q2Pred Std                           70.8111
trainer/Q2Pred Max                          304.433
trainer/Q2Pred Min                            3.29728
trainer/QTargetWithReg Mean                 222.143
trainer/QTargetWithReg Std                   71.1119
trainer/QTargetWithReg Max                  304.678
trainer/QTargetWithReg Min                    2.87959
trainer/PolicyLossWithoutReg Mean           222.698
trainer/PolicyLossWithoutReg Std             70.3916
trainer/PolicyLossWithoutReg Max            305.967
trainer/PolicyLossWithoutReg Min              0.14618
trainer/gradient_norm                       347.727
trainer/gradient_penalty                     -1.73863
trainer/gradient_percentage                  -0.00780714
exploration/num steps total              711000
exploration/num paths total                1871
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83593
exploration/Rewards Std                       1.29148
exploration/Rewards Max                      10.4544
exploration/Rewards Min                      -0.284568
exploration/Returns Mean                   4835.93
exploration/Returns Std                       0
exploration/Returns Max                    4835.93
exploration/Returns Min                    4835.93
exploration/Num Paths                         1
exploration/Average Returns                4835.93
evaluation_0/num steps total                  5.56546e+06
evaluation_0/num paths total              13720
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9395
evaluation_0/Rewards Std                      1.3063
evaluation_0/Rewards Max                     10.3445
evaluation_0/Rewards Min                     -0.504818
evaluation_0/Returns Mean                  4939.5
evaluation_0/Returns Std                     94.7438
evaluation_0/Returns Max                   5071.52
evaluation_0/Returns Min                   4726.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4939.5
time/epoch (s)                                0
time/total (s)                            13341.3
Epoch                                       706
---------------------------------------  ----------------
2022-11-16 14:28:24.200147 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 707 finished
---------------------------------------  ----------------
epoch                                       707
total_step                               712000
replay_pool/size                         712000
trainer/alpha                                 0.0641624
trainer/alpha_loss                            0.514193
trainer/entropy                              -6.18722
trainer/qf_loss                               6.24184
trainer/state_noise                           0.005
trainer/policy_loss                        -217.692
trainer/policy_loss_without_entropy         219.811
trainer/entropy_penalty                      -0.396987
trainer/entropy_percentage                   -0.00180604
trainer/Q1Pred Mean                         218.643
trainer/Q1Pred Std                           79.674
trainer/Q1Pred Max                          311.365
trainer/Q1Pred Min                          -11.934
trainer/Q2Pred Mean                         218.872
trainer/Q2Pred Std                           79.7994
trainer/Q2Pred Max                          314.698
trainer/Q2Pred Min                          -12.6782
trainer/QTargetWithReg Mean                 218.4
trainer/QTargetWithReg Std                   79.7747
trainer/QTargetWithReg Max                  313.482
trainer/QTargetWithReg Min                  -15.4003
trainer/PolicyLossWithoutReg Mean           219.811
trainer/PolicyLossWithoutReg Std             77.9973
trainer/PolicyLossWithoutReg Max            311.265
trainer/PolicyLossWithoutReg Min            -10.8511
trainer/gradient_norm                       344.298
trainer/gradient_penalty                     -1.72149
trainer/gradient_percentage                  -0.0078317
exploration/num steps total              712000
exploration/num paths total                1872
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88447
exploration/Rewards Std                       1.28697
exploration/Rewards Max                      10.2794
exploration/Rewards Min                      -0.48379
exploration/Returns Mean                   4884.47
exploration/Returns Std                       0
exploration/Returns Max                    4884.47
exploration/Returns Min                    4884.47
exploration/Num Paths                         1
exploration/Average Returns                4884.47
evaluation_0/num steps total                  5.57346e+06
evaluation_0/num paths total              13728
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98996
evaluation_0/Rewards Std                      1.32644
evaluation_0/Rewards Max                     10.6238
evaluation_0/Rewards Min                     -0.413434
evaluation_0/Returns Mean                  4989.96
evaluation_0/Returns Std                     59.4857
evaluation_0/Returns Max                   5043.44
evaluation_0/Returns Min                   4887.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4989.96
time/epoch (s)                                0
time/total (s)                            13357.9
Epoch                                       707
---------------------------------------  ----------------
2022-11-16 14:28:40.049778 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 708 finished
---------------------------------------  ----------------
epoch                                       708
total_step                               713000
replay_pool/size                         713000
trainer/alpha                                 0.0638948
trainer/alpha_loss                           -0.419934
trainer/entropy                              -5.84732
trainer/qf_loss                               9.7083
trainer/state_noise                           0.005
trainer/policy_loss                        -214.22
trainer/policy_loss_without_entropy         216.328
trainer/entropy_penalty                      -0.373614
trainer/entropy_percentage                   -0.00172707
trainer/Q1Pred Mean                         215.832
trainer/Q1Pred Std                           72.3793
trainer/Q1Pred Max                          309.35
trainer/Q1Pred Min                           12.5583
trainer/Q2Pred Mean                         215.98
trainer/Q2Pred Std                           72.453
trainer/Q2Pred Max                          309.061
trainer/Q2Pred Min                           13.9605
trainer/QTargetWithReg Mean                 215.417
trainer/QTargetWithReg Std                   72.422
trainer/QTargetWithReg Max                  308.782
trainer/QTargetWithReg Min                   15.1283
trainer/PolicyLossWithoutReg Mean           216.328
trainer/PolicyLossWithoutReg Std             71.6196
trainer/PolicyLossWithoutReg Max            308.577
trainer/PolicyLossWithoutReg Min             13.8307
trainer/gradient_norm                       346.859
trainer/gradient_penalty                     -1.73429
trainer/gradient_percentage                  -0.00801697
exploration/num steps total              713000
exploration/num paths total                1873
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95181
exploration/Rewards Std                       1.28784
exploration/Rewards Max                      10.1342
exploration/Rewards Min                      -0.357221
exploration/Returns Mean                   4951.81
exploration/Returns Std                       0
exploration/Returns Max                    4951.81
exploration/Returns Min                    4951.81
exploration/Num Paths                         1
exploration/Average Returns                4951.81
evaluation_0/num steps total                  5.58146e+06
evaluation_0/num paths total              13736
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00575
evaluation_0/Rewards Std                      1.2604
evaluation_0/Rewards Max                     10.2901
evaluation_0/Rewards Min                     -0.475878
evaluation_0/Returns Mean                  5005.75
evaluation_0/Returns Std                     40.5148
evaluation_0/Returns Max                   5056.75
evaluation_0/Returns Min                   4937.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5005.75
time/epoch (s)                                0
time/total (s)                            13373.8
Epoch                                       708
---------------------------------------  ----------------
2022-11-16 14:28:56.408373 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 709 finished
---------------------------------------  ----------------
epoch                                       709
total_step                               714000
replay_pool/size                         714000
trainer/alpha                                 0.0642019
trainer/alpha_loss                           -0.695497
trainer/entropy                              -5.74671
trainer/qf_loss                               5.39955
trainer/state_noise                           0.005
trainer/policy_loss                        -221.876
trainer/policy_loss_without_entropy         224.002
trainer/entropy_penalty                      -0.36895
trainer/entropy_percentage                   -0.00164708
trainer/Q1Pred Mean                         223.161
trainer/Q1Pred Std                           74.3773
trainer/Q1Pred Max                          300.928
trainer/Q1Pred Min                           -1.82724
trainer/Q2Pred Mean                         223.284
trainer/Q2Pred Std                           74.1893
trainer/Q2Pred Max                          302.727
trainer/Q2Pred Min                            0.909759
trainer/QTargetWithReg Mean                 223.104
trainer/QTargetWithReg Std                   74.2204
trainer/QTargetWithReg Max                  303.025
trainer/QTargetWithReg Min                   -8.88004
trainer/PolicyLossWithoutReg Mean           224.002
trainer/PolicyLossWithoutReg Std             73.3852
trainer/PolicyLossWithoutReg Max            302.256
trainer/PolicyLossWithoutReg Min              7.24962
trainer/gradient_norm                       351.296
trainer/gradient_penalty                     -1.75648
trainer/gradient_percentage                  -0.00784138
exploration/num steps total              714000
exploration/num paths total                1874
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87801
exploration/Rewards Std                       1.28167
exploration/Rewards Max                      10.2879
exploration/Rewards Min                      -0.397855
exploration/Returns Mean                   4878.01
exploration/Returns Std                       0
exploration/Returns Max                    4878.01
exploration/Returns Min                    4878.01
exploration/Num Paths                         1
exploration/Average Returns                4878.01
evaluation_0/num steps total                  5.58946e+06
evaluation_0/num paths total              13744
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8912
evaluation_0/Rewards Std                      1.26622
evaluation_0/Rewards Max                     10.2604
evaluation_0/Rewards Min                     -0.371918
evaluation_0/Returns Mean                  4891.2
evaluation_0/Returns Std                     38.9359
evaluation_0/Returns Max                   4960.43
evaluation_0/Returns Min                   4834.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4891.2
time/epoch (s)                                0
time/total (s)                            13390.2
Epoch                                       709
---------------------------------------  ----------------
2022-11-16 14:29:12.290418 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 710 finished
---------------------------------------  ----------------
epoch                                       710
total_step                               715000
replay_pool/size                         715000
trainer/alpha                                 0.0644205
trainer/alpha_loss                            0.696655
trainer/entropy                              -6.25403
trainer/qf_loss                               6.63523
trainer/state_noise                           0.005
trainer/policy_loss                        -217.678
trainer/policy_loss_without_entropy         219.789
trainer/entropy_penalty                      -0.402888
trainer/entropy_percentage                   -0.00183306
trainer/Q1Pred Mean                         218.883
trainer/Q1Pred Std                           72.5763
trainer/Q1Pred Max                          313.884
trainer/Q1Pred Min                           -9.16506
trainer/Q2Pred Mean                         218.618
trainer/Q2Pred Std                           72.4201
trainer/Q2Pred Max                          312.794
trainer/Q2Pred Min                           -0.846056
trainer/QTargetWithReg Mean                 219.248
trainer/QTargetWithReg Std                   72.6653
trainer/QTargetWithReg Max                  312.882
trainer/QTargetWithReg Min                   -7.20776
trainer/PolicyLossWithoutReg Mean           219.789
trainer/PolicyLossWithoutReg Std             71.6265
trainer/PolicyLossWithoutReg Max            312.288
trainer/PolicyLossWithoutReg Min             -1.55475
trainer/gradient_norm                       341.665
trainer/gradient_penalty                     -1.70833
trainer/gradient_percentage                  -0.00777257
exploration/num steps total              715000
exploration/num paths total                1875
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9988
exploration/Rewards Std                       1.29247
exploration/Rewards Max                      10.3617
exploration/Rewards Min                      -0.279552
exploration/Returns Mean                   4998.8
exploration/Returns Std                       0
exploration/Returns Max                    4998.8
exploration/Returns Min                    4998.8
exploration/Num Paths                         1
exploration/Average Returns                4998.8
evaluation_0/num steps total                  5.59746e+06
evaluation_0/num paths total              13752
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05556
evaluation_0/Rewards Std                      1.35859
evaluation_0/Rewards Max                     10.3898
evaluation_0/Rewards Min                     -0.433933
evaluation_0/Returns Mean                  5055.56
evaluation_0/Returns Std                     43.6788
evaluation_0/Returns Max                   5106.39
evaluation_0/Returns Min                   4972.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5055.56
time/epoch (s)                                0
time/total (s)                            13406
Epoch                                       710
---------------------------------------  ----------------
2022-11-16 14:29:28.058843 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 711 finished
---------------------------------------  ----------------
epoch                                       711
total_step                               716000
replay_pool/size                         716000
trainer/alpha                                 0.0649502
trainer/alpha_loss                            0.960401
trainer/entropy                              -6.35125
trainer/qf_loss                               7.71222
trainer/state_noise                           0.005
trainer/policy_loss                        -221.934
trainer/policy_loss_without_entropy         224.076
trainer/entropy_penalty                      -0.412515
trainer/entropy_percentage                   -0.00184096
trainer/Q1Pred Mean                         223.176
trainer/Q1Pred Std                           73.5705
trainer/Q1Pred Max                          306.255
trainer/Q1Pred Min                           -7.61603
trainer/Q2Pred Mean                         223.31
trainer/Q2Pred Std                           73.6237
trainer/Q2Pred Max                          304.892
trainer/Q2Pred Min                           -9.85822
trainer/QTargetWithReg Mean                 223.124
trainer/QTargetWithReg Std                   73.9194
trainer/QTargetWithReg Max                  304.974
trainer/QTargetWithReg Min                  -12.2862
trainer/PolicyLossWithoutReg Mean           224.076
trainer/PolicyLossWithoutReg Std             72.2456
trainer/PolicyLossWithoutReg Max            302.642
trainer/PolicyLossWithoutReg Min             -3.34218
trainer/gradient_norm                       345.885
trainer/gradient_penalty                     -1.72943
trainer/gradient_percentage                  -0.00771803
exploration/num steps total              716000
exploration/num paths total                1876
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8421
exploration/Rewards Std                       1.33346
exploration/Rewards Max                      10.0725
exploration/Rewards Min                      -0.426599
exploration/Returns Mean                   4842.1
exploration/Returns Std                       0
exploration/Returns Max                    4842.1
exploration/Returns Min                    4842.1
exploration/Num Paths                         1
exploration/Average Returns                4842.1
evaluation_0/num steps total                  5.60546e+06
evaluation_0/num paths total              13760
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08911
evaluation_0/Rewards Std                      1.27731
evaluation_0/Rewards Max                     10.3421
evaluation_0/Rewards Min                     -0.394213
evaluation_0/Returns Mean                  5089.11
evaluation_0/Returns Std                     19.5762
evaluation_0/Returns Max                   5119.26
evaluation_0/Returns Min                   5066.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5089.11
time/epoch (s)                                0
time/total (s)                            13421.8
Epoch                                       711
---------------------------------------  ----------------
2022-11-16 14:29:57.947053 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 712 finished
---------------------------------------  ----------------
epoch                                       712
total_step                               717000
replay_pool/size                         717000
trainer/alpha                                 0.0652732
trainer/alpha_loss                            0.194925
trainer/entropy                              -6.07142
trainer/qf_loss                               7.00312
trainer/state_noise                           0.005
trainer/policy_loss                        -211.388
trainer/policy_loss_without_entropy         213.475
trainer/entropy_penalty                      -0.396301
trainer/entropy_percentage                   -0.00185643
trainer/Q1Pred Mean                         212.708
trainer/Q1Pred Std                           74.2824
trainer/Q1Pred Max                          311.468
trainer/Q1Pred Min                            7.55797
trainer/Q2Pred Mean                         213.204
trainer/Q2Pred Std                           74.1051
trainer/Q2Pred Max                          310.698
trainer/Q2Pred Min                           14.7476
trainer/QTargetWithReg Mean                 212.867
trainer/QTargetWithReg Std                   74.6194
trainer/QTargetWithReg Max                  312.039
trainer/QTargetWithReg Min                    5.5255
trainer/PolicyLossWithoutReg Mean           213.475
trainer/PolicyLossWithoutReg Std             73.4692
trainer/PolicyLossWithoutReg Max            311.08
trainer/PolicyLossWithoutReg Min             10.0228
trainer/gradient_norm                       338.182
trainer/gradient_penalty                     -1.69091
trainer/gradient_percentage                  -0.00792088
exploration/num steps total              717000
exploration/num paths total                1877
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94055
exploration/Rewards Std                       1.30175
exploration/Rewards Max                      10.1641
exploration/Rewards Min                      -0.348645
exploration/Returns Mean                   4940.55
exploration/Returns Std                       0
exploration/Returns Max                    4940.55
exploration/Returns Min                    4940.55
exploration/Num Paths                         1
exploration/Average Returns                4940.55
evaluation_0/num steps total                  5.61346e+06
evaluation_0/num paths total              13768
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03228
evaluation_0/Rewards Std                      1.33083
evaluation_0/Rewards Max                     10.6845
evaluation_0/Rewards Min                     -0.504252
evaluation_0/Returns Mean                  5032.28
evaluation_0/Returns Std                     62.8785
evaluation_0/Returns Max                   5116.49
evaluation_0/Returns Min                   4935.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5032.28
time/epoch (s)                                0
time/total (s)                            13451.7
Epoch                                       712
---------------------------------------  ----------------
2022-11-16 14:31:01.774329 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 713 finished
---------------------------------------  ----------------
epoch                                       713
total_step                               718000
replay_pool/size                         718000
trainer/alpha                                 0.0652391
trainer/alpha_loss                            0.455404
trainer/entropy                              -6.16683
trainer/qf_loss                               7.93592
trainer/state_noise                           0.005
trainer/policy_loss                        -214.908
trainer/policy_loss_without_entropy         217.016
trainer/entropy_penalty                      -0.402318
trainer/entropy_percentage                   -0.00185387
trainer/Q1Pred Mean                         217.351
trainer/Q1Pred Std                           77.803
trainer/Q1Pred Max                          311.241
trainer/Q1Pred Min                          -24.0301
trainer/Q2Pred Mean                         217.051
trainer/Q2Pred Std                           77.8922
trainer/Q2Pred Max                          311.145
trainer/Q2Pred Min                          -18.5486
trainer/QTargetWithReg Mean                 217.023
trainer/QTargetWithReg Std                   78.1611
trainer/QTargetWithReg Max                  311.345
trainer/QTargetWithReg Min                  -14.1361
trainer/PolicyLossWithoutReg Mean           217.016
trainer/PolicyLossWithoutReg Std             77.2217
trainer/PolicyLossWithoutReg Max            310.149
trainer/PolicyLossWithoutReg Min            -17.7456
trainer/gradient_norm                       341.197
trainer/gradient_penalty                     -1.70599
trainer/gradient_percentage                  -0.00786111
exploration/num steps total              718000
exploration/num paths total                1878
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00302
exploration/Rewards Std                       1.30143
exploration/Rewards Max                      10.0962
exploration/Rewards Min                      -0.494225
exploration/Returns Mean                   5003.02
exploration/Returns Std                       0
exploration/Returns Max                    5003.02
exploration/Returns Min                    5003.02
exploration/Num Paths                         1
exploration/Average Returns                5003.02
evaluation_0/num steps total                  5.62146e+06
evaluation_0/num paths total              13776
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08241
evaluation_0/Rewards Std                      1.27973
evaluation_0/Rewards Max                     10.4638
evaluation_0/Rewards Min                     -0.465456
evaluation_0/Returns Mean                  5082.41
evaluation_0/Returns Std                     40.2107
evaluation_0/Returns Max                   5129.78
evaluation_0/Returns Min                   4992.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5082.41
time/epoch (s)                                0
time/total (s)                            13515.5
Epoch                                       713
---------------------------------------  ----------------
2022-11-16 14:32:25.784346 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 714 finished
---------------------------------------  ----------------
epoch                                       714
total_step                               719000
replay_pool/size                         719000
trainer/alpha                                 0.0643773
trainer/alpha_loss                            0.907848
trainer/entropy                              -6.33096
trainer/qf_loss                               7.44548
trainer/state_noise                           0.005
trainer/policy_loss                        -224.241
trainer/policy_loss_without_entropy         226.389
trainer/entropy_penalty                      -0.40757
trainer/entropy_percentage                   -0.00180031
trainer/Q1Pred Mean                         226.203
trainer/Q1Pred Std                           72.5248
trainer/Q1Pred Max                          314.366
trainer/Q1Pred Min                            3.0051
trainer/Q2Pred Mean                         225.698
trainer/Q2Pred Std                           72.6171
trainer/Q2Pred Max                          313.357
trainer/Q2Pred Min                            2.17028
trainer/QTargetWithReg Mean                 226.046
trainer/QTargetWithReg Std                   72.7278
trainer/QTargetWithReg Max                  314.255
trainer/QTargetWithReg Min                    6.44996
trainer/PolicyLossWithoutReg Mean           226.389
trainer/PolicyLossWithoutReg Std             71.8567
trainer/PolicyLossWithoutReg Max            314.011
trainer/PolicyLossWithoutReg Min              1.90295
trainer/gradient_norm                       348.213
trainer/gradient_penalty                     -1.74107
trainer/gradient_percentage                  -0.00769058
exploration/num steps total              719000
exploration/num paths total                1879
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93569
exploration/Rewards Std                       1.28675
exploration/Rewards Max                      10.4687
exploration/Rewards Min                      -0.373623
exploration/Returns Mean                   4935.69
exploration/Returns Std                       0
exploration/Returns Max                    4935.69
exploration/Returns Min                    4935.69
exploration/Num Paths                         1
exploration/Average Returns                4935.69
evaluation_0/num steps total                  5.62946e+06
evaluation_0/num paths total              13784
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03234
evaluation_0/Rewards Std                      1.32399
evaluation_0/Rewards Max                     10.3915
evaluation_0/Rewards Min                     -0.497905
evaluation_0/Returns Mean                  5032.34
evaluation_0/Returns Std                     71.9528
evaluation_0/Returns Max                   5149.75
evaluation_0/Returns Min                   4911.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5032.34
time/epoch (s)                                0
time/total (s)                            13599.5
Epoch                                       714
---------------------------------------  ----------------
2022-11-16 14:33:33.316945 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 715 finished
---------------------------------------  ----------------
epoch                                       715
total_step                               720000
replay_pool/size                         720000
trainer/alpha                                 0.0629561
trainer/alpha_loss                           -0.984494
trainer/entropy                              -5.64397
trainer/qf_loss                               5.84351
trainer/state_noise                           0.005
trainer/policy_loss                        -223.274
trainer/policy_loss_without_entropy         225.335
trainer/entropy_penalty                      -0.355323
trainer/entropy_percentage                   -0.00157686
trainer/Q1Pred Mean                         224.649
trainer/Q1Pred Std                           72.0733
trainer/Q1Pred Max                          311.815
trainer/Q1Pred Min                            3.03327
trainer/Q2Pred Mean                         224.582
trainer/Q2Pred Std                           71.9409
trainer/Q2Pred Max                          312.209
trainer/Q2Pred Min                            5.64918
trainer/QTargetWithReg Mean                 224.352
trainer/QTargetWithReg Std                   71.8619
trainer/QTargetWithReg Max                  312.222
trainer/QTargetWithReg Min                    6.10962
trainer/PolicyLossWithoutReg Mean           225.335
trainer/PolicyLossWithoutReg Std             71.3421
trainer/PolicyLossWithoutReg Max            312.256
trainer/PolicyLossWithoutReg Min              3.62073
trainer/gradient_norm                       341.196
trainer/gradient_penalty                     -1.70598
trainer/gradient_percentage                  -0.00757085
exploration/num steps total              720000
exploration/num paths total                1880
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95845
exploration/Rewards Std                       1.34191
exploration/Rewards Max                      10.4367
exploration/Rewards Min                      -0.489339
exploration/Returns Mean                   4958.45
exploration/Returns Std                       0
exploration/Returns Max                    4958.45
exploration/Returns Min                    4958.45
exploration/Num Paths                         1
exploration/Average Returns                4958.45
evaluation_0/num steps total                  5.63746e+06
evaluation_0/num paths total              13792
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00612
evaluation_0/Rewards Std                      1.29423
evaluation_0/Rewards Max                     10.3936
evaluation_0/Rewards Min                     -0.444492
evaluation_0/Returns Mean                  5006.12
evaluation_0/Returns Std                     56.9347
evaluation_0/Returns Max                   5055.39
evaluation_0/Returns Min                   4860.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5006.12
time/epoch (s)                                0
time/total (s)                            13667.1
Epoch                                       715
---------------------------------------  ----------------
2022-11-16 14:34:37.880748 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 716 finished
---------------------------------------  ----------------
epoch                                       716
total_step                               721000
replay_pool/size                         721000
trainer/alpha                                 0.0627864
trainer/alpha_loss                            0.992269
trainer/entropy                              -6.35847
trainer/qf_loss                              10.9533
trainer/state_noise                           0.005
trainer/policy_loss                        -212.79
trainer/policy_loss_without_entropy         214.885
trainer/entropy_penalty                      -0.399226
trainer/entropy_percentage                   -0.00185786
trainer/Q1Pred Mean                         215.218
trainer/Q1Pred Std                           76.1106
trainer/Q1Pred Max                          306.037
trainer/Q1Pred Min                           11.56
trainer/Q2Pred Mean                         214.505
trainer/Q2Pred Std                           75.9615
trainer/Q2Pred Max                          304.243
trainer/Q2Pred Min                           13.4634
trainer/QTargetWithReg Mean                 214.818
trainer/QTargetWithReg Std                   76.2389
trainer/QTargetWithReg Max                  304.972
trainer/QTargetWithReg Min                   11.1304
trainer/PolicyLossWithoutReg Mean           214.885
trainer/PolicyLossWithoutReg Std             75.0929
trainer/PolicyLossWithoutReg Max            302.615
trainer/PolicyLossWithoutReg Min             11.714
trainer/gradient_norm                       339.184
trainer/gradient_penalty                     -1.69592
trainer/gradient_percentage                  -0.00789223
exploration/num steps total              721000
exploration/num paths total                1881
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83625
exploration/Rewards Std                       1.29784
exploration/Rewards Max                      10.4088
exploration/Rewards Min                      -0.456913
exploration/Returns Mean                   4836.25
exploration/Returns Std                       0
exploration/Returns Max                    4836.25
exploration/Returns Min                    4836.25
exploration/Num Paths                         1
exploration/Average Returns                4836.25
evaluation_0/num steps total                  5.64546e+06
evaluation_0/num paths total              13800
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93268
evaluation_0/Rewards Std                      1.30303
evaluation_0/Rewards Max                     10.4538
evaluation_0/Rewards Min                     -0.486825
evaluation_0/Returns Mean                  4932.68
evaluation_0/Returns Std                     89.0833
evaluation_0/Returns Max                   5066.45
evaluation_0/Returns Min                   4829.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4932.68
time/epoch (s)                                0
time/total (s)                            13731.6
Epoch                                       716
---------------------------------------  ----------------
2022-11-16 14:35:28.219828 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 717 finished
---------------------------------------  ----------------
epoch                                       717
total_step                               722000
replay_pool/size                         722000
trainer/alpha                                 0.0624582
trainer/alpha_loss                           -1.94937
trainer/entropy                              -5.29701
trainer/qf_loss                               5.75811
trainer/state_noise                           0.005
trainer/policy_loss                        -224.678
trainer/policy_loss_without_entropy         226.716
trainer/entropy_penalty                      -0.330842
trainer/entropy_percentage                   -0.00145928
trainer/Q1Pred Mean                         226.254
trainer/Q1Pred Std                           78.1586
trainer/Q1Pred Max                          309.042
trainer/Q1Pred Min                           18.7003
trainer/Q2Pred Mean                         226.377
trainer/Q2Pred Std                           77.9993
trainer/Q2Pred Max                          309.299
trainer/Q2Pred Min                           18.9974
trainer/QTargetWithReg Mean                 225.864
trainer/QTargetWithReg Std                   77.9813
trainer/QTargetWithReg Max                  307.671
trainer/QTargetWithReg Min                   18.7349
trainer/PolicyLossWithoutReg Mean           226.716
trainer/PolicyLossWithoutReg Std             77.4258
trainer/PolicyLossWithoutReg Max            308.412
trainer/PolicyLossWithoutReg Min             18.95
trainer/gradient_norm                       341.596
trainer/gradient_penalty                     -1.70798
trainer/gradient_percentage                  -0.00753355
exploration/num steps total              722000
exploration/num paths total                1882
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.70539
exploration/Rewards Std                       1.31756
exploration/Rewards Max                      10.4368
exploration/Rewards Min                      -0.514788
exploration/Returns Mean                   4705.39
exploration/Returns Std                       0
exploration/Returns Max                    4705.39
exploration/Returns Min                    4705.39
exploration/Num Paths                         1
exploration/Average Returns                4705.39
evaluation_0/num steps total                  5.65346e+06
evaluation_0/num paths total              13808
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00899
evaluation_0/Rewards Std                      1.33296
evaluation_0/Rewards Max                     10.6144
evaluation_0/Rewards Min                     -0.401127
evaluation_0/Returns Mean                  5008.99
evaluation_0/Returns Std                     57.3731
evaluation_0/Returns Max                   5066.04
evaluation_0/Returns Min                   4927.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5008.99
time/epoch (s)                                0
time/total (s)                            13782
Epoch                                       717
---------------------------------------  ----------------
2022-11-16 14:35:41.702266 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 718 finished
---------------------------------------  ----------------
epoch                                       718
total_step                               723000
replay_pool/size                         723000
trainer/alpha                                 0.0639389
trainer/alpha_loss                            1.02355
trainer/entropy                              -6.37221
trainer/qf_loss                               7.2585
trainer/state_noise                           0.005
trainer/policy_loss                        -217.695
trainer/policy_loss_without_entropy         219.866
trainer/entropy_penalty                      -0.407432
trainer/entropy_percentage                   -0.00185309
trainer/Q1Pred Mean                         218.629
trainer/Q1Pred Std                           71.4015
trainer/Q1Pred Max                          308.363
trainer/Q1Pred Min                           18.6049
trainer/Q2Pred Mean                         218.913
trainer/Q2Pred Std                           71.2084
trainer/Q2Pred Max                          308.974
trainer/Q2Pred Min                           12.6062
trainer/QTargetWithReg Mean                 218.489
trainer/QTargetWithReg Std                   71.5581
trainer/QTargetWithReg Max                  308.834
trainer/QTargetWithReg Min                   14.4191
trainer/PolicyLossWithoutReg Mean           219.866
trainer/PolicyLossWithoutReg Std             70.571
trainer/PolicyLossWithoutReg Max            309.258
trainer/PolicyLossWithoutReg Min             13.7178
trainer/gradient_norm                       352.746
trainer/gradient_penalty                     -1.76373
trainer/gradient_percentage                  -0.00802182
exploration/num steps total              723000
exploration/num paths total                1883
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.71258
exploration/Rewards Std                       1.34391
exploration/Rewards Max                      10.1133
exploration/Rewards Min                      -0.286125
exploration/Returns Mean                   4712.58
exploration/Returns Std                       0
exploration/Returns Max                    4712.58
exploration/Returns Min                    4712.58
exploration/Num Paths                         1
exploration/Average Returns                4712.58
evaluation_0/num steps total                  5.66146e+06
evaluation_0/num paths total              13816
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95833
evaluation_0/Rewards Std                      1.32778
evaluation_0/Rewards Max                     10.3847
evaluation_0/Rewards Min                     -0.438502
evaluation_0/Returns Mean                  4958.33
evaluation_0/Returns Std                     66.0482
evaluation_0/Returns Max                   5071.53
evaluation_0/Returns Min                   4830.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4958.33
time/epoch (s)                                0
time/total (s)                            13795.4
Epoch                                       718
---------------------------------------  ----------------
2022-11-16 14:36:39.039659 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 719 finished
---------------------------------------  ----------------
epoch                                       719
total_step                               724000
replay_pool/size                         724000
trainer/alpha                                 0.0637082
trainer/alpha_loss                            0.0625942
trainer/entropy                              -6.02273
trainer/qf_loss                               7.67206
trainer/state_noise                           0.005
trainer/policy_loss                        -213.486
trainer/policy_loss_without_entropy         215.543
trainer/entropy_penalty                      -0.383698
trainer/entropy_percentage                   -0.00178015
trainer/Q1Pred Mean                         214.184
trainer/Q1Pred Std                           74.0519
trainer/Q1Pred Max                          312.73
trainer/Q1Pred Min                            0.282139
trainer/Q2Pred Mean                         214.638
trainer/Q2Pred Std                           73.9607
trainer/Q2Pred Max                          314.434
trainer/Q2Pred Min                           -1.00231
trainer/QTargetWithReg Mean                 214.525
trainer/QTargetWithReg Std                   73.7344
trainer/QTargetWithReg Max                  313.404
trainer/QTargetWithReg Min                   -0.287351
trainer/PolicyLossWithoutReg Mean           215.543
trainer/PolicyLossWithoutReg Std             73.3837
trainer/PolicyLossWithoutReg Max            313.383
trainer/PolicyLossWithoutReg Min              2.64934
trainer/gradient_norm                       334.62
trainer/gradient_penalty                     -1.6731
trainer/gradient_percentage                  -0.00776226
exploration/num steps total              724000
exploration/num paths total                1884
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98095
exploration/Rewards Std                       1.28055
exploration/Rewards Max                       9.99394
exploration/Rewards Min                      -0.441275
exploration/Returns Mean                   4980.95
exploration/Returns Std                       0
exploration/Returns Max                    4980.95
exploration/Returns Min                    4980.95
exploration/Num Paths                         1
exploration/Average Returns                4980.95
evaluation_0/num steps total                  5.66946e+06
evaluation_0/num paths total              13824
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88527
evaluation_0/Rewards Std                      1.31932
evaluation_0/Rewards Max                     10.4912
evaluation_0/Rewards Min                     -0.406519
evaluation_0/Returns Mean                  4885.27
evaluation_0/Returns Std                     41.6057
evaluation_0/Returns Max                   4964.68
evaluation_0/Returns Min                   4805.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4885.27
time/epoch (s)                                0
time/total (s)                            13852.8
Epoch                                       719
---------------------------------------  ----------------
2022-11-16 14:38:06.152092 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 720 finished
---------------------------------------  ----------------
epoch                                       720
total_step                               725000
replay_pool/size                         725000
trainer/alpha                                 0.0638259
trainer/alpha_loss                            0.2213
trainer/entropy                              -6.08043
trainer/qf_loss                               8.13474
trainer/state_noise                           0.005
trainer/policy_loss                        -217.839
trainer/policy_loss_without_entropy         219.98
trainer/entropy_penalty                      -0.388089
trainer/entropy_percentage                   -0.0017642
trainer/Q1Pred Mean                         219.617
trainer/Q1Pred Std                           76.7005
trainer/Q1Pred Max                          307.172
trainer/Q1Pred Min                            0.709588
trainer/Q2Pred Mean                         219.432
trainer/Q2Pred Std                           76.6342
trainer/Q2Pred Max                          307.172
trainer/Q2Pred Min                          -11.7685
trainer/QTargetWithReg Mean                 219.317
trainer/QTargetWithReg Std                   77.0062
trainer/QTargetWithReg Max                  306.294
trainer/QTargetWithReg Min                   -9.05429
trainer/PolicyLossWithoutReg Mean           219.98
trainer/PolicyLossWithoutReg Std             76.2698
trainer/PolicyLossWithoutReg Max            306.782
trainer/PolicyLossWithoutReg Min             -9.81584
trainer/gradient_norm                       350.529
trainer/gradient_penalty                     -1.75265
trainer/gradient_percentage                  -0.0079673
exploration/num steps total              725000
exploration/num paths total                1885
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87152
exploration/Rewards Std                       1.29867
exploration/Rewards Max                      10.2254
exploration/Rewards Min                      -0.392839
exploration/Returns Mean                   4871.52
exploration/Returns Std                       0
exploration/Returns Max                    4871.52
exploration/Returns Min                    4871.52
exploration/Num Paths                         1
exploration/Average Returns                4871.52
evaluation_0/num steps total                  5.67746e+06
evaluation_0/num paths total              13832
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92281
evaluation_0/Rewards Std                      1.31827
evaluation_0/Rewards Max                     10.5576
evaluation_0/Rewards Min                     -0.488143
evaluation_0/Returns Mean                  4922.81
evaluation_0/Returns Std                    103.855
evaluation_0/Returns Max                   5058.02
evaluation_0/Returns Min                   4781.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4922.81
time/epoch (s)                                0
time/total (s)                            13939.9
Epoch                                       720
---------------------------------------  ----------------
2022-11-16 14:39:34.978662 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 721 finished
---------------------------------------  ----------------
epoch                                       721
total_step                               726000
replay_pool/size                         726000
trainer/alpha                                 0.0644688
trainer/alpha_loss                            0.308047
trainer/entropy                              -6.11236
trainer/qf_loss                               4.62817
trainer/state_noise                           0.005
trainer/policy_loss                        -223.028
trainer/policy_loss_without_entropy         225.181
trainer/entropy_penalty                      -0.394056
trainer/entropy_percentage                   -0.00174996
trainer/Q1Pred Mean                         223.797
trainer/Q1Pred Std                           70.2264
trainer/Q1Pred Max                          305.124
trainer/Q1Pred Min                          -14.7387
trainer/Q2Pred Mean                         224.228
trainer/Q2Pred Std                           70.4072
trainer/Q2Pred Max                          307.918
trainer/Q2Pred Min                          -17.6089
trainer/QTargetWithReg Mean                 224.313
trainer/QTargetWithReg Std                   70.3353
trainer/QTargetWithReg Max                  306.493
trainer/QTargetWithReg Min                  -13.0034
trainer/PolicyLossWithoutReg Mean           225.181
trainer/PolicyLossWithoutReg Std             69.3968
trainer/PolicyLossWithoutReg Max            305.455
trainer/PolicyLossWithoutReg Min            -12.8243
trainer/gradient_norm                       351.699
trainer/gradient_penalty                     -1.75849
trainer/gradient_percentage                  -0.00780926
exploration/num steps total              726000
exploration/num paths total                1886
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87445
exploration/Rewards Std                       1.30481
exploration/Rewards Max                      10.1666
exploration/Rewards Min                      -0.340979
exploration/Returns Mean                   4874.45
exploration/Returns Std                       0
exploration/Returns Max                    4874.45
exploration/Returns Min                    4874.45
exploration/Num Paths                         1
exploration/Average Returns                4874.45
evaluation_0/num steps total                  5.68546e+06
evaluation_0/num paths total              13840
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93778
evaluation_0/Rewards Std                      1.30813
evaluation_0/Rewards Max                     10.6215
evaluation_0/Rewards Min                     -0.426828
evaluation_0/Returns Mean                  4937.78
evaluation_0/Returns Std                     35.1291
evaluation_0/Returns Max                   5000.08
evaluation_0/Returns Min                   4893.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4937.78
time/epoch (s)                                0
time/total (s)                            14028.7
Epoch                                       721
---------------------------------------  ----------------
2022-11-16 14:41:04.372978 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 722 finished
---------------------------------------  ----------------
epoch                                       722
total_step                               727000
replay_pool/size                         727000
trainer/alpha                                 0.062557
trainer/alpha_loss                           -0.484399
trainer/entropy                              -5.82523
trainer/qf_loss                               5.87887
trainer/state_noise                           0.005
trainer/policy_loss                        -223.601
trainer/policy_loss_without_entropy         225.677
trainer/entropy_penalty                      -0.364409
trainer/entropy_percentage                   -0.00161473
trainer/Q1Pred Mean                         224.788
trainer/Q1Pred Std                           75.1864
trainer/Q1Pred Max                          307.296
trainer/Q1Pred Min                            5.70404
trainer/Q2Pred Mean                         224.837
trainer/Q2Pred Std                           75.1086
trainer/Q2Pred Max                          307.909
trainer/Q2Pred Min                            4.50612
trainer/QTargetWithReg Mean                 224.558
trainer/QTargetWithReg Std                   75.4186
trainer/QTargetWithReg Max                  308.286
trainer/QTargetWithReg Min                    5.01044
trainer/PolicyLossWithoutReg Mean           225.677
trainer/PolicyLossWithoutReg Std             73.8109
trainer/PolicyLossWithoutReg Max            308.347
trainer/PolicyLossWithoutReg Min              5.31745
trainer/gradient_norm                       342.307
trainer/gradient_penalty                     -1.71153
trainer/gradient_percentage                  -0.00758398
exploration/num steps total              727000
exploration/num paths total                1887
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94194
exploration/Rewards Std                       1.28446
exploration/Rewards Max                      10.2837
exploration/Rewards Min                      -0.435592
exploration/Returns Mean                   4941.94
exploration/Returns Std                       0
exploration/Returns Max                    4941.94
exploration/Returns Min                    4941.94
exploration/Num Paths                         1
exploration/Average Returns                4941.94
evaluation_0/num steps total                  5.69346e+06
evaluation_0/num paths total              13848
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.60958
evaluation_0/Rewards Std                      1.20885
evaluation_0/Rewards Max                      9.30091
evaluation_0/Rewards Min                     -0.48082
evaluation_0/Returns Mean                  4609.58
evaluation_0/Returns Std                     64.3294
evaluation_0/Returns Max                   4777.09
evaluation_0/Returns Min                   4562.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4609.58
time/epoch (s)                                0
time/total (s)                            14118.1
Epoch                                       722
---------------------------------------  ----------------
2022-11-16 14:41:49.109276 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 723 finished
---------------------------------------  ----------------
epoch                                       723
total_step                               728000
replay_pool/size                         728000
trainer/alpha                                 0.0636915
trainer/alpha_loss                            0.505841
trainer/entropy                              -6.1837
trainer/qf_loss                               7.4432
trainer/state_noise                           0.005
trainer/policy_loss                        -219.115
trainer/policy_loss_without_entropy         221.189
trainer/entropy_penalty                      -0.393849
trainer/entropy_percentage                   -0.0017806
trainer/Q1Pred Mean                         220.856
trainer/Q1Pred Std                           75.6312
trainer/Q1Pred Max                          312.508
trainer/Q1Pred Min                           20.4034
trainer/Q2Pred Mean                         220.889
trainer/Q2Pred Std                           75.9541
trainer/Q2Pred Max                          312.187
trainer/Q2Pred Min                           16.8817
trainer/QTargetWithReg Mean                 220.543
trainer/QTargetWithReg Std                   76.2439
trainer/QTargetWithReg Max                  311.73
trainer/QTargetWithReg Min                   18.0929
trainer/PolicyLossWithoutReg Mean           221.189
trainer/PolicyLossWithoutReg Std             74.9833
trainer/PolicyLossWithoutReg Max            312.043
trainer/PolicyLossWithoutReg Min             19.7252
trainer/gradient_norm                       336.001
trainer/gradient_penalty                     -1.68
trainer/gradient_percentage                  -0.00759534
exploration/num steps total              728000
exploration/num paths total                1888
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96879
exploration/Rewards Std                       1.29648
exploration/Rewards Max                      10.0754
exploration/Rewards Min                      -0.342291
exploration/Returns Mean                   4968.79
exploration/Returns Std                       0
exploration/Returns Max                    4968.79
exploration/Returns Min                    4968.79
exploration/Num Paths                         1
exploration/Average Returns                4968.79
evaluation_0/num steps total                  5.70146e+06
evaluation_0/num paths total              13856
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9093
evaluation_0/Rewards Std                      1.32336
evaluation_0/Rewards Max                     10.6023
evaluation_0/Rewards Min                     -0.473283
evaluation_0/Returns Mean                  4909.3
evaluation_0/Returns Std                    115.674
evaluation_0/Returns Max                   5131.22
evaluation_0/Returns Min                   4781.68
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4909.3
time/epoch (s)                                0
time/total (s)                            14162.8
Epoch                                       723
---------------------------------------  ----------------
2022-11-16 14:42:03.292204 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 724 finished
---------------------------------------  ----------------
epoch                                       724
total_step                               729000
replay_pool/size                         729000
trainer/alpha                                 0.0629879
trainer/alpha_loss                            1.04099
trainer/entropy                              -6.37648
trainer/qf_loss                               5.64759
trainer/state_noise                           0.005
trainer/policy_loss                        -218.614
trainer/policy_loss_without_entropy         220.742
trainer/entropy_penalty                      -0.401641
trainer/entropy_percentage                   -0.0018195
trainer/Q1Pred Mean                         220.754
trainer/Q1Pred Std                           73.1008
trainer/Q1Pred Max                          313.947
trainer/Q1Pred Min                           22.6148
trainer/Q2Pred Mean                         220.338
trainer/Q2Pred Std                           72.9577
trainer/Q2Pred Max                          314.39
trainer/Q2Pred Min                           25.1409
trainer/QTargetWithReg Mean                 220.611
trainer/QTargetWithReg Std                   72.9557
trainer/QTargetWithReg Max                  314.82
trainer/QTargetWithReg Min                   24.0737
trainer/PolicyLossWithoutReg Mean           220.742
trainer/PolicyLossWithoutReg Std             72.2709
trainer/PolicyLossWithoutReg Max            313.934
trainer/PolicyLossWithoutReg Min             23.6978
trainer/gradient_norm                       345.258
trainer/gradient_penalty                     -1.72629
trainer/gradient_percentage                  -0.00782039
exploration/num steps total              729000
exploration/num paths total                1889
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81926
exploration/Rewards Std                       1.23434
exploration/Rewards Max                       9.39995
exploration/Rewards Min                      -0.418621
exploration/Returns Mean                   4819.26
exploration/Returns Std                       0
exploration/Returns Max                    4819.26
exploration/Returns Min                    4819.26
exploration/Num Paths                         1
exploration/Average Returns                4819.26
evaluation_0/num steps total                  5.70946e+06
evaluation_0/num paths total              13864
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74642
evaluation_0/Rewards Std                      1.22516
evaluation_0/Rewards Max                      9.62347
evaluation_0/Rewards Min                     -0.4265
evaluation_0/Returns Mean                  4746.42
evaluation_0/Returns Std                     71.3299
evaluation_0/Returns Max                   4852.44
evaluation_0/Returns Min                   4645.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4746.42
time/epoch (s)                                0
time/total (s)                            14177
Epoch                                       724
---------------------------------------  ----------------
2022-11-16 14:42:19.211631 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 725 finished
---------------------------------------  ----------------
epoch                                       725
total_step                               730000
replay_pool/size                         730000
trainer/alpha                                 0.0638447
trainer/alpha_loss                           -0.96681
trainer/entropy                              -5.64857
trainer/qf_loss                               5.95849
trainer/state_noise                           0.005
trainer/policy_loss                        -217.429
trainer/policy_loss_without_entropy         219.578
trainer/entropy_penalty                      -0.360632
trainer/entropy_percentage                   -0.00164238
trainer/Q1Pred Mean                         218.488
trainer/Q1Pred Std                           72.9583
trainer/Q1Pred Max                          315.93
trainer/Q1Pred Min                           -2.02497
trainer/Q2Pred Mean                         218.44
trainer/Q2Pred Std                           72.9304
trainer/Q2Pred Max                          315.576
trainer/Q2Pred Min                           -4.09862
trainer/QTargetWithReg Mean                 219.292
trainer/QTargetWithReg Std                   72.7889
trainer/QTargetWithReg Max                  317.384
trainer/QTargetWithReg Min                   -0.394824
trainer/PolicyLossWithoutReg Mean           219.578
trainer/PolicyLossWithoutReg Std             71.6149
trainer/PolicyLossWithoutReg Max            315.614
trainer/PolicyLossWithoutReg Min              5.34626
trainer/gradient_norm                       357.671
trainer/gradient_penalty                     -1.78836
trainer/gradient_percentage                  -0.00814451
exploration/num steps total              730000
exploration/num paths total                1890
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.92676
exploration/Rewards Std                       1.28631
exploration/Rewards Max                      10.631
exploration/Rewards Min                      -0.407573
exploration/Returns Mean                   4926.76
exploration/Returns Std                       0
exploration/Returns Max                    4926.76
exploration/Returns Min                    4926.76
exploration/Num Paths                         1
exploration/Average Returns                4926.76
evaluation_0/num steps total                  5.71746e+06
evaluation_0/num paths total              13872
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.56917
evaluation_0/Rewards Std                      1.29085
evaluation_0/Rewards Max                      9.8593
evaluation_0/Rewards Min                     -0.494153
evaluation_0/Returns Mean                  4569.17
evaluation_0/Returns Std                     90.6705
evaluation_0/Returns Max                   4784.02
evaluation_0/Returns Min                   4452.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4569.17
time/epoch (s)                                0
time/total (s)                            14192.9
Epoch                                       725
---------------------------------------  ----------------
2022-11-16 14:42:35.672082 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 726 finished
---------------------------------------  ----------------
epoch                                       726
total_step                               731000
replay_pool/size                         731000
trainer/alpha                                 0.0642628
trainer/alpha_loss                            0.200416
trainer/entropy                              -6.07301
trainer/qf_loss                               5.07888
trainer/state_noise                           0.005
trainer/policy_loss                        -225.131
trainer/policy_loss_without_entropy         227.264
trainer/entropy_penalty                      -0.390268
trainer/entropy_percentage                   -0.00171724
trainer/Q1Pred Mean                         226.68
trainer/Q1Pred Std                           70.082
trainer/Q1Pred Max                          307.477
trainer/Q1Pred Min                           16.1981
trainer/Q2Pred Mean                         226.876
trainer/Q2Pred Std                           70.0282
trainer/Q2Pred Max                          306.375
trainer/Q2Pred Min                           18.5109
trainer/QTargetWithReg Mean                 226.936
trainer/QTargetWithReg Std                   70.0443
trainer/QTargetWithReg Max                  307.244
trainer/QTargetWithReg Min                   14.1201
trainer/PolicyLossWithoutReg Mean           227.264
trainer/PolicyLossWithoutReg Std             69.5959
trainer/PolicyLossWithoutReg Max            307.446
trainer/PolicyLossWithoutReg Min             18.0934
trainer/gradient_norm                       348.733
trainer/gradient_penalty                     -1.74366
trainer/gradient_percentage                  -0.0076724
exploration/num steps total              731000
exploration/num paths total                1891
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.63203
exploration/Rewards Std                       1.30864
exploration/Rewards Max                       9.87194
exploration/Rewards Min                      -0.464024
exploration/Returns Mean                   4632.03
exploration/Returns Std                       0
exploration/Returns Max                    4632.03
exploration/Returns Min                    4632.03
exploration/Num Paths                         1
exploration/Average Returns                4632.03
evaluation_0/num steps total                  5.72546e+06
evaluation_0/num paths total              13880
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.71532
evaluation_0/Rewards Std                      1.27468
evaluation_0/Rewards Max                     10.402
evaluation_0/Rewards Min                     -0.398701
evaluation_0/Returns Mean                  4715.32
evaluation_0/Returns Std                    107.474
evaluation_0/Returns Max                   4893.1
evaluation_0/Returns Min                   4603.05
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4715.32
time/epoch (s)                                0
time/total (s)                            14209.4
Epoch                                       726
---------------------------------------  ----------------
2022-11-16 14:42:51.419545 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 727 finished
---------------------------------------  ----------------
epoch                                       727
total_step                               732000
replay_pool/size                         732000
trainer/alpha                                 0.0623139
trainer/alpha_loss                            0.730565
trainer/entropy                              -6.2632
trainer/qf_loss                              12.2318
trainer/state_noise                           0.005
trainer/policy_loss                        -224.049
trainer/policy_loss_without_entropy         226.208
trainer/entropy_penalty                      -0.390285
trainer/entropy_percentage                   -0.00172533
trainer/Q1Pred Mean                         225.698
trainer/Q1Pred Std                           69.7145
trainer/Q1Pred Max                          308.699
trainer/Q1Pred Min                           -5.35988
trainer/Q2Pred Mean                         225.385
trainer/Q2Pred Std                           69.9666
trainer/Q2Pred Max                          308.482
trainer/Q2Pred Min                           -8.74505
trainer/QTargetWithReg Mean                 226.399
trainer/QTargetWithReg Std                   69.6665
trainer/QTargetWithReg Max                  310.288
trainer/QTargetWithReg Min                    0.291116
trainer/PolicyLossWithoutReg Mean           226.208
trainer/PolicyLossWithoutReg Std             69.1813
trainer/PolicyLossWithoutReg Max            308.927
trainer/PolicyLossWithoutReg Min             -8.77544
trainer/gradient_norm                       353.8
trainer/gradient_penalty                     -1.769
trainer/gradient_percentage                  -0.00782024
exploration/num steps total              732000
exploration/num paths total                1892
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9404
exploration/Rewards Std                       1.31221
exploration/Rewards Max                      10.4921
exploration/Rewards Min                      -0.393263
exploration/Returns Mean                   4940.4
exploration/Returns Std                       0
exploration/Returns Max                    4940.4
exploration/Returns Min                    4940.4
exploration/Num Paths                         1
exploration/Average Returns                4940.4
evaluation_0/num steps total                  5.73346e+06
evaluation_0/num paths total              13888
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75849
evaluation_0/Rewards Std                      1.21558
evaluation_0/Rewards Max                     10.0266
evaluation_0/Rewards Min                     -0.467722
evaluation_0/Returns Mean                  4758.49
evaluation_0/Returns Std                     39.3672
evaluation_0/Returns Max                   4828.22
evaluation_0/Returns Min                   4712.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4758.49
time/epoch (s)                                0
time/total (s)                            14225.1
Epoch                                       727
---------------------------------------  ----------------
2022-11-16 14:43:09.445967 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 728 finished
---------------------------------------  ----------------
epoch                                       728
total_step                               733000
replay_pool/size                         733000
trainer/alpha                                 0.0632803
trainer/alpha_loss                            0.627897
trainer/entropy                              -6.22747
trainer/qf_loss                               8.75243
trainer/state_noise                           0.005
trainer/policy_loss                        -220.894
trainer/policy_loss_without_entropy         223.016
trainer/entropy_penalty                      -0.394076
trainer/entropy_percentage                   -0.00176703
trainer/Q1Pred Mean                         221.825
trainer/Q1Pred Std                           71.838
trainer/Q1Pred Max                          308.695
trainer/Q1Pred Min                           10.0497
trainer/Q2Pred Mean                         221.731
trainer/Q2Pred Std                           71.9521
trainer/Q2Pred Max                          309.248
trainer/Q2Pred Min                           13.153
trainer/QTargetWithReg Mean                 221.747
trainer/QTargetWithReg Std                   72.0602
trainer/QTargetWithReg Max                  310.221
trainer/QTargetWithReg Min                   -0.788262
trainer/PolicyLossWithoutReg Mean           223.016
trainer/PolicyLossWithoutReg Std             70.2597
trainer/PolicyLossWithoutReg Max            309.57
trainer/PolicyLossWithoutReg Min             16.7703
trainer/gradient_norm                       345.59
trainer/gradient_penalty                     -1.72795
trainer/gradient_percentage                  -0.00774811
exploration/num steps total              733000
exploration/num paths total                1893
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78061
exploration/Rewards Std                       1.24542
exploration/Rewards Max                      10.3292
exploration/Rewards Min                      -0.486749
exploration/Returns Mean                   4780.61
exploration/Returns Std                       0
exploration/Returns Max                    4780.61
exploration/Returns Min                    4780.61
exploration/Num Paths                         1
exploration/Average Returns                4780.61
evaluation_0/num steps total                  5.74106e+06
evaluation_0/num paths total              13896
evaluation_0/path length Mean               949.875
evaluation_0/path length Std                 89.6248
evaluation_0/path length Max               1000
evaluation_0/path length Min                755
evaluation_0/Rewards Mean                     4.55098
evaluation_0/Rewards Std                      1.28854
evaluation_0/Rewards Max                      9.7267
evaluation_0/Rewards Min                     -0.406965
evaluation_0/Returns Mean                  4322.86
evaluation_0/Returns Std                    405.503
evaluation_0/Returns Max                   4650.96
evaluation_0/Returns Min                   3427.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4322.86
time/epoch (s)                                0
time/total (s)                            14243.2
Epoch                                       728
---------------------------------------  ----------------
2022-11-16 14:43:25.348407 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 729 finished
---------------------------------------  ----------------
epoch                                       729
total_step                               734000
replay_pool/size                         734000
trainer/alpha                                 0.0635528
trainer/alpha_loss                           -0.527858
trainer/entropy                              -5.80846
trainer/qf_loss                               6.80756
trainer/state_noise                           0.005
trainer/policy_loss                        -225.632
trainer/policy_loss_without_entropy         227.78
trainer/entropy_penalty                      -0.369144
trainer/entropy_percentage                   -0.00162062
trainer/Q1Pred Mean                         226.624
trainer/Q1Pred Std                           69.1397
trainer/Q1Pred Max                          312.553
trainer/Q1Pred Min                           -4.3419
trainer/Q2Pred Mean                         226.786
trainer/Q2Pred Std                           68.9863
trainer/Q2Pred Max                          310.486
trainer/Q2Pred Min                           -3.70394
trainer/QTargetWithReg Mean                 226.936
trainer/QTargetWithReg Std                   69.6306
trainer/QTargetWithReg Max                  313.621
trainer/QTargetWithReg Min                   -6.38227
trainer/PolicyLossWithoutReg Mean           227.78
trainer/PolicyLossWithoutReg Std             68.0509
trainer/PolicyLossWithoutReg Max            312.122
trainer/PolicyLossWithoutReg Min             -5.87421
trainer/gradient_norm                       355.731
trainer/gradient_penalty                     -1.77866
trainer/gradient_percentage                  -0.00780865
exploration/num steps total              734000
exploration/num paths total                1894
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.815
exploration/Rewards Std                       1.28597
exploration/Rewards Max                      10.1779
exploration/Rewards Min                      -0.470763
exploration/Returns Mean                   4815
exploration/Returns Std                       0
exploration/Returns Max                    4815
exploration/Returns Min                    4815
exploration/Num Paths                         1
exploration/Average Returns                4815
evaluation_0/num steps total                  5.74906e+06
evaluation_0/num paths total              13904
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96421
evaluation_0/Rewards Std                      1.32544
evaluation_0/Rewards Max                     10.6135
evaluation_0/Rewards Min                     -0.426535
evaluation_0/Returns Mean                  4964.21
evaluation_0/Returns Std                     33.1885
evaluation_0/Returns Max                   5001.76
evaluation_0/Returns Min                   4900.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4964.21
time/epoch (s)                                0
time/total (s)                            14259.1
Epoch                                       729
---------------------------------------  ----------------
2022-11-16 14:43:41.860513 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 730 finished
---------------------------------------  ----------------
epoch                                       730
total_step                               735000
replay_pool/size                         735000
trainer/alpha                                 0.0636481
trainer/alpha_loss                           -1.25236
trainer/entropy                              -5.54529
trainer/qf_loss                               7.64368
trainer/state_noise                           0.005
trainer/policy_loss                        -220.997
trainer/policy_loss_without_entropy         223.016
trainer/entropy_penalty                      -0.352947
trainer/entropy_percentage                   -0.00158261
trainer/Q1Pred Mean                         222.62
trainer/Q1Pred Std                           72.3011
trainer/Q1Pred Max                          304.401
trainer/Q1Pred Min                            2.78095
trainer/Q2Pred Mean                         222.105
trainer/Q2Pred Std                           72.4188
trainer/Q2Pred Max                          307.341
trainer/Q2Pred Min                            4.97102
trainer/QTargetWithReg Mean                 222.948
trainer/QTargetWithReg Std                   72.4179
trainer/QTargetWithReg Max                  305.643
trainer/QTargetWithReg Min                    3.98187
trainer/PolicyLossWithoutReg Mean           223.016
trainer/PolicyLossWithoutReg Std             71.9352
trainer/PolicyLossWithoutReg Max            305.365
trainer/PolicyLossWithoutReg Min              4.78867
trainer/gradient_norm                       333.376
trainer/gradient_penalty                     -1.66688
trainer/gradient_percentage                  -0.00747424
exploration/num steps total              735000
exploration/num paths total                1895
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91932
exploration/Rewards Std                       1.29405
exploration/Rewards Max                      10.2066
exploration/Rewards Min                      -0.415964
exploration/Returns Mean                   4919.32
exploration/Returns Std                       0
exploration/Returns Max                    4919.32
exploration/Returns Min                    4919.32
exploration/Num Paths                         1
exploration/Average Returns                4919.32
evaluation_0/num steps total                  5.75706e+06
evaluation_0/num paths total              13912
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86282
evaluation_0/Rewards Std                      1.25498
evaluation_0/Rewards Max                     10.3181
evaluation_0/Rewards Min                     -0.506127
evaluation_0/Returns Mean                  4862.82
evaluation_0/Returns Std                     48.4875
evaluation_0/Returns Max                   4923.22
evaluation_0/Returns Min                   4773.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4862.82
time/epoch (s)                                0
time/total (s)                            14275.6
Epoch                                       730
---------------------------------------  ----------------
2022-11-16 14:43:57.661761 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 731 finished
---------------------------------------  ----------------
epoch                                       731
total_step                               736000
replay_pool/size                         736000
trainer/alpha                                 0.0637022
trainer/alpha_loss                           -0.744117
trainer/entropy                              -5.72974
trainer/qf_loss                               4.78996
trainer/state_noise                           0.005
trainer/policy_loss                        -229.386
trainer/policy_loss_without_entropy         231.549
trainer/entropy_penalty                      -0.364997
trainer/entropy_percentage                   -0.00157633
trainer/Q1Pred Mean                         231.676
trainer/Q1Pred Std                           68.8101
trainer/Q1Pred Max                          311.305
trainer/Q1Pred Min                           14.6849
trainer/Q2Pred Mean                         231.224
trainer/Q2Pred Std                           69.0481
trainer/Q2Pred Max                          312.166
trainer/Q2Pred Min                           15.3958
trainer/QTargetWithReg Mean                 231.137
trainer/QTargetWithReg Std                   68.6527
trainer/QTargetWithReg Max                  312.588
trainer/QTargetWithReg Min                   17.6031
trainer/PolicyLossWithoutReg Mean           231.549
trainer/PolicyLossWithoutReg Std             68.0527
trainer/PolicyLossWithoutReg Max            309.667
trainer/PolicyLossWithoutReg Min             14.5493
trainer/gradient_norm                       359.715
trainer/gradient_penalty                     -1.79858
trainer/gradient_percentage                  -0.00776757
exploration/num steps total              736000
exploration/num paths total                1896
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.78452
exploration/Rewards Std                       1.26594
exploration/Rewards Max                      10.0599
exploration/Rewards Min                      -0.464154
exploration/Returns Mean                   4784.52
exploration/Returns Std                       0
exploration/Returns Max                    4784.52
exploration/Returns Min                    4784.52
exploration/Num Paths                         1
exploration/Average Returns                4784.52
evaluation_0/num steps total                  5.76506e+06
evaluation_0/num paths total              13920
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01073
evaluation_0/Rewards Std                      1.32396
evaluation_0/Rewards Max                     10.4176
evaluation_0/Rewards Min                     -0.47575
evaluation_0/Returns Mean                  5010.73
evaluation_0/Returns Std                     25.764
evaluation_0/Returns Max                   5047.74
evaluation_0/Returns Min                   4959.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5010.73
time/epoch (s)                                0
time/total (s)                            14291.4
Epoch                                       731
---------------------------------------  ----------------
2022-11-16 14:44:13.924308 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 732 finished
---------------------------------------  ----------------
epoch                                       732
total_step                               737000
replay_pool/size                         737000
trainer/alpha                                 0.0630562
trainer/alpha_loss                            0.212448
trainer/entropy                              -6.07687
trainer/qf_loss                               8.62142
trainer/state_noise                           0.005
trainer/policy_loss                        -217.844
trainer/policy_loss_without_entropy         219.998
trainer/entropy_penalty                      -0.383184
trainer/entropy_percentage                   -0.00174176
trainer/Q1Pred Mean                         219.4
trainer/Q1Pred Std                           74.5118
trainer/Q1Pred Max                          310.288
trainer/Q1Pred Min                            6.08798
trainer/Q2Pred Mean                         219.335
trainer/Q2Pred Std                           74.6356
trainer/Q2Pred Max                          308.094
trainer/Q2Pred Min                            0.709306
trainer/QTargetWithReg Mean                 219.431
trainer/QTargetWithReg Std                   74.6743
trainer/QTargetWithReg Max                  309.984
trainer/QTargetWithReg Min                    5.53149
trainer/PolicyLossWithoutReg Mean           219.998
trainer/PolicyLossWithoutReg Std             73.5131
trainer/PolicyLossWithoutReg Max            308.42
trainer/PolicyLossWithoutReg Min              5.74336
trainer/gradient_norm                       354.135
trainer/gradient_penalty                     -1.77067
trainer/gradient_percentage                  -0.00804859
exploration/num steps total              737000
exploration/num paths total                1897
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97427
exploration/Rewards Std                       1.31798
exploration/Rewards Max                      10.3944
exploration/Rewards Min                      -0.358536
exploration/Returns Mean                   4974.27
exploration/Returns Std                       0
exploration/Returns Max                    4974.27
exploration/Returns Min                    4974.27
exploration/Num Paths                         1
exploration/Average Returns                4974.27
evaluation_0/num steps total                  5.77306e+06
evaluation_0/num paths total              13928
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.931
evaluation_0/Rewards Std                      1.25553
evaluation_0/Rewards Max                     10.2573
evaluation_0/Rewards Min                     -0.522278
evaluation_0/Returns Mean                  4931
evaluation_0/Returns Std                     26.1397
evaluation_0/Returns Max                   4964.59
evaluation_0/Returns Min                   4881.37
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4931
time/epoch (s)                                0
time/total (s)                            14307.7
Epoch                                       732
---------------------------------------  ----------------
2022-11-16 14:44:29.921804 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 733 finished
---------------------------------------  ----------------
epoch                                       733
total_step                               738000
replay_pool/size                         738000
trainer/alpha                                 0.0657452
trainer/alpha_loss                           -0.12776
trainer/entropy                              -5.95306
trainer/qf_loss                              10.9322
trainer/state_noise                           0.005
trainer/policy_loss                        -221.154
trainer/policy_loss_without_entropy         223.284
trainer/entropy_penalty                      -0.391385
trainer/entropy_percentage                   -0.00175286
trainer/Q1Pred Mean                         222.566
trainer/Q1Pred Std                           74.4845
trainer/Q1Pred Max                          312.734
trainer/Q1Pred Min                           -1.93788
trainer/Q2Pred Mean                         222.024
trainer/Q2Pred Std                           74.5114
trainer/Q2Pred Max                          312.595
trainer/Q2Pred Min                            0.101962
trainer/QTargetWithReg Mean                 223.053
trainer/QTargetWithReg Std                   74.8925
trainer/QTargetWithReg Max                  313.202
trainer/QTargetWithReg Min                   -2.00986
trainer/PolicyLossWithoutReg Mean           223.284
trainer/PolicyLossWithoutReg Std             73.9036
trainer/PolicyLossWithoutReg Max            312.53
trainer/PolicyLossWithoutReg Min              0.938461
trainer/gradient_norm                       347.616
trainer/gradient_penalty                     -1.73808
trainer/gradient_percentage                  -0.00778419
exploration/num steps total              738000
exploration/num paths total                1898
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94514
exploration/Rewards Std                       1.28604
exploration/Rewards Max                      10.1282
exploration/Rewards Min                      -0.515184
exploration/Returns Mean                   4945.14
exploration/Returns Std                       0
exploration/Returns Max                    4945.14
exploration/Returns Min                    4945.14
exploration/Num Paths                         1
exploration/Average Returns                4945.14
evaluation_0/num steps total                  5.78106e+06
evaluation_0/num paths total              13936
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98014
evaluation_0/Rewards Std                      1.32427
evaluation_0/Rewards Max                     10.3846
evaluation_0/Rewards Min                     -0.592168
evaluation_0/Returns Mean                  4980.14
evaluation_0/Returns Std                     38.7452
evaluation_0/Returns Max                   5047.83
evaluation_0/Returns Min                   4939.38
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4980.14
time/epoch (s)                                0
time/total (s)                            14323.7
Epoch                                       733
---------------------------------------  ----------------
2022-11-16 14:44:45.794362 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 734 finished
---------------------------------------  ----------------
epoch                                       734
total_step                               739000
replay_pool/size                         739000
trainer/alpha                                 0.0675266
trainer/alpha_loss                           -0.281284
trainer/entropy                              -5.89564
trainer/qf_loss                               6.87854
trainer/state_noise                           0.005
trainer/policy_loss                        -229.385
trainer/policy_loss_without_entropy         231.519
trainer/entropy_penalty                      -0.398112
trainer/entropy_percentage                   -0.00171957
trainer/Q1Pred Mean                         231.117
trainer/Q1Pred Std                           71.0474
trainer/Q1Pred Max                          310.252
trainer/Q1Pred Min                           16.0523
trainer/Q2Pred Mean                         230.608
trainer/Q2Pred Std                           71.0505
trainer/Q2Pred Max                          311.232
trainer/Q2Pred Min                           11.1981
trainer/QTargetWithReg Mean                 230.731
trainer/QTargetWithReg Std                   71.2811
trainer/QTargetWithReg Max                  313.267
trainer/QTargetWithReg Min                   14.981
trainer/PolicyLossWithoutReg Mean           231.519
trainer/PolicyLossWithoutReg Std             70.553
trainer/PolicyLossWithoutReg Max            311.755
trainer/PolicyLossWithoutReg Min             17.4333
trainer/gradient_norm                       347.178
trainer/gradient_penalty                     -1.73589
trainer/gradient_percentage                  -0.00749784
exploration/num steps total              739000
exploration/num paths total                1899
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88445
exploration/Rewards Std                       1.30383
exploration/Rewards Max                      10.0235
exploration/Rewards Min                      -0.569893
exploration/Returns Mean                   4884.45
exploration/Returns Std                       0
exploration/Returns Max                    4884.45
exploration/Returns Min                    4884.45
exploration/Num Paths                         1
exploration/Average Returns                4884.45
evaluation_0/num steps total                  5.78906e+06
evaluation_0/num paths total              13944
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09438
evaluation_0/Rewards Std                      1.30251
evaluation_0/Rewards Max                     10.3044
evaluation_0/Rewards Min                     -0.552968
evaluation_0/Returns Mean                  5094.38
evaluation_0/Returns Std                     25.3929
evaluation_0/Returns Max                   5140.14
evaluation_0/Returns Min                   5070.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5094.38
time/epoch (s)                                0
time/total (s)                            14339.5
Epoch                                       734
---------------------------------------  ----------------
2022-11-16 14:45:02.383718 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 735 finished
---------------------------------------  ----------------
epoch                                       735
total_step                               740000
replay_pool/size                         740000
trainer/alpha                                 0.0667056
trainer/alpha_loss                           -0.436835
trainer/entropy                              -5.83864
trainer/qf_loss                               6.37345
trainer/state_noise                           0.005
trainer/policy_loss                        -222.416
trainer/policy_loss_without_entropy         224.583
trainer/entropy_penalty                      -0.38947
trainer/entropy_percentage                   -0.00173419
trainer/Q1Pred Mean                         224.012
trainer/Q1Pred Std                           72.8003
trainer/Q1Pred Max                          310.579
trainer/Q1Pred Min                            8.91167
trainer/Q2Pred Mean                         223.563
trainer/Q2Pred Std                           72.8831
trainer/Q2Pred Max                          311.359
trainer/Q2Pred Min                            8.51747
trainer/QTargetWithReg Mean                 223.569
trainer/QTargetWithReg Std                   73.0982
trainer/QTargetWithReg Max                  310.026
trainer/QTargetWithReg Min                    8.00534
trainer/PolicyLossWithoutReg Mean           224.583
trainer/PolicyLossWithoutReg Std             72.1428
trainer/PolicyLossWithoutReg Max            310.927
trainer/PolicyLossWithoutReg Min              8.40597
trainer/gradient_norm                       355.419
trainer/gradient_penalty                     -1.7771
trainer/gradient_percentage                  -0.00791288
exploration/num steps total              740000
exploration/num paths total                1900
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04051
exploration/Rewards Std                       1.31207
exploration/Rewards Max                      10.1265
exploration/Rewards Min                      -0.440627
exploration/Returns Mean                   5040.51
exploration/Returns Std                       0
exploration/Returns Max                    5040.51
exploration/Returns Min                    5040.51
exploration/Num Paths                         1
exploration/Average Returns                5040.51
evaluation_0/num steps total                  5.79706e+06
evaluation_0/num paths total              13952
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.94121
evaluation_0/Rewards Std                      1.34334
evaluation_0/Rewards Max                     10.3342
evaluation_0/Rewards Min                     -0.604818
evaluation_0/Returns Mean                  4941.21
evaluation_0/Returns Std                     22.9595
evaluation_0/Returns Max                   4974.15
evaluation_0/Returns Min                   4910.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4941.21
time/epoch (s)                                0
time/total (s)                            14356.1
Epoch                                       735
---------------------------------------  ----------------
2022-11-16 14:45:18.223410 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 736 finished
---------------------------------------  ----------------
epoch                                       736
total_step                               741000
replay_pool/size                         741000
trainer/alpha                                 0.0640756
trainer/alpha_loss                           -0.907113
trainer/entropy                              -5.66985
trainer/qf_loss                               6.66947
trainer/state_noise                           0.005
trainer/policy_loss                        -226.486
trainer/policy_loss_without_entropy         228.589
trainer/entropy_penalty                      -0.363299
trainer/entropy_percentage                   -0.00158931
trainer/Q1Pred Mean                         227.95
trainer/Q1Pred Std                           68.3799
trainer/Q1Pred Max                          310.708
trainer/Q1Pred Min                           -2.78233
trainer/Q2Pred Mean                         227.981
trainer/Q2Pred Std                           68.0889
trainer/Q2Pred Max                          313.119
trainer/Q2Pred Min                           -7.23401
trainer/QTargetWithReg Mean                 227.876
trainer/QTargetWithReg Std                   68.0235
trainer/QTargetWithReg Max                  311.981
trainer/QTargetWithReg Min                   -0.737965
trainer/PolicyLossWithoutReg Mean           228.589
trainer/PolicyLossWithoutReg Std             66.8644
trainer/PolicyLossWithoutReg Max            310.144
trainer/PolicyLossWithoutReg Min              6.66136
trainer/gradient_norm                       347.961
trainer/gradient_penalty                     -1.7398
trainer/gradient_percentage                  -0.00761105
exploration/num steps total              741000
exploration/num paths total                1901
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99657
exploration/Rewards Std                       1.38139
exploration/Rewards Max                      10.5237
exploration/Rewards Min                      -0.584443
exploration/Returns Mean                   4996.57
exploration/Returns Std                       0
exploration/Returns Max                    4996.57
exploration/Returns Min                    4996.57
exploration/Num Paths                         1
exploration/Average Returns                4996.57
evaluation_0/num steps total                  5.80506e+06
evaluation_0/num paths total              13960
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92022
evaluation_0/Rewards Std                      1.31834
evaluation_0/Rewards Max                     10.1681
evaluation_0/Rewards Min                     -0.461154
evaluation_0/Returns Mean                  4920.22
evaluation_0/Returns Std                     81.6577
evaluation_0/Returns Max                   5025.13
evaluation_0/Returns Min                   4774.05
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4920.22
time/epoch (s)                                0
time/total (s)                            14371.9
Epoch                                       736
---------------------------------------  ----------------
2022-11-16 14:45:34.627707 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 737 finished
---------------------------------------  ----------------
epoch                                       737
total_step                               742000
replay_pool/size                         742000
trainer/alpha                                 0.0644306
trainer/alpha_loss                           -1.25122
trainer/entropy                              -5.54368
trainer/qf_loss                               6.3298
trainer/state_noise                           0.005
trainer/policy_loss                        -219.68
trainer/policy_loss_without_entropy         221.772
trainer/entropy_penalty                      -0.357183
trainer/entropy_percentage                   -0.00161059
trainer/Q1Pred Mean                         221.463
trainer/Q1Pred Std                           70.2893
trainer/Q1Pred Max                          305.201
trainer/Q1Pred Min                           18.9796
trainer/Q2Pred Mean                         221.916
trainer/Q2Pred Std                           70.5636
trainer/Q2Pred Max                          306.074
trainer/Q2Pred Min                           18.4003
trainer/QTargetWithReg Mean                 221.752
trainer/QTargetWithReg Std                   70.4426
trainer/QTargetWithReg Max                  306.646
trainer/QTargetWithReg Min                   17.6052
trainer/PolicyLossWithoutReg Mean           221.772
trainer/PolicyLossWithoutReg Std             69.8539
trainer/PolicyLossWithoutReg Max            307.119
trainer/PolicyLossWithoutReg Min             19.2341
trainer/gradient_norm                       346.99
trainer/gradient_penalty                     -1.73495
trainer/gradient_percentage                  -0.00782312
exploration/num steps total              742000
exploration/num paths total                1902
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94693
exploration/Rewards Std                       1.3264
exploration/Rewards Max                      10.2042
exploration/Rewards Min                      -0.378335
exploration/Returns Mean                   4946.93
exploration/Returns Std                       0
exploration/Returns Max                    4946.93
exploration/Returns Min                    4946.93
exploration/Num Paths                         1
exploration/Average Returns                4946.93
evaluation_0/num steps total                  5.81306e+06
evaluation_0/num paths total              13968
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95344
evaluation_0/Rewards Std                      1.33873
evaluation_0/Rewards Max                     10.3552
evaluation_0/Rewards Min                     -0.619601
evaluation_0/Returns Mean                  4953.44
evaluation_0/Returns Std                     52.8363
evaluation_0/Returns Max                   5026.15
evaluation_0/Returns Min                   4872.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4953.44
time/epoch (s)                                0
time/total (s)                            14388.4
Epoch                                       737
---------------------------------------  ----------------
2022-11-16 14:45:50.544023 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 738 finished
---------------------------------------  ----------------
epoch                                       738
total_step                               743000
replay_pool/size                         743000
trainer/alpha                                 0.0639283
trainer/alpha_loss                           -0.0524579
trainer/entropy                              -5.98092
trainer/qf_loss                               8.49573
trainer/state_noise                           0.005
trainer/policy_loss                        -224.492
trainer/policy_loss_without_entropy         226.609
trainer/entropy_penalty                      -0.382351
trainer/entropy_percentage                   -0.00168727
trainer/Q1Pred Mean                         225.979
trainer/Q1Pred Std                           73.7618
trainer/Q1Pred Max                          308.196
trainer/Q1Pred Min                           11.9806
trainer/Q2Pred Mean                         226.005
trainer/Q2Pred Std                           73.9634
trainer/Q2Pred Max                          309.215
trainer/Q2Pred Min                           12.4831
trainer/QTargetWithReg Mean                 226.566
trainer/QTargetWithReg Std                   73.9828
trainer/QTargetWithReg Max                  308.993
trainer/QTargetWithReg Min                   13.5416
trainer/PolicyLossWithoutReg Mean           226.609
trainer/PolicyLossWithoutReg Std             72.944
trainer/PolicyLossWithoutReg Max            307.45
trainer/PolicyLossWithoutReg Min             16.1654
trainer/gradient_norm                       346.831
trainer/gradient_penalty                     -1.73416
trainer/gradient_percentage                  -0.00765265
exploration/num steps total              743000
exploration/num paths total                1903
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89806
exploration/Rewards Std                       1.35487
exploration/Rewards Max                      10.2563
exploration/Rewards Min                      -0.539175
exploration/Returns Mean                   4898.06
exploration/Returns Std                       0
exploration/Returns Max                    4898.06
exploration/Returns Min                    4898.06
exploration/Num Paths                         1
exploration/Average Returns                4898.06
evaluation_0/num steps total                  5.82106e+06
evaluation_0/num paths total              13976
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06923
evaluation_0/Rewards Std                      1.30169
evaluation_0/Rewards Max                     10.4261
evaluation_0/Rewards Min                     -0.473377
evaluation_0/Returns Mean                  5069.23
evaluation_0/Returns Std                     19.1042
evaluation_0/Returns Max                   5106.51
evaluation_0/Returns Min                   5051.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5069.23
time/epoch (s)                                0
time/total (s)                            14404.3
Epoch                                       738
---------------------------------------  ----------------
2022-11-16 14:46:06.485082 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 739 finished
---------------------------------------  ----------------
epoch                                       739
total_step                               744000
replay_pool/size                         744000
trainer/alpha                                 0.0645886
trainer/alpha_loss                            1.66551
trainer/entropy                              -6.6079
trainer/qf_loss                               7.49536
trainer/state_noise                           0.005
trainer/policy_loss                        -221.746
trainer/policy_loss_without_entropy         223.934
trainer/entropy_penalty                      -0.426795
trainer/entropy_percentage                   -0.0019059
trainer/Q1Pred Mean                         223.226
trainer/Q1Pred Std                           74.7305
trainer/Q1Pred Max                          310.898
trainer/Q1Pred Min                           -6.98738
trainer/Q2Pred Mean                         223.155
trainer/Q2Pred Std                           74.6548
trainer/Q2Pred Max                          312.543
trainer/Q2Pred Min                           -5.51847
trainer/QTargetWithReg Mean                 222.777
trainer/QTargetWithReg Std                   74.5026
trainer/QTargetWithReg Max                  310.997
trainer/QTargetWithReg Min                   -0.238988
trainer/PolicyLossWithoutReg Mean           223.934
trainer/PolicyLossWithoutReg Std             73.3603
trainer/PolicyLossWithoutReg Max            312.189
trainer/PolicyLossWithoutReg Min              1.59934
trainer/gradient_norm                       352.147
trainer/gradient_penalty                     -1.76074
trainer/gradient_percentage                  -0.00786277
exploration/num steps total              744000
exploration/num paths total                1904
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02991
exploration/Rewards Std                       1.31275
exploration/Rewards Max                      10.4865
exploration/Rewards Min                      -0.377763
exploration/Returns Mean                   5029.91
exploration/Returns Std                       0
exploration/Returns Max                    5029.91
exploration/Returns Min                    5029.91
exploration/Num Paths                         1
exploration/Average Returns                5029.91
evaluation_0/num steps total                  5.82906e+06
evaluation_0/num paths total              13984
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17661
evaluation_0/Rewards Std                      1.34981
evaluation_0/Rewards Max                     10.5305
evaluation_0/Rewards Min                     -0.480879
evaluation_0/Returns Mean                  5176.61
evaluation_0/Returns Std                     26.0901
evaluation_0/Returns Max                   5208.41
evaluation_0/Returns Min                   5134.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5176.61
time/epoch (s)                                0
time/total (s)                            14420.2
Epoch                                       739
---------------------------------------  ----------------
2022-11-16 14:46:22.741505 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 740 finished
---------------------------------------  ----------------
epoch                                       740
total_step                               745000
replay_pool/size                         745000
trainer/alpha                                 0.0644823
trainer/alpha_loss                           -0.494562
trainer/entropy                              -5.81959
trainer/qf_loss                               7.07274
trainer/state_noise                           0.005
trainer/policy_loss                        -226.167
trainer/policy_loss_without_entropy         228.312
trainer/entropy_penalty                      -0.37526
trainer/entropy_percentage                   -0.00164363
trainer/Q1Pred Mean                         227.904
trainer/Q1Pred Std                           75.8703
trainer/Q1Pred Max                          312.949
trainer/Q1Pred Min                            3.46314
trainer/Q2Pred Mean                         228.607
trainer/Q2Pred Std                           75.8477
trainer/Q2Pred Max                          315.7
trainer/Q2Pred Min                            3.55159
trainer/QTargetWithReg Mean                 227.587
trainer/QTargetWithReg Std                   75.6029
trainer/QTargetWithReg Max                  314.3
trainer/QTargetWithReg Min                    2.71261
trainer/PolicyLossWithoutReg Mean           228.312
trainer/PolicyLossWithoutReg Std             74.9723
trainer/PolicyLossWithoutReg Max            314.751
trainer/PolicyLossWithoutReg Min              3.3499
trainer/gradient_norm                       353.874
trainer/gradient_penalty                     -1.76937
trainer/gradient_percentage                  -0.00774979
exploration/num steps total              745000
exploration/num paths total                1905
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01087
exploration/Rewards Std                       1.31544
exploration/Rewards Max                      10.0773
exploration/Rewards Min                      -0.609725
exploration/Returns Mean                   5010.87
exploration/Returns Std                       0
exploration/Returns Max                    5010.87
exploration/Returns Min                    5010.87
exploration/Num Paths                         1
exploration/Average Returns                5010.87
evaluation_0/num steps total                  5.83706e+06
evaluation_0/num paths total              13992
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1348
evaluation_0/Rewards Std                      1.3113
evaluation_0/Rewards Max                     10.3933
evaluation_0/Rewards Min                     -0.432917
evaluation_0/Returns Mean                  5134.8
evaluation_0/Returns Std                     27.8469
evaluation_0/Returns Max                   5197.57
evaluation_0/Returns Min                   5109.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5134.8
time/epoch (s)                                0
time/total (s)                            14436.5
Epoch                                       740
---------------------------------------  ----------------
2022-11-16 14:46:38.571849 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 741 finished
---------------------------------------  ----------------
epoch                                       741
total_step                               746000
replay_pool/size                         746000
trainer/alpha                                 0.0646559
trainer/alpha_loss                           -0.147396
trainer/entropy                              -5.94618
trainer/qf_loss                               6.29165
trainer/state_noise                           0.005
trainer/policy_loss                        -224.868
trainer/policy_loss_without_entropy         227
trainer/entropy_penalty                      -0.384456
trainer/entropy_percentage                   -0.00169364
trainer/Q1Pred Mean                         226.935
trainer/Q1Pred Std                           70.1275
trainer/Q1Pred Max                          311.351
trainer/Q1Pred Min                           16.8192
trainer/Q2Pred Mean                         226.571
trainer/Q2Pred Std                           70.2894
trainer/Q2Pred Max                          310.942
trainer/Q2Pred Min                           17.6383
trainer/QTargetWithReg Mean                 226.528
trainer/QTargetWithReg Std                   70.6518
trainer/QTargetWithReg Max                  310.598
trainer/QTargetWithReg Min                   15.7047
trainer/PolicyLossWithoutReg Mean           227
trainer/PolicyLossWithoutReg Std             69.5338
trainer/PolicyLossWithoutReg Max            311.025
trainer/PolicyLossWithoutReg Min             18.0466
trainer/gradient_norm                       349.473
trainer/gradient_penalty                     -1.74737
trainer/gradient_percentage                  -0.00769764
exploration/num steps total              746000
exploration/num paths total                1906
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00031
exploration/Rewards Std                       1.33241
exploration/Rewards Max                      10.7691
exploration/Rewards Min                      -0.396562
exploration/Returns Mean                   5000.31
exploration/Returns Std                       0
exploration/Returns Max                    5000.31
exploration/Returns Min                    5000.31
exploration/Num Paths                         1
exploration/Average Returns                5000.31
evaluation_0/num steps total                  5.84506e+06
evaluation_0/num paths total              14000
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15194
evaluation_0/Rewards Std                      1.25642
evaluation_0/Rewards Max                     10.0304
evaluation_0/Rewards Min                     -0.401813
evaluation_0/Returns Mean                  5151.94
evaluation_0/Returns Std                     10.3774
evaluation_0/Returns Max                   5160.88
evaluation_0/Returns Min                   5129.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5151.94
time/epoch (s)                                0
time/total (s)                            14452.3
Epoch                                       741
---------------------------------------  ----------------
2022-11-16 14:46:55.022753 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 742 finished
---------------------------------------  ----------------
epoch                                       742
total_step                               747000
replay_pool/size                         747000
trainer/alpha                                 0.0665576
trainer/alpha_loss                            0.461829
trainer/entropy                              -6.17042
trainer/qf_loss                               9.86873
trainer/state_noise                           0.005
trainer/policy_loss                        -229.315
trainer/policy_loss_without_entropy         231.47
trainer/entropy_penalty                      -0.410689
trainer/entropy_percentage                   -0.00177426
trainer/Q1Pred Mean                         231.164
trainer/Q1Pred Std                           71.4091
trainer/Q1Pred Max                          318.483
trainer/Q1Pred Min                           12.973
trainer/Q2Pred Mean                         230.911
trainer/Q2Pred Std                           71.6515
trainer/Q2Pred Max                          319.148
trainer/Q2Pred Min                            9.32929
trainer/QTargetWithReg Mean                 231.141
trainer/QTargetWithReg Std                   71.5048
trainer/QTargetWithReg Max                  318.727
trainer/QTargetWithReg Min                   10.6264
trainer/PolicyLossWithoutReg Mean           231.47
trainer/PolicyLossWithoutReg Std             70.228
trainer/PolicyLossWithoutReg Max            317.444
trainer/PolicyLossWithoutReg Min             10.0029
trainer/gradient_norm                       348.81
trainer/gradient_penalty                     -1.74405
trainer/gradient_percentage                  -0.00753468
exploration/num steps total              747000
exploration/num paths total                1907
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94815
exploration/Rewards Std                       1.30628
exploration/Rewards Max                      10.8478
exploration/Rewards Min                      -0.344453
exploration/Returns Mean                   4948.15
exploration/Returns Std                       0
exploration/Returns Max                    4948.15
exploration/Returns Min                    4948.15
exploration/Num Paths                         1
exploration/Average Returns                4948.15
evaluation_0/num steps total                  5.85306e+06
evaluation_0/num paths total              14008
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04764
evaluation_0/Rewards Std                      1.31135
evaluation_0/Rewards Max                     10.4126
evaluation_0/Rewards Min                     -0.405761
evaluation_0/Returns Mean                  5047.64
evaluation_0/Returns Std                     16.8
evaluation_0/Returns Max                   5074.14
evaluation_0/Returns Min                   5021.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5047.64
time/epoch (s)                                0
time/total (s)                            14468.7
Epoch                                       742
---------------------------------------  ----------------
2022-11-16 14:47:10.843720 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 743 finished
---------------------------------------  ----------------
epoch                                       743
total_step                               748000
replay_pool/size                         748000
trainer/alpha                                 0.0637545
trainer/alpha_loss                            2.62723
trainer/entropy                              -6.95433
trainer/qf_loss                               9.48719
trainer/state_noise                           0.005
trainer/policy_loss                        -222.358
trainer/policy_loss_without_entropy         224.546
trainer/entropy_penalty                      -0.44337
trainer/entropy_percentage                   -0.00197452
trainer/Q1Pred Mean                         223.461
trainer/Q1Pred Std                           73.7624
trainer/Q1Pred Max                          315.478
trainer/Q1Pred Min                           16.6705
trainer/Q2Pred Mean                         223.495
trainer/Q2Pred Std                           73.8068
trainer/Q2Pred Max                          315.498
trainer/Q2Pred Min                           19.3049
trainer/QTargetWithReg Mean                 223.796
trainer/QTargetWithReg Std                   73.9852
trainer/QTargetWithReg Max                  315.37
trainer/QTargetWithReg Min                   13.6594
trainer/PolicyLossWithoutReg Mean           224.546
trainer/PolicyLossWithoutReg Std             73.0406
trainer/PolicyLossWithoutReg Max            316.009
trainer/PolicyLossWithoutReg Min             17.8325
trainer/gradient_norm                       348.805
trainer/gradient_penalty                     -1.74402
trainer/gradient_percentage                  -0.00776691
exploration/num steps total              748000
exploration/num paths total                1908
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06534
exploration/Rewards Std                       1.32345
exploration/Rewards Max                      10.921
exploration/Rewards Min                      -0.375849
exploration/Returns Mean                   5065.34
exploration/Returns Std                       0
exploration/Returns Max                    5065.34
exploration/Returns Min                    5065.34
exploration/Num Paths                         1
exploration/Average Returns                5065.34
evaluation_0/num steps total                  5.86106e+06
evaluation_0/num paths total              14016
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10808
evaluation_0/Rewards Std                      1.31506
evaluation_0/Rewards Max                     10.4917
evaluation_0/Rewards Min                     -0.406525
evaluation_0/Returns Mean                  5108.08
evaluation_0/Returns Std                     21.4657
evaluation_0/Returns Max                   5127.67
evaluation_0/Returns Min                   5059.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5108.08
time/epoch (s)                                0
time/total (s)                            14484.6
Epoch                                       743
---------------------------------------  ----------------
2022-11-16 14:47:27.161487 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 744 finished
---------------------------------------  ----------------
epoch                                       744
total_step                               749000
replay_pool/size                         749000
trainer/alpha                                 0.0648427
trainer/alpha_loss                            0.784709
trainer/entropy                              -6.28682
trainer/qf_loss                               6.48772
trainer/state_noise                           0.005
trainer/policy_loss                        -220.712
trainer/policy_loss_without_entropy         222.924
trainer/entropy_penalty                      -0.407655
trainer/entropy_percentage                   -0.00182867
trainer/Q1Pred Mean                         222.039
trainer/Q1Pred Std                           73.6035
trainer/Q1Pred Max                          313.014
trainer/Q1Pred Min                           -3.22706
trainer/Q2Pred Mean                         222.409
trainer/Q2Pred Std                           73.7734
trainer/Q2Pred Max                          315.021
trainer/Q2Pred Min                           -3.95719
trainer/QTargetWithReg Mean                 221.781
trainer/QTargetWithReg Std                   73.8233
trainer/QTargetWithReg Max                  314.94
trainer/QTargetWithReg Min                   -0.645184
trainer/PolicyLossWithoutReg Mean           222.924
trainer/PolicyLossWithoutReg Std             72.1637
trainer/PolicyLossWithoutReg Max            313.718
trainer/PolicyLossWithoutReg Min              9.46812
trainer/gradient_norm                       360.918
trainer/gradient_penalty                     -1.80459
trainer/gradient_percentage                  -0.00809508
exploration/num steps total              749000
exploration/num paths total                1909
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99071
exploration/Rewards Std                       1.30947
exploration/Rewards Max                      10.2091
exploration/Rewards Min                      -0.492579
exploration/Returns Mean                   4990.71
exploration/Returns Std                       0
exploration/Returns Max                    4990.71
exploration/Returns Min                    4990.71
exploration/Num Paths                         1
exploration/Average Returns                4990.71
evaluation_0/num steps total                  5.86906e+06
evaluation_0/num paths total              14024
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0361
evaluation_0/Rewards Std                      1.26868
evaluation_0/Rewards Max                     10.2689
evaluation_0/Rewards Min                     -0.466847
evaluation_0/Returns Mean                  5036.1
evaluation_0/Returns Std                      8.31009
evaluation_0/Returns Max                   5049.87
evaluation_0/Returns Min                   5018.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5036.1
time/epoch (s)                                0
time/total (s)                            14500.9
Epoch                                       744
---------------------------------------  ----------------
2022-11-16 14:47:43.140029 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 745 finished
---------------------------------------  ----------------
epoch                                       745
total_step                               750000
replay_pool/size                         750000
trainer/alpha                                 0.0638429
trainer/alpha_loss                            0.326606
trainer/entropy                              -6.1187
trainer/qf_loss                               8.39037
trainer/state_noise                           0.005
trainer/policy_loss                        -228.023
trainer/policy_loss_without_entropy         230.17
trainer/entropy_penalty                      -0.390636
trainer/entropy_percentage                   -0.00169716
trainer/Q1Pred Mean                         229.751
trainer/Q1Pred Std                           69.6805
trainer/Q1Pred Max                          310.72
trainer/Q1Pred Min                           -0.396337
trainer/Q2Pred Mean                         229.911
trainer/Q2Pred Std                           69.684
trainer/Q2Pred Max                          309.894
trainer/Q2Pred Min                            3.28014
trainer/QTargetWithReg Mean                 229.177
trainer/QTargetWithReg Std                   69.8412
trainer/QTargetWithReg Max                  308.462
trainer/QTargetWithReg Min                   -1.00773
trainer/PolicyLossWithoutReg Mean           230.17
trainer/PolicyLossWithoutReg Std             68.9378
trainer/PolicyLossWithoutReg Max            309.198
trainer/PolicyLossWithoutReg Min              2.98536
trainer/gradient_norm                       351.151
trainer/gradient_penalty                     -1.75575
trainer/gradient_percentage                  -0.00762809
exploration/num steps total              750000
exploration/num paths total                1910
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09946
exploration/Rewards Std                       1.33023
exploration/Rewards Max                      10.2397
exploration/Rewards Min                      -0.356109
exploration/Returns Mean                   5099.46
exploration/Returns Std                       0
exploration/Returns Max                    5099.46
exploration/Returns Min                    5099.46
exploration/Num Paths                         1
exploration/Average Returns                5099.46
evaluation_0/num steps total                  5.87706e+06
evaluation_0/num paths total              14032
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16586
evaluation_0/Rewards Std                      1.35035
evaluation_0/Rewards Max                     10.5783
evaluation_0/Rewards Min                     -0.418728
evaluation_0/Returns Mean                  5165.86
evaluation_0/Returns Std                     18.75
evaluation_0/Returns Max                   5206.63
evaluation_0/Returns Min                   5137.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5165.86
time/epoch (s)                                0
time/total (s)                            14516.9
Epoch                                       745
---------------------------------------  ----------------
2022-11-16 14:47:58.815759 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 746 finished
---------------------------------------  ----------------
epoch                                       746
total_step                               751000
replay_pool/size                         751000
trainer/alpha                                 0.0633639
trainer/alpha_loss                           -0.0571576
trainer/entropy                              -5.97928
trainer/qf_loss                               6.56726
trainer/state_noise                           0.005
trainer/policy_loss                        -223.339
trainer/policy_loss_without_entropy         225.478
trainer/entropy_penalty                      -0.37887
trainer/entropy_percentage                   -0.0016803
trainer/Q1Pred Mean                         225.028
trainer/Q1Pred Std                           74.381
trainer/Q1Pred Max                          311.691
trainer/Q1Pred Min                           15.9303
trainer/Q2Pred Mean                         224.851
trainer/Q2Pred Std                           74.5031
trainer/Q2Pred Max                          309.757
trainer/Q2Pred Min                           13.3255
trainer/QTargetWithReg Mean                 224.766
trainer/QTargetWithReg Std                   75.1045
trainer/QTargetWithReg Max                  312.171
trainer/QTargetWithReg Min                   13.2626
trainer/PolicyLossWithoutReg Mean           225.478
trainer/PolicyLossWithoutReg Std             73.6092
trainer/PolicyLossWithoutReg Max            310.26
trainer/PolicyLossWithoutReg Min             16.7832
trainer/gradient_norm                       352.093
trainer/gradient_penalty                     -1.76046
trainer/gradient_percentage                  -0.0078077
exploration/num steps total              751000
exploration/num paths total                1911
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13664
exploration/Rewards Std                       1.33754
exploration/Rewards Max                      10.3438
exploration/Rewards Min                      -0.495848
exploration/Returns Mean                   5136.64
exploration/Returns Std                       0
exploration/Returns Max                    5136.64
exploration/Returns Min                    5136.64
exploration/Num Paths                         1
exploration/Average Returns                5136.64
evaluation_0/num steps total                  5.88506e+06
evaluation_0/num paths total              14040
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06341
evaluation_0/Rewards Std                      1.32058
evaluation_0/Rewards Max                     10.3516
evaluation_0/Rewards Min                     -0.475797
evaluation_0/Returns Mean                  5063.41
evaluation_0/Returns Std                     32.018
evaluation_0/Returns Max                   5099.79
evaluation_0/Returns Min                   4993.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5063.41
time/epoch (s)                                0
time/total (s)                            14532.5
Epoch                                       746
---------------------------------------  ----------------
2022-11-16 14:48:15.118104 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 747 finished
---------------------------------------  ----------------
epoch                                       747
total_step                               752000
replay_pool/size                         752000
trainer/alpha                                 0.0643226
trainer/alpha_loss                            0.699658
trainer/entropy                              -6.25499
trainer/qf_loss                               6.9615
trainer/state_noise                           0.005
trainer/policy_loss                        -225.168
trainer/policy_loss_without_entropy         227.392
trainer/entropy_penalty                      -0.402337
trainer/entropy_percentage                   -0.00176936
trainer/Q1Pred Mean                         226.744
trainer/Q1Pred Std                           71.1873
trainer/Q1Pred Max                          311.639
trainer/Q1Pred Min                           -8.92939
trainer/Q2Pred Mean                         226.882
trainer/Q2Pred Std                           71.5061
trainer/Q2Pred Max                          311.677
trainer/Q2Pred Min                           -5.99711
trainer/QTargetWithReg Mean                 226.657
trainer/QTargetWithReg Std                   71.2224
trainer/QTargetWithReg Max                  311.778
trainer/QTargetWithReg Min                   -9.74255
trainer/PolicyLossWithoutReg Mean           227.392
trainer/PolicyLossWithoutReg Std             70.8287
trainer/PolicyLossWithoutReg Max            310.82
trainer/PolicyLossWithoutReg Min             -6.53824
trainer/gradient_norm                       364.267
trainer/gradient_penalty                     -1.82134
trainer/gradient_percentage                  -0.00800968
exploration/num steps total              752000
exploration/num paths total                1912
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02385
exploration/Rewards Std                       1.33028
exploration/Rewards Max                      10.2576
exploration/Rewards Min                      -0.446264
exploration/Returns Mean                   5023.85
exploration/Returns Std                       0
exploration/Returns Max                    5023.85
exploration/Returns Min                    5023.85
exploration/Num Paths                         1
exploration/Average Returns                5023.85
evaluation_0/num steps total                  5.89306e+06
evaluation_0/num paths total              14048
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97114
evaluation_0/Rewards Std                      1.31769
evaluation_0/Rewards Max                     10.3883
evaluation_0/Rewards Min                     -0.477351
evaluation_0/Returns Mean                  4971.14
evaluation_0/Returns Std                     36.7708
evaluation_0/Returns Max                   5031.7
evaluation_0/Returns Min                   4926.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4971.14
time/epoch (s)                                0
time/total (s)                            14548.8
Epoch                                       747
---------------------------------------  ----------------
2022-11-16 14:48:30.909388 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 748 finished
---------------------------------------  ----------------
epoch                                       748
total_step                               753000
replay_pool/size                         753000
trainer/alpha                                 0.063706
trainer/alpha_loss                            1.25092
trainer/entropy                              -6.45429
trainer/qf_loss                               9.08573
trainer/state_noise                           0.005
trainer/policy_loss                        -227.937
trainer/policy_loss_without_entropy         230.178
trainer/entropy_penalty                      -0.411177
trainer/entropy_percentage                   -0.00178635
trainer/Q1Pred Mean                         228.923
trainer/Q1Pred Std                           65.587
trainer/Q1Pred Max                          308.299
trainer/Q1Pred Min                           -0.414023
trainer/Q2Pred Mean                         229.135
trainer/Q2Pred Std                           65.9282
trainer/Q2Pred Max                          306.274
trainer/Q2Pred Min                            7.68647
trainer/QTargetWithReg Mean                 228.843
trainer/QTargetWithReg Std                   65.3973
trainer/QTargetWithReg Max                  309.14
trainer/QTargetWithReg Min                    1.40898
trainer/PolicyLossWithoutReg Mean           230.178
trainer/PolicyLossWithoutReg Std             65.0532
trainer/PolicyLossWithoutReg Max            309.668
trainer/PolicyLossWithoutReg Min              0.433192
trainer/gradient_norm                       365.862
trainer/gradient_penalty                     -1.82931
trainer/gradient_percentage                  -0.00794738
exploration/num steps total              753000
exploration/num paths total                1913
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0456
exploration/Rewards Std                       1.32656
exploration/Rewards Max                      10.4055
exploration/Rewards Min                      -0.370439
exploration/Returns Mean                   5045.6
exploration/Returns Std                       0
exploration/Returns Max                    5045.6
exploration/Returns Min                    5045.6
exploration/Num Paths                         1
exploration/Average Returns                5045.6
evaluation_0/num steps total                  5.90106e+06
evaluation_0/num paths total              14056
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93788
evaluation_0/Rewards Std                      1.25792
evaluation_0/Rewards Max                     10.0771
evaluation_0/Rewards Min                     -0.419801
evaluation_0/Returns Mean                  4937.88
evaluation_0/Returns Std                     18.9167
evaluation_0/Returns Max                   4973.03
evaluation_0/Returns Min                   4907.19
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4937.88
time/epoch (s)                                0
time/total (s)                            14564.6
Epoch                                       748
---------------------------------------  ----------------
2022-11-16 14:48:47.362511 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 749 finished
---------------------------------------  ----------------
epoch                                       749
total_step                               754000
replay_pool/size                         754000
trainer/alpha                                 0.0640002
trainer/alpha_loss                           -0.149523
trainer/entropy                              -5.94561
trainer/qf_loss                               6.83545
trainer/state_noise                           0.005
trainer/policy_loss                        -226.292
trainer/policy_loss_without_entropy         228.383
trainer/entropy_penalty                      -0.38052
trainer/entropy_percentage                   -0.00166615
trainer/Q1Pred Mean                         227.877
trainer/Q1Pred Std                           72.4183
trainer/Q1Pred Max                          315.405
trainer/Q1Pred Min                            4.02631
trainer/Q2Pred Mean                         228.546
trainer/Q2Pred Std                           72.3555
trainer/Q2Pred Max                          314.855
trainer/Q2Pred Min                            5.34923
trainer/QTargetWithReg Mean                 227.857
trainer/QTargetWithReg Std                   72.3759
trainer/QTargetWithReg Max                  314.101
trainer/QTargetWithReg Min                    5.42112
trainer/PolicyLossWithoutReg Mean           228.383
trainer/PolicyLossWithoutReg Std             71.63
trainer/PolicyLossWithoutReg Max            315.402
trainer/PolicyLossWithoutReg Min              6.231
trainer/gradient_norm                       341.922
trainer/gradient_penalty                     -1.70961
trainer/gradient_percentage                  -0.00748572
exploration/num steps total              754000
exploration/num paths total                1914
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0017
exploration/Rewards Std                       1.30899
exploration/Rewards Max                      10.0266
exploration/Rewards Min                      -0.320322
exploration/Returns Mean                   5001.7
exploration/Returns Std                       0
exploration/Returns Max                    5001.7
exploration/Returns Min                    5001.7
exploration/Num Paths                         1
exploration/Average Returns                5001.7
evaluation_0/num steps total                  5.90906e+06
evaluation_0/num paths total              14064
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01777
evaluation_0/Rewards Std                      1.2571
evaluation_0/Rewards Max                     10.2078
evaluation_0/Rewards Min                     -0.442186
evaluation_0/Returns Mean                  5017.77
evaluation_0/Returns Std                     21.3356
evaluation_0/Returns Max                   5040.97
evaluation_0/Returns Min                   4973.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5017.77
time/epoch (s)                                0
time/total (s)                            14581.1
Epoch                                       749
---------------------------------------  ----------------
2022-11-16 14:49:03.275613 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 750 finished
---------------------------------------  ----------------
epoch                                       750
total_step                               755000
replay_pool/size                         755000
trainer/alpha                                 0.063307
trainer/alpha_loss                           -0.804302
trainer/entropy                              -5.70854
trainer/qf_loss                               8.36655
trainer/state_noise                           0.005
trainer/policy_loss                        -220.348
trainer/policy_loss_without_entropy         222.525
trainer/entropy_penalty                      -0.361391
trainer/entropy_percentage                   -0.00162405
trainer/Q1Pred Mean                         221.9
trainer/Q1Pred Std                           74.4144
trainer/Q1Pred Max                          311.204
trainer/Q1Pred Min                           12.7487
trainer/Q2Pred Mean                         221.674
trainer/Q2Pred Std                           74.0445
trainer/Q2Pred Max                          310.273
trainer/Q2Pred Min                           11.5684
trainer/QTargetWithReg Mean                 222.409
trainer/QTargetWithReg Std                   74.1713
trainer/QTargetWithReg Max                  310.951
trainer/QTargetWithReg Min                    6.93406
trainer/PolicyLossWithoutReg Mean           222.525
trainer/PolicyLossWithoutReg Std             73.3353
trainer/PolicyLossWithoutReg Max            310.061
trainer/PolicyLossWithoutReg Min             11.995
trainer/gradient_norm                       363.045
trainer/gradient_penalty                     -1.81523
trainer/gradient_percentage                  -0.00815742
exploration/num steps total              755000
exploration/num paths total                1915
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98117
exploration/Rewards Std                       1.31443
exploration/Rewards Max                      10.1179
exploration/Rewards Min                      -0.2813
exploration/Returns Mean                   4981.17
exploration/Returns Std                       0
exploration/Returns Max                    4981.17
exploration/Returns Min                    4981.17
exploration/Num Paths                         1
exploration/Average Returns                4981.17
evaluation_0/num steps total                  5.91706e+06
evaluation_0/num paths total              14072
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93962
evaluation_0/Rewards Std                      1.31563
evaluation_0/Rewards Max                     10.3415
evaluation_0/Rewards Min                     -0.452793
evaluation_0/Returns Mean                  4939.62
evaluation_0/Returns Std                     18.6575
evaluation_0/Returns Max                   4955.57
evaluation_0/Returns Min                   4894.78
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4939.62
time/epoch (s)                                0
time/total (s)                            14597
Epoch                                       750
---------------------------------------  ----------------
2022-11-16 14:49:19.319205 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 751 finished
---------------------------------------  ----------------
epoch                                       751
total_step                               756000
replay_pool/size                         756000
trainer/alpha                                 0.0634255
trainer/alpha_loss                           -0.267037
trainer/entropy                              -5.90317
trainer/qf_loss                               6.63484
trainer/state_noise                           0.005
trainer/policy_loss                        -221.063
trainer/policy_loss_without_entropy         223.19
trainer/entropy_penalty                      -0.374411
trainer/entropy_percentage                   -0.00167755
trainer/Q1Pred Mean                         222.22
trainer/Q1Pred Std                           76.0447
trainer/Q1Pred Max                          305.657
trainer/Q1Pred Min                          -15.6774
trainer/Q2Pred Mean                         222.307
trainer/Q2Pred Std                           76.3212
trainer/Q2Pred Max                          306.928
trainer/Q2Pred Min                          -19.351
trainer/QTargetWithReg Mean                 222.235
trainer/QTargetWithReg Std                   76.3592
trainer/QTargetWithReg Max                  305.76
trainer/QTargetWithReg Min                  -12.2471
trainer/PolicyLossWithoutReg Mean           223.19
trainer/PolicyLossWithoutReg Std             75.4382
trainer/PolicyLossWithoutReg Max            306.062
trainer/PolicyLossWithoutReg Min            -10.7338
trainer/gradient_norm                       350.361
trainer/gradient_penalty                     -1.75181
trainer/gradient_percentage                  -0.00784896
exploration/num steps total              756000
exploration/num paths total                1916
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91465
exploration/Rewards Std                       1.30511
exploration/Rewards Max                      10.2397
exploration/Rewards Min                      -0.42817
exploration/Returns Mean                   4914.65
exploration/Returns Std                       0
exploration/Returns Max                    4914.65
exploration/Returns Min                    4914.65
exploration/Num Paths                         1
exploration/Average Returns                4914.65
evaluation_0/num steps total                  5.92506e+06
evaluation_0/num paths total              14080
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03128
evaluation_0/Rewards Std                      1.31422
evaluation_0/Rewards Max                     10.3675
evaluation_0/Rewards Min                     -0.45047
evaluation_0/Returns Mean                  5031.28
evaluation_0/Returns Std                     20.1747
evaluation_0/Returns Max                   5066.14
evaluation_0/Returns Min                   4998.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5031.28
time/epoch (s)                                0
time/total (s)                            14613
Epoch                                       751
---------------------------------------  ----------------
2022-11-16 14:49:35.603502 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 752 finished
---------------------------------------  ----------------
epoch                                       752
total_step                               757000
replay_pool/size                         757000
trainer/alpha                                 0.0637966
trainer/alpha_loss                            0.922543
trainer/entropy                              -6.33521
trainer/qf_loss                               9.11311
trainer/state_noise                           0.005
trainer/policy_loss                        -218.928
trainer/policy_loss_without_entropy         221.185
trainer/entropy_penalty                      -0.404165
trainer/entropy_percentage                   -0.00182727
trainer/Q1Pred Mean                         220.506
trainer/Q1Pred Std                           73.7902
trainer/Q1Pred Max                          311.589
trainer/Q1Pred Min                            6.83094
trainer/Q2Pred Mean                         220.341
trainer/Q2Pred Std                           73.7887
trainer/Q2Pred Max                          312.041
trainer/Q2Pred Min                            9.53043
trainer/QTargetWithReg Mean                 220.285
trainer/QTargetWithReg Std                   73.957
trainer/QTargetWithReg Max                  312.46
trainer/QTargetWithReg Min                   -0.298071
trainer/PolicyLossWithoutReg Mean           221.185
trainer/PolicyLossWithoutReg Std             72.1474
trainer/PolicyLossWithoutReg Max            311.135
trainer/PolicyLossWithoutReg Min             11.549
trainer/gradient_norm                       370.415
trainer/gradient_penalty                     -1.85207
trainer/gradient_percentage                  -0.00837343
exploration/num steps total              757000
exploration/num paths total                1917
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0899
exploration/Rewards Std                       1.36199
exploration/Rewards Max                      10.4404
exploration/Rewards Min                      -0.381991
exploration/Returns Mean                   5089.9
exploration/Returns Std                       0
exploration/Returns Max                    5089.9
exploration/Returns Min                    5089.9
exploration/Num Paths                         1
exploration/Average Returns                5089.9
evaluation_0/num steps total                  5.93306e+06
evaluation_0/num paths total              14088
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05899
evaluation_0/Rewards Std                      1.29601
evaluation_0/Rewards Max                     10.2997
evaluation_0/Rewards Min                     -0.430738
evaluation_0/Returns Mean                  5058.99
evaluation_0/Returns Std                     47.8078
evaluation_0/Returns Max                   5136.52
evaluation_0/Returns Min                   5002.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5058.99
time/epoch (s)                                0
time/total (s)                            14629.3
Epoch                                       752
---------------------------------------  ----------------
2022-11-16 14:49:51.449198 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 753 finished
---------------------------------------  ----------------
epoch                                       753
total_step                               758000
replay_pool/size                         758000
trainer/alpha                                 0.0637156
trainer/alpha_loss                            0.844428
trainer/entropy                              -6.30668
trainer/qf_loss                               6.94458
trainer/state_noise                           0.005
trainer/policy_loss                        -221.877
trainer/policy_loss_without_entropy         224.063
trainer/entropy_penalty                      -0.401834
trainer/entropy_percentage                   -0.0017934
trainer/Q1Pred Mean                         223.172
trainer/Q1Pred Std                           70.1492
trainer/Q1Pred Max                          313.267
trainer/Q1Pred Min                          -16.072
trainer/Q2Pred Mean                         223.467
trainer/Q2Pred Std                           69.9942
trainer/Q2Pred Max                          313.369
trainer/Q2Pred Min                           -3.87907
trainer/QTargetWithReg Mean                 223.161
trainer/QTargetWithReg Std                   69.7744
trainer/QTargetWithReg Max                  312.306
trainer/QTargetWithReg Min                   -1.20951
trainer/PolicyLossWithoutReg Mean           224.063
trainer/PolicyLossWithoutReg Std             68.3931
trainer/PolicyLossWithoutReg Max            311.079
trainer/PolicyLossWithoutReg Min             12.9441
trainer/gradient_norm                       356.815
trainer/gradient_penalty                     -1.78407
trainer/gradient_percentage                  -0.00796239
exploration/num steps total              758000
exploration/num paths total                1918
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97019
exploration/Rewards Std                       1.31073
exploration/Rewards Max                      10.3727
exploration/Rewards Min                      -0.397727
exploration/Returns Mean                   4970.19
exploration/Returns Std                       0
exploration/Returns Max                    4970.19
exploration/Returns Min                    4970.19
exploration/Num Paths                         1
exploration/Average Returns                4970.19
evaluation_0/num steps total                  5.94106e+06
evaluation_0/num paths total              14096
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96215
evaluation_0/Rewards Std                      1.34839
evaluation_0/Rewards Max                     10.355
evaluation_0/Rewards Min                     -0.458566
evaluation_0/Returns Mean                  4962.15
evaluation_0/Returns Std                     32.9624
evaluation_0/Returns Max                   5016.13
evaluation_0/Returns Min                   4905.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4962.15
time/epoch (s)                                0
time/total (s)                            14645.2
Epoch                                       753
---------------------------------------  ----------------
2022-11-16 14:50:07.935435 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 754 finished
---------------------------------------  ----------------
epoch                                       754
total_step                               759000
replay_pool/size                         759000
trainer/alpha                                 0.0636299
trainer/alpha_loss                            0.866464
trainer/entropy                              -6.31451
trainer/qf_loss                               6.62582
trainer/state_noise                           0.005
trainer/policy_loss                        -222.638
trainer/policy_loss_without_entropy         224.8
trainer/entropy_penalty                      -0.401791
trainer/entropy_percentage                   -0.00178733
trainer/Q1Pred Mean                         223.713
trainer/Q1Pred Std                           68.8564
trainer/Q1Pred Max                          303.337
trainer/Q1Pred Min                          -11.426
trainer/Q2Pred Mean                         224.241
trainer/Q2Pred Std                           68.9967
trainer/Q2Pred Max                          305.823
trainer/Q2Pred Min                           -1.79425
trainer/QTargetWithReg Mean                 224.551
trainer/QTargetWithReg Std                   69.0162
trainer/QTargetWithReg Max                  306.543
trainer/QTargetWithReg Min                   -3.5986
trainer/PolicyLossWithoutReg Mean           224.8
trainer/PolicyLossWithoutReg Std             68.2636
trainer/PolicyLossWithoutReg Max            304.738
trainer/PolicyLossWithoutReg Min             -7.16633
trainer/gradient_norm                       352.013
trainer/gradient_penalty                     -1.76006
trainer/gradient_percentage                  -0.00782948
exploration/num steps total              759000
exploration/num paths total                1919
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93702
exploration/Rewards Std                       1.29994
exploration/Rewards Max                      10.3019
exploration/Rewards Min                      -0.417049
exploration/Returns Mean                   4937.02
exploration/Returns Std                       0
exploration/Returns Max                    4937.02
exploration/Returns Min                    4937.02
exploration/Num Paths                         1
exploration/Average Returns                4937.02
evaluation_0/num steps total                  5.94906e+06
evaluation_0/num paths total              14104
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01668
evaluation_0/Rewards Std                      1.31085
evaluation_0/Rewards Max                     10.2776
evaluation_0/Rewards Min                     -0.446451
evaluation_0/Returns Mean                  5016.68
evaluation_0/Returns Std                     37.6559
evaluation_0/Returns Max                   5088.05
evaluation_0/Returns Min                   4957.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5016.68
time/epoch (s)                                0
time/total (s)                            14661.7
Epoch                                       754
---------------------------------------  ----------------
2022-11-16 14:50:23.679999 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 755 finished
---------------------------------------  ----------------
epoch                                       755
total_step                               760000
replay_pool/size                         760000
trainer/alpha                                 0.064911
trainer/alpha_loss                            0.685059
trainer/entropy                              -6.2505
trainer/qf_loss                               8.93244
trainer/state_noise                           0.005
trainer/policy_loss                        -218.015
trainer/policy_loss_without_entropy         220.201
trainer/entropy_penalty                      -0.405726
trainer/entropy_percentage                   -0.00184253
trainer/Q1Pred Mean                         219.818
trainer/Q1Pred Std                           73.0472
trainer/Q1Pred Max                          314.092
trainer/Q1Pred Min                            1.11679
trainer/Q2Pred Mean                         219.682
trainer/Q2Pred Std                           73.1462
trainer/Q2Pred Max                          313.615
trainer/Q2Pred Min                            3.77438
trainer/QTargetWithReg Mean                 219.278
trainer/QTargetWithReg Std                   72.7971
trainer/QTargetWithReg Max                  312.736
trainer/QTargetWithReg Min                    1.98383
trainer/PolicyLossWithoutReg Mean           220.201
trainer/PolicyLossWithoutReg Std             72.3139
trainer/PolicyLossWithoutReg Max            311.802
trainer/PolicyLossWithoutReg Min              2.77829
trainer/gradient_norm                       355.964
trainer/gradient_penalty                     -1.77982
trainer/gradient_percentage                  -0.00808272
exploration/num steps total              760000
exploration/num paths total                1920
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06407
exploration/Rewards Std                       1.3234
exploration/Rewards Max                      10.6874
exploration/Rewards Min                      -0.465992
exploration/Returns Mean                   5064.07
exploration/Returns Std                       0
exploration/Returns Max                    5064.07
exploration/Returns Min                    5064.07
exploration/Num Paths                         1
exploration/Average Returns                5064.07
evaluation_0/num steps total                  5.95706e+06
evaluation_0/num paths total              14112
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95429
evaluation_0/Rewards Std                      1.31018
evaluation_0/Rewards Max                     10.2745
evaluation_0/Rewards Min                     -0.46583
evaluation_0/Returns Mean                  4954.29
evaluation_0/Returns Std                     29.9973
evaluation_0/Returns Max                   5025.9
evaluation_0/Returns Min                   4923.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4954.29
time/epoch (s)                                0
time/total (s)                            14677.4
Epoch                                       755
---------------------------------------  ----------------
2022-11-16 14:50:40.193092 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 756 finished
---------------------------------------  ----------------
epoch                                       756
total_step                               761000
replay_pool/size                         761000
trainer/alpha                                 0.0651668
trainer/alpha_loss                           -1.31401
trainer/entropy                              -5.51878
trainer/qf_loss                               8.45234
trainer/state_noise                           0.005
trainer/policy_loss                        -222.458
trainer/policy_loss_without_entropy         224.622
trainer/entropy_penalty                      -0.359641
trainer/entropy_percentage                   -0.00160109
trainer/Q1Pred Mean                         223.821
trainer/Q1Pred Std                           68.4798
trainer/Q1Pred Max                          313.011
trainer/Q1Pred Min                           17.5848
trainer/Q2Pred Mean                         223.9
trainer/Q2Pred Std                           68.1665
trainer/Q2Pred Max                          313.625
trainer/Q2Pred Min                           28.8113
trainer/QTargetWithReg Mean                 223.814
trainer/QTargetWithReg Std                   68.4159
trainer/QTargetWithReg Max                  314.863
trainer/QTargetWithReg Min                   14.1831
trainer/PolicyLossWithoutReg Mean           224.622
trainer/PolicyLossWithoutReg Std             67.4245
trainer/PolicyLossWithoutReg Max            312.28
trainer/PolicyLossWithoutReg Min             41.8957
trainer/gradient_norm                       360.912
trainer/gradient_penalty                     -1.80456
trainer/gradient_percentage                  -0.00803377
exploration/num steps total              761000
exploration/num paths total                1921
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98759
exploration/Rewards Std                       1.32779
exploration/Rewards Max                      10.2234
exploration/Rewards Min                      -0.472836
exploration/Returns Mean                   4987.59
exploration/Returns Std                       0
exploration/Returns Max                    4987.59
exploration/Returns Min                    4987.59
exploration/Num Paths                         1
exploration/Average Returns                4987.59
evaluation_0/num steps total                  5.96506e+06
evaluation_0/num paths total              14120
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13402
evaluation_0/Rewards Std                      1.31791
evaluation_0/Rewards Max                     10.4187
evaluation_0/Rewards Min                     -0.510846
evaluation_0/Returns Mean                  5134.02
evaluation_0/Returns Std                     29.7923
evaluation_0/Returns Max                   5175.29
evaluation_0/Returns Min                   5070.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5134.02
time/epoch (s)                                0
time/total (s)                            14693.9
Epoch                                       756
---------------------------------------  ----------------
2022-11-16 14:50:55.954237 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 757 finished
---------------------------------------  ----------------
epoch                                       757
total_step                               762000
replay_pool/size                         762000
trainer/alpha                                 0.0645164
trainer/alpha_loss                            0.571436
trainer/entropy                              -6.20849
trainer/qf_loss                               6.30347
trainer/state_noise                           0.005
trainer/policy_loss                        -216.765
trainer/policy_loss_without_entropy         218.959
trainer/entropy_penalty                      -0.400549
trainer/entropy_percentage                   -0.00182933
trainer/Q1Pred Mean                         217.997
trainer/Q1Pred Std                           76.6257
trainer/Q1Pred Max                          310.428
trainer/Q1Pred Min                          -23.8449
trainer/Q2Pred Mean                         218.322
trainer/Q2Pred Std                           77.1236
trainer/Q2Pred Max                          310.276
trainer/Q2Pred Min                          -18.7698
trainer/QTargetWithReg Mean                 218.45
trainer/QTargetWithReg Std                   76.6562
trainer/QTargetWithReg Max                  309.939
trainer/QTargetWithReg Min                   -8.5971
trainer/PolicyLossWithoutReg Mean           218.959
trainer/PolicyLossWithoutReg Std             76.2366
trainer/PolicyLossWithoutReg Max            309.717
trainer/PolicyLossWithoutReg Min            -13.0028
trainer/gradient_norm                       358.804
trainer/gradient_penalty                     -1.79402
trainer/gradient_percentage                  -0.00819338
exploration/num steps total              762000
exploration/num paths total                1922
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10836
exploration/Rewards Std                       1.30461
exploration/Rewards Max                      10.262
exploration/Rewards Min                      -0.512252
exploration/Returns Mean                   5108.36
exploration/Returns Std                       0
exploration/Returns Max                    5108.36
exploration/Returns Min                    5108.36
exploration/Num Paths                         1
exploration/Average Returns                5108.36
evaluation_0/num steps total                  5.97306e+06
evaluation_0/num paths total              14128
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10528
evaluation_0/Rewards Std                      1.30492
evaluation_0/Rewards Max                     10.4301
evaluation_0/Rewards Min                     -0.487979
evaluation_0/Returns Mean                  5105.28
evaluation_0/Returns Std                     37.386
evaluation_0/Returns Max                   5168.72
evaluation_0/Returns Min                   5064.67
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5105.28
time/epoch (s)                                0
time/total (s)                            14709.7
Epoch                                       757
---------------------------------------  ----------------
2022-11-16 14:51:12.453296 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 758 finished
---------------------------------------  ----------------
epoch                                       758
total_step                               763000
replay_pool/size                         763000
trainer/alpha                                 0.062503
trainer/alpha_loss                           -0.170989
trainer/entropy                              -5.93832
trainer/qf_loss                               7.65387
trainer/state_noise                           0.005
trainer/policy_loss                        -229.988
trainer/policy_loss_without_entropy         232.143
trainer/entropy_penalty                      -0.371163
trainer/entropy_percentage                   -0.00159886
trainer/Q1Pred Mean                         231.598
trainer/Q1Pred Std                           68.8523
trainer/Q1Pred Max                          313.713
trainer/Q1Pred Min                          -11.6486
trainer/Q2Pred Mean                         231.385
trainer/Q2Pred Std                           68.9209
trainer/Q2Pred Max                          313.986
trainer/Q2Pred Min                          -10.3805
trainer/QTargetWithReg Mean                 231.225
trainer/QTargetWithReg Std                   68.633
trainer/QTargetWithReg Max                  313.47
trainer/QTargetWithReg Min                  -11.4707
trainer/PolicyLossWithoutReg Mean           232.143
trainer/PolicyLossWithoutReg Std             67.8345
trainer/PolicyLossWithoutReg Max            313.237
trainer/PolicyLossWithoutReg Min             -6.92925
trainer/gradient_norm                       356.635
trainer/gradient_penalty                     -1.78317
trainer/gradient_percentage                  -0.00768137
exploration/num steps total              763000
exploration/num paths total                1923
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.23991
exploration/Rewards Std                       1.3625
exploration/Rewards Max                      10.6241
exploration/Rewards Min                      -0.444344
exploration/Returns Mean                   5239.91
exploration/Returns Std                       0
exploration/Returns Max                    5239.91
exploration/Returns Min                    5239.91
exploration/Num Paths                         1
exploration/Average Returns                5239.91
evaluation_0/num steps total                  5.98106e+06
evaluation_0/num paths total              14136
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07257
evaluation_0/Rewards Std                      1.32102
evaluation_0/Rewards Max                     10.3659
evaluation_0/Rewards Min                     -0.512946
evaluation_0/Returns Mean                  5072.57
evaluation_0/Returns Std                     21.7859
evaluation_0/Returns Max                   5112.99
evaluation_0/Returns Min                   5037.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5072.57
time/epoch (s)                                0
time/total (s)                            14726.2
Epoch                                       758
---------------------------------------  ----------------
2022-11-16 14:51:28.410680 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 759 finished
---------------------------------------  ----------------
epoch                                       759
total_step                               764000
replay_pool/size                         764000
trainer/alpha                                 0.063036
trainer/alpha_loss                            0.365865
trainer/entropy                              -6.13237
trainer/qf_loss                              12.1012
trainer/state_noise                           0.005
trainer/policy_loss                        -222.352
trainer/policy_loss_without_entropy         224.458
trainer/entropy_penalty                      -0.38656
trainer/entropy_percentage                   -0.00172219
trainer/Q1Pred Mean                         223.744
trainer/Q1Pred Std                           77.192
trainer/Q1Pred Max                          314.178
trainer/Q1Pred Min                            2.08972
trainer/Q2Pred Mean                         223.763
trainer/Q2Pred Std                           76.9556
trainer/Q2Pred Max                          313.189
trainer/Q2Pred Min                           -0.968213
trainer/QTargetWithReg Mean                 224.363
trainer/QTargetWithReg Std                   76.9212
trainer/QTargetWithReg Max                  316.894
trainer/QTargetWithReg Min                    1.46204
trainer/PolicyLossWithoutReg Mean           224.458
trainer/PolicyLossWithoutReg Std             76.3543
trainer/PolicyLossWithoutReg Max            313.453
trainer/PolicyLossWithoutReg Min              2.48211
trainer/gradient_norm                       344.004
trainer/gradient_penalty                     -1.72002
trainer/gradient_percentage                  -0.00766298
exploration/num steps total              764000
exploration/num paths total                1924
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94884
exploration/Rewards Std                       1.31834
exploration/Rewards Max                      10.2025
exploration/Rewards Min                      -0.564427
exploration/Returns Mean                   4948.84
exploration/Returns Std                       0
exploration/Returns Max                    4948.84
exploration/Returns Min                    4948.84
exploration/Num Paths                         1
exploration/Average Returns                4948.84
evaluation_0/num steps total                  5.98906e+06
evaluation_0/num paths total              14144
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18547
evaluation_0/Rewards Std                      1.35897
evaluation_0/Rewards Max                     10.484
evaluation_0/Rewards Min                     -0.515873
evaluation_0/Returns Mean                  5185.47
evaluation_0/Returns Std                     54.6148
evaluation_0/Returns Max                   5284.53
evaluation_0/Returns Min                   5122.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5185.47
time/epoch (s)                                0
time/total (s)                            14742.1
Epoch                                       759
---------------------------------------  ----------------
2022-11-16 14:51:44.505795 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 760 finished
---------------------------------------  ----------------
epoch                                       760
total_step                               765000
replay_pool/size                         765000
trainer/alpha                                 0.065018
trainer/alpha_loss                           -1.13727
trainer/entropy                              -5.58389
trainer/qf_loss                               7.41108
trainer/state_noise                           0.005
trainer/policy_loss                        -225.679
trainer/policy_loss_without_entropy         227.759
trainer/entropy_penalty                      -0.363053
trainer/entropy_percentage                   -0.00159403
trainer/Q1Pred Mean                         227.358
trainer/Q1Pred Std                           73.3039
trainer/Q1Pred Max                          309.856
trainer/Q1Pred Min                           11.538
trainer/Q2Pred Mean                         227.432
trainer/Q2Pred Std                           73.4035
trainer/Q2Pred Max                          310.999
trainer/Q2Pred Min                           12.7974
trainer/QTargetWithReg Mean                 227.095
trainer/QTargetWithReg Std                   73.1823
trainer/QTargetWithReg Max                  311.138
trainer/QTargetWithReg Min                   12.9486
trainer/PolicyLossWithoutReg Mean           227.759
trainer/PolicyLossWithoutReg Std             72.6946
trainer/PolicyLossWithoutReg Max            309.975
trainer/PolicyLossWithoutReg Min             12.1315
trainer/gradient_norm                       343.373
trainer/gradient_penalty                     -1.71686
trainer/gradient_percentage                  -0.00753808
exploration/num steps total              765000
exploration/num paths total                1925
exploration/path length this epoch Mean     927
exploration/path length this epoch Std        0
exploration/path length this epoch Max      927
exploration/path length this epoch Min      927
exploration/Rewards Mean                      4.96081
exploration/Rewards Std                       1.4288
exploration/Rewards Max                      10.2363
exploration/Rewards Min                      -0.554002
exploration/Returns Mean                   4598.67
exploration/Returns Std                       0
exploration/Returns Max                    4598.67
exploration/Returns Min                    4598.67
exploration/Num Paths                         1
exploration/Average Returns                4598.67
evaluation_0/num steps total                  5.99706e+06
evaluation_0/num paths total              14152
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01062
evaluation_0/Rewards Std                      1.30787
evaluation_0/Rewards Max                     10.3779
evaluation_0/Rewards Min                     -0.43912
evaluation_0/Returns Mean                  5010.62
evaluation_0/Returns Std                     11.372
evaluation_0/Returns Max                   5027.35
evaluation_0/Returns Min                   4989.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5010.62
time/epoch (s)                                0
time/total (s)                            14758.2
Epoch                                       760
---------------------------------------  ----------------
2022-11-16 14:52:00.670583 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 761 finished
---------------------------------------  ----------------
epoch                                       761
total_step                               766000
replay_pool/size                         766000
trainer/alpha                                 0.0633285
trainer/alpha_loss                            1.16393
trainer/entropy                              -6.42178
trainer/qf_loss                               8.72907
trainer/state_noise                           0.005
trainer/policy_loss                        -224.551
trainer/policy_loss_without_entropy         226.678
trainer/entropy_penalty                      -0.406681
trainer/entropy_percentage                   -0.00179409
trainer/Q1Pred Mean                         226.143
trainer/Q1Pred Std                           71.3542
trainer/Q1Pred Max                          312.511
trainer/Q1Pred Min                           34.6857
trainer/Q2Pred Mean                         225.985
trainer/Q2Pred Std                           70.9529
trainer/Q2Pred Max                          312.65
trainer/Q2Pred Min                           31.5641
trainer/QTargetWithReg Mean                 225.941
trainer/QTargetWithReg Std                   71.3149
trainer/QTargetWithReg Max                  312.799
trainer/QTargetWithReg Min                   31.9052
trainer/PolicyLossWithoutReg Mean           226.678
trainer/PolicyLossWithoutReg Std             70.0064
trainer/PolicyLossWithoutReg Max            312.974
trainer/PolicyLossWithoutReg Min             32.2203
trainer/gradient_norm                       344.203
trainer/gradient_penalty                     -1.72101
trainer/gradient_percentage                  -0.00759231
exploration/num steps total              766000
exploration/num paths total                1926
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00201
exploration/Rewards Std                       1.31871
exploration/Rewards Max                      10.8782
exploration/Rewards Min                      -0.442611
exploration/Returns Mean                   5002.01
exploration/Returns Std                       0
exploration/Returns Max                    5002.01
exploration/Returns Min                    5002.01
exploration/Num Paths                         1
exploration/Average Returns                5002.01
evaluation_0/num steps total                  6.00506e+06
evaluation_0/num paths total              14160
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00222
evaluation_0/Rewards Std                      1.27671
evaluation_0/Rewards Max                     10.4189
evaluation_0/Rewards Min                     -0.542586
evaluation_0/Returns Mean                  5002.22
evaluation_0/Returns Std                     36.3294
evaluation_0/Returns Max                   5044.88
evaluation_0/Returns Min                   4930.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5002.22
time/epoch (s)                                0
time/total (s)                            14774.4
Epoch                                       761
---------------------------------------  ----------------
2022-11-16 14:52:16.423840 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 762 finished
---------------------------------------  ----------------
epoch                                       762
total_step                               767000
replay_pool/size                         767000
trainer/alpha                                 0.063322
trainer/alpha_loss                           -0.204213
trainer/entropy                              -5.926
trainer/qf_loss                               6.80774
trainer/state_noise                           0.005
trainer/policy_loss                        -226.53
trainer/policy_loss_without_entropy         228.666
trainer/entropy_penalty                      -0.375246
trainer/entropy_percentage                   -0.00164102
trainer/Q1Pred Mean                         228.162
trainer/Q1Pred Std                           66.7389
trainer/Q1Pred Max                          311.175
trainer/Q1Pred Min                            5.03081
trainer/Q2Pred Mean                         228.012
trainer/Q2Pred Std                           67.3813
trainer/Q2Pred Max                          311.727
trainer/Q2Pred Min                            7.77742
trainer/QTargetWithReg Mean                 227.622
trainer/QTargetWithReg Std                   67.0917
trainer/QTargetWithReg Max                  310.242
trainer/QTargetWithReg Min                    6.90057
trainer/PolicyLossWithoutReg Mean           228.666
trainer/PolicyLossWithoutReg Std             66.2813
trainer/PolicyLossWithoutReg Max            311.218
trainer/PolicyLossWithoutReg Min              4.68621
trainer/gradient_norm                       352.115
trainer/gradient_penalty                     -1.76057
trainer/gradient_percentage                  -0.00769933
exploration/num steps total              767000
exploration/num paths total                1927
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11161
exploration/Rewards Std                       1.30102
exploration/Rewards Max                      10.2627
exploration/Rewards Min                      -0.56424
exploration/Returns Mean                   5111.61
exploration/Returns Std                       0
exploration/Returns Max                    5111.61
exploration/Returns Min                    5111.61
exploration/Num Paths                         1
exploration/Average Returns                5111.61
evaluation_0/num steps total                  6.01306e+06
evaluation_0/num paths total              14168
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18298
evaluation_0/Rewards Std                      1.31755
evaluation_0/Rewards Max                     10.33
evaluation_0/Rewards Min                     -0.520085
evaluation_0/Returns Mean                  5182.98
evaluation_0/Returns Std                     14.7507
evaluation_0/Returns Max                   5204.29
evaluation_0/Returns Min                   5160.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5182.98
time/epoch (s)                                0
time/total (s)                            14790.1
Epoch                                       762
---------------------------------------  ----------------
2022-11-16 14:52:32.864887 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 763 finished
---------------------------------------  ----------------
epoch                                       763
total_step                               768000
replay_pool/size                         768000
trainer/alpha                                 0.0628393
trainer/alpha_loss                            0.504556
trainer/entropy                              -6.18233
trainer/qf_loss                               6.98019
trainer/state_noise                           0.005
trainer/policy_loss                        -217.189
trainer/policy_loss_without_entropy         219.297
trainer/entropy_penalty                      -0.388493
trainer/entropy_percentage                   -0.00177154
trainer/Q1Pred Mean                         218.244
trainer/Q1Pred Std                           72.5545
trainer/Q1Pred Max                          313.227
trainer/Q1Pred Min                          -15.9715
trainer/Q2Pred Mean                         218.067
trainer/Q2Pred Std                           72.2396
trainer/Q2Pred Max                          313.303
trainer/Q2Pred Min                           -5.48494
trainer/QTargetWithReg Mean                 218.778
trainer/QTargetWithReg Std                   72.559
trainer/QTargetWithReg Max                  312.467
trainer/QTargetWithReg Min                   -3.57043
trainer/PolicyLossWithoutReg Mean           219.297
trainer/PolicyLossWithoutReg Std             71.007
trainer/PolicyLossWithoutReg Max            313.534
trainer/PolicyLossWithoutReg Min             -5.20744
trainer/gradient_norm                       344
trainer/gradient_penalty                     -1.72
trainer/gradient_percentage                  -0.00784323
exploration/num steps total              768000
exploration/num paths total                1928
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.97029
exploration/Rewards Std                       1.31508
exploration/Rewards Max                      10.0853
exploration/Rewards Min                      -0.490011
exploration/Returns Mean                   4970.29
exploration/Returns Std                       0
exploration/Returns Max                    4970.29
exploration/Returns Min                    4970.29
exploration/Num Paths                         1
exploration/Average Returns                4970.29
evaluation_0/num steps total                  6.02106e+06
evaluation_0/num paths total              14176
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10025
evaluation_0/Rewards Std                      1.33764
evaluation_0/Rewards Max                     10.2965
evaluation_0/Rewards Min                     -0.444324
evaluation_0/Returns Mean                  5100.25
evaluation_0/Returns Std                     46.0395
evaluation_0/Returns Max                   5170.09
evaluation_0/Returns Min                   5035.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5100.25
time/epoch (s)                                0
time/total (s)                            14806.6
Epoch                                       763
---------------------------------------  ----------------
2022-11-16 14:52:48.714625 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 764 finished
---------------------------------------  ----------------
epoch                                       764
total_step                               769000
replay_pool/size                         769000
trainer/alpha                                 0.0644348
trainer/alpha_loss                           -0.00181739
trainer/entropy                              -5.99934
trainer/qf_loss                               7.44565
trainer/state_noise                           0.005
trainer/policy_loss                        -215.983
trainer/policy_loss_without_entropy         218.188
trainer/entropy_penalty                      -0.386566
trainer/entropy_percentage                   -0.00177171
trainer/Q1Pred Mean                         217.749
trainer/Q1Pred Std                           75.4512
trainer/Q1Pred Max                          311.016
trainer/Q1Pred Min                          -18.6754
trainer/Q2Pred Mean                         218.249
trainer/Q2Pred Std                           75.6429
trainer/Q2Pred Max                          310.416
trainer/Q2Pred Min                          -26.8265
trainer/QTargetWithReg Mean                 217.934
trainer/QTargetWithReg Std                   75.4361
trainer/QTargetWithReg Max                  311.03
trainer/QTargetWithReg Min                  -19.8714
trainer/PolicyLossWithoutReg Mean           218.188
trainer/PolicyLossWithoutReg Std             75.2149
trainer/PolicyLossWithoutReg Max            310.125
trainer/PolicyLossWithoutReg Min            -24.8987
trainer/gradient_norm                       363.801
trainer/gradient_penalty                     -1.819
trainer/gradient_percentage                  -0.00833685
exploration/num steps total              769000
exploration/num paths total                1929
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11006
exploration/Rewards Std                       1.3667
exploration/Rewards Max                      10.3291
exploration/Rewards Min                      -0.453778
exploration/Returns Mean                   5110.06
exploration/Returns Std                       0
exploration/Returns Max                    5110.06
exploration/Returns Min                    5110.06
exploration/Num Paths                         1
exploration/Average Returns                5110.06
evaluation_0/num steps total                  6.02906e+06
evaluation_0/num paths total              14184
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13745
evaluation_0/Rewards Std                      1.3271
evaluation_0/Rewards Max                     10.4073
evaluation_0/Rewards Min                     -0.421852
evaluation_0/Returns Mean                  5137.45
evaluation_0/Returns Std                     30.6139
evaluation_0/Returns Max                   5174.66
evaluation_0/Returns Min                   5095.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5137.45
time/epoch (s)                                0
time/total (s)                            14822.4
Epoch                                       764
---------------------------------------  ----------------
2022-11-16 14:53:05.234115 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 765 finished
---------------------------------------  ----------------
epoch                                       765
total_step                               770000
replay_pool/size                         770000
trainer/alpha                                 0.0623636
trainer/alpha_loss                            0.566567
trainer/entropy                              -6.20419
trainer/qf_loss                               8.79272
trainer/state_noise                           0.005
trainer/policy_loss                        -229.757
trainer/policy_loss_without_entropy         231.958
trainer/entropy_penalty                      -0.386916
trainer/entropy_percentage                   -0.00166804
trainer/Q1Pred Mean                         231.126
trainer/Q1Pred Std                           67.9599
trainer/Q1Pred Max                          313.173
trainer/Q1Pred Min                           14.1577
trainer/Q2Pred Mean                         230.956
trainer/Q2Pred Std                           68.1592
trainer/Q2Pred Max                          312.889
trainer/Q2Pred Min                           12.205
trainer/QTargetWithReg Mean                 231.219
trainer/QTargetWithReg Std                   68.1161
trainer/QTargetWithReg Max                  314.599
trainer/QTargetWithReg Min                   13.7601
trainer/PolicyLossWithoutReg Mean           231.958
trainer/PolicyLossWithoutReg Std             67.2415
trainer/PolicyLossWithoutReg Max            313.082
trainer/PolicyLossWithoutReg Min             15.0741
trainer/gradient_norm                       362.936
trainer/gradient_penalty                     -1.81468
trainer/gradient_percentage                  -0.0078233
exploration/num steps total              770000
exploration/num paths total                1930
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98285
exploration/Rewards Std                       1.29613
exploration/Rewards Max                      10.0919
exploration/Rewards Min                      -0.485225
exploration/Returns Mean                   4982.85
exploration/Returns Std                       0
exploration/Returns Max                    4982.85
exploration/Returns Min                    4982.85
exploration/Num Paths                         1
exploration/Average Returns                4982.85
evaluation_0/num steps total                  6.03706e+06
evaluation_0/num paths total              14192
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00044
evaluation_0/Rewards Std                      1.32046
evaluation_0/Rewards Max                     10.2975
evaluation_0/Rewards Min                     -0.461421
evaluation_0/Returns Mean                  5000.44
evaluation_0/Returns Std                     36.8769
evaluation_0/Returns Max                   5094.88
evaluation_0/Returns Min                   4974.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5000.44
time/epoch (s)                                0
time/total (s)                            14839
Epoch                                       765
---------------------------------------  ----------------
2022-11-16 14:53:21.024076 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 766 finished
---------------------------------------  ----------------
epoch                                       766
total_step                               771000
replay_pool/size                         771000
trainer/alpha                                 0.0637068
trainer/alpha_loss                            1.28039
trainer/entropy                              -6.46499
trainer/qf_loss                               6.99174
trainer/state_noise                           0.005
trainer/policy_loss                        -226.861
trainer/policy_loss_without_entropy         229.027
trainer/entropy_penalty                      -0.411864
trainer/entropy_percentage                   -0.00179832
trainer/Q1Pred Mean                         228.328
trainer/Q1Pred Std                           74.8158
trainer/Q1Pred Max                          314.091
trainer/Q1Pred Min                            2.92405
trainer/Q2Pred Mean                         228.142
trainer/Q2Pred Std                           75.2242
trainer/Q2Pred Max                          315.887
trainer/Q2Pred Min                            2.98706
trainer/QTargetWithReg Mean                 228.395
trainer/QTargetWithReg Std                   75.039
trainer/QTargetWithReg Max                  314.874
trainer/QTargetWithReg Min                    5.77572
trainer/PolicyLossWithoutReg Mean           229.026
trainer/PolicyLossWithoutReg Std             74.4349
trainer/PolicyLossWithoutReg Max            314.055
trainer/PolicyLossWithoutReg Min              3.78813
trainer/gradient_norm                       350.694
trainer/gradient_penalty                     -1.75347
trainer/gradient_percentage                  -0.00765618
exploration/num steps total              771000
exploration/num paths total                1931
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98945
exploration/Rewards Std                       1.30307
exploration/Rewards Max                      10.0564
exploration/Rewards Min                      -0.533828
exploration/Returns Mean                   4989.45
exploration/Returns Std                       0
exploration/Returns Max                    4989.45
exploration/Returns Min                    4989.45
exploration/Num Paths                         1
exploration/Average Returns                4989.45
evaluation_0/num steps total                  6.04506e+06
evaluation_0/num paths total              14200
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05852
evaluation_0/Rewards Std                      1.26724
evaluation_0/Rewards Max                     10.239
evaluation_0/Rewards Min                     -0.463627
evaluation_0/Returns Mean                  5058.52
evaluation_0/Returns Std                     13.893
evaluation_0/Returns Max                   5082.25
evaluation_0/Returns Min                   5041.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5058.52
time/epoch (s)                                0
time/total (s)                            14854.7
Epoch                                       766
---------------------------------------  ----------------
2022-11-16 14:53:37.212146 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 767 finished
---------------------------------------  ----------------
epoch                                       767
total_step                               772000
replay_pool/size                         772000
trainer/alpha                                 0.0625002
trainer/alpha_loss                            0.140047
trainer/entropy                              -6.05051
trainer/qf_loss                               8.15189
trainer/state_noise                           0.005
trainer/policy_loss                        -231.14
trainer/policy_loss_without_entropy         233.294
trainer/entropy_penalty                      -0.378158
trainer/entropy_percentage                   -0.00162095
trainer/Q1Pred Mean                         232.394
trainer/Q1Pred Std                           69.7052
trainer/Q1Pred Max                          311.357
trainer/Q1Pred Min                           23.0243
trainer/Q2Pred Mean                         231.957
trainer/Q2Pred Std                           69.9797
trainer/Q2Pred Max                          310.89
trainer/Q2Pred Min                           21.5304
trainer/QTargetWithReg Mean                 232.55
trainer/QTargetWithReg Std                   69.9742
trainer/QTargetWithReg Max                  310.651
trainer/QTargetWithReg Min                   19.6442
trainer/PolicyLossWithoutReg Mean           233.294
trainer/PolicyLossWithoutReg Std             69.2193
trainer/PolicyLossWithoutReg Max            311.184
trainer/PolicyLossWithoutReg Min             24.2617
trainer/gradient_norm                       355.196
trainer/gradient_penalty                     -1.77598
trainer/gradient_percentage                  -0.0076126
exploration/num steps total              772000
exploration/num paths total                1932
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08597
exploration/Rewards Std                       1.32314
exploration/Rewards Max                      10.1666
exploration/Rewards Min                      -0.419445
exploration/Returns Mean                   5085.97
exploration/Returns Std                       0
exploration/Returns Max                    5085.97
exploration/Returns Min                    5085.97
exploration/Num Paths                         1
exploration/Average Returns                5085.97
evaluation_0/num steps total                  6.05306e+06
evaluation_0/num paths total              14208
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10976
evaluation_0/Rewards Std                      1.38327
evaluation_0/Rewards Max                     10.5526
evaluation_0/Rewards Min                     -0.531613
evaluation_0/Returns Mean                  5109.76
evaluation_0/Returns Std                     20.3507
evaluation_0/Returns Max                   5145.97
evaluation_0/Returns Min                   5077.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5109.76
time/epoch (s)                                0
time/total (s)                            14870.9
Epoch                                       767
---------------------------------------  ----------------
2022-11-16 14:53:53.174940 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 768 finished
---------------------------------------  ----------------
epoch                                       768
total_step                               773000
replay_pool/size                         773000
trainer/alpha                                 0.0634358
trainer/alpha_loss                            0.238917
trainer/entropy                              -6.08664
trainer/qf_loss                             150.882
trainer/state_noise                           0.005
trainer/policy_loss                        -226.62
trainer/policy_loss_without_entropy         228.828
trainer/entropy_penalty                      -0.386111
trainer/entropy_percentage                   -0.00168734
trainer/Q1Pred Mean                         228.629
trainer/Q1Pred Std                           70.1043
trainer/Q1Pred Max                          309.574
trainer/Q1Pred Min                           -4.02173
trainer/Q2Pred Mean                         228.556
trainer/Q2Pred Std                           69.7631
trainer/Q2Pred Max                          310.056
trainer/Q2Pred Min                           -2.45828
trainer/QTargetWithReg Mean                 227.555
trainer/QTargetWithReg Std                   71.557
trainer/QTargetWithReg Max                  308.044
trainer/QTargetWithReg Min                   -0.197232
trainer/PolicyLossWithoutReg Mean           228.828
trainer/PolicyLossWithoutReg Std             68.654
trainer/PolicyLossWithoutReg Max            309.161
trainer/PolicyLossWithoutReg Min              2.91516
trainer/gradient_norm                       364.361
trainer/gradient_penalty                     -1.82181
trainer/gradient_percentage                  -0.00796147
exploration/num steps total              773000
exploration/num paths total                1933
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87579
exploration/Rewards Std                       1.43479
exploration/Rewards Max                      10.3122
exploration/Rewards Min                      -0.430744
exploration/Returns Mean                   4875.79
exploration/Returns Std                       0
exploration/Returns Max                    4875.79
exploration/Returns Min                    4875.79
exploration/Num Paths                         1
exploration/Average Returns                4875.79
evaluation_0/num steps total                  6.06106e+06
evaluation_0/num paths total              14216
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00932
evaluation_0/Rewards Std                      1.3412
evaluation_0/Rewards Max                     10.1772
evaluation_0/Rewards Min                     -0.419047
evaluation_0/Returns Mean                  5009.32
evaluation_0/Returns Std                     41.841
evaluation_0/Returns Max                   5077.81
evaluation_0/Returns Min                   4954.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5009.32
time/epoch (s)                                0
time/total (s)                            14886.9
Epoch                                       768
---------------------------------------  ----------------
2022-11-16 14:54:09.035369 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 769 finished
---------------------------------------  ----------------
epoch                                       769
total_step                               774000
replay_pool/size                         774000
trainer/alpha                                 0.0615054
trainer/alpha_loss                           -0.468392
trainer/entropy                              -5.83204
trainer/qf_loss                               5.74882
trainer/state_noise                           0.005
trainer/policy_loss                        -230.563
trainer/policy_loss_without_entropy         232.678
trainer/entropy_penalty                      -0.358701
trainer/entropy_percentage                   -0.00154162
trainer/Q1Pred Mean                         232.252
trainer/Q1Pred Std                           66.9703
trainer/Q1Pred Max                          315.339
trainer/Q1Pred Min                           39.649
trainer/Q2Pred Mean                         232.112
trainer/Q2Pred Std                           66.9124
trainer/Q2Pred Max                          316.083
trainer/Q2Pred Min                           37.2768
trainer/QTargetWithReg Mean                 231.8
trainer/QTargetWithReg Std                   66.9308
trainer/QTargetWithReg Max                  317.229
trainer/QTargetWithReg Min                   34.3512
trainer/PolicyLossWithoutReg Mean           232.678
trainer/PolicyLossWithoutReg Std             66.0342
trainer/PolicyLossWithoutReg Max            315.332
trainer/PolicyLossWithoutReg Min             41.2263
trainer/gradient_norm                       351.342
trainer/gradient_penalty                     -1.75671
trainer/gradient_percentage                  -0.00754994
exploration/num steps total              774000
exploration/num paths total                1934
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03578
exploration/Rewards Std                       1.34422
exploration/Rewards Max                      10.1696
exploration/Rewards Min                      -0.403699
exploration/Returns Mean                   5035.78
exploration/Returns Std                       0
exploration/Returns Max                    5035.78
exploration/Returns Min                    5035.78
exploration/Num Paths                         1
exploration/Average Returns                5035.78
evaluation_0/num steps total                  6.06906e+06
evaluation_0/num paths total              14224
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02951
evaluation_0/Rewards Std                      1.30399
evaluation_0/Rewards Max                     10.3598
evaluation_0/Rewards Min                     -0.417661
evaluation_0/Returns Mean                  5029.51
evaluation_0/Returns Std                     17.0435
evaluation_0/Returns Max                   5060.56
evaluation_0/Returns Min                   5006.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5029.51
time/epoch (s)                                0
time/total (s)                            14902.8
Epoch                                       769
---------------------------------------  ----------------
2022-11-16 14:54:25.426657 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 770 finished
---------------------------------------  ----------------
epoch                                       770
total_step                               775000
replay_pool/size                         775000
trainer/alpha                                 0.062792
trainer/alpha_loss                            1.72934
trainer/entropy                              -6.62474
trainer/qf_loss                               7.42911
trainer/state_noise                           0.005
trainer/policy_loss                        -215.666
trainer/policy_loss_without_entropy         217.874
trainer/entropy_penalty                      -0.415981
trainer/entropy_percentage                   -0.00190927
trainer/Q1Pred Mean                         217.555
trainer/Q1Pred Std                           81.1405
trainer/Q1Pred Max                          306.738
trainer/Q1Pred Min                           -8.88297
trainer/Q2Pred Mean                         217.33
trainer/Q2Pred Std                           81.5747
trainer/Q2Pred Max                          307.82
trainer/Q2Pred Min                          -13.9873
trainer/QTargetWithReg Mean                 216.961
trainer/QTargetWithReg Std                   81.573
trainer/QTargetWithReg Max                  307.938
trainer/QTargetWithReg Min                  -24.0594
trainer/PolicyLossWithoutReg Mean           217.874
trainer/PolicyLossWithoutReg Std             80.3743
trainer/PolicyLossWithoutReg Max            306.088
trainer/PolicyLossWithoutReg Min              1.867
trainer/gradient_norm                       358.355
trainer/gradient_penalty                     -1.79178
trainer/gradient_percentage                  -0.00822392
exploration/num steps total              775000
exploration/num paths total                1935
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01481
exploration/Rewards Std                       1.31371
exploration/Rewards Max                      10.0867
exploration/Rewards Min                      -0.383999
exploration/Returns Mean                   5014.81
exploration/Returns Std                       0
exploration/Returns Max                    5014.81
exploration/Returns Min                    5014.81
exploration/Num Paths                         1
exploration/Average Returns                5014.81
evaluation_0/num steps total                  6.07706e+06
evaluation_0/num paths total              14232
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90184
evaluation_0/Rewards Std                      1.30645
evaluation_0/Rewards Max                     10.2631
evaluation_0/Rewards Min                     -0.477475
evaluation_0/Returns Mean                  4901.84
evaluation_0/Returns Std                     30.7168
evaluation_0/Returns Max                   4952.15
evaluation_0/Returns Min                   4858.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4901.84
time/epoch (s)                                0
time/total (s)                            14919.1
Epoch                                       770
---------------------------------------  ----------------
2022-11-16 14:54:41.223857 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 771 finished
---------------------------------------  ----------------
epoch                                       771
total_step                               776000
replay_pool/size                         776000
trainer/alpha                                 0.0624484
trainer/alpha_loss                            0.544229
trainer/entropy                              -6.19621
trainer/qf_loss                               7.73718
trainer/state_noise                           0.005
trainer/policy_loss                        -223.609
trainer/policy_loss_without_entropy         225.783
trainer/entropy_penalty                      -0.386943
trainer/entropy_percentage                   -0.00171378
trainer/Q1Pred Mean                         224.966
trainer/Q1Pred Std                           69.9537
trainer/Q1Pred Max                          312.117
trainer/Q1Pred Min                           24.9827
trainer/Q2Pred Mean                         225.099
trainer/Q2Pred Std                           69.9704
trainer/Q2Pred Max                          310.943
trainer/Q2Pred Min                           22.3147
trainer/QTargetWithReg Mean                 225.942
trainer/QTargetWithReg Std                   70.281
trainer/QTargetWithReg Max                  314.853
trainer/QTargetWithReg Min                   22.4016
trainer/PolicyLossWithoutReg Mean           225.783
trainer/PolicyLossWithoutReg Std             69.1214
trainer/PolicyLossWithoutReg Max            310.353
trainer/PolicyLossWithoutReg Min             23.7001
trainer/gradient_norm                       357.543
trainer/gradient_penalty                     -1.78771
trainer/gradient_percentage                  -0.00791783
exploration/num steps total              776000
exploration/num paths total                1936
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01545
exploration/Rewards Std                       1.35537
exploration/Rewards Max                      10.3882
exploration/Rewards Min                      -0.423314
exploration/Returns Mean                   5015.45
exploration/Returns Std                       0
exploration/Returns Max                    5015.45
exploration/Returns Min                    5015.45
exploration/Num Paths                         1
exploration/Average Returns                5015.45
evaluation_0/num steps total                  6.08506e+06
evaluation_0/num paths total              14240
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09229
evaluation_0/Rewards Std                      1.32017
evaluation_0/Rewards Max                     10.3249
evaluation_0/Rewards Min                     -0.574777
evaluation_0/Returns Mean                  5092.29
evaluation_0/Returns Std                     21.0536
evaluation_0/Returns Max                   5134.26
evaluation_0/Returns Min                   5060.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5092.29
time/epoch (s)                                0
time/total (s)                            14934.9
Epoch                                       771
---------------------------------------  ----------------
2022-11-16 14:54:57.753512 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 772 finished
---------------------------------------  ----------------
epoch                                       772
total_step                               777000
replay_pool/size                         777000
trainer/alpha                                 0.0633404
trainer/alpha_loss                           -0.680165
trainer/entropy                              -5.75347
trainer/qf_loss                               7.67575
trainer/state_noise                           0.005
trainer/policy_loss                        -217.796
trainer/policy_loss_without_entropy         219.858
trainer/entropy_penalty                      -0.364427
trainer/entropy_percentage                   -0.00165756
trainer/Q1Pred Mean                         219.142
trainer/Q1Pred Std                           79.2306
trainer/Q1Pred Max                          312.098
trainer/Q1Pred Min                           -0.462811
trainer/Q2Pred Mean                         219.301
trainer/Q2Pred Std                           79.3614
trainer/Q2Pred Max                          312.055
trainer/Q2Pred Min                           -1.01077
trainer/QTargetWithReg Mean                 218.938
trainer/QTargetWithReg Std                   79.6926
trainer/QTargetWithReg Max                  313.625
trainer/QTargetWithReg Min                    1.91833
trainer/PolicyLossWithoutReg Mean           219.858
trainer/PolicyLossWithoutReg Std             78.528
trainer/PolicyLossWithoutReg Max            313.662
trainer/PolicyLossWithoutReg Min             -1.72196
trainer/gradient_norm                       339.578
trainer/gradient_penalty                     -1.69789
trainer/gradient_percentage                  -0.00772267
exploration/num steps total              777000
exploration/num paths total                1937
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99756
exploration/Rewards Std                       1.33888
exploration/Rewards Max                      10.257
exploration/Rewards Min                      -0.451211
exploration/Returns Mean                   4997.56
exploration/Returns Std                       0
exploration/Returns Max                    4997.56
exploration/Returns Min                    4997.56
exploration/Num Paths                         1
exploration/Average Returns                4997.56
evaluation_0/num steps total                  6.09306e+06
evaluation_0/num paths total              14248
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03407
evaluation_0/Rewards Std                      1.31584
evaluation_0/Rewards Max                     10.2505
evaluation_0/Rewards Min                     -0.426045
evaluation_0/Returns Mean                  5034.07
evaluation_0/Returns Std                     12.2459
evaluation_0/Returns Max                   5051.13
evaluation_0/Returns Min                   5012.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5034.07
time/epoch (s)                                0
time/total (s)                            14951.5
Epoch                                       772
---------------------------------------  ----------------
2022-11-16 14:55:13.612872 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 773 finished
---------------------------------------  ----------------
epoch                                       773
total_step                               778000
replay_pool/size                         778000
trainer/alpha                                 0.0621412
trainer/alpha_loss                            0.526436
trainer/entropy                              -6.18948
trainer/qf_loss                               6.7502
trainer/state_noise                           0.005
trainer/policy_loss                        -226.458
trainer/policy_loss_without_entropy         228.638
trainer/entropy_penalty                      -0.384621
trainer/entropy_percentage                   -0.00168223
trainer/Q1Pred Mean                         227.814
trainer/Q1Pred Std                           72.6363
trainer/Q1Pred Max                          315.229
trainer/Q1Pred Min                            4.33183
trainer/Q2Pred Mean                         227.94
trainer/Q2Pred Std                           72.9563
trainer/Q2Pred Max                          315.214
trainer/Q2Pred Min                           -6.65505
trainer/QTargetWithReg Mean                 227.626
trainer/QTargetWithReg Std                   73.1066
trainer/QTargetWithReg Max                  316.98
trainer/QTargetWithReg Min                   -0.577041
trainer/PolicyLossWithoutReg Mean           228.638
trainer/PolicyLossWithoutReg Std             71.8224
trainer/PolicyLossWithoutReg Max            315.466
trainer/PolicyLossWithoutReg Min             15.974
trainer/gradient_norm                       358.963
trainer/gradient_penalty                     -1.79481
trainer/gradient_percentage                  -0.00785003
exploration/num steps total              778000
exploration/num paths total                1938
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90158
exploration/Rewards Std                       1.3464
exploration/Rewards Max                      10.4045
exploration/Rewards Min                      -0.438388
exploration/Returns Mean                   4901.58
exploration/Returns Std                       0
exploration/Returns Max                    4901.58
exploration/Returns Min                    4901.58
exploration/Num Paths                         1
exploration/Average Returns                4901.58
evaluation_0/num steps total                  6.10106e+06
evaluation_0/num paths total              14256
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.79553
evaluation_0/Rewards Std                      1.29118
evaluation_0/Rewards Max                     10.2414
evaluation_0/Rewards Min                     -0.504621
evaluation_0/Returns Mean                  4795.53
evaluation_0/Returns Std                     10.6803
evaluation_0/Returns Max                   4808.83
evaluation_0/Returns Min                   4778.18
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4795.53
time/epoch (s)                                0
time/total (s)                            14967.3
Epoch                                       773
---------------------------------------  ----------------
2022-11-16 14:55:30.034038 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 774 finished
---------------------------------------  ----------------
epoch                                       774
total_step                               779000
replay_pool/size                         779000
trainer/alpha                                 0.0641182
trainer/alpha_loss                           -0.358089
trainer/entropy                              -5.86965
trainer/qf_loss                               8.26972
trainer/state_noise                           0.005
trainer/policy_loss                        -228.424
trainer/policy_loss_without_entropy         230.503
trainer/entropy_penalty                      -0.376351
trainer/entropy_percentage                   -0.00163274
trainer/Q1Pred Mean                         230.234
trainer/Q1Pred Std                           71.2718
trainer/Q1Pred Max                          309.805
trainer/Q1Pred Min                           26.1358
trainer/Q2Pred Mean                         229.983
trainer/Q2Pred Std                           71.4632
trainer/Q2Pred Max                          311.832
trainer/Q2Pred Min                           23.4427
trainer/QTargetWithReg Mean                 230.106
trainer/QTargetWithReg Std                   71.0959
trainer/QTargetWithReg Max                  310.251
trainer/QTargetWithReg Min                   22.8103
trainer/PolicyLossWithoutReg Mean           230.503
trainer/PolicyLossWithoutReg Std             70.2182
trainer/PolicyLossWithoutReg Max            310.152
trainer/PolicyLossWithoutReg Min             23.0911
trainer/gradient_norm                       340.362
trainer/gradient_penalty                     -1.70181
trainer/gradient_percentage                  -0.00738305
exploration/num steps total              779000
exploration/num paths total                1939
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94919
exploration/Rewards Std                       1.31718
exploration/Rewards Max                      10.314
exploration/Rewards Min                      -0.488765
exploration/Returns Mean                   4949.19
exploration/Returns Std                       0
exploration/Returns Max                    4949.19
exploration/Returns Min                    4949.19
exploration/Num Paths                         1
exploration/Average Returns                4949.19
evaluation_0/num steps total                  6.10906e+06
evaluation_0/num paths total              14264
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07928
evaluation_0/Rewards Std                      1.32644
evaluation_0/Rewards Max                     10.2176
evaluation_0/Rewards Min                     -0.375247
evaluation_0/Returns Mean                  5079.28
evaluation_0/Returns Std                     31.7517
evaluation_0/Returns Max                   5118.91
evaluation_0/Returns Min                   5031.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5079.28
time/epoch (s)                                0
time/total (s)                            14983.7
Epoch                                       774
---------------------------------------  ----------------
2022-11-16 14:55:45.839250 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 775 finished
---------------------------------------  ----------------
epoch                                       775
total_step                               780000
replay_pool/size                         780000
trainer/alpha                                 0.0618446
trainer/alpha_loss                            0.686008
trainer/entropy                              -6.24648
trainer/qf_loss                               7.92828
trainer/state_noise                           0.005
trainer/policy_loss                        -235.458
trainer/policy_loss_without_entropy         237.632
trainer/entropy_penalty                      -0.386311
trainer/entropy_percentage                   -0.00162567
trainer/Q1Pred Mean                         237.099
trainer/Q1Pred Std                           67.8317
trainer/Q1Pred Max                          312.79
trainer/Q1Pred Min                          -24.5021
trainer/Q2Pred Mean                         236.723
trainer/Q2Pred Std                           67.4668
trainer/Q2Pred Max                          311.874
trainer/Q2Pred Min                          -19.3808
trainer/QTargetWithReg Mean                 237.329
trainer/QTargetWithReg Std                   67.3573
trainer/QTargetWithReg Max                  311.87
trainer/QTargetWithReg Min                   -0.52742
trainer/PolicyLossWithoutReg Mean           237.632
trainer/PolicyLossWithoutReg Std             66.5516
trainer/PolicyLossWithoutReg Max            312.307
trainer/PolicyLossWithoutReg Min             10.7101
trainer/gradient_norm                       357.499
trainer/gradient_penalty                     -1.7875
trainer/gradient_percentage                  -0.00752213
exploration/num steps total              780000
exploration/num paths total                1940
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.67479
exploration/Rewards Std                       1.26832
exploration/Rewards Max                       9.60585
exploration/Rewards Min                      -0.3971
exploration/Returns Mean                   4674.79
exploration/Returns Std                       0
exploration/Returns Max                    4674.79
exploration/Returns Min                    4674.79
exploration/Num Paths                         1
exploration/Average Returns                4674.79
evaluation_0/num steps total                  6.11706e+06
evaluation_0/num paths total              14272
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74398
evaluation_0/Rewards Std                      1.19824
evaluation_0/Rewards Max                      9.59468
evaluation_0/Rewards Min                     -0.563647
evaluation_0/Returns Mean                  4743.98
evaluation_0/Returns Std                     26.0672
evaluation_0/Returns Max                   4789.5
evaluation_0/Returns Min                   4709.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4743.98
time/epoch (s)                                0
time/total (s)                            14999.6
Epoch                                       775
---------------------------------------  ----------------
2022-11-16 14:56:02.172050 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 776 finished
---------------------------------------  ----------------
epoch                                       776
total_step                               781000
replay_pool/size                         781000
trainer/alpha                                 0.0614001
trainer/alpha_loss                           -0.336903
trainer/entropy                              -5.87926
trainer/qf_loss                              10.8776
trainer/state_noise                           0.005
trainer/policy_loss                        -229.686
trainer/policy_loss_without_entropy         231.843
trainer/entropy_penalty                      -0.360987
trainer/entropy_percentage                   -0.00155704
trainer/Q1Pred Mean                         231.346
trainer/Q1Pred Std                           69.3971
trainer/Q1Pred Max                          311.893
trainer/Q1Pred Min                           10.0897
trainer/Q2Pred Mean                         231.404
trainer/Q2Pred Std                           69.4795
trainer/Q2Pred Max                          311.367
trainer/Q2Pred Min                           13.5393
trainer/QTargetWithReg Mean                 231.626
trainer/QTargetWithReg Std                   70.1606
trainer/QTargetWithReg Max                  313.465
trainer/QTargetWithReg Min                    6.04852
trainer/PolicyLossWithoutReg Mean           231.843
trainer/PolicyLossWithoutReg Std             69.1143
trainer/PolicyLossWithoutReg Max            311.563
trainer/PolicyLossWithoutReg Min              8.70681
trainer/gradient_norm                       359.089
trainer/gradient_penalty                     -1.79544
trainer/gradient_percentage                  -0.00774424
exploration/num steps total              781000
exploration/num paths total                1941
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96316
exploration/Rewards Std                       1.31531
exploration/Rewards Max                      10.5777
exploration/Rewards Min                      -0.592143
exploration/Returns Mean                   4963.16
exploration/Returns Std                       0
exploration/Returns Max                    4963.16
exploration/Returns Min                    4963.16
exploration/Num Paths                         1
exploration/Average Returns                4963.16
evaluation_0/num steps total                  6.12506e+06
evaluation_0/num paths total              14280
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.88058
evaluation_0/Rewards Std                      1.29173
evaluation_0/Rewards Max                     10.17
evaluation_0/Rewards Min                     -0.467831
evaluation_0/Returns Mean                  4880.58
evaluation_0/Returns Std                     11.7946
evaluation_0/Returns Max                   4902.67
evaluation_0/Returns Min                   4863.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4880.58
time/epoch (s)                                0
time/total (s)                            15015.9
Epoch                                       776
---------------------------------------  ----------------
2022-11-16 14:56:18.116773 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 777 finished
---------------------------------------  ----------------
epoch                                       777
total_step                               782000
replay_pool/size                         782000
trainer/alpha                                 0.0617456
trainer/alpha_loss                            0.461314
trainer/entropy                              -6.16567
trainer/qf_loss                               6.84938
trainer/state_noise                           0.005
trainer/policy_loss                        -233.933
trainer/policy_loss_without_entropy         236.123
trainer/entropy_penalty                      -0.380703
trainer/entropy_percentage                   -0.0016123
trainer/Q1Pred Mean                         235.229
trainer/Q1Pred Std                           69.0676
trainer/Q1Pred Max                          316.177
trainer/Q1Pred Min                            2.17055
trainer/Q2Pred Mean                         235.932
trainer/Q2Pred Std                           69.3305
trainer/Q2Pred Max                          322.061
trainer/Q2Pred Min                            2.55581
trainer/QTargetWithReg Mean                 235.239
trainer/QTargetWithReg Std                   69.1727
trainer/QTargetWithReg Max                  318.822
trainer/QTargetWithReg Min                   -1.86956
trainer/PolicyLossWithoutReg Mean           236.123
trainer/PolicyLossWithoutReg Std             68.1528
trainer/PolicyLossWithoutReg Max            316.618
trainer/PolicyLossWithoutReg Min              3.90946
trainer/gradient_norm                       361.915
trainer/gradient_penalty                     -1.80958
trainer/gradient_percentage                  -0.00766368
exploration/num steps total              782000
exploration/num paths total                1942
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93112
exploration/Rewards Std                       1.31425
exploration/Rewards Max                      10.313
exploration/Rewards Min                      -0.309364
exploration/Returns Mean                   4931.12
exploration/Returns Std                       0
exploration/Returns Max                    4931.12
exploration/Returns Min                    4931.12
exploration/Num Paths                         1
exploration/Average Returns                4931.12
evaluation_0/num steps total                  6.13306e+06
evaluation_0/num paths total              14288
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93373
evaluation_0/Rewards Std                      1.2923
evaluation_0/Rewards Max                     10.1941
evaluation_0/Rewards Min                     -0.46388
evaluation_0/Returns Mean                  4933.73
evaluation_0/Returns Std                     12.1744
evaluation_0/Returns Max                   4952.93
evaluation_0/Returns Min                   4912.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4933.73
time/epoch (s)                                0
time/total (s)                            15031.8
Epoch                                       777
---------------------------------------  ----------------
2022-11-16 14:56:33.977155 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 778 finished
---------------------------------------  ----------------
epoch                                       778
total_step                               783000
replay_pool/size                         783000
trainer/alpha                                 0.0623186
trainer/alpha_loss                            0.875864
trainer/entropy                              -6.31554
trainer/qf_loss                               8.18299
trainer/state_noise                           0.005
trainer/policy_loss                        -225.036
trainer/policy_loss_without_entropy         227.218
trainer/entropy_penalty                      -0.393576
trainer/entropy_percentage                   -0.00173215
trainer/Q1Pred Mean                         226.877
trainer/Q1Pred Std                           73.5216
trainer/Q1Pred Max                          308.618
trainer/Q1Pred Min                           -0.511175
trainer/Q2Pred Mean                         226.979
trainer/Q2Pred Std                           73.4696
trainer/Q2Pred Max                          308.503
trainer/Q2Pred Min                            3.43213
trainer/QTargetWithReg Mean                 227.38
trainer/QTargetWithReg Std                   73.6898
trainer/QTargetWithReg Max                  308.745
trainer/QTargetWithReg Min                    7.37318
trainer/PolicyLossWithoutReg Mean           227.218
trainer/PolicyLossWithoutReg Std             72.7338
trainer/PolicyLossWithoutReg Max            308.111
trainer/PolicyLossWithoutReg Min              1.60426
trainer/gradient_norm                       357.765
trainer/gradient_penalty                     -1.78882
trainer/gradient_percentage                  -0.00787271
exploration/num steps total              783000
exploration/num paths total                1943
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98431
exploration/Rewards Std                       1.28467
exploration/Rewards Max                      10.1172
exploration/Rewards Min                      -0.613181
exploration/Returns Mean                   4984.31
exploration/Returns Std                       0
exploration/Returns Max                    4984.31
exploration/Returns Min                    4984.31
exploration/Num Paths                         1
exploration/Average Returns                4984.31
evaluation_0/num steps total                  6.14106e+06
evaluation_0/num paths total              14296
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90364
evaluation_0/Rewards Std                      1.29363
evaluation_0/Rewards Max                     10.0826
evaluation_0/Rewards Min                     -0.501981
evaluation_0/Returns Mean                  4903.64
evaluation_0/Returns Std                     16.2182
evaluation_0/Returns Max                   4938.73
evaluation_0/Returns Min                   4886.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4903.64
time/epoch (s)                                0
time/total (s)                            15047.7
Epoch                                       778
---------------------------------------  ----------------
2022-11-16 14:56:50.275838 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 779 finished
---------------------------------------  ----------------
epoch                                       779
total_step                               784000
replay_pool/size                         784000
trainer/alpha                                 0.0629408
trainer/alpha_loss                            0.68697
trainer/entropy                              -6.2484
trainer/qf_loss                               6.48486
trainer/state_noise                           0.005
trainer/policy_loss                        -231.624
trainer/policy_loss_without_entropy         233.784
trainer/entropy_penalty                      -0.393279
trainer/entropy_percentage                   -0.00168223
trainer/Q1Pred Mean                         233.696
trainer/Q1Pred Std                           71.2546
trainer/Q1Pred Max                          313.649
trainer/Q1Pred Min                            9.92039
trainer/Q2Pred Mean                         233.446
trainer/Q2Pred Std                           71.4154
trainer/Q2Pred Max                          312.495
trainer/Q2Pred Min                           10.8343
trainer/QTargetWithReg Mean                 233.494
trainer/QTargetWithReg Std                   71.5725
trainer/QTargetWithReg Max                  313.404
trainer/QTargetWithReg Min                   11.1909
trainer/PolicyLossWithoutReg Mean           233.784
trainer/PolicyLossWithoutReg Std             70.664
trainer/PolicyLossWithoutReg Max            311.758
trainer/PolicyLossWithoutReg Min             11.2762
trainer/gradient_norm                       353.492
trainer/gradient_penalty                     -1.76746
trainer/gradient_percentage                  -0.00756022
exploration/num steps total              784000
exploration/num paths total                1944
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90619
exploration/Rewards Std                       1.28005
exploration/Rewards Max                       9.99622
exploration/Rewards Min                      -0.473947
exploration/Returns Mean                   4906.19
exploration/Returns Std                       0
exploration/Returns Max                    4906.19
exploration/Returns Min                    4906.19
exploration/Num Paths                         1
exploration/Average Returns                4906.19
evaluation_0/num steps total                  6.14906e+06
evaluation_0/num paths total              14304
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19134
evaluation_0/Rewards Std                      1.31932
evaluation_0/Rewards Max                     10.3136
evaluation_0/Rewards Min                     -0.511452
evaluation_0/Returns Mean                  5191.34
evaluation_0/Returns Std                     16.0546
evaluation_0/Returns Max                   5203.78
evaluation_0/Returns Min                   5151.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5191.34
time/epoch (s)                                0
time/total (s)                            15064
Epoch                                       779
---------------------------------------  ----------------
2022-11-16 14:57:06.161253 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 780 finished
---------------------------------------  ----------------
epoch                                       780
total_step                               785000
replay_pool/size                         785000
trainer/alpha                                 0.0617584
trainer/alpha_loss                            1.4371
trainer/entropy                              -6.51608
trainer/qf_loss                               8.61734
trainer/state_noise                           0.005
trainer/policy_loss                        -232.729
trainer/policy_loss_without_entropy         234.913
trainer/entropy_penalty                      -0.402422
trainer/entropy_percentage                   -0.00171307
trainer/Q1Pred Mean                         234.306
trainer/Q1Pred Std                           71.9845
trainer/Q1Pred Max                          312.783
trainer/Q1Pred Min                           -3.62933
trainer/Q2Pred Mean                         234.506
trainer/Q2Pred Std                           71.9522
trainer/Q2Pred Max                          312.223
trainer/Q2Pred Min                            0.297595
trainer/QTargetWithReg Mean                 234.266
trainer/QTargetWithReg Std                   71.9576
trainer/QTargetWithReg Max                  310.612
trainer/QTargetWithReg Min                    1.54434
trainer/PolicyLossWithoutReg Mean           234.913
trainer/PolicyLossWithoutReg Std             71.2069
trainer/PolicyLossWithoutReg Max            311.642
trainer/PolicyLossWithoutReg Min              1.58179
trainer/gradient_norm                       356.267
trainer/gradient_penalty                     -1.78134
trainer/gradient_percentage                  -0.00758298
exploration/num steps total              785000
exploration/num paths total                1945
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04995
exploration/Rewards Std                       1.29877
exploration/Rewards Max                      10.1873
exploration/Rewards Min                      -0.43788
exploration/Returns Mean                   5049.95
exploration/Returns Std                       0
exploration/Returns Max                    5049.95
exploration/Returns Min                    5049.95
exploration/Num Paths                         1
exploration/Average Returns                5049.95
evaluation_0/num steps total                  6.15706e+06
evaluation_0/num paths total              14312
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02763
evaluation_0/Rewards Std                      1.28741
evaluation_0/Rewards Max                     10.1878
evaluation_0/Rewards Min                     -0.490142
evaluation_0/Returns Mean                  5027.63
evaluation_0/Returns Std                     14.4483
evaluation_0/Returns Max                   5054.2
evaluation_0/Returns Min                   5003.79
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5027.63
time/epoch (s)                                0
time/total (s)                            15079.9
Epoch                                       780
---------------------------------------  ----------------
2022-11-16 14:57:22.668743 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 781 finished
---------------------------------------  ----------------
epoch                                       781
total_step                               786000
replay_pool/size                         786000
trainer/alpha                                 0.0639266
trainer/alpha_loss                           -0.582
trainer/entropy                              -5.78836
trainer/qf_loss                               6.16855
trainer/state_noise                           0.005
trainer/policy_loss                        -229.934
trainer/policy_loss_without_entropy         232.089
trainer/entropy_penalty                      -0.370031
trainer/entropy_percentage                   -0.00159435
trainer/Q1Pred Mean                         231.403
trainer/Q1Pred Std                           75.727
trainer/Q1Pred Max                          311.337
trainer/Q1Pred Min                           22.6727
trainer/Q2Pred Mean                         232.306
trainer/Q2Pred Std                           75.9802
trainer/Q2Pred Max                          312.829
trainer/Q2Pred Min                           23.2246
trainer/QTargetWithReg Mean                 231.921
trainer/QTargetWithReg Std                   75.9743
trainer/QTargetWithReg Max                  311.554
trainer/QTargetWithReg Min                   23.2509
trainer/PolicyLossWithoutReg Mean           232.089
trainer/PolicyLossWithoutReg Std             75.4447
trainer/PolicyLossWithoutReg Max            311.978
trainer/PolicyLossWithoutReg Min             24.0815
trainer/gradient_norm                       356.965
trainer/gradient_penalty                     -1.78482
trainer/gradient_percentage                  -0.00769027
exploration/num steps total              786000
exploration/num paths total                1946
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90748
exploration/Rewards Std                       1.30123
exploration/Rewards Max                      10.0193
exploration/Rewards Min                      -0.393912
exploration/Returns Mean                   4907.48
exploration/Returns Std                       0
exploration/Returns Max                    4907.48
exploration/Returns Min                    4907.48
exploration/Num Paths                         1
exploration/Average Returns                4907.48
evaluation_0/num steps total                  6.16506e+06
evaluation_0/num paths total              14320
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.7653
evaluation_0/Rewards Std                      1.21927
evaluation_0/Rewards Max                      9.58586
evaluation_0/Rewards Min                     -0.415078
evaluation_0/Returns Mean                  4765.3
evaluation_0/Returns Std                    107.112
evaluation_0/Returns Max                   4873.23
evaluation_0/Returns Min                   4620.16
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4765.3
time/epoch (s)                                0
time/total (s)                            15096.4
Epoch                                       781
---------------------------------------  ----------------
2022-11-16 14:57:38.521816 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 782 finished
---------------------------------------  ----------------
epoch                                       782
total_step                               787000
replay_pool/size                         787000
trainer/alpha                                 0.0638763
trainer/alpha_loss                            0.832569
trainer/entropy                              -6.30265
trainer/qf_loss                               7.06288
trainer/state_noise                           0.005
trainer/policy_loss                        -223.904
trainer/policy_loss_without_entropy         226.05
trainer/entropy_penalty                      -0.40259
trainer/entropy_percentage                   -0.00178098
trainer/Q1Pred Mean                         225.642
trainer/Q1Pred Std                           76.434
trainer/Q1Pred Max                          316.553
trainer/Q1Pred Min                          -13.3774
trainer/Q2Pred Mean                         225.135
trainer/Q2Pred Std                           76.3771
trainer/Q2Pred Max                          313.14
trainer/Q2Pred Min                          -11.802
trainer/QTargetWithReg Mean                 225.226
trainer/QTargetWithReg Std                   76.9028
trainer/QTargetWithReg Max                  314.001
trainer/QTargetWithReg Min                  -21.6572
trainer/PolicyLossWithoutReg Mean           226.05
trainer/PolicyLossWithoutReg Std             75.6669
trainer/PolicyLossWithoutReg Max            314.238
trainer/PolicyLossWithoutReg Min            -15.901
trainer/gradient_norm                       348.585
trainer/gradient_penalty                     -1.74293
trainer/gradient_percentage                  -0.00771037
exploration/num steps total              787000
exploration/num paths total                1947
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.92041
exploration/Rewards Std                       1.28078
exploration/Rewards Max                       9.9861
exploration/Rewards Min                      -0.422554
exploration/Returns Mean                   4920.41
exploration/Returns Std                       0
exploration/Returns Max                    4920.41
exploration/Returns Min                    4920.41
exploration/Num Paths                         1
exploration/Average Returns                4920.41
evaluation_0/num steps total                  6.17306e+06
evaluation_0/num paths total              14328
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96295
evaluation_0/Rewards Std                      1.2918
evaluation_0/Rewards Max                     10.1248
evaluation_0/Rewards Min                     -0.442793
evaluation_0/Returns Mean                  4962.95
evaluation_0/Returns Std                     48.27
evaluation_0/Returns Max                   5079.04
evaluation_0/Returns Min                   4915.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4962.95
time/epoch (s)                                0
time/total (s)                            15112.2
Epoch                                       782
---------------------------------------  ----------------
2022-11-16 14:57:54.835571 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 783 finished
---------------------------------------  ----------------
epoch                                       783
total_step                               788000
replay_pool/size                         788000
trainer/alpha                                 0.0633541
trainer/alpha_loss                            0.0570747
trainer/entropy                              -6.02069
trainer/qf_loss                               6.70493
trainer/state_noise                           0.005
trainer/policy_loss                        -229.675
trainer/policy_loss_without_entropy         231.872
trainer/entropy_penalty                      -0.381435
trainer/entropy_percentage                   -0.00164503
trainer/Q1Pred Mean                         231.112
trainer/Q1Pred Std                           73.5426
trainer/Q1Pred Max                          313.979
trainer/Q1Pred Min                          -22.4779
trainer/Q2Pred Mean                         231.525
trainer/Q2Pred Std                           73.5238
trainer/Q2Pred Max                          312.677
trainer/Q2Pred Min                          -10.2983
trainer/QTargetWithReg Mean                 231.643
trainer/QTargetWithReg Std                   73.5266
trainer/QTargetWithReg Max                  312.691
trainer/QTargetWithReg Min                   -8.89835
trainer/PolicyLossWithoutReg Mean           231.872
trainer/PolicyLossWithoutReg Std             72.8197
trainer/PolicyLossWithoutReg Max            312.846
trainer/PolicyLossWithoutReg Min            -14.3744
trainer/gradient_norm                       363.167
trainer/gradient_penalty                     -1.81584
trainer/gradient_percentage                  -0.0078312
exploration/num steps total              788000
exploration/num paths total                1948
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91479
exploration/Rewards Std                       1.27025
exploration/Rewards Max                       9.89935
exploration/Rewards Min                      -0.37069
exploration/Returns Mean                   4914.79
exploration/Returns Std                       0
exploration/Returns Max                    4914.79
exploration/Returns Min                    4914.79
exploration/Num Paths                         1
exploration/Average Returns                4914.79
evaluation_0/num steps total                  6.18106e+06
evaluation_0/num paths total              14336
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0465
evaluation_0/Rewards Std                      1.31724
evaluation_0/Rewards Max                     10.2723
evaluation_0/Rewards Min                     -0.430051
evaluation_0/Returns Mean                  5046.5
evaluation_0/Returns Std                     16.068
evaluation_0/Returns Max                   5068.51
evaluation_0/Returns Min                   5010.29
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5046.5
time/epoch (s)                                0
time/total (s)                            15128.5
Epoch                                       783
---------------------------------------  ----------------
2022-11-16 14:58:10.749495 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 784 finished
---------------------------------------  ----------------
epoch                                       784
total_step                               789000
replay_pool/size                         789000
trainer/alpha                                 0.0642672
trainer/alpha_loss                            0.0574385
trainer/entropy                              -6.02093
trainer/qf_loss                               8.01661
trainer/state_noise                           0.005
trainer/policy_loss                        -224.566
trainer/policy_loss_without_entropy         226.786
trainer/entropy_penalty                      -0.386948
trainer/entropy_percentage                   -0.00170623
trainer/Q1Pred Mean                         226.713
trainer/Q1Pred Std                           74.1947
trainer/Q1Pred Max                          309.944
trainer/Q1Pred Min                           19.0858
trainer/Q2Pred Mean                         227.416
trainer/Q2Pred Std                           74.0216
trainer/Q2Pred Max                          312.318
trainer/Q2Pred Min                           21.4117
trainer/QTargetWithReg Mean                 226.679
trainer/QTargetWithReg Std                   73.9804
trainer/QTargetWithReg Max                  314.48
trainer/QTargetWithReg Min                   20.3163
trainer/PolicyLossWithoutReg Mean           226.786
trainer/PolicyLossWithoutReg Std             72.9502
trainer/PolicyLossWithoutReg Max            310.992
trainer/PolicyLossWithoutReg Min             18.6433
trainer/gradient_norm                       366.631
trainer/gradient_penalty                     -1.83315
trainer/gradient_percentage                  -0.00808319
exploration/num steps total              789000
exploration/num paths total                1949
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9504
exploration/Rewards Std                       1.30212
exploration/Rewards Max                      10.0792
exploration/Rewards Min                      -0.485205
exploration/Returns Mean                   4950.4
exploration/Returns Std                       0
exploration/Returns Max                    4950.4
exploration/Returns Min                    4950.4
exploration/Num Paths                         1
exploration/Average Returns                4950.4
evaluation_0/num steps total                  6.18906e+06
evaluation_0/num paths total              14344
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.58413
evaluation_0/Rewards Std                      1.2376
evaluation_0/Rewards Max                      9.44832
evaluation_0/Rewards Min                     -0.490498
evaluation_0/Returns Mean                  4584.13
evaluation_0/Returns Std                      9.71828
evaluation_0/Returns Max                   4601.81
evaluation_0/Returns Min                   4568.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4584.13
time/epoch (s)                                0
time/total (s)                            15144.5
Epoch                                       784
---------------------------------------  ----------------
2022-11-16 14:58:26.546147 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 785 finished
---------------------------------------  ----------------
epoch                                       785
total_step                               790000
replay_pool/size                         790000
trainer/alpha                                 0.0625585
trainer/alpha_loss                           -1.29133
trainer/entropy                              -5.53409
trainer/qf_loss                               6.06127
trainer/state_noise                           0.005
trainer/policy_loss                        -226.898
trainer/policy_loss_without_entropy         228.94
trainer/entropy_penalty                      -0.346204
trainer/entropy_percentage                   -0.0015122
trainer/Q1Pred Mean                         228.754
trainer/Q1Pred Std                           78.5387
trainer/Q1Pred Max                          316.855
trainer/Q1Pred Min                           -4.2994
trainer/Q2Pred Mean                         228.878
trainer/Q2Pred Std                           78.6345
trainer/Q2Pred Max                          314.901
trainer/Q2Pred Min                           -1.05697
trainer/QTargetWithReg Mean                 228.711
trainer/QTargetWithReg Std                   78.4752
trainer/QTargetWithReg Max                  314.132
trainer/QTargetWithReg Min                   -0.582007
trainer/PolicyLossWithoutReg Mean           228.94
trainer/PolicyLossWithoutReg Std             77.8514
trainer/PolicyLossWithoutReg Max            314.197
trainer/PolicyLossWithoutReg Min             -1.55378
trainer/gradient_norm                       339.138
trainer/gradient_penalty                     -1.69569
trainer/gradient_percentage                  -0.0074067
exploration/num steps total              790000
exploration/num paths total                1950
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90822
exploration/Rewards Std                       1.27827
exploration/Rewards Max                       9.84258
exploration/Rewards Min                      -0.454304
exploration/Returns Mean                   4908.22
exploration/Returns Std                       0
exploration/Returns Max                    4908.22
exploration/Returns Min                    4908.22
exploration/Num Paths                         1
exploration/Average Returns                4908.22
evaluation_0/num steps total                  6.19706e+06
evaluation_0/num paths total              14352
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87495
evaluation_0/Rewards Std                      1.20141
evaluation_0/Rewards Max                      9.51647
evaluation_0/Rewards Min                     -0.453054
evaluation_0/Returns Mean                  4874.95
evaluation_0/Returns Std                     23.606
evaluation_0/Returns Max                   4905.12
evaluation_0/Returns Min                   4835.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4874.95
time/epoch (s)                                0
time/total (s)                            15160.3
Epoch                                       785
---------------------------------------  ----------------
2022-11-16 14:58:43.102762 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 786 finished
---------------------------------------  ----------------
epoch                                       786
total_step                               791000
replay_pool/size                         791000
trainer/alpha                                 0.0639187
trainer/alpha_loss                           -0.546294
trainer/entropy                              -5.80136
trainer/qf_loss                               7.01933
trainer/state_noise                           0.005
trainer/policy_loss                        -226.188
trainer/policy_loss_without_entropy         228.426
trainer/entropy_penalty                      -0.370815
trainer/entropy_percentage                   -0.00162335
trainer/Q1Pred Mean                         227.768
trainer/Q1Pred Std                           71.8705
trainer/Q1Pred Max                          311.945
trainer/Q1Pred Min                          -10.9188
trainer/Q2Pred Mean                         228.391
trainer/Q2Pred Std                           71.9434
trainer/Q2Pred Max                          311.639
trainer/Q2Pred Min                           -7.98011
trainer/QTargetWithReg Mean                 228.027
trainer/QTargetWithReg Std                   72.2298
trainer/QTargetWithReg Max                  313.403
trainer/QTargetWithReg Min                  -10.6135
trainer/PolicyLossWithoutReg Mean           228.426
trainer/PolicyLossWithoutReg Std             71.3024
trainer/PolicyLossWithoutReg Max            311.156
trainer/PolicyLossWithoutReg Min             -7.56873
trainer/gradient_norm                       373.368
trainer/gradient_penalty                     -1.86684
trainer/gradient_percentage                  -0.00817264
exploration/num steps total              791000
exploration/num paths total                1951
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.851
exploration/Rewards Std                       1.26918
exploration/Rewards Max                       9.88862
exploration/Rewards Min                      -0.420217
exploration/Returns Mean                   4851
exploration/Returns Std                       0
exploration/Returns Max                    4851
exploration/Returns Min                    4851
exploration/Num Paths                         1
exploration/Average Returns                4851
evaluation_0/num steps total                  6.20506e+06
evaluation_0/num paths total              14360
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97454
evaluation_0/Rewards Std                      1.25979
evaluation_0/Rewards Max                     10.0034
evaluation_0/Rewards Min                     -0.458655
evaluation_0/Returns Mean                  4974.54
evaluation_0/Returns Std                     19.6019
evaluation_0/Returns Max                   5003.71
evaluation_0/Returns Min                   4948.13
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4974.54
time/epoch (s)                                0
time/total (s)                            15176.8
Epoch                                       786
---------------------------------------  ----------------
2022-11-16 14:58:59.008981 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 787 finished
---------------------------------------  ----------------
epoch                                       787
total_step                               792000
replay_pool/size                         792000
trainer/alpha                                 0.062875
trainer/alpha_loss                           -0.265666
trainer/entropy                              -5.90397
trainer/qf_loss                               9.2702
trainer/state_noise                           0.005
trainer/policy_loss                        -226.086
trainer/policy_loss_without_entropy         228.309
trainer/entropy_penalty                      -0.371212
trainer/entropy_percentage                   -0.00162592
trainer/Q1Pred Mean                         227.875
trainer/Q1Pred Std                           74.6813
trainer/Q1Pred Max                          315.19
trainer/Q1Pred Min                            5.33648
trainer/Q2Pred Mean                         227.747
trainer/Q2Pred Std                           74.6281
trainer/Q2Pred Max                          315.111
trainer/Q2Pred Min                            7.08142
trainer/QTargetWithReg Mean                 227.673
trainer/QTargetWithReg Std                   74.4514
trainer/QTargetWithReg Max                  313.676
trainer/QTargetWithReg Min                    9.76795
trainer/PolicyLossWithoutReg Mean           228.309
trainer/PolicyLossWithoutReg Std             73.6515
trainer/PolicyLossWithoutReg Max            314.322
trainer/PolicyLossWithoutReg Min              6.05257
trainer/gradient_norm                       370.248
trainer/gradient_penalty                     -1.85124
trainer/gradient_percentage                  -0.0081085
exploration/num steps total              792000
exploration/num paths total                1952
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96629
exploration/Rewards Std                       1.28542
exploration/Rewards Max                      10.1343
exploration/Rewards Min                      -0.421361
exploration/Returns Mean                   4966.29
exploration/Returns Std                       0
exploration/Returns Max                    4966.29
exploration/Returns Min                    4966.29
exploration/Num Paths                         1
exploration/Average Returns                4966.29
evaluation_0/num steps total                  6.21306e+06
evaluation_0/num paths total              14368
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04917
evaluation_0/Rewards Std                      1.27215
evaluation_0/Rewards Max                     10.0083
evaluation_0/Rewards Min                     -0.420546
evaluation_0/Returns Mean                  5049.17
evaluation_0/Returns Std                     15.5257
evaluation_0/Returns Max                   5081.09
evaluation_0/Returns Min                   5024.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5049.17
time/epoch (s)                                0
time/total (s)                            15192.7
Epoch                                       787
---------------------------------------  ----------------
2022-11-16 14:59:15.594748 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 788 finished
---------------------------------------  ----------------
epoch                                       788
total_step                               793000
replay_pool/size                         793000
trainer/alpha                                 0.062634
trainer/alpha_loss                            2.32964
trainer/entropy                              -6.84082
trainer/qf_loss                               7.14107
trainer/state_noise                           0.005
trainer/policy_loss                        -230.927
trainer/policy_loss_without_entropy         233.156
trainer/entropy_penalty                      -0.428468
trainer/entropy_percentage                   -0.00183769
trainer/Q1Pred Mean                         231.946
trainer/Q1Pred Std                           71.483
trainer/Q1Pred Max                          314.586
trainer/Q1Pred Min                          -18.5448
trainer/Q2Pred Mean                         232.074
trainer/Q2Pred Std                           71.4652
trainer/Q2Pred Max                          315.272
trainer/Q2Pred Min                          -16.1801
trainer/QTargetWithReg Mean                 232.315
trainer/QTargetWithReg Std                   71.4107
trainer/QTargetWithReg Max                  313.837
trainer/QTargetWithReg Min                  -17.5313
trainer/PolicyLossWithoutReg Mean           233.156
trainer/PolicyLossWithoutReg Std             70.5912
trainer/PolicyLossWithoutReg Max            314.923
trainer/PolicyLossWithoutReg Min            -18.053
trainer/gradient_norm                       360.014
trainer/gradient_penalty                     -1.80007
trainer/gradient_percentage                  -0.00772047
exploration/num steps total              793000
exploration/num paths total                1953
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91887
exploration/Rewards Std                       1.27487
exploration/Rewards Max                       9.83972
exploration/Rewards Min                      -0.432768
exploration/Returns Mean                   4918.87
exploration/Returns Std                       0
exploration/Returns Max                    4918.87
exploration/Returns Min                    4918.87
exploration/Num Paths                         1
exploration/Average Returns                4918.87
evaluation_0/num steps total                  6.22106e+06
evaluation_0/num paths total              14376
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.87081
evaluation_0/Rewards Std                      1.26995
evaluation_0/Rewards Max                     10.0708
evaluation_0/Rewards Min                     -0.478492
evaluation_0/Returns Mean                  4870.81
evaluation_0/Returns Std                     48.4016
evaluation_0/Returns Max                   4912.08
evaluation_0/Returns Min                   4799.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4870.81
time/epoch (s)                                0
time/total (s)                            15209.3
Epoch                                       788
---------------------------------------  ----------------
2022-11-16 14:59:31.380908 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 789 finished
---------------------------------------  ----------------
epoch                                       789
total_step                               794000
replay_pool/size                         794000
trainer/alpha                                 0.0623519
trainer/alpha_loss                           -0.0088984
trainer/entropy                              -5.99679
trainer/qf_loss                               6.82982
trainer/state_noise                           0.005
trainer/policy_loss                        -228.253
trainer/policy_loss_without_entropy         230.373
trainer/entropy_penalty                      -0.373911
trainer/entropy_percentage                   -0.00162307
trainer/Q1Pred Mean                         229.785
trainer/Q1Pred Std                           76.6683
trainer/Q1Pred Max                          312.991
trainer/Q1Pred Min                          -12.3438
trainer/Q2Pred Mean                         230.021
trainer/Q2Pred Std                           76.4865
trainer/Q2Pred Max                          311.287
trainer/Q2Pred Min                            0.596833
trainer/QTargetWithReg Mean                 229.727
trainer/QTargetWithReg Std                   76.3665
trainer/QTargetWithReg Max                  311.294
trainer/QTargetWithReg Min                   -1.25724
trainer/PolicyLossWithoutReg Mean           230.373
trainer/PolicyLossWithoutReg Std             75.3578
trainer/PolicyLossWithoutReg Max            310.908
trainer/PolicyLossWithoutReg Min              2.19822
trainer/gradient_norm                       349.149
trainer/gradient_penalty                     -1.74574
trainer/gradient_percentage                  -0.0075779
exploration/num steps total              794000
exploration/num paths total                1954
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87488
exploration/Rewards Std                       1.2578
exploration/Rewards Max                      10.1742
exploration/Rewards Min                      -0.472577
exploration/Returns Mean                   4874.88
exploration/Returns Std                       0
exploration/Returns Max                    4874.88
exploration/Returns Min                    4874.88
exploration/Num Paths                         1
exploration/Average Returns                4874.88
evaluation_0/num steps total                  6.22906e+06
evaluation_0/num paths total              14384
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09341
evaluation_0/Rewards Std                      1.30214
evaluation_0/Rewards Max                     10.1533
evaluation_0/Rewards Min                     -0.452869
evaluation_0/Returns Mean                  5093.41
evaluation_0/Returns Std                     29.2755
evaluation_0/Returns Max                   5125.44
evaluation_0/Returns Min                   5037.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5093.41
time/epoch (s)                                0
time/total (s)                            15225.1
Epoch                                       789
---------------------------------------  ----------------
2022-11-16 14:59:47.793369 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 790 finished
---------------------------------------  ----------------
epoch                                       790
total_step                               795000
replay_pool/size                         795000
trainer/alpha                                 0.0604595
trainer/alpha_loss                            0.184834
trainer/entropy                              -6.06588
trainer/qf_loss                               5.27843
trainer/state_noise                           0.005
trainer/policy_loss                        -230.456
trainer/policy_loss_without_entropy         232.645
trainer/entropy_penalty                      -0.36674
trainer/entropy_percentage                   -0.0015764
trainer/Q1Pred Mean                         232.165
trainer/Q1Pred Std                           67.635
trainer/Q1Pred Max                          310.159
trainer/Q1Pred Min                            6.67704
trainer/Q2Pred Mean                         232.38
trainer/Q2Pred Std                           67.2076
trainer/Q2Pred Max                          310.465
trainer/Q2Pred Min                           12.4501
trainer/QTargetWithReg Mean                 232.298
trainer/QTargetWithReg Std                   67.4339
trainer/QTargetWithReg Max                  309.042
trainer/QTargetWithReg Min                    6.02035
trainer/PolicyLossWithoutReg Mean           232.645
trainer/PolicyLossWithoutReg Std             66.6311
trainer/PolicyLossWithoutReg Max            310.175
trainer/PolicyLossWithoutReg Min             12.048
trainer/gradient_norm                       364.29
trainer/gradient_penalty                     -1.82145
trainer/gradient_percentage                  -0.00782932
exploration/num steps total              795000
exploration/num paths total                1955
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89189
exploration/Rewards Std                       1.28024
exploration/Rewards Max                      10.3702
exploration/Rewards Min                      -0.441574
exploration/Returns Mean                   4891.89
exploration/Returns Std                       0
exploration/Returns Max                    4891.89
exploration/Returns Min                    4891.89
exploration/Num Paths                         1
exploration/Average Returns                4891.89
evaluation_0/num steps total                  6.23706e+06
evaluation_0/num paths total              14392
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15267
evaluation_0/Rewards Std                      1.28126
evaluation_0/Rewards Max                     10.2837
evaluation_0/Rewards Min                     -0.447919
evaluation_0/Returns Mean                  5152.67
evaluation_0/Returns Std                     26.0117
evaluation_0/Returns Max                   5187.97
evaluation_0/Returns Min                   5108.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5152.67
time/epoch (s)                                0
time/total (s)                            15241.5
Epoch                                       790
---------------------------------------  ----------------
2022-11-16 15:00:03.650957 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 791 finished
---------------------------------------  ----------------
epoch                                       791
total_step                               796000
replay_pool/size                         796000
trainer/alpha                                 0.0611535
trainer/alpha_loss                           -1.67123
trainer/entropy                              -5.4019
trainer/qf_loss                               6.49789
trainer/state_noise                           0.005
trainer/policy_loss                        -228.746
trainer/policy_loss_without_entropy         230.828
trainer/entropy_penalty                      -0.330345
trainer/entropy_percentage                   -0.00143113
trainer/Q1Pred Mean                         230.295
trainer/Q1Pred Std                           72.7324
trainer/Q1Pred Max                          314.671
trainer/Q1Pred Min                           -3.13944
trainer/Q2Pred Mean                         230.823
trainer/Q2Pred Std                           72.797
trainer/Q2Pred Max                          314.954
trainer/Q2Pred Min                            6.29898
trainer/QTargetWithReg Mean                 230.107
trainer/QTargetWithReg Std                   72.6504
trainer/QTargetWithReg Max                  314.823
trainer/QTargetWithReg Min                   -1.52576
trainer/PolicyLossWithoutReg Mean           230.828
trainer/PolicyLossWithoutReg Std             71.975
trainer/PolicyLossWithoutReg Max            314.472
trainer/PolicyLossWithoutReg Min             -0.672513
trainer/gradient_norm                       350.145
trainer/gradient_penalty                     -1.75072
trainer/gradient_percentage                  -0.00758455
exploration/num steps total              796000
exploration/num paths total                1956
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96047
exploration/Rewards Std                       1.28964
exploration/Rewards Max                       9.97262
exploration/Rewards Min                      -0.47493
exploration/Returns Mean                   4960.47
exploration/Returns Std                       0
exploration/Returns Max                    4960.47
exploration/Returns Min                    4960.47
exploration/Num Paths                         1
exploration/Average Returns                4960.47
evaluation_0/num steps total                  6.24506e+06
evaluation_0/num paths total              14400
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93442
evaluation_0/Rewards Std                      1.24473
evaluation_0/Rewards Max                      9.9883
evaluation_0/Rewards Min                     -0.413626
evaluation_0/Returns Mean                  4934.42
evaluation_0/Returns Std                     15.7249
evaluation_0/Returns Max                   4952.36
evaluation_0/Returns Min                   4908.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4934.42
time/epoch (s)                                0
time/total (s)                            15257.4
Epoch                                       791
---------------------------------------  ----------------
2022-11-16 15:00:19.663290 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 792 finished
---------------------------------------  ----------------
epoch                                       792
total_step                               797000
replay_pool/size                         797000
trainer/alpha                                 0.0605952
trainer/alpha_loss                           -0.206652
trainer/entropy                              -5.92629
trainer/qf_loss                               6.92833
trainer/state_noise                           0.005
trainer/policy_loss                        -226.959
trainer/policy_loss_without_entropy         229.081
trainer/entropy_penalty                      -0.359104
trainer/entropy_percentage                   -0.00156759
trainer/Q1Pred Mean                         229.008
trainer/Q1Pred Std                           73.7483
trainer/Q1Pred Max                          313.34
trainer/Q1Pred Min                           22.1202
trainer/Q2Pred Mean                         229.089
trainer/Q2Pred Std                           73.4732
trainer/Q2Pred Max                          311.961
trainer/Q2Pred Min                           23.6821
trainer/QTargetWithReg Mean                 228.863
trainer/QTargetWithReg Std                   73.6583
trainer/QTargetWithReg Max                  313.073
trainer/QTargetWithReg Min                   22.3997
trainer/PolicyLossWithoutReg Mean           229.081
trainer/PolicyLossWithoutReg Std             72.7543
trainer/PolicyLossWithoutReg Max            311.784
trainer/PolicyLossWithoutReg Min             22.4056
trainer/gradient_norm                       352.62
trainer/gradient_penalty                     -1.7631
trainer/gradient_percentage                  -0.0076964
exploration/num steps total              797000
exploration/num paths total                1957
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.81831
exploration/Rewards Std                       1.27382
exploration/Rewards Max                       9.91171
exploration/Rewards Min                      -0.387893
exploration/Returns Mean                   4818.31
exploration/Returns Std                       0
exploration/Returns Max                    4818.31
exploration/Returns Min                    4818.31
exploration/Num Paths                         1
exploration/Average Returns                4818.31
evaluation_0/num steps total                  6.25306e+06
evaluation_0/num paths total              14408
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.77574
evaluation_0/Rewards Std                      1.2327
evaluation_0/Rewards Max                      9.60623
evaluation_0/Rewards Min                     -0.442888
evaluation_0/Returns Mean                  4775.74
evaluation_0/Returns Std                     11.2969
evaluation_0/Returns Max                   4793.83
evaluation_0/Returns Min                   4756.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4775.74
time/epoch (s)                                0
time/total (s)                            15273.4
Epoch                                       792
---------------------------------------  ----------------
2022-11-16 15:00:36.070260 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 793 finished
---------------------------------------  ----------------
epoch                                       793
total_step                               798000
replay_pool/size                         798000
trainer/alpha                                 0.0611083
trainer/alpha_loss                           -0.236103
trainer/entropy                              -5.91553
trainer/qf_loss                               8.14262
trainer/state_noise                           0.005
trainer/policy_loss                        -231.747
trainer/policy_loss_without_entropy         233.825
trainer/entropy_penalty                      -0.361488
trainer/entropy_percentage                   -0.00154598
trainer/Q1Pred Mean                         232.801
trainer/Q1Pred Std                           74.1235
trainer/Q1Pred Max                          314.826
trainer/Q1Pred Min                            4.75519
trainer/Q2Pred Mean                         233.086
trainer/Q2Pred Std                           74.2975
trainer/Q2Pred Max                          313.906
trainer/Q2Pred Min                            3.63358
trainer/QTargetWithReg Mean                 233.284
trainer/QTargetWithReg Std                   74.5786
trainer/QTargetWithReg Max                  313.755
trainer/QTargetWithReg Min                    7.30767
trainer/PolicyLossWithoutReg Mean           233.825
trainer/PolicyLossWithoutReg Std             73.9705
trainer/PolicyLossWithoutReg Max            314.938
trainer/PolicyLossWithoutReg Min              7.2303
trainer/gradient_norm                       343.337
trainer/gradient_penalty                     -1.71668
trainer/gradient_percentage                  -0.00734174
exploration/num steps total              798000
exploration/num paths total                1958
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84193
exploration/Rewards Std                       1.23104
exploration/Rewards Max                       9.53584
exploration/Rewards Min                      -0.530027
exploration/Returns Mean                   4841.93
exploration/Returns Std                       0
exploration/Returns Max                    4841.93
exploration/Returns Min                    4841.93
exploration/Num Paths                         1
exploration/Average Returns                4841.93
evaluation_0/num steps total                  6.26106e+06
evaluation_0/num paths total              14416
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93999
evaluation_0/Rewards Std                      1.23923
evaluation_0/Rewards Max                      9.79543
evaluation_0/Rewards Min                     -0.483516
evaluation_0/Returns Mean                  4939.99
evaluation_0/Returns Std                     22.8983
evaluation_0/Returns Max                   4973.02
evaluation_0/Returns Min                   4905.8
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4939.99
time/epoch (s)                                0
time/total (s)                            15289.8
Epoch                                       793
---------------------------------------  ----------------
2022-11-16 15:00:51.901596 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 794 finished
---------------------------------------  ----------------
epoch                                       794
total_step                               799000
replay_pool/size                         799000
trainer/alpha                                 0.0622054
trainer/alpha_loss                           -0.279087
trainer/entropy                              -5.89951
trainer/qf_loss                               7.61335
trainer/state_noise                           0.005
trainer/policy_loss                        -229.772
trainer/policy_loss_without_entropy         231.923
trainer/entropy_penalty                      -0.366982
trainer/entropy_percentage                   -0.00158234
trainer/Q1Pred Mean                         231.068
trainer/Q1Pred Std                           76.0663
trainer/Q1Pred Max                          315.342
trainer/Q1Pred Min                            5.06853
trainer/Q2Pred Mean                         231.476
trainer/Q2Pred Std                           76.0991
trainer/Q2Pred Max                          312.455
trainer/Q2Pred Min                            5.699
trainer/QTargetWithReg Mean                 231.138
trainer/QTargetWithReg Std                   76.2495
trainer/QTargetWithReg Max                  311.493
trainer/QTargetWithReg Min                    3.5363
trainer/PolicyLossWithoutReg Mean           231.923
trainer/PolicyLossWithoutReg Std             75.3113
trainer/PolicyLossWithoutReg Max            312.717
trainer/PolicyLossWithoutReg Min              6.22545
trainer/gradient_norm                       356.882
trainer/gradient_penalty                     -1.78441
trainer/gradient_percentage                  -0.00769397
exploration/num steps total              799000
exploration/num paths total                1959
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89265
exploration/Rewards Std                       1.27817
exploration/Rewards Max                       9.93323
exploration/Rewards Min                      -0.464773
exploration/Returns Mean                   4892.65
exploration/Returns Std                       0
exploration/Returns Max                    4892.65
exploration/Returns Min                    4892.65
exploration/Num Paths                         1
exploration/Average Returns                4892.65
evaluation_0/num steps total                  6.26906e+06
evaluation_0/num paths total              14424
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.98968
evaluation_0/Rewards Std                      1.32037
evaluation_0/Rewards Max                     10.1805
evaluation_0/Rewards Min                     -0.425931
evaluation_0/Returns Mean                  4989.68
evaluation_0/Returns Std                     48.6643
evaluation_0/Returns Max                   5082.04
evaluation_0/Returns Min                   4940.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4989.68
time/epoch (s)                                0
time/total (s)                            15305.6
Epoch                                       794
---------------------------------------  ----------------
2022-11-16 15:01:08.530134 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 795 finished
---------------------------------------  ----------------
epoch                                       795
total_step                               800000
replay_pool/size                         800000
trainer/alpha                                 0.0601469
trainer/alpha_loss                           -1.13912
trainer/entropy                              -5.59474
trainer/qf_loss                               8.63427
trainer/state_noise                           0.005
trainer/policy_loss                        -225.496
trainer/policy_loss_without_entropy         227.593
trainer/entropy_penalty                      -0.336506
trainer/entropy_percentage                   -0.00147855
trainer/Q1Pred Mean                         226.568
trainer/Q1Pred Std                           73.965
trainer/Q1Pred Max                          312.705
trainer/Q1Pred Min                           14.1091
trainer/Q2Pred Mean                         225.996
trainer/Q2Pred Std                           73.5581
trainer/Q2Pred Max                          311.741
trainer/Q2Pred Min                           17.1936
trainer/QTargetWithReg Mean                 226.649
trainer/QTargetWithReg Std                   73.8878
trainer/QTargetWithReg Max                  313.63
trainer/QTargetWithReg Min                   12.4936
trainer/PolicyLossWithoutReg Mean           227.593
trainer/PolicyLossWithoutReg Std             72.9289
trainer/PolicyLossWithoutReg Max            312.235
trainer/PolicyLossWithoutReg Min             18.6308
trainer/gradient_norm                       351.929
trainer/gradient_penalty                     -1.75965
trainer/gradient_percentage                  -0.00773156
exploration/num steps total              800000
exploration/num paths total                1960
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.80864
exploration/Rewards Std                       1.28478
exploration/Rewards Max                       9.86463
exploration/Rewards Min                      -0.462726
exploration/Returns Mean                   4808.64
exploration/Returns Std                       0
exploration/Returns Max                    4808.64
exploration/Returns Min                    4808.64
exploration/Num Paths                         1
exploration/Average Returns                4808.64
evaluation_0/num steps total                  6.27706e+06
evaluation_0/num paths total              14432
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86752
evaluation_0/Rewards Std                      1.25103
evaluation_0/Rewards Max                      9.61949
evaluation_0/Rewards Min                     -0.476088
evaluation_0/Returns Mean                  4867.52
evaluation_0/Returns Std                     14.86
evaluation_0/Returns Max                   4888.27
evaluation_0/Returns Min                   4842.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4867.52
time/epoch (s)                                0
time/total (s)                            15322.2
Epoch                                       795
---------------------------------------  ----------------
2022-11-16 15:01:24.342546 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 796 finished
---------------------------------------  ----------------
epoch                                       796
total_step                               801000
replay_pool/size                         801000
trainer/alpha                                 0.0621908
trainer/alpha_loss                            0.701066
trainer/entropy                              -6.25241
trainer/qf_loss                               6.35259
trainer/state_noise                           0.005
trainer/policy_loss                        -225.955
trainer/policy_loss_without_entropy         228.096
trainer/entropy_penalty                      -0.388842
trainer/entropy_percentage                   -0.00170473
trainer/Q1Pred Mean                         227.954
trainer/Q1Pred Std                           75.0369
trainer/Q1Pred Max                          313.778
trainer/Q1Pred Min                           -1.28283
trainer/Q2Pred Mean                         227.337
trainer/Q2Pred Std                           75.0098
trainer/Q2Pred Max                          316.818
trainer/Q2Pred Min                           -3.95056
trainer/QTargetWithReg Mean                 227.746
trainer/QTargetWithReg Std                   75.0258
trainer/QTargetWithReg Max                  314.905
trainer/QTargetWithReg Min                   -1.75898
trainer/PolicyLossWithoutReg Mean           228.096
trainer/PolicyLossWithoutReg Std             74.2359
trainer/PolicyLossWithoutReg Max            315.353
trainer/PolicyLossWithoutReg Min              0.221077
trainer/gradient_norm                       350.5
trainer/gradient_penalty                     -1.7525
trainer/gradient_percentage                  -0.00768318
exploration/num steps total              801000
exploration/num paths total                1961
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85004
exploration/Rewards Std                       1.32336
exploration/Rewards Max                      10.4435
exploration/Rewards Min                      -0.455358
exploration/Returns Mean                   4850.04
exploration/Returns Std                       0
exploration/Returns Max                    4850.04
exploration/Returns Min                    4850.04
exploration/Num Paths                         1
exploration/Average Returns                4850.04
evaluation_0/num steps total                  6.28506e+06
evaluation_0/num paths total              14440
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97168
evaluation_0/Rewards Std                      1.23315
evaluation_0/Rewards Max                     10.2579
evaluation_0/Rewards Min                     -0.457791
evaluation_0/Returns Mean                  4971.68
evaluation_0/Returns Std                     27.5711
evaluation_0/Returns Max                   5006.82
evaluation_0/Returns Min                   4925.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4971.68
time/epoch (s)                                0
time/total (s)                            15338
Epoch                                       796
---------------------------------------  ----------------
2022-11-16 15:01:40.912981 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 797 finished
---------------------------------------  ----------------
epoch                                       797
total_step                               802000
replay_pool/size                         802000
trainer/alpha                                 0.0609574
trainer/alpha_loss                            0.02806
trainer/entropy                              -6.01003
trainer/qf_loss                               6.04324
trainer/state_noise                           0.005
trainer/policy_loss                        -236.141
trainer/policy_loss_without_entropy         238.3
trainer/entropy_penalty                      -0.366356
trainer/entropy_percentage                   -0.00153737
trainer/Q1Pred Mean                         237.79
trainer/Q1Pred Std                           70.7112
trainer/Q1Pred Max                          313.309
trainer/Q1Pred Min                            9.08237
trainer/Q2Pred Mean                         237.465
trainer/Q2Pred Std                           70.6595
trainer/Q2Pred Max                          312.9
trainer/Q2Pred Min                            7.7067
trainer/QTargetWithReg Mean                 237.156
trainer/QTargetWithReg Std                   71.0517
trainer/QTargetWithReg Max                  312.201
trainer/QTargetWithReg Min                    8.18543
trainer/PolicyLossWithoutReg Mean           238.3
trainer/PolicyLossWithoutReg Std             69.8846
trainer/PolicyLossWithoutReg Max            313.572
trainer/PolicyLossWithoutReg Min             10.4718
trainer/gradient_norm                       358.689
trainer/gradient_penalty                     -1.79345
trainer/gradient_percentage                  -0.007526
exploration/num steps total              802000
exploration/num paths total                1962
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.85422
exploration/Rewards Std                       1.26768
exploration/Rewards Max                      10.0295
exploration/Rewards Min                      -0.461424
exploration/Returns Mean                   4854.22
exploration/Returns Std                       0
exploration/Returns Max                    4854.22
exploration/Returns Min                    4854.22
exploration/Num Paths                         1
exploration/Average Returns                4854.22
evaluation_0/num steps total                  6.29306e+06
evaluation_0/num paths total              14448
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86226
evaluation_0/Rewards Std                      1.24648
evaluation_0/Rewards Max                      9.85072
evaluation_0/Rewards Min                     -0.576247
evaluation_0/Returns Mean                  4862.26
evaluation_0/Returns Std                      4.78415
evaluation_0/Returns Max                   4868.86
evaluation_0/Returns Min                   4853.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4862.26
time/epoch (s)                                0
time/total (s)                            15354.6
Epoch                                       797
---------------------------------------  ----------------
2022-11-16 15:01:56.647640 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 798 finished
---------------------------------------  ----------------
epoch                                       798
total_step                               803000
replay_pool/size                         803000
trainer/alpha                                 0.0605347
trainer/alpha_loss                           -0.332108
trainer/entropy                              -5.88158
trainer/qf_loss                               5.74999
trainer/state_noise                           0.005
trainer/policy_loss                        -234.698
trainer/policy_loss_without_entropy         236.825
trainer/entropy_penalty                      -0.35604
trainer/entropy_percentage                   -0.00150339
trainer/Q1Pred Mean                         236.438
trainer/Q1Pred Std                           73.3813
trainer/Q1Pred Max                          312.677
trainer/Q1Pred Min                           12.5329
trainer/Q2Pred Mean                         236.204
trainer/Q2Pred Std                           73.1461
trainer/Q2Pred Max                          313.453
trainer/Q2Pred Min                           13.2528
trainer/QTargetWithReg Mean                 236.248
trainer/QTargetWithReg Std                   73.0943
trainer/QTargetWithReg Max                  312.928
trainer/QTargetWithReg Min                   13.5331
trainer/PolicyLossWithoutReg Mean           236.825
trainer/PolicyLossWithoutReg Std             72.5113
trainer/PolicyLossWithoutReg Max            312.683
trainer/PolicyLossWithoutReg Min             12.4599
trainer/gradient_norm                       354.148
trainer/gradient_penalty                     -1.77074
trainer/gradient_percentage                  -0.007477
exploration/num steps total              803000
exploration/num paths total                1963
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90773
exploration/Rewards Std                       1.26667
exploration/Rewards Max                       9.97494
exploration/Rewards Min                      -0.471845
exploration/Returns Mean                   4907.73
exploration/Returns Std                       0
exploration/Returns Max                    4907.73
exploration/Returns Min                    4907.73
exploration/Num Paths                         1
exploration/Average Returns                4907.73
evaluation_0/num steps total                  6.30106e+06
evaluation_0/num paths total              14456
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.99836
evaluation_0/Rewards Std                      1.30714
evaluation_0/Rewards Max                     10.2836
evaluation_0/Rewards Min                     -0.470254
evaluation_0/Returns Mean                  4998.36
evaluation_0/Returns Std                     20.0806
evaluation_0/Returns Max                   5030.2
evaluation_0/Returns Min                   4965.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4998.36
time/epoch (s)                                0
time/total (s)                            15370.4
Epoch                                       798
---------------------------------------  ----------------
2022-11-16 15:02:13.161619 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 799 finished
---------------------------------------  ----------------
epoch                                       799
total_step                               804000
replay_pool/size                         804000
trainer/alpha                                 0.0608532
trainer/alpha_loss                            0.431444
trainer/entropy                              -6.15414
trainer/qf_loss                               4.88693
trainer/state_noise                           0.005
trainer/policy_loss                        -228.076
trainer/policy_loss_without_entropy         230.245
trainer/entropy_penalty                      -0.374499
trainer/entropy_percentage                   -0.00162652
trainer/Q1Pred Mean                         228.925
trainer/Q1Pred Std                           74.0198
trainer/Q1Pred Max                          315.388
trainer/Q1Pred Min                           -5.66322
trainer/Q2Pred Mean                         229.344
trainer/Q2Pred Std                           74.217
trainer/Q2Pred Max                          315.338
trainer/Q2Pred Min                           -7.08656
trainer/QTargetWithReg Mean                 229.24
trainer/QTargetWithReg Std                   74.3107
trainer/QTargetWithReg Max                  315.673
trainer/QTargetWithReg Min                    0.0984115
trainer/PolicyLossWithoutReg Mean           230.245
trainer/PolicyLossWithoutReg Std             73.0688
trainer/PolicyLossWithoutReg Max            315.728
trainer/PolicyLossWithoutReg Min              2.89406
trainer/gradient_norm                       358.749
trainer/gradient_penalty                     -1.79375
trainer/gradient_percentage                  -0.00779061
exploration/num steps total              804000
exploration/num paths total                1964
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.82535
exploration/Rewards Std                       1.27352
exploration/Rewards Max                       9.69163
exploration/Rewards Min                      -0.386861
exploration/Returns Mean                   4825.35
exploration/Returns Std                       0
exploration/Returns Max                    4825.35
exploration/Returns Min                    4825.35
exploration/Num Paths                         1
exploration/Average Returns                4825.35
evaluation_0/num steps total                  6.30906e+06
evaluation_0/num paths total              14464
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83784
evaluation_0/Rewards Std                      1.20282
evaluation_0/Rewards Max                      9.53238
evaluation_0/Rewards Min                     -0.476728
evaluation_0/Returns Mean                  4837.84
evaluation_0/Returns Std                      5.92593
evaluation_0/Returns Max                   4845.35
evaluation_0/Returns Min                   4829.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4837.84
time/epoch (s)                                0
time/total (s)                            15386.9
Epoch                                       799
---------------------------------------  ----------------
2022-11-16 15:02:29.011532 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 800 finished
---------------------------------------  ----------------
epoch                                       800
total_step                               805000
replay_pool/size                         805000
trainer/alpha                                 0.0621367
trainer/alpha_loss                            1.48971
trainer/entropy                              -6.53616
trainer/qf_loss                               6.58447
trainer/state_noise                           0.005
trainer/policy_loss                        -225.002
trainer/policy_loss_without_entropy         227.195
trainer/entropy_penalty                      -0.406135
trainer/entropy_percentage                   -0.00178761
trainer/Q1Pred Mean                         226.911
trainer/Q1Pred Std                           74.4139
trainer/Q1Pred Max                          316.203
trainer/Q1Pred Min                          -10.9259
trainer/Q2Pred Mean                         226.63
trainer/Q2Pred Std                           74.5147
trainer/Q2Pred Max                          315.368
trainer/Q2Pred Min                          -11.9519
trainer/QTargetWithReg Mean                 226.252
trainer/QTargetWithReg Std                   74.5419
trainer/QTargetWithReg Max                  314.542
trainer/QTargetWithReg Min                   -8.74367
trainer/PolicyLossWithoutReg Mean           227.195
trainer/PolicyLossWithoutReg Std             73.4487
trainer/PolicyLossWithoutReg Max            315.142
trainer/PolicyLossWithoutReg Min             -9.92468
trainer/gradient_norm                       357.263
trainer/gradient_penalty                     -1.78631
trainer/gradient_percentage                  -0.00786248
exploration/num steps total              805000
exploration/num paths total                1965
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95699
exploration/Rewards Std                       1.27789
exploration/Rewards Max                      10.0774
exploration/Rewards Min                      -0.43067
exploration/Returns Mean                   4956.99
exploration/Returns Std                       0
exploration/Returns Max                    4956.99
exploration/Returns Min                    4956.99
exploration/Num Paths                         1
exploration/Average Returns                4956.99
evaluation_0/num steps total                  6.31706e+06
evaluation_0/num paths total              14472
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.92581
evaluation_0/Rewards Std                      1.30402
evaluation_0/Rewards Max                     10.1666
evaluation_0/Rewards Min                     -0.549365
evaluation_0/Returns Mean                  4925.81
evaluation_0/Returns Std                     20.0934
evaluation_0/Returns Max                   4942.79
evaluation_0/Returns Min                   4883.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4925.81
time/epoch (s)                                0
time/total (s)                            15402.7
Epoch                                       800
---------------------------------------  ----------------
2022-11-16 15:02:45.213820 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 801 finished
---------------------------------------  ----------------
epoch                                       801
total_step                               806000
replay_pool/size                         806000
trainer/alpha                                 0.0603256
trainer/alpha_loss                           -0.552068
trainer/entropy                              -5.80338
trainer/qf_loss                               7.73474
trainer/state_noise                           0.005
trainer/policy_loss                        -222.038
trainer/policy_loss_without_entropy         224.117
trainer/entropy_penalty                      -0.350093
trainer/entropy_percentage                   -0.0015621
trainer/Q1Pred Mean                         223.593
trainer/Q1Pred Std                           77.8723
trainer/Q1Pred Max                          315.295
trainer/Q1Pred Min                            7.39355
trainer/Q2Pred Mean                         222.782
trainer/Q2Pred Std                           77.743
trainer/Q2Pred Max                          315.271
trainer/Q2Pred Min                            6.3627
trainer/QTargetWithReg Mean                 223.948
trainer/QTargetWithReg Std                   78.0238
trainer/QTargetWithReg Max                  316.018
trainer/QTargetWithReg Min                    8.29037
trainer/PolicyLossWithoutReg Mean           224.117
trainer/PolicyLossWithoutReg Std             77.3296
trainer/PolicyLossWithoutReg Max            315.45
trainer/PolicyLossWithoutReg Min              6.5586
trainer/gradient_norm                       345.73
trainer/gradient_penalty                     -1.72865
trainer/gradient_percentage                  -0.00771318
exploration/num steps total              806000
exploration/num paths total                1966
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.90984
exploration/Rewards Std                       1.32845
exploration/Rewards Max                      10.5495
exploration/Rewards Min                      -0.613247
exploration/Returns Mean                   4909.84
exploration/Returns Std                       0
exploration/Returns Max                    4909.84
exploration/Returns Min                    4909.84
exploration/Num Paths                         1
exploration/Average Returns                4909.84
evaluation_0/num steps total                  6.32506e+06
evaluation_0/num paths total              14480
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.61582
evaluation_0/Rewards Std                      1.22756
evaluation_0/Rewards Max                      9.47145
evaluation_0/Rewards Min                     -0.542139
evaluation_0/Returns Mean                  4615.82
evaluation_0/Returns Std                     17.3504
evaluation_0/Returns Max                   4634.65
evaluation_0/Returns Min                   4576.99
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4615.82
time/epoch (s)                                0
time/total (s)                            15418.9
Epoch                                       801
---------------------------------------  ----------------
2022-11-16 15:03:01.323741 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 802 finished
---------------------------------------  ----------------
epoch                                       802
total_step                               807000
replay_pool/size                         807000
trainer/alpha                                 0.0610256
trainer/alpha_loss                            1.30489
trainer/entropy                              -6.46662
trainer/qf_loss                              12.1533
trainer/state_noise                           0.005
trainer/policy_loss                        -229.518
trainer/policy_loss_without_entropy         231.74
trainer/entropy_penalty                      -0.39463
trainer/entropy_percentage                   -0.0017029
trainer/Q1Pred Mean                         230.997
trainer/Q1Pred Std                           69.712
trainer/Q1Pred Max                          318.617
trainer/Q1Pred Min                           20.6769
trainer/Q2Pred Mean                         231.077
trainer/Q2Pred Std                           70.0915
trainer/Q2Pred Max                          317.625
trainer/Q2Pred Min                           16.9044
trainer/QTargetWithReg Mean                 231.505
trainer/QTargetWithReg Std                   69.7053
trainer/QTargetWithReg Max                  317.199
trainer/QTargetWithReg Min                    5.18108
trainer/PolicyLossWithoutReg Mean           231.74
trainer/PolicyLossWithoutReg Std             68.9577
trainer/PolicyLossWithoutReg Max            317.572
trainer/PolicyLossWithoutReg Min             16.8172
trainer/gradient_norm                       365.372
trainer/gradient_penalty                     -1.82686
trainer/gradient_percentage                  -0.00788324
exploration/num steps total              807000
exploration/num paths total                1967
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93123
exploration/Rewards Std                       1.28082
exploration/Rewards Max                      10.0296
exploration/Rewards Min                      -0.39648
exploration/Returns Mean                   4931.23
exploration/Returns Std                       0
exploration/Returns Max                    4931.23
exploration/Returns Min                    4931.23
exploration/Num Paths                         1
exploration/Average Returns                4931.23
evaluation_0/num steps total                  6.33306e+06
evaluation_0/num paths total              14488
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.73122
evaluation_0/Rewards Std                      1.25523
evaluation_0/Rewards Max                     10.256
evaluation_0/Rewards Min                     -0.509644
evaluation_0/Returns Mean                  4731.22
evaluation_0/Returns Std                    139.331
evaluation_0/Returns Max                   4995.96
evaluation_0/Returns Min                   4585.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4731.22
time/epoch (s)                                0
time/total (s)                            15435
Epoch                                       802
---------------------------------------  ----------------
2022-11-16 15:03:17.132904 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 803 finished
---------------------------------------  ----------------
epoch                                       803
total_step                               808000
replay_pool/size                         808000
trainer/alpha                                 0.0611594
trainer/alpha_loss                           -0.411816
trainer/entropy                              -5.85262
trainer/qf_loss                               6.61486
trainer/state_noise                           0.005
trainer/policy_loss                        -232.514
trainer/policy_loss_without_entropy         234.604
trainer/entropy_penalty                      -0.357943
trainer/entropy_percentage                   -0.00152573
trainer/Q1Pred Mean                         234.29
trainer/Q1Pred Std                           74.2509
trainer/Q1Pred Max                          316.141
trainer/Q1Pred Min                           -7.58626
trainer/Q2Pred Mean                         234.315
trainer/Q2Pred Std                           74.5777
trainer/Q2Pred Max                          316.004
trainer/Q2Pred Min                           -8.41195
trainer/QTargetWithReg Mean                 233.982
trainer/QTargetWithReg Std                   74.3009
trainer/QTargetWithReg Max                  315.899
trainer/QTargetWithReg Min                    1.72429
trainer/PolicyLossWithoutReg Mean           234.604
trainer/PolicyLossWithoutReg Std             73.6144
trainer/PolicyLossWithoutReg Max            315.959
trainer/PolicyLossWithoutReg Min             -4.54812
trainer/gradient_norm                       346.396
trainer/gradient_penalty                     -1.73198
trainer/gradient_percentage                  -0.00738258
exploration/num steps total              808000
exploration/num paths total                1968
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95139
exploration/Rewards Std                       1.30118
exploration/Rewards Max                       9.89845
exploration/Rewards Min                      -0.508066
exploration/Returns Mean                   4951.39
exploration/Returns Std                       0
exploration/Returns Max                    4951.39
exploration/Returns Min                    4951.39
exploration/Num Paths                         1
exploration/Average Returns                4951.39
evaluation_0/num steps total                  6.34106e+06
evaluation_0/num paths total              14496
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.93997
evaluation_0/Rewards Std                      1.31786
evaluation_0/Rewards Max                     10.2969
evaluation_0/Rewards Min                     -0.486122
evaluation_0/Returns Mean                  4939.97
evaluation_0/Returns Std                     15.7168
evaluation_0/Returns Max                   4957.79
evaluation_0/Returns Min                   4911.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4939.97
time/epoch (s)                                0
time/total (s)                            15450.8
Epoch                                       803
---------------------------------------  ----------------
2022-11-16 15:03:33.596027 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 804 finished
---------------------------------------  ----------------
epoch                                       804
total_step                               809000
replay_pool/size                         809000
trainer/alpha                                 0.0599223
trainer/alpha_loss                            0.701383
trainer/entropy                              -6.24919
trainer/qf_loss                              11.576
trainer/state_noise                           0.005
trainer/policy_loss                        -228.279
trainer/policy_loss_without_entropy         230.46
trainer/entropy_penalty                      -0.374466
trainer/entropy_percentage                   -0.00162486
trainer/Q1Pred Mean                         229.819
trainer/Q1Pred Std                           77.9552
trainer/Q1Pred Max                          314.023
trainer/Q1Pred Min                            5.76233
trainer/Q2Pred Mean                         229.863
trainer/Q2Pred Std                           78.2291
trainer/Q2Pred Max                          314.221
trainer/Q2Pred Min                           -0.265898
trainer/QTargetWithReg Mean                 229.006
trainer/QTargetWithReg Std                   78.0139
trainer/QTargetWithReg Max                  313.127
trainer/QTargetWithReg Min                    0.952818
trainer/PolicyLossWithoutReg Mean           230.46
trainer/PolicyLossWithoutReg Std             77.2589
trainer/PolicyLossWithoutReg Max            313.578
trainer/PolicyLossWithoutReg Min              4.46215
trainer/gradient_norm                       361.335
trainer/gradient_penalty                     -1.80667
trainer/gradient_percentage                  -0.00783943
exploration/num steps total              809000
exploration/num paths total                1969
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02546
exploration/Rewards Std                       1.29661
exploration/Rewards Max                      10.1128
exploration/Rewards Min                      -0.543308
exploration/Returns Mean                   5025.46
exploration/Returns Std                       0
exploration/Returns Max                    5025.46
exploration/Returns Min                    5025.46
exploration/Num Paths                         1
exploration/Average Returns                5025.46
evaluation_0/num steps total                  6.34906e+06
evaluation_0/num paths total              14504
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.91319
evaluation_0/Rewards Std                      1.20646
evaluation_0/Rewards Max                      9.60722
evaluation_0/Rewards Min                     -0.465616
evaluation_0/Returns Mean                  4913.19
evaluation_0/Returns Std                     16.0333
evaluation_0/Returns Max                   4940.06
evaluation_0/Returns Min                   4883.41
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4913.19
time/epoch (s)                                0
time/total (s)                            15467.3
Epoch                                       804
---------------------------------------  ----------------
2022-11-16 15:03:49.495719 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 805 finished
---------------------------------------  ----------------
epoch                                       805
total_step                               810000
replay_pool/size                         810000
trainer/alpha                                 0.0610352
trainer/alpha_loss                            0.971488
trainer/entropy                              -6.3474
trainer/qf_loss                              10.8448
trainer/state_noise                           0.005
trainer/policy_loss                        -234.361
trainer/policy_loss_without_entropy         236.531
trainer/entropy_penalty                      -0.387414
trainer/entropy_percentage                   -0.0016379
trainer/Q1Pred Mean                         236.437
trainer/Q1Pred Std                           69.158
trainer/Q1Pred Max                          317.341
trainer/Q1Pred Min                          -18.9691
trainer/Q2Pred Mean                         236.718
trainer/Q2Pred Std                           69.3161
trainer/Q2Pred Max                          317.557
trainer/Q2Pred Min                          -20.8112
trainer/QTargetWithReg Mean                 235.845
trainer/QTargetWithReg Std                   69.3967
trainer/QTargetWithReg Max                  316.885
trainer/QTargetWithReg Min                  -21.8604
trainer/PolicyLossWithoutReg Mean           236.531
trainer/PolicyLossWithoutReg Std             68.4216
trainer/PolicyLossWithoutReg Max            316.863
trainer/PolicyLossWithoutReg Min            -16.5239
trainer/gradient_norm                       356.521
trainer/gradient_penalty                     -1.78261
trainer/gradient_percentage                  -0.00753645
exploration/num steps total              810000
exploration/num paths total                1970
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9283
exploration/Rewards Std                       1.24598
exploration/Rewards Max                       9.76579
exploration/Rewards Min                      -0.542384
exploration/Returns Mean                   4928.3
exploration/Returns Std                       0
exploration/Returns Max                    4928.3
exploration/Returns Min                    4928.3
exploration/Num Paths                         1
exploration/Average Returns                4928.3
evaluation_0/num steps total                  6.35706e+06
evaluation_0/num paths total              14512
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63263
evaluation_0/Rewards Std                      1.24642
evaluation_0/Rewards Max                      9.57941
evaluation_0/Rewards Min                     -0.550564
evaluation_0/Returns Mean                  4632.63
evaluation_0/Returns Std                     75.1744
evaluation_0/Returns Max                   4802.32
evaluation_0/Returns Min                   4547.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4632.63
time/epoch (s)                                0
time/total (s)                            15483.2
Epoch                                       805
---------------------------------------  ----------------
2022-11-16 15:04:06.020127 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 806 finished
---------------------------------------  ----------------
epoch                                       806
total_step                               811000
replay_pool/size                         811000
trainer/alpha                                 0.0604504
trainer/alpha_loss                           -0.0187211
trainer/entropy                              -5.99333
trainer/qf_loss                               8.98395
trainer/state_noise                           0.005
trainer/policy_loss                        -230.775
trainer/policy_loss_without_entropy         232.92
trainer/entropy_penalty                      -0.362299
trainer/entropy_percentage                   -0.00155546
trainer/Q1Pred Mean                         231.904
trainer/Q1Pred Std                           74.3066
trainer/Q1Pred Max                          319.035
trainer/Q1Pred Min                           11.6656
trainer/Q2Pred Mean                         231.765
trainer/Q2Pred Std                           74.3549
trainer/Q2Pred Max                          317.999
trainer/Q2Pred Min                           12.7615
trainer/QTargetWithReg Mean                 231.293
trainer/QTargetWithReg Std                   74.6588
trainer/QTargetWithReg Max                  318.346
trainer/QTargetWithReg Min                   12.2425
trainer/PolicyLossWithoutReg Mean           232.92
trainer/PolicyLossWithoutReg Std             72.8342
trainer/PolicyLossWithoutReg Max            317.485
trainer/PolicyLossWithoutReg Min             11.9542
trainer/gradient_norm                       356.577
trainer/gradient_penalty                     -1.78288
trainer/gradient_percentage                  -0.00765449
exploration/num steps total              811000
exploration/num paths total                1971
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.73216
exploration/Rewards Std                       1.23451
exploration/Rewards Max                       9.50194
exploration/Rewards Min                      -0.576641
exploration/Returns Mean                   4732.16
exploration/Returns Std                       0
exploration/Returns Max                    4732.16
exploration/Returns Min                    4732.16
exploration/Num Paths                         1
exploration/Average Returns                4732.16
evaluation_0/num steps total                  6.36506e+06
evaluation_0/num paths total              14520
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.8688
evaluation_0/Rewards Std                      1.21396
evaluation_0/Rewards Max                      9.53602
evaluation_0/Rewards Min                     -0.523857
evaluation_0/Returns Mean                  4868.8
evaluation_0/Returns Std                     18.0445
evaluation_0/Returns Max                   4895.32
evaluation_0/Returns Min                   4838.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4868.8
time/epoch (s)                                0
time/total (s)                            15499.7
Epoch                                       806
---------------------------------------  ----------------
2022-11-16 15:04:21.853539 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 807 finished
---------------------------------------  ----------------
epoch                                       807
total_step                               812000
replay_pool/size                         812000
trainer/alpha                                 0.0591931
trainer/alpha_loss                           -0.491313
trainer/entropy                              -5.82621
trainer/qf_loss                               6.8827
trainer/state_noise                           0.005
trainer/policy_loss                        -235.906
trainer/policy_loss_without_entropy         238.013
trainer/entropy_penalty                      -0.344871
trainer/entropy_percentage                   -0.00144896
trainer/Q1Pred Mean                         237.627
trainer/Q1Pred Std                           72.7791
trainer/Q1Pred Max                          317.409
trainer/Q1Pred Min                            8.69944
trainer/Q2Pred Mean                         238.03
trainer/Q2Pred Std                           72.6676
trainer/Q2Pred Max                          316.924
trainer/Q2Pred Min                            9.81025
trainer/QTargetWithReg Mean                 237.09
trainer/QTargetWithReg Std                   72.818
trainer/QTargetWithReg Max                  317.441
trainer/QTargetWithReg Min                    7.44636
trainer/PolicyLossWithoutReg Mean           238.013
trainer/PolicyLossWithoutReg Std             71.9093
trainer/PolicyLossWithoutReg Max            317.674
trainer/PolicyLossWithoutReg Min              6.33827
trainer/gradient_norm                       352.459
trainer/gradient_penalty                     -1.7623
trainer/gradient_percentage                  -0.00740421
exploration/num steps total              812000
exploration/num paths total                1972
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93712
exploration/Rewards Std                       1.24962
exploration/Rewards Max                       9.91819
exploration/Rewards Min                      -0.522879
exploration/Returns Mean                   4937.12
exploration/Returns Std                       0
exploration/Returns Max                    4937.12
exploration/Returns Min                    4937.12
exploration/Num Paths                         1
exploration/Average Returns                4937.12
evaluation_0/num steps total                  6.37306e+06
evaluation_0/num paths total              14528
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.78165
evaluation_0/Rewards Std                      1.20874
evaluation_0/Rewards Max                      9.42765
evaluation_0/Rewards Min                     -0.48133
evaluation_0/Returns Mean                  4781.65
evaluation_0/Returns Std                     14.9216
evaluation_0/Returns Max                   4796.61
evaluation_0/Returns Min                   4756.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4781.65
time/epoch (s)                                0
time/total (s)                            15515.6
Epoch                                       807
---------------------------------------  ----------------
2022-11-16 15:04:38.202978 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 808 finished
---------------------------------------  ----------------
epoch                                       808
total_step                               813000
replay_pool/size                         813000
trainer/alpha                                 0.0609918
trainer/alpha_loss                            0.598958
trainer/entropy                              -6.21413
trainer/qf_loss                               5.75159
trainer/state_noise                           0.005
trainer/policy_loss                        -232.225
trainer/policy_loss_without_entropy         234.414
trainer/entropy_penalty                      -0.379011
trainer/entropy_percentage                   -0.00161685
trainer/Q1Pred Mean                         233.517
trainer/Q1Pred Std                           70.8507
trainer/Q1Pred Max                          315.059
trainer/Q1Pred Min                          -29.6322
trainer/Q2Pred Mean                         233.723
trainer/Q2Pred Std                           70.9513
trainer/Q2Pred Max                          318.146
trainer/Q2Pred Min                          -27.7229
trainer/QTargetWithReg Mean                 234.026
trainer/QTargetWithReg Std                   70.6016
trainer/QTargetWithReg Max                  316.048
trainer/QTargetWithReg Min                  -19.2902
trainer/PolicyLossWithoutReg Mean           234.414
trainer/PolicyLossWithoutReg Std             70.2146
trainer/PolicyLossWithoutReg Max            315.895
trainer/PolicyLossWithoutReg Min            -24.814
trainer/gradient_norm                       362.025
trainer/gradient_penalty                     -1.81012
trainer/gradient_percentage                  -0.00772191
exploration/num steps total              813000
exploration/num paths total                1973
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83244
exploration/Rewards Std                       1.22196
exploration/Rewards Max                       9.63176
exploration/Rewards Min                      -0.453287
exploration/Returns Mean                   4832.44
exploration/Returns Std                       0
exploration/Returns Max                    4832.44
exploration/Returns Min                    4832.44
exploration/Num Paths                         1
exploration/Average Returns                4832.44
evaluation_0/num steps total                  6.38106e+06
evaluation_0/num paths total              14536
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.69234
evaluation_0/Rewards Std                      1.20436
evaluation_0/Rewards Max                      9.43928
evaluation_0/Rewards Min                     -0.497335
evaluation_0/Returns Mean                  4692.34
evaluation_0/Returns Std                     16.407
evaluation_0/Returns Max                   4716.84
evaluation_0/Returns Min                   4665.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4692.34
time/epoch (s)                                0
time/total (s)                            15531.9
Epoch                                       808
---------------------------------------  ----------------
2022-11-16 15:04:54.018963 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 809 finished
---------------------------------------  ----------------
epoch                                       809
total_step                               814000
replay_pool/size                         814000
trainer/alpha                                 0.0599504
trainer/alpha_loss                            0.526129
trainer/entropy                              -6.18695
trainer/qf_loss                              11.4113
trainer/state_noise                           0.005
trainer/policy_loss                        -231.134
trainer/policy_loss_without_entropy         233.343
trainer/entropy_penalty                      -0.37091
trainer/entropy_percentage                   -0.00158955
trainer/Q1Pred Mean                         232.406
trainer/Q1Pred Std                           75.8029
trainer/Q1Pred Max                          317.123
trainer/Q1Pred Min                           -1.08029
trainer/Q2Pred Mean                         231.888
trainer/Q2Pred Std                           75.3182
trainer/Q2Pred Max                          315.454
trainer/Q2Pred Min                            0.745105
trainer/QTargetWithReg Mean                 233.042
trainer/QTargetWithReg Std                   75.4571
trainer/QTargetWithReg Max                  316.884
trainer/QTargetWithReg Min                    3.87055
trainer/PolicyLossWithoutReg Mean           233.343
trainer/PolicyLossWithoutReg Std             74.8231
trainer/PolicyLossWithoutReg Max            315.913
trainer/PolicyLossWithoutReg Min              2.62584
trainer/gradient_norm                       367.494
trainer/gradient_penalty                     -1.83747
trainer/gradient_percentage                  -0.00787455
exploration/num steps total              814000
exploration/num paths total                1974
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7142
exploration/Rewards Std                       1.20685
exploration/Rewards Max                       9.40565
exploration/Rewards Min                      -0.544418
exploration/Returns Mean                   4714.2
exploration/Returns Std                       0
exploration/Returns Max                    4714.2
exploration/Returns Min                    4714.2
exploration/Num Paths                         1
exploration/Average Returns                4714.2
evaluation_0/num steps total                  6.38906e+06
evaluation_0/num paths total              14544
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.74103
evaluation_0/Rewards Std                      1.24256
evaluation_0/Rewards Max                      9.52593
evaluation_0/Rewards Min                     -0.453641
evaluation_0/Returns Mean                  4741.03
evaluation_0/Returns Std                      6.78069
evaluation_0/Returns Max                   4753.67
evaluation_0/Returns Min                   4732.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4741.03
time/epoch (s)                                0
time/total (s)                            15547.7
Epoch                                       809
---------------------------------------  ----------------
2022-11-16 15:05:09.751270 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 810 finished
---------------------------------------  ----------------
epoch                                       810
total_step                               815000
replay_pool/size                         815000
trainer/alpha                                 0.0609069
trainer/alpha_loss                           -0.274685
trainer/entropy                              -5.90184
trainer/qf_loss                               6.59365
trainer/state_noise                           0.005
trainer/policy_loss                        -227.797
trainer/policy_loss_without_entropy         229.935
trainer/entropy_penalty                      -0.359463
trainer/entropy_percentage                   -0.00156332
trainer/Q1Pred Mean                         229.827
trainer/Q1Pred Std                           73.6556
trainer/Q1Pred Max                          314.305
trainer/Q1Pred Min                           18.9114
trainer/Q2Pred Mean                         229.606
trainer/Q2Pred Std                           73.662
trainer/Q2Pred Max                          313.663
trainer/Q2Pred Min                           19.3216
trainer/QTargetWithReg Mean                 229.42
trainer/QTargetWithReg Std                   74.1757
trainer/QTargetWithReg Max                  313.442
trainer/QTargetWithReg Min                   22.167
trainer/PolicyLossWithoutReg Mean           229.935
trainer/PolicyLossWithoutReg Std             72.9909
trainer/PolicyLossWithoutReg Max            313.14
trainer/PolicyLossWithoutReg Min             22.6777
trainer/gradient_norm                       355.872
trainer/gradient_penalty                     -1.77936
trainer/gradient_percentage                  -0.00773852
exploration/num steps total              815000
exploration/num paths total                1975
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.74848
exploration/Rewards Std                       1.24546
exploration/Rewards Max                       9.50208
exploration/Rewards Min                      -0.539492
exploration/Returns Mean                   4748.48
exploration/Returns Std                       0
exploration/Returns Max                    4748.48
exploration/Returns Min                    4748.48
exploration/Num Paths                         1
exploration/Average Returns                4748.48
evaluation_0/num steps total                  6.39706e+06
evaluation_0/num paths total              14552
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.95752
evaluation_0/Rewards Std                      1.19809
evaluation_0/Rewards Max                      9.98347
evaluation_0/Rewards Min                     -0.537349
evaluation_0/Returns Mean                  4957.52
evaluation_0/Returns Std                      6.83538
evaluation_0/Returns Max                   4965.08
evaluation_0/Returns Min                   4942.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4957.52
time/epoch (s)                                0
time/total (s)                            15563.5
Epoch                                       810
---------------------------------------  ----------------
2022-11-16 15:05:26.351514 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 811 finished
---------------------------------------  ----------------
epoch                                       811
total_step                               816000
replay_pool/size                         816000
trainer/alpha                                 0.0599794
trainer/alpha_loss                           -0.427797
trainer/entropy                              -5.84797
trainer/qf_loss                               9.64881
trainer/state_noise                           0.005
trainer/policy_loss                        -228.742
trainer/policy_loss_without_entropy         230.86
trainer/entropy_penalty                      -0.350757
trainer/entropy_percentage                   -0.00151935
trainer/Q1Pred Mean                         231.129
trainer/Q1Pred Std                           76.2691
trainer/Q1Pred Max                          321.84
trainer/Q1Pred Min                           -0.0752922
trainer/Q2Pred Mean                         231.058
trainer/Q2Pred Std                           76.4646
trainer/Q2Pred Max                          322.672
trainer/Q2Pred Min                           -0.0523758
trainer/QTargetWithReg Mean                 230.082
trainer/QTargetWithReg Std                   76.4739
trainer/QTargetWithReg Max                  318.411
trainer/QTargetWithReg Min                   -2.47745
trainer/PolicyLossWithoutReg Mean           230.86
trainer/PolicyLossWithoutReg Std             75.6947
trainer/PolicyLossWithoutReg Max            320.275
trainer/PolicyLossWithoutReg Min              2.00613
trainer/gradient_norm                       353.511
trainer/gradient_penalty                     -1.76756
trainer/gradient_percentage                  -0.00765638
exploration/num steps total              816000
exploration/num paths total                1976
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83129
exploration/Rewards Std                       1.21452
exploration/Rewards Max                       9.40985
exploration/Rewards Min                      -0.448225
exploration/Returns Mean                   4831.29
exploration/Returns Std                       0
exploration/Returns Max                    4831.29
exploration/Returns Min                    4831.29
exploration/Num Paths                         1
exploration/Average Returns                4831.29
evaluation_0/num steps total                  6.40506e+06
evaluation_0/num paths total              14560
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.90192
evaluation_0/Rewards Std                      1.2224
evaluation_0/Rewards Max                      9.65118
evaluation_0/Rewards Min                     -0.436009
evaluation_0/Returns Mean                  4901.92
evaluation_0/Returns Std                      8.72869
evaluation_0/Returns Max                   4910.29
evaluation_0/Returns Min                   4887.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4901.92
time/epoch (s)                                0
time/total (s)                            15580.1
Epoch                                       811
---------------------------------------  ----------------
2022-11-16 15:05:42.151427 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 812 finished
---------------------------------------  ----------------
epoch                                       812
total_step                               817000
replay_pool/size                         817000
trainer/alpha                                 0.060551
trainer/alpha_loss                            0.870568
trainer/entropy                              -6.31043
trainer/qf_loss                               6.06596
trainer/state_noise                           0.005
trainer/policy_loss                        -226.919
trainer/policy_loss_without_entropy         229.063
trainer/entropy_penalty                      -0.382103
trainer/entropy_percentage                   -0.00166811
trainer/Q1Pred Mean                         228.117
trainer/Q1Pred Std                           76.5314
trainer/Q1Pred Max                          320.719
trainer/Q1Pred Min                            9.21845
trainer/Q2Pred Mean                         228.325
trainer/Q2Pred Std                           76.5565
trainer/Q2Pred Max                          320.286
trainer/Q2Pred Min                           15.5973
trainer/QTargetWithReg Mean                 228.35
trainer/QTargetWithReg Std                   76.5863
trainer/QTargetWithReg Max                  320.958
trainer/QTargetWithReg Min                   11.1036
trainer/PolicyLossWithoutReg Mean           229.063
trainer/PolicyLossWithoutReg Std             75.3432
trainer/PolicyLossWithoutReg Max            320.928
trainer/PolicyLossWithoutReg Min              9.12472
trainer/gradient_norm                       352.226
trainer/gradient_penalty                     -1.76113
trainer/gradient_percentage                  -0.00768842
exploration/num steps total              817000
exploration/num paths total                1977
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.7367
exploration/Rewards Std                       1.232
exploration/Rewards Max                       9.6757
exploration/Rewards Min                      -0.42222
exploration/Returns Mean                   4736.7
exploration/Returns Std                       0
exploration/Returns Max                    4736.7
exploration/Returns Min                    4736.7
exploration/Num Paths                         1
exploration/Average Returns                4736.7
evaluation_0/num steps total                  6.41306e+06
evaluation_0/num paths total              14568
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.64613
evaluation_0/Rewards Std                      1.22789
evaluation_0/Rewards Max                      9.52145
evaluation_0/Rewards Min                     -0.550227
evaluation_0/Returns Mean                  4646.13
evaluation_0/Returns Std                     48.7282
evaluation_0/Returns Max                   4722.9
evaluation_0/Returns Min                   4566.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4646.13
time/epoch (s)                                0
time/total (s)                            15595.9
Epoch                                       812
---------------------------------------  ----------------
2022-11-16 15:05:58.646058 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 813 finished
---------------------------------------  ----------------
epoch                                       813
total_step                               818000
replay_pool/size                         818000
trainer/alpha                                 0.0616027
trainer/alpha_loss                            0.415358
trainer/entropy                              -6.14902
trainer/qf_loss                              10.8836
trainer/state_noise                           0.005
trainer/policy_loss                        -228.681
trainer/policy_loss_without_entropy         230.847
trainer/entropy_penalty                      -0.378797
trainer/entropy_percentage                   -0.0016409
trainer/Q1Pred Mean                         230.254
trainer/Q1Pred Std                           77.7549
trainer/Q1Pred Max                          312.996
trainer/Q1Pred Min                          -25.2609
trainer/Q2Pred Mean                         229.963
trainer/Q2Pred Std                           77.5233
trainer/Q2Pred Max                          310.09
trainer/Q2Pred Min                          -19.8266
trainer/QTargetWithReg Mean                 230.748
trainer/QTargetWithReg Std                   77.7864
trainer/QTargetWithReg Max                  309.896
trainer/QTargetWithReg Min                  -13.6224
trainer/PolicyLossWithoutReg Mean           230.847
trainer/PolicyLossWithoutReg Std             76.0078
trainer/PolicyLossWithoutReg Max            310.226
trainer/PolicyLossWithoutReg Min            -16.7253
trainer/gradient_norm                       357.417
trainer/gradient_penalty                     -1.78709
trainer/gradient_percentage                  -0.00774144
exploration/num steps total              818000
exploration/num paths total                1978
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.79403
exploration/Rewards Std                       1.20717
exploration/Rewards Max                       9.51684
exploration/Rewards Min                      -0.566584
exploration/Returns Mean                   4794.03
exploration/Returns Std                       0
exploration/Returns Max                    4794.03
exploration/Returns Min                    4794.03
exploration/Num Paths                         1
exploration/Average Returns                4794.03
evaluation_0/num steps total                  6.42106e+06
evaluation_0/num paths total              14576
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.84166
evaluation_0/Rewards Std                      1.2135
evaluation_0/Rewards Max                      9.51488
evaluation_0/Rewards Min                     -0.483162
evaluation_0/Returns Mean                  4841.66
evaluation_0/Returns Std                     13.1797
evaluation_0/Returns Max                   4859.31
evaluation_0/Returns Min                   4817.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4841.66
time/epoch (s)                                0
time/total (s)                            15612.3
Epoch                                       813
---------------------------------------  ----------------
2022-11-16 15:06:14.426357 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 814 finished
---------------------------------------  ----------------
epoch                                       814
total_step                               819000
replay_pool/size                         819000
trainer/alpha                                 0.0618658
trainer/alpha_loss                            0.741868
trainer/entropy                              -6.2666
trainer/qf_loss                              13.8105
trainer/state_noise                           0.005
trainer/policy_loss                        -226.534
trainer/policy_loss_without_entropy         228.749
trainer/entropy_penalty                      -0.387688
trainer/entropy_percentage                   -0.00169482
trainer/Q1Pred Mean                         227.434
trainer/Q1Pred Std                           76.2055
trainer/Q1Pred Max                          317.657
trainer/Q1Pred Min                           -6.45314
trainer/Q2Pred Mean                         227.859
trainer/Q2Pred Std                           76.0451
trainer/Q2Pred Max                          319.677
trainer/Q2Pred Min                           -2.7564
trainer/QTargetWithReg Mean                 227.983
trainer/QTargetWithReg Std                   76.1202
trainer/QTargetWithReg Max                  319.837
trainer/QTargetWithReg Min                   -5.31602
trainer/PolicyLossWithoutReg Mean           228.749
trainer/PolicyLossWithoutReg Std             75.3139
trainer/PolicyLossWithoutReg Max            319.776
trainer/PolicyLossWithoutReg Min              1.80488
trainer/gradient_norm                       365.413
trainer/gradient_penalty                     -1.82706
trainer/gradient_percentage                  -0.0079872
exploration/num steps total              819000
exploration/num paths total                1979
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87551
exploration/Rewards Std                       1.2368
exploration/Rewards Max                       9.81719
exploration/Rewards Min                      -0.636953
exploration/Returns Mean                   4875.51
exploration/Returns Std                       0
exploration/Returns Max                    4875.51
exploration/Returns Min                    4875.51
exploration/Num Paths                         1
exploration/Average Returns                4875.51
evaluation_0/num steps total                  6.42906e+06
evaluation_0/num paths total              14584
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83802
evaluation_0/Rewards Std                      1.1953
evaluation_0/Rewards Max                      9.42016
evaluation_0/Rewards Min                     -0.550586
evaluation_0/Returns Mean                  4838.02
evaluation_0/Returns Std                      8.21913
evaluation_0/Returns Max                   4850.53
evaluation_0/Returns Min                   4824.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4838.02
time/epoch (s)                                0
time/total (s)                            15628.1
Epoch                                       814
---------------------------------------  ----------------
2022-11-16 15:06:30.677546 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 815 finished
---------------------------------------  ----------------
epoch                                       815
total_step                               820000
replay_pool/size                         820000
trainer/alpha                                 0.0603714
trainer/alpha_loss                            0.352043
trainer/entropy                              -6.1254
trainer/qf_loss                               7.68366
trainer/state_noise                           0.005
trainer/policy_loss                        -231.218
trainer/policy_loss_without_entropy         233.329
trainer/entropy_penalty                      -0.369799
trainer/entropy_percentage                   -0.00158488
trainer/Q1Pred Mean                         232.766
trainer/Q1Pred Std                           76.8308
trainer/Q1Pred Max                          315.485
trainer/Q1Pred Min                            8.31202
trainer/Q2Pred Mean                         232.696
trainer/Q2Pred Std                           76.8546
trainer/Q2Pred Max                          318.031
trainer/Q2Pred Min                            8.01056
trainer/QTargetWithReg Mean                 232.872
trainer/QTargetWithReg Std                   76.8054
trainer/QTargetWithReg Max                  315.693
trainer/QTargetWithReg Min                    6.1479
trainer/PolicyLossWithoutReg Mean           233.329
trainer/PolicyLossWithoutReg Std             76.1067
trainer/PolicyLossWithoutReg Max            314.97
trainer/PolicyLossWithoutReg Min              8.33194
trainer/gradient_norm                       348.322
trainer/gradient_penalty                     -1.74161
trainer/gradient_percentage                  -0.00746417
exploration/num steps total              820000
exploration/num paths total                1980
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83266
exploration/Rewards Std                       1.22252
exploration/Rewards Max                       9.48504
exploration/Rewards Min                      -0.567732
exploration/Returns Mean                   4832.66
exploration/Returns Std                       0
exploration/Returns Max                    4832.66
exploration/Returns Min                    4832.66
exploration/Num Paths                         1
exploration/Average Returns                4832.66
evaluation_0/num steps total                  6.43706e+06
evaluation_0/num paths total              14592
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89345
evaluation_0/Rewards Std                      1.20206
evaluation_0/Rewards Max                      9.66332
evaluation_0/Rewards Min                     -0.514802
evaluation_0/Returns Mean                  4893.45
evaluation_0/Returns Std                     22.5937
evaluation_0/Returns Max                   4916.19
evaluation_0/Returns Min                   4849.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4893.45
time/epoch (s)                                0
time/total (s)                            15644.4
Epoch                                       815
---------------------------------------  ----------------
2022-11-16 15:06:46.732280 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 816 finished
---------------------------------------  ----------------
epoch                                       816
total_step                               821000
replay_pool/size                         821000
trainer/alpha                                 0.060424
trainer/alpha_loss                           -1.86382
trainer/entropy                              -5.33581
trainer/qf_loss                              13.3223
trainer/state_noise                           0.005
trainer/policy_loss                        -225.991
trainer/policy_loss_without_entropy         228.015
trainer/entropy_penalty                      -0.322411
trainer/entropy_percentage                   -0.00141399
trainer/Q1Pred Mean                         227.007
trainer/Q1Pred Std                           77.6064
trainer/Q1Pred Max                          318.86
trainer/Q1Pred Min                            5.46846
trainer/Q2Pred Mean                         227.006
trainer/Q2Pred Std                           77.5522
trainer/Q2Pred Max                          319.164
trainer/Q2Pred Min                            4.91699
trainer/QTargetWithReg Mean                 227.34
trainer/QTargetWithReg Std                   78.1211
trainer/QTargetWithReg Max                  320.522
trainer/QTargetWithReg Min                    0.896185
trainer/PolicyLossWithoutReg Mean           228.015
trainer/PolicyLossWithoutReg Std             76.3208
trainer/PolicyLossWithoutReg Max            319.297
trainer/PolicyLossWithoutReg Min              6.43746
trainer/gradient_norm                       340.265
trainer/gradient_penalty                     -1.70133
trainer/gradient_percentage                  -0.00746147
exploration/num steps total              821000
exploration/num paths total                1981
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.92085
exploration/Rewards Std                       1.23367
exploration/Rewards Max                       9.90511
exploration/Rewards Min                      -0.518195
exploration/Returns Mean                   4920.85
exploration/Returns Std                       0
exploration/Returns Max                    4920.85
exploration/Returns Min                    4920.85
exploration/Num Paths                         1
exploration/Average Returns                4920.85
evaluation_0/num steps total                  6.44506e+06
evaluation_0/num paths total              14600
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.97039
evaluation_0/Rewards Std                      1.21904
evaluation_0/Rewards Max                      9.84755
evaluation_0/Rewards Min                     -0.494837
evaluation_0/Returns Mean                  4970.39
evaluation_0/Returns Std                     25.3041
evaluation_0/Returns Max                   4998.7
evaluation_0/Returns Min                   4917.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4970.39
time/epoch (s)                                0
time/total (s)                            15660.4
Epoch                                       816
---------------------------------------  ----------------
2022-11-16 15:07:02.551985 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 817 finished
---------------------------------------  ----------------
epoch                                       817
total_step                               822000
replay_pool/size                         822000
trainer/alpha                                 0.0609075
trainer/alpha_loss                            1.27351
trainer/entropy                              -6.45508
trainer/qf_loss                               8.42596
trainer/state_noise                           0.005
trainer/policy_loss                        -231.756
trainer/policy_loss_without_entropy         233.913
trainer/entropy_penalty                      -0.393162
trainer/entropy_percentage                   -0.00168081
trainer/Q1Pred Mean                         233.089
trainer/Q1Pred Std                           73.7571
trainer/Q1Pred Max                          321.81
trainer/Q1Pred Min                           -1.93199
trainer/Q2Pred Mean                         233.822
trainer/Q2Pred Std                           73.4747
trainer/Q2Pred Max                          320.246
trainer/Q2Pred Min                            3.58228
trainer/QTargetWithReg Mean                 233.911
trainer/QTargetWithReg Std                   73.5672
trainer/QTargetWithReg Max                  318.927
trainer/QTargetWithReg Min                    6.65907
trainer/PolicyLossWithoutReg Mean           233.913
trainer/PolicyLossWithoutReg Std             72.9768
trainer/PolicyLossWithoutReg Max            320.386
trainer/PolicyLossWithoutReg Min             -0.231322
trainer/gradient_norm                       352.708
trainer/gradient_penalty                     -1.76354
trainer/gradient_percentage                  -0.00753931
exploration/num steps total              822000
exploration/num paths total                1982
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.9069
exploration/Rewards Std                       1.22515
exploration/Rewards Max                       9.89753
exploration/Rewards Min                      -0.478186
exploration/Returns Mean                   4906.9
exploration/Returns Std                       0
exploration/Returns Max                    4906.9
exploration/Returns Min                    4906.9
exploration/Num Paths                         1
exploration/Average Returns                4906.9
evaluation_0/num steps total                  6.45306e+06
evaluation_0/num paths total              14608
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.85116
evaluation_0/Rewards Std                      1.2107
evaluation_0/Rewards Max                      9.46433
evaluation_0/Rewards Min                     -0.45676
evaluation_0/Returns Mean                  4851.16
evaluation_0/Returns Std                     11.1883
evaluation_0/Returns Max                   4863.29
evaluation_0/Returns Min                   4830.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4851.16
time/epoch (s)                                0
time/total (s)                            15676.3
Epoch                                       817
---------------------------------------  ----------------
2022-11-16 15:07:19.043858 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 818 finished
---------------------------------------  ----------------
epoch                                       818
total_step                               823000
replay_pool/size                         823000
trainer/alpha                                 0.0598082
trainer/alpha_loss                           -0.889967
trainer/entropy                              -5.684
trainer/qf_loss                               6.28904
trainer/state_noise                           0.005
trainer/policy_loss                        -236.073
trainer/policy_loss_without_entropy         238.273
trainer/entropy_penalty                      -0.33995
trainer/entropy_percentage                   -0.00142672
trainer/Q1Pred Mean                         236.948
trainer/Q1Pred Std                           67.4547
trainer/Q1Pred Max                          316.836
trainer/Q1Pred Min                           14.238
trainer/Q2Pred Mean                         237.028
trainer/Q2Pred Std                           67.1958
trainer/Q2Pred Max                          315.856
trainer/Q2Pred Min                           12.8716
trainer/QTargetWithReg Mean                 236.718
trainer/QTargetWithReg Std                   67.162
trainer/QTargetWithReg Max                  315.997
trainer/QTargetWithReg Min                    9.79384
trainer/PolicyLossWithoutReg Mean           238.273
trainer/PolicyLossWithoutReg Std             66.3226
trainer/PolicyLossWithoutReg Max            316.86
trainer/PolicyLossWithoutReg Min             14.4697
trainer/gradient_norm                       372.094
trainer/gradient_penalty                     -1.86047
trainer/gradient_percentage                  -0.00780815
exploration/num steps total              823000
exploration/num paths total                1983
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84332
exploration/Rewards Std                       1.21768
exploration/Rewards Max                       9.48825
exploration/Rewards Min                      -0.369165
exploration/Returns Mean                   4843.32
exploration/Returns Std                       0
exploration/Returns Max                    4843.32
exploration/Returns Min                    4843.32
exploration/Num Paths                         1
exploration/Average Returns                4843.32
evaluation_0/num steps total                  6.46106e+06
evaluation_0/num paths total              14616
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83565
evaluation_0/Rewards Std                      1.21208
evaluation_0/Rewards Max                      9.67013
evaluation_0/Rewards Min                     -0.538452
evaluation_0/Returns Mean                  4835.65
evaluation_0/Returns Std                     32.4005
evaluation_0/Returns Max                   4895.5
evaluation_0/Returns Min                   4789.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4835.65
time/epoch (s)                                0
time/total (s)                            15692.7
Epoch                                       818
---------------------------------------  ----------------
2022-11-16 15:07:34.907821 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 819 finished
---------------------------------------  ----------------
epoch                                       819
total_step                               824000
replay_pool/size                         824000
trainer/alpha                                 0.0605703
trainer/alpha_loss                           -0.452829
trainer/entropy                              -5.8385
trainer/qf_loss                               6.38567
trainer/state_noise                           0.005
trainer/policy_loss                        -232.355
trainer/policy_loss_without_entropy         234.444
trainer/entropy_penalty                      -0.35364
trainer/entropy_percentage                   -0.00150842
trainer/Q1Pred Mean                         234.175
trainer/Q1Pred Std                           70.7122
trainer/Q1Pred Max                          320.353
trainer/Q1Pred Min                          -17.9531
trainer/Q2Pred Mean                         234.466
trainer/Q2Pred Std                           70.1831
trainer/Q2Pred Max                          318.222
trainer/Q2Pred Min                          -15.8175
trainer/QTargetWithReg Mean                 233.922
trainer/QTargetWithReg Std                   70.4347
trainer/QTargetWithReg Max                  318.455
trainer/QTargetWithReg Min                  -21.3184
trainer/PolicyLossWithoutReg Mean           234.444
trainer/PolicyLossWithoutReg Std             69.4508
trainer/PolicyLossWithoutReg Max            318.138
trainer/PolicyLossWithoutReg Min             -3.77161
trainer/gradient_norm                       347.146
trainer/gradient_penalty                     -1.73573
trainer/gradient_percentage                  -0.00740359
exploration/num steps total              824000
exploration/num paths total                1984
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.75422
exploration/Rewards Std                       1.22632
exploration/Rewards Max                       9.43384
exploration/Rewards Min                      -0.534868
exploration/Returns Mean                   4754.22
exploration/Returns Std                       0
exploration/Returns Max                    4754.22
exploration/Returns Min                    4754.22
exploration/Num Paths                         1
exploration/Average Returns                4754.22
evaluation_0/num steps total                  6.46906e+06
evaluation_0/num paths total              14624
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.89094
evaluation_0/Rewards Std                      1.23936
evaluation_0/Rewards Max                      9.70885
evaluation_0/Rewards Min                     -0.551206
evaluation_0/Returns Mean                  4890.94
evaluation_0/Returns Std                      7.55068
evaluation_0/Returns Max                   4904.46
evaluation_0/Returns Min                   4879.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4890.94
time/epoch (s)                                0
time/total (s)                            15708.6
Epoch                                       819
---------------------------------------  ----------------
2022-11-16 15:07:51.428365 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 820 finished
---------------------------------------  ----------------
epoch                                       820
total_step                               825000
replay_pool/size                         825000
trainer/alpha                                 0.0616917
trainer/alpha_loss                           -1.1157
trainer/entropy                              -5.59946
trainer/qf_loss                               8.61723
trainer/state_noise                           0.005
trainer/policy_loss                        -230.128
trainer/policy_loss_without_entropy         232.321
trainer/entropy_penalty                      -0.34544
trainer/entropy_percentage                   -0.00148691
trainer/Q1Pred Mean                         232.278
trainer/Q1Pred Std                           75.9542
trainer/Q1Pred Max                          317.887
trainer/Q1Pred Min                            5.78892
trainer/Q2Pred Mean                         232.359
trainer/Q2Pred Std                           75.8786
trainer/Q2Pred Max                          316.964
trainer/Q2Pred Min                           -8.8697
trainer/QTargetWithReg Mean                 231.946
trainer/QTargetWithReg Std                   76.3044
trainer/QTargetWithReg Max                  316.928
trainer/QTargetWithReg Min                   -3.09293
trainer/PolicyLossWithoutReg Mean           232.321
trainer/PolicyLossWithoutReg Std             75.07
trainer/PolicyLossWithoutReg Max            315.392
trainer/PolicyLossWithoutReg Min             -0.525324
trainer/gradient_norm                       369.493
trainer/gradient_penalty                     -1.84747
trainer/gradient_percentage                  -0.0079522
exploration/num steps total              825000
exploration/num paths total                1985
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.8845
exploration/Rewards Std                       1.23111
exploration/Rewards Max                       9.70404
exploration/Rewards Min                      -0.509238
exploration/Returns Mean                   4884.5
exploration/Returns Std                       0
exploration/Returns Max                    4884.5
exploration/Returns Min                    4884.5
exploration/Num Paths                         1
exploration/Average Returns                4884.5
evaluation_0/num steps total                  6.47706e+06
evaluation_0/num paths total              14632
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86234
evaluation_0/Rewards Std                      1.19144
evaluation_0/Rewards Max                      9.446
evaluation_0/Rewards Min                     -0.531853
evaluation_0/Returns Mean                  4862.34
evaluation_0/Returns Std                      8.17808
evaluation_0/Returns Max                   4874.11
evaluation_0/Returns Min                   4853.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4862.34
time/epoch (s)                                0
time/total (s)                            15725.1
Epoch                                       820
---------------------------------------  ----------------
2022-11-16 15:08:07.278301 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 821 finished
---------------------------------------  ----------------
epoch                                       821
total_step                               826000
replay_pool/size                         826000
trainer/alpha                                 0.061848
trainer/alpha_loss                           -1.3905
trainer/entropy                              -5.50034
trainer/qf_loss                               9.23458
trainer/state_noise                           0.005
trainer/policy_loss                        -234.661
trainer/policy_loss_without_entropy         236.779
trainer/entropy_penalty                      -0.340185
trainer/entropy_percentage                   -0.00143672
trainer/Q1Pred Mean                         236.266
trainer/Q1Pred Std                           74.0312
trainer/Q1Pred Max                          316.769
trainer/Q1Pred Min                            3.83949
trainer/Q2Pred Mean                         236.228
trainer/Q2Pred Std                           73.9602
trainer/Q2Pred Max                          316.668
trainer/Q2Pred Min                            5.32443
trainer/QTargetWithReg Mean                 236.331
trainer/QTargetWithReg Std                   73.6291
trainer/QTargetWithReg Max                  316.129
trainer/QTargetWithReg Min                    5.42687
trainer/PolicyLossWithoutReg Mean           236.779
trainer/PolicyLossWithoutReg Std             73.2021
trainer/PolicyLossWithoutReg Max            317.374
trainer/PolicyLossWithoutReg Min              7.02195
trainer/gradient_norm                       355.59
trainer/gradient_penalty                     -1.77795
trainer/gradient_percentage                  -0.00750892
exploration/num steps total              826000
exploration/num paths total                1986
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93526
exploration/Rewards Std                       1.24505
exploration/Rewards Max                       9.83541
exploration/Rewards Min                      -0.538998
exploration/Returns Mean                   4935.26
exploration/Returns Std                       0
exploration/Returns Max                    4935.26
exploration/Returns Min                    4935.26
exploration/Num Paths                         1
exploration/Average Returns                4935.26
evaluation_0/num steps total                  6.48506e+06
evaluation_0/num paths total              14640
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.9645
evaluation_0/Rewards Std                      1.24332
evaluation_0/Rewards Max                      9.98785
evaluation_0/Rewards Min                     -0.489364
evaluation_0/Returns Mean                  4964.5
evaluation_0/Returns Std                     18.4697
evaluation_0/Returns Max                   4985.83
evaluation_0/Returns Min                   4935.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4964.5
time/epoch (s)                                0
time/total (s)                            15741
Epoch                                       821
---------------------------------------  ----------------
2022-11-16 15:08:23.638435 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 822 finished
---------------------------------------  ----------------
epoch                                       822
total_step                               827000
replay_pool/size                         827000
trainer/alpha                                 0.0603994
trainer/alpha_loss                           -0.807295
trainer/entropy                              -5.71238
trainer/qf_loss                               5.62849
trainer/state_noise                           0.005
trainer/policy_loss                        -231.65
trainer/policy_loss_without_entropy         233.721
trainer/entropy_penalty                      -0.345024
trainer/entropy_percentage                   -0.00147622
trainer/Q1Pred Mean                         233.188
trainer/Q1Pred Std                           73.6771
trainer/Q1Pred Max                          318.943
trainer/Q1Pred Min                           17.7164
trainer/Q2Pred Mean                         233.034
trainer/Q2Pred Std                           73.9345
trainer/Q2Pred Max                          317.668
trainer/Q2Pred Min                           21.0953
trainer/QTargetWithReg Mean                 233.332
trainer/QTargetWithReg Std                   73.681
trainer/QTargetWithReg Max                  318.196
trainer/QTargetWithReg Min                   20.4516
trainer/PolicyLossWithoutReg Mean           233.721
trainer/PolicyLossWithoutReg Std             73.1173
trainer/PolicyLossWithoutReg Max            318.368
trainer/PolicyLossWithoutReg Min             17.9389
trainer/gradient_norm                       345.053
trainer/gradient_penalty                     -1.72527
trainer/gradient_percentage                  -0.00738175
exploration/num steps total              827000
exploration/num paths total                1987
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91735
exploration/Rewards Std                       1.26285
exploration/Rewards Max                      10.4167
exploration/Rewards Min                      -0.580382
exploration/Returns Mean                   4917.35
exploration/Returns Std                       0
exploration/Returns Max                    4917.35
exploration/Returns Min                    4917.35
exploration/Num Paths                         1
exploration/Average Returns                4917.35
evaluation_0/num steps total                  6.49306e+06
evaluation_0/num paths total              14648
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.83681
evaluation_0/Rewards Std                      1.2155
evaluation_0/Rewards Max                      9.73007
evaluation_0/Rewards Min                     -0.495059
evaluation_0/Returns Mean                  4836.81
evaluation_0/Returns Std                     15.9505
evaluation_0/Returns Max                   4852.75
evaluation_0/Returns Min                   4807.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4836.81
time/epoch (s)                                0
time/total (s)                            15757.3
Epoch                                       822
---------------------------------------  ----------------
2022-11-16 15:08:39.468695 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 823 finished
---------------------------------------  ----------------
epoch                                       823
total_step                               828000
replay_pool/size                         828000
trainer/alpha                                 0.0604377
trainer/alpha_loss                            0.626016
trainer/entropy                              -6.22309
trainer/qf_loss                               7.01398
trainer/state_noise                           0.005
trainer/policy_loss                        -227.854
trainer/policy_loss_without_entropy         230.003
trainer/entropy_penalty                      -0.376109
trainer/entropy_percentage                   -0.00163524
trainer/Q1Pred Mean                         230.038
trainer/Q1Pred Std                           75.7004
trainer/Q1Pred Max                          315.784
trainer/Q1Pred Min                           10.2457
trainer/Q2Pred Mean                         229.714
trainer/Q2Pred Std                           75.4831
trainer/Q2Pred Max                          316.236
trainer/Q2Pred Min                            5.48777
trainer/QTargetWithReg Mean                 230.08
trainer/QTargetWithReg Std                   76.0872
trainer/QTargetWithReg Max                  316.662
trainer/QTargetWithReg Min                    2.08984
trainer/PolicyLossWithoutReg Mean           230.003
trainer/PolicyLossWithoutReg Std             75.0014
trainer/PolicyLossWithoutReg Max            316.58
trainer/PolicyLossWithoutReg Min              5.59146
trainer/gradient_norm                       354.577
trainer/gradient_penalty                     -1.77289
trainer/gradient_percentage                  -0.00770811
exploration/num steps total              828000
exploration/num paths total                1988
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.87801
exploration/Rewards Std                       1.24554
exploration/Rewards Max                       9.62438
exploration/Rewards Min                      -0.423779
exploration/Returns Mean                   4878.01
exploration/Returns Std                       0
exploration/Returns Max                    4878.01
exploration/Returns Min                    4878.01
exploration/Num Paths                         1
exploration/Average Returns                4878.01
evaluation_0/num steps total                  6.50106e+06
evaluation_0/num paths total              14656
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02904
evaluation_0/Rewards Std                      1.26953
evaluation_0/Rewards Max                     10.3072
evaluation_0/Rewards Min                     -0.524536
evaluation_0/Returns Mean                  5029.04
evaluation_0/Returns Std                     13.3332
evaluation_0/Returns Max                   5050.55
evaluation_0/Returns Min                   5009.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5029.04
time/epoch (s)                                0
time/total (s)                            15773.2
Epoch                                       823
---------------------------------------  ----------------
2022-11-16 15:08:55.230740 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 824 finished
---------------------------------------  ----------------
epoch                                       824
total_step                               829000
replay_pool/size                         829000
trainer/alpha                                 0.0610409
trainer/alpha_loss                           -0.832826
trainer/entropy                              -5.70214
trainer/qf_loss                               7.68916
trainer/state_noise                           0.005
trainer/policy_loss                        -229.424
trainer/policy_loss_without_entropy         231.526
trainer/entropy_penalty                      -0.348063
trainer/entropy_percentage                   -0.00150334
trainer/Q1Pred Mean                         231.046
trainer/Q1Pred Std                           71.5067
trainer/Q1Pred Max                          317.764
trainer/Q1Pred Min                           17.2521
trainer/Q2Pred Mean                         230.842
trainer/Q2Pred Std                           71.4466
trainer/Q2Pred Max                          316.813
trainer/Q2Pred Min                           19.9279
trainer/QTargetWithReg Mean                 230.648
trainer/QTargetWithReg Std                   71.673
trainer/QTargetWithReg Max                  318.046
trainer/QTargetWithReg Min                   17.0119
trainer/PolicyLossWithoutReg Mean           231.526
trainer/PolicyLossWithoutReg Std             70.8011
trainer/PolicyLossWithoutReg Max            317.393
trainer/PolicyLossWithoutReg Min             16.6471
trainer/gradient_norm                       350.69
trainer/gradient_penalty                     -1.75345
trainer/gradient_percentage                  -0.00757344
exploration/num steps total              829000
exploration/num paths total                1989
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95257
exploration/Rewards Std                       1.29004
exploration/Rewards Max                       9.95149
exploration/Rewards Min                      -0.483596
exploration/Returns Mean                   4952.57
exploration/Returns Std                       0
exploration/Returns Max                    4952.57
exploration/Returns Min                    4952.57
exploration/Num Paths                         1
exploration/Average Returns                4952.57
evaluation_0/num steps total                  6.50906e+06
evaluation_0/num paths total              14664
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08488
evaluation_0/Rewards Std                      1.29812
evaluation_0/Rewards Max                     10.2118
evaluation_0/Rewards Min                     -0.475288
evaluation_0/Returns Mean                  5084.88
evaluation_0/Returns Std                     11.9696
evaluation_0/Returns Max                   5104.14
evaluation_0/Returns Min                   5068.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5084.88
time/epoch (s)                                0
time/total (s)                            15788.9
Epoch                                       824
---------------------------------------  ----------------
2022-11-16 15:09:11.702197 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 825 finished
---------------------------------------  ----------------
epoch                                       825
total_step                               830000
replay_pool/size                         830000
trainer/alpha                                 0.0609449
trainer/alpha_loss                            0.278727
trainer/entropy                              -6.09962
trainer/qf_loss                              10.2015
trainer/state_noise                           0.005
trainer/policy_loss                        -232.486
trainer/policy_loss_without_entropy         234.558
trainer/entropy_penalty                      -0.371741
trainer/entropy_percentage                   -0.00158486
trainer/Q1Pred Mean                         233.802
trainer/Q1Pred Std                           71.5781
trainer/Q1Pred Max                          317.968
trainer/Q1Pred Min                            3.62792
trainer/Q2Pred Mean                         234.032
trainer/Q2Pred Std                           71.9129
trainer/Q2Pred Max                          317.755
trainer/Q2Pred Min                            2.1585
trainer/QTargetWithReg Mean                 233.501
trainer/QTargetWithReg Std                   72.2223
trainer/QTargetWithReg Max                  316.608
trainer/QTargetWithReg Min                   -5.14192
trainer/PolicyLossWithoutReg Mean           234.558
trainer/PolicyLossWithoutReg Std             70.2793
trainer/PolicyLossWithoutReg Max            318.593
trainer/PolicyLossWithoutReg Min              4.23071
trainer/gradient_norm                       340.081
trainer/gradient_penalty                     -1.70041
trainer/gradient_percentage                  -0.0072494
exploration/num steps total              830000
exploration/num paths total                1990
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93694
exploration/Rewards Std                       1.27171
exploration/Rewards Max                      10.4944
exploration/Rewards Min                      -0.525827
exploration/Returns Mean                   4936.94
exploration/Returns Std                       0
exploration/Returns Max                    4936.94
exploration/Returns Min                    4936.94
exploration/Num Paths                         1
exploration/Average Returns                4936.94
evaluation_0/num steps total                  6.51706e+06
evaluation_0/num paths total              14672
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08613
evaluation_0/Rewards Std                      1.30068
evaluation_0/Rewards Max                     10.2961
evaluation_0/Rewards Min                     -0.428286
evaluation_0/Returns Mean                  5086.13
evaluation_0/Returns Std                     16.919
evaluation_0/Returns Max                   5114.26
evaluation_0/Returns Min                   5051.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5086.13
time/epoch (s)                                0
time/total (s)                            15805.4
Epoch                                       825
---------------------------------------  ----------------
2022-11-16 15:09:27.511033 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 826 finished
---------------------------------------  ----------------
epoch                                       826
total_step                               831000
replay_pool/size                         831000
trainer/alpha                                 0.0617395
trainer/alpha_loss                           -0.645697
trainer/entropy                              -5.76812
trainer/qf_loss                               6.16937
trainer/state_noise                           0.005
trainer/policy_loss                        -232.075
trainer/policy_loss_without_entropy         234.1
trainer/entropy_penalty                      -0.356121
trainer/entropy_percentage                   -0.00152123
trainer/Q1Pred Mean                         233.91
trainer/Q1Pred Std                           70.4534
trainer/Q1Pred Max                          319.598
trainer/Q1Pred Min                           12.168
trainer/Q2Pred Mean                         233.481
trainer/Q2Pred Std                           70.2968
trainer/Q2Pred Max                          319.904
trainer/Q2Pred Min                           14.0683
trainer/QTargetWithReg Mean                 233.785
trainer/QTargetWithReg Std                   70.2599
trainer/QTargetWithReg Max                  317.993
trainer/QTargetWithReg Min                   14.3653
trainer/PolicyLossWithoutReg Mean           234.1
trainer/PolicyLossWithoutReg Std             69.5243
trainer/PolicyLossWithoutReg Max            319.22
trainer/PolicyLossWithoutReg Min             12.5993
trainer/gradient_norm                       333.722
trainer/gradient_penalty                     -1.66861
trainer/gradient_percentage                  -0.00712776
exploration/num steps total              831000
exploration/num paths total                1991
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07868
exploration/Rewards Std                       1.30849
exploration/Rewards Max                      10.1647
exploration/Rewards Min                      -0.359308
exploration/Returns Mean                   5078.68
exploration/Returns Std                       0
exploration/Returns Max                    5078.68
exploration/Returns Min                    5078.68
exploration/Num Paths                         1
exploration/Average Returns                5078.68
evaluation_0/num steps total                  6.52506e+06
evaluation_0/num paths total              14680
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1367
evaluation_0/Rewards Std                      1.32763
evaluation_0/Rewards Max                     10.4441
evaluation_0/Rewards Min                     -0.488067
evaluation_0/Returns Mean                  5136.7
evaluation_0/Returns Std                      9.86984
evaluation_0/Returns Max                   5159.28
evaluation_0/Returns Min                   5127
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5136.7
time/epoch (s)                                0
time/total (s)                            15821.2
Epoch                                       826
---------------------------------------  ----------------
2022-11-16 15:09:43.899438 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 827 finished
---------------------------------------  ----------------
epoch                                       827
total_step                               832000
replay_pool/size                         832000
trainer/alpha                                 0.0605409
trainer/alpha_loss                           -0.37107
trainer/entropy                              -5.86768
trainer/qf_loss                               5.93049
trainer/state_noise                           0.005
trainer/policy_loss                        -234.896
trainer/policy_loss_without_entropy         237.009
trainer/entropy_penalty                      -0.355234
trainer/entropy_percentage                   -0.00149882
trainer/Q1Pred Mean                         236.298
trainer/Q1Pred Std                           77.1107
trainer/Q1Pred Max                          317.915
trainer/Q1Pred Min                           14.3548
trainer/Q2Pred Mean                         236.35
trainer/Q2Pred Std                           76.8339
trainer/Q2Pred Max                          318.447
trainer/Q2Pred Min                           18.3138
trainer/QTargetWithReg Mean                 236.278
trainer/QTargetWithReg Std                   77.0937
trainer/QTargetWithReg Max                  317.05
trainer/QTargetWithReg Min                   17.6699
trainer/PolicyLossWithoutReg Mean           237.009
trainer/PolicyLossWithoutReg Std             76.2981
trainer/PolicyLossWithoutReg Max            318.657
trainer/PolicyLossWithoutReg Min             14.6844
trainer/gradient_norm                       351.522
trainer/gradient_penalty                     -1.75761
trainer/gradient_percentage                  -0.00741579
exploration/num steps total              832000
exploration/num paths total                1992
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11844
exploration/Rewards Std                       1.35608
exploration/Rewards Max                      10.506
exploration/Rewards Min                      -0.410927
exploration/Returns Mean                   5118.44
exploration/Returns Std                       0
exploration/Returns Max                    5118.44
exploration/Returns Min                    5118.44
exploration/Num Paths                         1
exploration/Average Returns                5118.44
evaluation_0/num steps total                  6.53306e+06
evaluation_0/num paths total              14688
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00911
evaluation_0/Rewards Std                      1.20943
evaluation_0/Rewards Max                      9.85968
evaluation_0/Rewards Min                     -0.478338
evaluation_0/Returns Mean                  5009.11
evaluation_0/Returns Std                      8.57496
evaluation_0/Returns Max                   5020.49
evaluation_0/Returns Min                   4994.14
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5009.11
time/epoch (s)                                0
time/total (s)                            15837.6
Epoch                                       827
---------------------------------------  ----------------
2022-11-16 15:09:59.044047 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 828 finished
---------------------------------------  ----------------
epoch                                       828
total_step                               833000
replay_pool/size                         833000
trainer/alpha                                 0.0600661
trainer/alpha_loss                            0.871861
trainer/entropy                              -6.30999
trainer/qf_loss                               9.34595
trainer/state_noise                           0.005
trainer/policy_loss                        -236.18
trainer/policy_loss_without_entropy         238.352
trainer/entropy_penalty                      -0.379016
trainer/entropy_percentage                   -0.00159016
trainer/Q1Pred Mean                         237.87
trainer/Q1Pred Std                           74.6485
trainer/Q1Pred Max                          324.261
trainer/Q1Pred Min                           16.4096
trainer/Q2Pred Mean                         237.992
trainer/Q2Pred Std                           74.7824
trainer/Q2Pred Max                          325.291
trainer/Q2Pred Min                           12.9843
trainer/QTargetWithReg Mean                 236.826
trainer/QTargetWithReg Std                   74.2569
trainer/QTargetWithReg Max                  322.127
trainer/QTargetWithReg Min                   14.3171
trainer/PolicyLossWithoutReg Mean           238.352
trainer/PolicyLossWithoutReg Std             74.008
trainer/PolicyLossWithoutReg Max            325.019
trainer/PolicyLossWithoutReg Min             14.9435
trainer/gradient_norm                       358.531
trainer/gradient_penalty                     -1.79266
trainer/gradient_percentage                  -0.00752106
exploration/num steps total              833000
exploration/num paths total                1993
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07524
exploration/Rewards Std                       1.31021
exploration/Rewards Max                      10.4674
exploration/Rewards Min                      -0.41863
exploration/Returns Mean                   5075.24
exploration/Returns Std                       0
exploration/Returns Max                    5075.24
exploration/Returns Min                    5075.24
exploration/Num Paths                         1
exploration/Average Returns                5075.24
evaluation_0/num steps total                  6.54106e+06
evaluation_0/num paths total              14696
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.21636
evaluation_0/Rewards Std                      1.32777
evaluation_0/Rewards Max                     10.4607
evaluation_0/Rewards Min                     -0.442631
evaluation_0/Returns Mean                  5216.36
evaluation_0/Returns Std                     19.7178
evaluation_0/Returns Max                   5247.14
evaluation_0/Returns Min                   5176.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5216.36
time/epoch (s)                                0
time/total (s)                            15852.7
Epoch                                       828
---------------------------------------  ----------------
2022-11-16 15:10:15.391204 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 829 finished
---------------------------------------  ----------------
epoch                                       829
total_step                               834000
replay_pool/size                         834000
trainer/alpha                                 0.058321
trainer/alpha_loss                           -0.415889
trainer/entropy                              -5.85365
trainer/qf_loss                               6.26664
trainer/state_noise                           0.005
trainer/policy_loss                        -235.495
trainer/policy_loss_without_entropy         237.608
trainer/entropy_penalty                      -0.34139
trainer/entropy_percentage                   -0.00143678
trainer/Q1Pred Mean                         237.351
trainer/Q1Pred Std                           72.4981
trainer/Q1Pred Max                          316.447
trainer/Q1Pred Min                           26.4793
trainer/Q2Pred Mean                         236.738
trainer/Q2Pred Std                           72.2717
trainer/Q2Pred Max                          317.481
trainer/Q2Pred Min                           29.0356
trainer/QTargetWithReg Mean                 237.536
trainer/QTargetWithReg Std                   72.2505
trainer/QTargetWithReg Max                  317.418
trainer/QTargetWithReg Min                   28.5288
trainer/PolicyLossWithoutReg Mean           237.608
trainer/PolicyLossWithoutReg Std             71.6332
trainer/PolicyLossWithoutReg Max            316.089
trainer/PolicyLossWithoutReg Min             26.6032
trainer/gradient_norm                       354.145
trainer/gradient_penalty                     -1.77073
trainer/gradient_percentage                  -0.00745232
exploration/num steps total              834000
exploration/num paths total                1994
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06502
exploration/Rewards Std                       1.31613
exploration/Rewards Max                      10.6548
exploration/Rewards Min                      -0.591197
exploration/Returns Mean                   5065.02
exploration/Returns Std                       0
exploration/Returns Max                    5065.02
exploration/Returns Min                    5065.02
exploration/Num Paths                         1
exploration/Average Returns                5065.02
evaluation_0/num steps total                  6.54906e+06
evaluation_0/num paths total              14704
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14059
evaluation_0/Rewards Std                      1.32394
evaluation_0/Rewards Max                     10.3705
evaluation_0/Rewards Min                     -0.519104
evaluation_0/Returns Mean                  5140.59
evaluation_0/Returns Std                      8.01131
evaluation_0/Returns Max                   5155.56
evaluation_0/Returns Min                   5130.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5140.59
time/epoch (s)                                0
time/total (s)                            15869.1
Epoch                                       829
---------------------------------------  ----------------
2022-11-16 15:10:31.399596 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 830 finished
---------------------------------------  ----------------
epoch                                       830
total_step                               835000
replay_pool/size                         835000
trainer/alpha                                 0.0601736
trainer/alpha_loss                            0.359045
trainer/entropy                              -6.12775
trainer/qf_loss                               5.16329
trainer/state_noise                           0.005
trainer/policy_loss                        -233.443
trainer/policy_loss_without_entropy         235.557
trainer/entropy_penalty                      -0.368729
trainer/entropy_percentage                   -0.00156535
trainer/Q1Pred Mean                         234.545
trainer/Q1Pred Std                           72.9043
trainer/Q1Pred Max                          321.94
trainer/Q1Pred Min                          -13.1058
trainer/Q2Pred Mean                         234.661
trainer/Q2Pred Std                           72.9239
trainer/Q2Pred Max                          319.032
trainer/Q2Pred Min                          -11.4401
trainer/QTargetWithReg Mean                 234.882
trainer/QTargetWithReg Std                   72.5736
trainer/QTargetWithReg Max                  319.577
trainer/QTargetWithReg Min                  -12.094
trainer/PolicyLossWithoutReg Mean           235.557
trainer/PolicyLossWithoutReg Std             72.3007
trainer/PolicyLossWithoutReg Max            319.221
trainer/PolicyLossWithoutReg Min             -8.5968
trainer/gradient_norm                       348.916
trainer/gradient_penalty                     -1.74458
trainer/gradient_percentage                  -0.00740619
exploration/num steps total              835000
exploration/num paths total                1995
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08946
exploration/Rewards Std                       1.3482
exploration/Rewards Max                      10.6121
exploration/Rewards Min                      -0.461134
exploration/Returns Mean                   5089.46
exploration/Returns Std                       0
exploration/Returns Max                    5089.46
exploration/Returns Min                    5089.46
exploration/Num Paths                         1
exploration/Average Returns                5089.46
evaluation_0/num steps total                  6.55706e+06
evaluation_0/num paths total              14712
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19514
evaluation_0/Rewards Std                      1.34339
evaluation_0/Rewards Max                     10.484
evaluation_0/Rewards Min                     -0.472695
evaluation_0/Returns Mean                  5195.14
evaluation_0/Returns Std                     47.695
evaluation_0/Returns Max                   5261.53
evaluation_0/Returns Min                   5132.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5195.14
time/epoch (s)                                0
time/total (s)                            15885.1
Epoch                                       830
---------------------------------------  ----------------
2022-11-16 15:10:47.239005 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 831 finished
---------------------------------------  ----------------
epoch                                       831
total_step                               836000
replay_pool/size                         836000
trainer/alpha                                 0.0614511
trainer/alpha_loss                           -0.197018
trainer/entropy                              -5.92937
trainer/qf_loss                               5.80826
trainer/state_noise                           0.005
trainer/policy_loss                        -234.382
trainer/policy_loss_without_entropy         236.543
trainer/entropy_penalty                      -0.364366
trainer/entropy_percentage                   -0.00154038
trainer/Q1Pred Mean                         236.093
trainer/Q1Pred Std                           74.9354
trainer/Q1Pred Max                          320.308
trainer/Q1Pred Min                          -10.4131
trainer/Q2Pred Mean                         236.276
trainer/Q2Pred Std                           74.8838
trainer/Q2Pred Max                          319.409
trainer/Q2Pred Min                           -5.55085
trainer/QTargetWithReg Mean                 235.613
trainer/QTargetWithReg Std                   74.8336
trainer/QTargetWithReg Max                  318.72
trainer/QTargetWithReg Min                   -4.4365
trainer/PolicyLossWithoutReg Mean           236.543
trainer/PolicyLossWithoutReg Std             73.8832
trainer/PolicyLossWithoutReg Max            318.856
trainer/PolicyLossWithoutReg Min             -7.83582
trainer/gradient_norm                       359.405
trainer/gradient_penalty                     -1.79702
trainer/gradient_percentage                  -0.00759703
exploration/num steps total              836000
exploration/num paths total                1996
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04362
exploration/Rewards Std                       1.31079
exploration/Rewards Max                      10.1929
exploration/Rewards Min                      -0.395756
exploration/Returns Mean                   5043.62
exploration/Returns Std                       0
exploration/Returns Max                    5043.62
exploration/Returns Min                    5043.62
exploration/Num Paths                         1
exploration/Average Returns                5043.62
evaluation_0/num steps total                  6.56506e+06
evaluation_0/num paths total              14720
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04565
evaluation_0/Rewards Std                      1.3111
evaluation_0/Rewards Max                     10.3822
evaluation_0/Rewards Min                     -0.474868
evaluation_0/Returns Mean                  5045.65
evaluation_0/Returns Std                     15.9709
evaluation_0/Returns Max                   5081.46
evaluation_0/Returns Min                   5023.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5045.65
time/epoch (s)                                0
time/total (s)                            15900.9
Epoch                                       831
---------------------------------------  ----------------
2022-11-16 15:11:03.755444 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 832 finished
---------------------------------------  ----------------
epoch                                       832
total_step                               837000
replay_pool/size                         837000
trainer/alpha                                 0.0599165
trainer/alpha_loss                            0.304545
trainer/entropy                              -6.1082
trainer/qf_loss                               7.71511
trainer/state_noise                           0.005
trainer/policy_loss                        -226.912
trainer/policy_loss_without_entropy         229.074
trainer/entropy_penalty                      -0.365982
trainer/entropy_percentage                   -0.00159766
trainer/Q1Pred Mean                         228.039
trainer/Q1Pred Std                           77.4488
trainer/Q1Pred Max                          319.146
trainer/Q1Pred Min                            5.56912
trainer/Q2Pred Mean                         228.401
trainer/Q2Pred Std                           76.8473
trainer/Q2Pred Max                          317.658
trainer/Q2Pred Min                            2.27492
trainer/QTargetWithReg Mean                 228.596
trainer/QTargetWithReg Std                   77.1779
trainer/QTargetWithReg Max                  319.644
trainer/QTargetWithReg Min                    8.73092
trainer/PolicyLossWithoutReg Mean           229.074
trainer/PolicyLossWithoutReg Std             76.4323
trainer/PolicyLossWithoutReg Max            318.126
trainer/PolicyLossWithoutReg Min             11.5028
trainer/gradient_norm                       359.323
trainer/gradient_penalty                     -1.79662
trainer/gradient_percentage                  -0.00784295
exploration/num steps total              837000
exploration/num paths total                1997
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.93011
exploration/Rewards Std                       1.32232
exploration/Rewards Max                      10.3438
exploration/Rewards Min                      -0.458442
exploration/Returns Mean                   4930.11
exploration/Returns Std                       0
exploration/Returns Max                    4930.11
exploration/Returns Min                    4930.11
exploration/Num Paths                         1
exploration/Average Returns                4930.11
evaluation_0/num steps total                  6.57306e+06
evaluation_0/num paths total              14728
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.21965
evaluation_0/Rewards Std                      1.33022
evaluation_0/Rewards Max                     10.5756
evaluation_0/Rewards Min                     -0.457512
evaluation_0/Returns Mean                  5219.65
evaluation_0/Returns Std                     93.437
evaluation_0/Returns Max                   5379.57
evaluation_0/Returns Min                   5131.96
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5219.65
time/epoch (s)                                0
time/total (s)                            15917.4
Epoch                                       832
---------------------------------------  ----------------
2022-11-16 15:11:19.642337 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 833 finished
---------------------------------------  ----------------
epoch                                       833
total_step                               838000
replay_pool/size                         838000
trainer/alpha                                 0.0600802
trainer/alpha_loss                            0.275761
trainer/entropy                              -6.09806
trainer/qf_loss                               9.05781
trainer/state_noise                           0.005
trainer/policy_loss                        -229.013
trainer/policy_loss_without_entropy         231.088
trainer/entropy_penalty                      -0.366372
trainer/entropy_percentage                   -0.00158542
trainer/Q1Pred Mean                         231.348
trainer/Q1Pred Std                           74.2374
trainer/Q1Pred Max                          324.767
trainer/Q1Pred Min                            2.83308
trainer/Q2Pred Mean                         231.251
trainer/Q2Pred Std                           74.316
trainer/Q2Pred Max                          322.728
trainer/Q2Pred Min                            8.13131
trainer/QTargetWithReg Mean                 230.617
trainer/QTargetWithReg Std                   74.3268
trainer/QTargetWithReg Max                  323.877
trainer/QTargetWithReg Min                    2.8608
trainer/PolicyLossWithoutReg Mean           231.088
trainer/PolicyLossWithoutReg Std             73.0474
trainer/PolicyLossWithoutReg Max            322.434
trainer/PolicyLossWithoutReg Min              2.66273
trainer/gradient_norm                       341.893
trainer/gradient_penalty                     -1.70946
trainer/gradient_percentage                  -0.00739744
exploration/num steps total              838000
exploration/num paths total                1998
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02409
exploration/Rewards Std                       1.31049
exploration/Rewards Max                       9.97993
exploration/Rewards Min                      -0.510249
exploration/Returns Mean                   5024.09
exploration/Returns Std                       0
exploration/Returns Max                    5024.09
exploration/Returns Min                    5024.09
exploration/Num Paths                         1
exploration/Average Returns                5024.09
evaluation_0/num steps total                  6.58106e+06
evaluation_0/num paths total              14736
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09867
evaluation_0/Rewards Std                      1.25828
evaluation_0/Rewards Max                     10.3057
evaluation_0/Rewards Min                     -0.479365
evaluation_0/Returns Mean                  5098.67
evaluation_0/Returns Std                     16.1276
evaluation_0/Returns Max                   5130.96
evaluation_0/Returns Min                   5077.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5098.67
time/epoch (s)                                0
time/total (s)                            15933.3
Epoch                                       833
---------------------------------------  ----------------
2022-11-16 15:11:36.065191 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 834 finished
---------------------------------------  ----------------
epoch                                       834
total_step                               839000
replay_pool/size                         839000
trainer/alpha                                 0.0602841
trainer/alpha_loss                            0.0236035
trainer/entropy                              -6.0084
trainer/qf_loss                               6.46285
trainer/state_noise                           0.005
trainer/policy_loss                        -237.281
trainer/policy_loss_without_entropy         239.353
trainer/entropy_penalty                      -0.362211
trainer/entropy_percentage                   -0.00151329
trainer/Q1Pred Mean                         238.682
trainer/Q1Pred Std                           74.1386
trainer/Q1Pred Max                          316.317
trainer/Q1Pred Min                           14.8985
trainer/Q2Pred Mean                         239.202
trainer/Q2Pred Std                           74.2216
trainer/Q2Pred Max                          318.117
trainer/Q2Pred Min                           12.0185
trainer/QTargetWithReg Mean                 238.615
trainer/QTargetWithReg Std                   74.8689
trainer/QTargetWithReg Max                  318.705
trainer/QTargetWithReg Min                   12.3161
trainer/PolicyLossWithoutReg Mean           239.353
trainer/PolicyLossWithoutReg Std             73.6155
trainer/PolicyLossWithoutReg Max            317.249
trainer/PolicyLossWithoutReg Min             12.028
trainer/gradient_norm                       341.985
trainer/gradient_penalty                     -1.70992
trainer/gradient_percentage                  -0.00714393
exploration/num steps total              839000
exploration/num paths total                1999
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07206
exploration/Rewards Std                       1.28715
exploration/Rewards Max                      10.0583
exploration/Rewards Min                      -0.423378
exploration/Returns Mean                   5072.06
exploration/Returns Std                       0
exploration/Returns Max                    5072.06
exploration/Returns Min                    5072.06
exploration/Num Paths                         1
exploration/Average Returns                5072.06
evaluation_0/num steps total                  6.58906e+06
evaluation_0/num paths total              14744
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.01619
evaluation_0/Rewards Std                      1.30564
evaluation_0/Rewards Max                     10.323
evaluation_0/Rewards Min                     -0.524282
evaluation_0/Returns Mean                  5016.19
evaluation_0/Returns Std                     13.4845
evaluation_0/Returns Max                   5043.41
evaluation_0/Returns Min                   4999.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5016.19
time/epoch (s)                                0
time/total (s)                            15949.8
Epoch                                       834
---------------------------------------  ----------------
2022-11-16 15:11:51.878512 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 835 finished
---------------------------------------  ----------------
epoch                                       835
total_step                               840000
replay_pool/size                         840000
trainer/alpha                                 0.0618499
trainer/alpha_loss                            0.010087
trainer/entropy                              -6.00362
trainer/qf_loss                               6.26444
trainer/state_noise                           0.005
trainer/policy_loss                        -232.221
trainer/policy_loss_without_entropy         234.378
trainer/entropy_penalty                      -0.371324
trainer/entropy_percentage                   -0.0015843
trainer/Q1Pred Mean                         234.103
trainer/Q1Pred Std                           74.8048
trainer/Q1Pred Max                          319.478
trainer/Q1Pred Min                           24.4434
trainer/Q2Pred Mean                         234.18
trainer/Q2Pred Std                           74.7144
trainer/Q2Pred Max                          317.674
trainer/Q2Pred Min                           23.1049
trainer/QTargetWithReg Mean                 234.18
trainer/QTargetWithReg Std                   74.545
trainer/QTargetWithReg Max                  317.624
trainer/QTargetWithReg Min                   22.615
trainer/PolicyLossWithoutReg Mean           234.378
trainer/PolicyLossWithoutReg Std             74.0032
trainer/PolicyLossWithoutReg Max            317.395
trainer/PolicyLossWithoutReg Min             22.6849
trainer/gradient_norm                       357.104
trainer/gradient_penalty                     -1.78552
trainer/gradient_percentage                  -0.00761812
exploration/num steps total              840000
exploration/num paths total                2000
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.25273
exploration/Rewards Std                       1.32976
exploration/Rewards Max                      10.1969
exploration/Rewards Min                      -0.463646
exploration/Returns Mean                   5252.73
exploration/Returns Std                       0
exploration/Returns Max                    5252.73
exploration/Returns Min                    5252.73
exploration/Num Paths                         1
exploration/Average Returns                5252.73
evaluation_0/num steps total                  6.59706e+06
evaluation_0/num paths total              14752
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.123
evaluation_0/Rewards Std                      1.29189
evaluation_0/Rewards Max                     10.2645
evaluation_0/Rewards Min                     -0.471903
evaluation_0/Returns Mean                  5123
evaluation_0/Returns Std                     21.6558
evaluation_0/Returns Max                   5150.2
evaluation_0/Returns Min                   5094.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5123
time/epoch (s)                                0
time/total (s)                            15965.6
Epoch                                       835
---------------------------------------  ----------------
2022-11-16 15:12:08.343278 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 836 finished
---------------------------------------  ----------------
epoch                                       836
total_step                               841000
replay_pool/size                         841000
trainer/alpha                                 0.0611003
trainer/alpha_loss                           -0.540572
trainer/entropy                              -5.80662
trainer/qf_loss                               7.27163
trainer/state_noise                           0.005
trainer/policy_loss                        -241.122
trainer/policy_loss_without_entropy         243.176
trainer/entropy_penalty                      -0.354786
trainer/entropy_percentage                   -0.00145897
trainer/Q1Pred Mean                         243.453
trainer/Q1Pred Std                           71.6832
trainer/Q1Pred Max                          321.083
trainer/Q1Pred Min                            0.156241
trainer/Q2Pred Mean                         243.085
trainer/Q2Pred Std                           71.5948
trainer/Q2Pred Max                          317.931
trainer/Q2Pred Min                            1.65713
trainer/QTargetWithReg Mean                 242.78
trainer/QTargetWithReg Std                   71.9786
trainer/QTargetWithReg Max                  318.289
trainer/QTargetWithReg Min                    4.90999
trainer/PolicyLossWithoutReg Mean           243.176
trainer/PolicyLossWithoutReg Std             70.8971
trainer/PolicyLossWithoutReg Max            317.357
trainer/PolicyLossWithoutReg Min              7.17633
trainer/gradient_norm                       339.783
trainer/gradient_penalty                     -1.69892
trainer/gradient_percentage                  -0.00698636
exploration/num steps total              841000
exploration/num paths total                2001
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17282
exploration/Rewards Std                       1.32816
exploration/Rewards Max                      10.3353
exploration/Rewards Min                      -0.446685
exploration/Returns Mean                   5172.82
exploration/Returns Std                       0
exploration/Returns Max                    5172.82
exploration/Returns Min                    5172.82
exploration/Num Paths                         1
exploration/Average Returns                5172.82
evaluation_0/num steps total                  6.60506e+06
evaluation_0/num paths total              14760
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10911
evaluation_0/Rewards Std                      1.32656
evaluation_0/Rewards Max                     10.3812
evaluation_0/Rewards Min                     -0.455662
evaluation_0/Returns Mean                  5109.11
evaluation_0/Returns Std                     22.9969
evaluation_0/Returns Max                   5143.6
evaluation_0/Returns Min                   5070.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5109.11
time/epoch (s)                                0
time/total (s)                            15982
Epoch                                       836
---------------------------------------  ----------------
2022-11-16 15:12:24.192254 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 837 finished
---------------------------------------  ----------------
epoch                                       837
total_step                               842000
replay_pool/size                         842000
trainer/alpha                                 0.0619165
trainer/alpha_loss                           -0.626497
trainer/entropy                              -5.77481
trainer/qf_loss                               6.89874
trainer/state_noise                           0.005
trainer/policy_loss                        -228.047
trainer/policy_loss_without_entropy         230.182
trainer/entropy_penalty                      -0.357556
trainer/entropy_percentage                   -0.00155336
trainer/Q1Pred Mean                         229.941
trainer/Q1Pred Std                           76.3954
trainer/Q1Pred Max                          322.911
trainer/Q1Pred Min                            6.52779
trainer/Q2Pred Mean                         229.37
trainer/Q2Pred Std                           76.6233
trainer/Q2Pred Max                          324.333
trainer/Q2Pred Min                           10.5284
trainer/QTargetWithReg Mean                 229.523
trainer/QTargetWithReg Std                   76.8089
trainer/QTargetWithReg Max                  326.134
trainer/QTargetWithReg Min                    3.09315
trainer/PolicyLossWithoutReg Mean           230.182
trainer/PolicyLossWithoutReg Std             75.8407
trainer/PolicyLossWithoutReg Max            324.372
trainer/PolicyLossWithoutReg Min             11.9533
trainer/gradient_norm                       355.504
trainer/gradient_penalty                     -1.77752
trainer/gradient_percentage                  -0.00772224
exploration/num steps total              842000
exploration/num paths total                2002
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11414
exploration/Rewards Std                       1.40822
exploration/Rewards Max                      10.2275
exploration/Rewards Min                      -0.53776
exploration/Returns Mean                   5114.14
exploration/Returns Std                       0
exploration/Returns Max                    5114.14
exploration/Returns Min                    5114.14
exploration/Num Paths                         1
exploration/Average Returns                5114.14
evaluation_0/num steps total                  6.61306e+06
evaluation_0/num paths total              14768
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24087
evaluation_0/Rewards Std                      1.32567
evaluation_0/Rewards Max                     10.5396
evaluation_0/Rewards Min                     -0.491595
evaluation_0/Returns Mean                  5240.87
evaluation_0/Returns Std                     47.8782
evaluation_0/Returns Max                   5293.21
evaluation_0/Returns Min                   5155.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5240.87
time/epoch (s)                                0
time/total (s)                            15997.9
Epoch                                       837
---------------------------------------  ----------------
2022-11-16 15:12:40.571085 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 838 finished
---------------------------------------  ----------------
epoch                                       838
total_step                               843000
replay_pool/size                         843000
trainer/alpha                                 0.0606266
trainer/alpha_loss                           -0.565602
trainer/entropy                              -5.79822
trainer/qf_loss                               8.84426
trainer/state_noise                           0.005
trainer/policy_loss                        -236.499
trainer/policy_loss_without_entropy         238.639
trainer/entropy_penalty                      -0.351526
trainer/entropy_percentage                   -0.00147305
trainer/Q1Pred Mean                         238.071
trainer/Q1Pred Std                           72.2823
trainer/Q1Pred Max                          320.541
trainer/Q1Pred Min                           27.7125
trainer/Q2Pred Mean                         238.275
trainer/Q2Pred Std                           72.1594
trainer/Q2Pred Max                          320.072
trainer/Q2Pred Min                           30.7295
trainer/QTargetWithReg Mean                 238.319
trainer/QTargetWithReg Std                   72.1723
trainer/QTargetWithReg Max                  321.14
trainer/QTargetWithReg Min                   26.9379
trainer/PolicyLossWithoutReg Mean           238.639
trainer/PolicyLossWithoutReg Std             71.9531
trainer/PolicyLossWithoutReg Max            319.831
trainer/PolicyLossWithoutReg Min             28.4063
trainer/gradient_norm                       357.799
trainer/gradient_penalty                     -1.789
trainer/gradient_percentage                  -0.00749666
exploration/num steps total              843000
exploration/num paths total                2003
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0099
exploration/Rewards Std                       1.2823
exploration/Rewards Max                      10.2584
exploration/Rewards Min                      -0.515145
exploration/Returns Mean                   5009.9
exploration/Returns Std                       0
exploration/Returns Max                    5009.9
exploration/Returns Min                    5009.9
exploration/Num Paths                         1
exploration/Average Returns                5009.9
evaluation_0/num steps total                  6.62106e+06
evaluation_0/num paths total              14776
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09326
evaluation_0/Rewards Std                      1.32125
evaluation_0/Rewards Max                     10.3365
evaluation_0/Rewards Min                     -0.523614
evaluation_0/Returns Mean                  5093.26
evaluation_0/Returns Std                     33.7088
evaluation_0/Returns Max                   5135.85
evaluation_0/Returns Min                   5048.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5093.26
time/epoch (s)                                0
time/total (s)                            16014.3
Epoch                                       838
---------------------------------------  ----------------
2022-11-16 15:12:56.452034 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 839 finished
---------------------------------------  ----------------
epoch                                       839
total_step                               844000
replay_pool/size                         844000
trainer/alpha                                 0.0590704
trainer/alpha_loss                            1.96161
trainer/entropy                              -6.69332
trainer/qf_loss                               8.93878
trainer/state_noise                           0.005
trainer/policy_loss                        -229.772
trainer/policy_loss_without_entropy         231.916
trainer/entropy_penalty                      -0.395377
trainer/entropy_percentage                   -0.00170483
trainer/Q1Pred Mean                         230.861
trainer/Q1Pred Std                           75.9634
trainer/Q1Pred Max                          321.672
trainer/Q1Pred Min                           -7.05992
trainer/Q2Pred Mean                         231.037
trainer/Q2Pred Std                           75.5231
trainer/Q2Pred Max                          321.842
trainer/Q2Pred Min                           -6.28938
trainer/QTargetWithReg Mean                 231.8
trainer/QTargetWithReg Std                   76.121
trainer/QTargetWithReg Max                  322.698
trainer/QTargetWithReg Min                   -0.587591
trainer/PolicyLossWithoutReg Mean           231.916
trainer/PolicyLossWithoutReg Std             74.5634
trainer/PolicyLossWithoutReg Max            322.089
trainer/PolicyLossWithoutReg Min             26.3565
trainer/gradient_norm                       349.61
trainer/gradient_penalty                     -1.74805
trainer/gradient_percentage                  -0.00753744
exploration/num steps total              844000
exploration/num paths total                2004
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01943
exploration/Rewards Std                       1.33267
exploration/Rewards Max                      10.6771
exploration/Rewards Min                      -0.510931
exploration/Returns Mean                   5019.43
exploration/Returns Std                       0
exploration/Returns Max                    5019.43
exploration/Returns Min                    5019.43
exploration/Num Paths                         1
exploration/Average Returns                5019.43
evaluation_0/num steps total                  6.62906e+06
evaluation_0/num paths total              14784
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17601
evaluation_0/Rewards Std                      1.28513
evaluation_0/Rewards Max                     10.2042
evaluation_0/Rewards Min                     -0.588661
evaluation_0/Returns Mean                  5176.01
evaluation_0/Returns Std                     34.5885
evaluation_0/Returns Max                   5213.16
evaluation_0/Returns Min                   5102.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5176.01
time/epoch (s)                                0
time/total (s)                            16030.1
Epoch                                       839
---------------------------------------  ----------------
2022-11-16 15:13:12.537088 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 840 finished
---------------------------------------  ----------------
epoch                                       840
total_step                               845000
replay_pool/size                         845000
trainer/alpha                                 0.061321
trainer/alpha_loss                            1.49672
trainer/entropy                              -6.53615
trainer/qf_loss                              39.8038
trainer/state_noise                           0.005
trainer/policy_loss                        -221.533
trainer/policy_loss_without_entropy         223.691
trainer/entropy_penalty                      -0.400803
trainer/entropy_percentage                   -0.00179177
trainer/Q1Pred Mean                         223.63
trainer/Q1Pred Std                           85.096
trainer/Q1Pred Max                          322.984
trainer/Q1Pred Min                          -15.2894
trainer/Q2Pred Mean                         223.422
trainer/Q2Pred Std                           85.066
trainer/Q2Pred Max                          323.257
trainer/Q2Pred Min                          -20.2377
trainer/QTargetWithReg Mean                 222.857
trainer/QTargetWithReg Std                   85.6614
trainer/QTargetWithReg Max                  323.254
trainer/QTargetWithReg Min                  -15.0726
trainer/PolicyLossWithoutReg Mean           223.691
trainer/PolicyLossWithoutReg Std             84.3852
trainer/PolicyLossWithoutReg Max            322.408
trainer/PolicyLossWithoutReg Min            -16.7956
trainer/gradient_norm                       351.406
trainer/gradient_penalty                     -1.75703
trainer/gradient_percentage                  -0.0078547
exploration/num steps total              845000
exploration/num paths total                2005
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10916
exploration/Rewards Std                       1.28396
exploration/Rewards Max                      10.2345
exploration/Rewards Min                      -0.50353
exploration/Returns Mean                   5109.16
exploration/Returns Std                       0
exploration/Returns Max                    5109.16
exploration/Returns Min                    5109.16
exploration/Num Paths                         1
exploration/Average Returns                5109.16
evaluation_0/num steps total                  6.63706e+06
evaluation_0/num paths total              14792
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18479
evaluation_0/Rewards Std                      1.30812
evaluation_0/Rewards Max                     10.3616
evaluation_0/Rewards Min                     -0.484645
evaluation_0/Returns Mean                  5184.79
evaluation_0/Returns Std                     18.1433
evaluation_0/Returns Max                   5213.99
evaluation_0/Returns Min                   5156.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5184.79
time/epoch (s)                                0
time/total (s)                            16046.2
Epoch                                       840
---------------------------------------  ----------------
2022-11-16 15:13:28.617563 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 841 finished
---------------------------------------  ----------------
epoch                                       841
total_step                               846000
replay_pool/size                         846000
trainer/alpha                                 0.0612683
trainer/alpha_loss                           -0.20902
trainer/entropy                              -5.92515
trainer/qf_loss                               4.99421
trainer/state_noise                           0.005
trainer/policy_loss                        -236.11
trainer/policy_loss_without_entropy         238.211
trainer/entropy_penalty                      -0.363024
trainer/entropy_percentage                   -0.00152396
trainer/Q1Pred Mean                         237.171
trainer/Q1Pred Std                           71.817
trainer/Q1Pred Max                          320.864
trainer/Q1Pred Min                            9.53241
trainer/Q2Pred Mean                         236.96
trainer/Q2Pred Std                           71.6701
trainer/Q2Pred Max                          322.618
trainer/Q2Pred Min                            7.6076
trainer/QTargetWithReg Mean                 237.065
trainer/QTargetWithReg Std                   71.9321
trainer/QTargetWithReg Max                  320.987
trainer/QTargetWithReg Min                    7.80844
trainer/PolicyLossWithoutReg Mean           238.211
trainer/PolicyLossWithoutReg Std             70.7452
trainer/PolicyLossWithoutReg Max            321.769
trainer/PolicyLossWithoutReg Min              8.60096
trainer/gradient_norm                       347.562
trainer/gradient_penalty                     -1.73781
trainer/gradient_percentage                  -0.00729527
exploration/num steps total              846000
exploration/num paths total                2006
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.02132
exploration/Rewards Std                       1.28034
exploration/Rewards Max                      10.4987
exploration/Rewards Min                      -0.36975
exploration/Returns Mean                   5021.32
exploration/Returns Std                       0
exploration/Returns Max                    5021.32
exploration/Returns Min                    5021.32
exploration/Num Paths                         1
exploration/Average Returns                5021.32
evaluation_0/num steps total                  6.64506e+06
evaluation_0/num paths total              14800
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08554
evaluation_0/Rewards Std                      1.27471
evaluation_0/Rewards Max                     10.2572
evaluation_0/Rewards Min                     -0.446003
evaluation_0/Returns Mean                  5085.54
evaluation_0/Returns Std                     16.3678
evaluation_0/Returns Max                   5105.99
evaluation_0/Returns Min                   5059.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5085.54
time/epoch (s)                                0
time/total (s)                            16062.3
Epoch                                       841
---------------------------------------  ----------------
2022-11-16 15:13:44.425496 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 842 finished
---------------------------------------  ----------------
epoch                                       842
total_step                               847000
replay_pool/size                         847000
trainer/alpha                                 0.0632432
trainer/alpha_loss                            1.02854
trainer/entropy                              -6.37256
trainer/qf_loss                              13.8371
trainer/state_noise                           0.005
trainer/policy_loss                        -230.65
trainer/policy_loss_without_entropy         232.842
trainer/entropy_penalty                      -0.403021
trainer/entropy_percentage                   -0.00173088
trainer/Q1Pred Mean                         232.611
trainer/Q1Pred Std                           79.178
trainer/Q1Pred Max                          319.304
trainer/Q1Pred Min                           -2.1381
trainer/Q2Pred Mean                         232.445
trainer/Q2Pred Std                           78.8698
trainer/Q2Pred Max                          321.891
trainer/Q2Pred Min                          -10.1651
trainer/QTargetWithReg Mean                 232.317
trainer/QTargetWithReg Std                   79.5846
trainer/QTargetWithReg Max                  321.268
trainer/QTargetWithReg Min                  -10.739
trainer/PolicyLossWithoutReg Mean           232.842
trainer/PolicyLossWithoutReg Std             78.0998
trainer/PolicyLossWithoutReg Max            319.761
trainer/PolicyLossWithoutReg Min              4.34419
trainer/gradient_norm                       357.896
trainer/gradient_penalty                     -1.78948
trainer/gradient_percentage                  -0.00768538
exploration/num steps total              847000
exploration/num paths total                2007
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.20864
exploration/Rewards Std                       1.29404
exploration/Rewards Max                      10.221
exploration/Rewards Min                      -0.512012
exploration/Returns Mean                   5208.64
exploration/Returns Std                       0
exploration/Returns Max                    5208.64
exploration/Returns Min                    5208.64
exploration/Num Paths                         1
exploration/Average Returns                5208.64
evaluation_0/num steps total                  6.65306e+06
evaluation_0/num paths total              14808
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22214
evaluation_0/Rewards Std                      1.30894
evaluation_0/Rewards Max                     10.4143
evaluation_0/Rewards Min                     -0.4408
evaluation_0/Returns Mean                  5222.14
evaluation_0/Returns Std                     21.473
evaluation_0/Returns Max                   5247.33
evaluation_0/Returns Min                   5191.74
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5222.14
time/epoch (s)                                0
time/total (s)                            16078.1
Epoch                                       842
---------------------------------------  ----------------
2022-11-16 15:14:00.878936 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 843 finished
---------------------------------------  ----------------
epoch                                       843
total_step                               848000
replay_pool/size                         848000
trainer/alpha                                 0.0622755
trainer/alpha_loss                            0.0909526
trainer/entropy                              -6.03276
trainer/qf_loss                               7.70442
trainer/state_noise                           0.005
trainer/policy_loss                        -241.231
trainer/policy_loss_without_entropy         243.328
trainer/entropy_penalty                      -0.375694
trainer/entropy_percentage                   -0.00154398
trainer/Q1Pred Mean                         242.88
trainer/Q1Pred Std                           73.197
trainer/Q1Pred Max                          322.999
trainer/Q1Pred Min                            0.983505
trainer/Q2Pred Mean                         242.244
trainer/Q2Pred Std                           73.2367
trainer/Q2Pred Max                          322.483
trainer/Q2Pred Min                           -2.77435
trainer/QTargetWithReg Mean                 242.618
trainer/QTargetWithReg Std                   73.9986
trainer/QTargetWithReg Max                  322.785
trainer/QTargetWithReg Min                    0.0472331
trainer/PolicyLossWithoutReg Mean           243.328
trainer/PolicyLossWithoutReg Std             71.7071
trainer/PolicyLossWithoutReg Max            322.475
trainer/PolicyLossWithoutReg Min              8.1748
trainer/gradient_norm                       344.328
trainer/gradient_penalty                     -1.72164
trainer/gradient_percentage                  -0.00707539
exploration/num steps total              848000
exploration/num paths total                2008
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14999
exploration/Rewards Std                       1.31513
exploration/Rewards Max                      10.6017
exploration/Rewards Min                      -0.546576
exploration/Returns Mean                   5149.99
exploration/Returns Std                       0
exploration/Returns Max                    5149.99
exploration/Returns Min                    5149.99
exploration/Num Paths                         1
exploration/Average Returns                5149.99
evaluation_0/num steps total                  6.66106e+06
evaluation_0/num paths total              14816
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10858
evaluation_0/Rewards Std                      1.29241
evaluation_0/Rewards Max                     10.2773
evaluation_0/Rewards Min                     -0.428663
evaluation_0/Returns Mean                  5108.58
evaluation_0/Returns Std                     32.3377
evaluation_0/Returns Max                   5145.72
evaluation_0/Returns Min                   5063.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5108.58
time/epoch (s)                                0
time/total (s)                            16094.6
Epoch                                       843
---------------------------------------  ----------------
2022-11-16 15:14:16.765752 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 844 finished
---------------------------------------  ----------------
epoch                                       844
total_step                               849000
replay_pool/size                         849000
trainer/alpha                                 0.0591367
trainer/alpha_loss                           -1.20696
trainer/entropy                              -5.57318
trainer/qf_loss                               5.96855
trainer/state_noise                           0.005
trainer/policy_loss                        -235.924
trainer/policy_loss_without_entropy         238.118
trainer/entropy_penalty                      -0.32958
trainer/entropy_percentage                   -0.0013841
trainer/Q1Pred Mean                         238.05
trainer/Q1Pred Std                           69.3474
trainer/Q1Pred Max                          320.87
trainer/Q1Pred Min                           13.0586
trainer/Q2Pred Mean                         237.886
trainer/Q2Pred Std                           68.9858
trainer/Q2Pred Max                          320.227
trainer/Q2Pred Min                           11.9813
trainer/QTargetWithReg Mean                 237.78
trainer/QTargetWithReg Std                   68.4729
trainer/QTargetWithReg Max                  319.775
trainer/QTargetWithReg Min                   14.815
trainer/PolicyLossWithoutReg Mean           238.118
trainer/PolicyLossWithoutReg Std             68.4647
trainer/PolicyLossWithoutReg Max            319.379
trainer/PolicyLossWithoutReg Min             13.6418
trainer/gradient_norm                       372.875
trainer/gradient_penalty                     -1.86437
trainer/gradient_percentage                  -0.00782962
exploration/num steps total              849000
exploration/num paths total                2009
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04432
exploration/Rewards Std                       1.36813
exploration/Rewards Max                      10.3805
exploration/Rewards Min                      -0.423208
exploration/Returns Mean                   5044.32
exploration/Returns Std                       0
exploration/Returns Max                    5044.32
exploration/Returns Min                    5044.32
exploration/Num Paths                         1
exploration/Average Returns                5044.32
evaluation_0/num steps total                  6.66906e+06
evaluation_0/num paths total              14824
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17905
evaluation_0/Rewards Std                      1.351
evaluation_0/Rewards Max                     10.8979
evaluation_0/Rewards Min                     -0.433383
evaluation_0/Returns Mean                  5179.05
evaluation_0/Returns Std                     60.9189
evaluation_0/Returns Max                   5285.9
evaluation_0/Returns Min                   5099.47
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5179.05
time/epoch (s)                                0
time/total (s)                            16110.5
Epoch                                       844
---------------------------------------  ----------------
2022-11-16 15:14:33.078808 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 845 finished
---------------------------------------  ----------------
epoch                                       845
total_step                               850000
replay_pool/size                         850000
trainer/alpha                                 0.0591909
trainer/alpha_loss                            1.17524
trainer/entropy                              -6.41572
trainer/qf_loss                               5.68947
trainer/state_noise                           0.005
trainer/policy_loss                        -240.77
trainer/policy_loss_without_entropy         243.056
trainer/entropy_penalty                      -0.379752
trainer/entropy_percentage                   -0.0015624
trainer/Q1Pred Mean                         242.297
trainer/Q1Pred Std                           69.8853
trainer/Q1Pred Max                          315.245
trainer/Q1Pred Min                          -13.866
trainer/Q2Pred Mean                         242.956
trainer/Q2Pred Std                           69.9296
trainer/Q2Pred Max                          316.364
trainer/Q2Pred Min                           -6.67117
trainer/QTargetWithReg Mean                 242.326
trainer/QTargetWithReg Std                   69.655
trainer/QTargetWithReg Max                  317.003
trainer/QTargetWithReg Min                  -17.9125
trainer/PolicyLossWithoutReg Mean           243.056
trainer/PolicyLossWithoutReg Std             69.0884
trainer/PolicyLossWithoutReg Max            316.168
trainer/PolicyLossWithoutReg Min             -4.66549
trainer/gradient_norm                       381.223
trainer/gradient_penalty                     -1.90612
trainer/gradient_percentage                  -0.00784228
exploration/num steps total              850000
exploration/num paths total                2010
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03293
exploration/Rewards Std                       1.32401
exploration/Rewards Max                      10.3299
exploration/Rewards Min                      -0.490929
exploration/Returns Mean                   5032.93
exploration/Returns Std                       0
exploration/Returns Max                    5032.93
exploration/Returns Min                    5032.93
exploration/Num Paths                         1
exploration/Average Returns                5032.93
evaluation_0/num steps total                  6.67706e+06
evaluation_0/num paths total              14832
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08023
evaluation_0/Rewards Std                      1.34127
evaluation_0/Rewards Max                     10.3355
evaluation_0/Rewards Min                     -0.453202
evaluation_0/Returns Mean                  5080.23
evaluation_0/Returns Std                     20.0557
evaluation_0/Returns Max                   5107.06
evaluation_0/Returns Min                   5047.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5080.23
time/epoch (s)                                0
time/total (s)                            16126.8
Epoch                                       845
---------------------------------------  ----------------
2022-11-16 15:14:49.023795 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 846 finished
---------------------------------------  ----------------
epoch                                       846
total_step                               851000
replay_pool/size                         851000
trainer/alpha                                 0.0589323
trainer/alpha_loss                           -1.34863
trainer/entropy                              -5.52365
trainer/qf_loss                               6.63838
trainer/state_noise                           0.005
trainer/policy_loss                        -238.739
trainer/policy_loss_without_entropy         240.846
trainer/entropy_penalty                      -0.325522
trainer/entropy_percentage                   -0.00135158
trainer/Q1Pred Mean                         240.46
trainer/Q1Pred Std                           72.7159
trainer/Q1Pred Max                          323.498
trainer/Q1Pred Min                            2.9635
trainer/Q2Pred Mean                         240.847
trainer/Q2Pred Std                           72.8897
trainer/Q2Pred Max                          324.662
trainer/Q2Pred Min                            5.21463
trainer/QTargetWithReg Mean                 239.921
trainer/QTargetWithReg Std                   72.5913
trainer/QTargetWithReg Max                  322.269
trainer/QTargetWithReg Min                    3.3376
trainer/PolicyLossWithoutReg Mean           240.846
trainer/PolicyLossWithoutReg Std             72.1626
trainer/PolicyLossWithoutReg Max            325.449
trainer/PolicyLossWithoutReg Min              4.48346
trainer/gradient_norm                       356.307
trainer/gradient_penalty                     -1.78154
trainer/gradient_percentage                  -0.00739698
exploration/num steps total              851000
exploration/num paths total                2011
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.18619
exploration/Rewards Std                       1.34617
exploration/Rewards Max                      10.5929
exploration/Rewards Min                      -0.551675
exploration/Returns Mean                   5186.19
exploration/Returns Std                       0
exploration/Returns Max                    5186.19
exploration/Returns Min                    5186.19
exploration/Num Paths                         1
exploration/Average Returns                5186.19
evaluation_0/num steps total                  6.68506e+06
evaluation_0/num paths total              14840
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11192
evaluation_0/Rewards Std                      1.30343
evaluation_0/Rewards Max                     10.4918
evaluation_0/Rewards Min                     -0.474128
evaluation_0/Returns Mean                  5111.92
evaluation_0/Returns Std                     32.8207
evaluation_0/Returns Max                   5159.16
evaluation_0/Returns Min                   5071.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5111.92
time/epoch (s)                                0
time/total (s)                            16142.7
Epoch                                       846
---------------------------------------  ----------------
2022-11-16 15:15:04.832565 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 847 finished
---------------------------------------  ----------------
epoch                                       847
total_step                               852000
replay_pool/size                         852000
trainer/alpha                                 0.0594133
trainer/alpha_loss                            0.0618953
trainer/entropy                              -6.02192
trainer/qf_loss                               6.66794
trainer/state_noise                           0.005
trainer/policy_loss                        -241.648
trainer/policy_loss_without_entropy         243.796
trainer/entropy_penalty                      -0.357783
trainer/entropy_percentage                   -0.00146755
trainer/Q1Pred Mean                         243.841
trainer/Q1Pred Std                           72.6248
trainer/Q1Pred Max                          322.951
trainer/Q1Pred Min                            4.75157
trainer/Q2Pred Mean                         243.096
trainer/Q2Pred Std                           72.5595
trainer/Q2Pred Max                          321.364
trainer/Q2Pred Min                            7.00924
trainer/QTargetWithReg Mean                 243.133
trainer/QTargetWithReg Std                   72.5692
trainer/QTargetWithReg Max                  321.974
trainer/QTargetWithReg Min                    3.83009
trainer/PolicyLossWithoutReg Mean           243.796
trainer/PolicyLossWithoutReg Std             71.7148
trainer/PolicyLossWithoutReg Max            322.295
trainer/PolicyLossWithoutReg Min              5.02557
trainer/gradient_norm                       358.195
trainer/gradient_penalty                     -1.79098
trainer/gradient_percentage                  -0.0073462
exploration/num steps total              852000
exploration/num paths total                2012
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03983
exploration/Rewards Std                       1.32662
exploration/Rewards Max                      10.6578
exploration/Rewards Min                      -0.463649
exploration/Returns Mean                   5039.83
exploration/Returns Std                       0
exploration/Returns Max                    5039.83
exploration/Returns Min                    5039.83
exploration/Num Paths                         1
exploration/Average Returns                5039.83
evaluation_0/num steps total                  6.69306e+06
evaluation_0/num paths total              14848
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22904
evaluation_0/Rewards Std                      1.33997
evaluation_0/Rewards Max                     10.5663
evaluation_0/Rewards Min                     -0.47363
evaluation_0/Returns Mean                  5229.04
evaluation_0/Returns Std                     26.1402
evaluation_0/Returns Max                   5263.96
evaluation_0/Returns Min                   5195.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5229.04
time/epoch (s)                                0
time/total (s)                            16158.5
Epoch                                       847
---------------------------------------  ----------------
2022-11-16 15:15:21.327553 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 848 finished
---------------------------------------  ----------------
epoch                                       848
total_step                               853000
replay_pool/size                         853000
trainer/alpha                                 0.0611868
trainer/alpha_loss                           -0.7593
trainer/entropy                              -5.72824
trainer/qf_loss                               4.65957
trainer/state_noise                           0.005
trainer/policy_loss                        -242.726
trainer/policy_loss_without_entropy         244.84
trainer/entropy_penalty                      -0.350493
trainer/entropy_percentage                   -0.00143152
trainer/Q1Pred Mean                         244.286
trainer/Q1Pred Std                           69.958
trainer/Q1Pred Max                          320.586
trainer/Q1Pred Min                           19.1112
trainer/Q2Pred Mean                         243.923
trainer/Q2Pred Std                           69.9449
trainer/Q2Pred Max                          321.455
trainer/Q2Pred Min                           19.2293
trainer/QTargetWithReg Mean                 244.238
trainer/QTargetWithReg Std                   70.0006
trainer/QTargetWithReg Max                  322.003
trainer/QTargetWithReg Min                   21.5498
trainer/PolicyLossWithoutReg Mean           244.84
trainer/PolicyLossWithoutReg Std             69.4385
trainer/PolicyLossWithoutReg Max            321.638
trainer/PolicyLossWithoutReg Min             19.9235
trainer/gradient_norm                       352.668
trainer/gradient_penalty                     -1.76334
trainer/gradient_percentage                  -0.00720201
exploration/num steps total              853000
exploration/num paths total                2013
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17032
exploration/Rewards Std                       1.31844
exploration/Rewards Max                      10.6921
exploration/Rewards Min                      -0.504783
exploration/Returns Mean                   5170.32
exploration/Returns Std                       0
exploration/Returns Max                    5170.32
exploration/Returns Min                    5170.32
exploration/Num Paths                         1
exploration/Average Returns                5170.32
evaluation_0/num steps total                  6.70106e+06
evaluation_0/num paths total              14856
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11883
evaluation_0/Rewards Std                      1.29494
evaluation_0/Rewards Max                     10.4931
evaluation_0/Rewards Min                     -0.45458
evaluation_0/Returns Mean                  5118.83
evaluation_0/Returns Std                     32.9874
evaluation_0/Returns Max                   5170.21
evaluation_0/Returns Min                   5065.25
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5118.83
time/epoch (s)                                0
time/total (s)                            16175
Epoch                                       848
---------------------------------------  ----------------
2022-11-16 15:15:37.137099 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 849 finished
---------------------------------------  ----------------
epoch                                       849
total_step                               854000
replay_pool/size                         854000
trainer/alpha                                 0.0619227
trainer/alpha_loss                            1.65233
trainer/entropy                              -6.59392
trainer/qf_loss                               8.73407
trainer/state_noise                           0.005
trainer/policy_loss                        -231.162
trainer/policy_loss_without_entropy         233.374
trainer/entropy_penalty                      -0.408314
trainer/entropy_percentage                   -0.00174961
trainer/Q1Pred Mean                         233.04
trainer/Q1Pred Std                           76.3207
trainer/Q1Pred Max                          318.363
trainer/Q1Pred Min                           25.5096
trainer/Q2Pred Mean                         232.942
trainer/Q2Pred Std                           76.1158
trainer/Q2Pred Max                          321.746
trainer/Q2Pred Min                           20.4818
trainer/QTargetWithReg Mean                 232.63
trainer/QTargetWithReg Std                   76.2456
trainer/QTargetWithReg Max                  318.915
trainer/QTargetWithReg Min                   17.5773
trainer/PolicyLossWithoutReg Mean           233.374
trainer/PolicyLossWithoutReg Std             75.2324
trainer/PolicyLossWithoutReg Max            317.435
trainer/PolicyLossWithoutReg Min             21.7574
trainer/gradient_norm                       360.606
trainer/gradient_penalty                     -1.80303
trainer/gradient_percentage                  -0.00772594
exploration/num steps total              854000
exploration/num paths total                2014
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19943
exploration/Rewards Std                       1.32499
exploration/Rewards Max                      10.5254
exploration/Rewards Min                      -0.456677
exploration/Returns Mean                   5199.43
exploration/Returns Std                       0
exploration/Returns Max                    5199.43
exploration/Returns Min                    5199.43
exploration/Num Paths                         1
exploration/Average Returns                5199.43
evaluation_0/num steps total                  6.70906e+06
evaluation_0/num paths total              14864
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08633
evaluation_0/Rewards Std                      1.3224
evaluation_0/Rewards Max                     10.5232
evaluation_0/Rewards Min                     -0.39551
evaluation_0/Returns Mean                  5086.33
evaluation_0/Returns Std                     18.5302
evaluation_0/Returns Max                   5120.84
evaluation_0/Returns Min                   5060.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5086.33
time/epoch (s)                                0
time/total (s)                            16190.8
Epoch                                       849
---------------------------------------  ----------------
2022-11-16 15:15:53.654654 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 850 finished
---------------------------------------  ----------------
epoch                                       850
total_step                               855000
replay_pool/size                         855000
trainer/alpha                                 0.0622752
trainer/alpha_loss                            0.626883
trainer/entropy                              -6.22579
trainer/qf_loss                              10.0913
trainer/state_noise                           0.005
trainer/policy_loss                        -238.004
trainer/policy_loss_without_entropy         240.212
trainer/entropy_penalty                      -0.387712
trainer/entropy_percentage                   -0.00161404
trainer/Q1Pred Mean                         238.476
trainer/Q1Pred Std                           76.4959
trainer/Q1Pred Max                          322.429
trainer/Q1Pred Min                            0.231709
trainer/Q2Pred Mean                         238.445
trainer/Q2Pred Std                           76.1526
trainer/Q2Pred Max                          320.922
trainer/Q2Pred Min                            4.5128
trainer/QTargetWithReg Mean                 238.607
trainer/QTargetWithReg Std                   76.228
trainer/QTargetWithReg Max                  322.87
trainer/QTargetWithReg Min                    2.87083
trainer/PolicyLossWithoutReg Mean           240.213
trainer/PolicyLossWithoutReg Std             75.9236
trainer/PolicyLossWithoutReg Max            322.387
trainer/PolicyLossWithoutReg Min              3.76922
trainer/gradient_norm                       364.091
trainer/gradient_penalty                     -1.82045
trainer/gradient_percentage                  -0.00757851
exploration/num steps total              855000
exploration/num paths total                2015
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.23497
exploration/Rewards Std                       1.39254
exploration/Rewards Max                      10.4853
exploration/Rewards Min                      -0.443937
exploration/Returns Mean                   5234.97
exploration/Returns Std                       0
exploration/Returns Max                    5234.97
exploration/Returns Min                    5234.97
exploration/Num Paths                         1
exploration/Average Returns                5234.97
evaluation_0/num steps total                  6.71706e+06
evaluation_0/num paths total              14872
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16269
evaluation_0/Rewards Std                      1.31406
evaluation_0/Rewards Max                     10.5352
evaluation_0/Rewards Min                     -0.494936
evaluation_0/Returns Mean                  5162.69
evaluation_0/Returns Std                     32.5925
evaluation_0/Returns Max                   5213.28
evaluation_0/Returns Min                   5112.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5162.69
time/epoch (s)                                0
time/total (s)                            16207.3
Epoch                                       850
---------------------------------------  ----------------
2022-11-16 15:16:09.523544 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 851 finished
---------------------------------------  ----------------
epoch                                       851
total_step                               856000
replay_pool/size                         856000
trainer/alpha                                 0.0595523
trainer/alpha_loss                            0.352131
trainer/entropy                              -6.12483
trainer/qf_loss                               7.77143
trainer/state_noise                           0.005
trainer/policy_loss                        -233.852
trainer/policy_loss_without_entropy         236.023
trainer/entropy_penalty                      -0.364748
trainer/entropy_percentage                   -0.00154539
trainer/Q1Pred Mean                         235.346
trainer/Q1Pred Std                           73.9406
trainer/Q1Pred Max                          319.652
trainer/Q1Pred Min                           16.1358
trainer/Q2Pred Mean                         235.44
trainer/Q2Pred Std                           73.8756
trainer/Q2Pred Max                          319.849
trainer/Q2Pred Min                           19.656
trainer/QTargetWithReg Mean                 235.76
trainer/QTargetWithReg Std                   74.26
trainer/QTargetWithReg Max                  319.991
trainer/QTargetWithReg Min                    8.68532
trainer/PolicyLossWithoutReg Mean           236.023
trainer/PolicyLossWithoutReg Std             73.2185
trainer/PolicyLossWithoutReg Max            319.531
trainer/PolicyLossWithoutReg Min             17.3055
trainer/gradient_norm                       361.316
trainer/gradient_penalty                     -1.80658
trainer/gradient_percentage                  -0.00765424
exploration/num steps total              856000
exploration/num paths total                2016
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19582
exploration/Rewards Std                       1.36132
exploration/Rewards Max                      10.2603
exploration/Rewards Min                      -0.549645
exploration/Returns Mean                   5195.82
exploration/Returns Std                       0
exploration/Returns Max                    5195.82
exploration/Returns Min                    5195.82
exploration/Num Paths                         1
exploration/Average Returns                5195.82
evaluation_0/num steps total                  6.72506e+06
evaluation_0/num paths total              14880
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.30918
evaluation_0/Rewards Std                      1.35545
evaluation_0/Rewards Max                     10.833
evaluation_0/Rewards Min                     -0.481959
evaluation_0/Returns Mean                  5309.18
evaluation_0/Returns Std                     45.1396
evaluation_0/Returns Max                   5393.07
evaluation_0/Returns Min                   5232.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5309.18
time/epoch (s)                                0
time/total (s)                            16223.2
Epoch                                       851
---------------------------------------  ----------------
2022-11-16 15:16:27.222577 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 852 finished
---------------------------------------  ----------------
epoch                                       852
total_step                               857000
replay_pool/size                         857000
trainer/alpha                                 0.0599027
trainer/alpha_loss                            0.279918
trainer/entropy                              -6.09944
trainer/qf_loss                               7.42571
trainer/state_noise                           0.005
trainer/policy_loss                        -236.185
trainer/policy_loss_without_entropy         238.306
trainer/entropy_penalty                      -0.365373
trainer/entropy_percentage                   -0.00153321
trainer/Q1Pred Mean                         238.269
trainer/Q1Pred Std                           76.2318
trainer/Q1Pred Max                          324.713
trainer/Q1Pred Min                          -15.7083
trainer/Q2Pred Mean                         238.637
trainer/Q2Pred Std                           76.0735
trainer/Q2Pred Max                          322.56
trainer/Q2Pred Min                          -17.4774
trainer/QTargetWithReg Mean                 237.849
trainer/QTargetWithReg Std                   76.3933
trainer/QTargetWithReg Max                  322.755
trainer/QTargetWithReg Min                  -21.8638
trainer/PolicyLossWithoutReg Mean           238.306
trainer/PolicyLossWithoutReg Std             75.391
trainer/PolicyLossWithoutReg Max            321.305
trainer/PolicyLossWithoutReg Min            -16.3034
trainer/gradient_norm                       351.268
trainer/gradient_penalty                     -1.75634
trainer/gradient_percentage                  -0.0073701
exploration/num steps total              857000
exploration/num paths total                2017
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13888
exploration/Rewards Std                       1.33456
exploration/Rewards Max                      11.1984
exploration/Rewards Min                      -0.432586
exploration/Returns Mean                   5138.88
exploration/Returns Std                       0
exploration/Returns Max                    5138.88
exploration/Returns Min                    5138.88
exploration/Num Paths                         1
exploration/Average Returns                5138.88
evaluation_0/num steps total                  6.73279e+06
evaluation_0/num paths total              14888
evaluation_0/path length Mean               966.5
evaluation_0/path length Std                 88.6327
evaluation_0/path length Max               1000
evaluation_0/path length Min                732
evaluation_0/Rewards Mean                     5.2943
evaluation_0/Rewards Std                      1.40547
evaluation_0/Rewards Max                     11.2156
evaluation_0/Rewards Min                     -0.483415
evaluation_0/Returns Mean                  5116.94
evaluation_0/Returns Std                    489.353
evaluation_0/Returns Max                   5358.67
evaluation_0/Returns Min                   3825.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5116.94
time/epoch (s)                                0
time/total (s)                            16240.9
Epoch                                       852
---------------------------------------  ----------------
2022-11-16 15:16:43.389533 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 853 finished
---------------------------------------  ----------------
epoch                                       853
total_step                               858000
replay_pool/size                         858000
trainer/alpha                                 0.0597419
trainer/alpha_loss                           -1.07639
trainer/entropy                              -5.61798
trainer/qf_loss                               7.36093
trainer/state_noise                           0.005
trainer/policy_loss                        -238.453
trainer/policy_loss_without_entropy         240.597
trainer/entropy_penalty                      -0.335629
trainer/entropy_percentage                   -0.00139498
trainer/Q1Pred Mean                         239.749
trainer/Q1Pred Std                           75.2376
trainer/Q1Pred Max                          320.876
trainer/Q1Pred Min                            1.87057
trainer/Q2Pred Mean                         240.297
trainer/Q2Pred Std                           75.3118
trainer/Q2Pred Max                          321.505
trainer/Q2Pred Min                            5.90695
trainer/QTargetWithReg Mean                 239.964
trainer/QTargetWithReg Std                   75.0856
trainer/QTargetWithReg Max                  324.673
trainer/QTargetWithReg Min                    2.94697
trainer/PolicyLossWithoutReg Mean           240.597
trainer/PolicyLossWithoutReg Std             74.6543
trainer/PolicyLossWithoutReg Max            320.458
trainer/PolicyLossWithoutReg Min              0.945468
trainer/gradient_norm                       361.677
trainer/gradient_penalty                     -1.80839
trainer/gradient_percentage                  -0.00751625
exploration/num steps total              858000
exploration/num paths total                2018
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13849
exploration/Rewards Std                       1.37229
exploration/Rewards Max                      10.3904
exploration/Rewards Min                      -0.487461
exploration/Returns Mean                   5138.49
exploration/Returns Std                       0
exploration/Returns Max                    5138.49
exploration/Returns Min                    5138.49
exploration/Num Paths                         1
exploration/Average Returns                5138.49
evaluation_0/num steps total                  6.74079e+06
evaluation_0/num paths total              14896
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10017
evaluation_0/Rewards Std                      1.31558
evaluation_0/Rewards Max                     10.3159
evaluation_0/Rewards Min                     -0.395864
evaluation_0/Returns Mean                  5100.17
evaluation_0/Returns Std                     27.4595
evaluation_0/Returns Max                   5132.62
evaluation_0/Returns Min                   5056.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5100.17
time/epoch (s)                                0
time/total (s)                            16257.1
Epoch                                       853
---------------------------------------  ----------------
2022-11-16 15:16:59.226264 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 854 finished
---------------------------------------  ----------------
epoch                                       854
total_step                               859000
replay_pool/size                         859000
trainer/alpha                                 0.0623346
trainer/alpha_loss                           -0.0964359
trainer/entropy                              -5.96525
trainer/qf_loss                               6.66258
trainer/state_noise                           0.005
trainer/policy_loss                        -240.447
trainer/policy_loss_without_entropy         242.616
trainer/entropy_penalty                      -0.371842
trainer/entropy_percentage                   -0.00153264
trainer/Q1Pred Mean                         241.863
trainer/Q1Pred Std                           71.5107
trainer/Q1Pred Max                          320.158
trainer/Q1Pred Min                            7.15392
trainer/Q2Pred Mean                         241.971
trainer/Q2Pred Std                           71.8497
trainer/Q2Pred Max                          320.759
trainer/Q2Pred Min                            9.16359
trainer/QTargetWithReg Mean                 242.049
trainer/QTargetWithReg Std                   71.5989
trainer/QTargetWithReg Max                  320.49
trainer/QTargetWithReg Min                    7.8168
trainer/PolicyLossWithoutReg Mean           242.616
trainer/PolicyLossWithoutReg Std             70.6558
trainer/PolicyLossWithoutReg Max            320.63
trainer/PolicyLossWithoutReg Min              9.01225
trainer/gradient_norm                       359.477
trainer/gradient_penalty                     -1.79739
trainer/gradient_percentage                  -0.00740837
exploration/num steps total              859000
exploration/num paths total                2019
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04596
exploration/Rewards Std                       1.33331
exploration/Rewards Max                      10.4822
exploration/Rewards Min                      -0.439921
exploration/Returns Mean                   5045.96
exploration/Returns Std                       0
exploration/Returns Max                    5045.96
exploration/Returns Min                    5045.96
exploration/Num Paths                         1
exploration/Average Returns                5045.96
evaluation_0/num steps total                  6.74879e+06
evaluation_0/num paths total              14904
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24992
evaluation_0/Rewards Std                      1.36384
evaluation_0/Rewards Max                     10.6492
evaluation_0/Rewards Min                     -0.535998
evaluation_0/Returns Mean                  5249.92
evaluation_0/Returns Std                     46.5086
evaluation_0/Returns Max                   5308.99
evaluation_0/Returns Min                   5160.55
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5249.92
time/epoch (s)                                0
time/total (s)                            16272.9
Epoch                                       854
---------------------------------------  ----------------
2022-11-16 15:17:15.693177 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 855 finished
---------------------------------------  ----------------
epoch                                       855
total_step                               860000
replay_pool/size                         860000
trainer/alpha                                 0.0616591
trainer/alpha_loss                           -0.0360581
trainer/entropy                              -5.98706
trainer/qf_loss                               6.8866
trainer/state_noise                           0.005
trainer/policy_loss                        -239.56
trainer/policy_loss_without_entropy         241.732
trainer/entropy_penalty                      -0.369157
trainer/entropy_percentage                   -0.00152713
trainer/Q1Pred Mean                         241.022
trainer/Q1Pred Std                           68.7477
trainer/Q1Pred Max                          320.861
trainer/Q1Pred Min                            5.00365
trainer/Q2Pred Mean                         241.494
trainer/Q2Pred Std                           68.8525
trainer/Q2Pred Max                          322.454
trainer/Q2Pred Min                           -0.184947
trainer/QTargetWithReg Mean                 240.746
trainer/QTargetWithReg Std                   68.5995
trainer/QTargetWithReg Max                  322.549
trainer/QTargetWithReg Min                    8.82423
trainer/PolicyLossWithoutReg Mean           241.732
trainer/PolicyLossWithoutReg Std             68.0417
trainer/PolicyLossWithoutReg Max            320.897
trainer/PolicyLossWithoutReg Min              7.75521
trainer/gradient_norm                       360.744
trainer/gradient_penalty                     -1.80372
trainer/gradient_percentage                  -0.00746164
exploration/num steps total              860000
exploration/num paths total                2020
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09297
exploration/Rewards Std                       1.34315
exploration/Rewards Max                      10.5119
exploration/Rewards Min                      -0.53311
exploration/Returns Mean                   5092.97
exploration/Returns Std                       0
exploration/Returns Max                    5092.97
exploration/Returns Min                    5092.97
exploration/Num Paths                         1
exploration/Average Returns                5092.97
evaluation_0/num steps total                  6.75679e+06
evaluation_0/num paths total              14912
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14349
evaluation_0/Rewards Std                      1.30623
evaluation_0/Rewards Max                     10.3003
evaluation_0/Rewards Min                     -0.44374
evaluation_0/Returns Mean                  5143.49
evaluation_0/Returns Std                     13.5307
evaluation_0/Returns Max                   5161.99
evaluation_0/Returns Min                   5122.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5143.49
time/epoch (s)                                0
time/total (s)                            16289.4
Epoch                                       855
---------------------------------------  ----------------
2022-11-16 15:17:31.504917 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 856 finished
---------------------------------------  ----------------
epoch                                       856
total_step                               861000
replay_pool/size                         861000
trainer/alpha                                 0.0623978
trainer/alpha_loss                           -0.136018
trainer/entropy                              -5.95097
trainer/qf_loss                               7.48085
trainer/state_noise                           0.005
trainer/policy_loss                        -232.949
trainer/policy_loss_without_entropy         235.104
trainer/entropy_penalty                      -0.371327
trainer/entropy_percentage                   -0.00157942
trainer/Q1Pred Mean                         233.679
trainer/Q1Pred Std                           75.9706
trainer/Q1Pred Max                          321.669
trainer/Q1Pred Min                            7.95301
trainer/Q2Pred Mean                         234.378
trainer/Q2Pred Std                           75.8624
trainer/Q2Pred Max                          322.778
trainer/Q2Pred Min                            9.30427
trainer/QTargetWithReg Mean                 234.558
trainer/QTargetWithReg Std                   76.3081
trainer/QTargetWithReg Max                  322.618
trainer/QTargetWithReg Min                    5.70152
trainer/PolicyLossWithoutReg Mean           235.104
trainer/PolicyLossWithoutReg Std             75.4973
trainer/PolicyLossWithoutReg Max            322.319
trainer/PolicyLossWithoutReg Min              9.16065
trainer/gradient_norm                       356.698
trainer/gradient_penalty                     -1.78349
trainer/gradient_percentage                  -0.00758597
exploration/num steps total              861000
exploration/num paths total                2021
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19945
exploration/Rewards Std                       1.33362
exploration/Rewards Max                      10.4162
exploration/Rewards Min                      -0.519217
exploration/Returns Mean                   5199.45
exploration/Returns Std                       0
exploration/Returns Max                    5199.45
exploration/Returns Min                    5199.45
exploration/Num Paths                         1
exploration/Average Returns                5199.45
evaluation_0/num steps total                  6.76479e+06
evaluation_0/num paths total              14920
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18972
evaluation_0/Rewards Std                      1.31574
evaluation_0/Rewards Max                     10.3441
evaluation_0/Rewards Min                     -0.428455
evaluation_0/Returns Mean                  5189.72
evaluation_0/Returns Std                     12.9605
evaluation_0/Returns Max                   5208.02
evaluation_0/Returns Min                   5166.84
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5189.72
time/epoch (s)                                0
time/total (s)                            16305.2
Epoch                                       856
---------------------------------------  ----------------
2022-11-16 15:17:48.022774 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 857 finished
---------------------------------------  ----------------
epoch                                       857
total_step                               862000
replay_pool/size                         862000
trainer/alpha                                 0.0612956
trainer/alpha_loss                           -0.567056
trainer/entropy                              -5.7969
trainer/qf_loss                               7.05266
trainer/state_noise                           0.005
trainer/policy_loss                        -232.945
trainer/policy_loss_without_entropy         235.113
trainer/entropy_penalty                      -0.355324
trainer/entropy_percentage                   -0.00151129
trainer/Q1Pred Mean                         234.527
trainer/Q1Pred Std                           75.7453
trainer/Q1Pred Max                          322.255
trainer/Q1Pred Min                           -4.37584
trainer/Q2Pred Mean                         234.275
trainer/Q2Pred Std                           75.8184
trainer/Q2Pred Max                          319.821
trainer/Q2Pred Min                           -5.97345
trainer/QTargetWithReg Mean                 234.664
trainer/QTargetWithReg Std                   76.0614
trainer/QTargetWithReg Max                  320.853
trainer/QTargetWithReg Min                   -0.143988
trainer/PolicyLossWithoutReg Mean           235.113
trainer/PolicyLossWithoutReg Std             74.607
trainer/PolicyLossWithoutReg Max            320.543
trainer/PolicyLossWithoutReg Min              8.15561
trainer/gradient_norm                       362.635
trainer/gradient_penalty                     -1.81317
trainer/gradient_percentage                  -0.00771193
exploration/num steps total              862000
exploration/num paths total                2022
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06799
exploration/Rewards Std                       1.27471
exploration/Rewards Max                      10.8179
exploration/Rewards Min                      -0.382374
exploration/Returns Mean                   5067.99
exploration/Returns Std                       0
exploration/Returns Max                    5067.99
exploration/Returns Min                    5067.99
exploration/Num Paths                         1
exploration/Average Returns                5067.99
evaluation_0/num steps total                  6.77279e+06
evaluation_0/num paths total              14928
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16265
evaluation_0/Rewards Std                      1.34678
evaluation_0/Rewards Max                     10.3348
evaluation_0/Rewards Min                     -0.500314
evaluation_0/Returns Mean                  5162.65
evaluation_0/Returns Std                     16.9188
evaluation_0/Returns Max                   5186.23
evaluation_0/Returns Min                   5140.69
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5162.65
time/epoch (s)                                0
time/total (s)                            16321.7
Epoch                                       857
---------------------------------------  ----------------
2022-11-16 15:18:03.768260 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 858 finished
---------------------------------------  ----------------
epoch                                       858
total_step                               863000
replay_pool/size                         863000
trainer/alpha                                 0.0618006
trainer/alpha_loss                            0.179706
trainer/entropy                              -6.06456
trainer/qf_loss                               7.32951
trainer/state_noise                           0.005
trainer/policy_loss                        -241.199
trainer/policy_loss_without_entropy         243.415
trainer/entropy_penalty                      -0.374793
trainer/entropy_percentage                   -0.00153973
trainer/Q1Pred Mean                         242.75
trainer/Q1Pred Std                           71.4046
trainer/Q1Pred Max                          324.971
trainer/Q1Pred Min                            2.16567
trainer/Q2Pred Mean                         242.584
trainer/Q2Pred Std                           71.5226
trainer/Q2Pred Max                          324.793
trainer/Q2Pred Min                            5.79586
trainer/QTargetWithReg Mean                 242.479
trainer/QTargetWithReg Std                   71.5116
trainer/QTargetWithReg Max                  324.663
trainer/QTargetWithReg Min                   -1.6825
trainer/PolicyLossWithoutReg Mean           243.415
trainer/PolicyLossWithoutReg Std             70.7792
trainer/PolicyLossWithoutReg Max            323.611
trainer/PolicyLossWithoutReg Min              7.48595
trainer/gradient_norm                       368.346
trainer/gradient_penalty                     -1.84173
trainer/gradient_percentage                  -0.00756621
exploration/num steps total              863000
exploration/num paths total                2023
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05034
exploration/Rewards Std                       1.30507
exploration/Rewards Max                      10.5153
exploration/Rewards Min                      -0.497915
exploration/Returns Mean                   5050.34
exploration/Returns Std                       0
exploration/Returns Max                    5050.34
exploration/Returns Min                    5050.34
exploration/Num Paths                         1
exploration/Average Returns                5050.34
evaluation_0/num steps total                  6.78079e+06
evaluation_0/num paths total              14936
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29943
evaluation_0/Rewards Std                      1.36671
evaluation_0/Rewards Max                     10.6763
evaluation_0/Rewards Min                     -0.472049
evaluation_0/Returns Mean                  5299.43
evaluation_0/Returns Std                     54.9429
evaluation_0/Returns Max                   5357.89
evaluation_0/Returns Min                   5170.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5299.43
time/epoch (s)                                0
time/total (s)                            16337.5
Epoch                                       858
---------------------------------------  ----------------
2022-11-16 15:18:20.192544 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 859 finished
---------------------------------------  ----------------
epoch                                       859
total_step                               864000
replay_pool/size                         864000
trainer/alpha                                 0.0610282
trainer/alpha_loss                            0.558437
trainer/entropy                              -6.1997
trainer/qf_loss                               7.05443
trainer/state_noise                           0.005
trainer/policy_loss                        -235.638
trainer/policy_loss_without_entropy         237.799
trainer/entropy_penalty                      -0.378357
trainer/entropy_percentage                   -0.00159108
trainer/Q1Pred Mean                         236.926
trainer/Q1Pred Std                           76.608
trainer/Q1Pred Max                          326.083
trainer/Q1Pred Min                            4.85152
trainer/Q2Pred Mean                         236.835
trainer/Q2Pred Std                           76.728
trainer/Q2Pred Max                          326.928
trainer/Q2Pred Min                            6.14013
trainer/QTargetWithReg Mean                 237.509
trainer/QTargetWithReg Std                   76.7683
trainer/QTargetWithReg Max                  327.279
trainer/QTargetWithReg Min                    3.55579
trainer/PolicyLossWithoutReg Mean           237.799
trainer/PolicyLossWithoutReg Std             76.079
trainer/PolicyLossWithoutReg Max            326.561
trainer/PolicyLossWithoutReg Min              5.41429
trainer/gradient_norm                       356.471
trainer/gradient_penalty                     -1.78235
trainer/gradient_percentage                  -0.00749522
exploration/num steps total              864000
exploration/num paths total                2024
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12552
exploration/Rewards Std                       1.35874
exploration/Rewards Max                      10.672
exploration/Rewards Min                      -0.438267
exploration/Returns Mean                   5125.52
exploration/Returns Std                       0
exploration/Returns Max                    5125.52
exploration/Returns Min                    5125.52
exploration/Num Paths                         1
exploration/Average Returns                5125.52
evaluation_0/num steps total                  6.78879e+06
evaluation_0/num paths total              14944
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.00885
evaluation_0/Rewards Std                      1.30678
evaluation_0/Rewards Max                     10.2341
evaluation_0/Rewards Min                     -0.495581
evaluation_0/Returns Mean                  5008.85
evaluation_0/Returns Std                     22.7401
evaluation_0/Returns Max                   5047.76
evaluation_0/Returns Min                   4980.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5008.85
time/epoch (s)                                0
time/total (s)                            16353.9
Epoch                                       859
---------------------------------------  ----------------
2022-11-16 15:18:35.990366 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 860 finished
---------------------------------------  ----------------
epoch                                       860
total_step                               865000
replay_pool/size                         865000
trainer/alpha                                 0.0618444
trainer/alpha_loss                            1.79734
trainer/entropy                              -6.64572
trainer/qf_loss                              10.6146
trainer/state_noise                           0.005
trainer/policy_loss                        -238.94
trainer/policy_loss_without_entropy         241.18
trainer/entropy_penalty                      -0.411001
trainer/entropy_percentage                   -0.00170412
trainer/Q1Pred Mean                         240.501
trainer/Q1Pred Std                           74.051
trainer/Q1Pred Max                          327.424
trainer/Q1Pred Min                           -6.99215
trainer/Q2Pred Mean                         240.424
trainer/Q2Pred Std                           73.8325
trainer/Q2Pred Max                          325.877
trainer/Q2Pred Min                           -1.65587
trainer/QTargetWithReg Mean                 239.666
trainer/QTargetWithReg Std                   74.1058
trainer/QTargetWithReg Max                  322.013
trainer/QTargetWithReg Min                   -0.266743
trainer/PolicyLossWithoutReg Mean           241.18
trainer/PolicyLossWithoutReg Std             73.1827
trainer/PolicyLossWithoutReg Max            324.229
trainer/PolicyLossWithoutReg Min              5.73303
trainer/gradient_norm                       365.783
trainer/gradient_penalty                     -1.82892
trainer/gradient_percentage                  -0.00758319
exploration/num steps total              865000
exploration/num paths total                2025
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13675
exploration/Rewards Std                       1.35199
exploration/Rewards Max                      10.5916
exploration/Rewards Min                      -0.474291
exploration/Returns Mean                   5136.75
exploration/Returns Std                       0
exploration/Returns Max                    5136.75
exploration/Returns Min                    5136.75
exploration/Num Paths                         1
exploration/Average Returns                5136.75
evaluation_0/num steps total                  6.79679e+06
evaluation_0/num paths total              14952
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.33901
evaluation_0/Rewards Std                      1.30939
evaluation_0/Rewards Max                     10.4337
evaluation_0/Rewards Min                     -0.618491
evaluation_0/Returns Mean                  5339.01
evaluation_0/Returns Std                     30.4838
evaluation_0/Returns Max                   5370.71
evaluation_0/Returns Min                   5290.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5339.01
time/epoch (s)                                0
time/total (s)                            16369.7
Epoch                                       860
---------------------------------------  ----------------
2022-11-16 15:18:52.297430 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 861 finished
---------------------------------------  ----------------
epoch                                       861
total_step                               866000
replay_pool/size                         866000
trainer/alpha                                 0.0618889
trainer/alpha_loss                            0.294535
trainer/entropy                              -6.10585
trainer/qf_loss                               7.34931
trainer/state_noise                           0.005
trainer/policy_loss                        -236.148
trainer/policy_loss_without_entropy         238.361
trainer/entropy_penalty                      -0.377884
trainer/entropy_percentage                   -0.00158535
trainer/Q1Pred Mean                         237.391
trainer/Q1Pred Std                           71.3038
trainer/Q1Pred Max                          316.469
trainer/Q1Pred Min                           -8.26132
trainer/Q2Pred Mean                         237.846
trainer/Q2Pred Std                           71.211
trainer/Q2Pred Max                          315.775
trainer/Q2Pred Min                           -9.57081
trainer/QTargetWithReg Mean                 238.419
trainer/QTargetWithReg Std                   71.4249
trainer/QTargetWithReg Max                  317.373
trainer/QTargetWithReg Min                    0.403919
trainer/PolicyLossWithoutReg Mean           238.361
trainer/PolicyLossWithoutReg Std             70.3679
trainer/PolicyLossWithoutReg Max            316.198
trainer/PolicyLossWithoutReg Min             -5.67042
trainer/gradient_norm                       366.947
trainer/gradient_penalty                     -1.83473
trainer/gradient_percentage                  -0.00769729
exploration/num steps total              866000
exploration/num paths total                2026
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14273
exploration/Rewards Std                       1.31231
exploration/Rewards Max                      10.322
exploration/Rewards Min                      -0.522175
exploration/Returns Mean                   5142.73
exploration/Returns Std                       0
exploration/Returns Max                    5142.73
exploration/Returns Min                    5142.73
exploration/Num Paths                         1
exploration/Average Returns                5142.73
evaluation_0/num steps total                  6.80479e+06
evaluation_0/num paths total              14960
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19446
evaluation_0/Rewards Std                      1.29203
evaluation_0/Rewards Max                     10.2276
evaluation_0/Rewards Min                     -0.514487
evaluation_0/Returns Mean                  5194.46
evaluation_0/Returns Std                      9.91587
evaluation_0/Returns Max                   5210.24
evaluation_0/Returns Min                   5179.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5194.46
time/epoch (s)                                0
time/total (s)                            16386
Epoch                                       861
---------------------------------------  ----------------
2022-11-16 15:19:08.223169 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 862 finished
---------------------------------------  ----------------
epoch                                       862
total_step                               867000
replay_pool/size                         867000
trainer/alpha                                 0.0627742
trainer/alpha_loss                           -0.281041
trainer/entropy                              -5.89847
trainer/qf_loss                               6.44707
trainer/state_noise                           0.005
trainer/policy_loss                        -229.695
trainer/policy_loss_without_entropy         231.927
trainer/entropy_penalty                      -0.370272
trainer/entropy_percentage                   -0.0015965
trainer/Q1Pred Mean                         230.695
trainer/Q1Pred Std                           76.7562
trainer/Q1Pred Max                          321.977
trainer/Q1Pred Min                            4.49747
trainer/Q2Pred Mean                         231.029
trainer/Q2Pred Std                           76.4131
trainer/Q2Pred Max                          321.75
trainer/Q2Pred Min                            6.7855
trainer/QTargetWithReg Mean                 231.452
trainer/QTargetWithReg Std                   76.4812
trainer/QTargetWithReg Max                  321.637
trainer/QTargetWithReg Min                    4.78442
trainer/PolicyLossWithoutReg Mean           231.927
trainer/PolicyLossWithoutReg Std             76.0516
trainer/PolicyLossWithoutReg Max            320.983
trainer/PolicyLossWithoutReg Min              5.26752
trainer/gradient_norm                       372.406
trainer/gradient_penalty                     -1.86203
trainer/gradient_percentage                  -0.00802851
exploration/num steps total              867000
exploration/num paths total                2027
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06208
exploration/Rewards Std                       1.32522
exploration/Rewards Max                      10.2977
exploration/Rewards Min                      -0.695036
exploration/Returns Mean                   5062.08
exploration/Returns Std                       0
exploration/Returns Max                    5062.08
exploration/Returns Min                    5062.08
exploration/Num Paths                         1
exploration/Average Returns                5062.08
evaluation_0/num steps total                  6.81279e+06
evaluation_0/num paths total              14968
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19598
evaluation_0/Rewards Std                      1.31012
evaluation_0/Rewards Max                     10.3997
evaluation_0/Rewards Min                     -0.457168
evaluation_0/Returns Mean                  5195.98
evaluation_0/Returns Std                     24.3625
evaluation_0/Returns Max                   5233.87
evaluation_0/Returns Min                   5151.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5195.98
time/epoch (s)                                0
time/total (s)                            16401.9
Epoch                                       862
---------------------------------------  ----------------
2022-11-16 15:19:24.483623 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 863 finished
---------------------------------------  ----------------
epoch                                       863
total_step                               868000
replay_pool/size                         868000
trainer/alpha                                 0.0614794
trainer/alpha_loss                           -1.50096
trainer/entropy                              -5.46178
trainer/qf_loss                               5.4598
trainer/state_noise                           0.005
trainer/policy_loss                        -240.644
trainer/policy_loss_without_entropy         242.724
trainer/entropy_penalty                      -0.335787
trainer/entropy_percentage                   -0.00138341
trainer/Q1Pred Mean                         242.424
trainer/Q1Pred Std                           75.307
trainer/Q1Pred Max                          326.907
trainer/Q1Pred Min                          -10.7161
trainer/Q2Pred Mean                         242.476
trainer/Q2Pred Std                           75.6399
trainer/Q2Pred Max                          326.664
trainer/Q2Pred Min                           -7.92317
trainer/QTargetWithReg Mean                 242.234
trainer/QTargetWithReg Std                   75.2732
trainer/QTargetWithReg Max                  326.128
trainer/QTargetWithReg Min                    0.513956
trainer/PolicyLossWithoutReg Mean           242.724
trainer/PolicyLossWithoutReg Std             74.9235
trainer/PolicyLossWithoutReg Max            326.264
trainer/PolicyLossWithoutReg Min             -9.8504
trainer/gradient_norm                       348.767
trainer/gradient_penalty                     -1.74383
trainer/gradient_percentage                  -0.00718443
exploration/num steps total              868000
exploration/num paths total                2028
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.25424
exploration/Rewards Std                       1.33196
exploration/Rewards Max                      10.3619
exploration/Rewards Min                      -0.405699
exploration/Returns Mean                   5254.24
exploration/Returns Std                       0
exploration/Returns Max                    5254.24
exploration/Returns Min                    5254.24
exploration/Num Paths                         1
exploration/Average Returns                5254.24
evaluation_0/num steps total                  6.82079e+06
evaluation_0/num paths total              14976
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29677
evaluation_0/Rewards Std                      1.35071
evaluation_0/Rewards Max                     11.0933
evaluation_0/Rewards Min                     -0.454537
evaluation_0/Returns Mean                  5296.77
evaluation_0/Returns Std                     23.4117
evaluation_0/Returns Max                   5348.57
evaluation_0/Returns Min                   5272.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5296.77
time/epoch (s)                                0
time/total (s)                            16418.2
Epoch                                       863
---------------------------------------  ----------------
2022-11-16 15:19:40.473604 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 864 finished
---------------------------------------  ----------------
epoch                                       864
total_step                               869000
replay_pool/size                         869000
trainer/alpha                                 0.0620835
trainer/alpha_loss                            0.505423
trainer/entropy                              -6.18185
trainer/qf_loss                               6.03573
trainer/state_noise                           0.005
trainer/policy_loss                        -235.646
trainer/policy_loss_without_entropy         237.875
trainer/entropy_penalty                      -0.383791
trainer/entropy_percentage                   -0.00161341
trainer/Q1Pred Mean                         237.624
trainer/Q1Pred Std                           74.3258
trainer/Q1Pred Max                          320.241
trainer/Q1Pred Min                            8.97289
trainer/Q2Pred Mean                         237.442
trainer/Q2Pred Std                           74.4925
trainer/Q2Pred Max                          319.677
trainer/Q2Pred Min                           10.0916
trainer/QTargetWithReg Mean                 237.769
trainer/QTargetWithReg Std                   74.0618
trainer/QTargetWithReg Max                  320.054
trainer/QTargetWithReg Min                   11.3083
trainer/PolicyLossWithoutReg Mean           237.875
trainer/PolicyLossWithoutReg Std             73.6191
trainer/PolicyLossWithoutReg Max            319.851
trainer/PolicyLossWithoutReg Min             11.284
trainer/gradient_norm                       369.024
trainer/gradient_penalty                     -1.84512
trainer/gradient_percentage                  -0.00775668
exploration/num steps total              869000
exploration/num paths total                2029
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.28371
exploration/Rewards Std                       1.34351
exploration/Rewards Max                      10.6091
exploration/Rewards Min                      -0.624258
exploration/Returns Mean                   5283.71
exploration/Returns Std                       0
exploration/Returns Max                    5283.71
exploration/Returns Min                    5283.71
exploration/Num Paths                         1
exploration/Average Returns                5283.71
evaluation_0/num steps total                  6.82879e+06
evaluation_0/num paths total              14984
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24824
evaluation_0/Rewards Std                      1.31757
evaluation_0/Rewards Max                     10.5262
evaluation_0/Rewards Min                     -0.523943
evaluation_0/Returns Mean                  5248.24
evaluation_0/Returns Std                     20.5094
evaluation_0/Returns Max                   5270.89
evaluation_0/Returns Min                   5206.77
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5248.24
time/epoch (s)                                0
time/total (s)                            16434.2
Epoch                                       864
---------------------------------------  ----------------
2022-11-16 15:19:56.587910 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 865 finished
---------------------------------------  ----------------
epoch                                       865
total_step                               870000
replay_pool/size                         870000
trainer/alpha                                 0.0603772
trainer/alpha_loss                            0.399828
trainer/entropy                              -6.14243
trainer/qf_loss                               6.95791
trainer/state_noise                           0.005
trainer/policy_loss                        -229.89
trainer/policy_loss_without_entropy         232.087
trainer/entropy_penalty                      -0.370863
trainer/entropy_percentage                   -0.00159795
trainer/Q1Pred Mean                         231.981
trainer/Q1Pred Std                           79.5252
trainer/Q1Pred Max                          321.175
trainer/Q1Pred Min                           -0.601413
trainer/Q2Pred Mean                         231.402
trainer/Q2Pred Std                           79.9926
trainer/Q2Pred Max                          319.023
trainer/Q2Pred Min                           -8.19834
trainer/QTargetWithReg Mean                 231.648
trainer/QTargetWithReg Std                   80.0501
trainer/QTargetWithReg Max                  318.985
trainer/QTargetWithReg Min                  -15.1914
trainer/PolicyLossWithoutReg Mean           232.087
trainer/PolicyLossWithoutReg Std             78.4486
trainer/PolicyLossWithoutReg Max            318.535
trainer/PolicyLossWithoutReg Min             14.039
trainer/gradient_norm                       365.221
trainer/gradient_penalty                     -1.8261
trainer/gradient_percentage                  -0.0078682
exploration/num steps total              870000
exploration/num paths total                2030
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09487
exploration/Rewards Std                       1.28525
exploration/Rewards Max                      10.6452
exploration/Rewards Min                      -0.506379
exploration/Returns Mean                   5094.87
exploration/Returns Std                       0
exploration/Returns Max                    5094.87
exploration/Returns Min                    5094.87
exploration/Num Paths                         1
exploration/Average Returns                5094.87
evaluation_0/num steps total                  6.83679e+06
evaluation_0/num paths total              14992
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24027
evaluation_0/Rewards Std                      1.29692
evaluation_0/Rewards Max                     10.3304
evaluation_0/Rewards Min                     -0.50621
evaluation_0/Returns Mean                  5240.27
evaluation_0/Returns Std                     21.5408
evaluation_0/Returns Max                   5267.71
evaluation_0/Returns Min                   5206.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5240.27
time/epoch (s)                                0
time/total (s)                            16450.3
Epoch                                       865
---------------------------------------  ----------------
2022-11-16 15:20:12.740658 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 866 finished
---------------------------------------  ----------------
epoch                                       866
total_step                               871000
replay_pool/size                         871000
trainer/alpha                                 0.0598713
trainer/alpha_loss                            0.324445
trainer/entropy                              -6.11523
trainer/qf_loss                               6.96983
trainer/state_noise                           0.005
trainer/policy_loss                        -237
trainer/policy_loss_without_entropy         239.198
trainer/entropy_penalty                      -0.366126
trainer/entropy_percentage                   -0.00153064
trainer/Q1Pred Mean                         238.252
trainer/Q1Pred Std                           73.4175
trainer/Q1Pred Max                          322.588
trainer/Q1Pred Min                           16.1771
trainer/Q2Pred Mean                         238.072
trainer/Q2Pred Std                           73.3128
trainer/Q2Pred Max                          324.57
trainer/Q2Pred Min                           17.791
trainer/QTargetWithReg Mean                 238.514
trainer/QTargetWithReg Std                   73.7776
trainer/QTargetWithReg Max                  323.973
trainer/QTargetWithReg Min                   16.8723
trainer/PolicyLossWithoutReg Mean           239.198
trainer/PolicyLossWithoutReg Std             72.5461
trainer/PolicyLossWithoutReg Max            322.403
trainer/PolicyLossWithoutReg Min             17.2538
trainer/gradient_norm                       366.56
trainer/gradient_penalty                     -1.8328
trainer/gradient_percentage                  -0.00766225
exploration/num steps total              871000
exploration/num paths total                2031
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.22725
exploration/Rewards Std                       1.28419
exploration/Rewards Max                      10.2347
exploration/Rewards Min                      -0.587846
exploration/Returns Mean                   5227.25
exploration/Returns Std                       0
exploration/Returns Max                    5227.25
exploration/Returns Min                    5227.25
exploration/Num Paths                         1
exploration/Average Returns                5227.25
evaluation_0/num steps total                  6.84479e+06
evaluation_0/num paths total              15000
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.21637
evaluation_0/Rewards Std                      1.32068
evaluation_0/Rewards Max                     10.367
evaluation_0/Rewards Min                     -0.556099
evaluation_0/Returns Mean                  5216.37
evaluation_0/Returns Std                     34.9196
evaluation_0/Returns Max                   5259.59
evaluation_0/Returns Min                   5151.43
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5216.37
time/epoch (s)                                0
time/total (s)                            16466.4
Epoch                                       866
---------------------------------------  ----------------
2022-11-16 15:20:28.611014 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 867 finished
---------------------------------------  ----------------
epoch                                       867
total_step                               872000
replay_pool/size                         872000
trainer/alpha                                 0.0594265
trainer/alpha_loss                            0.0520187
trainer/entropy                              -6.01842
trainer/qf_loss                              12.6408
trainer/state_noise                           0.005
trainer/policy_loss                        -230.397
trainer/policy_loss_without_entropy         232.581
trainer/entropy_penalty                      -0.357654
trainer/entropy_percentage                   -0.00153776
trainer/Q1Pred Mean                         231.955
trainer/Q1Pred Std                           77.233
trainer/Q1Pred Max                          321.18
trainer/Q1Pred Min                          -11.2548
trainer/Q2Pred Mean                         232.096
trainer/Q2Pred Std                           77.4319
trainer/Q2Pred Max                          321.12
trainer/Q2Pred Min                          -27.7405
trainer/QTargetWithReg Mean                 231.08
trainer/QTargetWithReg Std                   77.8978
trainer/QTargetWithReg Max                  321.302
trainer/QTargetWithReg Min                   -0.0776008
trainer/PolicyLossWithoutReg Mean           232.581
trainer/PolicyLossWithoutReg Std             76.8664
trainer/PolicyLossWithoutReg Max            322.141
trainer/PolicyLossWithoutReg Min            -17.1087
trainer/gradient_norm                       365.274
trainer/gradient_penalty                     -1.82637
trainer/gradient_percentage                  -0.00785263
exploration/num steps total              872000
exploration/num paths total                2032
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.053
exploration/Rewards Std                       1.31274
exploration/Rewards Max                      10.1795
exploration/Rewards Min                      -0.588118
exploration/Returns Mean                   5053
exploration/Returns Std                       0
exploration/Returns Max                    5053
exploration/Returns Min                    5053
exploration/Num Paths                         1
exploration/Average Returns                5053
evaluation_0/num steps total                  6.85279e+06
evaluation_0/num paths total              15008
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26993
evaluation_0/Rewards Std                      1.30791
evaluation_0/Rewards Max                     10.4107
evaluation_0/Rewards Min                     -0.49846
evaluation_0/Returns Mean                  5269.93
evaluation_0/Returns Std                     27.8038
evaluation_0/Returns Max                   5330.38
evaluation_0/Returns Min                   5239.15
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5269.93
time/epoch (s)                                0
time/total (s)                            16482.3
Epoch                                       867
---------------------------------------  ----------------
2022-11-16 15:20:45.056868 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 868 finished
---------------------------------------  ----------------
epoch                                       868
total_step                               873000
replay_pool/size                         873000
trainer/alpha                                 0.0617552
trainer/alpha_loss                            1.22508
trainer/entropy                              -6.43993
trainer/qf_loss                               5.49604
trainer/state_noise                           0.005
trainer/policy_loss                        -234.419
trainer/policy_loss_without_entropy         236.732
trainer/entropy_penalty                      -0.397699
trainer/entropy_percentage                   -0.00167995
trainer/Q1Pred Mean                         236.994
trainer/Q1Pred Std                           75.5597
trainer/Q1Pred Max                          321.522
trainer/Q1Pred Min                          -31.4069
trainer/Q2Pred Mean                         236.358
trainer/Q2Pred Std                           75.6709
trainer/Q2Pred Max                          319.423
trainer/Q2Pred Min                          -31.7243
trainer/QTargetWithReg Mean                 236.37
trainer/QTargetWithReg Std                   75.6235
trainer/QTargetWithReg Max                  320.641
trainer/QTargetWithReg Min                  -35.1588
trainer/PolicyLossWithoutReg Mean           236.732
trainer/PolicyLossWithoutReg Std             74.9034
trainer/PolicyLossWithoutReg Max            319.37
trainer/PolicyLossWithoutReg Min            -31.995
trainer/gradient_norm                       383.177
trainer/gradient_penalty                     -1.91589
trainer/gradient_percentage                  -0.00809306
exploration/num steps total              873000
exploration/num paths total                2033
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08518
exploration/Rewards Std                       1.34567
exploration/Rewards Max                      10.5757
exploration/Rewards Min                      -0.436351
exploration/Returns Mean                   5085.18
exploration/Returns Std                       0
exploration/Returns Max                    5085.18
exploration/Returns Min                    5085.18
exploration/Num Paths                         1
exploration/Average Returns                5085.18
evaluation_0/num steps total                  6.86079e+06
evaluation_0/num paths total              15016
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24864
evaluation_0/Rewards Std                      1.32152
evaluation_0/Rewards Max                     10.284
evaluation_0/Rewards Min                     -0.586105
evaluation_0/Returns Mean                  5248.64
evaluation_0/Returns Std                     15.0753
evaluation_0/Returns Max                   5270.29
evaluation_0/Returns Min                   5215.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5248.64
time/epoch (s)                                0
time/total (s)                            16498.7
Epoch                                       868
---------------------------------------  ----------------
2022-11-16 15:21:00.953071 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 869 finished
---------------------------------------  ----------------
epoch                                       869
total_step                               874000
replay_pool/size                         874000
trainer/alpha                                 0.0627795
trainer/alpha_loss                            0.00594469
trainer/entropy                              -6.00215
trainer/qf_loss                              10.1572
trainer/state_noise                           0.005
trainer/policy_loss                        -232.591
trainer/policy_loss_without_entropy         234.767
trainer/entropy_penalty                      -0.376812
trainer/entropy_percentage                   -0.00160504
trainer/Q1Pred Mean                         233.911
trainer/Q1Pred Std                           77.5795
trainer/Q1Pred Max                          322.714
trainer/Q1Pred Min                            2.58684
trainer/Q2Pred Mean                         233.84
trainer/Q2Pred Std                           77.6964
trainer/Q2Pred Max                          322.919
trainer/Q2Pred Min                            5.28004
trainer/QTargetWithReg Mean                 234.32
trainer/QTargetWithReg Std                   78.2846
trainer/QTargetWithReg Max                  324.495
trainer/QTargetWithReg Min                    3.34648
trainer/PolicyLossWithoutReg Mean           234.767
trainer/PolicyLossWithoutReg Std             77.3255
trainer/PolicyLossWithoutReg Max            323.767
trainer/PolicyLossWithoutReg Min              6.19733
trainer/gradient_norm                       359.825
trainer/gradient_penalty                     -1.79913
trainer/gradient_percentage                  -0.00766346
exploration/num steps total              874000
exploration/num paths total                2034
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19305
exploration/Rewards Std                       1.32866
exploration/Rewards Max                      10.55
exploration/Rewards Min                      -0.424236
exploration/Returns Mean                   5193.05
exploration/Returns Std                       0
exploration/Returns Max                    5193.05
exploration/Returns Min                    5193.05
exploration/Num Paths                         1
exploration/Average Returns                5193.05
evaluation_0/num steps total                  6.86879e+06
evaluation_0/num paths total              15024
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.287
evaluation_0/Rewards Std                      1.31587
evaluation_0/Rewards Max                     10.3326
evaluation_0/Rewards Min                     -0.526927
evaluation_0/Returns Mean                  5287
evaluation_0/Returns Std                     19.8199
evaluation_0/Returns Max                   5316.46
evaluation_0/Returns Min                   5257.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5287
time/epoch (s)                                0
time/total (s)                            16514.6
Epoch                                       869
---------------------------------------  ----------------
2022-11-16 15:21:17.286094 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 870 finished
---------------------------------------  ----------------
epoch                                       870
total_step                               875000
replay_pool/size                         875000
trainer/alpha                                 0.0607895
trainer/alpha_loss                            0.433147
trainer/entropy                              -6.15468
trainer/qf_loss                             194.11
trainer/state_noise                           0.005
trainer/policy_loss                        -237.009
trainer/policy_loss_without_entropy         239.304
trainer/entropy_penalty                      -0.37414
trainer/entropy_percentage                   -0.00156345
trainer/Q1Pred Mean                         239.291
trainer/Q1Pred Std                           73.8862
trainer/Q1Pred Max                          321.292
trainer/Q1Pred Min                            7.73745
trainer/Q2Pred Mean                         239.269
trainer/Q2Pred Std                           74.034
trainer/Q2Pred Max                          321.609
trainer/Q2Pred Min                            5.5329
trainer/QTargetWithReg Mean                 239.435
trainer/QTargetWithReg Std                   75.3876
trainer/QTargetWithReg Max                  323.345
trainer/QTargetWithReg Min                    4.97588
trainer/PolicyLossWithoutReg Mean           239.304
trainer/PolicyLossWithoutReg Std             73.6317
trainer/PolicyLossWithoutReg Max            319.112
trainer/PolicyLossWithoutReg Min              7.96953
trainer/gradient_norm                       384.211
trainer/gradient_penalty                     -1.92105
trainer/gradient_percentage                  -0.00802766
exploration/num steps total              875000
exploration/num paths total                2035
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.1305
exploration/Rewards Std                       1.31866
exploration/Rewards Max                      10.1658
exploration/Rewards Min                      -0.47219
exploration/Returns Mean                   5130.5
exploration/Returns Std                       0
exploration/Returns Max                    5130.5
exploration/Returns Min                    5130.5
exploration/Num Paths                         1
exploration/Average Returns                5130.5
evaluation_0/num steps total                  6.87679e+06
evaluation_0/num paths total              15032
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15747
evaluation_0/Rewards Std                      1.27894
evaluation_0/Rewards Max                     10.2103
evaluation_0/Rewards Min                     -0.513464
evaluation_0/Returns Mean                  5157.47
evaluation_0/Returns Std                     21.3763
evaluation_0/Returns Max                   5200.84
evaluation_0/Returns Min                   5129.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5157.47
time/epoch (s)                                0
time/total (s)                            16531
Epoch                                       870
---------------------------------------  ----------------
2022-11-16 15:21:33.294429 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 871 finished
---------------------------------------  ----------------
epoch                                       871
total_step                               876000
replay_pool/size                         876000
trainer/alpha                                 0.0616886
trainer/alpha_loss                            0.967094
trainer/entropy                              -6.34717
trainer/qf_loss                               7.87545
trainer/state_noise                           0.005
trainer/policy_loss                        -229.252
trainer/policy_loss_without_entropy         231.49
trainer/entropy_penalty                      -0.391548
trainer/entropy_percentage                   -0.00169142
trainer/Q1Pred Mean                         230.687
trainer/Q1Pred Std                           71.6417
trainer/Q1Pred Max                          315.185
trainer/Q1Pred Min                           10.9803
trainer/Q2Pred Mean                         230.801
trainer/Q2Pred Std                           71.7073
trainer/Q2Pred Max                          316.408
trainer/Q2Pred Min                            9.68803
trainer/QTargetWithReg Mean                 231.055
trainer/QTargetWithReg Std                   71.953
trainer/QTargetWithReg Max                  317.963
trainer/QTargetWithReg Min                    8.68577
trainer/PolicyLossWithoutReg Mean           231.49
trainer/PolicyLossWithoutReg Std             71.0328
trainer/PolicyLossWithoutReg Max            316.071
trainer/PolicyLossWithoutReg Min              9.56631
trainer/gradient_norm                       369.336
trainer/gradient_penalty                     -1.84668
trainer/gradient_percentage                  -0.00797735
exploration/num steps total              876000
exploration/num paths total                2036
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12622
exploration/Rewards Std                       1.28733
exploration/Rewards Max                      10.4068
exploration/Rewards Min                      -0.566558
exploration/Returns Mean                   5126.22
exploration/Returns Std                       0
exploration/Returns Max                    5126.22
exploration/Returns Min                    5126.22
exploration/Num Paths                         1
exploration/Average Returns                5126.22
evaluation_0/num steps total                  6.88479e+06
evaluation_0/num paths total              15040
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.31911
evaluation_0/Rewards Std                      1.31746
evaluation_0/Rewards Max                     10.5676
evaluation_0/Rewards Min                     -0.488375
evaluation_0/Returns Mean                  5319.11
evaluation_0/Returns Std                      9.97644
evaluation_0/Returns Max                   5333.62
evaluation_0/Returns Min                   5299.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5319.11
time/epoch (s)                                0
time/total (s)                            16547
Epoch                                       871
---------------------------------------  ----------------
2022-11-16 15:21:49.435135 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 872 finished
---------------------------------------  ----------------
epoch                                       872
total_step                               877000
replay_pool/size                         877000
trainer/alpha                                 0.0626552
trainer/alpha_loss                            0.13815
trainer/entropy                              -6.04987
trainer/qf_loss                               6.88106
trainer/state_noise                           0.005
trainer/policy_loss                        -231.681
trainer/policy_loss_without_entropy         233.931
trainer/entropy_penalty                      -0.379056
trainer/entropy_percentage                   -0.00162037
trainer/Q1Pred Mean                         233.519
trainer/Q1Pred Std                           77.1656
trainer/Q1Pred Max                          322.556
trainer/Q1Pred Min                          -21.2046
trainer/Q2Pred Mean                         233.472
trainer/Q2Pred Std                           76.9944
trainer/Q2Pred Max                          321.137
trainer/Q2Pred Min                          -18.2529
trainer/QTargetWithReg Mean                 233.788
trainer/QTargetWithReg Std                   77.0412
trainer/QTargetWithReg Max                  322.863
trainer/QTargetWithReg Min                  -16.369
trainer/PolicyLossWithoutReg Mean           233.931
trainer/PolicyLossWithoutReg Std             76.2129
trainer/PolicyLossWithoutReg Max            320.354
trainer/PolicyLossWithoutReg Min            -13.6323
trainer/gradient_norm                       374.289
trainer/gradient_penalty                     -1.87144
trainer/gradient_percentage                  -0.00799998
exploration/num steps total              877000
exploration/num paths total                2037
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17373
exploration/Rewards Std                       1.31366
exploration/Rewards Max                      10.1322
exploration/Rewards Min                      -0.613339
exploration/Returns Mean                   5173.73
exploration/Returns Std                       0
exploration/Returns Max                    5173.73
exploration/Returns Min                    5173.73
exploration/Num Paths                         1
exploration/Average Returns                5173.73
evaluation_0/num steps total                  6.89279e+06
evaluation_0/num paths total              15048
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1818
evaluation_0/Rewards Std                      1.31219
evaluation_0/Rewards Max                     10.2784
evaluation_0/Rewards Min                     -0.585763
evaluation_0/Returns Mean                  5181.8
evaluation_0/Returns Std                     18.8281
evaluation_0/Returns Max                   5218.52
evaluation_0/Returns Min                   5157.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5181.8
time/epoch (s)                                0
time/total (s)                            16563.1
Epoch                                       872
---------------------------------------  ----------------
2022-11-16 15:22:05.529004 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 873 finished
---------------------------------------  ----------------
epoch                                       873
total_step                               878000
replay_pool/size                         878000
trainer/alpha                                 0.0606744
trainer/alpha_loss                           -0.0400451
trainer/entropy                              -5.98571
trainer/qf_loss                               5.13134
trainer/state_noise                           0.005
trainer/policy_loss                        -222.473
trainer/policy_loss_without_entropy         224.623
trainer/entropy_penalty                      -0.363179
trainer/entropy_percentage                   -0.00161684
trainer/Q1Pred Mean                         224.203
trainer/Q1Pred Std                           79.6581
trainer/Q1Pred Max                          318.453
trainer/Q1Pred Min                           10.5271
trainer/Q2Pred Mean                         224.288
trainer/Q2Pred Std                           79.3866
trainer/Q2Pred Max                          320.011
trainer/Q2Pred Min                            9.15892
trainer/QTargetWithReg Mean                 224.322
trainer/QTargetWithReg Std                   79.2373
trainer/QTargetWithReg Max                  319.606
trainer/QTargetWithReg Min                   14.3679
trainer/PolicyLossWithoutReg Mean           224.623
trainer/PolicyLossWithoutReg Std             78.5799
trainer/PolicyLossWithoutReg Max            318.479
trainer/PolicyLossWithoutReg Min              8.67155
trainer/gradient_norm                       357.312
trainer/gradient_penalty                     -1.78656
trainer/gradient_percentage                  -0.00795361
exploration/num steps total              878000
exploration/num paths total                2038
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.22693
exploration/Rewards Std                       1.31047
exploration/Rewards Max                      10.5241
exploration/Rewards Min                      -0.565708
exploration/Returns Mean                   5226.93
exploration/Returns Std                       0
exploration/Returns Max                    5226.93
exploration/Returns Min                    5226.93
exploration/Num Paths                         1
exploration/Average Returns                5226.93
evaluation_0/num steps total                  6.90079e+06
evaluation_0/num paths total              15056
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25074
evaluation_0/Rewards Std                      1.29985
evaluation_0/Rewards Max                     10.2885
evaluation_0/Rewards Min                     -0.445587
evaluation_0/Returns Mean                  5250.74
evaluation_0/Returns Std                     25.7685
evaluation_0/Returns Max                   5293.54
evaluation_0/Returns Min                   5212.3
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5250.74
time/epoch (s)                                0
time/total (s)                            16579.2
Epoch                                       873
---------------------------------------  ----------------
2022-11-16 15:22:21.358017 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 874 finished
---------------------------------------  ----------------
epoch                                       874
total_step                               879000
replay_pool/size                         879000
trainer/alpha                                 0.0599663
trainer/alpha_loss                           -0.99225
trainer/entropy                              -5.6474
trainer/qf_loss                               6.59838
trainer/state_noise                           0.005
trainer/policy_loss                        -231.429
trainer/policy_loss_without_entropy         233.543
trainer/entropy_penalty                      -0.338654
trainer/entropy_percentage                   -0.00145007
trainer/Q1Pred Mean                         232.776
trainer/Q1Pred Std                           78.2615
trainer/Q1Pred Max                          316.908
trainer/Q1Pred Min                            3.7971
trainer/Q2Pred Mean                         232.25
trainer/Q2Pred Std                           78.3055
trainer/Q2Pred Max                          317.172
trainer/Q2Pred Min                            5.25152
trainer/QTargetWithReg Mean                 233.558
trainer/QTargetWithReg Std                   78.3614
trainer/QTargetWithReg Max                  318.23
trainer/QTargetWithReg Min                    3.46782
trainer/PolicyLossWithoutReg Mean           233.543
trainer/PolicyLossWithoutReg Std             77.6518
trainer/PolicyLossWithoutReg Max            317.237
trainer/PolicyLossWithoutReg Min              6.81045
trainer/gradient_norm                       355.06
trainer/gradient_penalty                     -1.7753
trainer/gradient_percentage                  -0.00760161
exploration/num steps total              879000
exploration/num paths total                2039
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15275
exploration/Rewards Std                       1.31388
exploration/Rewards Max                      10.2719
exploration/Rewards Min                      -0.403612
exploration/Returns Mean                   5152.75
exploration/Returns Std                       0
exploration/Returns Max                    5152.75
exploration/Returns Min                    5152.75
exploration/Num Paths                         1
exploration/Average Returns                5152.75
evaluation_0/num steps total                  6.90879e+06
evaluation_0/num paths total              15064
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23554
evaluation_0/Rewards Std                      1.28006
evaluation_0/Rewards Max                     10.2453
evaluation_0/Rewards Min                     -0.46291
evaluation_0/Returns Mean                  5235.54
evaluation_0/Returns Std                     19.2909
evaluation_0/Returns Max                   5260.1
evaluation_0/Returns Min                   5198.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5235.54
time/epoch (s)                                0
time/total (s)                            16595
Epoch                                       874
---------------------------------------  ----------------
2022-11-16 15:22:37.954107 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 875 finished
---------------------------------------  ----------------
epoch                                       875
total_step                               880000
replay_pool/size                         880000
trainer/alpha                                 0.0597992
trainer/alpha_loss                            0.866716
trainer/entropy                              -6.30768
trainer/qf_loss                               6.71861
trainer/state_noise                           0.005
trainer/policy_loss                        -230.234
trainer/policy_loss_without_entropy         232.526
trainer/entropy_penalty                      -0.377194
trainer/entropy_percentage                   -0.00162216
trainer/Q1Pred Mean                         231.12
trainer/Q1Pred Std                           75.2002
trainer/Q1Pred Max                          321.828
trainer/Q1Pred Min                           17.0544
trainer/Q2Pred Mean                         231.382
trainer/Q2Pred Std                           75.3072
trainer/Q2Pred Max                          322.146
trainer/Q2Pred Min                           18.2347
trainer/QTargetWithReg Mean                 231.373
trainer/QTargetWithReg Std                   75.1171
trainer/QTargetWithReg Max                  321.672
trainer/QTargetWithReg Min                   17.6375
trainer/PolicyLossWithoutReg Mean           232.526
trainer/PolicyLossWithoutReg Std             74.396
trainer/PolicyLossWithoutReg Max            322.605
trainer/PolicyLossWithoutReg Min             18.6193
trainer/gradient_norm                       383.073
trainer/gradient_penalty                     -1.91536
trainer/gradient_percentage                  -0.0082372
exploration/num steps total              880000
exploration/num paths total                2040
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07308
exploration/Rewards Std                       1.35101
exploration/Rewards Max                      10.4468
exploration/Rewards Min                      -0.409849
exploration/Returns Mean                   5073.08
exploration/Returns Std                       0
exploration/Returns Max                    5073.08
exploration/Returns Min                    5073.08
exploration/Num Paths                         1
exploration/Average Returns                5073.08
evaluation_0/num steps total                  6.91679e+06
evaluation_0/num paths total              15072
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15614
evaluation_0/Rewards Std                      1.28423
evaluation_0/Rewards Max                     10.2634
evaluation_0/Rewards Min                     -0.480523
evaluation_0/Returns Mean                  5156.14
evaluation_0/Returns Std                     14.7349
evaluation_0/Returns Max                   5179
evaluation_0/Returns Min                   5131.81
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5156.14
time/epoch (s)                                0
time/total (s)                            16611.6
Epoch                                       875
---------------------------------------  ----------------
2022-11-16 15:22:53.819690 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 876 finished
---------------------------------------  ----------------
epoch                                       876
total_step                               881000
replay_pool/size                         881000
trainer/alpha                                 0.0596808
trainer/alpha_loss                           -0.835484
trainer/entropy                              -5.70358
trainer/qf_loss                               6.05625
trainer/state_noise                           0.005
trainer/policy_loss                        -242.225
trainer/policy_loss_without_entropy         244.527
trainer/entropy_penalty                      -0.340394
trainer/entropy_percentage                   -0.00139205
trainer/Q1Pred Mean                         244.765
trainer/Q1Pred Std                           69.6979
trainer/Q1Pred Max                          321.232
trainer/Q1Pred Min                            0.637823
trainer/Q2Pred Mean                         244.108
trainer/Q2Pred Std                           69.8248
trainer/Q2Pred Max                          320.026
trainer/Q2Pred Min                           -4.6785
trainer/QTargetWithReg Mean                 244.444
trainer/QTargetWithReg Std                   69.7896
trainer/QTargetWithReg Max                  319.427
trainer/QTargetWithReg Min                    0.133884
trainer/PolicyLossWithoutReg Mean           244.527
trainer/PolicyLossWithoutReg Std             68.9922
trainer/PolicyLossWithoutReg Max            318.824
trainer/PolicyLossWithoutReg Min             -1.24145
trainer/gradient_norm                       392.275
trainer/gradient_penalty                     -1.96138
trainer/gradient_percentage                  -0.00802112
exploration/num steps total              881000
exploration/num paths total                2041
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13394
exploration/Rewards Std                       1.28662
exploration/Rewards Max                      10.3521
exploration/Rewards Min                      -0.517258
exploration/Returns Mean                   5133.94
exploration/Returns Std                       0
exploration/Returns Max                    5133.94
exploration/Returns Min                    5133.94
exploration/Num Paths                         1
exploration/Average Returns                5133.94
evaluation_0/num steps total                  6.92479e+06
evaluation_0/num paths total              15080
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26562
evaluation_0/Rewards Std                      1.3232
evaluation_0/Rewards Max                     10.5641
evaluation_0/Rewards Min                     -0.479931
evaluation_0/Returns Mean                  5265.62
evaluation_0/Returns Std                     32.4851
evaluation_0/Returns Max                   5305.49
evaluation_0/Returns Min                   5211.98
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5265.62
time/epoch (s)                                0
time/total (s)                            16627.5
Epoch                                       876
---------------------------------------  ----------------
2022-11-16 15:23:09.956510 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 877 finished
---------------------------------------  ----------------
epoch                                       877
total_step                               882000
replay_pool/size                         882000
trainer/alpha                                 0.0602328
trainer/alpha_loss                            0.366535
trainer/entropy                              -6.13046
trainer/qf_loss                               8.09316
trainer/state_noise                           0.005
trainer/policy_loss                        -230.218
trainer/policy_loss_without_entropy         232.505
trainer/entropy_penalty                      -0.369255
trainer/entropy_percentage                   -0.00158815
trainer/Q1Pred Mean                         232.198
trainer/Q1Pred Std                           79.1577
trainer/Q1Pred Max                          319.341
trainer/Q1Pred Min                            3.002
trainer/Q2Pred Mean                         232.231
trainer/Q2Pred Std                           79.2631
trainer/Q2Pred Max                          317.936
trainer/Q2Pred Min                           -1.33787
trainer/QTargetWithReg Mean                 231.749
trainer/QTargetWithReg Std                   79.527
trainer/QTargetWithReg Max                  318.117
trainer/QTargetWithReg Min                    0.591448
trainer/PolicyLossWithoutReg Mean           232.505
trainer/PolicyLossWithoutReg Std             78.5001
trainer/PolicyLossWithoutReg Max            317.387
trainer/PolicyLossWithoutReg Min             -0.421845
trainer/gradient_norm                       383.543
trainer/gradient_penalty                     -1.91771
trainer/gradient_percentage                  -0.00824804
exploration/num steps total              882000
exploration/num paths total                2042
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15443
exploration/Rewards Std                       1.29716
exploration/Rewards Max                      10.2311
exploration/Rewards Min                      -0.404201
exploration/Returns Mean                   5154.43
exploration/Returns Std                       0
exploration/Returns Max                    5154.43
exploration/Returns Min                    5154.43
exploration/Num Paths                         1
exploration/Average Returns                5154.43
evaluation_0/num steps total                  6.93279e+06
evaluation_0/num paths total              15088
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18087
evaluation_0/Rewards Std                      1.29506
evaluation_0/Rewards Max                     10.2038
evaluation_0/Rewards Min                     -0.460764
evaluation_0/Returns Mean                  5180.87
evaluation_0/Returns Std                     12.78
evaluation_0/Returns Max                   5200.98
evaluation_0/Returns Min                   5159.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5180.87
time/epoch (s)                                0
time/total (s)                            16643.6
Epoch                                       877
---------------------------------------  ----------------
2022-11-16 15:23:26.170126 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 878 finished
---------------------------------------  ----------------
epoch                                       878
total_step                               883000
replay_pool/size                         883000
trainer/alpha                                 0.061203
trainer/alpha_loss                            0.188
trainer/entropy                              -6.0673
trainer/qf_loss                               8.22429
trainer/state_noise                           0.005
trainer/policy_loss                        -224.526
trainer/policy_loss_without_entropy         226.755
trainer/entropy_penalty                      -0.371337
trainer/entropy_percentage                   -0.00163761
trainer/Q1Pred Mean                         226.112
trainer/Q1Pred Std                           78.9191
trainer/Q1Pred Max                          319.224
trainer/Q1Pred Min                            9.91882
trainer/Q2Pred Mean                         226.482
trainer/Q2Pred Std                           78.8828
trainer/Q2Pred Max                          319.764
trainer/Q2Pred Min                           10.651
trainer/QTargetWithReg Mean                 226.636
trainer/QTargetWithReg Std                   78.709
trainer/QTargetWithReg Max                  320.62
trainer/QTargetWithReg Min                   13.1937
trainer/PolicyLossWithoutReg Mean           226.755
trainer/PolicyLossWithoutReg Std             78.2735
trainer/PolicyLossWithoutReg Max            319.316
trainer/PolicyLossWithoutReg Min             10.8002
trainer/gradient_norm                       371.575
trainer/gradient_penalty                     -1.85788
trainer/gradient_percentage                  -0.00819332
exploration/num steps total              883000
exploration/num paths total                2043
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14436
exploration/Rewards Std                       1.31275
exploration/Rewards Max                      10.2033
exploration/Rewards Min                      -0.476492
exploration/Returns Mean                   5144.36
exploration/Returns Std                       0
exploration/Returns Max                    5144.36
exploration/Returns Min                    5144.36
exploration/Num Paths                         1
exploration/Average Returns                5144.36
evaluation_0/num steps total                  6.94079e+06
evaluation_0/num paths total              15096
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19251
evaluation_0/Rewards Std                      1.32635
evaluation_0/Rewards Max                     10.3074
evaluation_0/Rewards Min                     -0.46776
evaluation_0/Returns Mean                  5192.51
evaluation_0/Returns Std                     40.9208
evaluation_0/Returns Max                   5272.96
evaluation_0/Returns Min                   5131.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5192.51
time/epoch (s)                                0
time/total (s)                            16659.8
Epoch                                       878
---------------------------------------  ----------------
2022-11-16 15:23:41.956960 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 879 finished
---------------------------------------  ----------------
epoch                                       879
total_step                               884000
replay_pool/size                         884000
trainer/alpha                                 0.0613886
trainer/alpha_loss                           -0.322025
trainer/entropy                              -5.8846
trainer/qf_loss                               7.31017
trainer/state_noise                           0.005
trainer/policy_loss                        -232.359
trainer/policy_loss_without_entropy         234.58
trainer/entropy_penalty                      -0.361248
trainer/entropy_percentage                   -0.00153998
trainer/Q1Pred Mean                         234.122
trainer/Q1Pred Std                           74.3139
trainer/Q1Pred Max                          321.732
trainer/Q1Pred Min                            8.97787
trainer/Q2Pred Mean                         234.035
trainer/Q2Pred Std                           74.2456
trainer/Q2Pred Max                          320.506
trainer/Q2Pred Min                            9.99089
trainer/QTargetWithReg Mean                 234.387
trainer/QTargetWithReg Std                   74.418
trainer/QTargetWithReg Max                  319.197
trainer/QTargetWithReg Min                   10.963
trainer/PolicyLossWithoutReg Mean           234.58
trainer/PolicyLossWithoutReg Std             73.7694
trainer/PolicyLossWithoutReg Max            320.314
trainer/PolicyLossWithoutReg Min             10.1012
trainer/gradient_norm                       371.924
trainer/gradient_penalty                     -1.85962
trainer/gradient_percentage                  -0.00792747
exploration/num steps total              884000
exploration/num paths total                2044
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.04871
exploration/Rewards Std                       1.30615
exploration/Rewards Max                      10.3079
exploration/Rewards Min                      -0.475156
exploration/Returns Mean                   5048.71
exploration/Returns Std                       0
exploration/Returns Max                    5048.71
exploration/Returns Min                    5048.71
exploration/Num Paths                         1
exploration/Average Returns                5048.71
evaluation_0/num steps total                  6.94879e+06
evaluation_0/num paths total              15104
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17645
evaluation_0/Rewards Std                      1.30456
evaluation_0/Rewards Max                     10.1562
evaluation_0/Rewards Min                     -0.523115
evaluation_0/Returns Mean                  5176.45
evaluation_0/Returns Std                     19.6136
evaluation_0/Returns Max                   5205.3
evaluation_0/Returns Min                   5140.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5176.45
time/epoch (s)                                0
time/total (s)                            16675.6
Epoch                                       879
---------------------------------------  ----------------
2022-11-16 15:23:58.413201 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 880 finished
---------------------------------------  ----------------
epoch                                       880
total_step                               885000
replay_pool/size                         885000
trainer/alpha                                 0.059939
trainer/alpha_loss                           -0.249902
trainer/entropy                              -5.91121
trainer/qf_loss                               6.5172
trainer/state_noise                           0.005
trainer/policy_loss                        -231.745
trainer/policy_loss_without_entropy         233.941
trainer/entropy_penalty                      -0.354312
trainer/entropy_percentage                   -0.00151453
trainer/Q1Pred Mean                         232.987
trainer/Q1Pred Std                           76.0286
trainer/Q1Pred Max                          318.886
trainer/Q1Pred Min                          -16.2615
trainer/Q2Pred Mean                         233.577
trainer/Q2Pred Std                           76.3107
trainer/Q2Pred Max                          319.592
trainer/Q2Pred Min                           -5.95727
trainer/QTargetWithReg Mean                 233.312
trainer/QTargetWithReg Std                   76.0269
trainer/QTargetWithReg Max                  318.013
trainer/QTargetWithReg Min                  -16.3745
trainer/PolicyLossWithoutReg Mean           233.941
trainer/PolicyLossWithoutReg Std             75.3553
trainer/PolicyLossWithoutReg Max            319.591
trainer/PolicyLossWithoutReg Min             -8.8136
trainer/gradient_norm                       368.399
trainer/gradient_penalty                     -1.842
trainer/gradient_percentage                  -0.00787376
exploration/num steps total              885000
exploration/num paths total                2045
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09195
exploration/Rewards Std                       1.33848
exploration/Rewards Max                      11.112
exploration/Rewards Min                      -0.511928
exploration/Returns Mean                   5091.95
exploration/Returns Std                       0
exploration/Returns Max                    5091.95
exploration/Returns Min                    5091.95
exploration/Num Paths                         1
exploration/Average Returns                5091.95
evaluation_0/num steps total                  6.95679e+06
evaluation_0/num paths total              15112
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03228
evaluation_0/Rewards Std                      1.30943
evaluation_0/Rewards Max                     10.2961
evaluation_0/Rewards Min                     -0.587315
evaluation_0/Returns Mean                  5032.28
evaluation_0/Returns Std                     33.4826
evaluation_0/Returns Max                   5071.33
evaluation_0/Returns Min                   4951.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5032.28
time/epoch (s)                                0
time/total (s)                            16692.1
Epoch                                       880
---------------------------------------  ----------------
2022-11-16 15:24:14.312907 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 881 finished
---------------------------------------  ----------------
epoch                                       881
total_step                               886000
replay_pool/size                         886000
trainer/alpha                                 0.0590309
trainer/alpha_loss                           -0.466921
trainer/entropy                              -5.83499
trainer/qf_loss                               8.8519
trainer/state_noise                           0.005
trainer/policy_loss                        -229.477
trainer/policy_loss_without_entropy         231.678
trainer/entropy_penalty                      -0.344445
trainer/entropy_percentage                   -0.00148674
trainer/Q1Pred Mean                         230.991
trainer/Q1Pred Std                           73.5694
trainer/Q1Pred Max                          321.023
trainer/Q1Pred Min                            9.23278
trainer/Q2Pred Mean                         230.675
trainer/Q2Pred Std                           73.2288
trainer/Q2Pred Max                          318.914
trainer/Q2Pred Min                            9.01769
trainer/QTargetWithReg Mean                 230.802
trainer/QTargetWithReg Std                   73.2193
trainer/QTargetWithReg Max                  320.529
trainer/QTargetWithReg Min                    9.94597
trainer/PolicyLossWithoutReg Mean           231.678
trainer/PolicyLossWithoutReg Std             72.7905
trainer/PolicyLossWithoutReg Max            317.815
trainer/PolicyLossWithoutReg Min              9.09016
trainer/gradient_norm                       371.217
trainer/gradient_penalty                     -1.85609
trainer/gradient_percentage                  -0.0080115
exploration/num steps total              886000
exploration/num paths total                2046
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.21147
exploration/Rewards Std                       1.33542
exploration/Rewards Max                      10.6509
exploration/Rewards Min                      -0.656188
exploration/Returns Mean                   5211.47
exploration/Returns Std                       0
exploration/Returns Max                    5211.47
exploration/Returns Min                    5211.47
exploration/Num Paths                         1
exploration/Average Returns                5211.47
evaluation_0/num steps total                  6.96479e+06
evaluation_0/num paths total              15120
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23818
evaluation_0/Rewards Std                      1.31126
evaluation_0/Rewards Max                     10.2206
evaluation_0/Rewards Min                     -0.505169
evaluation_0/Returns Mean                  5238.18
evaluation_0/Returns Std                     14.118
evaluation_0/Returns Max                   5257.4
evaluation_0/Returns Min                   5216.97
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5238.18
time/epoch (s)                                0
time/total (s)                            16708
Epoch                                       881
---------------------------------------  ----------------
2022-11-16 15:24:30.880058 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 882 finished
---------------------------------------  ----------------
epoch                                       882
total_step                               887000
replay_pool/size                         887000
trainer/alpha                                 0.0622622
trainer/alpha_loss                           -0.754041
trainer/entropy                              -5.7284
trainer/qf_loss                               8.88068
trainer/state_noise                           0.005
trainer/policy_loss                        -232.146
trainer/policy_loss_without_entropy         234.353
trainer/entropy_penalty                      -0.356663
trainer/entropy_percentage                   -0.00152191
trainer/Q1Pred Mean                         233.609
trainer/Q1Pred Std                           75.3049
trainer/Q1Pred Max                          323.147
trainer/Q1Pred Min                           11.1072
trainer/Q2Pred Mean                         233.806
trainer/Q2Pred Std                           75.0568
trainer/Q2Pred Max                          324.005
trainer/Q2Pred Min                           10.3788
trainer/QTargetWithReg Mean                 233.936
trainer/QTargetWithReg Std                   75.0762
trainer/QTargetWithReg Max                  324.78
trainer/QTargetWithReg Min                   14.2106
trainer/PolicyLossWithoutReg Mean           234.353
trainer/PolicyLossWithoutReg Std             74.4947
trainer/PolicyLossWithoutReg Max            322.826
trainer/PolicyLossWithoutReg Min             10.8458
trainer/gradient_norm                       369.983
trainer/gradient_penalty                     -1.84992
trainer/gradient_percentage                  -0.00789373
exploration/num steps total              887000
exploration/num paths total                2047
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10682
exploration/Rewards Std                       1.30437
exploration/Rewards Max                      10.4729
exploration/Rewards Min                      -0.414837
exploration/Returns Mean                   5106.82
exploration/Returns Std                       0
exploration/Returns Max                    5106.82
exploration/Returns Min                    5106.82
exploration/Num Paths                         1
exploration/Average Returns                5106.82
evaluation_0/num steps total                  6.97279e+06
evaluation_0/num paths total              15128
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18344
evaluation_0/Rewards Std                      1.28901
evaluation_0/Rewards Max                     10.2464
evaluation_0/Rewards Min                     -0.513149
evaluation_0/Returns Mean                  5183.44
evaluation_0/Returns Std                     14.5596
evaluation_0/Returns Max                   5205.99
evaluation_0/Returns Min                   5166.01
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5183.44
time/epoch (s)                                0
time/total (s)                            16724.6
Epoch                                       882
---------------------------------------  ----------------
2022-11-16 15:24:46.726035 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 883 finished
---------------------------------------  ----------------
epoch                                       883
total_step                               888000
replay_pool/size                         888000
trainer/alpha                                 0.0594959
trainer/alpha_loss                            0.843167
trainer/entropy                              -6.29881
trainer/qf_loss                               9.68394
trainer/state_noise                           0.005
trainer/policy_loss                        -232.854
trainer/policy_loss_without_entropy         235.113
trainer/entropy_penalty                      -0.374754
trainer/entropy_percentage                   -0.00159393
trainer/Q1Pred Mean                         234.116
trainer/Q1Pred Std                           81.1453
trainer/Q1Pred Max                          326.183
trainer/Q1Pred Min                          -20.9422
trainer/Q2Pred Mean                         233.93
trainer/Q2Pred Std                           81.1947
trainer/Q2Pred Max                          326.902
trainer/Q2Pred Min                          -19.6166
trainer/QTargetWithReg Mean                 234.325
trainer/QTargetWithReg Std                   81.0547
trainer/QTargetWithReg Max                  327.029
trainer/QTargetWithReg Min                  -11.3101
trainer/PolicyLossWithoutReg Mean           235.113
trainer/PolicyLossWithoutReg Std             79.6461
trainer/PolicyLossWithoutReg Max            326.427
trainer/PolicyLossWithoutReg Min            -13.596
trainer/gradient_norm                       376.94
trainer/gradient_penalty                     -1.8847
trainer/gradient_percentage                  -0.00801614
exploration/num steps total              888000
exploration/num paths total                2048
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12593
exploration/Rewards Std                       1.3283
exploration/Rewards Max                      10.275
exploration/Rewards Min                      -0.503853
exploration/Returns Mean                   5125.93
exploration/Returns Std                       0
exploration/Returns Max                    5125.93
exploration/Returns Min                    5125.93
exploration/Num Paths                         1
exploration/Average Returns                5125.93
evaluation_0/num steps total                  6.98079e+06
evaluation_0/num paths total              15136
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.04682
evaluation_0/Rewards Std                      1.29586
evaluation_0/Rewards Max                     10.2294
evaluation_0/Rewards Min                     -0.607118
evaluation_0/Returns Mean                  5046.82
evaluation_0/Returns Std                      7.81709
evaluation_0/Returns Max                   5058.62
evaluation_0/Returns Min                   5037.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5046.82
time/epoch (s)                                0
time/total (s)                            16740.4
Epoch                                       883
---------------------------------------  ----------------
2022-11-16 15:25:03.209955 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 884 finished
---------------------------------------  ----------------
epoch                                       884
total_step                               889000
replay_pool/size                         889000
trainer/alpha                                 0.0607096
trainer/alpha_loss                            1.26149
trainer/entropy                              -6.45026
trainer/qf_loss                               9.68714
trainer/state_noise                           0.005
trainer/policy_loss                        -234.655
trainer/policy_loss_without_entropy         236.901
trainer/entropy_penalty                      -0.391593
trainer/entropy_percentage                   -0.00165298
trainer/Q1Pred Mean                         235.906
trainer/Q1Pred Std                           73.7087
trainer/Q1Pred Max                          320.131
trainer/Q1Pred Min                           -4.56186
trainer/Q2Pred Mean                         235.788
trainer/Q2Pred Std                           74.0462
trainer/Q2Pred Max                          321.139
trainer/Q2Pred Min                            0.385193
trainer/QTargetWithReg Mean                 236.305
trainer/QTargetWithReg Std                   73.8007
trainer/QTargetWithReg Max                  319.732
trainer/QTargetWithReg Min                   -4.01855
trainer/PolicyLossWithoutReg Mean           236.901
trainer/PolicyLossWithoutReg Std             73.0591
trainer/PolicyLossWithoutReg Max            320.652
trainer/PolicyLossWithoutReg Min             -0.862066
trainer/gradient_norm                       370.882
trainer/gradient_penalty                     -1.85441
trainer/gradient_percentage                  -0.00782777
exploration/num steps total              889000
exploration/num paths total                2049
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14711
exploration/Rewards Std                       1.32647
exploration/Rewards Max                      10.3264
exploration/Rewards Min                      -0.533031
exploration/Returns Mean                   5147.11
exploration/Returns Std                       0
exploration/Returns Max                    5147.11
exploration/Returns Min                    5147.11
exploration/Num Paths                         1
exploration/Average Returns                5147.11
evaluation_0/num steps total                  6.98879e+06
evaluation_0/num paths total              15144
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.2998
evaluation_0/Rewards Std                      1.31308
evaluation_0/Rewards Max                     10.3517
evaluation_0/Rewards Min                     -0.565658
evaluation_0/Returns Mean                  5299.8
evaluation_0/Returns Std                     28.11
evaluation_0/Returns Max                   5340.23
evaluation_0/Returns Min                   5255.1
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5299.8
time/epoch (s)                                0
time/total (s)                            16756.9
Epoch                                       884
---------------------------------------  ----------------
2022-11-16 15:25:19.088059 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 885 finished
---------------------------------------  ----------------
epoch                                       885
total_step                               890000
replay_pool/size                         890000
trainer/alpha                                 0.0589916
trainer/alpha_loss                            0.239442
trainer/entropy                              -6.0846
trainer/qf_loss                               6.10662
trainer/state_noise                           0.005
trainer/policy_loss                        -238.189
trainer/policy_loss_without_entropy         240.387
trainer/entropy_penalty                      -0.35894
trainer/entropy_percentage                   -0.00149317
trainer/Q1Pred Mean                         240.034
trainer/Q1Pred Std                           71.9022
trainer/Q1Pred Max                          320.86
trainer/Q1Pred Min                           22.4189
trainer/Q2Pred Mean                         239.84
trainer/Q2Pred Std                           71.8322
trainer/Q2Pred Max                          321.707
trainer/Q2Pred Min                           22.1765
trainer/QTargetWithReg Mean                 240.056
trainer/QTargetWithReg Std                   72.0013
trainer/QTargetWithReg Max                  321.294
trainer/QTargetWithReg Min                   20.3943
trainer/PolicyLossWithoutReg Mean           240.388
trainer/PolicyLossWithoutReg Std             71.2223
trainer/PolicyLossWithoutReg Max            320.822
trainer/PolicyLossWithoutReg Min             22.7544
trainer/gradient_norm                       367.82
trainer/gradient_penalty                     -1.8391
trainer/gradient_percentage                  -0.00765057
exploration/num steps total              890000
exploration/num paths total                2050
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.34973
exploration/Rewards Std                       1.3856
exploration/Rewards Max                      10.4962
exploration/Rewards Min                      -0.543521
exploration/Returns Mean                   5349.73
exploration/Returns Std                       0
exploration/Returns Max                    5349.73
exploration/Returns Min                    5349.73
exploration/Num Paths                         1
exploration/Average Returns                5349.73
evaluation_0/num steps total                  6.99679e+06
evaluation_0/num paths total              15152
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14389
evaluation_0/Rewards Std                      1.2884
evaluation_0/Rewards Max                     10.4695
evaluation_0/Rewards Min                     -0.529473
evaluation_0/Returns Mean                  5143.89
evaluation_0/Returns Std                     31.8321
evaluation_0/Returns Max                   5208.68
evaluation_0/Returns Min                   5098.05
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5143.89
time/epoch (s)                                0
time/total (s)                            16772.8
Epoch                                       885
---------------------------------------  ----------------
2022-11-16 15:25:35.115310 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 886 finished
---------------------------------------  ----------------
epoch                                       886
total_step                               891000
replay_pool/size                         891000
trainer/alpha                                 0.0602937
trainer/alpha_loss                           -0.417232
trainer/entropy                              -5.85143
trainer/qf_loss                               5.97647
trainer/state_noise                           0.005
trainer/policy_loss                        -231.8
trainer/policy_loss_without_entropy         233.98
trainer/entropy_penalty                      -0.352804
trainer/entropy_percentage                   -0.00150784
trainer/Q1Pred Mean                         233.781
trainer/Q1Pred Std                           72.9435
trainer/Q1Pred Max                          321.687
trainer/Q1Pred Min                           23.5238
trainer/Q2Pred Mean                         233.936
trainer/Q2Pred Std                           72.9154
trainer/Q2Pred Max                          323.4
trainer/Q2Pred Min                           27.0338
trainer/QTargetWithReg Mean                 233.554
trainer/QTargetWithReg Std                   73.1472
trainer/QTargetWithReg Max                  324.294
trainer/QTargetWithReg Min                   26.2304
trainer/PolicyLossWithoutReg Mean           233.98
trainer/PolicyLossWithoutReg Std             71.7723
trainer/PolicyLossWithoutReg Max            322.157
trainer/PolicyLossWithoutReg Min             27.7079
trainer/gradient_norm                       365.431
trainer/gradient_penalty                     -1.82715
trainer/gradient_percentage                  -0.00780901
exploration/num steps total              891000
exploration/num paths total                2051
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17252
exploration/Rewards Std                       1.34252
exploration/Rewards Max                      10.7679
exploration/Rewards Min                      -0.628415
exploration/Returns Mean                   5172.52
exploration/Returns Std                       0
exploration/Returns Max                    5172.52
exploration/Returns Min                    5172.52
exploration/Num Paths                         1
exploration/Average Returns                5172.52
evaluation_0/num steps total                  7.00479e+06
evaluation_0/num paths total              15160
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19878
evaluation_0/Rewards Std                      1.31873
evaluation_0/Rewards Max                     10.3897
evaluation_0/Rewards Min                     -0.582879
evaluation_0/Returns Mean                  5198.78
evaluation_0/Returns Std                     16.4874
evaluation_0/Returns Max                   5223.3
evaluation_0/Returns Min                   5181.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5198.78
time/epoch (s)                                0
time/total (s)                            16788.8
Epoch                                       886
---------------------------------------  ----------------
2022-11-16 15:25:51.519056 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 887 finished
---------------------------------------  ----------------
epoch                                       887
total_step                               892000
replay_pool/size                         892000
trainer/alpha                                 0.0596442
trainer/alpha_loss                            1.23039
trainer/entropy                              -6.43641
trainer/qf_loss                               6.25506
trainer/state_noise                           0.005
trainer/policy_loss                        -232.385
trainer/policy_loss_without_entropy         234.613
trainer/entropy_penalty                      -0.383894
trainer/entropy_percentage                   -0.00163628
trainer/Q1Pred Mean                         233.514
trainer/Q1Pred Std                           79.4821
trainer/Q1Pred Max                          323.646
trainer/Q1Pred Min                            2.17662
trainer/Q2Pred Mean                         233.915
trainer/Q2Pred Std                           79.851
trainer/Q2Pred Max                          323.572
trainer/Q2Pred Min                           -2.74282
trainer/QTargetWithReg Mean                 233.549
trainer/QTargetWithReg Std                   79.6988
trainer/QTargetWithReg Max                  321.783
trainer/QTargetWithReg Min                    0.00786138
trainer/PolicyLossWithoutReg Mean           234.613
trainer/PolicyLossWithoutReg Std             79.052
trainer/PolicyLossWithoutReg Max            323.954
trainer/PolicyLossWithoutReg Min             -3.4215
trainer/gradient_norm                       368.973
trainer/gradient_penalty                     -1.84487
trainer/gradient_percentage                  -0.00786344
exploration/num steps total              892000
exploration/num paths total                2052
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09204
exploration/Rewards Std                       1.33476
exploration/Rewards Max                      11.304
exploration/Rewards Min                      -0.501851
exploration/Returns Mean                   5092.04
exploration/Returns Std                       0
exploration/Returns Max                    5092.04
exploration/Returns Min                    5092.04
exploration/Num Paths                         1
exploration/Average Returns                5092.04
evaluation_0/num steps total                  7.01279e+06
evaluation_0/num paths total              15168
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1385
evaluation_0/Rewards Std                      1.32046
evaluation_0/Rewards Max                     10.4186
evaluation_0/Rewards Min                     -0.476976
evaluation_0/Returns Mean                  5138.5
evaluation_0/Returns Std                      6.92331
evaluation_0/Returns Max                   5149.68
evaluation_0/Returns Min                   5129.4
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5138.5
time/epoch (s)                                0
time/total (s)                            16805.2
Epoch                                       887
---------------------------------------  ----------------
2022-11-16 15:26:07.394702 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 888 finished
---------------------------------------  ----------------
epoch                                       888
total_step                               893000
replay_pool/size                         893000
trainer/alpha                                 0.0589879
trainer/alpha_loss                            0.342655
trainer/entropy                              -6.12106
trainer/qf_loss                               5.73101
trainer/state_noise                           0.005
trainer/policy_loss                        -240.077
trainer/policy_loss_without_entropy         242.307
trainer/entropy_penalty                      -0.361069
trainer/entropy_percentage                   -0.00149013
trainer/Q1Pred Mean                         241.377
trainer/Q1Pred Std                           70.3525
trainer/Q1Pred Max                          321.685
trainer/Q1Pred Min                            9.82249
trainer/Q2Pred Mean                         241.787
trainer/Q2Pred Std                           70.0321
trainer/Q2Pred Max                          320.592
trainer/Q2Pred Min                           13.988
trainer/QTargetWithReg Mean                 241.97
trainer/QTargetWithReg Std                   70.401
trainer/QTargetWithReg Max                  322.457
trainer/QTargetWithReg Min                   13.8029
trainer/PolicyLossWithoutReg Mean           242.307
trainer/PolicyLossWithoutReg Std             69.2197
trainer/PolicyLossWithoutReg Max            320.493
trainer/PolicyLossWithoutReg Min             11.3641
trainer/gradient_norm                       373.806
trainer/gradient_penalty                     -1.86903
trainer/gradient_percentage                  -0.00771346
exploration/num steps total              893000
exploration/num paths total                2053
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16589
exploration/Rewards Std                       1.33805
exploration/Rewards Max                      10.6761
exploration/Rewards Min                      -0.442954
exploration/Returns Mean                   5165.89
exploration/Returns Std                       0
exploration/Returns Max                    5165.89
exploration/Returns Min                    5165.89
exploration/Num Paths                         1
exploration/Average Returns                5165.89
evaluation_0/num steps total                  7.02079e+06
evaluation_0/num paths total              15176
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03825
evaluation_0/Rewards Std                      1.3121
evaluation_0/Rewards Max                     10.4321
evaluation_0/Rewards Min                     -0.623937
evaluation_0/Returns Mean                  5038.25
evaluation_0/Returns Std                     18.4535
evaluation_0/Returns Max                   5064.84
evaluation_0/Returns Min                   4999.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5038.25
time/epoch (s)                                0
time/total (s)                            16821.1
Epoch                                       888
---------------------------------------  ----------------
2022-11-16 15:26:23.926773 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 889 finished
---------------------------------------  ----------------
epoch                                       889
total_step                               894000
replay_pool/size                         894000
trainer/alpha                                 0.0602739
trainer/alpha_loss                           -0.398026
trainer/entropy                              -5.85829
trainer/qf_loss                              10.7263
trainer/state_noise                           0.005
trainer/policy_loss                        -234.046
trainer/policy_loss_without_entropy         236.276
trainer/entropy_penalty                      -0.353102
trainer/entropy_percentage                   -0.00149444
trainer/Q1Pred Mean                         235.111
trainer/Q1Pred Std                           73.3282
trainer/Q1Pred Max                          325.101
trainer/Q1Pred Min                           27.9757
trainer/Q2Pred Mean                         235.808
trainer/Q2Pred Std                           73.3647
trainer/Q2Pred Max                          322.345
trainer/Q2Pred Min                           26.849
trainer/QTargetWithReg Mean                 236.796
trainer/QTargetWithReg Std                   72.9899
trainer/QTargetWithReg Max                  322.404
trainer/QTargetWithReg Min                   30.5605
trainer/PolicyLossWithoutReg Mean           236.276
trainer/PolicyLossWithoutReg Std             72.6467
trainer/PolicyLossWithoutReg Max            324.887
trainer/PolicyLossWithoutReg Min             30.2589
trainer/gradient_norm                       375.546
trainer/gradient_penalty                     -1.87773
trainer/gradient_percentage                  -0.00794718
exploration/num steps total              894000
exploration/num paths total                2054
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.18186
exploration/Rewards Std                       1.31659
exploration/Rewards Max                      10.3277
exploration/Rewards Min                      -0.602426
exploration/Returns Mean                   5181.86
exploration/Returns Std                       0
exploration/Returns Max                    5181.86
exploration/Returns Min                    5181.86
exploration/Num Paths                         1
exploration/Average Returns                5181.86
evaluation_0/num steps total                  7.02879e+06
evaluation_0/num paths total              15184
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.2113
evaluation_0/Rewards Std                      1.33674
evaluation_0/Rewards Max                     10.5785
evaluation_0/Rewards Min                     -0.437464
evaluation_0/Returns Mean                  5211.3
evaluation_0/Returns Std                     23.9635
evaluation_0/Returns Max                   5248.03
evaluation_0/Returns Min                   5166.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5211.3
time/epoch (s)                                0
time/total (s)                            16837.6
Epoch                                       889
---------------------------------------  ----------------
2022-11-16 15:26:39.778038 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 890 finished
---------------------------------------  ----------------
epoch                                       890
total_step                               895000
replay_pool/size                         895000
trainer/alpha                                 0.060456
trainer/alpha_loss                           -1.47141
trainer/entropy                              -5.47561
trainer/qf_loss                               6.37084
trainer/state_noise                           0.005
trainer/policy_loss                        -234.408
trainer/policy_loss_without_entropy         236.58
trainer/entropy_penalty                      -0.331033
trainer/entropy_percentage                   -0.00139924
trainer/Q1Pred Mean                         236.758
trainer/Q1Pred Std                           75.2334
trainer/Q1Pred Max                          320.813
trainer/Q1Pred Min                           -2.81932
trainer/Q2Pred Mean                         236.505
trainer/Q2Pred Std                           75.2377
trainer/Q2Pred Max                          321.75
trainer/Q2Pred Min                           -2.80813
trainer/QTargetWithReg Mean                 236.708
trainer/QTargetWithReg Std                   75.169
trainer/QTargetWithReg Max                  319.859
trainer/QTargetWithReg Min                   -2.55938
trainer/PolicyLossWithoutReg Mean           236.58
trainer/PolicyLossWithoutReg Std             74.7496
trainer/PolicyLossWithoutReg Max            320.874
trainer/PolicyLossWithoutReg Min             -1.72709
trainer/gradient_norm                       368.135
trainer/gradient_penalty                     -1.84068
trainer/gradient_percentage                  -0.00778036
exploration/num steps total              895000
exploration/num paths total                2055
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.23822
exploration/Rewards Std                       1.36735
exploration/Rewards Max                      11.2374
exploration/Rewards Min                      -0.437468
exploration/Returns Mean                   5238.22
exploration/Returns Std                       0
exploration/Returns Max                    5238.22
exploration/Returns Min                    5238.22
exploration/Num Paths                         1
exploration/Average Returns                5238.22
evaluation_0/num steps total                  7.03679e+06
evaluation_0/num paths total              15192
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16021
evaluation_0/Rewards Std                      1.32582
evaluation_0/Rewards Max                     10.5224
evaluation_0/Rewards Min                     -0.388243
evaluation_0/Returns Mean                  5160.21
evaluation_0/Returns Std                     34.6351
evaluation_0/Returns Max                   5218.25
evaluation_0/Returns Min                   5123.45
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5160.21
time/epoch (s)                                0
time/total (s)                            16853.5
Epoch                                       890
---------------------------------------  ----------------
2022-11-16 15:26:56.177545 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 891 finished
---------------------------------------  ----------------
epoch                                       891
total_step                               896000
replay_pool/size                         896000
trainer/alpha                                 0.0592559
trainer/alpha_loss                            0.321813
trainer/entropy                              -6.11388
trainer/qf_loss                               8.41873
trainer/state_noise                           0.005
trainer/policy_loss                        -230.004
trainer/policy_loss_without_entropy         232.207
trainer/entropy_penalty                      -0.362283
trainer/entropy_percentage                   -0.00156017
trainer/Q1Pred Mean                         232.175
trainer/Q1Pred Std                           74.2736
trainer/Q1Pred Max                          318.702
trainer/Q1Pred Min                            0.847656
trainer/Q2Pred Mean                         232.216
trainer/Q2Pred Std                           74.2358
trainer/Q2Pred Max                          318.726
trainer/Q2Pred Min                            2.013
trainer/QTargetWithReg Mean                 232.243
trainer/QTargetWithReg Std                   74.0957
trainer/QTargetWithReg Max                  319.209
trainer/QTargetWithReg Min                    2.90629
trainer/PolicyLossWithoutReg Mean           232.207
trainer/PolicyLossWithoutReg Std             73.6724
trainer/PolicyLossWithoutReg Max            318.382
trainer/PolicyLossWithoutReg Min              1.21285
trainer/gradient_norm                       368.19
trainer/gradient_penalty                     -1.84095
trainer/gradient_percentage                  -0.00792804
exploration/num steps total              896000
exploration/num paths total                2056
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.18461
exploration/Rewards Std                       1.36476
exploration/Rewards Max                      10.4347
exploration/Rewards Min                      -0.41167
exploration/Returns Mean                   5184.61
exploration/Returns Std                       0
exploration/Returns Max                    5184.61
exploration/Returns Min                    5184.61
exploration/Num Paths                         1
exploration/Average Returns                5184.61
evaluation_0/num steps total                  7.04479e+06
evaluation_0/num paths total              15200
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.36035
evaluation_0/Rewards Std                      1.34541
evaluation_0/Rewards Max                     10.6886
evaluation_0/Rewards Min                     -0.478855
evaluation_0/Returns Mean                  5360.35
evaluation_0/Returns Std                     36.9375
evaluation_0/Returns Max                   5400.65
evaluation_0/Returns Min                   5298.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5360.35
time/epoch (s)                                0
time/total (s)                            16869.9
Epoch                                       891
---------------------------------------  ----------------
2022-11-16 15:27:12.099429 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 892 finished
---------------------------------------  ----------------
epoch                                       892
total_step                               897000
replay_pool/size                         897000
trainer/alpha                                 0.0573768
trainer/alpha_loss                            2.15897
trainer/entropy                              -6.75532
trainer/qf_loss                               7.57022
trainer/state_noise                           0.005
trainer/policy_loss                        -229.932
trainer/policy_loss_without_entropy         232.192
trainer/entropy_penalty                      -0.387599
trainer/entropy_percentage                   -0.0016693
trainer/Q1Pred Mean                         230.748
trainer/Q1Pred Std                           77.4991
trainer/Q1Pred Max                          319.451
trainer/Q1Pred Min                           -8.34069
trainer/Q2Pred Mean                         230.852
trainer/Q2Pred Std                           77.6217
trainer/Q2Pred Max                          320.62
trainer/Q2Pred Min                           -1.7507
trainer/QTargetWithReg Mean                 231.325
trainer/QTargetWithReg Std                   77.8218
trainer/QTargetWithReg Max                  318.709
trainer/QTargetWithReg Min                   -0.544409
trainer/PolicyLossWithoutReg Mean           232.192
trainer/PolicyLossWithoutReg Std             75.9477
trainer/PolicyLossWithoutReg Max            320.012
trainer/PolicyLossWithoutReg Min             10.1163
trainer/gradient_norm                       374.469
trainer/gradient_penalty                     -1.87235
trainer/gradient_percentage                  -0.00806378
exploration/num steps total              897000
exploration/num paths total                2057
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.28064
exploration/Rewards Std                       1.34356
exploration/Rewards Max                      10.3809
exploration/Rewards Min                      -0.402339
exploration/Returns Mean                   5280.64
exploration/Returns Std                       0
exploration/Returns Max                    5280.64
exploration/Returns Min                    5280.64
exploration/Num Paths                         1
exploration/Average Returns                5280.64
evaluation_0/num steps total                  7.05279e+06
evaluation_0/num paths total              15208
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25392
evaluation_0/Rewards Std                      1.33464
evaluation_0/Rewards Max                     10.5067
evaluation_0/Rewards Min                     -0.430874
evaluation_0/Returns Mean                  5253.92
evaluation_0/Returns Std                     33.2793
evaluation_0/Returns Max                   5296.89
evaluation_0/Returns Min                   5203.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5253.92
time/epoch (s)                                0
time/total (s)                            16885.8
Epoch                                       892
---------------------------------------  ----------------
2022-11-16 15:27:28.226381 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 893 finished
---------------------------------------  ----------------
epoch                                       893
total_step                               898000
replay_pool/size                         898000
trainer/alpha                                 0.0599028
trainer/alpha_loss                            0.766408
trainer/entropy                              -6.27225
trainer/qf_loss                               7.71326
trainer/state_noise                           0.005
trainer/policy_loss                        -235.275
trainer/policy_loss_without_entropy         237.505
trainer/entropy_penalty                      -0.375726
trainer/entropy_percentage                   -0.00158197
trainer/Q1Pred Mean                         237.183
trainer/Q1Pred Std                           75.4182
trainer/Q1Pred Max                          324.623
trainer/Q1Pred Min                          -18.9632
trainer/Q2Pred Mean                         237.02
trainer/Q2Pred Std                           75.5649
trainer/Q2Pred Max                          321.503
trainer/Q2Pred Min                          -20.7869
trainer/QTargetWithReg Mean                 237.168
trainer/QTargetWithReg Std                   75.7068
trainer/QTargetWithReg Max                  320.413
trainer/QTargetWithReg Min                  -13.4398
trainer/PolicyLossWithoutReg Mean           237.505
trainer/PolicyLossWithoutReg Std             74.6348
trainer/PolicyLossWithoutReg Max            321.256
trainer/PolicyLossWithoutReg Min             -1.17935
trainer/gradient_norm                       370.95
trainer/gradient_penalty                     -1.85475
trainer/gradient_percentage                  -0.0078093
exploration/num steps total              898000
exploration/num paths total                2058
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15942
exploration/Rewards Std                       1.31465
exploration/Rewards Max                      10.4826
exploration/Rewards Min                      -0.415931
exploration/Returns Mean                   5159.42
exploration/Returns Std                       0
exploration/Returns Max                    5159.42
exploration/Returns Min                    5159.42
exploration/Num Paths                         1
exploration/Average Returns                5159.42
evaluation_0/num steps total                  7.06079e+06
evaluation_0/num paths total              15216
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25131
evaluation_0/Rewards Std                      1.29396
evaluation_0/Rewards Max                     10.398
evaluation_0/Rewards Min                     -0.41665
evaluation_0/Returns Mean                  5251.31
evaluation_0/Returns Std                     26.609
evaluation_0/Returns Max                   5287.05
evaluation_0/Returns Min                   5218.88
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5251.31
time/epoch (s)                                0
time/total (s)                            16901.9
Epoch                                       893
---------------------------------------  ----------------
2022-11-16 15:27:44.481464 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 894 finished
---------------------------------------  ----------------
epoch                                       894
total_step                               899000
replay_pool/size                         899000
trainer/alpha                                 0.0608808
trainer/alpha_loss                           -1.02697
trainer/entropy                              -5.63306
trainer/qf_loss                               7.5912
trainer/state_noise                           0.005
trainer/policy_loss                        -231.904
trainer/policy_loss_without_entropy         234.034
trainer/entropy_penalty                      -0.342945
trainer/entropy_percentage                   -0.00146536
trainer/Q1Pred Mean                         233.533
trainer/Q1Pred Std                           75.6038
trainer/Q1Pred Max                          319.352
trainer/Q1Pred Min                            9.80564
trainer/Q2Pred Mean                         233.156
trainer/Q2Pred Std                           75.6766
trainer/Q2Pred Max                          317.493
trainer/Q2Pred Min                            9.35252
trainer/QTargetWithReg Mean                 233.427
trainer/QTargetWithReg Std                   75.96
trainer/QTargetWithReg Max                  318.57
trainer/QTargetWithReg Min                   10.0878
trainer/PolicyLossWithoutReg Mean           234.034
trainer/PolicyLossWithoutReg Std             75.1223
trainer/PolicyLossWithoutReg Max            318.994
trainer/PolicyLossWithoutReg Min             10.2725
trainer/gradient_norm                       357.491
trainer/gradient_penalty                     -1.78745
trainer/gradient_percentage                  -0.00763756
exploration/num steps total              899000
exploration/num paths total                2059
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.20851
exploration/Rewards Std                       1.32027
exploration/Rewards Max                      10.6923
exploration/Rewards Min                      -0.432315
exploration/Returns Mean                   5208.51
exploration/Returns Std                       0
exploration/Returns Max                    5208.51
exploration/Returns Min                    5208.51
exploration/Num Paths                         1
exploration/Average Returns                5208.51
evaluation_0/num steps total                  7.06879e+06
evaluation_0/num paths total              15224
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.32825
evaluation_0/Rewards Std                      1.3644
evaluation_0/Rewards Max                     10.701
evaluation_0/Rewards Min                     -0.470112
evaluation_0/Returns Mean                  5328.25
evaluation_0/Returns Std                     45.9107
evaluation_0/Returns Max                   5399.82
evaluation_0/Returns Min                   5241.52
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5328.25
time/epoch (s)                                0
time/total (s)                            16918.2
Epoch                                       894
---------------------------------------  ----------------
2022-11-16 15:27:59.713653 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 895 finished
---------------------------------------  ----------------
epoch                                       895
total_step                               900000
replay_pool/size                         900000
trainer/alpha                                 0.0606754
trainer/alpha_loss                            0.581516
trainer/entropy                              -6.20753
trainer/qf_loss                               5.95566
trainer/state_noise                           0.005
trainer/policy_loss                        -232.372
trainer/policy_loss_without_entropy         234.67
trainer/entropy_penalty                      -0.376644
trainer/entropy_percentage                   -0.001605
trainer/Q1Pred Mean                         234.153
trainer/Q1Pred Std                           74.0964
trainer/Q1Pred Max                          322.614
trainer/Q1Pred Min                            6.13686
trainer/Q2Pred Mean                         234.277
trainer/Q2Pred Std                           74.3024
trainer/Q2Pred Max                          323.363
trainer/Q2Pred Min                            3.49646
trainer/QTargetWithReg Mean                 234.089
trainer/QTargetWithReg Std                   73.8886
trainer/QTargetWithReg Max                  323.429
trainer/QTargetWithReg Min                    3.28565
trainer/PolicyLossWithoutReg Mean           234.67
trainer/PolicyLossWithoutReg Std             73.2073
trainer/PolicyLossWithoutReg Max            322.41
trainer/PolicyLossWithoutReg Min              4.1453
trainer/gradient_norm                       384.308
trainer/gradient_penalty                     -1.92154
trainer/gradient_percentage                  -0.00818826
exploration/num steps total              900000
exploration/num paths total                2060
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07941
exploration/Rewards Std                       1.33591
exploration/Rewards Max                      10.3093
exploration/Rewards Min                      -0.480482
exploration/Returns Mean                   5079.41
exploration/Returns Std                       0
exploration/Returns Max                    5079.41
exploration/Returns Min                    5079.41
exploration/Num Paths                         1
exploration/Average Returns                5079.41
evaluation_0/num steps total                  7.07679e+06
evaluation_0/num paths total              15232
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.37905
evaluation_0/Rewards Std                      1.34924
evaluation_0/Rewards Max                     10.5941
evaluation_0/Rewards Min                     -0.465896
evaluation_0/Returns Mean                  5379.05
evaluation_0/Returns Std                     20.1595
evaluation_0/Returns Max                   5413.03
evaluation_0/Returns Min                   5350.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5379.05
time/epoch (s)                                0
time/total (s)                            16933.4
Epoch                                       895
---------------------------------------  ----------------
2022-11-16 15:28:16.016889 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 896 finished
---------------------------------------  ----------------
epoch                                       896
total_step                               901000
replay_pool/size                         901000
trainer/alpha                                 0.0607842
trainer/alpha_loss                            1.29509
trainer/entropy                              -6.46241
trainer/qf_loss                               5.36164
trainer/state_noise                           0.005
trainer/policy_loss                        -233.107
trainer/policy_loss_without_entropy         235.388
trainer/entropy_penalty                      -0.392812
trainer/entropy_percentage                   -0.00166878
trainer/Q1Pred Mean                         235.366
trainer/Q1Pred Std                           74.433
trainer/Q1Pred Max                          316.908
trainer/Q1Pred Min                           27.8308
trainer/Q2Pred Mean                         235.377
trainer/Q2Pred Std                           74.6058
trainer/Q2Pred Max                          318.754
trainer/Q2Pred Min                           24.1547
trainer/QTargetWithReg Mean                 234.856
trainer/QTargetWithReg Std                   74.6636
trainer/QTargetWithReg Max                  317.3
trainer/QTargetWithReg Min                   25.5027
trainer/PolicyLossWithoutReg Mean           235.388
trainer/PolicyLossWithoutReg Std             73.981
trainer/PolicyLossWithoutReg Max            316.868
trainer/PolicyLossWithoutReg Min             25.0524
trainer/gradient_norm                       377.793
trainer/gradient_penalty                     -1.88896
trainer/gradient_percentage                  -0.00802487
exploration/num steps total              901000
exploration/num paths total                2061
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13789
exploration/Rewards Std                       1.34135
exploration/Rewards Max                      10.7431
exploration/Rewards Min                      -0.403709
exploration/Returns Mean                   5137.89
exploration/Returns Std                       0
exploration/Returns Max                    5137.89
exploration/Returns Min                    5137.89
exploration/Num Paths                         1
exploration/Average Returns                5137.89
evaluation_0/num steps total                  7.08479e+06
evaluation_0/num paths total              15240
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25307
evaluation_0/Rewards Std                      1.32569
evaluation_0/Rewards Max                     10.5206
evaluation_0/Rewards Min                     -0.502535
evaluation_0/Returns Mean                  5253.07
evaluation_0/Returns Std                     44.5695
evaluation_0/Returns Max                   5310.62
evaluation_0/Returns Min                   5164.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5253.07
time/epoch (s)                                0
time/total (s)                            16949.7
Epoch                                       896
---------------------------------------  ----------------
2022-11-16 15:28:31.867011 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 897 finished
---------------------------------------  ----------------
epoch                                       897
total_step                               902000
replay_pool/size                         902000
trainer/alpha                                 0.0591681
trainer/alpha_loss                           -0.00216114
trainer/entropy                              -5.99924
trainer/qf_loss                             196.468
trainer/state_noise                           0.005
trainer/policy_loss                        -233.312
trainer/policy_loss_without_entropy         235.571
trainer/entropy_penalty                      -0.354964
trainer/entropy_percentage                   -0.00150682
trainer/Q1Pred Mean                         235.635
trainer/Q1Pred Std                           70.2368
trainer/Q1Pred Max                          320.462
trainer/Q1Pred Min                           23.7006
trainer/Q2Pred Mean                         235.349
trainer/Q2Pred Std                           70.0336
trainer/Q2Pred Max                          319.347
trainer/Q2Pred Min                           25.0118
trainer/QTargetWithReg Mean                 234.744
trainer/QTargetWithReg Std                   71.3237
trainer/QTargetWithReg Max                  320.074
trainer/QTargetWithReg Min                    5.31587
trainer/PolicyLossWithoutReg Mean           235.571
trainer/PolicyLossWithoutReg Std             69.273
trainer/PolicyLossWithoutReg Max            319.694
trainer/PolicyLossWithoutReg Min             23.522
trainer/gradient_norm                       380.816
trainer/gradient_penalty                     -1.90408
trainer/gradient_percentage                  -0.00808284
exploration/num steps total              902000
exploration/num paths total                2062
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09202
exploration/Rewards Std                       1.34619
exploration/Rewards Max                      10.2823
exploration/Rewards Min                      -0.437916
exploration/Returns Mean                   5092.02
exploration/Returns Std                       0
exploration/Returns Max                    5092.02
exploration/Returns Min                    5092.02
exploration/Num Paths                         1
exploration/Average Returns                5092.02
evaluation_0/num steps total                  7.09279e+06
evaluation_0/num paths total              15248
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29652
evaluation_0/Rewards Std                      1.32102
evaluation_0/Rewards Max                     10.5374
evaluation_0/Rewards Min                     -0.574941
evaluation_0/Returns Mean                  5296.52
evaluation_0/Returns Std                     32.5584
evaluation_0/Returns Max                   5345.13
evaluation_0/Returns Min                   5253.08
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5296.52
time/epoch (s)                                0
time/total (s)                            16965.5
Epoch                                       897
---------------------------------------  ----------------
2022-11-16 15:28:48.232712 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 898 finished
---------------------------------------  ----------------
epoch                                       898
total_step                               903000
replay_pool/size                         903000
trainer/alpha                                 0.0590377
trainer/alpha_loss                           -0.0892512
trainer/entropy                              -5.96846
trainer/qf_loss                               5.42658
trainer/state_noise                           0.005
trainer/policy_loss                        -232.911
trainer/policy_loss_without_entropy         235.167
trainer/entropy_penalty                      -0.352364
trainer/entropy_percentage                   -0.00149836
trainer/Q1Pred Mean                         234.602
trainer/Q1Pred Std                           79.8124
trainer/Q1Pred Max                          320.186
trainer/Q1Pred Min                           -6.05226
trainer/Q2Pred Mean                         234.526
trainer/Q2Pred Std                           79.6588
trainer/Q2Pred Max                          320.325
trainer/Q2Pred Min                           -1.16301
trainer/QTargetWithReg Mean                 234.653
trainer/QTargetWithReg Std                   79.1617
trainer/QTargetWithReg Max                  317.881
trainer/QTargetWithReg Min                   -0.952834
trainer/PolicyLossWithoutReg Mean           235.167
trainer/PolicyLossWithoutReg Std             79.3082
trainer/PolicyLossWithoutReg Max            318.191
trainer/PolicyLossWithoutReg Min             -6.29068
trainer/gradient_norm                       380.746
trainer/gradient_penalty                     -1.90373
trainer/gradient_percentage                  -0.00809523
exploration/num steps total              903000
exploration/num paths total                2063
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.28531
exploration/Rewards Std                       1.34096
exploration/Rewards Max                      10.3671
exploration/Rewards Min                      -0.499664
exploration/Returns Mean                   5285.31
exploration/Returns Std                       0
exploration/Returns Max                    5285.31
exploration/Returns Min                    5285.31
exploration/Num Paths                         1
exploration/Average Returns                5285.31
evaluation_0/num steps total                  7.10079e+06
evaluation_0/num paths total              15256
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.32385
evaluation_0/Rewards Std                      1.34147
evaluation_0/Rewards Max                     10.6808
evaluation_0/Rewards Min                     -0.517104
evaluation_0/Returns Mean                  5323.85
evaluation_0/Returns Std                     29.4764
evaluation_0/Returns Max                   5357.15
evaluation_0/Returns Min                   5264.86
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5323.85
time/epoch (s)                                0
time/total (s)                            16981.9
Epoch                                       898
---------------------------------------  ----------------
2022-11-16 15:29:04.151836 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 899 finished
---------------------------------------  ----------------
epoch                                       899
total_step                               904000
replay_pool/size                         904000
trainer/alpha                                 0.0601997
trainer/alpha_loss                            0.782413
trainer/entropy                              -6.27842
trainer/qf_loss                               6.85739
trainer/state_noise                           0.005
trainer/policy_loss                        -232.67
trainer/policy_loss_without_entropy         234.912
trainer/entropy_penalty                      -0.377959
trainer/entropy_percentage                   -0.00160894
trainer/Q1Pred Mean                         234.678
trainer/Q1Pred Std                           76.7637
trainer/Q1Pred Max                          322.855
trainer/Q1Pred Min                           24.0853
trainer/Q2Pred Mean                         234.583
trainer/Q2Pred Std                           76.6973
trainer/Q2Pred Max                          322.188
trainer/Q2Pred Min                           22.6739
trainer/QTargetWithReg Mean                 234.34
trainer/QTargetWithReg Std                   76.607
trainer/QTargetWithReg Max                  323.152
trainer/QTargetWithReg Min                   21.3271
trainer/PolicyLossWithoutReg Mean           234.911
trainer/PolicyLossWithoutReg Std             75.8627
trainer/PolicyLossWithoutReg Max            321.86
trainer/PolicyLossWithoutReg Min             23.0965
trainer/gradient_norm                       372.63
trainer/gradient_penalty                     -1.86315
trainer/gradient_percentage                  -0.00793128
exploration/num steps total              904000
exploration/num paths total                2064
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05632
exploration/Rewards Std                       1.36127
exploration/Rewards Max                      10.2866
exploration/Rewards Min                      -0.467555
exploration/Returns Mean                   5056.32
exploration/Returns Std                       0
exploration/Returns Max                    5056.32
exploration/Returns Min                    5056.32
exploration/Num Paths                         1
exploration/Average Returns                5056.32
evaluation_0/num steps total                  7.10879e+06
evaluation_0/num paths total              15264
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.24876
evaluation_0/Rewards Std                      1.3132
evaluation_0/Rewards Max                     10.3024
evaluation_0/Rewards Min                     -0.440704
evaluation_0/Returns Mean                  5248.76
evaluation_0/Returns Std                     10.2535
evaluation_0/Returns Max                   5267.42
evaluation_0/Returns Min                   5233.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5248.76
time/epoch (s)                                0
time/total (s)                            16997.8
Epoch                                       899
---------------------------------------  ----------------
2022-11-16 15:29:20.461217 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 900 finished
---------------------------------------  ----------------
epoch                                       900
total_step                               905000
replay_pool/size                         905000
trainer/alpha                                 0.0579751
trainer/alpha_loss                            0.731157
trainer/entropy                              -6.25675
trainer/qf_loss                               5.44178
trainer/state_noise                           0.005
trainer/policy_loss                        -225.89
trainer/policy_loss_without_entropy         228.101
trainer/entropy_penalty                      -0.362736
trainer/entropy_percentage                   -0.00159025
trainer/Q1Pred Mean                         227.974
trainer/Q1Pred Std                           76.7572
trainer/Q1Pred Max                          321.229
trainer/Q1Pred Min                            3.02647
trainer/Q2Pred Mean                         227.348
trainer/Q2Pred Std                           77.0987
trainer/Q2Pred Max                          320.548
trainer/Q2Pred Min                            6.50778
trainer/QTargetWithReg Mean                 227.629
trainer/QTargetWithReg Std                   76.9928
trainer/QTargetWithReg Max                  321.658
trainer/QTargetWithReg Min                    2.6775
trainer/PolicyLossWithoutReg Mean           228.101
trainer/PolicyLossWithoutReg Std             76.4229
trainer/PolicyLossWithoutReg Max            321.327
trainer/PolicyLossWithoutReg Min              3.40633
trainer/gradient_norm                       369.482
trainer/gradient_penalty                     -1.84741
trainer/gradient_percentage                  -0.00809909
exploration/num steps total              905000
exploration/num paths total                2065
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.28601
exploration/Rewards Std                       1.35604
exploration/Rewards Max                      10.3172
exploration/Rewards Min                      -0.58594
exploration/Returns Mean                   5286.01
exploration/Returns Std                       0
exploration/Returns Max                    5286.01
exploration/Returns Min                    5286.01
exploration/Num Paths                         1
exploration/Average Returns                5286.01
evaluation_0/num steps total                  7.11679e+06
evaluation_0/num paths total              15272
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29262
evaluation_0/Rewards Std                      1.3159
evaluation_0/Rewards Max                     10.4519
evaluation_0/Rewards Min                     -0.478487
evaluation_0/Returns Mean                  5292.62
evaluation_0/Returns Std                     17.0368
evaluation_0/Returns Max                   5327.17
evaluation_0/Returns Min                   5264.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5292.62
time/epoch (s)                                0
time/total (s)                            17014.1
Epoch                                       900
---------------------------------------  ----------------
2022-11-16 15:29:36.404013 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 901 finished
---------------------------------------  ----------------
epoch                                       901
total_step                               906000
replay_pool/size                         906000
trainer/alpha                                 0.0590676
trainer/alpha_loss                            0.759105
trainer/entropy                              -6.2683
trainer/qf_loss                               5.49923
trainer/state_noise                           0.005
trainer/policy_loss                        -229.058
trainer/policy_loss_without_entropy         231.271
trainer/entropy_penalty                      -0.370253
trainer/entropy_percentage                   -0.00160095
trainer/Q1Pred Mean                         230.432
trainer/Q1Pred Std                           72.5116
trainer/Q1Pred Max                          323.073
trainer/Q1Pred Min                            5.8598
trainer/Q2Pred Mean                         230.341
trainer/Q2Pred Std                           72.0602
trainer/Q2Pred Max                          321.629
trainer/Q2Pred Min                            8.02487
trainer/QTargetWithReg Mean                 230.468
trainer/QTargetWithReg Std                   72.6599
trainer/QTargetWithReg Max                  323.084
trainer/QTargetWithReg Min                    6.1223
trainer/PolicyLossWithoutReg Mean           231.271
trainer/PolicyLossWithoutReg Std             71.6983
trainer/PolicyLossWithoutReg Max            321.974
trainer/PolicyLossWithoutReg Min              7.14845
trainer/gradient_norm                       368.501
trainer/gradient_penalty                     -1.84251
trainer/gradient_percentage                  -0.00796688
exploration/num steps total              906000
exploration/num paths total                2066
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.27188
exploration/Rewards Std                       1.31912
exploration/Rewards Max                      10.4836
exploration/Rewards Min                      -0.494051
exploration/Returns Mean                   5271.88
exploration/Returns Std                       0
exploration/Returns Max                    5271.88
exploration/Returns Min                    5271.88
exploration/Num Paths                         1
exploration/Average Returns                5271.88
evaluation_0/num steps total                  7.12479e+06
evaluation_0/num paths total              15280
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.21111
evaluation_0/Rewards Std                      1.40501
evaluation_0/Rewards Max                     10.6973
evaluation_0/Rewards Min                     -0.419723
evaluation_0/Returns Mean                  5211.11
evaluation_0/Returns Std                     68.0356
evaluation_0/Returns Max                   5318.05
evaluation_0/Returns Min                   5097.24
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5211.11
time/epoch (s)                                0
time/total (s)                            17030.1
Epoch                                       901
---------------------------------------  ----------------
2022-11-16 15:29:52.283202 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 902 finished
---------------------------------------  ----------------
epoch                                       902
total_step                               907000
replay_pool/size                         907000
trainer/alpha                                 0.0599029
trainer/alpha_loss                           -0.351718
trainer/entropy                              -5.87506
trainer/qf_loss                               5.91799
trainer/state_noise                           0.005
trainer/policy_loss                        -228.355
trainer/policy_loss_without_entropy         230.531
trainer/entropy_penalty                      -0.351933
trainer/entropy_percentage                   -0.00152662
trainer/Q1Pred Mean                         229.643
trainer/Q1Pred Std                           75.0632
trainer/Q1Pred Max                          322.241
trainer/Q1Pred Min                            2.03998
trainer/Q2Pred Mean                         229.978
trainer/Q2Pred Std                           75.0096
trainer/Q2Pred Max                          322.466
trainer/Q2Pred Min                            2.43387
trainer/QTargetWithReg Mean                 229.357
trainer/QTargetWithReg Std                   74.9351
trainer/QTargetWithReg Max                  321.556
trainer/QTargetWithReg Min                    7.56421
trainer/PolicyLossWithoutReg Mean           230.531
trainer/PolicyLossWithoutReg Std             74.0842
trainer/PolicyLossWithoutReg Max            322.164
trainer/PolicyLossWithoutReg Min              3.83617
trainer/gradient_norm                       364.773
trainer/gradient_penalty                     -1.82387
trainer/gradient_percentage                  -0.0079116
exploration/num steps total              907000
exploration/num paths total                2067
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.03382
exploration/Rewards Std                       1.36345
exploration/Rewards Max                      10.4768
exploration/Rewards Min                      -0.527372
exploration/Returns Mean                   5033.82
exploration/Returns Std                       0
exploration/Returns Max                    5033.82
exploration/Returns Min                    5033.82
exploration/Num Paths                         1
exploration/Average Returns                5033.82
evaluation_0/num steps total                  7.13279e+06
evaluation_0/num paths total              15288
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.28769
evaluation_0/Rewards Std                      1.34054
evaluation_0/Rewards Max                     10.6674
evaluation_0/Rewards Min                     -0.499385
evaluation_0/Returns Mean                  5287.69
evaluation_0/Returns Std                     25.5539
evaluation_0/Returns Max                   5321.25
evaluation_0/Returns Min                   5251.36
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5287.69
time/epoch (s)                                0
time/total (s)                            17046
Epoch                                       902
---------------------------------------  ----------------
2022-11-16 15:30:08.677148 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 903 finished
---------------------------------------  ----------------
epoch                                       903
total_step                               908000
replay_pool/size                         908000
trainer/alpha                                 0.0588916
trainer/alpha_loss                            0.83545
trainer/entropy                              -6.29497
trainer/qf_loss                               6.59578
trainer/state_noise                           0.005
trainer/policy_loss                        -237.371
trainer/policy_loss_without_entropy         239.674
trainer/entropy_penalty                      -0.370721
trainer/entropy_percentage                   -0.00154677
trainer/Q1Pred Mean                         238.62
trainer/Q1Pred Std                           74.7538
trainer/Q1Pred Max                          319.528
trainer/Q1Pred Min                          -14.9531
trainer/Q2Pred Mean                         238.561
trainer/Q2Pred Std                           74.5325
trainer/Q2Pred Max                          319.412
trainer/Q2Pred Min                          -12.2467
trainer/QTargetWithReg Mean                 238.766
trainer/QTargetWithReg Std                   74.6432
trainer/QTargetWithReg Max                  321.321
trainer/QTargetWithReg Min                  -12.7675
trainer/PolicyLossWithoutReg Mean           239.674
trainer/PolicyLossWithoutReg Std             73.6107
trainer/PolicyLossWithoutReg Max            319.896
trainer/PolicyLossWithoutReg Min             -5.91138
trainer/gradient_norm                       386.456
trainer/gradient_penalty                     -1.93228
trainer/gradient_percentage                  -0.00806212
exploration/num steps total              908000
exploration/num paths total                2068
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.1073
exploration/Rewards Std                       1.33184
exploration/Rewards Max                      10.4595
exploration/Rewards Min                      -0.469541
exploration/Returns Mean                   5107.3
exploration/Returns Std                       0
exploration/Returns Max                    5107.3
exploration/Returns Min                    5107.3
exploration/Num Paths                         1
exploration/Average Returns                5107.3
evaluation_0/num steps total                  7.14079e+06
evaluation_0/num paths total              15296
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15565
evaluation_0/Rewards Std                      1.39095
evaluation_0/Rewards Max                     10.3515
evaluation_0/Rewards Min                     -0.541911
evaluation_0/Returns Mean                  5155.65
evaluation_0/Returns Std                     58.013
evaluation_0/Returns Max                   5236.45
evaluation_0/Returns Min                   5074.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5155.65
time/epoch (s)                                0
time/total (s)                            17062.3
Epoch                                       903
---------------------------------------  ----------------
2022-11-16 15:30:24.569167 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 904 finished
---------------------------------------  ----------------
epoch                                       904
total_step                               909000
replay_pool/size                         909000
trainer/alpha                                 0.0608294
trainer/alpha_loss                           -0.973706
trainer/entropy                              -5.65222
trainer/qf_loss                               5.20361
trainer/state_noise                           0.005
trainer/policy_loss                        -243.514
trainer/policy_loss_without_entropy         245.766
trainer/entropy_penalty                      -0.343821
trainer/entropy_percentage                   -0.00139898
trainer/Q1Pred Mean                         245.122
trainer/Q1Pred Std                           68.2018
trainer/Q1Pred Max                          320.059
trainer/Q1Pred Min                            5.74381
trainer/Q2Pred Mean                         245.484
trainer/Q2Pred Std                           67.4067
trainer/Q2Pred Max                          319.522
trainer/Q2Pred Min                            5.36414
trainer/QTargetWithReg Mean                 245.086
trainer/QTargetWithReg Std                   67.9665
trainer/QTargetWithReg Max                  321.921
trainer/QTargetWithReg Min                    6.33043
trainer/PolicyLossWithoutReg Mean           245.766
trainer/PolicyLossWithoutReg Std             67.0956
trainer/PolicyLossWithoutReg Max            319.471
trainer/PolicyLossWithoutReg Min              7.19765
trainer/gradient_norm                       381.502
trainer/gradient_penalty                     -1.90751
trainer/gradient_percentage                  -0.00776149
exploration/num steps total              909000
exploration/num paths total                2069
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05067
exploration/Rewards Std                       1.36997
exploration/Rewards Max                      10.3844
exploration/Rewards Min                      -0.65373
exploration/Returns Mean                   5050.67
exploration/Returns Std                       0
exploration/Returns Max                    5050.67
exploration/Returns Min                    5050.67
exploration/Num Paths                         1
exploration/Average Returns                5050.67
evaluation_0/num steps total                  7.14879e+06
evaluation_0/num paths total              15304
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03797
evaluation_0/Rewards Std                      1.36993
evaluation_0/Rewards Max                     10.4381
evaluation_0/Rewards Min                     -0.550085
evaluation_0/Returns Mean                  5037.97
evaluation_0/Returns Std                     73.9836
evaluation_0/Returns Max                   5133.3
evaluation_0/Returns Min                   4930.91
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5037.97
time/epoch (s)                                0
time/total (s)                            17078.2
Epoch                                       904
---------------------------------------  ----------------
2022-11-16 15:30:41.181156 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 905 finished
---------------------------------------  ----------------
epoch                                       905
total_step                               910000
replay_pool/size                         910000
trainer/alpha                                 0.0607057
trainer/alpha_loss                           -1.17607
trainer/entropy                              -5.58021
trainer/qf_loss                              11.4327
trainer/state_noise                           0.005
trainer/policy_loss                        -241.423
trainer/policy_loss_without_entropy         243.671
trainer/entropy_penalty                      -0.338751
trainer/entropy_percentage                   -0.0013902
trainer/Q1Pred Mean                         242.317
trainer/Q1Pred Std                           68.1692
trainer/Q1Pred Max                          317.153
trainer/Q1Pred Min                           24.2477
trainer/Q2Pred Mean                         242.919
trainer/Q2Pred Std                           68.3102
trainer/Q2Pred Max                          318.486
trainer/Q2Pred Min                           24.0399
trainer/QTargetWithReg Mean                 242.271
trainer/QTargetWithReg Std                   68.6459
trainer/QTargetWithReg Max                  317.844
trainer/QTargetWithReg Min                   26.5261
trainer/PolicyLossWithoutReg Mean           243.671
trainer/PolicyLossWithoutReg Std             67.7568
trainer/PolicyLossWithoutReg Max            317.544
trainer/PolicyLossWithoutReg Min             24.795
trainer/gradient_norm                       381.827
trainer/gradient_penalty                     -1.90914
trainer/gradient_percentage                  -0.00783488
exploration/num steps total              910000
exploration/num paths total                2070
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0112
exploration/Rewards Std                       1.37593
exploration/Rewards Max                      10.1482
exploration/Rewards Min                      -0.497454
exploration/Returns Mean                   5011.2
exploration/Returns Std                       0
exploration/Returns Max                    5011.2
exploration/Returns Min                    5011.2
exploration/Num Paths                         1
exploration/Average Returns                5011.2
evaluation_0/num steps total                  7.15679e+06
evaluation_0/num paths total              15312
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19925
evaluation_0/Rewards Std                      1.2967
evaluation_0/Rewards Max                     10.4348
evaluation_0/Rewards Min                     -0.528706
evaluation_0/Returns Mean                  5199.25
evaluation_0/Returns Std                     15.8433
evaluation_0/Returns Max                   5227.83
evaluation_0/Returns Min                   5180.22
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5199.25
time/epoch (s)                                0
time/total (s)                            17094.8
Epoch                                       905
---------------------------------------  ----------------
2022-11-16 15:30:57.062753 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 906 finished
---------------------------------------  ----------------
epoch                                       906
total_step                               911000
replay_pool/size                         911000
trainer/alpha                                 0.0607533
trainer/alpha_loss                           -0.926835
trainer/entropy                              -5.66908
trainer/qf_loss                               6.42228
trainer/state_noise                           0.005
trainer/policy_loss                        -234.822
trainer/policy_loss_without_entropy         237.015
trainer/entropy_penalty                      -0.344415
trainer/entropy_percentage                   -0.00145314
trainer/Q1Pred Mean                         236.699
trainer/Q1Pred Std                           74.4405
trainer/Q1Pred Max                          322.089
trainer/Q1Pred Min                            4.49998
trainer/Q2Pred Mean                         235.923
trainer/Q2Pred Std                           74.4809
trainer/Q2Pred Max                          320.413
trainer/Q2Pred Min                            4.30908
trainer/QTargetWithReg Mean                 236.373
trainer/QTargetWithReg Std                   74.7228
trainer/QTargetWithReg Max                  322.089
trainer/QTargetWithReg Min                    3.58512
trainer/PolicyLossWithoutReg Mean           237.015
trainer/PolicyLossWithoutReg Std             73.4452
trainer/PolicyLossWithoutReg Max            320.405
trainer/PolicyLossWithoutReg Min              5.63434
trainer/gradient_norm                       369.831
trainer/gradient_penalty                     -1.84915
trainer/gradient_percentage                  -0.00780184
exploration/num steps total              911000
exploration/num paths total                2071
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16532
exploration/Rewards Std                       1.33074
exploration/Rewards Max                      10.6546
exploration/Rewards Min                      -0.426967
exploration/Returns Mean                   5165.32
exploration/Returns Std                       0
exploration/Returns Max                    5165.32
exploration/Returns Min                    5165.32
exploration/Num Paths                         1
exploration/Average Returns                5165.32
evaluation_0/num steps total                  7.16479e+06
evaluation_0/num paths total              15320
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18941
evaluation_0/Rewards Std                      1.33047
evaluation_0/Rewards Max                     10.3748
evaluation_0/Rewards Min                     -0.543331
evaluation_0/Returns Mean                  5189.41
evaluation_0/Returns Std                     22.491
evaluation_0/Returns Max                   5212.15
evaluation_0/Returns Min                   5136.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5189.41
time/epoch (s)                                0
time/total (s)                            17110.7
Epoch                                       906
---------------------------------------  ----------------
2022-11-16 15:31:13.596721 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 907 finished
---------------------------------------  ----------------
epoch                                       907
total_step                               912000
replay_pool/size                         912000
trainer/alpha                                 0.05972
trainer/alpha_loss                           -0.0979447
trainer/entropy                              -5.96524
trainer/qf_loss                               7.87859
trainer/state_noise                           0.005
trainer/policy_loss                        -228.106
trainer/policy_loss_without_entropy         230.377
trainer/entropy_penalty                      -0.356244
trainer/entropy_percentage                   -0.00154636
trainer/Q1Pred Mean                         229.865
trainer/Q1Pred Std                           80.7548
trainer/Q1Pred Max                          322.531
trainer/Q1Pred Min                          -19.1986
trainer/Q2Pred Mean                         229.848
trainer/Q2Pred Std                           81.1521
trainer/Q2Pred Max                          321.584
trainer/Q2Pred Min                          -23.8204
trainer/QTargetWithReg Mean                 229.429
trainer/QTargetWithReg Std                   80.731
trainer/QTargetWithReg Max                  321.793
trainer/QTargetWithReg Min                  -18.9689
trainer/PolicyLossWithoutReg Mean           230.377
trainer/PolicyLossWithoutReg Std             79.5881
trainer/PolicyLossWithoutReg Max            320.981
trainer/PolicyLossWithoutReg Min            -18.2645
trainer/gradient_norm                       382.847
trainer/gradient_penalty                     -1.91424
trainer/gradient_percentage                  -0.00830916
exploration/num steps total              912000
exploration/num paths total                2072
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14711
exploration/Rewards Std                       1.29695
exploration/Rewards Max                      10.28
exploration/Rewards Min                      -0.500218
exploration/Returns Mean                   5147.11
exploration/Returns Std                       0
exploration/Returns Max                    5147.11
exploration/Returns Min                    5147.11
exploration/Num Paths                         1
exploration/Average Returns                5147.11
evaluation_0/num steps total                  7.17279e+06
evaluation_0/num paths total              15328
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13241
evaluation_0/Rewards Std                      1.31429
evaluation_0/Rewards Max                     10.227
evaluation_0/Rewards Min                     -0.45663
evaluation_0/Returns Mean                  5132.41
evaluation_0/Returns Std                     30.0506
evaluation_0/Returns Max                   5192.94
evaluation_0/Returns Min                   5095.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5132.41
time/epoch (s)                                0
time/total (s)                            17127.3
Epoch                                       907
---------------------------------------  ----------------
2022-11-16 15:31:29.436164 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 908 finished
---------------------------------------  ----------------
epoch                                       908
total_step                               913000
replay_pool/size                         913000
trainer/alpha                                 0.0597606
trainer/alpha_loss                            1.30316
trainer/entropy                              -6.46253
trainer/qf_loss                               5.54311
trainer/state_noise                           0.005
trainer/policy_loss                        -232.228
trainer/policy_loss_without_entropy         234.486
trainer/entropy_penalty                      -0.386205
trainer/entropy_percentage                   -0.00164703
trainer/Q1Pred Mean                         233.469
trainer/Q1Pred Std                           71.4174
trainer/Q1Pred Max                          316.713
trainer/Q1Pred Min                           25.0981
trainer/Q2Pred Mean                         234.086
trainer/Q2Pred Std                           71.4942
trainer/Q2Pred Max                          318.452
trainer/Q2Pred Min                           25.5861
trainer/QTargetWithReg Mean                 233.458
trainer/QTargetWithReg Std                   71.4806
trainer/QTargetWithReg Max                  316.332
trainer/QTargetWithReg Min                   25.5333
trainer/PolicyLossWithoutReg Mean           234.486
trainer/PolicyLossWithoutReg Std             70.7062
trainer/PolicyLossWithoutReg Max            316.942
trainer/PolicyLossWithoutReg Min             26.013
trainer/gradient_norm                       374.3
trainer/gradient_penalty                     -1.8715
trainer/gradient_percentage                  -0.00798129
exploration/num steps total              913000
exploration/num paths total                2073
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16731
exploration/Rewards Std                       1.31389
exploration/Rewards Max                      10.4401
exploration/Rewards Min                      -0.440823
exploration/Returns Mean                   5167.31
exploration/Returns Std                       0
exploration/Returns Max                    5167.31
exploration/Returns Min                    5167.31
exploration/Num Paths                         1
exploration/Average Returns                5167.31
evaluation_0/num steps total                  7.18079e+06
evaluation_0/num paths total              15336
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26474
evaluation_0/Rewards Std                      1.3388
evaluation_0/Rewards Max                     10.5339
evaluation_0/Rewards Min                     -0.475376
evaluation_0/Returns Mean                  5264.74
evaluation_0/Returns Std                     16.4738
evaluation_0/Returns Max                   5284.49
evaluation_0/Returns Min                   5228.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5264.74
time/epoch (s)                                0
time/total (s)                            17143.1
Epoch                                       908
---------------------------------------  ----------------
2022-11-16 15:31:45.784165 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 909 finished
---------------------------------------  ----------------
epoch                                       909
total_step                               914000
replay_pool/size                         914000
trainer/alpha                                 0.0604854
trainer/alpha_loss                           -0.064839
trainer/entropy                              -5.97689
trainer/qf_loss                               5.42471
trainer/state_noise                           0.005
trainer/policy_loss                        -230.429
trainer/policy_loss_without_entropy         232.684
trainer/entropy_penalty                      -0.361515
trainer/entropy_percentage                   -0.00155367
trainer/Q1Pred Mean                         232.13
trainer/Q1Pred Std                           76.8475
trainer/Q1Pred Max                          321.391
trainer/Q1Pred Min                            0.742078
trainer/Q2Pred Mean                         231.838
trainer/Q2Pred Std                           77.1465
trainer/Q2Pred Max                          321.841
trainer/Q2Pred Min                           -1.3641
trainer/QTargetWithReg Mean                 232.196
trainer/QTargetWithReg Std                   76.7564
trainer/QTargetWithReg Max                  321.334
trainer/QTargetWithReg Min                    2.71291
trainer/PolicyLossWithoutReg Mean           232.684
trainer/PolicyLossWithoutReg Std             76.4906
trainer/PolicyLossWithoutReg Max            321.502
trainer/PolicyLossWithoutReg Min             -1.68123
trainer/gradient_norm                       378.784
trainer/gradient_penalty                     -1.89392
trainer/gradient_percentage                  -0.00813944
exploration/num steps total              914000
exploration/num paths total                2074
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09488
exploration/Rewards Std                       1.30826
exploration/Rewards Max                      10.2768
exploration/Rewards Min                      -0.454347
exploration/Returns Mean                   5094.88
exploration/Returns Std                       0
exploration/Returns Max                    5094.88
exploration/Returns Min                    5094.88
exploration/Num Paths                         1
exploration/Average Returns                5094.88
evaluation_0/num steps total                  7.18879e+06
evaluation_0/num paths total              15344
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.20317
evaluation_0/Rewards Std                      1.31492
evaluation_0/Rewards Max                     10.3956
evaluation_0/Rewards Min                     -0.528381
evaluation_0/Returns Mean                  5203.17
evaluation_0/Returns Std                     33.6527
evaluation_0/Returns Max                   5246.44
evaluation_0/Returns Min                   5156.23
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5203.17
time/epoch (s)                                0
time/total (s)                            17159.5
Epoch                                       909
---------------------------------------  ----------------
2022-11-16 15:32:01.892651 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 910 finished
---------------------------------------  ----------------
epoch                                       910
total_step                               915000
replay_pool/size                         915000
trainer/alpha                                 0.0611748
trainer/alpha_loss                           -0.777626
trainer/entropy                              -5.72168
trainer/qf_loss                               5.75836
trainer/state_noise                           0.005
trainer/policy_loss                        -236.8
trainer/policy_loss_without_entropy         238.996
trainer/entropy_penalty                      -0.350022
trainer/entropy_percentage                   -0.00146455
trainer/Q1Pred Mean                         238.879
trainer/Q1Pred Std                           71.1204
trainer/Q1Pred Max                          320.909
trainer/Q1Pred Min                           -1.01391
trainer/Q2Pred Mean                         238.775
trainer/Q2Pred Std                           71.0094
trainer/Q2Pred Max                          319.213
trainer/Q2Pred Min                            0.148165
trainer/QTargetWithReg Mean                 238.766
trainer/QTargetWithReg Std                   70.5611
trainer/QTargetWithReg Max                  319.319
trainer/QTargetWithReg Min                    0.904848
trainer/PolicyLossWithoutReg Mean           238.996
trainer/PolicyLossWithoutReg Std             70.4583
trainer/PolicyLossWithoutReg Max            319.086
trainer/PolicyLossWithoutReg Min             -0.529487
trainer/gradient_norm                       369.14
trainer/gradient_penalty                     -1.8457
trainer/gradient_percentage                  -0.00772272
exploration/num steps total              915000
exploration/num paths total                2075
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15571
exploration/Rewards Std                       1.3899
exploration/Rewards Max                      10.4469
exploration/Rewards Min                      -0.47009
exploration/Returns Mean                   5155.71
exploration/Returns Std                       0
exploration/Returns Max                    5155.71
exploration/Returns Min                    5155.71
exploration/Num Paths                         1
exploration/Average Returns                5155.71
evaluation_0/num steps total                  7.19679e+06
evaluation_0/num paths total              15352
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.20148
evaluation_0/Rewards Std                      1.32832
evaluation_0/Rewards Max                     10.4135
evaluation_0/Rewards Min                     -0.537204
evaluation_0/Returns Mean                  5201.48
evaluation_0/Returns Std                     12.1476
evaluation_0/Returns Max                   5226.39
evaluation_0/Returns Min                   5183.66
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5201.48
time/epoch (s)                                0
time/total (s)                            17175.6
Epoch                                       910
---------------------------------------  ----------------
2022-11-16 15:32:17.922756 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 911 finished
---------------------------------------  ----------------
epoch                                       911
total_step                               916000
replay_pool/size                         916000
trainer/alpha                                 0.0610778
trainer/alpha_loss                           -0.91749
trainer/entropy                              -5.6718
trainer/qf_loss                               7.89996
trainer/state_noise                           0.005
trainer/policy_loss                        -231.325
trainer/policy_loss_without_entropy         233.515
trainer/entropy_penalty                      -0.346421
trainer/entropy_percentage                   -0.00148351
trainer/Q1Pred Mean                         232.072
trainer/Q1Pred Std                           70.467
trainer/Q1Pred Max                          320.945
trainer/Q1Pred Min                            5.48949
trainer/Q2Pred Mean                         232.541
trainer/Q2Pred Std                           70.0888
trainer/Q2Pred Max                          321.388
trainer/Q2Pred Min                            9.75152
trainer/QTargetWithReg Mean                 232.749
trainer/QTargetWithReg Std                   70.3304
trainer/QTargetWithReg Max                  320.961
trainer/QTargetWithReg Min                    7.06873
trainer/PolicyLossWithoutReg Mean           233.515
trainer/PolicyLossWithoutReg Std             69.8266
trainer/PolicyLossWithoutReg Max            321.826
trainer/PolicyLossWithoutReg Min              6.96645
trainer/gradient_norm                       368.583
trainer/gradient_penalty                     -1.84292
trainer/gradient_percentage                  -0.00789208
exploration/num steps total              916000
exploration/num paths total                2076
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.25334
exploration/Rewards Std                       1.32508
exploration/Rewards Max                      10.3977
exploration/Rewards Min                      -0.526822
exploration/Returns Mean                   5253.34
exploration/Returns Std                       0
exploration/Returns Max                    5253.34
exploration/Returns Min                    5253.34
exploration/Num Paths                         1
exploration/Average Returns                5253.34
evaluation_0/num steps total                  7.20479e+06
evaluation_0/num paths total              15360
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17438
evaluation_0/Rewards Std                      1.32516
evaluation_0/Rewards Max                     10.3798
evaluation_0/Rewards Min                     -0.471517
evaluation_0/Returns Mean                  5174.38
evaluation_0/Returns Std                     19.7609
evaluation_0/Returns Max                   5211.83
evaluation_0/Returns Min                   5149.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5174.38
time/epoch (s)                                0
time/total (s)                            17191.6
Epoch                                       911
---------------------------------------  ----------------
2022-11-16 15:32:34.206721 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 912 finished
---------------------------------------  ----------------
epoch                                       912
total_step                               917000
replay_pool/size                         917000
trainer/alpha                                 0.0581071
trainer/alpha_loss                            0.965785
trainer/entropy                              -6.33938
trainer/qf_loss                               7.48575
trainer/state_noise                           0.005
trainer/policy_loss                        -239.672
trainer/policy_loss_without_entropy         242.021
trainer/entropy_penalty                      -0.368363
trainer/entropy_percentage                   -0.00152203
trainer/Q1Pred Mean                         241.806
trainer/Q1Pred Std                           72.71
trainer/Q1Pred Max                          320.964
trainer/Q1Pred Min                            5.98718
trainer/Q2Pred Mean                         241.708
trainer/Q2Pred Std                           73.2714
trainer/Q2Pred Max                          320.524
trainer/Q2Pred Min                            4.08592
trainer/QTargetWithReg Mean                 241.452
trainer/QTargetWithReg Std                   73.1782
trainer/QTargetWithReg Max                  320.319
trainer/QTargetWithReg Min                    3.72003
trainer/PolicyLossWithoutReg Mean           242.021
trainer/PolicyLossWithoutReg Std             72.3329
trainer/PolicyLossWithoutReg Max            320.546
trainer/PolicyLossWithoutReg Min              6.0368
trainer/gradient_norm                       396.189
trainer/gradient_penalty                     -1.98094
trainer/gradient_percentage                  -0.00818501
exploration/num steps total              917000
exploration/num paths total                2077
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.09964
exploration/Rewards Std                       1.35581
exploration/Rewards Max                      10.4465
exploration/Rewards Min                      -0.499741
exploration/Returns Mean                   5099.64
exploration/Returns Std                       0
exploration/Returns Max                    5099.64
exploration/Returns Min                    5099.64
exploration/Num Paths                         1
exploration/Average Returns                5099.64
evaluation_0/num steps total                  7.21279e+06
evaluation_0/num paths total              15368
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.39313
evaluation_0/Rewards Std                      1.40689
evaluation_0/Rewards Max                     10.7434
evaluation_0/Rewards Min                     -0.627487
evaluation_0/Returns Mean                  5393.13
evaluation_0/Returns Std                     30.6179
evaluation_0/Returns Max                   5441.6
evaluation_0/Returns Min                   5325.75
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5393.13
time/epoch (s)                                0
time/total (s)                            17207.9
Epoch                                       912
---------------------------------------  ----------------
2022-11-16 15:32:50.131592 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 913 finished
---------------------------------------  ----------------
epoch                                       913
total_step                               918000
replay_pool/size                         918000
trainer/alpha                                 0.0589693
trainer/alpha_loss                            0.347061
trainer/entropy                              -6.1226
trainer/qf_loss                              10.6442
trainer/state_noise                           0.005
trainer/policy_loss                        -234.358
trainer/policy_loss_without_entropy         236.639
trainer/entropy_penalty                      -0.361045
trainer/entropy_percentage                   -0.00152572
trainer/Q1Pred Mean                         236.536
trainer/Q1Pred Std                           74.6288
trainer/Q1Pred Max                          319.685
trainer/Q1Pred Min                           40.2985
trainer/Q2Pred Mean                         236.843
trainer/Q2Pred Std                           74.559
trainer/Q2Pred Max                          319.102
trainer/Q2Pred Min                           41.1085
trainer/QTargetWithReg Mean                 235.143
trainer/QTargetWithReg Std                   74.7008
trainer/QTargetWithReg Max                  323.579
trainer/QTargetWithReg Min                   41.0763
trainer/PolicyLossWithoutReg Mean           236.639
trainer/PolicyLossWithoutReg Std             73.5255
trainer/PolicyLossWithoutReg Max            319.142
trainer/PolicyLossWithoutReg Min             40.5234
trainer/gradient_norm                       384.117
trainer/gradient_penalty                     -1.92059
trainer/gradient_percentage                  -0.00811609
exploration/num steps total              918000
exploration/num paths total                2078
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99191
exploration/Rewards Std                       1.38461
exploration/Rewards Max                      10.428
exploration/Rewards Min                      -0.520923
exploration/Returns Mean                   4991.91
exploration/Returns Std                       0
exploration/Returns Max                    4991.91
exploration/Returns Min                    4991.91
exploration/Num Paths                         1
exploration/Average Returns                4991.91
evaluation_0/num steps total                  7.22079e+06
evaluation_0/num paths total              15376
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11818
evaluation_0/Rewards Std                      1.419
evaluation_0/Rewards Max                     10.3521
evaluation_0/Rewards Min                     -0.587852
evaluation_0/Returns Mean                  5118.18
evaluation_0/Returns Std                     46.6611
evaluation_0/Returns Max                   5239.12
evaluation_0/Returns Min                   5081.35
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5118.18
time/epoch (s)                                0
time/total (s)                            17223.8
Epoch                                       913
---------------------------------------  ----------------
2022-11-16 15:33:06.602077 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 914 finished
---------------------------------------  ----------------
epoch                                       914
total_step                               919000
replay_pool/size                         919000
trainer/alpha                                 0.0586762
trainer/alpha_loss                            0.141332
trainer/entropy                              -6.04984
trainer/qf_loss                              10.5195
trainer/state_noise                           0.005
trainer/policy_loss                        -234.462
trainer/policy_loss_without_entropy         236.647
trainer/entropy_penalty                      -0.354981
trainer/entropy_percentage                   -0.00150005
trainer/Q1Pred Mean                         235.643
trainer/Q1Pred Std                           77.2482
trainer/Q1Pred Max                          322.487
trainer/Q1Pred Min                          -14.999
trainer/Q2Pred Mean                         236.205
trainer/Q2Pred Std                           77.3867
trainer/Q2Pred Max                          322.721
trainer/Q2Pred Min                          -14.2679
trainer/QTargetWithReg Mean                 236.395
trainer/QTargetWithReg Std                   77.6635
trainer/QTargetWithReg Max                  323.475
trainer/QTargetWithReg Min                  -11.9529
trainer/PolicyLossWithoutReg Mean           236.647
trainer/PolicyLossWithoutReg Std             76.8804
trainer/PolicyLossWithoutReg Max            323.077
trainer/PolicyLossWithoutReg Min             -6.13129
trainer/gradient_norm                       365.965
trainer/gradient_penalty                     -1.82982
trainer/gradient_percentage                  -0.0077323
exploration/num steps total              919000
exploration/num paths total                2079
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01752
exploration/Rewards Std                       1.44049
exploration/Rewards Max                      10.3394
exploration/Rewards Min                      -0.609739
exploration/Returns Mean                   5017.52
exploration/Returns Std                       0
exploration/Returns Max                    5017.52
exploration/Returns Min                    5017.52
exploration/Num Paths                         1
exploration/Average Returns                5017.52
evaluation_0/num steps total                  7.22879e+06
evaluation_0/num paths total              15384
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16008
evaluation_0/Rewards Std                      1.45754
evaluation_0/Rewards Max                     10.6621
evaluation_0/Rewards Min                     -0.706898
evaluation_0/Returns Mean                  5160.08
evaluation_0/Returns Std                     20.1694
evaluation_0/Returns Max                   5184.01
evaluation_0/Returns Min                   5128.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5160.08
time/epoch (s)                                0
time/total (s)                            17240.3
Epoch                                       914
---------------------------------------  ----------------
2022-11-16 15:33:22.429558 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 915 finished
---------------------------------------  ----------------
epoch                                       915
total_step                               920000
replay_pool/size                         920000
trainer/alpha                                 0.0591034
trainer/alpha_loss                            0.243549
trainer/entropy                              -6.0861
trainer/qf_loss                               6.51151
trainer/state_noise                           0.005
trainer/policy_loss                        -232.391
trainer/policy_loss_without_entropy         234.621
trainer/entropy_penalty                      -0.359709
trainer/entropy_percentage                   -0.00153315
trainer/Q1Pred Mean                         234.154
trainer/Q1Pred Std                           78.4495
trainer/Q1Pred Max                          320.594
trainer/Q1Pred Min                            5.71643
trainer/Q2Pred Mean                         234.192
trainer/Q2Pred Std                           78.7019
trainer/Q2Pred Max                          322.561
trainer/Q2Pred Min                            3.36917
trainer/QTargetWithReg Mean                 233.971
trainer/QTargetWithReg Std                   78.36
trainer/QTargetWithReg Max                  320.451
trainer/QTargetWithReg Min                    4.64678
trainer/PolicyLossWithoutReg Mean           234.621
trainer/PolicyLossWithoutReg Std             78.0018
trainer/PolicyLossWithoutReg Max            321.254
trainer/PolicyLossWithoutReg Min              4.581
trainer/gradient_norm                       374.11
trainer/gradient_penalty                     -1.87055
trainer/gradient_percentage                  -0.00797263
exploration/num steps total              920000
exploration/num paths total                2080
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88943
exploration/Rewards Std                       1.35562
exploration/Rewards Max                      10.4241
exploration/Rewards Min                      -0.705245
exploration/Returns Mean                   4889.43
exploration/Returns Std                       0
exploration/Returns Max                    4889.43
exploration/Returns Min                    4889.43
exploration/Num Paths                         1
exploration/Average Returns                4889.43
evaluation_0/num steps total                  7.23679e+06
evaluation_0/num paths total              15392
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25035
evaluation_0/Rewards Std                      1.35166
evaluation_0/Rewards Max                     10.4564
evaluation_0/Rewards Min                     -0.531628
evaluation_0/Returns Mean                  5250.35
evaluation_0/Returns Std                     24.9603
evaluation_0/Returns Max                   5277.92
evaluation_0/Returns Min                   5191.92
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5250.35
time/epoch (s)                                0
time/total (s)                            17256.1
Epoch                                       915
---------------------------------------  ----------------
2022-11-16 15:33:38.906007 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 916 finished
---------------------------------------  ----------------
epoch                                       916
total_step                               921000
replay_pool/size                         921000
trainer/alpha                                 0.0582711
trainer/alpha_loss                            0.00959147
trainer/entropy                              -6.00337
trainer/qf_loss                               7.87773
trainer/state_noise                           0.005
trainer/policy_loss                        -230.335
trainer/policy_loss_without_entropy         232.513
trainer/entropy_penalty                      -0.349823
trainer/entropy_percentage                   -0.00150453
trainer/Q1Pred Mean                         231.634
trainer/Q1Pred Std                           78.9358
trainer/Q1Pred Max                          321.924
trainer/Q1Pred Min                            7.11798
trainer/Q2Pred Mean                         232.067
trainer/Q2Pred Std                           78.5577
trainer/Q2Pred Max                          322.993
trainer/Q2Pred Min                           11.6903
trainer/QTargetWithReg Mean                 232.469
trainer/QTargetWithReg Std                   79.139
trainer/QTargetWithReg Max                  323.257
trainer/QTargetWithReg Min                   11.0685
trainer/PolicyLossWithoutReg Mean           232.513
trainer/PolicyLossWithoutReg Std             77.93
trainer/PolicyLossWithoutReg Max            322.429
trainer/PolicyLossWithoutReg Min             10.9442
trainer/gradient_norm                       365.698
trainer/gradient_penalty                     -1.82849
trainer/gradient_percentage                  -0.00786402
exploration/num steps total              921000
exploration/num paths total                2081
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.20999
exploration/Rewards Std                       1.34548
exploration/Rewards Max                      10.524
exploration/Rewards Min                      -0.562046
exploration/Returns Mean                   5209.99
exploration/Returns Std                       0
exploration/Returns Max                    5209.99
exploration/Returns Min                    5209.99
exploration/Num Paths                         1
exploration/Average Returns                5209.99
evaluation_0/num steps total                  7.24479e+06
evaluation_0/num paths total              15400
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.20814
evaluation_0/Rewards Std                      1.34578
evaluation_0/Rewards Max                     10.5841
evaluation_0/Rewards Min                     -0.571686
evaluation_0/Returns Mean                  5208.14
evaluation_0/Returns Std                     81.8059
evaluation_0/Returns Max                   5336.15
evaluation_0/Returns Min                   5067.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5208.14
time/epoch (s)                                0
time/total (s)                            17272.6
Epoch                                       916
---------------------------------------  ----------------
2022-11-16 15:33:54.741111 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 917 finished
---------------------------------------  ----------------
epoch                                       917
total_step                               922000
replay_pool/size                         922000
trainer/alpha                                 0.0600148
trainer/alpha_loss                            0.184085
trainer/entropy                              -6.06543
trainer/qf_loss                               8.26049
trainer/state_noise                           0.005
trainer/policy_loss                        -237.766
trainer/policy_loss_without_entropy         240.02
trainer/entropy_penalty                      -0.364016
trainer/entropy_percentage                   -0.00151661
trainer/Q1Pred Mean                         239.144
trainer/Q1Pred Std                           69.5803
trainer/Q1Pred Max                          321.652
trainer/Q1Pred Min                            4.04231
trainer/Q2Pred Mean                         239.084
trainer/Q2Pred Std                           70.056
trainer/Q2Pred Max                          322.562
trainer/Q2Pred Min                            3.54453
trainer/QTargetWithReg Mean                 240.097
trainer/QTargetWithReg Std                   69.7951
trainer/QTargetWithReg Max                  322.756
trainer/QTargetWithReg Min                   10.2581
trainer/PolicyLossWithoutReg Mean           240.02
trainer/PolicyLossWithoutReg Std             69.0658
trainer/PolicyLossWithoutReg Max            322.623
trainer/PolicyLossWithoutReg Min              7.74234
trainer/gradient_norm                       377.974
trainer/gradient_penalty                     -1.88987
trainer/gradient_percentage                  -0.00787381
exploration/num steps total              922000
exploration/num paths total                2082
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12007
exploration/Rewards Std                       1.35016
exploration/Rewards Max                      10.615
exploration/Rewards Min                      -0.693192
exploration/Returns Mean                   5120.07
exploration/Returns Std                       0
exploration/Returns Max                    5120.07
exploration/Returns Min                    5120.07
exploration/Num Paths                         1
exploration/Average Returns                5120.07
evaluation_0/num steps total                  7.25279e+06
evaluation_0/num paths total              15408
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16744
evaluation_0/Rewards Std                      1.35766
evaluation_0/Rewards Max                     10.3895
evaluation_0/Rewards Min                     -0.499357
evaluation_0/Returns Mean                  5167.44
evaluation_0/Returns Std                     10.3833
evaluation_0/Returns Max                   5178.05
evaluation_0/Returns Min                   5142.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5167.44
time/epoch (s)                                0
time/total (s)                            17288.4
Epoch                                       917
---------------------------------------  ----------------
2022-11-16 15:34:10.915457 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 918 finished
---------------------------------------  ----------------
epoch                                       918
total_step                               923000
replay_pool/size                         923000
trainer/alpha                                 0.0599145
trainer/alpha_loss                            0.194406
trainer/entropy                              -6.06906
trainer/qf_loss                               6.45689
trainer/state_noise                           0.005
trainer/policy_loss                        -239.443
trainer/policy_loss_without_entropy         241.664
trainer/entropy_penalty                      -0.363625
trainer/entropy_percentage                   -0.00150467
trainer/Q1Pred Mean                         241.09
trainer/Q1Pred Std                           76.2297
trainer/Q1Pred Max                          321.3
trainer/Q1Pred Min                            5.48085
trainer/Q2Pred Mean                         240.685
trainer/Q2Pred Std                           76.6934
trainer/Q2Pred Max                          321.033
trainer/Q2Pred Min                            0.782222
trainer/QTargetWithReg Mean                 240.877
trainer/QTargetWithReg Std                   76.2128
trainer/QTargetWithReg Max                  320.755
trainer/QTargetWithReg Min                    0.704363
trainer/PolicyLossWithoutReg Mean           241.664
trainer/PolicyLossWithoutReg Std             76.1124
trainer/PolicyLossWithoutReg Max            321.299
trainer/PolicyLossWithoutReg Min             -1.07463
trainer/gradient_norm                       371.519
trainer/gradient_penalty                     -1.85759
trainer/gradient_percentage                  -0.00768668
exploration/num steps total              923000
exploration/num paths total                2083
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11489
exploration/Rewards Std                       1.34887
exploration/Rewards Max                      10.3787
exploration/Rewards Min                      -0.381001
exploration/Returns Mean                   5114.89
exploration/Returns Std                       0
exploration/Returns Max                    5114.89
exploration/Returns Min                    5114.89
exploration/Num Paths                         1
exploration/Average Returns                5114.89
evaluation_0/num steps total                  7.26079e+06
evaluation_0/num paths total              15416
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22068
evaluation_0/Rewards Std                      1.32437
evaluation_0/Rewards Max                     10.6402
evaluation_0/Rewards Min                     -0.564051
evaluation_0/Returns Mean                  5220.68
evaluation_0/Returns Std                     60.9568
evaluation_0/Returns Max                   5278.72
evaluation_0/Returns Min                   5074.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5220.68
time/epoch (s)                                0
time/total (s)                            17304.6
Epoch                                       918
---------------------------------------  ----------------
2022-11-16 15:34:27.054509 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 919 finished
---------------------------------------  ----------------
epoch                                       919
total_step                               924000
replay_pool/size                         924000
trainer/alpha                                 0.0594427
trainer/alpha_loss                           -0.957905
trainer/entropy                              -5.66062
trainer/qf_loss                               5.44651
trainer/state_noise                           0.005
trainer/policy_loss                        -235.149
trainer/policy_loss_without_entropy         237.346
trainer/entropy_penalty                      -0.336482
trainer/entropy_percentage                   -0.00141769
trainer/Q1Pred Mean                         236.226
trainer/Q1Pred Std                           73.5245
trainer/Q1Pred Max                          323.801
trainer/Q1Pred Min                           14.6147
trainer/Q2Pred Mean                         236.578
trainer/Q2Pred Std                           73.6975
trainer/Q2Pred Max                          324.971
trainer/Q2Pred Min                           14.7679
trainer/QTargetWithReg Mean                 236.751
trainer/QTargetWithReg Std                   73.5867
trainer/QTargetWithReg Max                  323.88
trainer/QTargetWithReg Min                   14.3597
trainer/PolicyLossWithoutReg Mean           237.346
trainer/PolicyLossWithoutReg Std             73.0254
trainer/PolicyLossWithoutReg Max            324.357
trainer/PolicyLossWithoutReg Min             16.0525
trainer/gradient_norm                       372.118
trainer/gradient_penalty                     -1.86059
trainer/gradient_percentage                  -0.00783915
exploration/num steps total              924000
exploration/num paths total                2084
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19685
exploration/Rewards Std                       1.33831
exploration/Rewards Max                      10.3061
exploration/Rewards Min                      -0.629555
exploration/Returns Mean                   5196.85
exploration/Returns Std                       0
exploration/Returns Max                    5196.85
exploration/Returns Min                    5196.85
exploration/Num Paths                         1
exploration/Average Returns                5196.85
evaluation_0/num steps total                  7.26879e+06
evaluation_0/num paths total              15424
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29146
evaluation_0/Rewards Std                      1.37627
evaluation_0/Rewards Max                     10.6203
evaluation_0/Rewards Min                     -0.64202
evaluation_0/Returns Mean                  5291.46
evaluation_0/Returns Std                     45.4683
evaluation_0/Returns Max                   5361
evaluation_0/Returns Min                   5219.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5291.46
time/epoch (s)                                0
time/total (s)                            17320.7
Epoch                                       919
---------------------------------------  ----------------
2022-11-16 15:34:42.891384 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 920 finished
---------------------------------------  ----------------
epoch                                       920
total_step                               925000
replay_pool/size                         925000
trainer/alpha                                 0.0591181
trainer/alpha_loss                            0.516817
trainer/entropy                              -6.18274
trainer/qf_loss                               9.60717
trainer/state_noise                           0.005
trainer/policy_loss                        -223.268
trainer/policy_loss_without_entropy         225.412
trainer/entropy_penalty                      -0.365512
trainer/entropy_percentage                   -0.00162153
trainer/Q1Pred Mean                         223.917
trainer/Q1Pred Std                           87.4889
trainer/Q1Pred Max                          321.621
trainer/Q1Pred Min                            4.08213
trainer/Q2Pred Mean                         224.343
trainer/Q2Pred Std                           87.1581
trainer/Q2Pred Max                          320.864
trainer/Q2Pred Min                            3.97659
trainer/QTargetWithReg Mean                 224.116
trainer/QTargetWithReg Std                   87.2714
trainer/QTargetWithReg Max                  319.885
trainer/QTargetWithReg Min                    0.70673
trainer/PolicyLossWithoutReg Mean           225.412
trainer/PolicyLossWithoutReg Std             85.9405
trainer/PolicyLossWithoutReg Max            320.073
trainer/PolicyLossWithoutReg Min              3.40801
trainer/gradient_norm                       355.724
trainer/gradient_penalty                     -1.77862
trainer/gradient_percentage                  -0.00789053
exploration/num steps total              925000
exploration/num paths total                2085
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.94771
exploration/Rewards Std                       1.42061
exploration/Rewards Max                      10.5296
exploration/Rewards Min                      -0.591429
exploration/Returns Mean                   4947.71
exploration/Returns Std                       0
exploration/Returns Max                    4947.71
exploration/Returns Min                    4947.71
exploration/Num Paths                         1
exploration/Average Returns                4947.71
evaluation_0/num steps total                  7.27679e+06
evaluation_0/num paths total              15432
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15322
evaluation_0/Rewards Std                      1.48488
evaluation_0/Rewards Max                     10.6528
evaluation_0/Rewards Min                     -0.669042
evaluation_0/Returns Mean                  5153.22
evaluation_0/Returns Std                     27.6666
evaluation_0/Returns Max                   5185.09
evaluation_0/Returns Min                   5091.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5153.22
time/epoch (s)                                0
time/total (s)                            17336.6
Epoch                                       920
---------------------------------------  ----------------
2022-11-16 15:34:59.357450 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 921 finished
---------------------------------------  ----------------
epoch                                       921
total_step                               926000
replay_pool/size                         926000
trainer/alpha                                 0.0615253
trainer/alpha_loss                            0.830435
trainer/entropy                              -6.29782
trainer/qf_loss                               5.12392
trainer/state_noise                           0.005
trainer/policy_loss                        -235.609
trainer/policy_loss_without_entropy         237.781
trainer/entropy_penalty                      -0.387475
trainer/entropy_percentage                   -0.00162954
trainer/Q1Pred Mean                         237.128
trainer/Q1Pred Std                           72.1139
trainer/Q1Pred Max                          319.88
trainer/Q1Pred Min                            9.29013
trainer/Q2Pred Mean                         237.646
trainer/Q2Pred Std                           71.9753
trainer/Q2Pred Max                          321.474
trainer/Q2Pred Min                           10.38
trainer/QTargetWithReg Mean                 237.452
trainer/QTargetWithReg Std                   72.1217
trainer/QTargetWithReg Max                  321.054
trainer/QTargetWithReg Min                   10.5661
trainer/PolicyLossWithoutReg Mean           237.781
trainer/PolicyLossWithoutReg Std             71.4246
trainer/PolicyLossWithoutReg Max            319.183
trainer/PolicyLossWithoutReg Min              9.28951
trainer/gradient_norm                       356.998
trainer/gradient_penalty                     -1.78499
trainer/gradient_percentage                  -0.00750686
exploration/num steps total              926000
exploration/num paths total                2086
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84572
exploration/Rewards Std                       1.44851
exploration/Rewards Max                      10.1822
exploration/Rewards Min                      -0.604068
exploration/Returns Mean                   4845.72
exploration/Returns Std                       0
exploration/Returns Max                    4845.72
exploration/Returns Min                    4845.72
exploration/Num Paths                         1
exploration/Average Returns                4845.72
evaluation_0/num steps total                  7.28479e+06
evaluation_0/num paths total              15440
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08449
evaluation_0/Rewards Std                      1.34392
evaluation_0/Rewards Max                     10.3512
evaluation_0/Rewards Min                     -0.585166
evaluation_0/Returns Mean                  5084.49
evaluation_0/Returns Std                     23.2151
evaluation_0/Returns Max                   5135.7
evaluation_0/Returns Min                   5058.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5084.49
time/epoch (s)                                0
time/total (s)                            17353
Epoch                                       921
---------------------------------------  ----------------
2022-11-16 15:35:15.151800 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 922 finished
---------------------------------------  ----------------
epoch                                       922
total_step                               927000
replay_pool/size                         927000
trainer/alpha                                 0.0584352
trainer/alpha_loss                            0.301921
trainer/entropy                              -6.10632
trainer/qf_loss                               6.70791
trainer/state_noise                           0.005
trainer/policy_loss                        -235.876
trainer/policy_loss_without_entropy         238.116
trainer/entropy_penalty                      -0.356824
trainer/entropy_percentage                   -0.00149853
trainer/Q1Pred Mean                         237.363
trainer/Q1Pred Std                           78.074
trainer/Q1Pred Max                          322.597
trainer/Q1Pred Min                          -10.4799
trainer/Q2Pred Mean                         237.311
trainer/Q2Pred Std                           78.1187
trainer/Q2Pred Max                          322.936
trainer/Q2Pred Min                          -14.91
trainer/QTargetWithReg Mean                 237.155
trainer/QTargetWithReg Std                   78.244
trainer/QTargetWithReg Max                  322.304
trainer/QTargetWithReg Min                    0.261482
trainer/PolicyLossWithoutReg Mean           238.116
trainer/PolicyLossWithoutReg Std             76.2944
trainer/PolicyLossWithoutReg Max            322.528
trainer/PolicyLossWithoutReg Min             19.6041
trainer/gradient_norm                       376.634
trainer/gradient_penalty                     -1.88317
trainer/gradient_percentage                  -0.00790862
exploration/num steps total              927000
exploration/num paths total                2087
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16894
exploration/Rewards Std                       1.33372
exploration/Rewards Max                      10.2701
exploration/Rewards Min                      -0.441525
exploration/Returns Mean                   5168.94
exploration/Returns Std                       0
exploration/Returns Max                    5168.94
exploration/Returns Min                    5168.94
exploration/Num Paths                         1
exploration/Average Returns                5168.94
evaluation_0/num steps total                  7.29279e+06
evaluation_0/num paths total              15448
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15139
evaluation_0/Rewards Std                      1.35563
evaluation_0/Rewards Max                     10.5271
evaluation_0/Rewards Min                     -0.49612
evaluation_0/Returns Mean                  5151.39
evaluation_0/Returns Std                     47.997
evaluation_0/Returns Max                   5220.1
evaluation_0/Returns Min                   5065.76
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5151.39
time/epoch (s)                                0
time/total (s)                            17368.8
Epoch                                       922
---------------------------------------  ----------------
2022-11-16 15:35:33.098835 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 923 finished
---------------------------------------  ----------------
epoch                                       923
total_step                               928000
replay_pool/size                         928000
trainer/alpha                                 0.0587488
trainer/alpha_loss                            0.572195
trainer/entropy                              -6.20188
trainer/qf_loss                              11.259
trainer/state_noise                           0.005
trainer/policy_loss                        -237.057
trainer/policy_loss_without_entropy         239.362
trainer/entropy_penalty                      -0.364353
trainer/entropy_percentage                   -0.00152218
trainer/Q1Pred Mean                         238.701
trainer/Q1Pred Std                           75.6879
trainer/Q1Pred Max                          327.071
trainer/Q1Pred Min                            0.88123
trainer/Q2Pred Mean                         238.776
trainer/Q2Pred Std                           76.0258
trainer/Q2Pred Max                          329.359
trainer/Q2Pred Min                           -2.82259
trainer/QTargetWithReg Mean                 238.589
trainer/QTargetWithReg Std                   75.8872
trainer/QTargetWithReg Max                  327.062
trainer/QTargetWithReg Min                   -0.442858
trainer/PolicyLossWithoutReg Mean           239.362
trainer/PolicyLossWithoutReg Std             74.529
trainer/PolicyLossWithoutReg Max            326.997
trainer/PolicyLossWithoutReg Min              4.54027
trainer/gradient_norm                       388.18
trainer/gradient_penalty                     -1.9409
trainer/gradient_percentage                  -0.00810863
exploration/num steps total              928000
exploration/num paths total                2088
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17057
exploration/Rewards Std                       1.36636
exploration/Rewards Max                      10.8532
exploration/Rewards Min                      -0.481604
exploration/Returns Mean                   5170.57
exploration/Returns Std                       0
exploration/Returns Max                    5170.57
exploration/Returns Min                    5170.57
exploration/Num Paths                         1
exploration/Average Returns                5170.57
evaluation_0/num steps total                  7.30000e+06
evaluation_0/num paths total              15456
evaluation_0/path length Mean               902.125
evaluation_0/path length Std                258.953
evaluation_0/path length Max               1000
evaluation_0/path length Min                217
evaluation_0/Rewards Mean                     4.97578
evaluation_0/Rewards Std                      1.59948
evaluation_0/Rewards Max                     10.8063
evaluation_0/Rewards Min                     -0.590775
evaluation_0/Returns Mean                  4488.78
evaluation_0/Returns Std                   1423.1
evaluation_0/Returns Max                   5231.37
evaluation_0/Returns Min                    738.899
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4488.78
time/epoch (s)                                0
time/total (s)                            17386.8
Epoch                                       923
---------------------------------------  ----------------
2022-11-16 15:35:50.505195 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 924 finished
---------------------------------------  ----------------
epoch                                       924
total_step                               929000
replay_pool/size                         929000
trainer/alpha                                 0.0584244
trainer/alpha_loss                            0.856444
trainer/entropy                              -6.30155
trainer/qf_loss                              11.7035
trainer/state_noise                           0.005
trainer/policy_loss                        -232.974
trainer/policy_loss_without_entropy         235.192
trainer/entropy_penalty                      -0.368164
trainer/entropy_percentage                   -0.00156538
trainer/Q1Pred Mean                         234.243
trainer/Q1Pred Std                           81.7352
trainer/Q1Pred Max                          320.087
trainer/Q1Pred Min                          -15.0068
trainer/Q2Pred Mean                         234.554
trainer/Q2Pred Std                           80.7809
trainer/Q2Pred Max                          317.916
trainer/Q2Pred Min                            2.29064
trainer/QTargetWithReg Mean                 234.951
trainer/QTargetWithReg Std                   81.3523
trainer/QTargetWithReg Max                  320.131
trainer/QTargetWithReg Min                   -2.04151
trainer/PolicyLossWithoutReg Mean           235.192
trainer/PolicyLossWithoutReg Std             80.853
trainer/PolicyLossWithoutReg Max            318.767
trainer/PolicyLossWithoutReg Min             -1.69
trainer/gradient_norm                       369.966
trainer/gradient_penalty                     -1.84983
trainer/gradient_percentage                  -0.00786518
exploration/num steps total              929000
exploration/num paths total                2089
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11783
exploration/Rewards Std                       1.4047
exploration/Rewards Max                      10.5566
exploration/Rewards Min                      -0.599564
exploration/Returns Mean                   5117.83
exploration/Returns Std                       0
exploration/Returns Max                    5117.83
exploration/Returns Min                    5117.83
exploration/Num Paths                         1
exploration/Average Returns                5117.83
evaluation_0/num steps total                  7.30736e+06
evaluation_0/num paths total              15464
evaluation_0/path length Mean               918.875
evaluation_0/path length Std                214.637
evaluation_0/path length Max               1000
evaluation_0/path length Min                351
evaluation_0/Rewards Mean                     4.73793
evaluation_0/Rewards Std                      1.478
evaluation_0/Rewards Max                     10.3272
evaluation_0/Rewards Min                     -0.765746
evaluation_0/Returns Mean                  4353.57
evaluation_0/Returns Std                   1140.61
evaluation_0/Returns Max                   4900.02
evaluation_0/Returns Min                   1342.11
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4353.57
time/epoch (s)                                0
time/total (s)                            17404.2
Epoch                                       924
---------------------------------------  ----------------
2022-11-16 15:36:06.931485 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 925 finished
---------------------------------------  ----------------
epoch                                       925
total_step                               930000
replay_pool/size                         930000
trainer/alpha                                 0.0601285
trainer/alpha_loss                           -0.608557
trainer/entropy                              -5.78352
trainer/qf_loss                               9.11868
trainer/state_noise                           0.005
trainer/policy_loss                        -244.402
trainer/policy_loss_without_entropy         246.692
trainer/entropy_penalty                      -0.347755
trainer/entropy_percentage                   -0.00140967
trainer/Q1Pred Mean                         245.982
trainer/Q1Pred Std                           70.6504
trainer/Q1Pred Max                          323.485
trainer/Q1Pred Min                            0.883322
trainer/Q2Pred Mean                         246.501
trainer/Q2Pred Std                           70.6958
trainer/Q2Pred Max                          324.325
trainer/Q2Pred Min                            2.35928
trainer/QTargetWithReg Mean                 245.797
trainer/QTargetWithReg Std                   70.4178
trainer/QTargetWithReg Max                  324.36
trainer/QTargetWithReg Min                  -15.1862
trainer/PolicyLossWithoutReg Mean           246.692
trainer/PolicyLossWithoutReg Std             69.065
trainer/PolicyLossWithoutReg Max            324.064
trainer/PolicyLossWithoutReg Min             29.7488
trainer/gradient_norm                       388.449
trainer/gradient_penalty                     -1.94225
trainer/gradient_percentage                  -0.00787317
exploration/num steps total              930000
exploration/num paths total                2090
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95069
exploration/Rewards Std                       1.43605
exploration/Rewards Max                      10.5402
exploration/Rewards Min                      -0.688739
exploration/Returns Mean                   4950.69
exploration/Returns Std                       0
exploration/Returns Max                    4950.69
exploration/Returns Min                    4950.69
exploration/Num Paths                         1
exploration/Average Returns                4950.69
evaluation_0/num steps total                  7.31536e+06
evaluation_0/num paths total              15472
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.03563
evaluation_0/Rewards Std                      1.46497
evaluation_0/Rewards Max                     10.5014
evaluation_0/Rewards Min                     -0.715911
evaluation_0/Returns Mean                  5035.63
evaluation_0/Returns Std                    109.036
evaluation_0/Returns Max                   5215.82
evaluation_0/Returns Min                   4898.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5035.63
time/epoch (s)                                0
time/total (s)                            17420.6
Epoch                                       925
---------------------------------------  ----------------
2022-11-16 15:36:24.413010 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 926 finished
---------------------------------------  ----------------
epoch                                       926
total_step                               931000
replay_pool/size                         931000
trainer/alpha                                 0.0608734
trainer/alpha_loss                           -0.681594
trainer/entropy                              -5.75648
trainer/qf_loss                              13.0541
trainer/state_noise                           0.005
trainer/policy_loss                        -229.901
trainer/policy_loss_without_entropy         232.112
trainer/entropy_penalty                      -0.350417
trainer/entropy_percentage                   -0.00150969
trainer/Q1Pred Mean                         231.266
trainer/Q1Pred Std                           81.2227
trainer/Q1Pred Max                          317.46
trainer/Q1Pred Min                          -42.5846
trainer/Q2Pred Mean                         231.537
trainer/Q2Pred Std                           80.8704
trainer/Q2Pred Max                          316.576
trainer/Q2Pred Min                          -41.2855
trainer/QTargetWithReg Mean                 231.398
trainer/QTargetWithReg Std                   80.6815
trainer/QTargetWithReg Max                  316.083
trainer/QTargetWithReg Min                    1.02365
trainer/PolicyLossWithoutReg Mean           232.112
trainer/PolicyLossWithoutReg Std             80.3121
trainer/PolicyLossWithoutReg Max            316.051
trainer/PolicyLossWithoutReg Min            -30.154
trainer/gradient_norm                       372.106
trainer/gradient_penalty                     -1.86053
trainer/gradient_percentage                  -0.00801566
exploration/num steps total              931000
exploration/num paths total                2091
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.84645
exploration/Rewards Std                       1.50407
exploration/Rewards Max                      10.5606
exploration/Rewards Min                      -0.629399
exploration/Returns Mean                   4846.45
exploration/Returns Std                       0
exploration/Returns Max                    4846.45
exploration/Returns Min                    4846.45
exploration/Num Paths                         1
exploration/Average Returns                4846.45
evaluation_0/num steps total                  7.32261e+06
evaluation_0/num paths total              15480
evaluation_0/path length Mean               907.125
evaluation_0/path length Std                245.724
evaluation_0/path length Max               1000
evaluation_0/path length Min                257
evaluation_0/Rewards Mean                     4.8976
evaluation_0/Rewards Std                      1.45357
evaluation_0/Rewards Max                     10.3292
evaluation_0/Rewards Min                     -0.655449
evaluation_0/Returns Mean                  4442.73
evaluation_0/Returns Std                   1337.67
evaluation_0/Returns Max                   5037.39
evaluation_0/Returns Min                    908.603
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4442.73
time/epoch (s)                                0
time/total (s)                            17438.1
Epoch                                       926
---------------------------------------  ----------------
2022-11-16 15:36:40.465792 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 927 finished
---------------------------------------  ----------------
epoch                                       927
total_step                               932000
replay_pool/size                         932000
trainer/alpha                                 0.059354
trainer/alpha_loss                            0.937542
trainer/entropy                              -6.33192
trainer/qf_loss                              26.8234
trainer/state_noise                           0.005
trainer/policy_loss                        -235.559
trainer/policy_loss_without_entropy         237.858
trainer/entropy_penalty                      -0.375825
trainer/entropy_percentage                   -0.00158004
trainer/Q1Pred Mean                         237.377
trainer/Q1Pred Std                           76.2302
trainer/Q1Pred Max                          328.736
trainer/Q1Pred Min                           -5.79806
trainer/Q2Pred Mean                         237.691
trainer/Q2Pred Std                           76.2389
trainer/Q2Pred Max                          328.252
trainer/Q2Pred Min                           -5.58849
trainer/QTargetWithReg Mean                 237.259
trainer/QTargetWithReg Std                   76.1488
trainer/QTargetWithReg Max                  326.44
trainer/QTargetWithReg Min                   -4.89684
trainer/PolicyLossWithoutReg Mean           237.858
trainer/PolicyLossWithoutReg Std             75.361
trainer/PolicyLossWithoutReg Max            328.11
trainer/PolicyLossWithoutReg Min             -3.4488
trainer/gradient_norm                       384.649
trainer/gradient_penalty                     -1.92324
trainer/gradient_percentage                  -0.00808569
exploration/num steps total              932000
exploration/num paths total                2092
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.96954
exploration/Rewards Std                       1.39972
exploration/Rewards Max                      10.5433
exploration/Rewards Min                      -0.5504
exploration/Returns Mean                   4969.54
exploration/Returns Std                       0
exploration/Returns Max                    4969.54
exploration/Returns Min                    4969.54
exploration/Num Paths                         1
exploration/Average Returns                4969.54
evaluation_0/num steps total                  7.33061e+06
evaluation_0/num paths total              15488
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26466
evaluation_0/Rewards Std                      1.36136
evaluation_0/Rewards Max                     10.6278
evaluation_0/Rewards Min                     -0.683978
evaluation_0/Returns Mean                  5264.66
evaluation_0/Returns Std                     34.3547
evaluation_0/Returns Max                   5338.82
evaluation_0/Returns Min                   5208.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5264.66
time/epoch (s)                                0
time/total (s)                            17454.1
Epoch                                       927
---------------------------------------  ----------------
2022-11-16 15:36:56.761438 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 928 finished
---------------------------------------  ----------------
epoch                                       928
total_step                               933000
replay_pool/size                         933000
trainer/alpha                                 0.0593399
trainer/alpha_loss                           -0.133694
trainer/entropy                              -5.95266
trainer/qf_loss                               5.45246
trainer/state_noise                           0.005
trainer/policy_loss                        -235.302
trainer/policy_loss_without_entropy         237.495
trainer/entropy_penalty                      -0.35323
trainer/entropy_percentage                   -0.00148732
trainer/Q1Pred Mean                         236.732
trainer/Q1Pred Std                           71.5547
trainer/Q1Pred Max                          321.708
trainer/Q1Pred Min                           35.8731
trainer/Q2Pred Mean                         236.935
trainer/Q2Pred Std                           71.5155
trainer/Q2Pred Max                          322.031
trainer/Q2Pred Min                           35.4401
trainer/QTargetWithReg Mean                 237.322
trainer/QTargetWithReg Std                   71.4881
trainer/QTargetWithReg Max                  321.746
trainer/QTargetWithReg Min                   33.696
trainer/PolicyLossWithoutReg Mean           237.495
trainer/PolicyLossWithoutReg Std             71.1312
trainer/PolicyLossWithoutReg Max            321.538
trainer/PolicyLossWithoutReg Min             36.9066
trainer/gradient_norm                       368.058
trainer/gradient_penalty                     -1.84029
trainer/gradient_percentage                  -0.00774874
exploration/num steps total              933000
exploration/num paths total                2093
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.29873
exploration/Rewards Std                       1.37539
exploration/Rewards Max                      10.508
exploration/Rewards Min                      -0.684119
exploration/Returns Mean                   5298.73
exploration/Returns Std                       0
exploration/Returns Max                    5298.73
exploration/Returns Min                    5298.73
exploration/Num Paths                         1
exploration/Average Returns                5298.73
evaluation_0/num steps total                  7.33861e+06
evaluation_0/num paths total              15496
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14016
evaluation_0/Rewards Std                      1.36404
evaluation_0/Rewards Max                     10.572
evaluation_0/Rewards Min                     -0.645145
evaluation_0/Returns Mean                  5140.16
evaluation_0/Returns Std                     25.7268
evaluation_0/Returns Max                   5167.88
evaluation_0/Returns Min                   5090.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5140.16
time/epoch (s)                                0
time/total (s)                            17470.4
Epoch                                       928
---------------------------------------  ----------------
2022-11-16 15:37:12.560729 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 929 finished
---------------------------------------  ----------------
epoch                                       929
total_step                               934000
replay_pool/size                         934000
trainer/alpha                                 0.0602973
trainer/alpha_loss                            0.604468
trainer/entropy                              -6.21522
trainer/qf_loss                               6.53051
trainer/state_noise                           0.005
trainer/policy_loss                        -228.81
trainer/policy_loss_without_entropy         231.066
trainer/entropy_penalty                      -0.374761
trainer/entropy_percentage                   -0.00162188
trainer/Q1Pred Mean                         230.305
trainer/Q1Pred Std                           80.6578
trainer/Q1Pred Max                          320.034
trainer/Q1Pred Min                            0.427507
trainer/Q2Pred Mean                         230.503
trainer/Q2Pred Std                           80.6499
trainer/Q2Pred Max                          319.073
trainer/Q2Pred Min                            5.40787
trainer/QTargetWithReg Mean                 229.989
trainer/QTargetWithReg Std                   80.5614
trainer/QTargetWithReg Max                  320.719
trainer/QTargetWithReg Min                    2.91896
trainer/PolicyLossWithoutReg Mean           231.066
trainer/PolicyLossWithoutReg Std             80.0247
trainer/PolicyLossWithoutReg Max            320.081
trainer/PolicyLossWithoutReg Min              2.41965
trainer/gradient_norm                       376.215
trainer/gradient_penalty                     -1.88107
trainer/gradient_percentage                  -0.00814084
exploration/num steps total              934000
exploration/num paths total                2094
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10053
exploration/Rewards Std                       1.32865
exploration/Rewards Max                      10.3582
exploration/Rewards Min                      -0.608767
exploration/Returns Mean                   5100.53
exploration/Returns Std                       0
exploration/Returns Max                    5100.53
exploration/Returns Min                    5100.53
exploration/Num Paths                         1
exploration/Average Returns                5100.53
evaluation_0/num steps total                  7.34661e+06
evaluation_0/num paths total              15504
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26711
evaluation_0/Rewards Std                      1.38154
evaluation_0/Rewards Max                     10.5549
evaluation_0/Rewards Min                     -0.636835
evaluation_0/Returns Mean                  5267.11
evaluation_0/Returns Std                     26.2821
evaluation_0/Returns Max                   5316.04
evaluation_0/Returns Min                   5239.44
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5267.11
time/epoch (s)                                0
time/total (s)                            17486.2
Epoch                                       929
---------------------------------------  ----------------
2022-11-16 15:37:29.106678 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 930 finished
---------------------------------------  ----------------
epoch                                       930
total_step                               935000
replay_pool/size                         935000
trainer/alpha                                 0.0582994
trainer/alpha_loss                            1.46277
trainer/entropy                              -6.51465
trainer/qf_loss                               8.87764
trainer/state_noise                           0.005
trainer/policy_loss                        -231.438
trainer/policy_loss_without_entropy         233.586
trainer/entropy_penalty                      -0.379801
trainer/entropy_percentage                   -0.00162595
trainer/Q1Pred Mean                         233.279
trainer/Q1Pred Std                           75.0869
trainer/Q1Pred Max                          321.26
trainer/Q1Pred Min                          -14.4719
trainer/Q2Pred Mean                         233.175
trainer/Q2Pred Std                           75.0051
trainer/Q2Pred Max                          320.706
trainer/Q2Pred Min                           -4.35628
trainer/QTargetWithReg Mean                 232.613
trainer/QTargetWithReg Std                   74.8636
trainer/QTargetWithReg Max                  320.842
trainer/QTargetWithReg Min                   -3.80316
trainer/PolicyLossWithoutReg Mean           233.586
trainer/PolicyLossWithoutReg Std             73.0551
trainer/PolicyLossWithoutReg Max            319.696
trainer/PolicyLossWithoutReg Min             -6.72198
trainer/gradient_norm                       353.674
trainer/gradient_penalty                     -1.76837
trainer/gradient_percentage                  -0.00757052
exploration/num steps total              935000
exploration/num paths total                2095
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05935
exploration/Rewards Std                       1.46102
exploration/Rewards Max                      10.4225
exploration/Rewards Min                      -0.726538
exploration/Returns Mean                   5059.35
exploration/Returns Std                       0
exploration/Returns Max                    5059.35
exploration/Returns Min                    5059.35
exploration/Num Paths                         1
exploration/Average Returns                5059.35
evaluation_0/num steps total                  7.35461e+06
evaluation_0/num paths total              15512
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.2009
evaluation_0/Rewards Std                      1.28748
evaluation_0/Rewards Max                     10.3841
evaluation_0/Rewards Min                     -0.433817
evaluation_0/Returns Mean                  5200.9
evaluation_0/Returns Std                     19.5567
evaluation_0/Returns Max                   5236.47
evaluation_0/Returns Min                   5167.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5200.9
time/epoch (s)                                0
time/total (s)                            17502.8
Epoch                                       930
---------------------------------------  ----------------
2022-11-16 15:37:44.946013 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 931 finished
---------------------------------------  ----------------
epoch                                       931
total_step                               936000
replay_pool/size                         936000
trainer/alpha                                 0.0591701
trainer/alpha_loss                           -0.639542
trainer/entropy                              -5.77378
trainer/qf_loss                               5.92388
trainer/state_noise                           0.005
trainer/policy_loss                        -244.141
trainer/policy_loss_without_entropy         246.365
trainer/entropy_penalty                      -0.341635
trainer/entropy_percentage                   -0.0013867
trainer/Q1Pred Mean                         245.579
trainer/Q1Pred Std                           66.4058
trainer/Q1Pred Max                          325.066
trainer/Q1Pred Min                           23.6184
trainer/Q2Pred Mean                         246.208
trainer/Q2Pred Std                           66.7242
trainer/Q2Pred Max                          327.067
trainer/Q2Pred Min                           24.1845
trainer/QTargetWithReg Mean                 245.442
trainer/QTargetWithReg Std                   66.8251
trainer/QTargetWithReg Max                  325.757
trainer/QTargetWithReg Min                   23.8226
trainer/PolicyLossWithoutReg Mean           246.365
trainer/PolicyLossWithoutReg Std             65.5126
trainer/PolicyLossWithoutReg Max            325.421
trainer/PolicyLossWithoutReg Min             23.786
trainer/gradient_norm                       376.374
trainer/gradient_penalty                     -1.88187
trainer/gradient_percentage                  -0.00763854
exploration/num steps total              936000
exploration/num paths total                2096
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11422
exploration/Rewards Std                       1.29009
exploration/Rewards Max                      10.1061
exploration/Rewards Min                      -0.370548
exploration/Returns Mean                   5114.22
exploration/Returns Std                       0
exploration/Returns Max                    5114.22
exploration/Returns Min                    5114.22
exploration/Num Paths                         1
exploration/Average Returns                5114.22
evaluation_0/num steps total                  7.36261e+06
evaluation_0/num paths total              15520
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.26275
evaluation_0/Rewards Std                      1.337
evaluation_0/Rewards Max                     10.6453
evaluation_0/Rewards Min                     -0.479376
evaluation_0/Returns Mean                  5262.75
evaluation_0/Returns Std                     22.9625
evaluation_0/Returns Max                   5295.25
evaluation_0/Returns Min                   5226.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5262.75
time/epoch (s)                                0
time/total (s)                            17518.6
Epoch                                       931
---------------------------------------  ----------------
2022-11-16 15:38:01.578832 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 932 finished
---------------------------------------  ----------------
epoch                                       932
total_step                               937000
replay_pool/size                         937000
trainer/alpha                                 0.0577784
trainer/alpha_loss                            0.945416
trainer/entropy                              -6.33157
trainer/qf_loss                               6.67539
trainer/state_noise                           0.005
trainer/policy_loss                        -236.108
trainer/policy_loss_without_entropy         238.321
trainer/entropy_penalty                      -0.365828
trainer/entropy_percentage                   -0.00153502
trainer/Q1Pred Mean                         237.979
trainer/Q1Pred Std                           77.5347
trainer/Q1Pred Max                          320.719
trainer/Q1Pred Min                           -6.09314
trainer/Q2Pred Mean                         237.547
trainer/Q2Pred Std                           77.5642
trainer/Q2Pred Max                          321.473
trainer/Q2Pred Min                           -0.387245
trainer/QTargetWithReg Mean                 237.782
trainer/QTargetWithReg Std                   77.3525
trainer/QTargetWithReg Max                  321.416
trainer/QTargetWithReg Min                   -0.469096
trainer/PolicyLossWithoutReg Mean           238.321
trainer/PolicyLossWithoutReg Std             76.8398
trainer/PolicyLossWithoutReg Max            321.077
trainer/PolicyLossWithoutReg Min             -3.53464
trainer/gradient_norm                       369.363
trainer/gradient_penalty                     -1.84682
trainer/gradient_percentage                  -0.00774929
exploration/num steps total              937000
exploration/num paths total                2097
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12675
exploration/Rewards Std                       1.40577
exploration/Rewards Max                      10.4749
exploration/Rewards Min                      -0.49017
exploration/Returns Mean                   5126.75
exploration/Returns Std                       0
exploration/Returns Max                    5126.75
exploration/Returns Min                    5126.75
exploration/Num Paths                         1
exploration/Average Returns                5126.75
evaluation_0/num steps total                  7.37061e+06
evaluation_0/num paths total              15528
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.34118
evaluation_0/Rewards Std                      1.40639
evaluation_0/Rewards Max                     10.9548
evaluation_0/Rewards Min                     -0.646013
evaluation_0/Returns Mean                  5341.18
evaluation_0/Returns Std                     36.0173
evaluation_0/Returns Max                   5384.11
evaluation_0/Returns Min                   5262.89
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5341.18
time/epoch (s)                                0
time/total (s)                            17535.2
Epoch                                       932
---------------------------------------  ----------------
2022-11-16 15:38:17.430351 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 933 finished
---------------------------------------  ----------------
epoch                                       933
total_step                               938000
replay_pool/size                         938000
trainer/alpha                                 0.0595175
trainer/alpha_loss                           -0.172628
trainer/entropy                              -5.93882
trainer/qf_loss                               6.13073
trainer/state_noise                           0.005
trainer/policy_loss                        -241.866
trainer/policy_loss_without_entropy         244.132
trainer/entropy_penalty                      -0.353464
trainer/entropy_percentage                   -0.00144784
trainer/Q1Pred Mean                         243.576
trainer/Q1Pred Std                           75.5576
trainer/Q1Pred Max                          324.3
trainer/Q1Pred Min                            4.99515
trainer/Q2Pred Mean                         243.636
trainer/Q2Pred Std                           75.457
trainer/Q2Pred Max                          325.248
trainer/Q2Pred Min                            7.15268
trainer/QTargetWithReg Mean                 243.341
trainer/QTargetWithReg Std                   75.6688
trainer/QTargetWithReg Max                  324.877
trainer/QTargetWithReg Min                   -5.13501
trainer/PolicyLossWithoutReg Mean           244.132
trainer/PolicyLossWithoutReg Std             74.1287
trainer/PolicyLossWithoutReg Max            323.808
trainer/PolicyLossWithoutReg Min              7.06108
trainer/gradient_norm                       382.617
trainer/gradient_penalty                     -1.91309
trainer/gradient_percentage                  -0.00783628
exploration/num steps total              938000
exploration/num paths total                2098
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0947
exploration/Rewards Std                       1.33621
exploration/Rewards Max                      10.483
exploration/Rewards Min                      -0.635086
exploration/Returns Mean                   5094.7
exploration/Returns Std                       0
exploration/Returns Max                    5094.7
exploration/Returns Min                    5094.7
exploration/Num Paths                         1
exploration/Average Returns                5094.7
evaluation_0/num steps total                  7.37861e+06
evaluation_0/num paths total              15536
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.29031
evaluation_0/Rewards Std                      1.36734
evaluation_0/Rewards Max                     10.895
evaluation_0/Rewards Min                     -0.50325
evaluation_0/Returns Mean                  5290.31
evaluation_0/Returns Std                     30.0713
evaluation_0/Returns Max                   5332.66
evaluation_0/Returns Min                   5224.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5290.31
time/epoch (s)                                0
time/total (s)                            17551.1
Epoch                                       933
---------------------------------------  ----------------
2022-11-16 15:38:33.803330 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 934 finished
---------------------------------------  ----------------
epoch                                       934
total_step                               939000
replay_pool/size                         939000
trainer/alpha                                 0.0603522
trainer/alpha_loss                            0.0732312
trainer/entropy                              -6.02608
trainer/qf_loss                               8.35249
trainer/state_noise                           0.005
trainer/policy_loss                        -229.682
trainer/policy_loss_without_entropy         231.904
trainer/entropy_penalty                      -0.363687
trainer/entropy_percentage                   -0.00156826
trainer/Q1Pred Mean                         231.607
trainer/Q1Pred Std                           78.7777
trainer/Q1Pred Max                          326.836
trainer/Q1Pred Min                            9.77254
trainer/Q2Pred Mean                         231.723
trainer/Q2Pred Std                           79.2213
trainer/Q2Pred Max                          327.387
trainer/Q2Pred Min                           10.7987
trainer/QTargetWithReg Mean                 231.343
trainer/QTargetWithReg Std                   79.3637
trainer/QTargetWithReg Max                  326.15
trainer/QTargetWithReg Min                   11.7125
trainer/PolicyLossWithoutReg Mean           231.904
trainer/PolicyLossWithoutReg Std             78.3173
trainer/PolicyLossWithoutReg Max            327.593
trainer/PolicyLossWithoutReg Min              9.82004
trainer/gradient_norm                       371.826
trainer/gradient_penalty                     -1.85913
trainer/gradient_percentage                  -0.00801679
exploration/num steps total              939000
exploration/num paths total                2099
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.26323
exploration/Rewards Std                       1.41271
exploration/Rewards Max                      10.4574
exploration/Rewards Min                      -0.532852
exploration/Returns Mean                   5263.23
exploration/Returns Std                       0
exploration/Returns Max                    5263.23
exploration/Returns Min                    5263.23
exploration/Num Paths                         1
exploration/Average Returns                5263.23
evaluation_0/num steps total                  7.38661e+06
evaluation_0/num paths total              15544
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.34682
evaluation_0/Rewards Std                      1.38125
evaluation_0/Rewards Max                     10.8149
evaluation_0/Rewards Min                     -0.49296
evaluation_0/Returns Mean                  5346.82
evaluation_0/Returns Std                     57.0092
evaluation_0/Returns Max                   5425.69
evaluation_0/Returns Min                   5270.03
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5346.82
time/epoch (s)                                0
time/total (s)                            17567.5
Epoch                                       934
---------------------------------------  ----------------
2022-11-16 15:38:49.713752 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 935 finished
---------------------------------------  ----------------
epoch                                       935
total_step                               940000
replay_pool/size                         940000
trainer/alpha                                 0.0592605
trainer/alpha_loss                           -0.232123
trainer/entropy                              -5.91785
trainer/qf_loss                               8.63517
trainer/state_noise                           0.005
trainer/policy_loss                        -234.106
trainer/policy_loss_without_entropy         236.315
trainer/entropy_penalty                      -0.350695
trainer/entropy_percentage                   -0.00148401
trainer/Q1Pred Mean                         235.54
trainer/Q1Pred Std                           75.8709
trainer/Q1Pred Max                          320.668
trainer/Q1Pred Min                           12.8081
trainer/Q2Pred Mean                         235.188
trainer/Q2Pred Std                           76.0775
trainer/Q2Pred Max                          321.275
trainer/Q2Pred Min                            9.13725
trainer/QTargetWithReg Mean                 236.226
trainer/QTargetWithReg Std                   75.6308
trainer/QTargetWithReg Max                  320.978
trainer/QTargetWithReg Min                   11.2857
trainer/PolicyLossWithoutReg Mean           236.315
trainer/PolicyLossWithoutReg Std             74.8838
trainer/PolicyLossWithoutReg Max            320.508
trainer/PolicyLossWithoutReg Min             13.0034
trainer/gradient_norm                       371.661
trainer/gradient_penalty                     -1.8583
trainer/gradient_percentage                  -0.00786367
exploration/num steps total              940000
exploration/num paths total                2100
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15331
exploration/Rewards Std                       1.30076
exploration/Rewards Max                      10.3474
exploration/Rewards Min                      -0.487039
exploration/Returns Mean                   5153.31
exploration/Returns Std                       0
exploration/Returns Max                    5153.31
exploration/Returns Min                    5153.31
exploration/Num Paths                         1
exploration/Average Returns                5153.31
evaluation_0/num steps total                  7.39461e+06
evaluation_0/num paths total              15552
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.5144
evaluation_0/Rewards Std                      1.46056
evaluation_0/Rewards Max                     11.0062
evaluation_0/Rewards Min                     -0.399121
evaluation_0/Returns Mean                  5514.4
evaluation_0/Returns Std                     36.2047
evaluation_0/Returns Max                   5571.49
evaluation_0/Returns Min                   5475.51
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5514.4
time/epoch (s)                                0
time/total (s)                            17583.4
Epoch                                       935
---------------------------------------  ----------------
2022-11-16 15:39:05.676545 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 936 finished
---------------------------------------  ----------------
epoch                                       936
total_step                               941000
replay_pool/size                         941000
trainer/alpha                                 0.0601242
trainer/alpha_loss                           -0.0840774
trainer/entropy                              -5.97009
trainer/qf_loss                               8.52382
trainer/state_noise                           0.005
trainer/policy_loss                        -234.374
trainer/policy_loss_without_entropy         236.61
trainer/entropy_penalty                      -0.358947
trainer/entropy_percentage                   -0.00151704
trainer/Q1Pred Mean                         235.813
trainer/Q1Pred Std                           74.2491
trainer/Q1Pred Max                          325.653
trainer/Q1Pred Min                           26.0681
trainer/Q2Pred Mean                         235.924
trainer/Q2Pred Std                           73.8797
trainer/Q2Pred Max                          324.467
trainer/Q2Pred Min                           25.2636
trainer/QTargetWithReg Mean                 236.846
trainer/QTargetWithReg Std                   74.6006
trainer/QTargetWithReg Max                  324.829
trainer/QTargetWithReg Min                   25.1144
trainer/PolicyLossWithoutReg Mean           236.61
trainer/PolicyLossWithoutReg Std             73.4202
trainer/PolicyLossWithoutReg Max            323.851
trainer/PolicyLossWithoutReg Min             26.6379
trainer/gradient_norm                       375.408
trainer/gradient_penalty                     -1.87704
trainer/gradient_percentage                  -0.00793305
exploration/num steps total              941000
exploration/num paths total                2101
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.19049
exploration/Rewards Std                       1.38686
exploration/Rewards Max                      10.4744
exploration/Rewards Min                      -0.364903
exploration/Returns Mean                   5190.49
exploration/Returns Std                       0
exploration/Returns Max                    5190.49
exploration/Returns Min                    5190.49
exploration/Num Paths                         1
exploration/Average Returns                5190.49
evaluation_0/num steps total                  7.40261e+06
evaluation_0/num paths total              15560
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14438
evaluation_0/Rewards Std                      1.31195
evaluation_0/Rewards Max                     10.3521
evaluation_0/Rewards Min                     -0.642657
evaluation_0/Returns Mean                  5144.38
evaluation_0/Returns Std                     10.1492
evaluation_0/Returns Max                   5160.88
evaluation_0/Returns Min                   5126.27
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5144.38
time/epoch (s)                                0
time/total (s)                            17599.3
Epoch                                       936
---------------------------------------  ----------------
2022-11-16 15:39:22.140991 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 937 finished
---------------------------------------  ----------------
epoch                                       937
total_step                               942000
replay_pool/size                         942000
trainer/alpha                                 0.0602213
trainer/alpha_loss                           -0.834714
trainer/entropy                              -5.70293
trainer/qf_loss                              10.0374
trainer/state_noise                           0.005
trainer/policy_loss                        -240.557
trainer/policy_loss_without_entropy         242.801
trainer/entropy_penalty                      -0.343438
trainer/entropy_percentage                   -0.00141448
trainer/Q1Pred Mean                         242.956
trainer/Q1Pred Std                           71.1753
trainer/Q1Pred Max                          319.855
trainer/Q1Pred Min                           -2.30805
trainer/Q2Pred Mean                         242.677
trainer/Q2Pred Std                           71.2256
trainer/Q2Pred Max                          317.648
trainer/Q2Pred Min                           -5.69484
trainer/QTargetWithReg Mean                 242.897
trainer/QTargetWithReg Std                   71.2795
trainer/QTargetWithReg Max                  318.019
trainer/QTargetWithReg Min                   -5.90311
trainer/PolicyLossWithoutReg Mean           242.801
trainer/PolicyLossWithoutReg Std             70.7188
trainer/PolicyLossWithoutReg Max            317.234
trainer/PolicyLossWithoutReg Min             -4.03401
trainer/gradient_norm                       380.07
trainer/gradient_penalty                     -1.90035
trainer/gradient_percentage                  -0.00782678
exploration/num steps total              942000
exploration/num paths total                2102
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.2007
exploration/Rewards Std                       1.3068
exploration/Rewards Max                      10.3584
exploration/Rewards Min                      -0.489453
exploration/Returns Mean                   5200.7
exploration/Returns Std                       0
exploration/Returns Max                    5200.7
exploration/Returns Min                    5200.7
exploration/Num Paths                         1
exploration/Average Returns                5200.7
evaluation_0/num steps total                  7.41061e+06
evaluation_0/num paths total              15568
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23729
evaluation_0/Rewards Std                      1.29621
evaluation_0/Rewards Max                     10.3698
evaluation_0/Rewards Min                     -0.56763
evaluation_0/Returns Mean                  5237.29
evaluation_0/Returns Std                      8.12189
evaluation_0/Returns Max                   5249.68
evaluation_0/Returns Min                   5228.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5237.29
time/epoch (s)                                0
time/total (s)                            17615.8
Epoch                                       937
---------------------------------------  ----------------
2022-11-16 15:39:38.080273 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 938 finished
---------------------------------------  ----------------
epoch                                       938
total_step                               943000
replay_pool/size                         943000
trainer/alpha                                 0.0603539
trainer/alpha_loss                           -1.06521
trainer/entropy                              -5.62055
trainer/qf_loss                               5.0302
trainer/state_noise                           0.005
trainer/policy_loss                        -233.35
trainer/policy_loss_without_entropy         235.497
trainer/entropy_penalty                      -0.339222
trainer/entropy_percentage                   -0.00144045
trainer/Q1Pred Mean                         235.705
trainer/Q1Pred Std                           75.7657
trainer/Q1Pred Max                          322.29
trainer/Q1Pred Min                           -3.98929
trainer/Q2Pred Mean                         235.937
trainer/Q2Pred Std                           75.9649
trainer/Q2Pred Max                          321.672
trainer/Q2Pred Min                           -7.86338
trainer/QTargetWithReg Mean                 235.399
trainer/QTargetWithReg Std                   75.9736
trainer/QTargetWithReg Max                  320.878
trainer/QTargetWithReg Min                   -7.75436
trainer/PolicyLossWithoutReg Mean           235.497
trainer/PolicyLossWithoutReg Std             75.5121
trainer/PolicyLossWithoutReg Max            320.202
trainer/PolicyLossWithoutReg Min             -9.16272
trainer/gradient_norm                       361.655
trainer/gradient_penalty                     -1.80827
trainer/gradient_percentage                  -0.00767854
exploration/num steps total              943000
exploration/num paths total                2103
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14208
exploration/Rewards Std                       1.31177
exploration/Rewards Max                      10.2823
exploration/Rewards Min                      -0.421178
exploration/Returns Mean                   5142.08
exploration/Returns Std                       0
exploration/Returns Max                    5142.08
exploration/Returns Min                    5142.08
exploration/Num Paths                         1
exploration/Average Returns                5142.08
evaluation_0/num steps total                  7.41861e+06
evaluation_0/num paths total              15576
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17242
evaluation_0/Rewards Std                      1.35532
evaluation_0/Rewards Max                     10.2575
evaluation_0/Rewards Min                     -0.519622
evaluation_0/Returns Mean                  5172.42
evaluation_0/Returns Std                     21.2608
evaluation_0/Returns Max                   5199.02
evaluation_0/Returns Min                   5141.93
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5172.42
time/epoch (s)                                0
time/total (s)                            17631.7
Epoch                                       938
---------------------------------------  ----------------
2022-11-16 15:39:54.511257 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 939 finished
---------------------------------------  ----------------
epoch                                       939
total_step                               944000
replay_pool/size                         944000
trainer/alpha                                 0.0587403
trainer/alpha_loss                            1.38445
trainer/entropy                              -6.48841
trainer/qf_loss                               7.01249
trainer/state_noise                           0.005
trainer/policy_loss                        -243.335
trainer/policy_loss_without_entropy         245.492
trainer/entropy_penalty                      -0.381131
trainer/entropy_percentage                   -0.00155252
trainer/Q1Pred Mean                         244.498
trainer/Q1Pred Std                           74.5161
trainer/Q1Pred Max                          321.618
trainer/Q1Pred Min                           12.2839
trainer/Q2Pred Mean                         244.752
trainer/Q2Pred Std                           74.5094
trainer/Q2Pred Max                          322.42
trainer/Q2Pred Min                            7.80939
trainer/QTargetWithReg Mean                 244.969
trainer/QTargetWithReg Std                   74.7152
trainer/QTargetWithReg Max                  321.224
trainer/QTargetWithReg Min                   11.6677
trainer/PolicyLossWithoutReg Mean           245.492
trainer/PolicyLossWithoutReg Std             73.899
trainer/PolicyLossWithoutReg Max            322.415
trainer/PolicyLossWithoutReg Min             12.4515
trainer/gradient_norm                       355.145
trainer/gradient_penalty                     -1.77573
trainer/gradient_percentage                  -0.00723335
exploration/num steps total              944000
exploration/num paths total                2104
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14775
exploration/Rewards Std                       1.32469
exploration/Rewards Max                      10.1566
exploration/Rewards Min                      -0.677879
exploration/Returns Mean                   5147.75
exploration/Returns Std                       0
exploration/Returns Max                    5147.75
exploration/Returns Min                    5147.75
exploration/Num Paths                         1
exploration/Average Returns                5147.75
evaluation_0/num steps total                  7.42661e+06
evaluation_0/num paths total              15584
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.28811
evaluation_0/Rewards Std                      1.32386
evaluation_0/Rewards Max                     10.4215
evaluation_0/Rewards Min                     -0.395615
evaluation_0/Returns Mean                  5288.11
evaluation_0/Returns Std                      9.75251
evaluation_0/Returns Max                   5304.45
evaluation_0/Returns Min                   5275.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5288.11
time/epoch (s)                                0
time/total (s)                            17648.2
Epoch                                       939
---------------------------------------  ----------------
2022-11-16 15:40:10.373265 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 940 finished
---------------------------------------  ----------------
epoch                                       940
total_step                               945000
replay_pool/size                         945000
trainer/alpha                                 0.0602042
trainer/alpha_loss                           -0.229388
trainer/entropy                              -5.91837
trainer/qf_loss                               6.11684
trainer/state_noise                           0.005
trainer/policy_loss                        -235.114
trainer/policy_loss_without_entropy         237.297
trainer/entropy_penalty                      -0.356311
trainer/entropy_percentage                   -0.00150154
trainer/Q1Pred Mean                         236.607
trainer/Q1Pred Std                           75.9503
trainer/Q1Pred Max                          321.706
trainer/Q1Pred Min                           12.3901
trainer/Q2Pred Mean                         236.72
trainer/Q2Pred Std                           75.6916
trainer/Q2Pred Max                          323.601
trainer/Q2Pred Min                           13.4243
trainer/QTargetWithReg Mean                 236.65
trainer/QTargetWithReg Std                   75.4426
trainer/QTargetWithReg Max                  321.062
trainer/QTargetWithReg Min                   13.8141
trainer/PolicyLossWithoutReg Mean           237.297
trainer/PolicyLossWithoutReg Std             75.2893
trainer/PolicyLossWithoutReg Max            323.006
trainer/PolicyLossWithoutReg Min             13.2516
trainer/gradient_norm                       365.502
trainer/gradient_penalty                     -1.82751
trainer/gradient_percentage                  -0.00770135
exploration/num steps total              945000
exploration/num paths total                2105
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16979
exploration/Rewards Std                       1.31012
exploration/Rewards Max                      10.2367
exploration/Rewards Min                      -0.551652
exploration/Returns Mean                   5169.79
exploration/Returns Std                       0
exploration/Returns Max                    5169.79
exploration/Returns Min                    5169.79
exploration/Num Paths                         1
exploration/Average Returns                5169.79
evaluation_0/num steps total                  7.43461e+06
evaluation_0/num paths total              15592
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25715
evaluation_0/Rewards Std                      1.30144
evaluation_0/Rewards Max                     10.4309
evaluation_0/Rewards Min                     -0.458278
evaluation_0/Returns Mean                  5257.15
evaluation_0/Returns Std                     13.5566
evaluation_0/Returns Max                   5278.87
evaluation_0/Returns Min                   5230.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5257.15
time/epoch (s)                                0
time/total (s)                            17664
Epoch                                       940
---------------------------------------  ----------------
2022-11-16 15:40:27.044126 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 941 finished
---------------------------------------  ----------------
epoch                                       941
total_step                               946000
replay_pool/size                         946000
trainer/alpha                                 0.0602389
trainer/alpha_loss                           -1.0333
trainer/entropy                              -5.63218
trainer/qf_loss                               7.1522
trainer/state_noise                           0.005
trainer/policy_loss                        -240.891
trainer/policy_loss_without_entropy         243.059
trainer/entropy_penalty                      -0.339277
trainer/entropy_percentage                   -0.00139586
trainer/Q1Pred Mean                         243.05
trainer/Q1Pred Std                           69.7323
trainer/Q1Pred Max                          322.65
trainer/Q1Pred Min                           10.6106
trainer/Q2Pred Mean                         242.784
trainer/Q2Pred Std                           69.5257
trainer/Q2Pred Max                          322.363
trainer/Q2Pred Min                           15.3309
trainer/QTargetWithReg Mean                 243.063
trainer/QTargetWithReg Std                   70.1904
trainer/QTargetWithReg Max                  323.793
trainer/QTargetWithReg Min                    7.81533
trainer/PolicyLossWithoutReg Mean           243.059
trainer/PolicyLossWithoutReg Std             69.0176
trainer/PolicyLossWithoutReg Max            322.572
trainer/PolicyLossWithoutReg Min             12.757
trainer/gradient_norm                       365.855
trainer/gradient_penalty                     -1.82927
trainer/gradient_percentage                  -0.00752603
exploration/num steps total              946000
exploration/num paths total                2106
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14158
exploration/Rewards Std                       1.29666
exploration/Rewards Max                      10.3899
exploration/Rewards Min                      -0.407729
exploration/Returns Mean                   5141.58
exploration/Returns Std                       0
exploration/Returns Max                    5141.58
exploration/Returns Min                    5141.58
exploration/Num Paths                         1
exploration/Average Returns                5141.58
evaluation_0/num steps total                  7.44261e+06
evaluation_0/num paths total              15600
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09823
evaluation_0/Rewards Std                      1.31633
evaluation_0/Rewards Max                     10.3642
evaluation_0/Rewards Min                     -0.499809
evaluation_0/Returns Mean                  5098.23
evaluation_0/Returns Std                     13.506
evaluation_0/Returns Max                   5123.94
evaluation_0/Returns Min                   5077.2
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5098.23
time/epoch (s)                                0
time/total (s)                            17680.7
Epoch                                       941
---------------------------------------  ----------------
2022-11-16 15:40:42.861683 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 942 finished
---------------------------------------  ----------------
epoch                                       942
total_step                               947000
replay_pool/size                         947000
trainer/alpha                                 0.0598796
trainer/alpha_loss                            0.703595
trainer/entropy                              -6.2499
trainer/qf_loss                               7.78026
trainer/state_noise                           0.005
trainer/policy_loss                        -228.773
trainer/policy_loss_without_entropy         230.978
trainer/entropy_penalty                      -0.374241
trainer/entropy_percentage                   -0.00162025
trainer/Q1Pred Mean                         230.784
trainer/Q1Pred Std                           75.6069
trainer/Q1Pred Max                          321.056
trainer/Q1Pred Min                          -17.4448
trainer/Q2Pred Mean                         231.025
trainer/Q2Pred Std                           75.3086
trainer/Q2Pred Max                          322.882
trainer/Q2Pred Min                          -12.1279
trainer/QTargetWithReg Mean                 230.64
trainer/QTargetWithReg Std                   75.7981
trainer/QTargetWithReg Max                  322.058
trainer/QTargetWithReg Min                  -16.1606
trainer/PolicyLossWithoutReg Mean           230.978
trainer/PolicyLossWithoutReg Std             75.0045
trainer/PolicyLossWithoutReg Max            320.965
trainer/PolicyLossWithoutReg Min            -16.6556
trainer/gradient_norm                       366.213
trainer/gradient_penalty                     -1.83106
trainer/gradient_percentage                  -0.00792744
exploration/num steps total              947000
exploration/num paths total                2107
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15132
exploration/Rewards Std                       1.31719
exploration/Rewards Max                      10.3629
exploration/Rewards Min                      -0.514821
exploration/Returns Mean                   5151.32
exploration/Returns Std                       0
exploration/Returns Max                    5151.32
exploration/Returns Min                    5151.32
exploration/Num Paths                         1
exploration/Average Returns                5151.32
evaluation_0/num steps total                  7.45061e+06
evaluation_0/num paths total              15608
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23999
evaluation_0/Rewards Std                      1.29522
evaluation_0/Rewards Max                     10.5145
evaluation_0/Rewards Min                     -0.268189
evaluation_0/Returns Mean                  5239.99
evaluation_0/Returns Std                     12.4758
evaluation_0/Returns Max                   5259.9
evaluation_0/Returns Min                   5225.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5239.99
time/epoch (s)                                0
time/total (s)                            17696.5
Epoch                                       942
---------------------------------------  ----------------
2022-11-16 15:40:59.304367 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 943 finished
---------------------------------------  ----------------
epoch                                       943
total_step                               948000
replay_pool/size                         948000
trainer/alpha                                 0.0595506
trainer/alpha_loss                            0.419816
trainer/entropy                              -6.14881
trainer/qf_loss                               4.16049
trainer/state_noise                           0.005
trainer/policy_loss                        -235.842
trainer/policy_loss_without_entropy         238.105
trainer/entropy_penalty                      -0.366165
trainer/entropy_percentage                   -0.00153783
trainer/Q1Pred Mean                         237.754
trainer/Q1Pred Std                           83.9394
trainer/Q1Pred Max                          325.46
trainer/Q1Pred Min                            4.07942
trainer/Q2Pred Mean                         237.122
trainer/Q2Pred Std                           83.7495
trainer/Q2Pred Max                          324.574
trainer/Q2Pred Min                            1.11922
trainer/QTargetWithReg Mean                 237.072
trainer/QTargetWithReg Std                   83.8739
trainer/QTargetWithReg Max                  328.131
trainer/QTargetWithReg Min                    3.17708
trainer/PolicyLossWithoutReg Mean           238.105
trainer/PolicyLossWithoutReg Std             83.1881
trainer/PolicyLossWithoutReg Max            325.358
trainer/PolicyLossWithoutReg Min              3.85208
trainer/gradient_norm                       379.344
trainer/gradient_penalty                     -1.89672
trainer/gradient_percentage                  -0.00796589
exploration/num steps total              948000
exploration/num paths total                2108
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.26251
exploration/Rewards Std                       1.34154
exploration/Rewards Max                      10.7684
exploration/Rewards Min                      -0.371522
exploration/Returns Mean                   5262.51
exploration/Returns Std                       0
exploration/Returns Max                    5262.51
exploration/Returns Min                    5262.51
exploration/Num Paths                         1
exploration/Average Returns                5262.51
evaluation_0/num steps total                  7.45861e+06
evaluation_0/num paths total              15616
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23252
evaluation_0/Rewards Std                      1.27793
evaluation_0/Rewards Max                     10.3387
evaluation_0/Rewards Min                     -0.360594
evaluation_0/Returns Mean                  5232.52
evaluation_0/Returns Std                      9.10072
evaluation_0/Returns Max                   5241.65
evaluation_0/Returns Min                   5210.65
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5232.52
time/epoch (s)                                0
time/total (s)                            17713
Epoch                                       943
---------------------------------------  ----------------
2022-11-16 15:41:15.162996 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 944 finished
---------------------------------------  ----------------
epoch                                       944
total_step                               949000
replay_pool/size                         949000
trainer/alpha                                 0.0594565
trainer/alpha_loss                            0.0749143
trainer/entropy                              -6.02654
trainer/qf_loss                               7.82191
trainer/state_noise                           0.005
trainer/policy_loss                        -236.717
trainer/policy_loss_without_entropy         238.98
trainer/entropy_penalty                      -0.358317
trainer/entropy_percentage                   -0.00149936
trainer/Q1Pred Mean                         238.649
trainer/Q1Pred Std                           75.7169
trainer/Q1Pred Max                          320.283
trainer/Q1Pred Min                           12.6955
trainer/Q2Pred Mean                         238.366
trainer/Q2Pred Std                           75.8013
trainer/Q2Pred Max                          320.227
trainer/Q2Pred Min                           10.8991
trainer/QTargetWithReg Mean                 238.838
trainer/QTargetWithReg Std                   76.0969
trainer/QTargetWithReg Max                  321.12
trainer/QTargetWithReg Min                   10.5969
trainer/PolicyLossWithoutReg Mean           238.98
trainer/PolicyLossWithoutReg Std             75.0641
trainer/PolicyLossWithoutReg Max            319.986
trainer/PolicyLossWithoutReg Min             12.979
trainer/gradient_norm                       380.831
trainer/gradient_penalty                     -1.90415
trainer/gradient_percentage                  -0.00796784
exploration/num steps total              949000
exploration/num paths total                2109
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07899
exploration/Rewards Std                       1.27862
exploration/Rewards Max                      10.5205
exploration/Rewards Min                      -0.384487
exploration/Returns Mean                   5078.99
exploration/Returns Std                       0
exploration/Returns Max                    5078.99
exploration/Returns Min                    5078.99
exploration/Num Paths                         1
exploration/Average Returns                5078.99
evaluation_0/num steps total                  7.46661e+06
evaluation_0/num paths total              15624
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19595
evaluation_0/Rewards Std                      1.26722
evaluation_0/Rewards Max                     10.3151
evaluation_0/Rewards Min                     -0.445383
evaluation_0/Returns Mean                  5195.95
evaluation_0/Returns Std                     16.3027
evaluation_0/Returns Max                   5218.33
evaluation_0/Returns Min                   5170.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5195.95
time/epoch (s)                                0
time/total (s)                            17728.8
Epoch                                       944
---------------------------------------  ----------------
2022-11-16 15:41:31.173187 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 945 finished
---------------------------------------  ----------------
epoch                                       945
total_step                               950000
replay_pool/size                         950000
trainer/alpha                                 0.058605
trainer/alpha_loss                           -0.0235994
trainer/entropy                              -5.99168
trainer/qf_loss                               6.43122
trainer/state_noise                           0.005
trainer/policy_loss                        -234.493
trainer/policy_loss_without_entropy         236.756
trainer/entropy_penalty                      -0.351143
trainer/entropy_percentage                   -0.00148314
trainer/Q1Pred Mean                         236.241
trainer/Q1Pred Std                           79.2733
trainer/Q1Pred Max                          323.017
trainer/Q1Pred Min                            5.30236
trainer/Q2Pred Mean                         237.013
trainer/Q2Pred Std                           79.5145
trainer/Q2Pred Max                          324.28
trainer/Q2Pred Min                           -3.02702
trainer/QTargetWithReg Mean                 235.946
trainer/QTargetWithReg Std                   79.7662
trainer/QTargetWithReg Max                  324.214
trainer/QTargetWithReg Min                   -0.412057
trainer/PolicyLossWithoutReg Mean           236.756
trainer/PolicyLossWithoutReg Std             78.729
trainer/PolicyLossWithoutReg Max            322.759
trainer/PolicyLossWithoutReg Min              2.92175
trainer/gradient_norm                       382.382
trainer/gradient_penalty                     -1.91191
trainer/gradient_percentage                  -0.00807547
exploration/num steps total              950000
exploration/num paths total                2110
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.2314
exploration/Rewards Std                       1.32032
exploration/Rewards Max                      10.6184
exploration/Rewards Min                      -0.507822
exploration/Returns Mean                   5231.4
exploration/Returns Std                       0
exploration/Returns Max                    5231.4
exploration/Returns Min                    5231.4
exploration/Num Paths                         1
exploration/Average Returns                5231.4
evaluation_0/num steps total                  7.47461e+06
evaluation_0/num paths total              15632
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22094
evaluation_0/Rewards Std                      1.28923
evaluation_0/Rewards Max                     10.4387
evaluation_0/Rewards Min                     -0.536512
evaluation_0/Returns Mean                  5220.94
evaluation_0/Returns Std                     10.5777
evaluation_0/Returns Max                   5230.46
evaluation_0/Returns Min                   5195.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5220.94
time/epoch (s)                                0
time/total (s)                            17744.8
Epoch                                       945
---------------------------------------  ----------------
2022-11-16 15:41:47.367677 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 946 finished
---------------------------------------  ----------------
epoch                                       946
total_step                               951000
replay_pool/size                         951000
trainer/alpha                                 0.0590733
trainer/alpha_loss                            0.617873
trainer/entropy                              -6.21841
trainer/qf_loss                               8.8872
trainer/state_noise                           0.005
trainer/policy_loss                        -234.759
trainer/policy_loss_without_entropy         237.01
trainer/entropy_penalty                      -0.367342
trainer/entropy_percentage                   -0.0015499
trainer/Q1Pred Mean                         237.114
trainer/Q1Pred Std                           75.4939
trainer/Q1Pred Max                          324.471
trainer/Q1Pred Min                           -6.34517
trainer/Q2Pred Mean                         236.96
trainer/Q2Pred Std                           75.3573
trainer/Q2Pred Max                          322.722
trainer/Q2Pred Min                           -3.70559
trainer/QTargetWithReg Mean                 236.623
trainer/QTargetWithReg Std                   76.0509
trainer/QTargetWithReg Max                  323.15
trainer/QTargetWithReg Min                  -15.6416
trainer/PolicyLossWithoutReg Mean           237.01
trainer/PolicyLossWithoutReg Std             74.6534
trainer/PolicyLossWithoutReg Max            322.014
trainer/PolicyLossWithoutReg Min             -6.18791
trainer/gradient_norm                       376.761
trainer/gradient_penalty                     -1.88381
trainer/gradient_percentage                  -0.00794822
exploration/num steps total              951000
exploration/num paths total                2111
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15486
exploration/Rewards Std                       1.30729
exploration/Rewards Max                      10.2989
exploration/Rewards Min                      -0.309001
exploration/Returns Mean                   5154.86
exploration/Returns Std                       0
exploration/Returns Max                    5154.86
exploration/Returns Min                    5154.86
exploration/Num Paths                         1
exploration/Average Returns                5154.86
evaluation_0/num steps total                  7.48261e+06
evaluation_0/num paths total              15640
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23292
evaluation_0/Rewards Std                      1.29607
evaluation_0/Rewards Max                     10.5762
evaluation_0/Rewards Min                     -0.483468
evaluation_0/Returns Mean                  5232.92
evaluation_0/Returns Std                     21.1094
evaluation_0/Returns Max                   5257.27
evaluation_0/Returns Min                   5186.72
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5232.92
time/epoch (s)                                0
time/total (s)                            17761
Epoch                                       946
---------------------------------------  ----------------
2022-11-16 15:42:03.246790 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 947 finished
---------------------------------------  ----------------
epoch                                       947
total_step                               952000
replay_pool/size                         952000
trainer/alpha                                 0.0590369
trainer/alpha_loss                           -0.219743
trainer/entropy                              -5.92234
trainer/qf_loss                               7.24573
trainer/state_noise                           0.005
trainer/policy_loss                        -239.602
trainer/policy_loss_without_entropy         241.85
trainer/entropy_penalty                      -0.349637
trainer/entropy_percentage                   -0.00144568
trainer/Q1Pred Mean                         241.335
trainer/Q1Pred Std                           73.1149
trainer/Q1Pred Max                          322.612
trainer/Q1Pred Min                           38.427
trainer/Q2Pred Mean                         241.336
trainer/Q2Pred Std                           72.7252
trainer/Q2Pred Max                          324.264
trainer/Q2Pred Min                           39.9646
trainer/QTargetWithReg Mean                 241.478
trainer/QTargetWithReg Std                   72.6413
trainer/QTargetWithReg Max                  323.955
trainer/QTargetWithReg Min                   38.87
trainer/PolicyLossWithoutReg Mean           241.85
trainer/PolicyLossWithoutReg Std             72.3142
trainer/PolicyLossWithoutReg Max            324.485
trainer/PolicyLossWithoutReg Min             39.2659
trainer/gradient_norm                       379.596
trainer/gradient_penalty                     -1.89798
trainer/gradient_percentage                  -0.00784777
exploration/num steps total              952000
exploration/num paths total                2112
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17686
exploration/Rewards Std                       1.29041
exploration/Rewards Max                      10.1801
exploration/Rewards Min                      -0.311896
exploration/Returns Mean                   5176.86
exploration/Returns Std                       0
exploration/Returns Max                    5176.86
exploration/Returns Min                    5176.86
exploration/Num Paths                         1
exploration/Average Returns                5176.86
evaluation_0/num steps total                  7.49061e+06
evaluation_0/num paths total              15648
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22033
evaluation_0/Rewards Std                      1.28377
evaluation_0/Rewards Max                     10.3828
evaluation_0/Rewards Min                     -0.390828
evaluation_0/Returns Mean                  5220.33
evaluation_0/Returns Std                     13.2747
evaluation_0/Returns Max                   5239.57
evaluation_0/Returns Min                   5198.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5220.33
time/epoch (s)                                0
time/total (s)                            17776.9
Epoch                                       947
---------------------------------------  ----------------
2022-11-16 15:42:19.433088 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 948 finished
---------------------------------------  ----------------
epoch                                       948
total_step                               953000
replay_pool/size                         953000
trainer/alpha                                 0.0579302
trainer/alpha_loss                            0.622019
trainer/entropy                              -6.21837
trainer/qf_loss                               6.05881
trainer/state_noise                           0.005
trainer/policy_loss                        -238.438
trainer/policy_loss_without_entropy         240.629
trainer/entropy_penalty                      -0.360231
trainer/entropy_percentage                   -0.00149704
trainer/Q1Pred Mean                         241.042
trainer/Q1Pred Std                           71.7671
trainer/Q1Pred Max                          324.31
trainer/Q1Pred Min                            9.50072
trainer/Q2Pred Mean                         241.062
trainer/Q2Pred Std                           71.6137
trainer/Q2Pred Max                          323.959
trainer/Q2Pred Min                            9.39925
trainer/QTargetWithReg Mean                 240.199
trainer/QTargetWithReg Std                   71.8233
trainer/QTargetWithReg Max                  324.293
trainer/QTargetWithReg Min                    5.68667
trainer/PolicyLossWithoutReg Mean           240.629
trainer/PolicyLossWithoutReg Std             71.0702
trainer/PolicyLossWithoutReg Max            323.685
trainer/PolicyLossWithoutReg Min             10.4163
trainer/gradient_norm                       366.119
trainer/gradient_penalty                     -1.8306
trainer/gradient_percentage                  -0.00760754
exploration/num steps total              953000
exploration/num paths total                2113
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14023
exploration/Rewards Std                       1.26176
exploration/Rewards Max                      10.2049
exploration/Rewards Min                      -0.418425
exploration/Returns Mean                   5140.23
exploration/Returns Std                       0
exploration/Returns Max                    5140.23
exploration/Returns Min                    5140.23
exploration/Num Paths                         1
exploration/Average Returns                5140.23
evaluation_0/num steps total                  7.49861e+06
evaluation_0/num paths total              15656
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.27315
evaluation_0/Rewards Std                      1.29318
evaluation_0/Rewards Max                     10.1338
evaluation_0/Rewards Min                     -0.375471
evaluation_0/Returns Mean                  5273.15
evaluation_0/Returns Std                      9.32481
evaluation_0/Returns Max                   5286.6
evaluation_0/Returns Min                   5259.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5273.15
time/epoch (s)                                0
time/total (s)                            17793.1
Epoch                                       948
---------------------------------------  ----------------
2022-11-16 15:43:33.139815 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 949 finished
---------------------------------------  ----------------
epoch                                       949
total_step                               954000
replay_pool/size                         954000
trainer/alpha                                 0.0589805
trainer/alpha_loss                           -1.13461
trainer/entropy                              -5.59915
trainer/qf_loss                               5.58825
trainer/state_noise                           0.005
trainer/policy_loss                        -234.476
trainer/policy_loss_without_entropy         236.773
trainer/entropy_penalty                      -0.330241
trainer/entropy_percentage                   -0.00139476
trainer/Q1Pred Mean                         236.122
trainer/Q1Pred Std                           78.4123
trainer/Q1Pred Max                          325.613
trainer/Q1Pred Min                           -2.0475
trainer/Q2Pred Mean                         236.666
trainer/Q2Pred Std                           78.4469
trainer/Q2Pred Max                          325.658
trainer/Q2Pred Min                           -2.4159
trainer/QTargetWithReg Mean                 236.405
trainer/QTargetWithReg Std                   78.1005
trainer/QTargetWithReg Max                  328.16
trainer/QTargetWithReg Min                    4.97058
trainer/PolicyLossWithoutReg Mean           236.773
trainer/PolicyLossWithoutReg Std             77.6111
trainer/PolicyLossWithoutReg Max            325.559
trainer/PolicyLossWithoutReg Min             -0.0780875
trainer/gradient_norm                       393.28
trainer/gradient_penalty                     -1.9664
trainer/gradient_percentage                  -0.00830502
exploration/num steps total              954000
exploration/num paths total                2114
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14045
exploration/Rewards Std                       1.30049
exploration/Rewards Max                      10.3115
exploration/Rewards Min                      -0.386961
exploration/Returns Mean                   5140.45
exploration/Returns Std                       0
exploration/Returns Max                    5140.45
exploration/Returns Min                    5140.45
exploration/Num Paths                         1
exploration/Average Returns                5140.45
evaluation_0/num steps total                  7.50661e+06
evaluation_0/num paths total              15664
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10518
evaluation_0/Rewards Std                      1.25505
evaluation_0/Rewards Max                     10.1216
evaluation_0/Rewards Min                     -0.374683
evaluation_0/Returns Mean                  5105.18
evaluation_0/Returns Std                      6.86219
evaluation_0/Returns Max                   5116.33
evaluation_0/Returns Min                   5092.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5105.18
time/epoch (s)                                0
time/total (s)                            17866.8
Epoch                                       949
---------------------------------------  ----------------
2022-11-16 15:44:41.899320 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 950 finished
---------------------------------------  ----------------
epoch                                       950
total_step                               955000
replay_pool/size                         955000
trainer/alpha                                 0.0591519
trainer/alpha_loss                           -0.371618
trainer/entropy                              -5.86858
trainer/qf_loss                               9.8609
trainer/state_noise                           0.005
trainer/policy_loss                        -234.462
trainer/policy_loss_without_entropy         236.701
trainer/entropy_penalty                      -0.347137
trainer/entropy_percentage                   -0.00146656
trainer/Q1Pred Mean                         235.856
trainer/Q1Pred Std                           79.481
trainer/Q1Pred Max                          321.285
trainer/Q1Pred Min                           10.6801
trainer/Q2Pred Mean                         235.967
trainer/Q2Pred Std                           79.3974
trainer/Q2Pred Max                          322.403
trainer/Q2Pred Min                           11.8824
trainer/QTargetWithReg Mean                 236.99
trainer/QTargetWithReg Std                   80.162
trainer/QTargetWithReg Max                  322.365
trainer/QTargetWithReg Min                    0.0842574
trainer/PolicyLossWithoutReg Mean           236.701
trainer/PolicyLossWithoutReg Std             77.9364
trainer/PolicyLossWithoutReg Max            320.978
trainer/PolicyLossWithoutReg Min             10.1483
trainer/gradient_norm                       378.52
trainer/gradient_penalty                     -1.8926
trainer/gradient_percentage                  -0.00799572
exploration/num steps total              955000
exploration/num paths total                2115
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.2403
exploration/Rewards Std                       1.31475
exploration/Rewards Max                      10.4166
exploration/Rewards Min                      -0.402198
exploration/Returns Mean                   5240.3
exploration/Returns Std                       0
exploration/Returns Max                    5240.3
exploration/Returns Min                    5240.3
exploration/Num Paths                         1
exploration/Average Returns                5240.3
evaluation_0/num steps total                  7.51461e+06
evaluation_0/num paths total              15672
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.32223
evaluation_0/Rewards Std                      1.31581
evaluation_0/Rewards Max                     10.6035
evaluation_0/Rewards Min                     -0.498081
evaluation_0/Returns Mean                  5322.23
evaluation_0/Returns Std                     36.4574
evaluation_0/Returns Max                   5390.1
evaluation_0/Returns Min                   5273.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5322.23
time/epoch (s)                                0
time/total (s)                            17935.6
Epoch                                       950
---------------------------------------  ----------------
2022-11-16 15:46:10.584007 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 951 finished
---------------------------------------  ----------------
epoch                                       951
total_step                               956000
replay_pool/size                         956000
trainer/alpha                                 0.0580409
trainer/alpha_loss                            1.22716
trainer/entropy                              -6.43109
trainer/qf_loss                               7.87381
trainer/state_noise                           0.005
trainer/policy_loss                        -239.502
trainer/policy_loss_without_entropy         241.707
trainer/entropy_penalty                      -0.373266
trainer/entropy_percentage                   -0.00154429
trainer/Q1Pred Mean                         240.834
trainer/Q1Pred Std                           73.308
trainer/Q1Pred Max                          331.668
trainer/Q1Pred Min                           -1.62516
trainer/Q2Pred Mean                         240.771
trainer/Q2Pred Std                           73.4178
trainer/Q2Pred Max                          332.825
trainer/Q2Pred Min                          -14.6633
trainer/QTargetWithReg Mean                 241.199
trainer/QTargetWithReg Std                   73.7986
trainer/QTargetWithReg Max                  332.615
trainer/QTargetWithReg Min                  -22.5415
trainer/PolicyLossWithoutReg Mean           241.707
trainer/PolicyLossWithoutReg Std             71.7097
trainer/PolicyLossWithoutReg Max            331.107
trainer/PolicyLossWithoutReg Min              0.699961
trainer/gradient_norm                       366.325
trainer/gradient_penalty                     -1.83162
trainer/gradient_percentage                  -0.00757785
exploration/num steps total              956000
exploration/num paths total                2116
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.1156
exploration/Rewards Std                       1.30749
exploration/Rewards Max                      10.0427
exploration/Rewards Min                      -0.568814
exploration/Returns Mean                   5115.6
exploration/Returns Std                       0
exploration/Returns Max                    5115.6
exploration/Returns Min                    5115.6
exploration/Num Paths                         1
exploration/Average Returns                5115.6
evaluation_0/num steps total                  7.52261e+06
evaluation_0/num paths total              15680
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14478
evaluation_0/Rewards Std                      1.29253
evaluation_0/Rewards Max                     10.2317
evaluation_0/Rewards Min                     -0.434522
evaluation_0/Returns Mean                  5144.78
evaluation_0/Returns Std                     47.5167
evaluation_0/Returns Max                   5213.79
evaluation_0/Returns Min                   5079.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5144.78
time/epoch (s)                                0
time/total (s)                            18024.2
Epoch                                       951
---------------------------------------  ----------------
2022-11-16 15:47:21.099156 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 952 finished
---------------------------------------  ----------------
epoch                                       952
total_step                               957000
replay_pool/size                         957000
trainer/alpha                                 0.0589253
trainer/alpha_loss                           -1.34362
trainer/entropy                              -5.52545
trainer/qf_loss                               5.28652
trainer/state_noise                           0.005
trainer/policy_loss                        -249.139
trainer/policy_loss_without_entropy         251.313
trainer/entropy_penalty                      -0.325589
trainer/entropy_percentage                   -0.00129555
trainer/Q1Pred Mean                         250.687
trainer/Q1Pred Std                           72.3568
trainer/Q1Pred Max                          328.256
trainer/Q1Pred Min                           -2.81184
trainer/Q2Pred Mean                         250.765
trainer/Q2Pred Std                           72.5832
trainer/Q2Pred Max                          327.329
trainer/Q2Pred Min                           -9.98334
trainer/QTargetWithReg Mean                 250.614
trainer/QTargetWithReg Std                   72.3395
trainer/QTargetWithReg Max                  325.932
trainer/QTargetWithReg Min                   -5.53886
trainer/PolicyLossWithoutReg Mean           251.313
trainer/PolicyLossWithoutReg Std             71.1094
trainer/PolicyLossWithoutReg Max            326.774
trainer/PolicyLossWithoutReg Min              4.82616
trainer/gradient_norm                       369.774
trainer/gradient_penalty                     -1.84887
trainer/gradient_percentage                  -0.00735684
exploration/num steps total              957000
exploration/num paths total                2117
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14818
exploration/Rewards Std                       1.30963
exploration/Rewards Max                      10.3431
exploration/Rewards Min                      -0.414044
exploration/Returns Mean                   5148.18
exploration/Returns Std                       0
exploration/Returns Max                    5148.18
exploration/Returns Min                    5148.18
exploration/Num Paths                         1
exploration/Average Returns                5148.18
evaluation_0/num steps total                  7.53061e+06
evaluation_0/num paths total              15688
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.21838
evaluation_0/Rewards Std                      1.26703
evaluation_0/Rewards Max                     10.2556
evaluation_0/Rewards Min                     -0.39592
evaluation_0/Returns Mean                  5218.38
evaluation_0/Returns Std                     10.352
evaluation_0/Returns Max                   5232.63
evaluation_0/Returns Min                   5200.04
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5218.38
time/epoch (s)                                0
time/total (s)                            18094.8
Epoch                                       952
---------------------------------------  ----------------
2022-11-16 15:48:08.951069 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 953 finished
---------------------------------------  ----------------
epoch                                       953
total_step                               958000
replay_pool/size                         958000
trainer/alpha                                 0.0585613
trainer/alpha_loss                           -0.237887
trainer/entropy                              -5.91617
trainer/qf_loss                               7.32757
trainer/state_noise                           0.005
trainer/policy_loss                        -234.793
trainer/policy_loss_without_entropy         237.03
trainer/entropy_penalty                      -0.346458
trainer/entropy_percentage                   -0.00146167
trainer/Q1Pred Mean                         236.185
trainer/Q1Pred Std                           72.843
trainer/Q1Pred Max                          324.792
trainer/Q1Pred Min                            1.70728
trainer/Q2Pred Mean                         235.874
trainer/Q2Pred Std                           72.9128
trainer/Q2Pred Max                          322.275
trainer/Q2Pred Min                           -3.24964
trainer/QTargetWithReg Mean                 236.543
trainer/QTargetWithReg Std                   73.3898
trainer/QTargetWithReg Max                  324.834
trainer/QTargetWithReg Min                   -6.81464
trainer/PolicyLossWithoutReg Mean           237.03
trainer/PolicyLossWithoutReg Std             72.4012
trainer/PolicyLossWithoutReg Max            323.459
trainer/PolicyLossWithoutReg Min              3.57126
trainer/gradient_norm                       377.992
trainer/gradient_penalty                     -1.88996
trainer/gradient_percentage                  -0.0079735
exploration/num steps total              958000
exploration/num paths total                2118
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14895
exploration/Rewards Std                       1.29405
exploration/Rewards Max                      10.4026
exploration/Rewards Min                      -0.355203
exploration/Returns Mean                   5148.95
exploration/Returns Std                       0
exploration/Returns Max                    5148.95
exploration/Returns Min                    5148.95
exploration/Num Paths                         1
exploration/Average Returns                5148.95
evaluation_0/num steps total                  7.53861e+06
evaluation_0/num paths total              15696
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.20292
evaluation_0/Rewards Std                      1.28838
evaluation_0/Rewards Max                     10.4747
evaluation_0/Rewards Min                     -0.434945
evaluation_0/Returns Mean                  5202.92
evaluation_0/Returns Std                     38.1194
evaluation_0/Returns Max                   5241.13
evaluation_0/Returns Min                   5144.58
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5202.92
time/epoch (s)                                0
time/total (s)                            18142.6
Epoch                                       953
---------------------------------------  ----------------
2022-11-16 15:48:22.672769 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 954 finished
---------------------------------------  ----------------
epoch                                       954
total_step                               959000
replay_pool/size                         959000
trainer/alpha                                 0.0597596
trainer/alpha_loss                            1.426
trainer/entropy                              -6.50613
trainer/qf_loss                               6.98499
trainer/state_noise                           0.005
trainer/policy_loss                        -238.143
trainer/policy_loss_without_entropy         240.452
trainer/entropy_penalty                      -0.388803
trainer/entropy_percentage                   -0.00161696
trainer/Q1Pred Mean                         240.374
trainer/Q1Pred Std                           73.8231
trainer/Q1Pred Max                          323.224
trainer/Q1Pred Min                           38.5008
trainer/Q2Pred Mean                         240.184
trainer/Q2Pred Std                           74.1381
trainer/Q2Pred Max                          323.416
trainer/Q2Pred Min                           38.0403
trainer/QTargetWithReg Mean                 240.329
trainer/QTargetWithReg Std                   74.1176
trainer/QTargetWithReg Max                  322.819
trainer/QTargetWithReg Min                   32.7562
trainer/PolicyLossWithoutReg Mean           240.452
trainer/PolicyLossWithoutReg Std             73.4083
trainer/PolicyLossWithoutReg Max            322.982
trainer/PolicyLossWithoutReg Min             37.8312
trainer/gradient_norm                       384.229
trainer/gradient_penalty                     -1.92114
trainer/gradient_percentage                  -0.00798971
exploration/num steps total              959000
exploration/num paths total                2119
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.15862
exploration/Rewards Std                       1.28605
exploration/Rewards Max                      10.371
exploration/Rewards Min                      -0.42051
exploration/Returns Mean                   5158.62
exploration/Returns Std                       0
exploration/Returns Max                    5158.62
exploration/Returns Min                    5158.62
exploration/Num Paths                         1
exploration/Average Returns                5158.62
evaluation_0/num steps total                  7.54661e+06
evaluation_0/num paths total              15704
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.1617
evaluation_0/Rewards Std                      1.27252
evaluation_0/Rewards Max                     10.2746
evaluation_0/Rewards Min                     -0.471065
evaluation_0/Returns Mean                  5161.7
evaluation_0/Returns Std                     14.642
evaluation_0/Returns Max                   5182.74
evaluation_0/Returns Min                   5138.48
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5161.7
time/epoch (s)                                0
time/total (s)                            18156.3
Epoch                                       954
---------------------------------------  ----------------
2022-11-16 15:49:18.862865 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 955 finished
---------------------------------------  ----------------
epoch                                       955
total_step                               960000
replay_pool/size                         960000
trainer/alpha                                 0.0564642
trainer/alpha_loss                           -0.286111
trainer/entropy                              -5.90045
trainer/qf_loss                               7.60547
trainer/state_noise                           0.005
trainer/policy_loss                        -242.507
trainer/policy_loss_without_entropy         244.716
trainer/entropy_penalty                      -0.333164
trainer/entropy_percentage                   -0.00136143
trainer/Q1Pred Mean                         244.37
trainer/Q1Pred Std                           73.41
trainer/Q1Pred Max                          325.097
trainer/Q1Pred Min                           -0.517792
trainer/Q2Pred Mean                         244.301
trainer/Q2Pred Std                           73.8001
trainer/Q2Pred Max                          324.614
trainer/Q2Pred Min                            8.30592
trainer/QTargetWithReg Mean                 243.944
trainer/QTargetWithReg Std                   73.9993
trainer/QTargetWithReg Max                  323.755
trainer/QTargetWithReg Min                    0.14379
trainer/PolicyLossWithoutReg Mean           244.716
trainer/PolicyLossWithoutReg Std             72.6493
trainer/PolicyLossWithoutReg Max            326.137
trainer/PolicyLossWithoutReg Min             10.2275
trainer/gradient_norm                       375.08
trainer/gradient_penalty                     -1.8754
trainer/gradient_percentage                  -0.00766357
exploration/num steps total              960000
exploration/num paths total                2120
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.21405
exploration/Rewards Std                       1.27566
exploration/Rewards Max                      10.1994
exploration/Rewards Min                      -0.489457
exploration/Returns Mean                   5214.05
exploration/Returns Std                       0
exploration/Returns Max                    5214.05
exploration/Returns Min                    5214.05
exploration/Num Paths                         1
exploration/Average Returns                5214.05
evaluation_0/num steps total                  7.55461e+06
evaluation_0/num paths total              15712
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.19509
evaluation_0/Rewards Std                      1.27575
evaluation_0/Rewards Max                     10.3209
evaluation_0/Rewards Min                     -0.456895
evaluation_0/Returns Mean                  5195.09
evaluation_0/Returns Std                     22.9907
evaluation_0/Returns Max                   5245.59
evaluation_0/Returns Min                   5174.34
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5195.09
time/epoch (s)                                0
time/total (s)                            18212.5
Epoch                                       955
---------------------------------------  ----------------
2022-11-16 15:50:50.055455 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 956 finished
---------------------------------------  ----------------
epoch                                       956
total_step                               961000
replay_pool/size                         961000
trainer/alpha                                 0.0589337
trainer/alpha_loss                            1.34888
trainer/entropy                              -6.47638
trainer/qf_loss                             255.598
trainer/state_noise                           0.005
trainer/policy_loss                        -238.163
trainer/policy_loss_without_entropy         240.373
trainer/entropy_penalty                      -0.381677
trainer/entropy_percentage                   -0.00158785
trainer/Q1Pred Mean                         240.498
trainer/Q1Pred Std                           74.3866
trainer/Q1Pred Max                          325.826
trainer/Q1Pred Min                            4.04288
trainer/Q2Pred Mean                         240.372
trainer/Q2Pred Std                           74.5604
trainer/Q2Pred Max                          324.169
trainer/Q2Pred Min                            0.915573
trainer/QTargetWithReg Mean                 239.177
trainer/QTargetWithReg Std                   75.8127
trainer/QTargetWithReg Max                  325.478
trainer/QTargetWithReg Min                    0.116373
trainer/PolicyLossWithoutReg Mean           240.373
trainer/PolicyLossWithoutReg Std             71.9284
trainer/PolicyLossWithoutReg Max            321.839
trainer/PolicyLossWithoutReg Min              9.77664
trainer/gradient_norm                       365.775
trainer/gradient_penalty                     -1.82887
trainer/gradient_percentage                  -0.00760847
exploration/num steps total              961000
exploration/num paths total                2121
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.18989
exploration/Rewards Std                       1.27222
exploration/Rewards Max                      10.2633
exploration/Rewards Min                      -0.470543
exploration/Returns Mean                   5189.89
exploration/Returns Std                       0
exploration/Returns Max                    5189.89
exploration/Returns Min                    5189.89
exploration/Num Paths                         1
exploration/Average Returns                5189.89
evaluation_0/num steps total                  7.56261e+06
evaluation_0/num paths total              15720
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22294
evaluation_0/Rewards Std                      1.30217
evaluation_0/Rewards Max                     10.3463
evaluation_0/Rewards Min                     -0.415665
evaluation_0/Returns Mean                  5222.94
evaluation_0/Returns Std                     25.4486
evaluation_0/Returns Max                   5264.61
evaluation_0/Returns Min                   5182.49
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5222.94
time/epoch (s)                                0
time/total (s)                            18303.7
Epoch                                       956
---------------------------------------  ----------------
2022-11-16 15:52:13.884416 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 957 finished
---------------------------------------  ----------------
epoch                                       957
total_step                               962000
replay_pool/size                         962000
trainer/alpha                                 0.0596173
trainer/alpha_loss                            0.227771
trainer/entropy                              -6.08077
trainer/qf_loss                               5.35193
trainer/state_noise                           0.005
trainer/policy_loss                        -239.313
trainer/policy_loss_without_entropy         241.482
trainer/entropy_penalty                      -0.36252
trainer/entropy_percentage                   -0.00150123
trainer/Q1Pred Mean                         241.204
trainer/Q1Pred Std                           76.2252
trainer/Q1Pred Max                          324.828
trainer/Q1Pred Min                            4.34292
trainer/Q2Pred Mean                         241.173
trainer/Q2Pred Std                           76.1313
trainer/Q2Pred Max                          327.336
trainer/Q2Pred Min                            6.61728
trainer/QTargetWithReg Mean                 241.121
trainer/QTargetWithReg Std                   76.3693
trainer/QTargetWithReg Max                  327.637
trainer/QTargetWithReg Min                    4.14127
trainer/PolicyLossWithoutReg Mean           241.482
trainer/PolicyLossWithoutReg Std             75.61
trainer/PolicyLossWithoutReg Max            325.129
trainer/PolicyLossWithoutReg Min              6.65036
trainer/gradient_norm                       361.382
trainer/gradient_penalty                     -1.80691
trainer/gradient_percentage                  -0.00748259
exploration/num steps total              962000
exploration/num paths total                2122
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14444
exploration/Rewards Std                       1.27032
exploration/Rewards Max                      10.1514
exploration/Rewards Min                      -0.492039
exploration/Returns Mean                   5144.44
exploration/Returns Std                       0
exploration/Returns Max                    5144.44
exploration/Returns Min                    5144.44
exploration/Num Paths                         1
exploration/Average Returns                5144.44
evaluation_0/num steps total                  7.57061e+06
evaluation_0/num paths total              15728
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11445
evaluation_0/Rewards Std                      1.27634
evaluation_0/Rewards Max                     10.1474
evaluation_0/Rewards Min                     -0.466773
evaluation_0/Returns Mean                  5114.45
evaluation_0/Returns Std                     14.92
evaluation_0/Returns Max                   5133.06
evaluation_0/Returns Min                   5094.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5114.45
time/epoch (s)                                0
time/total (s)                            18387.5
Epoch                                       957
---------------------------------------  ----------------
2022-11-16 15:53:47.995441 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 958 finished
---------------------------------------  ----------------
epoch                                       958
total_step                               963000
replay_pool/size                         963000
trainer/alpha                                 0.0575032
trainer/alpha_loss                            1.70996
trainer/entropy                              -6.59871
trainer/qf_loss                               7.98234
trainer/state_noise                           0.005
trainer/policy_loss                        -235.9
trainer/policy_loss_without_entropy         238.122
trainer/entropy_penalty                      -0.379447
trainer/entropy_percentage                   -0.0015935
trainer/Q1Pred Mean                         237.484
trainer/Q1Pred Std                           72.3756
trainer/Q1Pred Max                          327.827
trainer/Q1Pred Min                           18.4351
trainer/Q2Pred Mean                         237.753
trainer/Q2Pred Std                           72.6082
trainer/Q2Pred Max                          330.399
trainer/Q2Pred Min                           14.9326
trainer/QTargetWithReg Mean                 237.664
trainer/QTargetWithReg Std                   72.7758
trainer/QTargetWithReg Max                  328.82
trainer/QTargetWithReg Min                   17.0881
trainer/PolicyLossWithoutReg Mean           238.122
trainer/PolicyLossWithoutReg Std             71.8006
trainer/PolicyLossWithoutReg Max            328.597
trainer/PolicyLossWithoutReg Min             19.2965
trainer/gradient_norm                       368.4
trainer/gradient_penalty                     -1.842
trainer/gradient_percentage                  -0.00773555
exploration/num steps total              963000
exploration/num paths total                2123
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.05922
exploration/Rewards Std                       1.29168
exploration/Rewards Max                      10.2298
exploration/Rewards Min                      -0.472492
exploration/Returns Mean                   5059.22
exploration/Returns Std                       0
exploration/Returns Max                    5059.22
exploration/Returns Min                    5059.22
exploration/Num Paths                         1
exploration/Average Returns                5059.22
evaluation_0/num steps total                  7.57861e+06
evaluation_0/num paths total              15736
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.2001
evaluation_0/Rewards Std                      1.27209
evaluation_0/Rewards Max                     10.2371
evaluation_0/Rewards Min                     -0.552816
evaluation_0/Returns Mean                  5200.1
evaluation_0/Returns Std                     13.2303
evaluation_0/Returns Max                   5216.62
evaluation_0/Returns Min                   5175.7
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5200.1
time/epoch (s)                                0
time/total (s)                            18481.7
Epoch                                       958
---------------------------------------  ----------------
2022-11-16 15:54:31.426156 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 959 finished
---------------------------------------  ----------------
epoch                                       959
total_step                               964000
replay_pool/size                         964000
trainer/alpha                                 0.0582249
trainer/alpha_loss                           -1.34135
trainer/entropy                              -5.52823
trainer/qf_loss                               9.82413
trainer/state_noise                           0.005
trainer/policy_loss                        -239.998
trainer/policy_loss_without_entropy         242.236
trainer/entropy_penalty                      -0.321881
trainer/entropy_percentage                   -0.00132879
trainer/Q1Pred Mean                         241.784
trainer/Q1Pred Std                           69.8282
trainer/Q1Pred Max                          324.674
trainer/Q1Pred Min                            8.16391
trainer/Q2Pred Mean                         241.865
trainer/Q2Pred Std                           69.8161
trainer/Q2Pred Max                          325.982
trainer/Q2Pred Min                            4.82609
trainer/QTargetWithReg Mean                 241.603
trainer/QTargetWithReg Std                   70.3035
trainer/QTargetWithReg Max                  326.031
trainer/QTargetWithReg Min                    5.54973
trainer/PolicyLossWithoutReg Mean           242.236
trainer/PolicyLossWithoutReg Std             69.1621
trainer/PolicyLossWithoutReg Max            324.448
trainer/PolicyLossWithoutReg Min              5.87538
trainer/gradient_norm                       383.17
trainer/gradient_penalty                     -1.91585
trainer/gradient_percentage                  -0.00790904
exploration/num steps total              964000
exploration/num paths total                2124
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13753
exploration/Rewards Std                       1.26894
exploration/Rewards Max                      10.4398
exploration/Rewards Min                      -0.453068
exploration/Returns Mean                   5137.53
exploration/Returns Std                       0
exploration/Returns Max                    5137.53
exploration/Returns Min                    5137.53
exploration/Num Paths                         1
exploration/Average Returns                5137.53
evaluation_0/num steps total                  7.58661e+06
evaluation_0/num paths total              15744
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.23195
evaluation_0/Rewards Std                      1.27547
evaluation_0/Rewards Max                     10.2307
evaluation_0/Rewards Min                     -0.56748
evaluation_0/Returns Mean                  5231.95
evaluation_0/Returns Std                     17.2297
evaluation_0/Returns Max                   5253.29
evaluation_0/Returns Min                   5200.42
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5231.95
time/epoch (s)                                0
time/total (s)                            18525.1
Epoch                                       959
---------------------------------------  ----------------
2022-11-16 15:54:45.309744 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 960 finished
---------------------------------------  ----------------
epoch                                       960
total_step                               965000
replay_pool/size                         965000
trainer/alpha                                 0.0587225
trainer/alpha_loss                            1.2731
trainer/entropy                              -6.44903
trainer/qf_loss                               6.55756
trainer/state_noise                           0.005
trainer/policy_loss                        -238.997
trainer/policy_loss_without_entropy         241.233
trainer/entropy_penalty                      -0.378703
trainer/entropy_percentage                   -0.00156987
trainer/Q1Pred Mean                         240.187
trainer/Q1Pred Std                           73.8832
trainer/Q1Pred Max                          325.894
trainer/Q1Pred Min                           -0.773916
trainer/Q2Pred Mean                         240.158
trainer/Q2Pred Std                           73.6826
trainer/Q2Pred Max                          323.287
trainer/Q2Pred Min                           -1.86854
trainer/QTargetWithReg Mean                 240.437
trainer/QTargetWithReg Std                   73.7597
trainer/QTargetWithReg Max                  328.155
trainer/QTargetWithReg Min                   -5.9574
trainer/PolicyLossWithoutReg Mean           241.233
trainer/PolicyLossWithoutReg Std             72.5851
trainer/PolicyLossWithoutReg Max            324.081
trainer/PolicyLossWithoutReg Min             -4.96575
trainer/gradient_norm                       371.512
trainer/gradient_penalty                     -1.85756
trainer/gradient_percentage                  -0.00770028
exploration/num steps total              965000
exploration/num paths total                2125
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14212
exploration/Rewards Std                       1.27444
exploration/Rewards Max                      10.2329
exploration/Rewards Min                      -0.532019
exploration/Returns Mean                   5142.12
exploration/Returns Std                       0
exploration/Returns Max                    5142.12
exploration/Returns Min                    5142.12
exploration/Num Paths                         1
exploration/Average Returns                5142.12
evaluation_0/num steps total                  7.59461e+06
evaluation_0/num paths total              15752
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.06066
evaluation_0/Rewards Std                      1.29719
evaluation_0/Rewards Max                     10.2212
evaluation_0/Rewards Min                     -0.491718
evaluation_0/Returns Mean                  5060.66
evaluation_0/Returns Std                     52.7866
evaluation_0/Returns Max                   5191.91
evaluation_0/Returns Min                   5008.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5060.66
time/epoch (s)                                0
time/total (s)                            18539
Epoch                                       960
---------------------------------------  ----------------
2022-11-16 15:55:01.686826 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 961 finished
---------------------------------------  ----------------
epoch                                       961
total_step                               966000
replay_pool/size                         966000
trainer/alpha                                 0.0575395
trainer/alpha_loss                           -1.59287
trainer/entropy                              -5.44212
trainer/qf_loss                               7.51635
trainer/state_noise                           0.005
trainer/policy_loss                        -243.299
trainer/policy_loss_without_entropy         245.458
trainer/entropy_penalty                      -0.313137
trainer/entropy_percentage                   -0.00127573
trainer/Q1Pred Mean                         244.252
trainer/Q1Pred Std                           71.0439
trainer/Q1Pred Max                          319.16
trainer/Q1Pred Min                           14.2577
trainer/Q2Pred Mean                         245.036
trainer/Q2Pred Std                           71.1251
trainer/Q2Pred Max                          321.268
trainer/Q2Pred Min                           17.3892
trainer/QTargetWithReg Mean                 245.068
trainer/QTargetWithReg Std                   71.5666
trainer/QTargetWithReg Max                  322.663
trainer/QTargetWithReg Min                   13.607
trainer/PolicyLossWithoutReg Mean           245.458
trainer/PolicyLossWithoutReg Std             70.6281
trainer/PolicyLossWithoutReg Max            319.606
trainer/PolicyLossWithoutReg Min             15.3306
trainer/gradient_norm                       369.123
trainer/gradient_penalty                     -1.84561
trainer/gradient_percentage                  -0.00751907
exploration/num steps total              966000
exploration/num paths total                2126
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99323
exploration/Rewards Std                       1.29471
exploration/Rewards Max                      10.2652
exploration/Rewards Min                      -0.56028
exploration/Returns Mean                   4993.23
exploration/Returns Std                       0
exploration/Returns Max                    4993.23
exploration/Returns Min                    4993.23
exploration/Num Paths                         1
exploration/Average Returns                4993.23
evaluation_0/num steps total                  7.60261e+06
evaluation_0/num paths total              15760
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18243
evaluation_0/Rewards Std                      1.26812
evaluation_0/Rewards Max                     10.2307
evaluation_0/Rewards Min                     -0.441069
evaluation_0/Returns Mean                  5182.43
evaluation_0/Returns Std                     32.6411
evaluation_0/Returns Max                   5222.31
evaluation_0/Returns Min                   5118.32
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5182.43
time/epoch (s)                                0
time/total (s)                            18555.3
Epoch                                       961
---------------------------------------  ----------------
2022-11-16 15:55:17.524458 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 962 finished
---------------------------------------  ----------------
epoch                                       962
total_step                               967000
replay_pool/size                         967000
trainer/alpha                                 0.0572668
trainer/alpha_loss                            0.824557
trainer/entropy                              -6.28829
trainer/qf_loss                               5.82826
trainer/state_noise                           0.005
trainer/policy_loss                        -235.073
trainer/policy_loss_without_entropy         237.251
trainer/entropy_penalty                      -0.36011
trainer/entropy_percentage                   -0.00151785
trainer/Q1Pred Mean                         236.776
trainer/Q1Pred Std                           77.3117
trainer/Q1Pred Max                          323.441
trainer/Q1Pred Min                          -29.6563
trainer/Q2Pred Mean                         236.665
trainer/Q2Pred Std                           77.4583
trainer/Q2Pred Max                          325.412
trainer/Q2Pred Min                          -28.7093
trainer/QTargetWithReg Mean                 236.531
trainer/QTargetWithReg Std                   77.2793
trainer/QTargetWithReg Max                  327.116
trainer/QTargetWithReg Min                  -16.9672
trainer/PolicyLossWithoutReg Mean           237.251
trainer/PolicyLossWithoutReg Std             76.5344
trainer/PolicyLossWithoutReg Max            323.174
trainer/PolicyLossWithoutReg Min            -21.2914
trainer/gradient_norm                       363.59
trainer/gradient_penalty                     -1.81795
trainer/gradient_percentage                  -0.00766258
exploration/num steps total              967000
exploration/num paths total                2127
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16539
exploration/Rewards Std                       1.27274
exploration/Rewards Max                      10.2605
exploration/Rewards Min                      -0.462018
exploration/Returns Mean                   5165.39
exploration/Returns Std                       0
exploration/Returns Max                    5165.39
exploration/Returns Min                    5165.39
exploration/Num Paths                         1
exploration/Average Returns                5165.39
evaluation_0/num steps total                  7.61061e+06
evaluation_0/num paths total              15768
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.14922
evaluation_0/Rewards Std                      1.24651
evaluation_0/Rewards Max                      9.96987
evaluation_0/Rewards Min                     -0.513539
evaluation_0/Returns Mean                  5149.22
evaluation_0/Returns Std                     12.9691
evaluation_0/Returns Max                   5168.46
evaluation_0/Returns Min                   5130.09
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5149.22
time/epoch (s)                                0
time/total (s)                            18571.2
Epoch                                       962
---------------------------------------  ----------------
2022-11-16 15:55:33.525884 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 963 finished
---------------------------------------  ----------------
epoch                                       963
total_step                               968000
replay_pool/size                         968000
trainer/alpha                                 0.0576647
trainer/alpha_loss                            0.839225
trainer/entropy                              -6.29414
trainer/qf_loss                               8.85146
trainer/state_noise                           0.005
trainer/policy_loss                        -231.126
trainer/policy_loss_without_entropy         233.366
trainer/entropy_penalty                      -0.36295
trainer/entropy_percentage                   -0.00155528
trainer/Q1Pred Mean                         234.214
trainer/Q1Pred Std                           76.1422
trainer/Q1Pred Max                          325.403
trainer/Q1Pred Min                            1.67411
trainer/Q2Pred Mean                         233.077
trainer/Q2Pred Std                           76.112
trainer/Q2Pred Max                          323.799
trainer/Q2Pred Min                           -0.487176
trainer/QTargetWithReg Mean                 232.974
trainer/QTargetWithReg Std                   76.0716
trainer/QTargetWithReg Max                  324.957
trainer/QTargetWithReg Min                   -0.200737
trainer/PolicyLossWithoutReg Mean           233.366
trainer/PolicyLossWithoutReg Std             75.6316
trainer/PolicyLossWithoutReg Max            323.634
trainer/PolicyLossWithoutReg Min             -0.228426
trainer/gradient_norm                       375.435
trainer/gradient_penalty                     -1.87717
trainer/gradient_percentage                  -0.00804392
exploration/num steps total              968000
exploration/num paths total                2128
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.21916
exploration/Rewards Std                       1.32884
exploration/Rewards Max                      10.4902
exploration/Rewards Min                      -0.457909
exploration/Returns Mean                   5219.16
exploration/Returns Std                       0
exploration/Returns Max                    5219.16
exploration/Returns Min                    5219.16
exploration/Num Paths                         1
exploration/Average Returns                5219.16
evaluation_0/num steps total                  7.61861e+06
evaluation_0/num paths total              15776
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.12617
evaluation_0/Rewards Std                      1.25152
evaluation_0/Rewards Max                     10.1062
evaluation_0/Rewards Min                     -0.557223
evaluation_0/Returns Mean                  5126.17
evaluation_0/Returns Std                      9.95601
evaluation_0/Returns Max                   5134.66
evaluation_0/Returns Min                   5103.12
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5126.17
time/epoch (s)                                0
time/total (s)                            18587.2
Epoch                                       963
---------------------------------------  ----------------
2022-11-16 15:55:49.791690 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 964 finished
---------------------------------------  ----------------
epoch                                       964
total_step                               969000
replay_pool/size                         969000
trainer/alpha                                 0.0584673
trainer/alpha_loss                           -0.649727
trainer/entropy                              -5.77115
trainer/qf_loss                               6.10327
trainer/state_noise                           0.005
trainer/policy_loss                        -245.975
trainer/policy_loss_without_entropy         248.188
trainer/entropy_penalty                      -0.337423
trainer/entropy_percentage                   -0.00135955
trainer/Q1Pred Mean                         247.551
trainer/Q1Pred Std                           69.2672
trainer/Q1Pred Max                          322.69
trainer/Q1Pred Min                           38.1913
trainer/Q2Pred Mean                         247.958
trainer/Q2Pred Std                           69.0993
trainer/Q2Pred Max                          324.197
trainer/Q2Pred Min                           37.6817
trainer/QTargetWithReg Mean                 247.767
trainer/QTargetWithReg Std                   68.9919
trainer/QTargetWithReg Max                  323.5
trainer/QTargetWithReg Min                   35.4842
trainer/PolicyLossWithoutReg Mean           248.188
trainer/PolicyLossWithoutReg Std             68.5546
trainer/PolicyLossWithoutReg Max            323.609
trainer/PolicyLossWithoutReg Min             38.6034
trainer/gradient_norm                       375.206
trainer/gradient_penalty                     -1.87603
trainer/gradient_percentage                  -0.0075589
exploration/num steps total              969000
exploration/num paths total                2129
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17634
exploration/Rewards Std                       1.28558
exploration/Rewards Max                      10.0711
exploration/Rewards Min                      -0.432788
exploration/Returns Mean                   5176.34
exploration/Returns Std                       0
exploration/Returns Max                    5176.34
exploration/Returns Min                    5176.34
exploration/Num Paths                         1
exploration/Average Returns                5176.34
evaluation_0/num steps total                  7.62661e+06
evaluation_0/num paths total              15784
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.22856
evaluation_0/Rewards Std                      1.28363
evaluation_0/Rewards Max                     10.4136
evaluation_0/Rewards Min                     -0.456818
evaluation_0/Returns Mean                  5228.56
evaluation_0/Returns Std                     14.2752
evaluation_0/Returns Max                   5256.88
evaluation_0/Returns Min                   5205.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5228.56
time/epoch (s)                                0
time/total (s)                            18603.4
Epoch                                       964
---------------------------------------  ----------------
2022-11-16 15:56:05.856851 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 965 finished
---------------------------------------  ----------------
epoch                                       965
total_step                               970000
replay_pool/size                         970000
trainer/alpha                                 0.0585156
trainer/alpha_loss                           -0.67001
trainer/entropy                              -5.76396
trainer/qf_loss                               4.49546
trainer/state_noise                           0.005
trainer/policy_loss                        -235.413
trainer/policy_loss_without_entropy         237.608
trainer/entropy_penalty                      -0.337281
trainer/entropy_percentage                   -0.00141949
trainer/Q1Pred Mean                         237.451
trainer/Q1Pred Std                           74.3252
trainer/Q1Pred Max                          322.766
trainer/Q1Pred Min                           27.8445
trainer/Q2Pred Mean                         237.15
trainer/Q2Pred Std                           74.6736
trainer/Q2Pred Max                          323.44
trainer/Q2Pred Min                           26.0549
trainer/QTargetWithReg Mean                 237.008
trainer/QTargetWithReg Std                   74.9913
trainer/QTargetWithReg Max                  324
trainer/QTargetWithReg Min                   27.4209
trainer/PolicyLossWithoutReg Mean           237.608
trainer/PolicyLossWithoutReg Std             74.0956
trainer/PolicyLossWithoutReg Max            322.467
trainer/PolicyLossWithoutReg Min             27.1064
trainer/gradient_norm                       371.549
trainer/gradient_penalty                     -1.85775
trainer/gradient_percentage                  -0.00781855
exploration/num steps total              970000
exploration/num paths total                2130
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13037
exploration/Rewards Std                       1.27107
exploration/Rewards Max                      10.0837
exploration/Rewards Min                      -0.448629
exploration/Returns Mean                   5130.37
exploration/Returns Std                       0
exploration/Returns Max                    5130.37
exploration/Returns Min                    5130.37
exploration/Num Paths                         1
exploration/Average Returns                5130.37
evaluation_0/num steps total                  7.63461e+06
evaluation_0/num paths total              15792
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15416
evaluation_0/Rewards Std                      1.23222
evaluation_0/Rewards Max                     10.1913
evaluation_0/Rewards Min                     -0.416659
evaluation_0/Returns Mean                  5154.16
evaluation_0/Returns Std                     15.872
evaluation_0/Returns Max                   5181.28
evaluation_0/Returns Min                   5133.26
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5154.16
time/epoch (s)                                0
time/total (s)                            18619.5
Epoch                                       965
---------------------------------------  ----------------
2022-11-16 15:56:22.071311 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 966 finished
---------------------------------------  ----------------
epoch                                       966
total_step                               971000
replay_pool/size                         971000
trainer/alpha                                 0.0577775
trainer/alpha_loss                            0.746461
trainer/entropy                              -6.2618
trainer/qf_loss                               6.50637
trainer/state_noise                           0.005
trainer/policy_loss                        -242.908
trainer/policy_loss_without_entropy         245.113
trainer/entropy_penalty                      -0.361791
trainer/entropy_percentage                   -0.00147602
trainer/Q1Pred Mean                         245.078
trainer/Q1Pred Std                           70.5116
trainer/Q1Pred Max                          324.301
trainer/Q1Pred Min                           -3.63866
trainer/Q2Pred Mean                         244.635
trainer/Q2Pred Std                           70.427
trainer/Q2Pred Max                          325.725
trainer/Q2Pred Min                           -4.32205
trainer/QTargetWithReg Mean                 244.692
trainer/QTargetWithReg Std                   70.783
trainer/QTargetWithReg Max                  325.753
trainer/QTargetWithReg Min                   -7.18459
trainer/PolicyLossWithoutReg Mean           245.113
trainer/PolicyLossWithoutReg Std             69.5748
trainer/PolicyLossWithoutReg Max            323.888
trainer/PolicyLossWithoutReg Min              2.31015
trainer/gradient_norm                       368.699
trainer/gradient_penalty                     -1.84349
trainer/gradient_percentage                  -0.00752098
exploration/num steps total              971000
exploration/num paths total                2131
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17169
exploration/Rewards Std                       1.25744
exploration/Rewards Max                      10.1028
exploration/Rewards Min                      -0.413013
exploration/Returns Mean                   5171.69
exploration/Returns Std                       0
exploration/Returns Max                    5171.69
exploration/Returns Min                    5171.69
exploration/Num Paths                         1
exploration/Average Returns                5171.69
evaluation_0/num steps total                  7.64261e+06
evaluation_0/num paths total              15800
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.25333
evaluation_0/Rewards Std                      1.24999
evaluation_0/Rewards Max                     10.3484
evaluation_0/Rewards Min                     -0.436091
evaluation_0/Returns Mean                  5253.33
evaluation_0/Returns Std                     23.6319
evaluation_0/Returns Max                   5290.03
evaluation_0/Returns Min                   5217.46
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5253.33
time/epoch (s)                                0
time/total (s)                            18635.7
Epoch                                       966
---------------------------------------  ----------------
2022-11-16 15:56:37.917944 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 967 finished
---------------------------------------  ----------------
epoch                                       967
total_step                               972000
replay_pool/size                         972000
trainer/alpha                                 0.0597943
trainer/alpha_loss                            0.544202
trainer/entropy                              -6.19318
trainer/qf_loss                               6.7088
trainer/state_noise                           0.005
trainer/policy_loss                        -234.2
trainer/policy_loss_without_entropy         236.434
trainer/entropy_penalty                      -0.370317
trainer/entropy_percentage                   -0.00156626
trainer/Q1Pred Mean                         235.899
trainer/Q1Pred Std                           78.3219
trainer/Q1Pred Max                          325.887
trainer/Q1Pred Min                          -35.9107
trainer/Q2Pred Mean                         235.72
trainer/Q2Pred Std                           78.8072
trainer/Q2Pred Max                          326.04
trainer/Q2Pred Min                          -46.3734
trainer/QTargetWithReg Mean                 236.062
trainer/QTargetWithReg Std                   78.7131
trainer/QTargetWithReg Max                  325.166
trainer/QTargetWithReg Min                  -48.4208
trainer/PolicyLossWithoutReg Mean           236.434
trainer/PolicyLossWithoutReg Std             77.9923
trainer/PolicyLossWithoutReg Max            325.374
trainer/PolicyLossWithoutReg Min            -45.8122
trainer/gradient_norm                       372.74
trainer/gradient_penalty                     -1.8637
trainer/gradient_percentage                  -0.00788253
exploration/num steps total              972000
exploration/num paths total                2132
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.16182
exploration/Rewards Std                       1.26344
exploration/Rewards Max                      10.1754
exploration/Rewards Min                      -0.392072
exploration/Returns Mean                   5161.82
exploration/Returns Std                       0
exploration/Returns Max                    5161.82
exploration/Returns Min                    5161.82
exploration/Num Paths                         1
exploration/Average Returns                5161.82
evaluation_0/num steps total                  7.65061e+06
evaluation_0/num paths total              15808
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10097
evaluation_0/Rewards Std                      1.23698
evaluation_0/Rewards Max                      9.90801
evaluation_0/Rewards Min                     -0.489081
evaluation_0/Returns Mean                  5100.97
evaluation_0/Returns Std                     31.9615
evaluation_0/Returns Max                   5126.9
evaluation_0/Returns Min                   5019.9
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5100.97
time/epoch (s)                                0
time/total (s)                            18651.6
Epoch                                       967
---------------------------------------  ----------------
2022-11-16 15:56:54.426030 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 968 finished
---------------------------------------  ----------------
epoch                                       968
total_step                               973000
replay_pool/size                         973000
trainer/alpha                                 0.0588373
trainer/alpha_loss                            0.452909
trainer/entropy                              -6.15987
trainer/qf_loss                               6.32619
trainer/state_noise                           0.005
trainer/policy_loss                        -244.298
trainer/policy_loss_without_entropy         246.492
trainer/entropy_penalty                      -0.36243
trainer/entropy_percentage                   -0.00147035
trainer/Q1Pred Mean                         246.204
trainer/Q1Pred Std                           71.5481
trainer/Q1Pred Max                          324.335
trainer/Q1Pred Min                           15.1809
trainer/Q2Pred Mean                         246.17
trainer/Q2Pred Std                           71.9235
trainer/Q2Pred Max                          324.707
trainer/Q2Pred Min                           16.8887
trainer/QTargetWithReg Mean                 245.881
trainer/QTargetWithReg Std                   71.8467
trainer/QTargetWithReg Max                  324.931
trainer/QTargetWithReg Min                   14.8391
trainer/PolicyLossWithoutReg Mean           246.492
trainer/PolicyLossWithoutReg Std             71.2076
trainer/PolicyLossWithoutReg Max            324.42
trainer/PolicyLossWithoutReg Min             15.8276
trainer/gradient_norm                       366.354
trainer/gradient_penalty                     -1.83177
trainer/gradient_percentage                  -0.00743135
exploration/num steps total              973000
exploration/num paths total                2133
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10474
exploration/Rewards Std                       1.29512
exploration/Rewards Max                      10.4321
exploration/Rewards Min                      -0.531145
exploration/Returns Mean                   5104.74
exploration/Returns Std                       0
exploration/Returns Max                    5104.74
exploration/Returns Min                    5104.74
exploration/Num Paths                         1
exploration/Average Returns                5104.74
evaluation_0/num steps total                  7.65861e+06
evaluation_0/num paths total              15816
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.86341
evaluation_0/Rewards Std                      1.23371
evaluation_0/Rewards Max                      9.7419
evaluation_0/Rewards Min                     -0.628595
evaluation_0/Returns Mean                  4863.41
evaluation_0/Returns Std                     77.4628
evaluation_0/Returns Max                   5042.14
evaluation_0/Returns Min                   4796.33
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4863.41
time/epoch (s)                                0
time/total (s)                            18668.1
Epoch                                       968
---------------------------------------  ----------------
2022-11-16 15:57:10.233258 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 969 finished
---------------------------------------  ----------------
epoch                                       969
total_step                               974000
replay_pool/size                         974000
trainer/alpha                                 0.0571967
trainer/alpha_loss                           -0.238113
trainer/entropy                              -5.91678
trainer/qf_loss                               8.60512
trainer/state_noise                           0.005
trainer/policy_loss                        -246.015
trainer/policy_loss_without_entropy         248.209
trainer/entropy_penalty                      -0.33842
trainer/entropy_percentage                   -0.00136345
trainer/Q1Pred Mean                         248.211
trainer/Q1Pred Std                           70.7052
trainer/Q1Pred Max                          327.76
trainer/Q1Pred Min                            0.6665
trainer/Q2Pred Mean                         247.512
trainer/Q2Pred Std                           70.7358
trainer/Q2Pred Max                          328.028
trainer/Q2Pred Min                            2.06474
trainer/QTargetWithReg Mean                 248.062
trainer/QTargetWithReg Std                   70.8364
trainer/QTargetWithReg Max                  326.149
trainer/QTargetWithReg Min                    3.42717
trainer/PolicyLossWithoutReg Mean           248.209
trainer/PolicyLossWithoutReg Std             69.5448
trainer/PolicyLossWithoutReg Max            326.093
trainer/PolicyLossWithoutReg Min              2.00281
trainer/gradient_norm                       371.097
trainer/gradient_penalty                     -1.85549
trainer/gradient_percentage                  -0.0074755
exploration/num steps total              974000
exploration/num paths total                2134
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06009
exploration/Rewards Std                       1.28021
exploration/Rewards Max                      10.1239
exploration/Rewards Min                      -0.585351
exploration/Returns Mean                   5060.09
exploration/Returns Std                       0
exploration/Returns Max                    5060.09
exploration/Returns Min                    5060.09
exploration/Num Paths                         1
exploration/Average Returns                5060.09
evaluation_0/num steps total                  7.66661e+06
evaluation_0/num paths total              15824
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.09044
evaluation_0/Rewards Std                      1.25059
evaluation_0/Rewards Max                     10.0347
evaluation_0/Rewards Min                     -0.523147
evaluation_0/Returns Mean                  5090.44
evaluation_0/Returns Std                     32.9801
evaluation_0/Returns Max                   5140.99
evaluation_0/Returns Min                   5038.63
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5090.44
time/epoch (s)                                0
time/total (s)                            18683.9
Epoch                                       969
---------------------------------------  ----------------
2022-11-16 15:57:26.583835 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 970 finished
---------------------------------------  ----------------
epoch                                       970
total_step                               975000
replay_pool/size                         975000
trainer/alpha                                 0.0581646
trainer/alpha_loss                           -0.134492
trainer/entropy                              -5.95272
trainer/qf_loss                              10.5522
trainer/state_noise                           0.005
trainer/policy_loss                        -243.164
trainer/policy_loss_without_entropy         245.425
trainer/entropy_penalty                      -0.346237
trainer/entropy_percentage                   -0.00141077
trainer/Q1Pred Mean                         244.943
trainer/Q1Pred Std                           72.1215
trainer/Q1Pred Max                          325.732
trainer/Q1Pred Min                          -11.2282
trainer/Q2Pred Mean                         245.496
trainer/Q2Pred Std                           72.0118
trainer/Q2Pred Max                          325.7
trainer/Q2Pred Min                          -10.6321
trainer/QTargetWithReg Mean                 244.932
trainer/QTargetWithReg Std                   72.5416
trainer/QTargetWithReg Max                  325.868
trainer/QTargetWithReg Min                  -12.0643
trainer/PolicyLossWithoutReg Mean           245.425
trainer/PolicyLossWithoutReg Std             71.3166
trainer/PolicyLossWithoutReg Max            325.092
trainer/PolicyLossWithoutReg Min             -4.43467
trainer/gradient_norm                       382.827
trainer/gradient_penalty                     -1.91414
trainer/gradient_percentage                  -0.00779929
exploration/num steps total              975000
exploration/num paths total                2135
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.1021
exploration/Rewards Std                       1.27946
exploration/Rewards Max                      10.3674
exploration/Rewards Min                      -0.54507
exploration/Returns Mean                   5102.1
exploration/Returns Std                       0
exploration/Returns Max                    5102.1
exploration/Returns Min                    5102.1
exploration/Num Paths                         1
exploration/Average Returns                5102.1
evaluation_0/num steps total                  7.67461e+06
evaluation_0/num paths total              15832
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18807
evaluation_0/Rewards Std                      1.24892
evaluation_0/Rewards Max                     10.0505
evaluation_0/Rewards Min                     -0.434002
evaluation_0/Returns Mean                  5188.07
evaluation_0/Returns Std                     10.5621
evaluation_0/Returns Max                   5202.9
evaluation_0/Returns Min                   5174.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5188.07
time/epoch (s)                                0
time/total (s)                            18700.2
Epoch                                       970
---------------------------------------  ----------------
2022-11-16 15:57:42.577178 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 971 finished
---------------------------------------  ----------------
epoch                                       971
total_step                               976000
replay_pool/size                         976000
trainer/alpha                                 0.0586296
trainer/alpha_loss                           -1.0158
trainer/entropy                              -5.64189
trainer/qf_loss                               8.30293
trainer/state_noise                           0.005
trainer/policy_loss                        -241.034
trainer/policy_loss_without_entropy         243.233
trainer/entropy_penalty                      -0.330782
trainer/entropy_percentage                   -0.00135993
trainer/Q1Pred Mean                         242.059
trainer/Q1Pred Std                           73.6423
trainer/Q1Pred Max                          330.168
trainer/Q1Pred Min                           16.6504
trainer/Q2Pred Mean                         242.794
trainer/Q2Pred Std                           73.2212
trainer/Q2Pred Max                          330.844
trainer/Q2Pred Min                           14.3411
trainer/QTargetWithReg Mean                 242.648
trainer/QTargetWithReg Std                   73.3598
trainer/QTargetWithReg Max                  329.805
trainer/QTargetWithReg Min                   13.6386
trainer/PolicyLossWithoutReg Mean           243.233
trainer/PolicyLossWithoutReg Std             72.9257
trainer/PolicyLossWithoutReg Max            331.192
trainer/PolicyLossWithoutReg Min             15.1363
trainer/gradient_norm                       373.656
trainer/gradient_penalty                     -1.86828
trainer/gradient_percentage                  -0.00768102
exploration/num steps total              976000
exploration/num paths total                2136
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.13581
exploration/Rewards Std                       1.29477
exploration/Rewards Max                      10.2747
exploration/Rewards Min                      -0.389668
exploration/Returns Mean                   5135.81
exploration/Returns Std                       0
exploration/Returns Max                    5135.81
exploration/Returns Min                    5135.81
exploration/Num Paths                         1
exploration/Average Returns                5135.81
evaluation_0/num steps total                  7.68261e+06
evaluation_0/num paths total              15840
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11263
evaluation_0/Rewards Std                      1.28038
evaluation_0/Rewards Max                     10.08
evaluation_0/Rewards Min                     -0.549533
evaluation_0/Returns Mean                  5112.63
evaluation_0/Returns Std                     22.2902
evaluation_0/Returns Max                   5155.15
evaluation_0/Returns Min                   5078.57
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5112.63
time/epoch (s)                                0
time/total (s)                            18716.2
Epoch                                       971
---------------------------------------  ----------------
2022-11-16 15:57:59.041566 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 972 finished
---------------------------------------  ----------------
epoch                                       972
total_step                               977000
replay_pool/size                         977000
trainer/alpha                                 0.0576151
trainer/alpha_loss                           -0.415857
trainer/entropy                              -5.85429
trainer/qf_loss                               7.39972
trainer/state_noise                           0.005
trainer/policy_loss                        -239.232
trainer/policy_loss_without_entropy         241.423
trainer/entropy_penalty                      -0.337295
trainer/entropy_percentage                   -0.00139711
trainer/Q1Pred Mean                         240.919
trainer/Q1Pred Std                           77.1916
trainer/Q1Pred Max                          326.328
trainer/Q1Pred Min                            0.824022
trainer/Q2Pred Mean                         241.378
trainer/Q2Pred Std                           77.3446
trainer/Q2Pred Max                          325.421
trainer/Q2Pred Min                            5.81266
trainer/QTargetWithReg Mean                 240.906
trainer/QTargetWithReg Std                   77.3628
trainer/QTargetWithReg Max                  326.993
trainer/QTargetWithReg Min                    3.976
trainer/PolicyLossWithoutReg Mean           241.423
trainer/PolicyLossWithoutReg Std             76.4198
trainer/PolicyLossWithoutReg Max            326.167
trainer/PolicyLossWithoutReg Min              4.05119
trainer/gradient_norm                       370.788
trainer/gradient_penalty                     -1.85394
trainer/gradient_percentage                  -0.00767921
exploration/num steps total              977000
exploration/num paths total                2137
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.12711
exploration/Rewards Std                       1.27469
exploration/Rewards Max                      10.2059
exploration/Rewards Min                      -0.43108
exploration/Returns Mean                   5127.11
exploration/Returns Std                       0
exploration/Returns Max                    5127.11
exploration/Returns Min                    5127.11
exploration/Num Paths                         1
exploration/Average Returns                5127.11
evaluation_0/num steps total                  7.69061e+06
evaluation_0/num paths total              15848
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.17499
evaluation_0/Rewards Std                      1.29518
evaluation_0/Rewards Max                     10.2712
evaluation_0/Rewards Min                     -0.512215
evaluation_0/Returns Mean                  5174.99
evaluation_0/Returns Std                     14.3357
evaluation_0/Returns Max                   5200.54
evaluation_0/Returns Min                   5159.06
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5174.99
time/epoch (s)                                0
time/total (s)                            18732.7
Epoch                                       972
---------------------------------------  ----------------
2022-11-16 15:58:15.097696 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 973 finished
---------------------------------------  ----------------
epoch                                       973
total_step                               978000
replay_pool/size                         978000
trainer/alpha                                 0.0592772
trainer/alpha_loss                            0.900525
trainer/entropy                              -6.3187
trainer/qf_loss                               6.66353
trainer/state_noise                           0.005
trainer/policy_loss                        -235.729
trainer/policy_loss_without_entropy         238.032
trainer/entropy_penalty                      -0.374555
trainer/entropy_percentage                   -0.00157355
trainer/Q1Pred Mean                         238.05
trainer/Q1Pred Std                           74.7729
trainer/Q1Pred Max                          325.494
trainer/Q1Pred Min                           19.9506
trainer/Q2Pred Mean                         237.488
trainer/Q2Pred Std                           74.8199
trainer/Q2Pred Max                          325.254
trainer/Q2Pred Min                           20.1449
trainer/QTargetWithReg Mean                 237.922
trainer/QTargetWithReg Std                   74.8317
trainer/QTargetWithReg Max                  327.732
trainer/QTargetWithReg Min                   21.1717
trainer/PolicyLossWithoutReg Mean           238.032
trainer/PolicyLossWithoutReg Std             74.3832
trainer/PolicyLossWithoutReg Max            325.078
trainer/PolicyLossWithoutReg Min             19.0561
trainer/gradient_norm                       385.642
trainer/gradient_penalty                     -1.92821
trainer/gradient_percentage                  -0.00810064
exploration/num steps total              978000
exploration/num paths total                2138
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14708
exploration/Rewards Std                       1.29234
exploration/Rewards Max                      10.2656
exploration/Rewards Min                      -0.513543
exploration/Returns Mean                   5147.08
exploration/Returns Std                       0
exploration/Returns Max                    5147.08
exploration/Returns Min                    5147.08
exploration/Num Paths                         1
exploration/Average Returns                5147.08
evaluation_0/num steps total                  7.69861e+06
evaluation_0/num paths total              15856
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16469
evaluation_0/Rewards Std                      1.25723
evaluation_0/Rewards Max                     10.1287
evaluation_0/Rewards Min                     -0.408943
evaluation_0/Returns Mean                  5164.69
evaluation_0/Returns Std                      6.30553
evaluation_0/Returns Max                   5176.2
evaluation_0/Returns Min                   5155.31
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5164.69
time/epoch (s)                                0
time/total (s)                            18748.7
Epoch                                       973
---------------------------------------  ----------------
2022-11-16 15:58:30.898064 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 974 finished
---------------------------------------  ----------------
epoch                                       974
total_step                               979000
replay_pool/size                         979000
trainer/alpha                                 0.0579763
trainer/alpha_loss                            0.25519
trainer/entropy                              -6.08961
trainer/qf_loss                               6.8446
trainer/state_noise                           0.005
trainer/policy_loss                        -237.432
trainer/policy_loss_without_entropy         239.683
trainer/entropy_penalty                      -0.353053
trainer/entropy_percentage                   -0.001473
trainer/Q1Pred Mean                         239.167
trainer/Q1Pred Std                           78.065
trainer/Q1Pred Max                          322.09
trainer/Q1Pred Min                           -3.54952
trainer/Q2Pred Mean                         238.933
trainer/Q2Pred Std                           78.815
trainer/Q2Pred Max                          321.75
trainer/Q2Pred Min                           -8.96894
trainer/QTargetWithReg Mean                 239.245
trainer/QTargetWithReg Std                   78.2506
trainer/QTargetWithReg Max                  321.667
trainer/QTargetWithReg Min                   -3.32832
trainer/PolicyLossWithoutReg Mean           239.683
trainer/PolicyLossWithoutReg Std             77.7846
trainer/PolicyLossWithoutReg Max            322.561
trainer/PolicyLossWithoutReg Min             -3.34574
trainer/gradient_norm                       379.497
trainer/gradient_penalty                     -1.89748
trainer/gradient_percentage                  -0.00791664
exploration/num steps total              979000
exploration/num paths total                2139
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.17074
exploration/Rewards Std                       1.27887
exploration/Rewards Max                      10.2632
exploration/Rewards Min                      -0.385395
exploration/Returns Mean                   5170.74
exploration/Returns Std                       0
exploration/Returns Max                    5170.74
exploration/Returns Min                    5170.74
exploration/Num Paths                         1
exploration/Average Returns                5170.74
evaluation_0/num steps total                  7.70661e+06
evaluation_0/num paths total              15864
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.12268
evaluation_0/Rewards Std                      1.25578
evaluation_0/Rewards Max                     10.0152
evaluation_0/Rewards Min                     -0.488146
evaluation_0/Returns Mean                  5122.68
evaluation_0/Returns Std                      8.74909
evaluation_0/Returns Max                   5134.84
evaluation_0/Returns Min                   5105.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5122.68
time/epoch (s)                                0
time/total (s)                            18764.5
Epoch                                       974
---------------------------------------  ----------------
2022-11-16 15:58:47.427773 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 975 finished
---------------------------------------  ----------------
epoch                                       975
total_step                               980000
replay_pool/size                         980000
trainer/alpha                                 0.0589283
trainer/alpha_loss                            0.0792003
trainer/entropy                              -6.02797
trainer/qf_loss                               7.21587
trainer/state_noise                           0.005
trainer/policy_loss                        -236.541
trainer/policy_loss_without_entropy         238.805
trainer/entropy_penalty                      -0.355218
trainer/entropy_percentage                   -0.00148748
trainer/Q1Pred Mean                         238.237
trainer/Q1Pred Std                           74.023
trainer/Q1Pred Max                          326.883
trainer/Q1Pred Min                            6.62767
trainer/Q2Pred Mean                         238.317
trainer/Q2Pred Std                           73.7053
trainer/Q2Pred Max                          325.495
trainer/Q2Pred Min                           11.9378
trainer/QTargetWithReg Mean                 239.03
trainer/QTargetWithReg Std                   73.8401
trainer/QTargetWithReg Max                  326.302
trainer/QTargetWithReg Min                   14.016
trainer/PolicyLossWithoutReg Mean           238.805
trainer/PolicyLossWithoutReg Std             73.0733
trainer/PolicyLossWithoutReg Max            324.789
trainer/PolicyLossWithoutReg Min             28.4452
trainer/gradient_norm                       381.817
trainer/gradient_penalty                     -1.90908
trainer/gradient_percentage                  -0.00799431
exploration/num steps total              980000
exploration/num paths total                2140
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08942
exploration/Rewards Std                       1.3042
exploration/Rewards Max                      10.2569
exploration/Rewards Min                      -0.487482
exploration/Returns Mean                   5089.42
exploration/Returns Std                       0
exploration/Returns Max                    5089.42
exploration/Returns Min                    5089.42
exploration/Num Paths                         1
exploration/Average Returns                5089.42
evaluation_0/num steps total                  7.71461e+06
evaluation_0/num paths total              15872
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10812
evaluation_0/Rewards Std                      1.25022
evaluation_0/Rewards Max                      9.93067
evaluation_0/Rewards Min                     -0.570028
evaluation_0/Returns Mean                  5108.12
evaluation_0/Returns Std                     17.8985
evaluation_0/Returns Max                   5127.5
evaluation_0/Returns Min                   5067.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5108.12
time/epoch (s)                                0
time/total (s)                            18781.1
Epoch                                       975
---------------------------------------  ----------------
2022-11-16 15:59:03.143625 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 976 finished
---------------------------------------  ----------------
epoch                                       976
total_step                               981000
replay_pool/size                         981000
trainer/alpha                                 0.0581967
trainer/alpha_loss                            0.0973653
trainer/entropy                              -6.03424
trainer/qf_loss                               7.85853
trainer/state_noise                           0.005
trainer/policy_loss                        -243.617
trainer/policy_loss_without_entropy         245.813
trainer/entropy_penalty                      -0.351173
trainer/entropy_percentage                   -0.00142862
trainer/Q1Pred Mean                         245.967
trainer/Q1Pred Std                           72.8443
trainer/Q1Pred Max                          324.996
trainer/Q1Pred Min                           12.0175
trainer/Q2Pred Mean                         245.387
trainer/Q2Pred Std                           72.9089
trainer/Q2Pred Max                          323.153
trainer/Q2Pred Min                           11.428
trainer/QTargetWithReg Mean                 246.142
trainer/QTargetWithReg Std                   72.9438
trainer/QTargetWithReg Max                  323.435
trainer/QTargetWithReg Min                   12.1987
trainer/PolicyLossWithoutReg Mean           245.813
trainer/PolicyLossWithoutReg Std             72.2294
trainer/PolicyLossWithoutReg Max            323.587
trainer/PolicyLossWithoutReg Min             11.4016
trainer/gradient_norm                       368.879
trainer/gradient_penalty                     -1.84439
trainer/gradient_percentage                  -0.00750324
exploration/num steps total              981000
exploration/num paths total                2141
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.14339
exploration/Rewards Std                       1.29226
exploration/Rewards Max                      10.0398
exploration/Rewards Min                      -0.423633
exploration/Returns Mean                   5143.39
exploration/Returns Std                       0
exploration/Returns Max                    5143.39
exploration/Returns Min                    5143.39
exploration/Num Paths                         1
exploration/Average Returns                5143.39
evaluation_0/num steps total                  7.72261e+06
evaluation_0/num paths total              15880
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.18898
evaluation_0/Rewards Std                      1.28613
evaluation_0/Rewards Max                     10.216
evaluation_0/Rewards Min                     -0.539184
evaluation_0/Returns Mean                  5188.98
evaluation_0/Returns Std                     18.496
evaluation_0/Returns Max                   5220.3
evaluation_0/Returns Min                   5159.94
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5188.98
time/epoch (s)                                0
time/total (s)                            18796.8
Epoch                                       976
---------------------------------------  ----------------
2022-11-16 15:59:19.545473 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 977 finished
---------------------------------------  ----------------
epoch                                       977
total_step                               982000
replay_pool/size                         982000
trainer/alpha                                 0.0567154
trainer/alpha_loss                            1.8825
trainer/entropy                              -6.65599
trainer/qf_loss                               9.47951
trainer/state_noise                           0.005
trainer/policy_loss                        -234.767
trainer/policy_loss_without_entropy         236.956
trainer/entropy_penalty                      -0.377497
trainer/entropy_percentage                   -0.00159311
trainer/Q1Pred Mean                         235.717
trainer/Q1Pred Std                           76.8077
trainer/Q1Pred Max                          325.223
trainer/Q1Pred Min                            8.17429
trainer/Q2Pred Mean                         235.562
trainer/Q2Pred Std                           77.638
trainer/Q2Pred Max                          326.449
trainer/Q2Pred Min                           -4.18702
trainer/QTargetWithReg Mean                 235.755
trainer/QTargetWithReg Std                   77.1176
trainer/QTargetWithReg Max                  322.987
trainer/QTargetWithReg Min                   -3.78074
trainer/PolicyLossWithoutReg Mean           236.957
trainer/PolicyLossWithoutReg Std             75.2644
trainer/PolicyLossWithoutReg Max            324.771
trainer/PolicyLossWithoutReg Min             10.3411
trainer/gradient_norm                       362.374
trainer/gradient_penalty                     -1.81187
trainer/gradient_percentage                  -0.00764642
exploration/num steps total              982000
exploration/num paths total                2142
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.98745
exploration/Rewards Std                       1.31929
exploration/Rewards Max                      10.0046
exploration/Rewards Min                      -0.521042
exploration/Returns Mean                   4987.45
exploration/Returns Std                       0
exploration/Returns Max                    4987.45
exploration/Returns Min                    4987.45
exploration/Num Paths                         1
exploration/Average Returns                4987.45
evaluation_0/num steps total                  7.73061e+06
evaluation_0/num paths total              15888
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13788
evaluation_0/Rewards Std                      1.26283
evaluation_0/Rewards Max                     10.2875
evaluation_0/Rewards Min                     -0.469045
evaluation_0/Returns Mean                  5137.88
evaluation_0/Returns Std                     18.9797
evaluation_0/Returns Max                   5166.17
evaluation_0/Returns Min                   5102.28
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5137.88
time/epoch (s)                                0
time/total (s)                            18813.2
Epoch                                       977
---------------------------------------  ----------------
2022-11-16 15:59:35.478463 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 978 finished
---------------------------------------  ----------------
epoch                                       978
total_step                               983000
replay_pool/size                         983000
trainer/alpha                                 0.0568527
trainer/alpha_loss                            0.0898594
trainer/entropy                              -6.03134
trainer/qf_loss                               6.18233
trainer/state_noise                           0.005
trainer/policy_loss                        -236.257
trainer/policy_loss_without_entropy         238.47
trainer/entropy_penalty                      -0.342898
trainer/entropy_percentage                   -0.00143791
trainer/Q1Pred Mean                         237.744
trainer/Q1Pred Std                           78.4242
trainer/Q1Pred Max                          321.214
trainer/Q1Pred Min                          -14.5549
trainer/Q2Pred Mean                         238.346
trainer/Q2Pred Std                           78.0902
trainer/Q2Pred Max                          323.539
trainer/Q2Pred Min                          -16.5142
trainer/QTargetWithReg Mean                 238.011
trainer/QTargetWithReg Std                   78.6728
trainer/QTargetWithReg Max                  322.645
trainer/QTargetWithReg Min                  -14.1991
trainer/PolicyLossWithoutReg Mean           238.47
trainer/PolicyLossWithoutReg Std             77.602
trainer/PolicyLossWithoutReg Max            322.304
trainer/PolicyLossWithoutReg Min            -13.7914
trainer/gradient_norm                       374
trainer/gradient_penalty                     -1.87
trainer/gradient_percentage                  -0.00784166
exploration/num steps total              983000
exploration/num paths total                2143
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.10028
exploration/Rewards Std                       1.26529
exploration/Rewards Max                      10.1204
exploration/Rewards Min                      -0.40353
exploration/Returns Mean                   5100.28
exploration/Returns Std                       0
exploration/Returns Max                    5100.28
exploration/Returns Min                    5100.28
exploration/Num Paths                         1
exploration/Average Returns                5100.28
evaluation_0/num steps total                  7.73861e+06
evaluation_0/num paths total              15896
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16032
evaluation_0/Rewards Std                      1.24769
evaluation_0/Rewards Max                     10.0593
evaluation_0/Rewards Min                     -0.486715
evaluation_0/Returns Mean                  5160.32
evaluation_0/Returns Std                      8.43295
evaluation_0/Returns Max                   5174.51
evaluation_0/Returns Min                   5149.53
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5160.32
time/epoch (s)                                0
time/total (s)                            18829.1
Epoch                                       978
---------------------------------------  ----------------
2022-11-16 15:59:51.577243 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 979 finished
---------------------------------------  ----------------
epoch                                       979
total_step                               984000
replay_pool/size                         984000
trainer/alpha                                 0.0562008
trainer/alpha_loss                           -0.776601
trainer/entropy                              -5.73023
trainer/qf_loss                               4.17173
trainer/state_noise                           0.005
trainer/policy_loss                        -240.315
trainer/policy_loss_without_entropy         242.551
trainer/entropy_penalty                      -0.322044
trainer/entropy_percentage                   -0.00132774
trainer/Q1Pred Mean                         242.29
trainer/Q1Pred Std                           73.0537
trainer/Q1Pred Max                          325.625
trainer/Q1Pred Min                           -6.2515
trainer/Q2Pred Mean                         242.599
trainer/Q2Pred Std                           73.2659
trainer/Q2Pred Max                          325.217
trainer/Q2Pred Min                           -6.41106
trainer/QTargetWithReg Mean                 242.441
trainer/QTargetWithReg Std                   73.1388
trainer/QTargetWithReg Max                  324.813
trainer/QTargetWithReg Min                   -7.00561
trainer/PolicyLossWithoutReg Mean           242.551
trainer/PolicyLossWithoutReg Std             72.3748
trainer/PolicyLossWithoutReg Max            324.949
trainer/PolicyLossWithoutReg Min             -1.40152
trainer/gradient_norm                       382.64
trainer/gradient_penalty                     -1.9132
trainer/gradient_percentage                  -0.00788783
exploration/num steps total              984000
exploration/num paths total                2144
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.07906
exploration/Rewards Std                       1.257
exploration/Rewards Max                      10.2025
exploration/Rewards Min                      -0.473603
exploration/Returns Mean                   5079.06
exploration/Returns Std                       0
exploration/Returns Max                    5079.06
exploration/Returns Min                    5079.06
exploration/Num Paths                         1
exploration/Average Returns                5079.06
evaluation_0/num steps total                  7.74661e+06
evaluation_0/num paths total              15904
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.16195
evaluation_0/Rewards Std                      1.25418
evaluation_0/Rewards Max                     10.129
evaluation_0/Rewards Min                     -0.453265
evaluation_0/Returns Mean                  5161.95
evaluation_0/Returns Std                     26.0677
evaluation_0/Returns Max                   5207.46
evaluation_0/Returns Min                   5120.59
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5161.95
time/epoch (s)                                0
time/total (s)                            18845.2
Epoch                                       979
---------------------------------------  ----------------
2022-11-16 16:00:07.769549 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 980 finished
---------------------------------------  ----------------
epoch                                       980
total_step                               985000
replay_pool/size                         985000
trainer/alpha                                 0.0576238
trainer/alpha_loss                            0.714665
trainer/entropy                              -6.25041
trainer/qf_loss                               9.58935
trainer/state_noise                           0.005
trainer/policy_loss                        -232.166
trainer/policy_loss_without_entropy         234.399
trainer/entropy_penalty                      -0.360172
trainer/entropy_percentage                   -0.00153658
trainer/Q1Pred Mean                         233.339
trainer/Q1Pred Std                           81.5396
trainer/Q1Pred Max                          332.174
trainer/Q1Pred Min                            7.14589
trainer/Q2Pred Mean                         233.619
trainer/Q2Pred Std                           81.5961
trainer/Q2Pred Max                          329.241
trainer/Q2Pred Min                            7.8374
trainer/QTargetWithReg Mean                 233.963
trainer/QTargetWithReg Std                   81.546
trainer/QTargetWithReg Max                  330.399
trainer/QTargetWithReg Min                   11.9525
trainer/PolicyLossWithoutReg Mean           234.399
trainer/PolicyLossWithoutReg Std             80.7985
trainer/PolicyLossWithoutReg Max            329.908
trainer/PolicyLossWithoutReg Min              7.83903
trainer/gradient_norm                       374.679
trainer/gradient_penalty                     -1.87339
trainer/gradient_percentage                  -0.00799232
exploration/num steps total              985000
exploration/num paths total                2145
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.08675
exploration/Rewards Std                       1.28141
exploration/Rewards Max                      10.0156
exploration/Rewards Min                      -0.413748
exploration/Returns Mean                   5086.75
exploration/Returns Std                       0
exploration/Returns Max                    5086.75
exploration/Returns Min                    5086.75
exploration/Num Paths                         1
exploration/Average Returns                5086.75
evaluation_0/num steps total                  7.75461e+06
evaluation_0/num paths total              15912
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.13509
evaluation_0/Rewards Std                      1.27302
evaluation_0/Rewards Max                     10.1289
evaluation_0/Rewards Min                     -0.442279
evaluation_0/Returns Mean                  5135.09
evaluation_0/Returns Std                     20.124
evaluation_0/Returns Max                   5172.69
evaluation_0/Returns Min                   5096.5
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5135.09
time/epoch (s)                                0
time/total (s)                            18861.4
Epoch                                       980
---------------------------------------  ----------------
2022-11-16 16:00:23.141683 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 981 finished
---------------------------------------  ----------------
epoch                                       981
total_step                               986000
replay_pool/size                         986000
trainer/alpha                                 0.0570697
trainer/alpha_loss                            0.0764861
trainer/entropy                              -6.02671
trainer/qf_loss                               7.84001
trainer/state_noise                           0.005
trainer/policy_loss                        -234.127
trainer/policy_loss_without_entropy         236.386
trainer/entropy_penalty                      -0.343942
trainer/entropy_percentage                   -0.001455
trainer/Q1Pred Mean                         235.572
trainer/Q1Pred Std                           79.8871
trainer/Q1Pred Max                          325.708
trainer/Q1Pred Min                            3.80481
trainer/Q2Pred Mean                         235.472
trainer/Q2Pred Std                           79.7046
trainer/Q2Pred Max                          326.829
trainer/Q2Pred Min                            6.79916
trainer/QTargetWithReg Mean                 235.32
trainer/QTargetWithReg Std                   79.6351
trainer/QTargetWithReg Max                  326.443
trainer/QTargetWithReg Min                    3.08102
trainer/PolicyLossWithoutReg Mean           236.386
trainer/PolicyLossWithoutReg Std             78.8547
trainer/PolicyLossWithoutReg Max            326.013
trainer/PolicyLossWithoutReg Min              7.10384
trainer/gradient_norm                       383.083
trainer/gradient_penalty                     -1.91541
trainer/gradient_percentage                  -0.0081029
exploration/num steps total              986000
exploration/num paths total                2146
exploration/path length this epoch Mean     904
exploration/path length this epoch Std        0
exploration/path length this epoch Max      904
exploration/path length this epoch Min      904
exploration/Rewards Mean                      5.10293
exploration/Rewards Std                       1.30314
exploration/Rewards Max                      10.2498
exploration/Rewards Min                      -0.383819
exploration/Returns Mean                   4613.05
exploration/Returns Std                       0
exploration/Returns Max                    4613.05
exploration/Returns Min                    4613.05
exploration/Num Paths                         1
exploration/Average Returns                4613.05
evaluation_0/num steps total                  7.76261e+06
evaluation_0/num paths total              15920
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.63687
evaluation_0/Rewards Std                      1.222
evaluation_0/Rewards Max                      9.44969
evaluation_0/Rewards Min                     -0.42363
evaluation_0/Returns Mean                  4636.87
evaluation_0/Returns Std                      9.81301
evaluation_0/Returns Max                   4649.75
evaluation_0/Returns Min                   4626.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4636.87
time/epoch (s)                                0
time/total (s)                            18876.8
Epoch                                       981
---------------------------------------  ----------------
2022-11-16 16:00:39.555911 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 982 finished
---------------------------------------  ----------------
epoch                                       982
total_step                               987000
replay_pool/size                         987000
trainer/alpha                                 0.0573328
trainer/alpha_loss                            0.287297
trainer/entropy                              -6.1005
trainer/qf_loss                               6.52087
trainer/state_noise                           0.005
trainer/policy_loss                        -239.629
trainer/policy_loss_without_entropy         241.857
trainer/entropy_penalty                      -0.349758
trainer/entropy_percentage                   -0.00144614
trainer/Q1Pred Mean                         241.22
trainer/Q1Pred Std                           73.5037
trainer/Q1Pred Max                          325.369
trainer/Q1Pred Min                            6.22891
trainer/Q2Pred Mean                         241.231
trainer/Q2Pred Std                           73.9295
trainer/Q2Pred Max                          326.372
trainer/Q2Pred Min                            7.46383
trainer/QTargetWithReg Mean                 241.135
trainer/QTargetWithReg Std                   73.3041
trainer/QTargetWithReg Max                  324.281
trainer/QTargetWithReg Min                   11.5552
trainer/PolicyLossWithoutReg Mean           241.857
trainer/PolicyLossWithoutReg Std             73.1907
trainer/PolicyLossWithoutReg Max            325.35
trainer/PolicyLossWithoutReg Min              8.44909
trainer/gradient_norm                       375.624
trainer/gradient_penalty                     -1.87812
trainer/gradient_percentage                  -0.00776543
exploration/num steps total              987000
exploration/num paths total                2147
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.0244
exploration/Rewards Std                       1.25241
exploration/Rewards Max                       9.82779
exploration/Rewards Min                      -0.511705
exploration/Returns Mean                   5024.4
exploration/Returns Std                       0
exploration/Returns Max                    5024.4
exploration/Returns Min                    5024.4
exploration/Num Paths                         1
exploration/Average Returns                5024.4
evaluation_0/num steps total                  7.77061e+06
evaluation_0/num paths total              15928
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.96023
evaluation_0/Rewards Std                      1.25653
evaluation_0/Rewards Max                      9.82199
evaluation_0/Rewards Min                     -0.356479
evaluation_0/Returns Mean                  4960.23
evaluation_0/Returns Std                     41.9638
evaluation_0/Returns Max                   5003.02
evaluation_0/Returns Min                   4888.54
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4960.23
time/epoch (s)                                0
time/total (s)                            18893.2
Epoch                                       982
---------------------------------------  ----------------
2022-11-16 16:00:55.383060 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 983 finished
---------------------------------------  ----------------
epoch                                       983
total_step                               988000
replay_pool/size                         988000
trainer/alpha                                 0.0577314
trainer/alpha_loss                            0.049791
trainer/entropy                              -6.01746
trainer/qf_loss                               6.87879
trainer/state_noise                           0.005
trainer/policy_loss                        -233.109
trainer/policy_loss_without_entropy         235.354
trainer/entropy_penalty                      -0.347396
trainer/entropy_percentage                   -0.00147606
trainer/Q1Pred Mean                         234.527
trainer/Q1Pred Std                           77.8649
trainer/Q1Pred Max                          322.727
trainer/Q1Pred Min                           15.6172
trainer/Q2Pred Mean                         234.391
trainer/Q2Pred Std                           77.8034
trainer/Q2Pred Max                          322.474
trainer/Q2Pred Min                           17.48
trainer/QTargetWithReg Mean                 234.553
trainer/QTargetWithReg Std                   77.412
trainer/QTargetWithReg Max                  324.656
trainer/QTargetWithReg Min                   14.6547
trainer/PolicyLossWithoutReg Mean           235.354
trainer/PolicyLossWithoutReg Std             76.8837
trainer/PolicyLossWithoutReg Max            322.957
trainer/PolicyLossWithoutReg Min             14.8206
trainer/gradient_norm                       379.546
trainer/gradient_penalty                     -1.89773
trainer/gradient_percentage                  -0.0080633
exploration/num steps total              988000
exploration/num paths total                2148
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.06642
exploration/Rewards Std                       1.27957
exploration/Rewards Max                      10.1212
exploration/Rewards Min                      -0.344407
exploration/Returns Mean                   5066.42
exploration/Returns Std                       0
exploration/Returns Max                    5066.42
exploration/Returns Min                    5066.42
exploration/Num Paths                         1
exploration/Average Returns                5066.42
evaluation_0/num steps total                  7.77861e+06
evaluation_0/num paths total              15936
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.10756
evaluation_0/Rewards Std                      1.26463
evaluation_0/Rewards Max                     10.0028
evaluation_0/Rewards Min                     -0.349602
evaluation_0/Returns Mean                  5107.56
evaluation_0/Returns Std                     15.666
evaluation_0/Returns Max                   5133.4
evaluation_0/Returns Min                   5089.73
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5107.56
time/epoch (s)                                0
time/total (s)                            18909
Epoch                                       983
---------------------------------------  ----------------
2022-11-16 16:01:11.976501 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 984 finished
---------------------------------------  ----------------
epoch                                       984
total_step                               989000
replay_pool/size                         989000
trainer/alpha                                 0.0562894
trainer/alpha_loss                            0.512534
trainer/entropy                              -6.17814
trainer/qf_loss                               6.64278
trainer/state_noise                           0.005
trainer/policy_loss                        -233.969
trainer/policy_loss_without_entropy         236.117
trainer/entropy_penalty                      -0.347764
trainer/entropy_percentage                   -0.00147285
trainer/Q1Pred Mean                         236.097
trainer/Q1Pred Std                           79.7962
trainer/Q1Pred Max                          328.496
trainer/Q1Pred Min                           12.9167
trainer/Q2Pred Mean                         235.496
trainer/Q2Pred Std                           79.9613
trainer/Q2Pred Max                          326.816
trainer/Q2Pred Min                            2.31274
trainer/QTargetWithReg Mean                 235.934
trainer/QTargetWithReg Std                   80.2649
trainer/QTargetWithReg Max                  328.206
trainer/QTargetWithReg Min                    1.20987
trainer/PolicyLossWithoutReg Mean           236.117
trainer/PolicyLossWithoutReg Std             78.8556
trainer/PolicyLossWithoutReg Max            327.997
trainer/PolicyLossWithoutReg Min             11.0891
trainer/gradient_norm                       360.032
trainer/gradient_penalty                     -1.80016
trainer/gradient_percentage                  -0.00762402
exploration/num steps total              989000
exploration/num paths total                2149
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11841
exploration/Rewards Std                       1.25549
exploration/Rewards Max                      10.0316
exploration/Rewards Min                      -0.384638
exploration/Returns Mean                   5118.41
exploration/Returns Std                       0
exploration/Returns Max                    5118.41
exploration/Returns Min                    5118.41
exploration/Num Paths                         1
exploration/Average Returns                5118.41
evaluation_0/num steps total                  7.78661e+06
evaluation_0/num paths total              15944
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.15591
evaluation_0/Rewards Std                      1.24585
evaluation_0/Rewards Max                     10.0239
evaluation_0/Rewards Min                     -0.479909
evaluation_0/Returns Mean                  5155.91
evaluation_0/Returns Std                     13.7819
evaluation_0/Returns Max                   5174.12
evaluation_0/Returns Min                   5128.95
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5155.91
time/epoch (s)                                0
time/total (s)                            18925.6
Epoch                                       984
---------------------------------------  ----------------
2022-11-16 16:01:27.808224 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 985 finished
---------------------------------------  ----------------
epoch                                       985
total_step                               990000
replay_pool/size                         990000
trainer/alpha                                 0.0563473
trainer/alpha_loss                           -0.744121
trainer/entropy                              -5.74126
trainer/qf_loss                               5.41905
trainer/state_noise                           0.005
trainer/policy_loss                        -246.969
trainer/policy_loss_without_entropy         249.107
trainer/entropy_penalty                      -0.323505
trainer/entropy_percentage                   -0.00129866
trainer/Q1Pred Mean                         249.234
trainer/Q1Pred Std                           70.2893
trainer/Q1Pred Max                          326.635
trainer/Q1Pred Min                           37.8635
trainer/Q2Pred Mean                         248.895
trainer/Q2Pred Std                           70.3704
trainer/Q2Pred Max                          326.544
trainer/Q2Pred Min                           35.2318
trainer/QTargetWithReg Mean                 249.307
trainer/QTargetWithReg Std                   70.2001
trainer/QTargetWithReg Max                  325.883
trainer/QTargetWithReg Min                   33.9309
trainer/PolicyLossWithoutReg Mean           249.107
trainer/PolicyLossWithoutReg Std             69.522
trainer/PolicyLossWithoutReg Max            326.06
trainer/PolicyLossWithoutReg Min             36.5716
trainer/gradient_norm                       362.915
trainer/gradient_penalty                     -1.81458
trainer/gradient_percentage                  -0.00728433
exploration/num steps total              990000
exploration/num paths total                2150
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.01533
exploration/Rewards Std                       1.25814
exploration/Rewards Max                      10.0781
exploration/Rewards Min                      -0.603823
exploration/Returns Mean                   5015.33
exploration/Returns Std                       0
exploration/Returns Max                    5015.33
exploration/Returns Min                    5015.33
exploration/Num Paths                         1
exploration/Average Returns                5015.33
evaluation_0/num steps total                  7.79461e+06
evaluation_0/num paths total              15952
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08723
evaluation_0/Rewards Std                      1.26762
evaluation_0/Rewards Max                      9.97209
evaluation_0/Rewards Min                     -0.390298
evaluation_0/Returns Mean                  5087.23
evaluation_0/Returns Std                     75.6723
evaluation_0/Returns Max                   5212.09
evaluation_0/Returns Min                   4961.02
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5087.23
time/epoch (s)                                0
time/total (s)                            18941.4
Epoch                                       985
---------------------------------------  ----------------
2022-11-16 16:01:43.992021 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 986 finished
---------------------------------------  ----------------
epoch                                       986
total_step                               991000
replay_pool/size                         991000
trainer/alpha                                 0.0578808
trainer/alpha_loss                            1.70522
trainer/entropy                              -6.59841
trainer/qf_loss                              11.4419
trainer/state_noise                           0.005
trainer/policy_loss                        -236.823
trainer/policy_loss_without_entropy         239.072
trainer/entropy_penalty                      -0.381922
trainer/entropy_percentage                   -0.00159752
trainer/Q1Pred Mean                         238.896
trainer/Q1Pred Std                           81.9382
trainer/Q1Pred Max                          323.683
trainer/Q1Pred Min                           20.9961
trainer/Q2Pred Mean                         237.884
trainer/Q2Pred Std                           82.0599
trainer/Q2Pred Max                          323.099
trainer/Q2Pred Min                            8.80639
trainer/QTargetWithReg Mean                 237.997
trainer/QTargetWithReg Std                   82.2615
trainer/QTargetWithReg Max                  322.184
trainer/QTargetWithReg Min                  -21.8877
trainer/PolicyLossWithoutReg Mean           239.072
trainer/PolicyLossWithoutReg Std             80.4657
trainer/PolicyLossWithoutReg Max            323.399
trainer/PolicyLossWithoutReg Min             25.3101
trainer/gradient_norm                       373.483
trainer/gradient_penalty                     -1.86741
trainer/gradient_percentage                  -0.00781108
exploration/num steps total              991000
exploration/num paths total                2151
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.99171
exploration/Rewards Std                       1.28983
exploration/Rewards Max                       9.80874
exploration/Rewards Min                      -0.394031
exploration/Returns Mean                   4991.71
exploration/Returns Std                       0
exploration/Returns Max                    4991.71
exploration/Returns Min                    4991.71
exploration/Num Paths                         1
exploration/Average Returns                4991.71
evaluation_0/num steps total                  7.80261e+06
evaluation_0/num paths total              15960
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.02671
evaluation_0/Rewards Std                      1.23298
evaluation_0/Rewards Max                      9.92272
evaluation_0/Rewards Min                     -0.436242
evaluation_0/Returns Mean                  5026.71
evaluation_0/Returns Std                     48.0902
evaluation_0/Returns Max                   5062.79
evaluation_0/Returns Min                   4902.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5026.71
time/epoch (s)                                0
time/total (s)                            18957.6
Epoch                                       986
---------------------------------------  ----------------
2022-11-16 16:02:00.211281 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 987 finished
---------------------------------------  ----------------
epoch                                       987
total_step                               992000
replay_pool/size                         992000
trainer/alpha                                 0.0572239
trainer/alpha_loss                           -0.107532
trainer/entropy                              -5.96241
trainer/qf_loss                              11.2849
trainer/state_noise                           0.005
trainer/policy_loss                        -237.857
trainer/policy_loss_without_entropy         240.105
trainer/entropy_penalty                      -0.341192
trainer/entropy_percentage                   -0.00142101
trainer/Q1Pred Mean                         239.509
trainer/Q1Pred Std                           76.4193
trainer/Q1Pred Max                          330.328
trainer/Q1Pred Min                          -15.734
trainer/Q2Pred Mean                         240.087
trainer/Q2Pred Std                           76.3317
trainer/Q2Pred Max                          332.178
trainer/Q2Pred Min                           -2.99676
trainer/QTargetWithReg Mean                 239.454
trainer/QTargetWithReg Std                   76.2197
trainer/QTargetWithReg Max                  330.816
trainer/QTargetWithReg Min                   -0.0602562
trainer/PolicyLossWithoutReg Mean           240.105
trainer/PolicyLossWithoutReg Std             75.5866
trainer/PolicyLossWithoutReg Max            330.998
trainer/PolicyLossWithoutReg Min            -14.2344
trainer/gradient_norm                       381.306
trainer/gradient_penalty                     -1.90653
trainer/gradient_percentage                  -0.0079404
exploration/num steps total              992000
exploration/num paths total                2152
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.91304
exploration/Rewards Std                       1.25914
exploration/Rewards Max                       9.64348
exploration/Rewards Min                      -0.333592
exploration/Returns Mean                   4913.04
exploration/Returns Std                       0
exploration/Returns Max                    4913.04
exploration/Returns Min                    4913.04
exploration/Num Paths                         1
exploration/Average Returns                4913.04
evaluation_0/num steps total                  7.81061e+06
evaluation_0/num paths total              15968
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.05048
evaluation_0/Rewards Std                      1.24713
evaluation_0/Rewards Max                     10.0445
evaluation_0/Rewards Min                     -0.432112
evaluation_0/Returns Mean                  5050.48
evaluation_0/Returns Std                     16.6138
evaluation_0/Returns Max                   5076.13
evaluation_0/Returns Min                   5018.17
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5050.48
time/epoch (s)                                0
time/total (s)                            18973.8
Epoch                                       987
---------------------------------------  ----------------
2022-11-16 16:02:16.051627 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 988 finished
---------------------------------------  ----------------
epoch                                       988
total_step                               993000
replay_pool/size                         993000
trainer/alpha                                 0.0586092
trainer/alpha_loss                            0.0593271
trainer/entropy                              -6.02091
trainer/qf_loss                               4.38669
trainer/state_noise                           0.005
trainer/policy_loss                        -246.909
trainer/policy_loss_without_entropy         249.11
trainer/entropy_penalty                      -0.35288
trainer/entropy_percentage                   -0.00141657
trainer/Q1Pred Mean                         249.161
trainer/Q1Pred Std                           72.4087
trainer/Q1Pred Max                          328.965
trainer/Q1Pred Min                           -0.608793
trainer/Q2Pred Mean                         249.047
trainer/Q2Pred Std                           72.3981
trainer/Q2Pred Max                          331.834
trainer/Q2Pred Min                           -0.309541
trainer/QTargetWithReg Mean                 249.289
trainer/QTargetWithReg Std                   72.4692
trainer/QTargetWithReg Max                  330.372
trainer/QTargetWithReg Min                    4.06966
trainer/PolicyLossWithoutReg Mean           249.11
trainer/PolicyLossWithoutReg Std             72.022
trainer/PolicyLossWithoutReg Max            328.307
trainer/PolicyLossWithoutReg Min              4.51716
trainer/gradient_norm                       369.513
trainer/gradient_penalty                     -1.84757
trainer/gradient_percentage                  -0.00741668
exploration/num steps total              993000
exploration/num paths total                2153
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89483
exploration/Rewards Std                       1.26255
exploration/Rewards Max                       9.77657
exploration/Rewards Min                      -0.469277
exploration/Returns Mean                   4894.83
exploration/Returns Std                       0
exploration/Returns Max                    4894.83
exploration/Returns Min                    4894.83
exploration/Num Paths                         1
exploration/Average Returns                4894.83
evaluation_0/num steps total                  7.81861e+06
evaluation_0/num paths total              15976
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.0344
evaluation_0/Rewards Std                      1.23833
evaluation_0/Rewards Max                      9.93361
evaluation_0/Rewards Min                     -0.463788
evaluation_0/Returns Mean                  5034.4
evaluation_0/Returns Std                     32.2997
evaluation_0/Returns Max                   5082.06
evaluation_0/Returns Min                   4983.39
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5034.4
time/epoch (s)                                0
time/total (s)                            18989.7
Epoch                                       988
---------------------------------------  ----------------
2022-11-16 16:02:32.530973 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 989 finished
---------------------------------------  ----------------
epoch                                       989
total_step                               994000
replay_pool/size                         994000
trainer/alpha                                 0.0561317
trainer/alpha_loss                            1.20486
trainer/entropy                              -6.41834
trainer/qf_loss                               8.09229
trainer/state_noise                           0.005
trainer/policy_loss                        -240.905
trainer/policy_loss_without_entropy         243.057
trainer/entropy_penalty                      -0.360273
trainer/entropy_percentage                   -0.00148226
trainer/Q1Pred Mean                         242.865
trainer/Q1Pred Std                           76.5418
trainer/Q1Pred Max                          328.155
trainer/Q1Pred Min                            9.82387
trainer/Q2Pred Mean                         242.596
trainer/Q2Pred Std                           76.3582
trainer/Q2Pred Max                          326.453
trainer/Q2Pred Min                            5.96028
trainer/QTargetWithReg Mean                 242.537
trainer/QTargetWithReg Std                   76.2303
trainer/QTargetWithReg Max                  327.058
trainer/QTargetWithReg Min                    3.70914
trainer/PolicyLossWithoutReg Mean           243.057
trainer/PolicyLossWithoutReg Std             75.6314
trainer/PolicyLossWithoutReg Max            326.34
trainer/PolicyLossWithoutReg Min             14.5079
trainer/gradient_norm                       358.243
trainer/gradient_penalty                     -1.79122
trainer/gradient_percentage                  -0.00736953
exploration/num steps total              994000
exploration/num paths total                2154
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.00097
exploration/Rewards Std                       1.21895
exploration/Rewards Max                       9.81375
exploration/Rewards Min                      -0.382585
exploration/Returns Mean                   5000.97
exploration/Returns Std                       0
exploration/Returns Max                    5000.97
exploration/Returns Min                    5000.97
exploration/Num Paths                         1
exploration/Average Returns                5000.97
evaluation_0/num steps total                  7.82661e+06
evaluation_0/num paths total              15984
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.07545
evaluation_0/Rewards Std                      1.25794
evaluation_0/Rewards Max                     10.0442
evaluation_0/Rewards Min                     -0.541517
evaluation_0/Returns Mean                  5075.45
evaluation_0/Returns Std                      9.61671
evaluation_0/Returns Max                   5085.54
evaluation_0/Returns Min                   5058.07
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5075.45
time/epoch (s)                                0
time/total (s)                            19006.2
Epoch                                       989
---------------------------------------  ----------------
2022-11-16 16:02:48.407070 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 990 finished
---------------------------------------  ----------------
epoch                                       990
total_step                               995000
replay_pool/size                         995000
trainer/alpha                                 0.05873
trainer/alpha_loss                           -0.0641378
trainer/entropy                              -5.97738
trainer/qf_loss                               6.44788
trainer/state_noise                           0.005
trainer/policy_loss                        -237.959
trainer/policy_loss_without_entropy         240.144
trainer/entropy_penalty                      -0.351052
trainer/entropy_percentage                   -0.00146184
trainer/Q1Pred Mean                         239.704
trainer/Q1Pred Std                           77.0738
trainer/Q1Pred Max                          325.429
trainer/Q1Pred Min                          -36.7815
trainer/Q2Pred Mean                         239.76
trainer/Q2Pred Std                           76.9625
trainer/Q2Pred Max                          326.659
trainer/Q2Pred Min                          -41.6932
trainer/QTargetWithReg Mean                 239.758
trainer/QTargetWithReg Std                   77.3452
trainer/QTargetWithReg Max                  326.009
trainer/QTargetWithReg Min                  -40.508
trainer/PolicyLossWithoutReg Mean           240.144
trainer/PolicyLossWithoutReg Std             76.5405
trainer/PolicyLossWithoutReg Max            326.419
trainer/PolicyLossWithoutReg Min            -41.6768
trainer/gradient_norm                       366.654
trainer/gradient_penalty                     -1.83327
trainer/gradient_percentage                  -0.00763405
exploration/num steps total              995000
exploration/num paths total                2155
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.88197
exploration/Rewards Std                       1.27447
exploration/Rewards Max                       9.73979
exploration/Rewards Min                      -0.560729
exploration/Returns Mean                   4881.97
exploration/Returns Std                       0
exploration/Returns Max                    4881.97
exploration/Returns Min                    4881.97
exploration/Num Paths                         1
exploration/Average Returns                4881.97
evaluation_0/num steps total                  7.83461e+06
evaluation_0/num paths total              15992
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.68357
evaluation_0/Rewards Std                      1.18491
evaluation_0/Rewards Max                      9.44289
evaluation_0/Rewards Min                     -0.394917
evaluation_0/Returns Mean                  4683.57
evaluation_0/Returns Std                     12.546
evaluation_0/Returns Max                   4707.75
evaluation_0/Returns Min                   4669.21
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4683.57
time/epoch (s)                                0
time/total (s)                            19022
Epoch                                       990
---------------------------------------  ----------------
2022-11-16 16:03:04.787664 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 991 finished
---------------------------------------  ----------------
epoch                                       991
total_step                               996000
replay_pool/size                         996000
trainer/alpha                                 0.0565539
trainer/alpha_loss                            0.324335
trainer/entropy                              -6.11291
trainer/qf_loss                               5.68969
trainer/state_noise                           0.005
trainer/policy_loss                        -245.445
trainer/policy_loss_without_entropy         247.652
trainer/entropy_penalty                      -0.345709
trainer/entropy_percentage                   -0.00139595
trainer/Q1Pred Mean                         247.246
trainer/Q1Pred Std                           67.0438
trainer/Q1Pred Max                          327.298
trainer/Q1Pred Min                           -9.59057
trainer/Q2Pred Mean                         247.632
trainer/Q2Pred Std                           66.7773
trainer/Q2Pred Max                          327.06
trainer/Q2Pred Min                          -10.1662
trainer/QTargetWithReg Mean                 247.181
trainer/QTargetWithReg Std                   67.3082
trainer/QTargetWithReg Max                  323.271
trainer/QTargetWithReg Min                  -12.4187
trainer/PolicyLossWithoutReg Mean           247.652
trainer/PolicyLossWithoutReg Std             66.1769
trainer/PolicyLossWithoutReg Max            327.012
trainer/PolicyLossWithoutReg Min             -7.27752
trainer/gradient_norm                       372.206
trainer/gradient_penalty                     -1.86103
trainer/gradient_percentage                  -0.00751469
exploration/num steps total              996000
exploration/num paths total                2156
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.95777
exploration/Rewards Std                       1.25554
exploration/Rewards Max                      10.015
exploration/Rewards Min                      -0.299787
exploration/Returns Mean                   4957.77
exploration/Returns Std                       0
exploration/Returns Max                    4957.77
exploration/Returns Min                    4957.77
exploration/Num Paths                         1
exploration/Average Returns                4957.77
evaluation_0/num steps total                  7.84261e+06
evaluation_0/num paths total              16000
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     4.75659
evaluation_0/Rewards Std                      1.21547
evaluation_0/Rewards Max                      9.55888
evaluation_0/Rewards Min                     -0.409667
evaluation_0/Returns Mean                  4756.59
evaluation_0/Returns Std                     10.1046
evaluation_0/Returns Max                   4774.27
evaluation_0/Returns Min                   4740.87
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               4756.59
time/epoch (s)                                0
time/total (s)                            19038.4
Epoch                                       991
---------------------------------------  ----------------
2022-11-16 16:03:20.557036 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 992 finished
---------------------------------------  ----------------
epoch                                       992
total_step                               997000
replay_pool/size                         997000
trainer/alpha                                 0.0576475
trainer/alpha_loss                            0.228479
trainer/entropy                              -6.08007
trainer/qf_loss                              31.0775
trainer/state_noise                           0.005
trainer/policy_loss                        -243.091
trainer/policy_loss_without_entropy         245.379
trainer/entropy_penalty                      -0.350501
trainer/entropy_percentage                   -0.0014284
trainer/Q1Pred Mean                         244.819
trainer/Q1Pred Std                           73.3454
trainer/Q1Pred Max                          325.952
trainer/Q1Pred Min                           -7.76225
trainer/Q2Pred Mean                         244.763
trainer/Q2Pred Std                           72.9062
trainer/Q2Pred Max                          326.971
trainer/Q2Pred Min                           -6.76185
trainer/QTargetWithReg Mean                 244.263
trainer/QTargetWithReg Std                   73.5875
trainer/QTargetWithReg Max                  326.169
trainer/QTargetWithReg Min                   -6.20971
trainer/PolicyLossWithoutReg Mean           245.379
trainer/PolicyLossWithoutReg Std             72.3044
trainer/PolicyLossWithoutReg Max            326.842
trainer/PolicyLossWithoutReg Min             -7.39768
trainer/gradient_norm                       387.623
trainer/gradient_penalty                     -1.93812
trainer/gradient_percentage                  -0.00789845
exploration/num steps total              997000
exploration/num paths total                2157
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.83302
exploration/Rewards Std                       1.22633
exploration/Rewards Max                       9.69315
exploration/Rewards Min                      -0.429751
exploration/Returns Mean                   4833.02
exploration/Returns Std                       0
exploration/Returns Max                    4833.02
exploration/Returns Min                    4833.02
exploration/Num Paths                         1
exploration/Average Returns                4833.02
evaluation_0/num steps total                  7.85061e+06
evaluation_0/num paths total              16008
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11686
evaluation_0/Rewards Std                      1.24404
evaluation_0/Rewards Max                      9.96859
evaluation_0/Rewards Min                     -0.505389
evaluation_0/Returns Mean                  5116.86
evaluation_0/Returns Std                      8.12322
evaluation_0/Returns Max                   5129.32
evaluation_0/Returns Min                   5105.71
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5116.86
time/epoch (s)                                0
time/total (s)                            19054.2
Epoch                                       992
---------------------------------------  ----------------
2022-11-16 16:03:37.007387 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 993 finished
---------------------------------------  ----------------
epoch                                       993
total_step                               998000
replay_pool/size                         998000
trainer/alpha                                 0.0573134
trainer/alpha_loss                           -0.456473
trainer/entropy                              -5.84035
trainer/qf_loss                               6.8844
trainer/state_noise                           0.005
trainer/policy_loss                        -241.86
trainer/policy_loss_without_entropy         244.05
trainer/entropy_penalty                      -0.33473
trainer/entropy_percentage                   -0.00137157
trainer/Q1Pred Mean                         243.753
trainer/Q1Pred Std                           76.9081
trainer/Q1Pred Max                          326.666
trainer/Q1Pred Min                           -5.42589
trainer/Q2Pred Mean                         243.28
trainer/Q2Pred Std                           77.195
trainer/Q2Pred Max                          325.274
trainer/Q2Pred Min                           -7.32702
trainer/QTargetWithReg Mean                 243.076
trainer/QTargetWithReg Std                   77.3171
trainer/QTargetWithReg Max                  325.108
trainer/QTargetWithReg Min                  -10.2221
trainer/PolicyLossWithoutReg Mean           244.05
trainer/PolicyLossWithoutReg Std             76.2734
trainer/PolicyLossWithoutReg Max            325.403
trainer/PolicyLossWithoutReg Min             -1.54595
trainer/gradient_norm                       370.946
trainer/gradient_penalty                     -1.85473
trainer/gradient_percentage                  -0.00759979
exploration/num steps total              998000
exploration/num paths total                2158
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      5.11551
exploration/Rewards Std                       1.24503
exploration/Rewards Max                      10.1293
exploration/Rewards Min                      -0.447528
exploration/Returns Mean                   5115.51
exploration/Returns Std                       0
exploration/Returns Max                    5115.51
exploration/Returns Min                    5115.51
exploration/Num Paths                         1
exploration/Average Returns                5115.51
evaluation_0/num steps total                  7.85861e+06
evaluation_0/num paths total              16016
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.11244
evaluation_0/Rewards Std                      1.24464
evaluation_0/Rewards Max                     10.17
evaluation_0/Rewards Min                     -0.484016
evaluation_0/Returns Mean                  5112.44
evaluation_0/Returns Std                     44.5207
evaluation_0/Returns Max                   5161.01
evaluation_0/Returns Min                   5019.62
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5112.44
time/epoch (s)                                0
time/total (s)                            19070.6
Epoch                                       993
---------------------------------------  ----------------
2022-11-16 16:03:52.909828 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 994 finished
---------------------------------------  ----------------
epoch                                       994
total_step                               999000
replay_pool/size                         999000
trainer/alpha                                 0.0578796
trainer/alpha_loss                            0.482126
trainer/entropy                              -6.16921
trainer/qf_loss                               7.1418
trainer/state_noise                           0.005
trainer/policy_loss                        -240.515
trainer/policy_loss_without_entropy         242.794
trainer/entropy_penalty                      -0.357071
trainer/entropy_percentage                   -0.00147068
trainer/Q1Pred Mean                         242.114
trainer/Q1Pred Std                           74.6803
trainer/Q1Pred Max                          326.111
trainer/Q1Pred Min                            9.68679
trainer/Q2Pred Mean                         242.066
trainer/Q2Pred Std                           74.4231
trainer/Q2Pred Max                          326.095
trainer/Q2Pred Min                            4.21108
trainer/QTargetWithReg Mean                 242.213
trainer/QTargetWithReg Std                   74.1006
trainer/QTargetWithReg Max                  325.667
trainer/QTargetWithReg Min                    2.57425
trainer/PolicyLossWithoutReg Mean           242.794
trainer/PolicyLossWithoutReg Std             73.4996
trainer/PolicyLossWithoutReg Max            325.635
trainer/PolicyLossWithoutReg Min              7.20838
trainer/gradient_norm                       384.373
trainer/gradient_penalty                     -1.92187
trainer/gradient_percentage                  -0.00791563
exploration/num steps total              999000
exploration/num paths total                2159
exploration/path length this epoch Mean    1000
exploration/path length this epoch Std        0
exploration/path length this epoch Max     1000
exploration/path length this epoch Min     1000
exploration/Rewards Mean                      4.89878
exploration/Rewards Std                       1.22908
exploration/Rewards Max                       9.84934
exploration/Rewards Min                      -0.618431
exploration/Returns Mean                   4898.78
exploration/Returns Std                       0
exploration/Returns Max                    4898.78
exploration/Returns Min                    4898.78
exploration/Num Paths                         1
exploration/Average Returns                4898.78
evaluation_0/num steps total                  7.86661e+06
evaluation_0/num paths total              16024
evaluation_0/path length Mean              1000
evaluation_0/path length Std                  0
evaluation_0/path length Max               1000
evaluation_0/path length Min               1000
evaluation_0/Rewards Mean                     5.08582
evaluation_0/Rewards Std                      1.24391
evaluation_0/Rewards Max                      9.96747
evaluation_0/Rewards Min                     -0.405714
evaluation_0/Returns Mean                  5085.82
evaluation_0/Returns Std                     13.6746
evaluation_0/Returns Max                   5103.36
evaluation_0/Returns Min                   5065.56
evaluation_0/Num Paths                        8
evaluation_0/Average Returns               5085.82
time/epoch (s)                                0
time/total (s)                            19086.5
Epoch                                       994
---------------------------------------  ----------------
2022-11-16 16:04:09.299529 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 995 finished
---------------------------------------  ---------------
epoch                                      995
total_step                                   1e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0570839
trainer/alpha_loss                           0.0578511
trainer/entropy                             -6.0202
trainer/qf_loss                              7.92546
trainer/state_noise                          0.005
trainer/policy_loss                       -230.773
trainer/policy_loss_without_entropy        232.978
trainer/entropy_penalty                     -0.343657
trainer/entropy_percentage                  -0.00147506
trainer/Q1Pred Mean                        232.628
trainer/Q1Pred Std                          81.0888
trainer/Q1Pred Max                         324.904
trainer/Q1Pred Min                         -26.9602
trainer/Q2Pred Mean                        232.667
trainer/Q2Pred Std                          81.2048
trainer/Q2Pred Max                         325.109
trainer/Q2Pred Min                         -28.2825
trainer/QTargetWithReg Mean                232.585
trainer/QTargetWithReg Std                  81.2424
trainer/QTargetWithReg Max                 324.389
trainer/QTargetWithReg Min                 -25.1762
trainer/PolicyLossWithoutReg Mean          232.978
trainer/PolicyLossWithoutReg Std            80.4918
trainer/PolicyLossWithoutReg Max           324.122
trainer/PolicyLossWithoutReg Min           -17.377
trainer/gradient_norm                      372.255
trainer/gradient_penalty                    -1.86127
trainer/gradient_percentage                 -0.00798907
exploration/num steps total                  1e+06
exploration/num paths total               2160
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     5.09172
exploration/Rewards Std                      1.26658
exploration/Rewards Max                      9.97566
exploration/Rewards Min                     -0.486316
exploration/Returns Mean                  5091.72
exploration/Returns Std                      0
exploration/Returns Max                   5091.72
exploration/Returns Min                   5091.72
exploration/Num Paths                        1
exploration/Average Returns               5091.72
evaluation_0/num steps total                 7.87461e+06
evaluation_0/num paths total             16032
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    5.10429
evaluation_0/Rewards Std                     1.24576
evaluation_0/Rewards Max                    10.1902
evaluation_0/Rewards Min                    -0.558831
evaluation_0/Returns Mean                 5104.29
evaluation_0/Returns Std                    15.6792
evaluation_0/Returns Max                  5126.2
evaluation_0/Returns Min                  5068.39
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              5104.29
time/epoch (s)                               0
time/total (s)                           19102.9
Epoch                                      995
---------------------------------------  ---------------
2022-11-16 16:04:25.244833 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 996 finished
---------------------------------------  ---------------
epoch                                      996
total_step                                   1.001e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0560028
trainer/alpha_loss                          -0.796275
trainer/entropy                             -5.72373
trainer/qf_loss                              6.05019
trainer/state_noise                          0.005
trainer/policy_loss                       -248.138
trainer/policy_loss_without_entropy        250.377
trainer/entropy_penalty                     -0.320545
trainer/entropy_percentage                  -0.00128025
trainer/Q1Pred Mean                        250.511
trainer/Q1Pred Std                          70.6437
trainer/Q1Pred Max                         330.498
trainer/Q1Pred Min                          36.1272
trainer/Q2Pred Mean                        250.24
trainer/Q2Pred Std                          70.8083
trainer/Q2Pred Max                         332.774
trainer/Q2Pred Min                          34.0031
trainer/QTargetWithReg Mean                250.444
trainer/QTargetWithReg Std                  70.8088
trainer/QTargetWithReg Max                 332.105
trainer/QTargetWithReg Min                  34.1237
trainer/PolicyLossWithoutReg Mean          250.377
trainer/PolicyLossWithoutReg Std            70.255
trainer/PolicyLossWithoutReg Max           331.726
trainer/PolicyLossWithoutReg Min            35.3186
trainer/gradient_norm                      383.57
trainer/gradient_penalty                    -1.91785
trainer/gradient_percentage                 -0.00765985
exploration/num steps total                  1.001e+06
exploration/num paths total               2161
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     5.01697
exploration/Rewards Std                      1.2626
exploration/Rewards Max                     10.3664
exploration/Rewards Min                     -0.546141
exploration/Returns Mean                  5016.97
exploration/Returns Std                      0
exploration/Returns Max                   5016.97
exploration/Returns Min                   5016.97
exploration/Num Paths                        1
exploration/Average Returns               5016.97
evaluation_0/num steps total                 7.88261e+06
evaluation_0/num paths total             16040
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    5.13929
evaluation_0/Rewards Std                     1.24682
evaluation_0/Rewards Max                    10.3805
evaluation_0/Rewards Min                    -0.411546
evaluation_0/Returns Mean                 5139.29
evaluation_0/Returns Std                    16.6936
evaluation_0/Returns Max                  5164.01
evaluation_0/Returns Min                  5116.67
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              5139.29
time/epoch (s)                               0
time/total (s)                           19118.9
Epoch                                      996
---------------------------------------  ---------------
2022-11-16 16:04:41.429323 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 997 finished
---------------------------------------  ---------------
epoch                                      997
total_step                                   1.002e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0585502
trainer/alpha_loss                           0.0911026
trainer/entropy                             -6.0321
trainer/qf_loss                              6.13019
trainer/state_noise                          0.005
trainer/policy_loss                       -238.467
trainer/policy_loss_without_entropy        240.669
trainer/entropy_penalty                     -0.35318
trainer/entropy_percentage                  -0.0014675
trainer/Q1Pred Mean                        240.588
trainer/Q1Pred Std                          76.2759
trainer/Q1Pred Max                         324.505
trainer/Q1Pred Min                          -2.28743
trainer/Q2Pred Mean                        240.656
trainer/Q2Pred Std                          76.3164
trainer/Q2Pred Max                         324.204
trainer/Q2Pred Min                           0.160088
trainer/QTargetWithReg Mean                240.301
trainer/QTargetWithReg Std                  76.6033
trainer/QTargetWithReg Max                 325.139
trainer/QTargetWithReg Min                   2.59877
trainer/PolicyLossWithoutReg Mean          240.669
trainer/PolicyLossWithoutReg Std            75.8237
trainer/PolicyLossWithoutReg Max           325.333
trainer/PolicyLossWithoutReg Min             0.55812
trainer/gradient_norm                      369.698
trainer/gradient_penalty                    -1.84849
trainer/gradient_percentage                 -0.00768064
exploration/num steps total                  1.002e+06
exploration/num paths total               2162
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     5.02391
exploration/Rewards Std                      1.26648
exploration/Rewards Max                     10.0111
exploration/Rewards Min                     -0.517289
exploration/Returns Mean                  5023.91
exploration/Returns Std                      0
exploration/Returns Max                   5023.91
exploration/Returns Min                   5023.91
exploration/Num Paths                        1
exploration/Average Returns               5023.91
evaluation_0/num steps total                 7.89061e+06
evaluation_0/num paths total             16048
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.96832
evaluation_0/Rewards Std                     1.22982
evaluation_0/Rewards Max                     9.72996
evaluation_0/Rewards Min                    -0.420329
evaluation_0/Returns Mean                 4968.32
evaluation_0/Returns Std                    16.6669
evaluation_0/Returns Max                  4998.34
evaluation_0/Returns Min                  4942.73
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4968.32
time/epoch (s)                               0
time/total (s)                           19135.1
Epoch                                      997
---------------------------------------  ---------------
2022-11-16 16:04:57.548200 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 998 finished
---------------------------------------  ---------------
epoch                                      998
total_step                                   1.003e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0556656
trainer/alpha_loss                          -0.99819
trainer/entropy                             -5.65439
trainer/qf_loss                              5.79983
trainer/state_noise                          0.005
trainer/policy_loss                       -246.121
trainer/policy_loss_without_entropy        248.298
trainer/entropy_penalty                     -0.314755
trainer/entropy_percentage                  -0.00126765
trainer/Q1Pred Mean                        247.997
trainer/Q1Pred Std                          73.8411
trainer/Q1Pred Max                         327.35
trainer/Q1Pred Min                          -4.02968
trainer/Q2Pred Mean                        248.115
trainer/Q2Pred Std                          73.6608
trainer/Q2Pred Max                         327.592
trainer/Q2Pred Min                           3.3211
trainer/QTargetWithReg Mean                248.142
trainer/QTargetWithReg Std                  73.5997
trainer/QTargetWithReg Max                 327.043
trainer/QTargetWithReg Min                  -0.667587
trainer/PolicyLossWithoutReg Mean          248.298
trainer/PolicyLossWithoutReg Std            73.336
trainer/PolicyLossWithoutReg Max           328.262
trainer/PolicyLossWithoutReg Min            -0.117436
trainer/gradient_norm                      372.438
trainer/gradient_penalty                    -1.86219
trainer/gradient_percentage                 -0.00749983
exploration/num steps total                  1.003e+06
exploration/num paths total               2163
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     5.01779
exploration/Rewards Std                      1.23822
exploration/Rewards Max                      9.699
exploration/Rewards Min                     -0.456919
exploration/Returns Mean                  5017.79
exploration/Returns Std                      0
exploration/Returns Max                   5017.79
exploration/Returns Min                   5017.79
exploration/Num Paths                        1
exploration/Average Returns               5017.79
evaluation_0/num steps total                 7.89861e+06
evaluation_0/num paths total             16056
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    4.97386
evaluation_0/Rewards Std                     1.21622
evaluation_0/Rewards Max                     9.82793
evaluation_0/Rewards Min                    -0.446554
evaluation_0/Returns Mean                 4973.86
evaluation_0/Returns Std                    12.8968
evaluation_0/Returns Max                  5001.26
evaluation_0/Returns Min                  4962.28
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              4973.86
time/epoch (s)                               0
time/total (s)                           19151.2
Epoch                                      998
---------------------------------------  ---------------
2022-11-16 16:05:13.368522 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 999 finished
---------------------------------------  ---------------
epoch                                      999
total_step                                   1.004e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0561545
trainer/alpha_loss                          -0.253973
trainer/entropy                             -5.91181
trainer/qf_loss                              5.62197
trainer/state_noise                          0.005
trainer/policy_loss                       -235.672
trainer/policy_loss_without_entropy        237.874
trainer/entropy_penalty                     -0.331974
trainer/entropy_percentage                  -0.00139559
trainer/Q1Pred Mean                        237.794
trainer/Q1Pred Std                          81.6072
trainer/Q1Pred Max                         326.472
trainer/Q1Pred Min                           4.50911
trainer/Q2Pred Mean                        237.415
trainer/Q2Pred Std                          81.563
trainer/Q2Pred Max                         326.591
trainer/Q2Pred Min                           7.54365
trainer/QTargetWithReg Mean                237.397
trainer/QTargetWithReg Std                  81.4843
trainer/QTargetWithReg Max                 326.591
trainer/QTargetWithReg Min                   2.48828
trainer/PolicyLossWithoutReg Mean          237.874
trainer/PolicyLossWithoutReg Std            81.0793
trainer/PolicyLossWithoutReg Max           326.295
trainer/PolicyLossWithoutReg Min             7.00107
trainer/gradient_norm                      373.988
trainer/gradient_penalty                    -1.86994
trainer/gradient_percentage                 -0.00786107
exploration/num steps total                  1.004e+06
exploration/num paths total               2164
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     5.03989
exploration/Rewards Std                      1.25432
exploration/Rewards Max                      9.89312
exploration/Rewards Min                     -0.473825
exploration/Returns Mean                  5039.89
exploration/Returns Std                      0
exploration/Returns Max                   5039.89
exploration/Returns Min                   5039.89
exploration/Num Paths                        1
exploration/Average Returns               5039.89
evaluation_0/num steps total                 7.90661e+06
evaluation_0/num paths total             16064
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    5.05798
evaluation_0/Rewards Std                     1.23939
evaluation_0/Rewards Max                     9.81221
evaluation_0/Rewards Min                    -0.532874
evaluation_0/Returns Mean                 5057.98
evaluation_0/Returns Std                    18.9652
evaluation_0/Returns Max                  5103.2
evaluation_0/Returns Min                  5038.53
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              5057.98
time/epoch (s)                               0
time/total (s)                           19167
Epoch                                      999
---------------------------------------  ---------------
2022-11-16 16:05:29.983602 CST | [0_sc-sac_Walker2d-v2_test_default] Epoch 1000 finished
---------------------------------------  ---------------
epoch                                     1000
total_step                                   1.005e+06
replay_pool/size                             1e+06
trainer/alpha                                0.0579256
trainer/alpha_loss                           0.472235
trainer/entropy                             -6.16577
trainer/qf_loss                             10.1442
trainer/state_noise                          0.005
trainer/policy_loss                       -241.878
trainer/policy_loss_without_entropy        244.166
trainer/entropy_penalty                     -0.357156
trainer/entropy_percentage                  -0.00146276
trainer/Q1Pred Mean                        244.591
trainer/Q1Pred Std                          74.0749
trainer/Q1Pred Max                         326.535
trainer/Q1Pred Min                          23.0846
trainer/Q2Pred Mean                        244.894
trainer/Q2Pred Std                          74.0764
trainer/Q2Pred Max                         328.587
trainer/Q2Pred Min                          23.6378
trainer/QTargetWithReg Mean                244.092
trainer/QTargetWithReg Std                  74.1734
trainer/QTargetWithReg Max                 328.299
trainer/QTargetWithReg Min                  22.7079
trainer/PolicyLossWithoutReg Mean          244.166
trainer/PolicyLossWithoutReg Std            73.2223
trainer/PolicyLossWithoutReg Max           326.818
trainer/PolicyLossWithoutReg Min            24.2234
trainer/gradient_norm                      386.263
trainer/gradient_penalty                    -1.93131
trainer/gradient_percentage                 -0.00790983
exploration/num steps total                  1.005e+06
exploration/num paths total               2165
exploration/path length this epoch Mean   1000
exploration/path length this epoch Std       0
exploration/path length this epoch Max    1000
exploration/path length this epoch Min    1000
exploration/Rewards Mean                     4.95656
exploration/Rewards Std                      1.23461
exploration/Rewards Max                      9.65223
exploration/Rewards Min                     -0.472336
exploration/Returns Mean                  4956.56
exploration/Returns Std                      0
exploration/Returns Max                   4956.56
exploration/Returns Min                   4956.56
exploration/Num Paths                        1
exploration/Average Returns               4956.56
evaluation_0/num steps total                 7.91461e+06
evaluation_0/num paths total             16072
evaluation_0/path length Mean             1000
evaluation_0/path length Std                 0
evaluation_0/path length Max              1000
evaluation_0/path length Min              1000
evaluation_0/Rewards Mean                    5.08758
evaluation_0/Rewards Std                     1.22845
evaluation_0/Rewards Max                     9.90343
evaluation_0/Rewards Min                    -0.476455
evaluation_0/Returns Mean                 5087.58
evaluation_0/Returns Std                    14.2779
evaluation_0/Returns Max                  5102.63
evaluation_0/Returns Min                  5059.77
evaluation_0/Num Paths                       8
evaluation_0/Average Returns              5087.58
time/epoch (s)                               0
time/total (s)                           19183.6
Epoch                                     1000
---------------------------------------  ---------------
